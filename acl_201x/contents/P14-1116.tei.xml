<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:09+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Comparing Multi-label Classification with Reinforcement Learning for Summarisation of Time-series Data</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>June 23-25 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitra</forename><surname>Gkatzia</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Mathematical and Computer Sciences</orgName>
								<orgName type="institution">Heriot-Watt University</orgName>
								<address>
									<settlement>Edinburgh</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helen</forename><surname>Hastie</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Mathematical and Computer Sciences</orgName>
								<orgName type="institution">Heriot-Watt University</orgName>
								<address>
									<settlement>Edinburgh</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Lemon</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Mathematical and Computer Sciences</orgName>
								<orgName type="institution">Heriot-Watt University</orgName>
								<address>
									<settlement>Edinburgh</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Comparing Multi-label Classification with Reinforcement Learning for Summarisation of Time-series Data</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1231" to="1240"/>
							<date type="published">June 23-25 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present a novel approach for automatic report generation from time-series data, in the context of student feedback generation. Our proposed methodology treats content selection as a multi-label (ML) classification problem, which takes as input time-series data and outputs a set of templates, while capturing the dependencies between selected templates. We show that this method generates output closer to the feedback that lecturers actually generated , achieving 3.5% higher accuracy and 15% higher F-score than multiple simple classifiers that keep a history of selected templates. Furthermore, we compare a ML classifier with a Reinforcement Learning (RL) approach in simulation and using ratings from real student users. We show that the different methods have different benefits, with ML being more accurate for predicting what was seen in the training data, whereas RL is more exploratory and slightly preferred by the students.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Summarisation of time-series data refers to the task of automatically generating text from vari- ables whose values change over time. We con- sider the task of automatically generating feed- back summaries for students describing their per- formance during the lab of a Computer Science module over the semester. Students' learning can be influenced by many variables, such as difficulty of the material ( <ref type="bibr" target="#b7">Person et al., 1995)</ref>, other dead- lines ( <ref type="bibr">Craig et al., 2004</ref>), attendance in lectures <ref type="bibr">(Ames, 1992)</ref>, etc. These variables have two im- portant qualities. Firstly, they change over time, and secondly they can be dependent on or inde- pendent of each other. Therefore, when generating feedback, we need to take into account all vari- ables simultaneously in order to capture potential dependencies and provide more effective and use- ful feedback that is relevant to the students.</p><p>In this work, we concentrate on content selec- tion which is the task of choosing what to say, i.e. what information is to be included in a report <ref type="bibr" target="#b8">(Reiter and Dale, 2000</ref>). Content selection deci- sions based on trends in time-series data determine the selection of the useful and important variables, which we refer to here as factors, that should be conveyed in a summary. The decisions of factor selection can be influenced by other factors that their values are correlated with; can be based on the appearance or absence of other factors in the summary; and can be based on the factors' be- haviour over time. Moreover, some factors may have to be discussed together in order to achieve some communicative goal, for instance, a teacher might want to refer to student's marks as a moti- vation for increasing the number of hours studied.</p><p>We frame content selection as a simple classifi- cation task: given a set of time-series data, decide for each template whether it should be included in a summary or not. In this paper, with the term 'template' we refer to a quadruple consisting of an id, a factor (bottom left of <ref type="table" target="#tab_1">Table 1</ref>), a reference type (trend, weeks, average, other) and surface text. However, simple classification assumes that the templates are independent of each other, thus the decision for each template is taken in isolation from the others, which is not appropriate for our domain. In order to capture the dependencies in the context, multiple simple classifiers can make the decisions for each template iteratively. After each iteration, the feature space grows by 1 fea- ture, in order to include the history of the previous template decisions. Here, we propose an alterna- tive method that tackles the challenge of interde- pendent data by using multi-label (ML) classifica- tion, which is efficient in taking data dependencies trend decreasing</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Summary</head><p>Your overall performance was excellent during the semester. Keep up the good work and maybe try some more challeng- ing exercises. Your attendance was vary- ing over the semester. Have a think about how to use time in lectures to improve your understanding of the material. You spent 2 hours studying the lecture material on average. You should dedicate more time to study. You seem to find the material easier to understand compared to the beginning of the semester. Keep up the good work! You revised part of the learn- ing material. Have a think whether revis- ing has improved your performance. into account and generating a set of labels (in our case templates) simultaneously ( <ref type="bibr">Tsoumakas et al., 2010)</ref>. ML classification requires no history, i.e. does not keep track of previous decisions, and thus has a smaller feature space. Our contributions to the field are as follows: we present a novel and efficient method for tackling the challenge of content selection using a ML clas- sification approach; we applied this method to the domain of feedback summarisation; we present a comparison with an optimisation technique (Rein- forcement Learning), and we discuss the similari- ties and differences between the two methods.</p><p>In the next section, we refer to the related work on Natural Language Generation from time-series data and on Content Selection. In Section 4.2, we describe our approach and we carry out a compar- ison with simple classification methods. In Sec- tion 5, we present the evaluation setup and in Sec- tion 6 we discuss the results, obtained in simula- tion and with real students. Finally, in Section 8, directions for future work are discussed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Natural Language Generation from time-series data has been investigated for various tasks such as weather forecast generation <ref type="bibr">(Belz and Kow, 2010;</ref><ref type="bibr">Angeli et al., 2010;</ref><ref type="bibr" target="#b11">Sripada et al., 2004</ref>), report generation from clinical data <ref type="bibr" target="#b0">(Hunter et al., 2011;</ref><ref type="bibr">Gatt et al., 2009)</ref>, narrative to assist children with communication needs <ref type="bibr">(Black et al., 2010)</ref> and audiovisual debrief generation from sensor data from Autonomous Underwater Vehicles missions ( <ref type="bibr" target="#b2">Johnson and Lane, 2011)</ref>.</p><p>The important tasks of time-series data sum- marisation systems are content selection (what to say), surface realisation (how to say it) and infor- mation presentation (Document Planning, Order- ing, etc.). In this work, we concentrate on content selection. Previous methods for content selection include Reinforcement Learning ( <ref type="bibr" target="#b9">Rieser et al., 2010)</ref>; multi-objective optimisation ( <ref type="bibr">Gkatzia et al., 2014</ref>); Gricean Maxims ( <ref type="bibr" target="#b10">Sripada et al., 2003)</ref>; Integer Linear Programming (Lampouras and An- droutsopoulos, 2013); collective content selection ( <ref type="bibr">Barzilay and Lapata, 2004</ref>); interest scores as- signed to content <ref type="bibr">(Androutsopoulos et al., 2013)</ref>; a combination of statistical and template-based ap- proaches to NLG ( <ref type="bibr" target="#b3">Kondadadi et al., 2013)</ref>; statis- tical acquisition of rules ( <ref type="bibr">Duboue and McKeown, 2003)</ref> and the Hidden Markov model approach for Content Selection and ordering ( <ref type="bibr">Barzilay and Lee, 2004</ref>).</p><p>Collective content selection ( <ref type="bibr">Barzilay and Lapata, 2004</ref>) is similar to our proposed method in that it is a classification task that predicts the tem- plates from the same instance simultaneously. The difference between the two methods lies in that the collective content selection requires the considera- tion of an individual preference score (which is de- fined as the preference of the entity to be selected or omitted, and it is based on the values of entity attributes and is computed using a boosting algo- rithm) and the identification of links between the entities with similar labels. In contrast, ML clas- sification does not need the computation of links between the data and the templates. ML classi- fication can also apply to other problems whose features are correlated, such as text classification <ref type="bibr" target="#b6">(Madjarov et al., 2012)</ref>, when an aligned dataset is provided.</p><p>ML classification algorithms have been divided into three categories: algorithm adaptation meth- ods, problem transformation and ensemble meth- ods ( <ref type="bibr" target="#b13">Tsoumakas and Katakis, 2007;</ref><ref type="bibr" target="#b6">Madjarov et al., 2012)</ref>. Algorithm adaptation approaches ( <ref type="bibr">Tsoumakas et al., 2010</ref>) extend simple classifi- cation methods to handle ML data. For exam- ple, the k-nearest neighbour algorithm is extended to ML-kNN by <ref type="bibr" target="#b18">Zhang and Zhou (2007)</ref>. ML- kNN identifies for each new instance its k nearest neighbours in the training set and then it predicts the label set by utilising the maximum a posteri- ori principle according to statistical information derived from the label sets of the k neighbours. Problem transformation approaches <ref type="bibr" target="#b13">(Tsoumakas and Katakis, 2007</ref>) transform the ML classifica- tion task into one or more simple classification tasks. Ensemble methods ( <ref type="bibr">Tsoumakas et al., 2010)</ref> are algorithms that use ensembles to perform ML learning and they are based on problem transfor- mation or algorithm adaptation methods. In this paper, we applied RAkEL (Random k-labelsets) ( <ref type="bibr">Tsoumakas et al., 2010)</ref>: an ensemble problem transformation method, which constructs an en- semble of simple-label classifiers, where each one deals with a random subset of the labels.</p><p>Finally, our domain for feedback generation is motivated by previous studies <ref type="bibr" target="#b5">(Law et al., 2005;</ref><ref type="bibr" target="#b16">van den Meulen et al., 2010</ref>) who show that text summaries are more effective in decision making than graphs therefore it is advantageous to provide a summary over showing users the raw data graph- ically. In addition, feedback summarisation from time-series data can be applied to the field of In- telligent Tutoring Systems ( <ref type="bibr">Gross et al., 2012</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data</head><p>The dataset consists of 37 instances referring to the activities of 26 students. For a few students there is more than 1 instance. An example of one such instance is presented in <ref type="table" target="#tab_1">Table 1</ref>. Each in- stance includes time-series information about the student's learning habits and the selected tem- plates that lecturers used to provide feedback to this student. The time-series information includes for each week of the semester: (1) the marks achieved at the lab; (2) the hours that the stu- dent spent studying; (3) the understandability of the material; (4) the difficulty of the lab exercises as assessed by the student; (5) the number of other deadlines that the student had that week; (6) health issues; (7) personal issues; (8) the number of lec- tures attended; and (9) the amount of revision that the student had performed. The templates describe these factors in four different ways:</p><p>1. &lt;trend&gt;: referring to the trend of a fac- tor over the semester (e.g. "Your performance was increasing..."), 2. &lt;weeks&gt;: explicitly describing the factor value at specific weeks (e.g. "In weeks 2, 3 and 9..."), 3. &lt;average&gt;: considering the average of a factor value (e.g. "You dedicated 1.5 hours studying on average..."), and 4. &lt;other&gt;: mentioning other relevant infor- mation (e.g. "Revising material will improve your performance"). For the corpus creation, 11 lecturers selected the content to be conveyed in a summary, given the set of raw data ( <ref type="bibr">Gkatzia et al., 2013)</ref>. As a result, for the same student there are various summaries provided by the different experts. This character- istic of the dataset, that each instance is associated with more than one solution, additionally moti- vates the use of multi-label classification, which is concerned with learning from examples, where each example is associated with multiple labels.</p><p>Our analysis of the dataset showed that there are significant correlations between the factors, for example, the number of lectures attended (LA) correlates with the student's understanding of the material (Und), see <ref type="table">Table 2</ref>. As we will discuss further in Section 5.1, content decisions are in- fluenced by the previously generated content, for example, if the lecturer has previously mentioned health issues, mentioning hours studied has a high probability of also being mentioned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Factor</head><p>(1) M (2) HS (3) Und (4) Diff (5) DL (6) HI <ref type="formula">(7)</ref> PI <ref type="formula">(8)</ref> LA <ref type="formula">(9)</ref>   <ref type="table">Table 2</ref>: The table presents the Pearson's correlation coefficients of the factors (* means p&lt;0.05).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Methodology</head><p>In this section, the content selection task and the suggested multi-label classification approach are presented. The development and evaluation of the time-series generation system follows the follow- ing pipeline ( <ref type="bibr">Gkatzia et al., 2013</ref>):</p><p>1. Time-Series data collection from students 2. Template construction by Learning and Teaching (L&amp;T) expert 3. Feedback summaries constructed by lectur- ers; random summaries rated by lecturers 4. Development of time-series generation sys- tems (Section 4.2, Section 5.3): ML system, RL system, Rule-based and Random system 5. Evaluation: (Section 5) -Offline evaluation (Accuracy and Reward) -Online evaluation (Subjective Ratings)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">The Content Selection Task</head><p>Our learning task is formed as follows: given a set of 9 time-series factors, select the content that is most appropriate to be included in a summary. Content is regarded as labels (each template rep- resents a label) and thus the task can be thought of as a classification problem. As mentioned, there are 4 ways to refer to a factor: (1) describing the trend, <ref type="formula">(2)</ref>   <ref type="table" target="#tab_1">Table 1</ref>. There are two decisions that need to be made: (1) whether to talk about a factor and (2) in which way to refer to it. Instead of dealing with this task in a hierarchical way, where the algorithm will first learn whether to talk about a factor and then to decide how to</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">The Multi-label Classification Approach</head><p>Traditional single-label classification is the task of identifying which label one new observation is as- sociated with, by choosing from a set of labels L ( <ref type="bibr">Tsoumakas et al., 2010)</ref>. Multi-label classifica- tion is the task of associating an observation with a set of labels Y ⊆ L ( <ref type="bibr">Tsoumakas et al., 2010)</ref>. One set of factor values can result in various sets of templates as interpreted by the different experts. A ML classifier is able to make deci- sions for all templates simultaneously and cap- ture these differences. The RAndom k-labELsets (RAkEL) ( <ref type="bibr">Tsoumakas et al., 2010</ref>) was applied in order to perform ML classification. RAkEL is based on Label Powerset (LP), a problem transfor- mation method ( <ref type="bibr">Tsoumakas et al., 2010)</ref>. LP ben- efits from taking into consideration label correla- tions, but does not perform well when trained with few examples as in our case ( <ref type="bibr">Tsoumakas et al., 2010)</ref>. RAkEL overcomes this limitation by con- structing a set of LP classifiers, which are trained with different random subsets of the set of labels ( <ref type="bibr">Tsoumakas et al., 2010)</ref>.</p><p>The LP method transforms the ML task, into one single-label multi-class classification task, where the possible set of predicted variables for the transformed class is the powerset of labels present in the original dataset. For instance, the set of labels L = {temp 0 , temp 1 , ...temp 28 } could be transformed to {temp 0,1,2 , temp 28,3,17, ...}. This algorithm does not perform well when consider- ing a large number of labels, due to the fact that the label space grows exponentially (Tsoumakas Classifier Accuracy Precision Recall F score (10-fold) Decision Tree (no history) *75.95% 67.56 75.96 67.87 Decision Tree (with predicted history) **73.43% 65. <ref type="bibr">49</ref> 72.05 70.95 Decision Tree (with real history) **78.09% 74.51 78.11 75.54 Majority-class (single label) **72.02% 61.73 77.37 68.21 RAkEL (multi-label) (no history) 76.95% 85.08 85.94 85.50 <ref type="table">Table 3</ref>: Average, precision, recall and F-score of the different classification methods (T-test, * denotes significance with p&lt;0.05 and ** significance with p&lt;0.01, when comparing each result to RAkEL).</p><p>et al., 2010). RAkEL tackles this problem by con- structing an ensemble of LP classifiers and train- ing each one on a different random subset of the set of labels ( <ref type="bibr">Tsoumakas et al., 2010</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">The Production Phase of RAkEL</head><p>The algorithm was implemented using the MU- LAN Open Source Java library <ref type="bibr">(Tsoumakas et al., 2011</ref>), which is based on WEKA <ref type="bibr" target="#b17">(Witten and Frank, 2005</ref>). The algorithm works in two phases:</p><p>1. the production of an ensemble of LP algo- rithms, and 2. the combination of the LP algorithms. RAkEL takes as input the following parameters: (1) the numbers of iterations m (which is devel- oper specified and denotes the number of models that the algorithm will produce), (2) the size of la- belset k (which is also developer specified), (3) the set of labels L, and (4) the training set D. During the initial phase it outputs an ensemble of LP clas- sifiers and the corresponding k-labelsets. A pseu- docode for the production phase is shown below: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">The Combination Phase</head><p>During the combination phase, the algorithm takes as input the results of the production phase, i.e. the ensemble of LPs with the corresponding k- labelsets, the set of labels L, and the new instance x and it outputs the result vector of predicted la- bels for instance x. During run time, RAkEL es- timates the average decision for each label in L and if the average is greater than a threshold t (de- termined by the developer) it includes the label in the predicted labelset. We used the standard pa- rameter values of t, k and m (t = 0.5, k = 3 and m equals to 58 (2*29 templates)). In future, we could perform parameter optimisation by using a technique similar to ( <ref type="bibr">Gabsdil and Lemon, 2004</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation</head><p>Firstly, we performed a preliminary evaluation on classification methods, comparing our proposed ML classification with multiple iterated classifica- tion approaches. The summaries generated by the ML classification system are then compared with the output of a RL system and two baseline sys- tems in simulation and with real students.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Comparison with Simple Classification</head><p>We compared the RAkEL algorithm with single- label (SL) classification. Different SL classifiers were trained using WEKA: JRip, Decision Trees, Naive Bayes, k-nearest neighbour, logistic regres- sion, multi-layer perceptron and support vector machines. It was found out that Decision Trees achieved on average 3% higher accuracy. We, therefore, went on to use Decision Trees that use generation history in three ways. Firstly, for Decision Tree (no history), 29 decision-tree classifiers were trained, one for each template. The input of these classifiers were the 9 factors and each classifier was trained in order to decide whether to include a specific template or not. This method did not take into account other selected templates -it was only based on the time- series data.</p><p>Secondly, for Decision Tree (with predicted history), 29 classifiers were also trained, but this time the input included the previous decisions made by the previous classifiers (i.e. the history) as well as the set of time-series data in order to emulate the dependencies in the dataset. For in- stance, classifier n was trained using the data from the 9 factors and the template decisions for tem- plates 0 to n − 1.</p><p>Thirdly, for Decision Tree (with real his- tory), the real, expert values were used rather than the predicted ones in the history. The above-mentioned classifiers are compared with, the Majority-class (single label) baseline, which labels each instance with the most frequent tem- plate.</p><p>The accuracy, the weighted precision, the weighted recall, and the weighted F-score of the classifiers are shown in <ref type="table">Table 3</ref>. It was found that in 10-fold cross validation RAkEL performs sig- nificantly better in all these automatic measures (accuracy = 76.95%, F-score = 85.50%). Remark- ably, ML achieves more than 10% higher F-score than the other methods <ref type="table">(Table 3)</ref>. The average accuracy of the single-label classifiers is 75.95% (10-fold validation), compared to 73.43% of clas- sification with history. The reduced accuracy of the classification with predicted history is due to the error in the predicted values. In this method, at every step, the predicted outcome was used in- cluding the incorrect decisions that the classifier made. The upper-bound accuracy is 78.09% cal- culated by using the expert previous decisions and not the potentially erroneous predicted decisions. This result is indicative of the significance of the relations between the factors showing that the pre- dicted decisions are dependent due to existing cor- relations as discussed in Section 1, therefore the system should not take these decisions indepen- dently. ML classification performs better because it does take into account these correlations and de- pendencies in the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">The Reinforcement Learning System</head><p>Reinforcement Learning (RL) is a machine learn- ing technique that defines how an agent learns to take optimal actions so as to maximise a cumu- lative reward <ref type="bibr" target="#b12">(Sutton and Barto, 1998)</ref>. Content selection is seen as a Markov Decision problem and the goal of the agent is to learn to take the se- quence of actions that leads to optimal content se- lection. The Temporal Difference learning method was used to train an agent for content selection.</p><p>Actions and States: The state consists of the time-series data and the selected templates. In or- der to explore the state space the agent selects a factor (e.g. marks, deadlines etc.) and then decides whether to talk about it or not.</p><p>Reward Function: The reward function reflects the lecturers' preferences on summaries and is derived through linear regression analysis of a dataset containing lecturer constructed summaries and ratings of randomly generated summaries. Specifically, it is the following cumulative multi- variate function:</p><formula xml:id="formula_0">Reward = a + n ∑ i=1 b i * x i + c * length</formula><p>where X = {x 1 , x 2 , ..., x n } describes the com- binations of the data trends observed in the time- series data and a particular template. a, b and c are the regression coefficients, and their values vary from -99 to 221. The value of x i is given by the function:</p><formula xml:id="formula_1">x i =           </formula><p>1, the combination of a factor trend and a template type is included in a summary 0, if not.</p><p>The RL system differs from the classification system in the way it performs content selection. In the training phase, the agent selects a factor and then decides whether to talk about it or not. If the agent decides to refer to a factor, the template is selected in a deterministic way, i.e. from the avail- able templates it selects the template that results in higher expected cumulative future reward.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">The Baseline Systems</head><p>We compared the ML system and the RL system with two baselines described below by measuring the accuracy of their outputs, the reward achieved by the reward function used for the RL system, and finally we also performed evaluation with stu- dent users. In order to reduce the confounding variables, we kept the ordering of content in all systems the same, by adopting the ordering of the rule-based system. The baselines are as follows:</p><p>1. Rule-based System: generates summaries based on Content Selection rules derived by work- ing with a L&amp;T expert and a student ( <ref type="bibr">Gkatzia et al., 2013</ref>).</p><p>2. Random System: initially, selects a factor randomly and then selects a template randomly, until it makes decisions for all factors.  <ref type="table">Table 4</ref>: Accuracy, average rewards (based on lecturers' preferences) and averages of the means of the student ratings. Accuracy significance (Z-test) with RAkEL at p&lt;0.05 is indicated as * and at p&lt;0.01 as **. Student ratings significance (Mann Whitney U test) with RAkEL at p&lt;0.05 is indicated as *.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head><p>Each of the four systems described above gener- ated 26 feedback summaries corresponding to the 26 student profiles. These summaries were evalu- ated in simulation and with real student users. <ref type="table">Table 4</ref> presents the accuracy, reward, and mode of student rating of each algorithm when used to generate the 26 summaries. Accuracy was esti- mated as the proportion of the correctly classified templates to the population of templates. In or- der to have a more objective view on the results, the score achieved by each algorithm using the reward function was also calculated. ML clas- sification achieved significantly higher accuracy, which was expected as it is a supervised learning method. The rule-based system and the RL sys- tem have lower accuracy compared to the ML sys- tem. There is evidently a mismatch between the rules and the test-set; the content selection rules are based on heuristics provided by a L&amp;T Expert rather than by the same pool of lecturers that cre- ated the test-set. On the contrary, the RL is trained to optimise the selected content and not to repli- cate the existing lecturer summaries, hence there is a difference in accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Results in Simulation</head><p>Accuracy measures how similar the generated output is to the gold standard, whereas the reward function calculates a score regarding how good the output is, given an objective function. RL is trained to optimise for this function, and therefore it achieves higher reward, whereas ML is trained to learn by examples, therefore it produces out- put closer to the gold standard (lecturer's produced summaries). RL uses exploration and exploitation to discover combinations of content that result in higher reward. The reward represents predicted ratings that lecturers would give to the summary. The reward for the lecturers' produced summaries is 124.62 and for the ML method is 107.77. The ML classification system performed worse than this gold standard in terms of reward, which is ex- pected given the error in predictions (supervised methods learn to reproduce the gold standard). Moreover, each decision is rewarded with a dif- ferent value as some combinations of factors and templates have greater or negative regression coef- ficients. For instance, the combination of the fac- tors "deadlines" and the template that corresponds to &lt;weeks&gt; is rewarded with 57. On the other hand, when mentioning the &lt;average&gt; difficulty the summary is "punished" with -81 (see descrip- tion of the reward function in Section 5.2). Conse- quently, a single poor decision in the ML classifi- cation can result in much less reward.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Subjective Results with Students</head><p>37 first year computer science students partici- pated in the study. Each participant was shown a graphical representation of the time-series data of one student and four different summaries gen- erated by the four systems (see <ref type="figure" target="#fig_1">Figure 1)</ref>. The or- der of the presented summaries was randomised. They were asked to rate each feedback summary on a 10-point rating scale in response to the fol- lowing statement: "Imagine you are the following student. How would you evaluate the following feedback summaries from 1 to 10?", where 10 cor- responds to the most preferred summary and 1 to the least preferred.</p><p>The difference in ratings between the ML clas- sification system, the RL system and the Rule- based system is not significant (see Mode (mean) in <ref type="table">Table 4</ref>, p&gt;0.05). However, there is a trend to- wards the RL system. The classification method reduces the generation steps, by making the de- cision of the factor selection and the template se- lection jointly. Moreover, the training time for the classification method is faster (a couple of seconds compared to over an hour). Finally, the student significantly prefer all the systems over the ran- dom.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Summary</head><p>We have shown that ML classification for sum- marisation of our time-series data has an accuracy of 76.95% and that this approach significantly out- performs other classification methods as it is able to capture dependencies in the data when mak- ing content selection decisions. ML classifica- tion was also directly compared to a RL method. It was found that although ML classification is almost 20% more accurate than RL, both meth- ods perform comparably when rated by humans. This may be due to the fact that the RL optimi- sation method is able to provide more varied re- sponses over time rather than just emulating the training data as with standard supervised learn- ing approaches. <ref type="bibr">Foster (2008)</ref> found similar re- sults when performing a study on generation of emphatic facial displays. A previous study by <ref type="bibr">Belz and Reiter (2006)</ref> has demonstrated that au- tomatic metrics can correlate highly with human ratings if the training dataset is of high quality. In our study, the human ratings correlate well to the average scores achieved by the reward func- tion. However, the human ratings do not correlate well to the accuracy scores. It is interesting that the two methods that score differently on various automatic metrics, such as accuracy, reward, pre- cision, recall and F-score, are evaluated similarly by users.</p><p>The comparison shows that each method can serve different goals. Multi-label classification generates output closer to gold standard whereas RL can optimise the output according to a reward function. ML classification could be used when the goal of the generation is to replicate phenom- ena seen in the dataset, because it achieves high accuracy, precision and recall. However, opti- misation methods can be more flexible, provide more varied output and can be trained for different goals, e.g. for capturing preferences of different users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Future Work</head><p>For this initial experiment, we evaluated with stu- dents and not with lecturers, since the students are the recipients of feedback. In future, we plan to evaluate with students' own data under real cir- cumstances as well as with ratings from lecturers. Moreover, we plan to utilise the results from this student evaluation in order to train an optimisation algorithm to perform summarisation according to students' preferences. In this case, optimisation would be the preferred method as it would not be appropriate to collect gold standard data from stu- dents. In fact, it would be of interest to investi- gate multi-objective optimisation techniques that can balance the needs of the lecturers to convey important content to the satisfaction of students.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The Figure show the evaluation setup. Students were presenting with the data in a graphical way and then they were asked to evaluate each summary in a 10-point Rating scale. Summaries displayed from left to right: ML system, RL, rule-based and random.</figDesc><graphic url="image-1.png" coords="8,72.00,62.82,510.22,318.63" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc>The table on the top left shows an example of the time-series raw data for feedback generation. The table on the bottom left shows an example of described trends. The box on the right presents a target summary (target summaries have been constructed by teaching staff).</figDesc><table></table></figure>

			<note place="foot" n="1"> There are fewer than 36 templates, because for some factors there are less than 4 possible ways of referring to them. refer to it, we transformed the task in order to reduce the learning steps. Therefore, classification can reduce the decision workload by deciding either in which way to talk about it, or not to talk about a factor at all.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Acknowledgements</head><p>The research leading to this work has re-ceived funding from the EC's FP7 programme: (FP7/2011-14) under grant agreement no. 248765 (Help4Mood).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head><p>Carole Ames. 1992. Classrooms: Goals, structures, and student motivation. </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Bt-nurse: Computer generation of natural language shift summaries from complex heterogeneous medical data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jim</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yvonne</forename><surname>Freer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Gatt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaji</forename><surname>Sripada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cindy</forename><surname>Sykes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Westwater</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="621" to="624" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Narrative monologue as a first step towards advanced mission debrief for AUV operator situational awareness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">15th International Conference on Advanced Robotics</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A statistical nlg framework for aggregated planning and realization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravi</forename><surname>Kondadadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blake</forename><surname>Howald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Schilder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">51st Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Using integer linear programming in conceptto-text generation to produce more compact texts</title>
	</analytic>
	<monogr>
		<title level="m">51st Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Gerasimos Lampouras and Ion Androutsopoulos</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A comparison of graphical and textual presentations of time series data to support medical decision making in the neonatal intensive care unit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><forename type="middle">S</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yvonne</forename><surname>Freer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jim</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">H</forename><surname>Logie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Mcintosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Quinn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Clinical Monitoring and Computing</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="183" to="194" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An extensive experimental comparison of methods for multi-label learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gjorgji</forename><surname>Madjarov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragi</forename><surname>Kocev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dejan</forename><surname>Gjorgjevikj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saso</forename><surname>Dzeroski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="3084" to="3104" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Pragmatics and pedagogy: Conversational rules and politeness strategies may inhibit effective tutoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalie</forename><forename type="middle">K</forename><surname>Person</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><forename type="middle">J</forename><surname>Kreuz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rolf</forename><forename type="middle">A</forename><surname>Zwaan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><forename type="middle">C</forename><surname>Graesser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Cognition and Instruction</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="161" to="188" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Building natural language generation systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehud</forename><surname>Reiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Dale</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Optimising information presentation for spoken dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Verena</forename><surname>Rieser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Lemon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingkun</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">48th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Generating english summaries of time series data using the gricean maxims</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Somayajulu</forename><surname>Sripada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehud</forename><surname>Reiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jim</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">9th ACM international conference on Knowledge discovery and data mining (SIGKDD)</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Lessons from deploying NLG technology for marine weather forecast text generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Somayajulu</forename><surname>Sripada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehud</forename><surname>Reiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Davy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nilssen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PAIS session of ECAI</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="760" to="764" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richart</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Multi-label classification: An overview</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grigorios</forename><surname>Tsoumakas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Katakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal Data Warehousing and Mining</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Random k-labelsets for multilabel classification</title>
	</analytic>
	<monogr>
		<title level="m">Grigorios Tsoumakas, Ioannis Katakis, and Ioannis Vlahavas</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="1079" to="1089" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Mulan: A java library for multi-label learning</title>
	</analytic>
	<monogr>
		<title level="m">Grigorios Tsoumakas, Eleftherios SpyromitrosXioufis, Josef Vilcek, and Ioannis Vlahavas</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2411" to="2414" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">When a graph is poorer than 100 words: A comparison of computerised natural language generation, human generated descriptions and graphical displays in neonatal intensive care</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marian</forename><surname>Van Den Meulen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Logie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yvonne</forename><surname>Freer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cindy</forename><surname>Sykes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Mcintosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jim</forename><surname>Hunter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Applied Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="77" to="89" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Data mining: Practical machine learning tools and techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eibe</forename><surname>Frank</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>Morgan Kaufmann Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Ml-knn: A lazy learning approach to multi-label learning. Pattern Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min-Ling</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Hua</forename><surname>Zhou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="2038" to="2048" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
