<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:15+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">WINGS: Writing with Intelligent Guidance and Suggestions</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>June 23-24, 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianjun</forename><surname>Dai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanchao</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingquan</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">WINGS: Writing with Intelligent Guidance and Suggestions</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
						<meeting>52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations <address><addrLine>Baltimore, Maryland USA</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="25" to="30"/>
							<date type="published">June 23-24, 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Without inspirations, writing may be a frustrating task for most people. In this study, we designed and implemented WINGS, a Chinese input method extended on IBus-Pinyin with intelligent writing assistance. In addition to supporting common Chinese input, WINGS mainly attempts to spark users&apos; inspirations by recommending both word level and sentence level writing suggestions. The main strategies used by WINGS, including providing syntactically and semantically related words based on word vector representation and recommending contextually related sentences based on LDA, are discussed and described. Experimental results suggest that WINGS can facilitate Chinese writing in an effective and creative manner.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Writing articles may be a challenging task, as we usually have trouble in finding the suitable words or suffer from lack of ideas. Thus it may be very helpful if some writing reference information, e.g., words or sentences, can be recommended while we are composing an article.</p><p>On the one hand, for non-english users, e.g., Chinese, the Chinese input method is our first tool for interacting with a computer. Nowadays, the most popular Chinese input methods are Pinyin-based ones, such as Sougou Pinyin <ref type="bibr">1</ref> and Google Pinyin 2 . These systems only present accurate results of Pinyin-to-Character conversion. Considering these systems' lack of suggestions for related words, they hardly provide writers with substantial help in writing. On the other hand, try to meet the need of writing assistance, more and more systems facilitating Chinese writing have been available to the public, such as WenXin Super Writing Assistant <ref type="bibr">3</ref> and BigWriter <ref type="bibr">4</ref> , and among others. However, due to their shortcomings of building examples library manually and lack of corpus mining techniques, most of the time the suggestions made by these systems are not creative or contextual.</p><p>Thus, in this paper, we present Writing with INtelligent Guidance and Suggestions (WINGS) <ref type="bibr">5</ref> , a Chinese input method extended with intelligent writing assistance. Through WINGS, users can receive intelligent, real-time writing suggestions, including both word level and sentence level. Different from existing Chinese writing assistants, WINGS mainly attempts to spark users' writing inspirations from two aspects: providing diverse related words to expand users' minds and recommending contextual sentences according to their writing intentions. Based on corpus mining with Natural Language Processing techniques, e.g., word vector representation and LDA model, WINGS aims to facilitate Chinese writing in an effective and creative manner.</p><p>For example, when using WINGS to type "xuxurusheng", a sequence of Chinese Pinyin characters for "栩栩如生" (vivid/vividly), the Pinyin-to-Character Module will generate "栩栩 如生" and some other candidate Chinese words.</p><p>Then the Words Recommending Module generates word recommendations for "栩栩如 生 ". The recommended words are obtained through calculating word similarities based on word vector representations as well as rule-based strategy (POS patterns).</p><p>In the Sentences Recommending Module, we first use " 栩栩如生" to retrieve example sentences from sentences library. Then the topic similarities between the local context and the candidate sentences are evaluated for contextual Chinese Pinyin Sequence</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recommended Words</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recommended Sentences</head><p>Pinyin-to-Character results (Original Words) <ref type="figure">Figure 1</ref>. Screenshot of WINGS.</p><p>sentence recommendations.</p><p>At last in consideration of users' feedback, we introduce a User Feedback Module to our system. The recorded feedback data will in turn influence the scores of words and sentences in Recommending Modules above. <ref type="figure">Figure 1</ref> shows a screenshot of WINGS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Input Method</head><p>Chinese input method is one of the most important tools for Chinese PC users. Nowadays, Pinyin-based input method is the most popular one. The main strategy that Pinyin-based input method uses is automatically converting Pinyin to Chinese characters <ref type="bibr" target="#b2">(Chen and Lee, 2000</ref>). In recent years, more and more intelligent strategies have been adopted by different input methods, such as Triivi <ref type="bibr">6</ref> , an English input method that attempts to increase writing speed by suggesting words and phrases, and PRIME ( <ref type="bibr" target="#b3">Komatsu et al., 2005</ref>), an English/Japanese input system that utilizes visited documents to predict the user's next word to be input.</p><p>In our system the basic process was Pinyin  Characters (words)  Writing Suggestions (including words and sentences). We mainly focused on writing suggestions from Characters (words) in this paper. As the Pinyin-to-Character was the underlining work, we developed our system directly on the open source framework of the IBus (an intelligent input Bus for Linux and Unix OS) and IBus-Pinyin 7 input method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Writing Assistant</head><p>As previously mentioned, several systems are available in supporting Chinese writing, such as WenXin Super Writing Assistant and Big Writer.</p><p>These systems are examples of a retrieval-based writing assistant, which is primarily based on a large examples library and provides users with a search function.</p><p>In contrast, other writing assistants employ special NLP strategies. <ref type="bibr" target="#b4">Liu et al. (2011</ref><ref type="bibr" target="#b5">Liu et al. ( , 2012</ref> proposed two computer writing assistants: one for writing love letters and the other for blog writing. In these two systems, some special techniques were used, including text generation, synonym substitution, and concept expansion. PENS ( <ref type="bibr" target="#b6">Liu et al., 2000</ref>) and FLOW ( <ref type="bibr" target="#b1">Chen et al., 2012</ref>) are two writing assistants designed for students of English as a Foreign Language (EFL) practicing writing, which are mainly based on Statistical Machine Translation (SMT) strategies.</p><p>Compared with the above mentioned systems, WINGS is closer to retrieval-based writing assistants in terms of function. However, WINGS can provide more intelligent suggestions because of the introduction of NLP techniques, e.g., word vector representation and topic model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Word Representations in Vector Space</head><p>Recently, <ref type="bibr" target="#b7">Mikolov et al. (2013)</ref> proposed novel model architectures to compute continuous vector representations of words obtained from very large data sets. The quality of these representations was assessed through a word similarity task, and according to their report, the word vectors provided state-of-the-art performance for measuring syntactic and semantic word similarities in their test set. Their research produced the open source tool word2vec 8 .</p><p>In our system, we used word2vec to train the word vectors from a corpus we processed beforehand. For the Words Recommending Module, these vectors were used to determine the similarity among different words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Latent Dirichlet Allocation</head><p>The topic model Latent Dirichlet Allocation (LDA) is a generative probabilistic model of a corpus. In this model, documents are represented as random mixtures of latent topics, where each topic is characterized by the distribution of words ( <ref type="bibr" target="#b0">Blei et al., 2003)</ref>. Each document can thus be represented as a distribution of topics.</p><p>Gibbs Sampling is a popular and efficient strategy used for LDA parameter estimation and inference. This technique is used in implementing several open sourcing LDA tools, such as GibbsLDA++ 9 <ref type="bibr" target="#b8">(Phan and Nguyen, 2007)</ref>, which was used in this paper.</p><p>In order to generate contextual sentence suggestions, we ensured that the sentences recommended to the user were topic related to the local context (5-10 words previously input) based on the LDA model. <ref type="figure" target="#fig_1">Figure 2</ref> illustrates the overall architecture of WINGS.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Overview of WINGS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Start</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pinyin to Character</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">System Architecture</head><p>Our system is composed of four different <ref type="bibr">9</ref> http://gibbslda.sourceforge.net modules: Pinyin-to-Character Module, Words Recommending Module, Sentences Recommending Module, and User Feedback Module. The following sub-sections discuss these modules in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Pinyin-to-Character Module</head><p>Our system is based on the open sourcing input framework IBus and extended on the IBus-Pinyin input method. Thus, the Pinyin-to-Character module is adopted from the original IBus-Pinyin system. This module converts the input Chinese Pinyin sequence into a list of candidate Chinese words, which we refer to as original words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Words Recommending Module  Words vector representations</head><p>In this preparatory step for word recommendation, words vector representations are obtained using the word2vec tool. This will be described in detail in Section 4.  Obtain the most related words Our system will obtain the focused original word and calculate the cosine similarities between this word and the rest of the words in the dictionary. Thus, we can obtain the top 200 most similar words according to their cosine values. These words are referred to as recommended words. According to <ref type="bibr" target="#b7">Mikolov et al. (2013)</ref>, these words are syntactically and semantically similar to the original word.  Re-rank the recommended words In order to further improve word recommending, we introduce several special POS patterns <ref type="table">(Table  1)</ref>. If the POS of the original word and the recommended word satisfy one of the POS patterns we specified, the score (based on the cosine similarity) of the recommended word will be boosted. In addition, the score of the word selected by the user before will also be boosted. Therefore, these words will be ranked higher in the recommended words list.  <ref type="table">Table 1</ref>. Special POS patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Sentences Recommending Module  Sentences topic distribution</head><p>In this preparatory step for sentence recommendation, sentences topic distribution vectors and other parameters are trained using the GibbsLDA++. This step will be discussed in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head> Retrieve relative sentences via CLucene</head><p>The focused original or recommended word will be used to search the most related sentences in the sentences index via CLucene <ref type="bibr">10</ref> . At most 200 sentences will be taken as candidates, which will be called recommended sentences.  Re-rank the recommended sentences To ensure that the recommended sentences are topic related to our local input context (5-10 words previously input), we use Gibbs Sampling to infer the topic vector of the local context, and calculate the KL divergence between the local context and each recommended sentence. Finally, the recommended sentences will be re-ranked based on their KL divergences value with respect to the local context and the boost score derived from the feedback information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">User Feedback Module</head><p>This module saves the users' feedback information, particularly the number of times when users select the recommended words and sentences. This information will be used as a boost factor for the Words and Sentences Recommending Modules. Our reasons for introducing this module are two-fold: the users' feedback reflects their preference, and at the same time, this information can somewhat indicate the quality of the words and sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Data Pre-processing</head><p>In this section, the procedure of our data pre-processing is discussed in detail. Firstly, our raw corpus was crawled from DiYiFanWen 11 , a Chinese writing website that includes all types of writing materials. After extracting useful composition examples from each raw html file, we merged all articles into a single file named large corpus. Finally, a total of 324,302 articles were merged into the large corpus (with a total size of 320 MB). For words recommending, each of the articles in our large corpus was segmented into words by ICTCLAS 12 with POS tags. Subsequently, word2vec tool was used on the words sequence (with useless symbols filtered). Finally, the words, their respective vector representations and main POS tags were combined, and we built these data into one binary file.</p><p>For sentences recommending, the large corpus was segmented into sentences based on special punctuations. Sentences that were either too long or too short were discarded. Finally, 2,567,948 sentences were left, which we called original sentences. An index was created on these sentences using CLucene. Moreover, we segmented these original sentences and filtered the punctuations and stop words. Accordingly, these new sentences were named segmented sentences. We then ran GibbsLDA++ on the segmented sentences, and the Gibbs sampling result and topic vector of each sentence were thus obtained. Finally, we built the original sentence and their topic vectors into a binary file. The Gibbs sampling data used for inference was likewise saved into a binary file. <ref type="table" target="#tab_2">Table 2</ref> lists all information on the resources of WINGS.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Items Information</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Results</head><p>This section discusses the experimental results of WINGS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Words Recommending</head><p>The top 20 recommended words for the sample word "老师" (teacher) are listed in <ref type="table" target="#tab_3">Table 3</ref>.</p><p>Compared with traditional methods (using Cilin, Hownet, and so forth.), using the word vectors to determine related words will identify more diverse and meaningful related words and this quality of WINGS is shown in <ref type="table">Table 4</ref>. With the diversity of recommended words, writers' minds can be expanded easily.</p><p>1-10: 同学(student), 上课(conduct class), 语文 课(Chinese class), 语重心长(with sincere words and earnest wishes), 和蔼可亲(affability), 教导 (guide), 讲课(lecture), 讲台(dais), 不厌其烦 (patient), 全班(the whole class) 11-20: 下课(finish class), 一番话(remarks), 数 学课(math class), 开小差(be absent-minded), 戒 尺 (ferule), 班 主 任 (class adviser), 忐 忑 不 安 (restless), 记得(remember), 青出于蓝而胜于蓝 (excel one's master), 听讲(listen to)  <ref type="table">Table 4</ref>. Diversity of recommended words for "老师" (teacher).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Sentences Recommending</head><p>By introducing the topic model LDA, the sentences recommended by WINGS are related to the topic of the local context. <ref type="table">Table 5</ref> presents the top 5 recommended sentences for the word "栩栩如生" (vivid/vividly) in two different local contexts: one refers to characters in books; the other refers to statues and sculptures. Most sentences in the first group are related to the first context, and most from the second group are related to the second context. In order to assess the performance of WINGS in sentence recommendation, the following evaluation was implemented. A total of 10 Chinese words were randomly selected, and each word was given two or three different local contexts as above (contexts varied for different words). Finally, we obtained a total of 24 groups of data, each of which included an original word, a local context, and the top 10 sentences recommended by WINGS. To avoid the influence of personal preferences, 12 students were invited to judge whether each sentence in the 24 different groups was related to their respective local context. We believed that a sentence was related to its context only when at least 70% of the evaluators agreed. The Precision@10 measure in Information Retrieval was used, and the total average was 0.76, as shown in <ref type="table">Table 6</ref>.</p><p>Additionally, when we checked the sentences which were judged not related to their respective local context, we found that these sentences were generally too short after stop words removal, and as a result the topic distributions inferred from Gibbs Sampling were not that reliable.</p><p>Context 1 is about characters in books: 故事(story), 人物(character), 形象(image), 作品(works)  <ref type="table">Table 6</ref>. Precision@10 value of each word under their respective context and the total average.</p><formula xml:id="formula_0">1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Real Time Performance</head><p>In order to ensure the real time process for each recommendation, we used CLucene to index and retrieve sentences and memory cache strategy to reduce the time cost of fetching sentences' information. <ref type="table">Table 7</ref> shows the average and max responding time of each recommendation of randomly selected 200 different words (Our test environment is 64-bit Ubuntu 12.04 LTS OS on PC with 4GB memory and 3.10GHz Dual-Core CPU).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Item</head><p>Responding time Average 154 ms Max 181 ms <ref type="table">Table 7</ref>. The average and max responding time of 200 different words' recommending process</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>In this paper, we presented WINGS, a Chinese input method extended with writing assistance that provides intelligent, real-time suggestions for writers. Overall, our system provides syntactically and semantically related words, as well as recommends contextually related sentences to users. As for the large corpus, on which the recommended words and sentences are based, and the corpus mining based on NLP techniques (e.g., word vector representation and topic model LDA), experimental results show that our system is both helpful and meaningful. In addition, given that the writers' feedback is recorded, WINGS will become increasingly effective for users while in use. Thus, we believe that WINGS will considerably benefit writers.</p><p>In future work, we will conduct more user experiments to understand the benefits of our system to their writing. For example, we can integrate WINGS into a crowdsourcing system and analyze the improvement in our users' writing. Moreover, our system may still be improved further. For example, we are interested in adding a function similar to Google Suggest, which is based on the query log of the search engine, in order to provide more valuable suggestions for users.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Boost in score: 1).Whether the original and recommended word match one of the specified patterns, such as A-N, V-N and etc. 2). Whether The word has been used before 2. Re-rank candidate words.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Overall architecture of WINGS.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Average Precision@10 value of the 24 groups data 0. 76</head><label>76</label><figDesc>这本书刻画了许多栩栩如生的人物 (The characters of this book are depicted vividly) 2 这本书人物描写栩栩如生，故事叙述有声有 色 (The characters of this book are depicted vividly and the story is impressive narrative) 3 故事中的人物形象栩栩如生 (The characters of this story are depicted vividly) 4 他的作品情节惊险曲折人物栩栩如生结局出 人意料 (His works are full of plot twists, vivid characters, and surprising endings) 5 书中的人物都被葛竞姐姐描写得栩栩如生 (The characters in the book are depicted vividly by Jing Zhuge) Context 2 is about statues and sculptures: 塑像(statue), 雕塑(sculpture), 石刻(stone inscription), 寺庙(temple) 1 墙上绘满了威武的龙，栩栩如生 (The walls are painted with mighty and vivid dragons) 2 两侧的十八罗汉神态各异，栩栩如生 (On both sides there are standing 18 vivid Arhats with different manners) 3 大雄宝殿气势恢弘，殿内人物栩栩如生 (the Great Buddha Hall is grand and the statues there are vivid) 4 每尊都栩栩如生，活灵活现 (Each statue is vivid and lifelike) 5 檐角上各有七个栩栩如生的飞禽走兽像，它 们各有其寓意 (On each of the eave angles there are 7 vivid statues of animals and birds with special meanings) Table 5. Top 5 recommended sentences for "栩 栩如生" (vivid/vividly) in two different local contexts.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 . Resources information.</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 .</head><label>3</label><figDesc></figDesc><table>Top 20 recommended words for "老师" 
(teacher). </table></figure>

			<note place="foot" n="3"> http://www.xiesky.com 4 http://www.zidongxiezuo.com/bigwriter_intro.php 5 The DEB package for Ubuntu 64 and recorded video of our system demonstration can be accessed at this URL: http://yunpan.cn/Qp4gM3HW446Rx (password:63b3)</note>

			<note place="foot" n="6"> http://baike.baidu.com/view/4849876.htm 7 https://code.google.com/p/ibus</note>

			<note place="foot" n="8"> https://code.google.com/p/word2vec</note>

			<note place="foot" n="10"> http://sourceforge.net/projects/clucene 11 http://www.diyifanwen.com 12 http://ictclas.nlpir.org</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Latent dirichlet allocation. the Journal of machine Learning research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">FLOW: a first-language-oriented writing assistant system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mei-Hua</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shih-Ting</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hung-Ting</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting-Hui</forename><surname>Kao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><forename type="middle">S</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2012 System Demonstrations</title>
		<meeting>the ACL 2012 System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="157" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A new statistical approach to Chinese Pinyin input</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Fu</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th annual meeting on association for computational linguistics</title>
		<meeting>the 38th annual meeting on association for computational linguistics</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="241" to="247" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Corpus-based predictive text input</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroyuki</forename><surname>Komatsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoru</forename><surname>Takabayash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshiyuki</forename><surname>Masui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2005 international conference on active media technology</title>
		<meeting>the 2005 international conference on active media technology</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="75" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Computer assisted writing system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chien-Liang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chia-Hoang</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ssu-Han</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Wei</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Expert Systems with Applications</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="804" to="811" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Intelligent computer assisted blog writing system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chien-Liang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chia-Hoang</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo-Yuan</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="4496" to="4504" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">PENS: A machine-aided English writing system for Chinese users</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Endong</forename><surname>Xun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changning</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 38th Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="529" to="536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">GibbsLDA++: A C/C++ implementation of latent Dirichlet allocation (LDA)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuan-Hieu</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cam-Tu</forename><surname>Nguyen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
