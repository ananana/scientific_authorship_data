<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:51+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Exploring Semantic Properties of Sentence Embeddings</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 15-20, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xunjie</forename><surname>Zhu</surname></persName>
							<email>xunjie.zhu@ rutgers.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Rutgers University Piscataway</orgName>
								<address>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tingfeng</forename><surname>Li</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Northwestern Polytechnical University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>De Melo</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Rutgers University Piscataway</orgName>
								<address>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Exploring Semantic Properties of Sentence Embeddings</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="632" to="637"/>
							<date type="published">July 15-20, 2018</date>
						</imprint>
					</monogr>
					<note>632</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Neural vector representations are ubiquitous throughout all subfields of NLP. While word vectors have been studied in much detail, thus far only little light has been shed on the properties of sentence embeddings. In this paper, we assess to what extent prominent sentence embedding methods exhibit select semantic properties. We propose a framework that generate triplets of sentences to explore how changes in the syntactic structure or semantics of a given sentence affect the similarities obtained between their sentence embeddings.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Neural vector representations have become ubiq- uitous in all subfields of natural language process- ing. For the case of word vectors, important prop- erties of the representations have been studied, in- cluding their linear substructures ( <ref type="bibr" target="#b13">Mikolov et al., 2013;</ref><ref type="bibr" target="#b11">Levy and Goldberg, 2014)</ref>, the linear super- position of word senses ( <ref type="bibr" target="#b3">Arora et al., 2016b)</ref>, and the nexus to pointwise mutual information scores between co-occurring words ( <ref type="bibr" target="#b2">Arora et al., 2016a</ref>).</p><p>However, thus far, only little is known about the properties of sentence embeddings. Sentence embedding methods attempt to encode a variable- length input sentence into a fixed length vector. A number of such sentence embedding methods have been proposed in recent years ( <ref type="bibr" target="#b10">Le and Mikolov, 2014;</ref><ref type="bibr">Kiros et al., 2015;</ref><ref type="bibr" target="#b19">Wieting et al., 2015;</ref><ref type="bibr" target="#b7">Conneau et al., 2017;</ref><ref type="bibr" target="#b4">Arora et al., 2017)</ref>.</p><p>Sentence embeddings have mainly been eval- uated in terms of how well their cosine similar- ities mirror human judgments of semantic relat- edness, typically with respect to the SemEval Se- mantic Textual Similarity competitions. The SICK dataset ( <ref type="bibr" target="#b12">Marelli et al., 2014</ref>) was created to better benchmark the effectiveness of different models across a broad range of challenging lexical, syn- tactic, and semantic phenomena, in terms of both similarities and the ability to be predictive of en- tailment. However, even on SICK, oftentimes very shallow methods prove effective at obtaining fairly competitive results ( <ref type="bibr" target="#b19">Wieting et al., 2015)</ref>. <ref type="bibr">Adi et al. investigated</ref> to what extent different embed- ding methods are predictive of i) the occurrence of words in the original sentence, ii) the order of words in the original sentence, and iii) the length of the original sentence ( <ref type="bibr" target="#b0">Adi et al., 2016</ref><ref type="bibr" target="#b1">Adi et al., , 2017</ref>.  inspected neural machine translation systems with regard to their ability to acquire morphology, while <ref type="bibr" target="#b17">Shi et al. (2016)</ref> inves- tigated to what extent they learn source side syn- tax. <ref type="bibr" target="#b18">Wang et al. (2016)</ref> argue that the latent repre- sentations of advanced neural reading comprehen- sion architectures encode information about pred- ication. Finally, sentence embeddings have also often been investigated in classification tasks such as sentiment polarity or question type classifica- tion ( <ref type="bibr">Kiros et al., 2015)</ref>. Concurrently with our re- search, <ref type="bibr" target="#b6">Conneau et al. (2018)</ref> investigated to what extent one can learn to classify specific syntactic and semantic properties of sentences using large amounts of training data (100,000 instances) for each property.</p><p>Overall, still, remarkably little is known about what specific semantic properties are directly re- flected by such embeddings. In this paper, we specifically focus on a few select aspects of sen- tence semantics and inspect to what extent promi- nent sentence embedding methods are able to cap- ture them. Our framework generates triplets of sentences to explore how changes in the syntac- tic structure or semantics of a given sentence af- fect the similarities obtained between their sen- tence embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Analysis</head><p>To conduct our analysis, we proceed by generating new phenomena-specific evaluation datasets.</p><p>Our starting point is that even minor alterations of a sentence may lead to notable shifts in mean- ing. For instance, a sentence S such as A rabbit is jumping over the fence and a sentence S * such as A rabbit is not jumping over the fence diverge with respect to many of the inferences that they warrant. Even if sentence S * is somewhat less idiomatic than alternative wordings such as There are no rabbits jumping over the fence, we never- theless expect sentence embedding methods to in- terpret both correctly, just as humans do.</p><p>Despite the semantic differences between the two sentences due to the negation, we still expect the cosine similarity between their respective em- beddings to be fairly high, in light of their seman- tic relatedness in touching on similar themes.</p><p>Hence, only comparing the similarity between sentence pairs of this sort does not easily lend itself to insightful automated analyses. Instead, we draw on another key idea. It is common for two sentences to be semantically close despite dif- ferences in their specific linguistic realizations. Building on the previous example, we can con- struct a further contrasting sentence S + such as A rabbit is hopping over the fence. This sentence is very close in meaning to sentence S, despite minor differences in the choice of words. In this case, we would want for the semantic relatedness between sentences S and S + to be assessed as higher than between sentence S and sentence S * .</p><p>We refer to this sort of scheme as sentence triplets. We rely on simple transformations to gen- erate several different sets of sentence triplets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Sentence Modification Schemes</head><p>In the following, we first describe the kinds of transformations we apply to generate altered sen- tences. Subsequently, in Section 2.2, we shall con- sider how to assemble such sentences into sen- tence triplets of various kinds so as to assess differ- ent semantic properties of sentence embeddings.</p><p>Not-Negation. We negate the original sentence by inserting the negation marker not before the first verb of the original sentence A to generate a new sentence B, including contractions as ap- propriate, or removing negations when they are al- ready present, as in:</p><p>A: The young boy is climbing the wall made of rock.</p><p>B: The young boy isn't climbing the wall made of rock.</p><p>Quantifier-Negation. We prepend the quantifier expression there is no to original sentences begin- ning with A to generate new sentences.</p><p>A: A girl is cutting butter into two pieces. B: There is no girl cutting butter into two pieces.</p><p>Synonym Substitution. We substitute the verb in the original sentence with an appropriate syn- onym to generate a new sentence B. A: The man is talking on the telephone. B: The man is chatting on the telephone.</p><p>Embedded Clause Extraction. For those sen- tences containing verbs such as say, think with em- bedded clauses, we extract the clauses as the new sentence. A: Octel said the purchase was expected. B: The purchase was expected.</p><p>Passivization. Sentences that are expressed in active voice are changed to passive voice. A: Harley asked Abigail to bake some muffins. B: Abigail is asked to bake some muffins.</p><p>Argument Reordering. For sentences matching the structure "somebody verb somebody to do something", we swap the subject and object of the original sentence A to generate a new sen- tence B. A: Matilda encouraged Sophia to compete in a match.</p><p>B: Sophia encouraged Matilda to compete in a match.</p><p>Fixed Point Inversion. We select a word in the sentence as the pivot and invert the order of words before and after the pivot. The intuition here is that this simple corruption is likely to result in a new sentence that does not properly convey the origi- nal meaning, despite sharing the original words in common with it. Hence, these sorts of corruptions can serve as a useful diagnostic.</p><p>A: A dog is running on concrete and is holding a blue ball B: concrete and is holding a blue ball a dog is running on.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Sentence Triplet Generation</head><p>Given the above forms of modified sentences, we induce five evaluation datasets, consisting of triplets of sentences as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Negation Detection: Original sentence, Syn- onym Substitution, Not-Negation</head><p>With this dataset, we seek to explore how well sentence embeddings can distinguish sentences with similar structure and opposite meaning, while using Synonym Substitution as the contrast set. We would want the simi- larity between the original sentence and the negated sentence to be lower than that be- tween the original sentence and its synonym version.</p><p>2. Negation Variants: Quantifier-Negation, Not-Negation, Original sentence</p><p>In the second dataset, we aim to investigate how well the sentence embeddings reflect negation quantifiers. We posit that the sim- ilarity between the Quantifier-Negation and Not-Negation versions should be a bit higher than between either the Not-Negation or the Quantifier-Negation and original sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Clause Relatedness: Original sentence, Em- bedded Clause Extraction, Not-Negation</head><p>In this third set, we want to explore whether the similarity between a sentence and its em- bedded clause is higher than between a sen- tence and its negation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Argument Sensitivity: Original sentence, Passivization, Argument Reordering</head><p>With this last test, we wish to ascertain whether the sentence embeddings succeed in distinguishing semantic information from structural information. Consider, for in- stance, the following triplet.</p><p>S: Lilly loves Imogen. S + : Imogen is loved by Lilly. S * : Imogen loves Lilly.</p><p>Here, S and S + mostly share the same mean- ing, whereas S + and S * have a similar word order, but do not possess the same specific meaning. If the sentence embeddings focus more on semantic cues, then the similarity between S and S + ought to be larger than that between S + and S * . If the sentence em- bedding however is easily misled by match- ing sentence structures, the opposite will be the case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Fixed Point Reorder: Original sentence, Se- mantically equivalent sentence, Fixed Point Inversion</head><p>With this dataset, our objective is to explore how well the sentence embeddings account for shifts in meaning due to the word order in a sentence. We select sentence pairs from the SICK dataset according to their seman- tic relatedness score and entailment labeling. Sentence pairs with a high relatedness score and the Entailment tag are considered seman- tically similar sentences. We rely on the Lev- enshtein Distance as a filter to ensure a struc- tural similarity between the two sentences, i.e., sentence pairs whose Levenshtein Dis- tance is sufficiently high are regarded as eli- gible.</p><p>Additionally, we use the Fixed Point In- version technique to generate a contrastive sentence. The resulting sentence likely no longer adequately reflects the original mean- ing. Hence, we expect that, on average, the similarity between the original sentence and the semantically similar sentence should be higher than that between the original sen- tence and the contrastive version.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>We now proceed to describe our experimental evaluation based on this paradigm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets</head><p>Using the aforementioned triplet generation meth- ods, we create the evaluation datasets listed in Ta- ble 1, drawing on source sentences from SICK, Penn Treebank WSJ and MSR Paraphase cor- pus. Although the process to modify the sen- tences is automatic, we rely on human annotators to double-check the results for grammaticality and semantics. This is particularly important for syn- onym substitution, for which we relied on Word- Net <ref type="bibr">(Fellbaum, 1998</ref>). Unfortunately, not all syn- onyms are suitable as replacements in a given con- text. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Embedding Methods</head><p>In our experiments, we compare three particularly prominent sentence embedding methods:</p><p>1. GloVe Averaging (GloVe Avg.): The simple approach of taking the average of the word vectors for all words in a sentence. Although this method neglects the order of words en- tirely, it can fare reasonably well on some of the most commonly invoked forms of evalua- tion ( <ref type="bibr" target="#b19">Wieting et al., 2015;</ref><ref type="bibr" target="#b4">Arora et al., 2017)</ref>. Note that we here rely on regular unweighted GloVe vectors ( <ref type="bibr" target="#b15">Pennington et al., 2014</ref>) in- stead of fine-tuned or weighted word vectors.</p><p>2. Concatenated P-Mean Embeddings (P- Means): Rücklé et al. <ref type="formula">(2018)</ref> proposed concatenating different p-means of multiple kinds of word vectors.</p><p>3. Sent2Vec: <ref type="bibr" target="#b14">Pagliardini et al. (2018)</ref> proposed a method to learn word and n-gram embed- dings such that the average of all words and n-grams in a sentence can serve as a high- quality sentence vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">The Skip-Thought</head><p>Vector approach (SkipThought) by <ref type="bibr">Kiros et al. (2015)</ref> applies the neighbour prediction intuitions of the word2vec Skip-Gram model at the level of entire sentences, as encoded and decoded via recurrent neural networks. The method trains an encoder to process an input sentence such that the resulting latent representation is optimized for predicting neighbouring sentences via the decoder.</p><p>5. InferSent ( <ref type="bibr" target="#b7">Conneau et al., 2017</ref>) is based on supervision from an auxiliary task, namely the Stanford NLI dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results and Discussion</head><p>Negation Detection. <ref type="table" target="#tab_1">Table 2</ref> lists the results for the Negation Detection dataset, where S, S + , S * refer to the original, Synonym Substitution, and Not-Negation versions of the sentences, respec- tively. For each of the considered embedding methods, we first report the average cosine simi- larity scores between all relevant sorts of pairings of two sentences, i.e. between the original and the Synonym-Substitution sentences (S and S + ), be- tween original and Not-Negated (S and S * ), and between Not-Negated and Synonym-Substitution (S + and S * ). Finally, in the last column, we report the Accuracy, computed as the percentage of sen- tence triplets for which the proximity relationships were as desired, i.e., the cosine similarity between the original and synonym-substituted versions was higher than the similarity between that same orig- inal and its Not-Negation version.</p><p>On this dataset, we observe that GloVe Avg. is more often than not misled by the introduction of synonyms, although the corresponding word vec- tor typically has a high cosine similarity with the original word's embedding. In contrast, both In- ferSent and SkipThought succeed in distinguish- ing unnegated sentences from negated ones. Negation Variants. In <ref type="table" target="#tab_2">Table 3</ref>, S, S + , S * re- fer to the original, Not-Negation, and Quantifier- Negation versions of a sentence, respectively. Ac- curacy in this problem is defined as percentage of sentence triples whose similarity between S+ and S * is the higher than similarity between S and S+ and S + and S * The results of both averaging of word embeddings. and SkipThought are dismal in terms of the accuracy. InferSent, in contrast, ap- pears to have acquired a better understanding of negation quantifiers, as these are commonplace in many NLI datasets.</p><p>Clause Relatedness. In <ref type="table" target="#tab_3">Table 4</ref>, S, S + , S * re- fer to original, Embedded Clause Extraction, and Not-Negation, respectively. Although not particu- larly more accurate than random guessing, among the considered approaches, Sent2vec fares best in distinguishing the embedded clause of a sentence from a negation of said sentence.</p><p>For a detailed analysis, we can divide the sen- tence triplets in this dataset into two categories as exemplified by the following examples: a) Copperweld said it doesn't expect a pro- tracted strike. -Copperweld said it expected a protracted strike. -It doesn't expect a protracted strike.</p><p>b) "We made our own decision," he said. - "We didn't make our own decision," he said. - We made our own decision.</p><p>For cases resembling a), the average SkipThought similarity between the sentence and its Not-Negation version is 79.90%, while for cases resembling b), it is 26.71%. The accuracy of SkipThought on cases resembling a is 36.90%, and the accuracy of SkipThought on cases like b is only 0.75% It seems plausible that SkipThought is more sensitive to the word order due to the recurrent architecture. Infersent also achieved better performance on sentences resembling a) compared with sentences resembling b), its accuracy on these two structures is 28.37% and 15.73% respectively. Argument Sensitivity. In <ref type="table" target="#tab_4">Table 5</ref>, S, S + , S * to refer to the original sentence, it Passivization form, and the Argument Reordering version, re- spectively. Although recurrent architectures are able to consider the order of words, unfortu- nately, none of the analysed approaches prove adept at distinguishing the semantic information from structural information in this case.</p><p>Fixed Point Reorder. In <ref type="table" target="#tab_5">Table 6</ref>, S, S + , S * to refer to the original sentence, its semantically equivalent one and Fixed Point Inversion Ver- sion. As <ref type="table" target="#tab_5">Table 6</ref> indicates, sentence embed- dings based on means (GloVe averages), weighted means (Sent2Vec), or concatenation of p-mean embeddings (P-Means) are unable to distinguish the fixed point inverted sentence from the se- mantically equivalent one, as they do not encode sufficient word order information into the sen- tence embeddings. Sent2Vec does consider n- grams but these do not affect the results suffi- ciently.SkipThought and InferSent did well when the original sentence and its semantically equiva- lence share similar structure. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>This paper proposes a simple method to inspect sentence embeddings with respect to their se- mantic properties, analysing three popular embed- ding methods. We find that both SkipThought and InferSent distinguish negation of a sentence from synonymy. InferSent fares better at identi- fying semantic equivalence regardless of the or- der of words and copes better with quantifiers. SkipThoughts is more suitable for tasks in which the semantics of the sentence corresponds to its structure, but it often fails to identify sentences with different word order yet similar meaning. In almost all cases, dedicated sentence embeddings from hidden states a neural network outperform a simple averaging of word embeddings.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Generated Evaluation Datasets 
Dataset 
# of Sentences 

Negation Detection 
674 
Negation Variants 
516 
Clause Relatedness 
567 
Argument Sensitivity 
445 
Fixed Point Reorder 
623 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Evaluation of Negation Detection 

S ∧ S + S ∧ S  *  S + ∧ S  *  Accuracy 

Glove Avg 
97.42% 98.80% 96.53% 13.06% 
P Means 
98.49% 99.47% 98.13% 6.82% 
Sent2Vec 
91.28% 93.50% 85.30% 41.99% 
SkipThought 88.34% 81.95% 73.74% 78.19% 
Infersent 
94.74% 88.64% 85.15% 91.10% 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 3 : Evaluation of Negation Variants S ∧ S + S ∧ S * S + ∧ S * Accuracy</head><label>3</label><figDesc></figDesc><table>Glove Avg 
96.91% 97.99% 97.05% 1.56% 
P Means 
98.66% 99.07% 98.49% 0.19% 
Sent2Vec 
90.53% 90.59% 86.87% 1.56% 
SkipThought 71.94% 75.40% 73.11% 22.96% 
InferSent 
84.51% 88.45% 91.63% 85.78% 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Evaluation of Clause Relatedness 

S ∧ S + S ∧ S  *  S + ∧ S  *  Accuracy 

Glove Avg 
94.76% 99.14% 94.03% 4.58% 
P Means 
97.40% 99.61% 97.08% 2.46% 
Sent2Vec 
86.62% 92.40% 79.23% 32.92% 
SkipThought 54.94% 84.27% 45.48% 19.51% 
Infersent 
89.47% 95.12% 85.22% 18.45% 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><head>Table 5 : Evaluation of Argument Sensitivity S ∧ S + S ∧ S * S + ∧ S * Accuracy</head><label>5</label><figDesc></figDesc><table>Glove Avg 
96.17% 99.96% 96.17% 0.00% 
P Means 
97.94% 99.98% 97.94% 0.00% 
Sent2Vec 
89.11% 99.80% 89.13% 0.00% 
SkipThought 83.44% 95.57% 82.32% 4.71% 
Infersent 
93.70% 97.98% 94.11% 2.24% 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Evaluation of Fixed Point Reorder 

S ∧ S + S ∧ S  *  
S + ∧ S  *  Accuracy 

Glove avg 
97.74% 100.00% 97.74% 0.00% 
P-Means 
98.68% 100.00% 98.68% 0.00% 
Sent2Vec 
92.88% 100.00% 92.88% 0.00% 
SkipThought 89.83% 39.75% 37.28% 99.84% 
InferSent 
95.53% 94.26% 90.64% 72.92% 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research is funded in part by ARO grant no. W911NF-17-C-0098 as part of the DARPA So-cialSim program.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yossi</forename><surname>Adi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Einat</forename><surname>Kermany</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Belinkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ofer</forename><surname>Lavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<title level="m">Fine-grained Analysis of Sentence Embeddings Using Auxiliary Prediction Tasks. arXiv.org</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Analysis of sentence embedding models using prediction tasks in natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yossi</forename><surname>Adi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Einat</forename><surname>Kermany</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Belinkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ofer</forename><surname>Lavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Journal of Research and Development</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="3" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A latent variable model approach to pmi-based word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanzhi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingyu</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengyu</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Risteski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="385" to="399" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Linear algebraic structure of word senses, with applications to polysemy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanzhi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingyu</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengyu</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Risteski</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1601.03764</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A simple but tough-to-beat baseline for sentence embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingyu</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengyu</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR 2017</title>
		<meeting>ICLR 2017</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">What do neural machine translation models learn about morphology?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Belinkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nadir</forename><surname>Durrani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fahim</forename><surname>Dalvi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hassan</forename><surname>Sajjad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">R</forename><surname>Glass</surname></persName>
		</author>
		<idno>abs/1704.03471</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">What you can cram into a single vector: Probing sentence embeddings for linguistic properties</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kruszewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Baroni</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Supervised learning of universal sentence representations from natural language inference data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lo¨ıclo¨ıc</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<idno>abs/1705.02364</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">WordNet: An Electronic Lexical Database</title>
		<editor>Christiane Fellbaum</editor>
		<imprint>
			<date type="published" when="1998" />
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Raquel Urtasun, and Sanja Fidler. 2015. Skip-thought vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS 2015</title>
		<meeting>NIPS 2015</meeting>
		<imprint>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Distributed representations of sentences and documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Linguistic regularities in sparse and explicit word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighteenth Conference on Computational Natural Language Learning</title>
		<meeting>the Eighteenth Conference on Computational Natural Language Learning<address><addrLine>Ann Arbor, Michigan</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="171" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A sick cure for the evaluation of compositional distributional semantic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Marelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Menini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luisa</forename><surname>Bentivogli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raffaella</forename><surname>Bernardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Zamparelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC-2014). European Language Resources Association (ELRA)</title>
		<meeting>the Ninth International Conference on Language Resources and Evaluation (LREC-2014). European Language Resources Association (ELRA)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Linguistic regularities in continuous space word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="746" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Unsupervised learning of sentence embeddings using compositional n-Gram features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Pagliardini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prakhar</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Jaggi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL 2018-Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">GloVe: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Concatenated p-mean embeddings as universal cross-lingual sentence representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Rücklé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steffen</forename><surname>Eger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxime</forename><surname>Peyrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>arXiv</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Does string-based neural mt learn source syntax?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inkit</forename><surname>Padhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1526" to="1534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Emergent logical structure in vector representations of neural readers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeshi</forename><surname>Onishi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">A</forename><surname>Mcallester</surname></persName>
		</author>
		<idno>abs/1611.07954</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Towards universal paraphrastic sentence embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Wieting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Livescu</surname></persName>
		</author>
		<idno>abs/1511.08198</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
