<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:53+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Detecting Good Arguments in a Non-Topic-Specific Way: An Oxymoron?</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beata</forename><surname>Beigman Klebanov</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Binod</forename><surname>Gyawali</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Song</surname></persName>
						</author>
						<title level="a" type="main">Detecting Good Arguments in a Non-Topic-Specific Way: An Oxymoron?</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</title>
						<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="244" to="249"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-2038</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Automatic identification of good arguments on a controversial topic has applications in civics and education, to name a few. While in the civics context it might be acceptable to create separate models for each topic, in the context of scoring of stu-dents&apos; writing there is a preference for a single model that applies to all responses. Given that good arguments for one topic are likely to be irrelevant for another, is a single model for detecting good arguments a contradiction in terms? We investigate the extent to which it is possible to close the performance gap between topic-specific and across-topics models for identification of good arguments.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction &amp; Related Work</head><p>Argumentation is an important skill in higher edu- cation and the workplace; students are expected to show sound reasoning and use relevant evidence (Council of Chief State <ref type="bibr">School Officers &amp; National Governors Association, 2010)</ref>. The increase in argumentative writing tasks, in both instruc- tional and assessment contexts, results in a high demand for automated feedback on and scoring of arguments.</p><p>Automated analysis of argumentative writing has mostly concentrated on argument structure - namely, presence of claims and premises, and relationships between them ( <ref type="bibr" target="#b2">Ghosh et al., 2016;</ref><ref type="bibr" target="#b4">Nguyen and Litman, 2016;</ref><ref type="bibr" target="#b6">Persing and Ng, 2016;</ref><ref type="bibr" target="#b5">Ong et al., 2014;</ref><ref type="bibr" target="#b9">Stab and Gurevych, 2014</ref>). Ad- dressing the content of arguments in on-line de- bates, <ref type="bibr" target="#b3">Habernal and Gurevych (2016)</ref> ranked argu- ments on the same topic by convincingness; they showed that convincingness can be automatically predicted, to an extent, in a cross-topics fashion, as they trained their systems on 31 debates and tested on a new one. <ref type="bibr" target="#b10">Swanson et al. (2015)</ref> reported that annotation of argument quality is challeng- ing, with inter-annotator agreement (ICC) around 0.40. They also showed that automated across- topics prediction is very hard; for some topics, no effective prediction was achieved. <ref type="bibr" target="#b8">Song et al. (2014)</ref> developed an annotation pro- tocol for analyzing argument critiques in students' essays, drawing on the theory of argumentation schemes ( <ref type="bibr" target="#b12">Walton et al., 2008;</ref><ref type="bibr" target="#b11">Walton, 1996)</ref>. Ac- cording to this theory, different types of arguments invite specific types of critiques. For example, an argument from authority made in the prompt - According to X, Y is the case -avails critiques along the lines of whether X has the necessary knowledge and is an unbiased source of informa- tion about Y. Analyzing prompts used in an assess- ment of argument critique skills, <ref type="bibr" target="#b8">Song et al. (2014)</ref> identified a number of common schemes, such as arguments from policy, sample, example, and used the argumentation schemes theory to specify what critiques would count as "good" for argu- ments from the given scheme. Once a prompt is associated with a specific set of argumentation schemes, it follows that those critiques that count as good under one of the schemes used in the prompt would be considered as good critiques in essays responding to that prompt. The goal of the annotation was to identify all sentences in an essay that participate in making a good critique, accord- ing to the above definition. Every sentence in an essay is annotated with the label of the critique that it raises, or "generic" if none. In the current paper, we build upon this earlier work.</p><p>In practical large-scale automated scoring con- texts, new essay prompts are often introduced without rebuilding the scoring system, which is typically subject to a periodic release sched- ule. Therefore, the assumption that the system will have seen essays responding to each of the prompts it could encounter at deployment time is often unwarranted. Further, not only should a system be able to handle responses to an unseen prompt, it must do it gracefully, since a large dis- parity in the system's performance across different prompts might raise fairness concerns.</p><p>Our practical goal is thus a development of a ro- bust argument critique analysis system for essays. Our theoretical goal is the investigation of the ex- tent that it is at all possible to capture aspects of argument content in a fashion that would genera- lize across various essay topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Annotation</head><p>We used <ref type="bibr" target="#b8">Song et al. (2014)</ref> annotation protocol, adapting as needed to cover additional argumen- tation schemes. <ref type="bibr" target="#b7">Song et al. (2017)</ref> provides a detailed exposition of the argumentation-scheme- based analysis of a number of prompts and of the annotation process. For the current study, we used a simplified version of the annotation where sen- tences are labeled as non-generic (namely, con- taining a good critique according to some argu- mentation scheme), or generic (all the rest of the sentences in the essay). The average inter- annotator agreement on the "generic" vs "non- generic" sentence-level classification is k=0.67.</p><p>The "non-generic" category covers all sen- tences that raise a good critique; everything else is "generic". The latter category thus includes, for example, sentences that rehash the argument in the prompt, provide critical but vague statements that cannot be clearly identified as a specific critique from our list (such as "The author should provide more information"), provide specific critical state- ments that aren't valid arguments. For example, in response to the prompt that states that the new policy led to a 10% decrease in unemployment in four years, one writer argued that "People who were unemployed could have died within the last four years and that is why there is a decrease." While trying to provide an alternative explanation to the putative effect of the policy is a reasonable move, this is not a valid argument, because it is exceedingly unlikely that unemployed people died in such disproportionate numbers to have such a big impact on the unemployment statistics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data</head><p>For this study, we use a same-topic and an across- topics sets of college-level argument critique es- says. The first is used to set the bar for the per- formance in the context where the training and the testing essays respond to the same prompt. The second is the main dataset focused on generaliza- tion across prompts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Same-topic</head><p>A total of 900 essays were annotated, 300 essays for each of 3 prompts. For each prompt, we train a model on 260 responses and test on 40. The training sets per prompt contain on average 2,700 sentences, of which 38% are classified as con- taining good argument critiques. Two of the three same-topic sets were used previously in <ref type="bibr" target="#b8">Song et al. (2014)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Across-topics</head><p>A total of 500 essays were annotated, 50 essays for each of 10 prompts. We perform 10-fold cross validation, training on 9 prompts and testing on the 10th, modeling a scenario of generalization to an unknown topic. There are, on average, 5,492 sen- tences available for training, of which 3,917 (42%) are classified as containing good critiques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">How far do we get with pure content?</head><p>Given that making a good critique is presumably mostly about saying the right things, we ex- pect lexical models to perform well in same- topic context and badly in the across-topics one. We evaluated 1-3grams, 1-4grams, and 1-5grams models learned using a logistic regression clas- sifier. Differences in performance tended to be in the third or fourth decimal digit; we there- fore report results for 1-3grams only. Classifica- tion accuracies are shown in row 2 of <ref type="table">Table 1</ref>, following the majority baseline (row 1), in both same-topic and across-topics scenarios. We show average performance (Av) as well as the worst per- formance (Min) on 3 prompts (same-topic) and on 10 prompts (across topics). We also evaluated models built using chi-square based feature selec- tion (f.s.), eliminating all features with p value above 0.05 (row 3 in <ref type="table">Table 1</ref>).</p><p>For the same-topic context, lexical features per- form at .738. As expected, lexical features are much less effective across topics, with average performance of only .645. We observe substan- tial gaps of 9 (.738 vs .645) and 8 (.679 vs .604) accuracy points, for average and worst case, re- spectively, between same-topic and across-topics scenarios for ngram models. Feature selection is ineffective in both scenarios (compare rows 2 and 3 in <ref type="table">Table 1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">How far do we get with pure structure?</head><p>An approach that is perhaps better aligned with the across-topics setting is to notice that in detailing one's arguments, one tends to utilize a specially structured discourse, and that discourse role could provide a clue to the argumentative function of a sentence, without reliance on what the sentence is actually saying (beyond discourse connectives that are used to help identify the discourse role). In particular, argumentative essays often have a fairly standard structure, where a general claim (or stance, or thesis) on the issue is introduced in the beginning of the essay, followed by a se- quence of main points, each elaborated using sup- porting statements, and finally followed by a con- clusion that often re-states the thesis and provides a high-level summary of the argument. We expect the "meat" of the argument to occur mostly in the supporting statements that provide detailed expo- sition of the author's arguments. We use a dis- course parser for argumentative essays ( <ref type="bibr" target="#b0">Burstein et al., 2003</ref>) to classify sentences into the follow- ing discourse units: Thesis, Background, Main- Point, Support, Conclusion, and Other. Row 4 (dr) in <ref type="table">Table 1</ref> shows the performance of this set of 6 binary features. Of the 6 features, Support and MainPoint have a positive weight (predict "non- generic"), the rest predict "generic".</p><p>We further hypothesize that the position of a sentence inside a discourse segment might also provide some information: A sentence surrounded by Support sentences is likely to be in the middle of exposition of an argument, as opposed to the last Supporting sentence before the next Main Point that could be summary-like, leading up to a shift to a new topic. We therefore built two sets of transition features, one for all pairs of &lt;previous sentence role,current sentence role&gt; (such as &lt;Thesis,Main Point&gt; for a sentence that is classified as Main Point and follows a Thesis sentence), and the other -for all pairs of &lt;current sentence role,next sentence role&gt;. We also added BeginningOfEssay and EndOfEssay  We observe that the likelihood of the current Support sentence to carry argumentative content is higher if it follows another Support sentence (row 1) than if it follows a Main Point (row 2); if the Support sentence follows Thesis, it is actually not likely to contain argumentative content (perhaps it is more like a Main Point sentence than like a typi- cal Support). Likewise, being followed by another Support sentence is a good sign (row 4), but being the last Support sentence before transitioning to a new Main Point has a much lower positive weight (row 5), and being the last Support before Conclu- sion has a still lower positive weight (row 6). Inter- estingly, while being the last Conclusion sentence in the essay strongly predicts "generic" (row 8), if the next sentence is still within the Conclusion segment, the prediction is actually slightly posi- tive (row 7), suggesting that some authors rehash their arguments in substantial detail in concluding remarks, warranting a "non-generic" designation. <ref type="table">Table 1</ref> shows the performance of the discourse role features (dr), the transition pairs using pre- vious and next discourse roles (dr pn), 2 and the combination of content and discourse (row 6).</p><p>We observe that transforming the discourse role features into transitional features is effective. Second, the discourse role features are inferior to the content features for same-topic, while the op- posite is true for the across-topics scenario.</p><p>Discourse structure information does in fact get us quite far in the across-topics scenario, further than the lexical information on its own. Com- bining the two types of information further im- proves performance in across-topics scenario, and reduces the gap between across-topics and same- topic contexts to 4 points on average (.741 vs .700) and 1.5 points in worst case (.690 vs .674), for a combined discourse structure and content model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Can we do better?</head><p>In an attempt to further improve across-topics per- formance, we generalized ngrams representations and adapted feature selection to reflect the across- topics dynamic more directly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Generalized ngrams</head><p>Suppose the prompt is arguing that some entity N should do some action V. While N and V might differ across prompts, critical sentences to the end that N should not do V are likely to occur across different prompts. In the current ngrams repre- sentation, N and V differ across prompts, and are unknown for a prompt that is unseen during training. We represent all content words (nouns, verbs, adjectives, adverbs, and cardinal numbers) in the prompt as their part-of-speech labels; we should be able to capture features such as "should not VB". Rows 7 and 8 in <ref type="table">Table 1</ref> show the 1- 3gr ppos model; it improves over 1-3gr in both the average and the worst cases, on its own and on top of the dr pn features, in the across-topics scenario. The improvement over dr pn+1-3gr is marginally significant (p&lt;0.1, Wilcoxon Signed- Ranks 2-tailed test, n=10, W=33).</p><p>The single strongest lexical predictor of a generic sentence is the first person singular pro- noun I; such sentences are likely to express stance (I think this is a good plan), or contain discourse- management expressions such as I will show that the author's arguments are flawed. Words such as assumptions, evidence, information, argument, statistics, idea, reasons all have negative weight, suggesting that they typically belong to generic sentences such as The author's argument lacks evi- dence that does not raise a specific critique. Lexi- cal features for the positive class include moda- lity as in might, perhaps, could, possible that, po- tential, necessarily, if a; negation (not, will not), as well as more specific lexica that point out, for example, outcomes of a policy (expensive, in- crease in, affected the, fails to). Positive features with prompt elements include NNS does not, NN do not, many NNS, NN NNS are, NNS who VBD, could have VBN, will not VB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Feature Selection</head><p>We experimented with three feature selection methods. (1) We selected features with p&lt;0.05 using Ï‡ 2 test (p0.05). (2) We selected features with p&lt;0.05 for at least two out of the 9 training prompts, to find features that are likely to genera- lize across prompts (p0.05 2pr). (3) We selected features based on their mutual information with the label conditioned on values of the dr pn fea- tures, to encourage selection of features that aug- ment, rather than repeat, the discourse informa- tion. We calculated for each training prompt, and took the 2nd highest of the 9 values. <ref type="bibr">3</ref> We selected features in the top 5% of this metric (mi5% 2pr). <ref type="table" target="#tab_3">Table 3</ref> shows the results. The p0.05 mecha- nism is ineffective; 0.05 2pr selection is better. The mi5% 2pr mechanism performs within .002 of the original, while reducing the number of fea- tures by two orders of magnitude.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Benchmark</head><p>We also compared our best across-topics system (dr pn+1-3gr ppos) to the system described in <ref type="bibr" target="#b8">Song et al. (2014)</ref>. The <ref type="bibr" target="#b8">Song et al. (2014)</ref> system uses the following features: length of the sentence, parts of speech, overlap of words in the sentence with the prompt, relative position of the sentence in the essay, 1-3gr, and 1-3gr in previous and next sentences. The performance is shown in row 9 in <ref type="table">Table 1</ref>. Our improvement over <ref type="bibr" target="#b8">Song et al. (2014)</ref> is statistically significant in the across-topics sce- nario (p&lt;0.05, Wilcoxon Signed-Ranks test, 2- tailed, n=10, W=51).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>We presented experiments on classifying essay sentences as containing good argument critiques or not. While a good argument critique is a mat- ter of content, we show that it is possible to build classifiers that are not prompt-specific, using dis- course structure features and generalized lexical features that take into account reference to the text of the prompt to which the author is responding. Starting from a ngrams baseline where the per- formance gap between same-prompt and across- topics scenarios is 9 accuracy points on average (.738 vs .645) and 8 points in worst case (.679 vs .604), we close half the gap in average perfor- mance (.745 vs .706) and are down to only 1.5 point difference in worst case performance <ref type="bibr">(.701 vs .686)</ref>. This performance is preserved with only about 0.5% of the features, using a conditional mutual information criterion. The improvement in worst case performance is important for ensuring that the system does not exhibit large performance differences across different essay prompts used on the same test. We also show that our best system significantly improves over the state-of-art system for argument critique detection task on compara- ble essay data for the across-topics scenario.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Weights of the transition features.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Performance of feature selection, for the 
dr pn+1-3gr ppos model, across topics. 

</table></figure>

			<note place="foot" n="1"> The majority baseline for one prompt is below 50% because for that prompt the majority class is actually sentences that raise appropriate arguments, differently from the other 9 prompts.</note>

			<note place="foot" n="2"> Since argument critiques often span more than one sentence, we experimented with sequence labeling using Conditional Random Fields, but performance was not better than with logistic regression.</note>

			<note place="foot" n="3"> Thus, the feature has at least that much informaton beyond dr pn for at least two different prompts.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Finding the write stuff: Automatic identification of discourse structure in student essays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jill</forename><surname>Burstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="32" to="39" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<idno type="doi">10.1109/MIS.2003.1179191</idno>
		<ptr target="https://doi.org/10.1109/MIS.2003.1179191" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Coarse-grained argumentation features for scoring persuasive essays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Debanjan</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aquila</forename><surname>Khanam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yubo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Smaranda</forename><surname>Muresan</surname></persName>
		</author>
		<ptr target="http://anthology.aclweb.org/P16-2089" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="549" to="554" />
		</imprint>
	</monogr>
	<note>Short Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Which argument is more convincing? Analyzing and predicting convincingness of Web arguments using bidirectional LSTM</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Habernal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P16-1150" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1589" to="1599" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Contextaware argumentative relation mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huy</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><surname>Litman</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P16-1107" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1127" to="1137" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Ontology-based argument mining and automatic essay scoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><surname>Litman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Brusilovsky</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/W14-2104" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Argumentation Mining. Association for Computational Linguistics</title>
		<meeting>the First Workshop on Argumentation Mining. Association for Computational Linguistics<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="24" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">End-to-end argumentation mining in student essays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isaac</forename><surname>Persing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/N16-1164" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1384" to="1394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Toward the automated scoring of written arguments: Developing an innovative approach for annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Deane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beata</forename><forename type="middle">Beigman</forename><surname>Klebanov</surname></persName>
		</author>
		<idno type="doi">10.1002/ets2.12138</idno>
		<ptr target="https://doi.org/10.1002/ets2.12138" />
	</analytic>
	<monogr>
		<title level="j">ETS Research Report Series</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Applying argumentation schemes for essay scoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Heilman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beata</forename><forename type="middle">Beigman</forename><surname>Klebanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Deane</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/W14-2110" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Argumentation Mining</title>
		<meeting>the First Workshop on Argumentation Mining<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="69" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Identifying argumentative discourse structures in persuasive essays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Stab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/D14-1006" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="46" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Argument mining: Extracting arguments from online dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reid</forename><surname>Swanson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Ecker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marilyn</forename><surname>Walker</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/W15-4631" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue. Association for Computational Linguistics</title>
		<meeting>the 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue. Association for Computational Linguistics<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="217" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Argumentation schemes for presumptive reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><forename type="middle">N</forename><surname>Walton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<publisher>Lawrence Erlbaum</publisher>
			<pubPlace>Mahwah, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Argumentation schemes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><forename type="middle">N</forename><surname>Walton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabrizio</forename><surname>Macagno</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Cambridge University Press</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
