<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:58+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Transferring Coreference Resolvers with Posterior Regularization</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">André</forename><forename type="middle">F T</forename><surname>Martins</surname></persName>
							<email>atm@priberam.pt</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Priberam Labs</orgName>
								<address>
									<addrLine>Alameda D. Afonso Henriques, 41, 2 o</addrLine>
									<postCode>1000-123</postCode>
									<settlement>Lisboa</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Instituto de TelecomunicaçTelecomunicaç˜Telecomunicações</orgName>
								<orgName type="institution" key="instit2">Instituto Superior Técnico</orgName>
								<address>
									<postCode>1049-001</postCode>
									<settlement>Lisboa</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Transferring Coreference Resolvers with Posterior Regularization</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1427" to="1437"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We propose a cross-lingual framework for learning coreference resolvers for resource-poor target languages, given a re-solver in a source language. Our method uses word-aligned bitext to project information from the source to the target. To handle task-specific costs, we propose a softmax-margin variant of posterior regu-larization, and we use it to achieve robust-ness to projection errors. We show empirically that this strategy outperforms competitive cross-lingual methods, such as delexicalized transfer with bilingual word embeddings, bitext direct projection, and vanilla posterior regularization.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The goal of coreference resolution is to find the mentions in text that refer to the same discourse entity. While early work focused primarily on En- glish ( <ref type="bibr">Soon et al., 2001;</ref><ref type="bibr" target="#b27">Ng and Cardie, 2002</ref>), efforts have been made toward multilingual sys- tems, this being addressed in recent shared tasks <ref type="bibr" target="#b32">Pradhan et al., 2012)</ref>. How- ever, the lack of annotated data hinders rapid sys- tem deployment for new languages. Unsupervised methods ( <ref type="bibr" target="#b14">Haghighi and Klein, 2007;</ref><ref type="bibr" target="#b28">Ng, 2008)</ref> and rule-based approaches ( <ref type="bibr" target="#b35">Raghunathan et al., 2010)</ref> avoid this data annotation bottleneck, but they often require complex generative models or expert linguistic knowledge.</p><p>We propose cross-lingual coreference resolu- tion as a way of transferring information from a rich-resource language to build coreference re- solvers for languages with scarcer resources; as a testbed, we transfer from English to Spanish and to Brazilian Portuguese. We build upon the recent successes of cross-lingual learning in NLP, which proved quite effective in several structured predic- tion tasks, such as POS tagging <ref type="bibr">(Täckström et al., 2013</ref>), named entity recognition ( <ref type="bibr" target="#b51">Wang and Manning, 2014</ref>), dependency parsing <ref type="bibr" target="#b26">(McDonald et al., 2011</ref>), semantic role labeling <ref type="bibr" target="#b47">(Titov and Klementiev, 2012)</ref>, and fine-grained opinion mining ( <ref type="bibr" target="#b0">Almeida et al., 2015)</ref>. The potential of these tech- niques, however, has never been fully exploited in coreference resolution (despite some existing work, reviewed in §6, but none resulting in an end- to-end coreference resolver).</p><p>We bridge this gap by proposing a simple learning-based method with weak supervision, based on posterior regularization ( <ref type="bibr" target="#b12">Ganchev et al., 2010</ref>). We adapt this framework to handle softmax-margin objective functions ( <ref type="bibr" target="#b13">Gimpel and Smith, 2010)</ref>, leading to softmax-margin poste- rior regularization ( §4). This step, while fairly simple, opens the door for incorporating task- specific cost functions, which are important to manage the precision/recall trade-offs in corefer- ence resolution systems. We show that the result- ing problem involves optimizing the difference of two cost-augmented log-partition functions, mak- ing a bridge with supervised systems based on la- tent coreference trees <ref type="bibr" target="#b10">(Fernandes et al., 2012;</ref>, reviewed in §3. In- spired by this idea, we consider a simple penal- ized variant of posterior regularization that tunes the Lagrange multipliers directly, bypassing the saddle-point problem of existing EM and alternat- ing stochastic gradient algorithms ( <ref type="bibr" target="#b12">Ganchev et al., 2010;</ref><ref type="bibr" target="#b21">Liang et al., 2009)</ref>. <ref type="bibr">Experiments ( §5)</ref> show that the proposed method outperforms commonly used cross-lingual approaches, such as delexical- ized transfer with bilingual embeddings, direct projection, and "vanilla" posterior regularization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Architecture and Experimental Setup</head><p>Our methodology, outlined as Algorithm 1, is in- spired by the recent work of <ref type="bibr" target="#b11">Ganchev and Das (2013)</ref> on cross-lingual learning of sequence mod- els. For simplicity, we call the source and tar- <ref type="figure">Figure 1</ref>: Excerpt of a bitext document with automatic coreference annotations (from FAPESP). The English side had its coreferences resolved by a state-of-the-art system . The predicted coreference chains {The pulmonary alveoli, the alveoli, their} and {The pulmonary surfactant} are then projected to the Portuguese side, via word alignments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Cross-Lingual Coreference Resolution via Softmax-Margin Posterior Regularization</head><p>Input: Source coreference system S e , parallel data D e and D f , posterior constraints Q. Output: Target coreference system S f .</p><p>1:</p><formula xml:id="formula_0">D e↔f ← RUNWORDALIGNER(D e , D f ) 2: D e ← RUNCOREF(S e , D e ) 3: D f ← PROJECTANDFILTERENTITIES(D e↔f , D e ) 4: S f ← LEARNCOREFWITHSOFTMARGPR( D f , Q)</formula><p>get languages English (e) and "foreign" (f ), re- spectively, and we assume the existence of parallel documents on the two languages (bitext). The first two steps (lines 1-2) run a word aligner and label the source side of the parallel data with a pre-trained English coreference system. After- wards, the predicted English entities are projected to the target side of the parallel data (line 3), in- ducing an automatic (and noisy) training dataset for the foreign language. Finally, a coreference system is trained in this dataset with the aid of softmax-margin posterior regularization (line 4).</p><p>We next detail all the datasets and tools involved in our experimental setup. <ref type="table">Table 1</ref> provides a sum- mary, along with some statistics.</p><p>Parallel Data. As parallel data, we use a sentence-aligned trilingual (English-Portuguese- Spanish) parallel corpus based on the scien- tific news Brazilian magazine Revista Pesquisa FAPESP, collected by Aziz and Specia (2011). <ref type="bibr">1</ref> We preprocessed this dataset as follows. We la- beled the English side with the Berkeley Corefer- ence Resolution system v1.0, using the provided English model . Then, we computed word alignments using the Berke- ley aligner ( <ref type="bibr" target="#b20">Liang et al., 2006</ref>), intersected them and filtered out all the alignments whose confi- dence is below 0.95. After this, we projected En- glish mentions to the target side using the maxi- mal span heuristic of <ref type="bibr" target="#b52">Yarowsky et al. (2001)</ref>. We filtered out documents where more than 15% of the mentions were not aligned. At this point, we obtained an automatically annotated corpus D f in the target language. <ref type="figure">Figure 1</ref> shows a small excerpt where all mentions were correctly pro- jected. In practice, not all documents are so well behaved: in the English-Portuguese parallel data, only 200,175 out of the original 271,122 mentions (about 73.8%) were conserved after the projection step. In Spanish, this number drops to 69.9%.</p><p>Monolingual Data. We also use monolingual data for validation and comparison with super- vised systems. The Berkeley Coreference Reso- lution system is trained in the English OntoNotes dataset used in the CoNLL 2011 shared task; this dataset is also used to train delexicalized models.</p><p>For Spanish, we use the AnCora dataset  provided in the SemEval 2010 coreference task, which we preprocessed as follows. We split all MWEs into individual tokens (for consistency with the other corpora). We also removed the extra gap tokens associated with zero- anaphoric relations, and the anaphoric annotations associated with relative pronouns (e.g., in "[una central de ciclo combinado <ref type="bibr">[que]</ref> 1 debe empezar a funcionar en mayo del 2002] 1 " we removed the nested mention [que] 1 ), since these are not anno- tated in the English dataset.</p><p>For Portuguese, we used the Summ-It 3.0 cor- pus ( <ref type="bibr" target="#b6">Collovini et al., 2007)</ref>, which contains 50 documents annotated with coreferences, from the science section of the Folha de São Paulo newspa- per. This dataset is much smaller than OntoNotes and AnCora, as shown in <ref type="table">Table 1</ref>. We split the data into train, development, and test partitions.</p><p>For both Spanish and Portuguese, we obtained automatic POS tags and dependency parses by us- ing TurboParser ( <ref type="bibr" target="#b25">Martins et al., 2013</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Coreference Resolution</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem Definition and Prior Work</head><p>In coreference resolution, we are given a set of mentions M := {m 1 , . . . , m M }, and the goal is to cluster them into discourse entities, E := {e 1 , . . . , e E }, where each e j ⊆ M and e j = ∅. The set E must form a partition of M, i.e., we must have E j=1 e j = M, and e i ∩ e j = ∅ for i = j. A variety of approaches have been proposed to this problem, including entity-centric models <ref type="bibr" target="#b15">(Haghighi and Klein, 2010;</ref><ref type="bibr" target="#b36">Rahman and Ng, 2011;</ref>), pairwise models ( <ref type="bibr" target="#b4">Bengtson and Roth, 2008;</ref><ref type="bibr" target="#b49">Versley et al., 2008)</ref>, greedy rule-based methods ( <ref type="bibr" target="#b35">Raghunathan et al., 2010)</ref>, and mention-ranking decoders <ref type="bibr" target="#b7">(Denis and Baldridge, 2008;</ref>. We chose to base our coreference resolvers on this last class of methods, which permit efficient decoding by shifting from entity clusters to latent corefer- ence trees. In particular, the inclusion of lexical- ized features by  yields nearly state-of-the-art performance with surface information only. Given that our goal is to pro- totype resolvers for resource-poor languages, this model is a good fit-we next describe it in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Latent Coreference Tree Models</head><p>Let x be a document containing M mentions, sorted from left to right. We associate to the mth mention a random variable y m ∈ {0, 1, . . . , m−1} to denote its antecedent, where the value y m = 0 means that m is a singleton or starts a new coref- erence chain. We denote by Y(x) the set of coref- erence trees that can be formed by linking men- tions to their antecedents; we represent each tree as a vector y := y 1 , . . . , y M . Note that each tree y induces a unique clustering E, but that this map is many-to-one, i.e., different trees may corre- spond to the same set of entity clusters. We denote by Y(E) the set of trees that are consistent with a given clustering E.</p><p>We model the probability distribution p(y|x) as an arc-factored log-linear model:</p><formula xml:id="formula_1">p w (y|x) ∝ exp M m=1 w f (x, m, y m ) , (1)</formula><p>where w is a weight vector, and each f (x, m, y m ) is a local feature vector that depends on the document x, the mention m, and its candi- date antecedent y m . This model permits a cheap computation of the most likely tree y := arg max y∈Y(x) p w (y|x): simply compute the best antecedent independently for each mention, and collect them to form a tree. An analogous pro- cedure can be employed to compute the posterior marginals p w (y m |x) for every mention m.</p><p>Gold coreference tree annotations are rarely available; datasets usually consist of documents annotated with entity clusters,</p><formula xml:id="formula_2">{{x (n) , E (n) } N n=1</formula><p>.  proposed to learn the probabilistic model in Eq. 1 by maximizing condi- tional log-likelihood, treating the coreference trees as latent variables. They also found advantageous to incorporate a cost function (y, Y(E)), measur- ing the extent to which a prediction y differs from the ones that are consistent with the gold entity set E. <ref type="bibr">2</ref> Putting these pieces together, we arrive at the following loss function to be minimized:</p><formula xml:id="formula_3">L(w) = − N n=1 log y∈Y(E (n) ) p w (y|x (n) ) , (2) where p w is the cost-augmented distribution: p w (y|x) ∝ p w (y|x)e (y,Y(E)) .<label>(3)</label></formula><p>The loss function in Eq. 2 can be seen as a prob- abilistic analogous of the hinge loss of support vector machines, and a model trained this way is called a softmax-margin CRF ( <ref type="bibr" target="#b13">Gimpel and Smith, 2010)</ref>. Note that L(w) is non-convex, cor- responding to the difference of two log-partition functions (both convex on w),</p><formula xml:id="formula_4">L(w) = N n=1 log Z (w, x (n) ) − log Z(w, x (n) ) ; (4) above we denoted Z (w, x) = y∈Y(x) e w f (x,y)+(y,Y(E)) (5) Z(w, x) = y∈Y(E) e w f (x,y) ,<label>(6)</label></formula><p>where f (x, y) := M m=1 f (x, m, y m ). 3 Evaluat- ing the gradient of the loss in Eq. 4 requires com- puting marginals for the candidate antecedents of each mention, which can be done in a mention- synchronous fashion. This enables a simple stochastic gradient descent algorithm, which was the procedure taken by .</p><p>Another way of regarding this framework, ex- pressed through the marginalization in Eq. 2, is to "pretend" that the outputs we care about are the actual coreference trees, but that the datasets are only "weakly labeled" with the entity clusters. We build on this point of view in §4.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Cross-Lingual Coreference Resolution</head><p>We now adapt the framework above to learn coref- erence resolvers in a cross-lingual manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Softmax-Margin Posterior Regularization</head><p>In the weakly supervised case, the training data may only be partially labeled or contain annota- tion errors. For taking advantage of these data, we need a procedure that handles uncertainty about the missing data, and is robust to mislabelings. We describe next an approach based on posterior reg- ularization (PR) that fulfills these requirements.</p><p>For ease of explanation, we introduce corpus- level counterparts for the variables in §3.2. We use bold capital letters X := {x (1) , . . . , x (N ) } and Y := {y (1) , . . . , y (N ) } to denote the documents and candidate coreference trees in our corpus. We denote by p w (Y|X) := N n=1 p w (y|x (n) ) the conditional distribution of trees over the corpus, induced by a model w, and similarly for the cost- augmented distribution p w (Y|X). In PR, we define a vector g(X, Y) of corpus- level constraint features, and a vector b of upper bounds for those features. We consider the family of distributions over Y (call it Q) that satisfy these constraints in a posteriori expectation,</p><formula xml:id="formula_5">Q := {q | E q [g(X, Y)] ≤ b}.<label>(7)</label></formula><p>To make the analysis simpler, we assume that 0 ≤ b ≤ 1, and that for every j, min Y g j (X, Y) = 0 and max Y g j (X, Y) = 1, where the min/max above are over all possible coreference trees Y that can be build from the documents X in the cor-pus. <ref type="bibr">4</ref> Under this assumption, the two extreme val- ues of the upper bounds have a precise meaning: if b j = 0, the jth feature becomes a hard constraint, (i.e., any feasible distribution in Q will vanish out- side {Y | g j (X, Y) = 0}), while b j = 1 turns it into a vacuous feature. We also make the usual assumption that the constraint features decompose over documents, g(X, Y) := N n=1 g(x (n) , y (n) ); if this were not the case, decoding would be much harder, as the documents would be coupled.</p><p>In vanilla PR ( <ref type="bibr" target="#b12">Ganchev et al., 2010)</ref>, one seeks the model w minimizing the Kullback-Leibler di- vergence between the set Q and the distribution p w . Here, we go one step farther to consider the cost-augmented distribution in Eq. 3. That is, we minimize KL(Q||p w ) := min q∈Q KL(qp w ). The next proposition shows that this expression also corresponds to a difference of two log- partition functions, as in Eq. 4. Proposition 1. The (regularized) minimization of the cost-augmented KL divergence is equivalent to the following saddle-point problem:</p><formula xml:id="formula_6">min w KL(QQp w ) + γ 2 w 2 = (8) min w max u≥0 F (w, u) − b u + γ 2 w 2 ,</formula><p>where</p><formula xml:id="formula_7">F (w, u) := N n=1 log Z (w, x (n) ) − log Z u (w, x (n) ) ,<label>(9)</label></formula><p>with Z (w, x) as in Eq. 5, and</p><formula xml:id="formula_8">Z u (w, x) := y∈Y(x) e w f (x,y)+(y,Y(E))−u g(x,y) .<label>(10)</label></formula><p>Proof. See Appendix A.</p><p>In sum, what Proposition 1 shows is that we can easily extend the vanilla PR framework of <ref type="bibr" target="#b12">Ganchev et al. (2010)</ref> to incorporate a task-specific cost: by Lagrange duality, the resulting optimiza- tion problem still amounts to finding a saddle point of an objective function (Eq. 8), which in- volves the difference of two log-partition func- tions (Eq. 9). The difference is that these par- tition functions now incorporate the cost term (y, Y(E)). If this cost term has a factorization compatible with the features and the constraints, this comes at no additional computational burden.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Penalized Variant</head><p>In their discriminative PR formulation for learning sequence models, <ref type="bibr" target="#b11">Ganchev and Das (2013)</ref> opti- mize an objective similar to Eq. 8 by alternating stochastic gradient updates with respect to w and u. In their procedure, b was chosen a priori via linear regression (see their <ref type="figure" target="#fig_0">Figure 2</ref></p><note type="other">). Here, we propose a different strategy, based on Proposition 1 and a simple observation: while the constraint values b have a more intuitive meaning than the Lagrange multipliers u (since they may correspond, e.g., to proportions of events observed in the data), choosing these upper bounds is often no easier than tuning u. In this case, a preferable strategy is to specify u directly-this leaves this variable fixed in Eq. 8, and allows us to get rid of b. The resulting problem becomes</note><formula xml:id="formula_9">min w F (w, u) + γ 2 w 2 ,<label>(11)</label></formula><p>which is a penalized variant of PR and no longer a saddle point problem. This variant requires tuning the Lagrange multipliers u j in the range [0, +∞], for every constraint. The two extreme cases of b j = 0 and b j = 1 correspond respectively to u j = +∞ and u j = 0. 5 Note that this grid search is only appealing for a small number of posterior constraints at corpus-level (since document-level constraints would require tuning separate coeffi- cients for each document). The practical advantages of the penalized vari- ant over the saddle-point formulation are illus- trated in <ref type="figure" target="#fig_0">Figure 2</ref>, which compares the perfor- mance of stochastic gradient algorithms for the two formulations (there, η 2 = 1 − b 2 ).</p><p>An interesting aspect of this penalized formula- tion is its resemblance to latent variable models. Indeed, the objective of Eq. 11 is also a differ- ence of log-partition functions, as the latent-tree supervised case (cf. Eq. 4). The noticeable differ- ence is that now both partition functions include extra cost terms, either task-specific ((y, Y(E)) in Z ) or with soft constraints (u g(x, y) in Z u ). In particular, if we set a single constrained feature g 1 (x, y) := I((y, Y(E)) = 0) with weight u 1 → +∞, all non-zero-cost summands in Z u (w, x) vanish and we get Z u (w, x) = Z(w, x), recov- ering the supervised case (see Eq. 6).</p><p>Intuitively, this formulation pushes probability mass toward structures that respect the constraints in Eq. 7, while moving away from those that have a large task-specific cost. A similar idea, but applied to the generative case, underlies the framework of constrastive estimation <ref type="bibr" target="#b41">(Smith and Eisner, 2005</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Cost Function</head><p>Denote by E m the entire coreference chain of the mth mention (so E = m∈M {E m }), and by M sing := {m ∈ M | E m = {m}} the set of men- tions that are projected as singleton in the data (we call this gold-singleton mentions).</p><p>We design a task-specific cost ( y, Y(E)) as in  to balance three kinds of mistakes: (i) false anaphora ( y m = 0 while m ∈ M sing ); (ii) false new ( y m = 0 while m / ∈ M sing ); and (iii) wrong link ( y m = 0 but E m = E ym ). Letting I FA ( y m , E), I FN ( y m , E), and I WL ( y m , E) be indicators for these events, we define a weighted Hamming cost function:</p><formula xml:id="formula_10">( y, Y(E)) := M m=1 (α FA I FA ( y m , E)+ α FN I FN ( y m , E) + α WL I WL ( y m , E)).</formula><p>We set α FA = 0.0, α FN = 3.0, and α WL = 1.0. 6 Since this cost decomposes as a sum over mentions, the computation of cost-augmented marginals (neces- sary to evaluate the gradient of Eq. 11) can still be done with mention-ranking decoders.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Constraint Features</head><p>Finally, we describe the constraint features (Eq. 7) used in our softmax-margin PR formulation.</p><p>Constraint #1: Clusters should not split. Let |M| − |E| be the number of anaphoric mentions in the projected data. We push these mentions to preserve their anaphoricity (y m = 0) and to have their antecedent in the projected coreference chain (E m = E ym ). To do so, we force the fraction of mentions satisfying these properties to be at least η 1 . This can be enforced via a constraint feature</p><formula xml:id="formula_11">g 1 (X, Y) :=<label>(12)</label></formula><formula xml:id="formula_12">− N n=1 M (n) m=1 I(y (n) m = 0 ∧ E (n) m = E (n) ym ),</formula><p>and an upper bound b 1 := −η 1 N n=1 (|M (n) | − |E (n) |). (These quantities are summed by a con- stant and rescaled to meet the assumption in §4.1.)</p><p>In our experiments, we set η 1 = 1.0, turning this into a hard constraint. This is equivalent to setting u 1 = +∞ in the penalized formulation.</p><p>Constraint #2: Most projected singletons should become non-anaphoric. We define a soft constraint so that a large fraction of the gold- singleton mentions m ∈ M sing satisfy y m = 0. This can be done via a constraint feature</p><formula xml:id="formula_13">g 2 (X, Y) :=<label>(13)</label></formula><formula xml:id="formula_14">− N n=1 M (n) m=1 I(y (n) m = 0 ∧ E (n) m = {m}),</formula><p>and an upper bound</p><formula xml:id="formula_15">b 2 := −η 2 N n=1 |M (n) sing |.</formula><p>In our experiments, we varied η 2 in the range <ref type="bibr">[0,</ref><ref type="bibr">1]</ref>, either directly or via the dual variable u 2 , as de- scribed in §4.1. The extreme case η 2 = 0 corre- sponds to a vacuous constraint, while for η 2 = 1 this becomes a hard constraint which, combined with the previous constraint, recovers bitext direct projection (see §5.3). The intermediate case makes this a soft constraint which allows some single- tons to be attached to existing entities (therefore introducing some robustness to non-aligned men- tions), but penalizes the number of reattachments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>We now present experiments using the setup in §2. We compare our coreference resolvers trained with softmax-margin PR ( §5.5) with three other weakly-supervised baselines: delexicalized trans- fer with cross-lingual embeddings ( §5.2), bitext projection ( §5.3), and vanilla PR ( §5.4). We also run fully supervised systems ( §5.1), to obtain up- per bounds for the level of performance we expect to achieve with the weakly-supervised systems.</p><p>An important step in coreference resolution sys- tems is mention prediction. For English, mention spans were predicted from the noun phrases given by the Berkeley parser ( <ref type="bibr" target="#b29">Petrov and Klein, 2007)</ref>, the same procedure as . For Spanish and Portuguese, this prediction relied on the output of the dependency parser, using a simple heuristic: besides pronouns, each maximal span formed by contiguous descendants of a noun becomes a candidate mention. This heuristic is quite effective, as shown by <ref type="bibr" target="#b1">Attardi et al. (2010)</ref>. <ref type="table" target="#tab_2">Table 2</ref> shows the performance of supervised sys- tems for English, Spanish and Portuguese. All op- timize Eq. 4 appended with an extra regularization term γ 2 w 2 , by running 20 epochs of stochastic gradient descent (SGD; we set γ = 1.0 and se- lected the best epoch using the dev-set). All lexi- calized systems use the same features as the SUR- FACE model of , plus fea- tures for gender and number. <ref type="bibr">7</ref> We collected a list of pronouns for all languages along with their gen- der, number, and person information. For English, we trained on the WSJ portion of the OntoNotes dataset, and for Spanish and Portuguese we trained on the monolingual datasets described in §2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Supervised Systems</head><p>We observe that the Spanish system obtains av- eraged F 1 scores around 44%, a few points below the English figures. 8 In Portuguese, these scores are significantly lower (in the 37-39% range), which is explained by the fact that the training dataset is much smaller (cf. <ref type="table">Table 1</ref>).</p><p>For English, we also report the performance of delexicalized systems, i.e., systems where all the lexical features were removed. The second row of <ref type="table" target="#tab_2">Table 2</ref> shows a drop of 2-2.5 points with re- spect to the lexicalized system. For the third and fourth rows, the lexical features were replaced by bilingual word embeddings (either English- Spanish or English-Portuguese; a detailed descrip- tion of these embeddings will be provided in §5.2). Here the drop is small, and for English-Spanish it looks on par with the lexicalized system.    <ref type="table">Table 3</ref>: Results for all the cross-lingual systems. Bold indicates the overall highest scores. As a lower bound, we show a simple deterministic baseline that, for pronominal mentions, selects the closest non-pronominal antecedent, and, for non-pronominal mentions, selects the closest non-pronominal mention that is a superstring of the current mention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Baseline #1: Delexicalized Transfer With Cross-Lingual Embeddings</head><p>We now turn to the cross-lingual systems. Delex- icalized transfer is a popular strategy in NLP <ref type="bibr" target="#b53">(Zeman and Resnik, 2008;</ref><ref type="bibr" target="#b26">McDonald et al., 2011)</ref>, recently strengthened with cross-lingual word rep- resentations <ref type="bibr">(Täckström et al., 2012</ref>). The proce- dure works as follows: a delexicalized model for the source language is trained by eliminating all the language-specific features (such as lexical fea- tures); then, this model is used directly in the tar- get language. We report here the performance of this baseline on coreference resolution for Span- ish and Portuguese, using the delexicalized models trained on the English data as mentioned in §5.1. To achieve a unified feature representation, we mapped all language-specific POS tags to univer- sal tags ( <ref type="bibr" target="#b30">Petrov et al., 2012</ref>). All lexical features were replaced either by cross-lingual word em- beddings (for words that are not pronouns); or by a universal representation containing the gender, number, and person information of the pronoun. To obtain the cross-lingual word embeddings, we ran the method described by <ref type="bibr">Hermann and Blunsom (2014)</ref> for the English-Spanish and English- Portuguese pairs, using the parallel sentences in §2. When used as features, these 128-dimensional continuous representations were scaled by a factor of 0.5 (selected on the dev-set), using the proce- dure of <ref type="bibr" target="#b48">Turian et al. (2010)</ref>.</p><p>The second and seventh rows in <ref type="table">Table 3</ref> show the performance of this baseline, which is rather disappointing. For Spanish, we observe a large drop in performance when going from supervised training to delexicalized transfer (about 11-13% in averaged F 1 ). For Portuguese, where the super- vised system is not so accurate, the difference is less sharp (about 9-11%). These drops are mainly due to the fact that this method does not take into account the intricacies of each language-e.g., possessive forms have different agreement rules in English and in Romance languages; 9 those, on the other hand, have clitic pronouns that are absent in English. Feature weights that promote certain En- glish agreement relations may then harm perfor- mance more than they help.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Baseline #2: Bitext Direct Projection</head><p>Another popular strategy for cross-lingual learn- ing is bitext direct projection, which consists in projecting annotations through parallel data in the source and target languages ( <ref type="bibr" target="#b52">Yarowsky et al., 2001;</ref><ref type="bibr" target="#b19">Hwa et al., 2005</ref>). This is essentially the same as Algorithm 1, except that line 4 is replaced by simple supervised learning, via a minimization of the loss function in Eq. 4 with 2 -regularization. This procedure has the disadvantage of being very sensitive to annotation errors, as we shall see. For Portuguese, this baseline is a near-reproduction of Souza and Or˘ asan (2011)'s work, discussed in §6.</p><p>The third and eighth rows in <ref type="table">Table 3</ref> show that this baseline is stronger than the delexicalized baseline, but still 6-8 points away from the super- vised systems. This gap is due to a mix of two factors: prediction errors in the English side of the bitext, and missing alignments. Indeed, when automatic alignments are used, false negatives for coreferent pairs of mentions are common, due to words that have not been aligned with sufficiently high confidence. The direct projection method is not robust to these annotation errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Baseline #3: Vanilla PR</head><p>Our last baseline is a vanilla PR approach; this is an adaptation of the procedure carried out by <ref type="bibr" target="#b11">Ganchev and Das (2013)</ref> to our coreference reso- lution problem. The motivation is to increase the robustness of bitext projection to annotation er- rors, which we do by applying the soft constraints in §4.4. We seek a saddle-point of the PR objec- tive by running 20 epochs of SGD, alternating w- updates and u-updates. The best results in the dev- set were obtained with η 1 = 1.0 and η 2 = 0.9.</p><p>By looking at the fourth and ninth rows of Ta- ble 3, we observe that vanilla PR manages to re- duce the gap to supervised systems, obtaining con- sistent gains over the bitext projection baseline (with the exception of the Portuguese dev-set). This confirms the ability of PR methods to handle annotation mistakes in a robust manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Our Proposal: Softmax-Margin PR</head><p>Finally, the fifth and last rows in <ref type="table">Table 3</ref> show the performance of our systems trained with softmax- margin PR, as described in §4.1. We optimized the loss function in Eq. 11 with γ = 1.0 by running 20 epochs of SGD, setting u 1 = +∞ and u 2 = 1.0 (cf. §4.4)-the last value was tuned in the dev-set. As shown in <ref type="figure" target="#fig_0">Figure 2</ref>, this penalized variant was more effective than the saddle point formulation.</p><p>From <ref type="table">Table 3</ref>, we observe that softmax-margin PR consistently beats all the baselines, narrow- ing the gap with respect to supervised systems to about 5 points for Spanish, and 2-3 points for Por- tuguese. Gains over the vanilla PR procedure (the strongest baseline) lie in the range 0.5-3%. These gains come from the ability of softmax-margin PR to handle task-specific cost functions, enabling a better management of precision/recall tradeoffs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Error Analysis</head><p>We carried out some error analysis, focused on the Spanish development dataset, to better under- stand where the improvements of softmax-margin PR come from. The main conclusions carry out to the Portuguese case, with a few exceptions, mostly due to different human annotation criteria. <ref type="table" target="#tab_4">Table 4</ref> shows the precision and recall scores for mention prediction and the different corefer- ence evaluation metrics. Note that all systems pre- dict the same candidate mentions; however a final post-processing discards all mentions that ended up in singleton entities, for compliance with the official scorer. Therefore, the mention prediction score reflects how well a system does in predicting if a mention is anaphoric or not. The first thing to note is that the PR methods, due to their ability to create new links during training (via constraint #2) tend to predict fewer singletons than the direct projection method. Indeed, we observe that soft max-margin PR achieves 47.1% mention predic- tion recall, which is more than 5% above the di- rect projection method, and 10% above the delex- icalized transfer method. Note also that, while the vanilla PR method achieves higher recall than the two other baselines, it is still almost 5% be- low the system trained with soft-max margin PR. This is because vanilla PR does not benefit from the cost function in §4.3-such cost is able to pe- nalize false non-anaphoric mentions and encour- age larger clusters, allowing softmax-margin PR to achieve a better precision-recall trade-off. From <ref type="table" target="#tab_4">Table 4</ref>, we can see that this improvement in men- tion recall consistently translates into higher recall for the MUC, B 3 and CEAF e coreference metrics.</p><p>Further analysis revealed that a major source of error for the delexicalized baseline is its inabil- ity to handle pronominal mentions robustly across languages-as hinted in footnote 9. In practice, we found the delexicalized systems to be quite conservative with possessive pronouns: for the Spanish dataset, where the vast majority of pos- sessive pronouns are anaphoric, the delexicalized model incorrectly predicts 53.3% of these pro- nouns as non-anaphoric. The direct projection model is slightly less conservative, missing 30.1% of the possessives (arguably due to its inability to recover missing links in the projected data, dur-  ing training). By comparison, the vanilla and soft- max margin PR models only miss 4.9% and 3.4% of the possessives, respectively. In Portuguese, where many possessives are not annotated in the gold data, we observe a similar but much less pro- nounced trend.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>While multilingual coreference resolution has been the subject of recent SemEval and CoNLL shared tasks, no submitted system attempted cross-lingual training. As shown by <ref type="bibr" target="#b38">Recasens and Hovy (2010)</ref>, language-specific issues pose a chal- lenge, due to phenomena as pronoun dropping and grammatical gender that are absent in English but exist in other languages. We have discussed some of these issues in the scope of the present work. <ref type="bibr" target="#b16">Harabagiu and</ref><ref type="bibr" target="#b16">Maiorano (2000) and</ref><ref type="bibr" target="#b31">Postolache et al. (2006)</ref> projected English corpora to Roma- nian to bootstrap human annotation, either manu- ally or via automatic alignments. Rahman and Ng (2012) applied translation-based projection at test time (but require an external translation service). <ref type="bibr" target="#b17">Hardmeier et al. (2013)</ref> addressed the related task of cross-lingual pronoun prediction. While all these approaches help alleviate the corpus annota- tion bottleneck, none resulted in a full coreference resolver, which our work accomplished.</p><p>The work most related with ours is Souza and Or˘ asan (2011), who also used parallel data to transfer an English coreference resolver to Por- tuguese, but could not beat a simple baseline that clusters together mentions with the same head. Their approach is similar to our bitext direct pro- jection baseline, except that they used Reconcile ( <ref type="bibr" target="#b44">Stoyanov et al., 2010</ref>) instead of the Berkeley Coreference System, and a smaller version of the FAPESP corpus. We have shown that our softmax- margin PR procedure is superior to this approach.</p><p>Discriminative PR has been proposed by <ref type="bibr" target="#b12">Ganchev et al. (2010)</ref>. The same idea underlies the generalized expectation criterion <ref type="bibr" target="#b23">(Mann and McCallum, 2010;</ref><ref type="bibr" target="#b51">Wang and Manning, 2014</ref>). An SGD algorithm for solving the resulting saddle point problem has been proposed by <ref type="bibr" target="#b21">Liang et al. (2009)</ref>, and used by <ref type="bibr" target="#b11">Ganchev and Das (2013)</ref> for cross-lingual learning of sequence models. We ex- tended this framework in two aspects: by incorpo- rating a task-specific cost in the objective function, and by formulating a penalized variant of PR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>We presented a framework for cross-lingual trans- fer of coreference resolvers. Our method uses word-aligned bitext to project information from the source to the target language.</p><p>Robust- ness to projection errors was achieved via a PR framework, which we generalized to handle task-specific costs, yielding softmax-margin PR. We also proposed a penalized formulation that is effective for a small number of corpus-based constraints. Empirical gains were shown over three popular cross-lingual methods: delexicalized transfer, bitext direct projection, and vanilla PR. .</p><p>Plugging this in the Lagrangian yields Eq. 8.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Comparison of saddle-point and penalized PR for Spanish, using the setup in §5.5. Left: variation of the multiplier u2 over gradient iterations, with strong oscillations in initial epochs and somewhat slow convergence. Right: impact in the averaged F1 scores (on the dev-set). Contrast with the more "stable" scores achieved by the penalized method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Dev</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Acknowledgments I would like to thank the reviewers for their helpful comments, José Guilherme Camargo de Souza for pointing to existing datasets, and Mar- iana Almeida for valuable feedback. This work was partially supported by the EU/FEDER pro- gramme, QREN/POR Lisboa (Portugal), under the Intelligo project (contract 2012/24803), and by the FCT grants UID/EEA/50008/2013 and PTDC/EEI-SII/2312/2012. A Proof of Proposition 1 Let us fix w and see how to evaluate KL(Q||p w ) = minq∈Q KL(qp w ). We have: KL(qp w ) = −H(q) − Y q(Y) log p w (Y|X) = −H(q) + n log Z (w, x (n) ) − Y q(Y)(w f (X, Y) + (Y)), where (Y) := N n=1 (y, Y(E (n) )) and f (X, Y) := N n=1 f (x (n) , y (n) ). Introducing Lagrange multipliers u for the posterior constraints, we get the Lagrangian function: L(q, u) = −H(q) + n log Z (w, x (n) ) − b u − Y q(Y)(w f (X, Y)+(Y)−u g(X, Y)). By standard variational arguments (namely, Fenchel duality between the the log-partition function and the negative en- tropy; see e.g. Martins et al. (2010)), we have that the optimal q * that minimizes the Lagrangian is q * (Y) = e w f (X,Y)+(Y)−u g(X,Y) N n=1 Z u (w, x (n) )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Results for the supervised systems. We show also the performance of delexicalized English systems, with and without 
cross-lingual embeddings. Shown are MUC (Vilain et al., 1995), B 3 (Bagga and Baldwin, 1998), and CEAFe (Luo, 2005), as 
well their averaged F1 scores, all computed using the reference implementation of the CoNLL scorer (Pradhan et al., 2014). 

Dev 
Test 
MUC 
B 3 CEAFe 
Avg. MUC 
B 3 CEAFe 
Avg. 
ES simple baseline 
25.73 24.73 
27.89 26.12 26.06 26.12 
29.87 27.35 
ES baseline #1 (delex. transfer) 
33.04 27.47 
32.71 31.07 34.35 28.69 
34.42 32.49 
ES baseline #2 (bitext dir. proj.) 39.42 30.04 
38.25 35.90 37.21 29.72 
35.97 34.30 
ES baseline #3 (vanilla PR) 
41.29 33.68 
38.56 37.84 39.34 32.95 
38.23 36.84 
ES softmax-margin PR 
42.34 35.53 
39.95 39.27 41.22 35.30 
39.94 38.82 
PT simple baseline 
26.04 26.67 
33.19 28.63 22.72 23.91 
27.35 24.66 
PT baseline #1 (delex. transfer) 
22.51 23.27 
33.27 26.35 31.11 27.36 
32.78 30.42 
PT baseline #2 (bitext dir. proj.) 30.43 27.37 
36.47 31.42 31.93 27.97 
35.40 31.77 
PT baseline #3 (vanilla PR) 
30.97 27.82 
35.14 31.31 38.39 33.34 
38.73 36.82 
PT softmax-margin PR 
33.43 31.00 
38.82 34.42 38.18 34.05 
39.47 37.23 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 : Recall/precision scores for mention prediction, MUC, B 3 and CEAFe, all computed in the Spanish dev set.</head><label>4</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="1"> We found that other commonly used parallel data (such as Europarl or the UN corpus) have a predominance of direct speech that is not suitable for our newswire test domain, so we decided not to use these data.</note>

			<note place="foot" n="2"> A precise definition of this cost is provided in §4.3.</note>

			<note place="foot" n="3"> Note that the scope of the sum is different in Eqs. 5 and 6: Z (w, x) sums over all coreference trees, while Z(w, x) sums only over those consistent with the gold clusters.</note>

			<note place="foot" n="4"> We can always reduce the problem to this case by scaling and adding a constant to the constraint feature vectors.</note>

			<note place="foot" n="5"> This follows from Lagrange duality. If bj = 1, the constraint is vacuous and by complementary slackness we must have uj = 0. If bj = 0, this becomes a hard constraint, so for the nth document, any coreference tree y for which gj(x (n) , y) = 0 must have probability zero-this corresponds to setting uj → +∞ in Eq. 10.</note>

			<note place="foot" n="6"> The only difference with respect to Durrett and Klein (2013) is that they set αFA = 0.1. We set this coefficient to zero so that all configurations licensed by the constraint features (to be made precise in §4.4) will have zero cost.</note>

			<note place="foot" n="7"> For English, the gender and number of nominal and proper mentions were obtained from the statistics collected by Bergsma and Lin (2006). For Spanish and Portuguese we used a simple heuristic for nominal mentions, based on the determiner preceding the noun (when there is one). 8 We point out that the supervised Spanish system we present here is strong enough to outperform all participating systems in the SemEval 2010&apos;s closed regular track. When trained on the original Spanish SemEval data (with zero-and relative pronoun anaphoras) and evaluated in the provided scorer, it achieves 53.0% averaged F1 in the test partition; for comparison, TALN-1 (Attardi et al., 2010), the best system at the shared task, achieved 49.6% averaged F1.</note>

			<note place="foot" n="9"> For example, in Figure 1, their agrees in number with the possessor (the alveoli), but the corresponding sua agrees in number and gender with the thing possessed (funçfunç˜função).</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Aligning opinions: Cross-lingual opinion mining with dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Mariana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cláudia</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helena</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro</forename><surname>Figueira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">André</forename><forename type="middle">F T</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Martins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>of the Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">TANL-1: coreference resolution by parse analysis and similarity clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Attardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><forename type="middle">Dei</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Simi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Workshop on Semantic Evaluation</title>
		<meeting>of the International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Fully automatic compilation of a Portuguese-English parallel corpus for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilker</forename><surname>Aziz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Algorithms for scoring coreference chains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Bagga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Breck</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of International Conference on Language Resources and Evaluation: Workshop on Linguistics Coreference</title>
		<meeting>of International Conference on Language Resources and Evaluation: Workshop on Linguistics Coreference</meeting>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Understanding the value of features for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Bengtson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Empirical Methods in Natural Language Processing</title>
		<meeting>of Empirical Methods in Natural Language essing</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Bootstrapping pathbased pronoun resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shane</forename><surname>Bergsma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>of the Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Summ-it: Um corpus anotado com informaçinformaç˜informações discursivas visando a sumarizaçsumarizaç˜sumarização automática</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandra</forename><surname>Collovini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thiago</forename><surname>Carbonel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juliana</forename><forename type="middle">Thiesen</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jorge</forename><forename type="middle">César</forename><surname>Coelho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lúcia</forename><surname>Rino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renata</forename><surname>Vieira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop em Tecnologia da InformaçInformaç˜Informação e da Linguagem Humana</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Specialized models and ranking for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Denis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Baldridge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Empirical Methods in Natural Language Processing</title>
		<meeting>of Empirical Methods in Natural Language essing</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Easy victories and uphill battles in coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Durrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Empirical Methods in Natural Language Processing</title>
		<meeting>of Empirical Methods in Natural Language essing</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Decentralized entity-level modeling for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Durrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>of Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Latent structure perceptron with feature induction for unrestricted coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cícero</forename><surname>Eraldo Rezende Fernandes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruy Luiz</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Milidiú</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint Conference on EMNLP and CoNLL-Shared Task</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Cross-lingual discriminative learning of sequence models with posterior regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuzman</forename><surname>Ganchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Empirical Methods in Natural Language Processing</title>
		<meeting>of Empirical Methods in Natural Language essing</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Posterior regularization for structured latent variable models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuzman</forename><surname>Ganchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">João</forename><surname>Graça</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Gillenwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Taskar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="2001" to="2049" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Softmax-Margin CRFs: Training Log-Linear Models with Loss Functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Unsupervised coreference resolution in a nonparametric bayesian model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aria</forename><surname>Haghighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>of Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Coreference resolution in a modular, entity-centered model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aria</forename><surname>Haghighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>of Annual Conference of the North American Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Multilingual coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sanda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Harabagiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Steven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Maiorano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conference on Applied Natural Language Processing</title>
		<meeting>of the Conference on Applied Natural Language essing</meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Latent anaphora resolution for cross-lingual pronoun prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Hardmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jörg</forename><surname>Tiedemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Empirical Methods in Natural Language Processing</title>
		<meeting>of Empirical Methods in Natural Language essing</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Multilingual Models for Compositional Distributional Semantics</title>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Annual Meeting of the Association for Computational Linguistics</title>
		<editor>Karl Moritz Hermann and Phil Blunsom</editor>
		<meeting>of the Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Bootstrapping parsers via syntactic projection across parallel texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Hwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><surname>Weinberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clara</forename><surname>Cabezas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Okan</forename><surname>Kolak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural language engineering</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="311" to="325" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Alignment by agreement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Taskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of North American Chapter of the Association of Computational Linguistics</title>
		<meeting>of North American Chapter of the Association of Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning from measurements in exponential families</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Michael I Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of International Conference on Machine Learning</title>
		<meeting>of International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="641" to="648" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">On coreference resolution performance metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoqiang</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Empirical Methods in Natural Language Processing</title>
		<meeting>of Empirical Methods in Natural Language essing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Generalized expectation criteria for semi-supervised learning with weakly labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gideon</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="955" to="984" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Turbo Parsers: Dependency Parsing by Approximate Variational Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>André</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro</forename><forename type="middle">M Q</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Aguiar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">T</forename><surname>Mário</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Figueiredo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Empirical Methods for Natural Language Processing</title>
		<meeting>of Empirical Methods for Natural Language essing</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Turning on the turbo: Fast third-order nonprojective turbo parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>André</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><forename type="middle">B</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>of the Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Multisource transfer of delexicalized dependency parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Hall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Empirical Methods in Natural Language Processing</title>
		<meeting>of Empirical Methods in Natural Language essing</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Improving machine learning approaches to coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Annual Meeting on Association for Computational Linguistics</title>
		<meeting>of the Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Unsupervised models for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Empirical Methods in Natural Language Processing</title>
		<meeting>of Empirical Methods in Natural Language essing</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Improved inference for unlexicalized parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Annual Meeting of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>of Annual Meeting of the North American Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="404" to="411" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A universal part-of-speech tagset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of LREC</title>
		<meeting>of LREC</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Transferring coreference chains through word alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Oana Postolache</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Constantin</forename><surname>Cristea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Orasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Conference on Language Resources and Evaluation</title>
		<meeting>of the International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sameer Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchen</forename><surname>Uryupina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Shared Task: Modeling multilingual unrestricted coreference in OntoNotes</title>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conference on Computational Natural Language Learning: Shared Task</title>
		<meeting>of the Conference on Computational Natural Language Learning: Shared Task</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Scoring coreference partitions of predicted mentions: A reference implementation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoqiang</forename><surname>Sameer Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Recasens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Strube</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>of the Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A multi-pass sieve for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heeyoung</forename><surname>Karthik Raghunathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Sudarshan Rangarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Empirical Methods in Natural Language Processing</title>
		<meeting>of Empirical Methods in Natural Language essing</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Narrowing the modeling gap: A cluster-ranking approach to coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Altaf</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="469" to="521" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Translation-based projection for multilingual coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Altaf</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conference of the North American Chapter</title>
		<meeting>of the Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Coreference resolution across corpora: Languages, coding schemes, and preprocessing information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><surname>Recasens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>of the Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Ancora-co: Coreferentially annotated corpora for spanish and catalan. Language resources and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><surname>Recasens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Martí</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="315" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Semeval-2010 task 1: Coreference resolution in multiple languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><surname>Recasens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lluís</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emili</forename><surname>Sapena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antònia</forename><surname>Martí</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mariona</forename><surname>Taulé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Véronique</forename><surname>Hoste</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimo</forename><surname>Poesio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannick</forename><surname>Versley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Workshop on Semantic Evaluation</title>
		<meeting>of the International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Contrastive estimation: Training log-linear models on unlabeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Annual Meeting on Association for Computational Linguistics</title>
		<meeting>of Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">A machine learning approach to coreference resolution of noun phrases</title>
		<editor>Wee Meng Soon, Hwee Tou Ng, and Daniel Chung Yong Lim</editor>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="521" to="544" />
		</imprint>
	</monogr>
	<note>Computational linguistics</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Can projected chains in parallel corpora help coreference resolution?</title>
	</analytic>
	<monogr>
		<title level="m">Anaphora Processing and Applications</title>
		<editor>José Guilherme Camargo de Souza and Constantin Or˘ asan</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="59" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Coreference resolution with reconcile</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Buttler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Hysom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>of the Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Cross-lingual word clusters for direct transfer of linguistic structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Täckström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>of the North American Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Token and type constraints for cross-lingual part-of-speech tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Täckström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Cross-lingual induction of semantic roles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Klementiev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>of the Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Word representations: a simple and general method for semisupervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Turian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>of the Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Bart: A modular toolkit for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannick</forename><surname>Versley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><forename type="middle">Paolo</forename><surname>Ponzetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimo</forename><surname>Poesio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Eidelman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Jern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofeng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Annual Meeting of the Association for Computational Linguistics: Demo Session</title>
		<meeting>of the Annual Meeting of the Association for Computational Linguistics: Demo Session</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A model-theoretic coreference scoring scheme</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Vilain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Aberdeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dennis</forename><surname>Connolly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lynette</forename><surname>Hirschman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conference on Message Understanding</title>
		<meeting>of the Conference on Message Understanding</meeting>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="45" to="52" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Cross-lingual projected expectation regularization for weakly supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengqiu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="55" to="66" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Inducing multilingual text analysis tools via robust projection across aligned corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grace</forename><surname>Ngai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Wicentowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the First International Conference on Human Language Technology Research</title>
		<meeting>of the First International Conference on Human Language Technology Research</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Cross-language parser adaptation between related languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Zeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCNLP</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="35" to="42" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
