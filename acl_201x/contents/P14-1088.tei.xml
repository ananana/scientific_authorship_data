<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:46+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A chance-corrected measure of inter-annotator agreement for syntax</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>June 23-25 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arne</forename><surname>Skjaerholt</surname></persName>
							<email>arnskj@ifi.uio.no</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Language technology group</orgName>
								<orgName type="institution">University of Oslo</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A chance-corrected measure of inter-annotator agreement for syntax</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="934" to="944"/>
							<date type="published">June 23-25 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Following the works of Carletta (1996) and Artstein and Poesio (2008), there is an increasing consensus within the field that in order to properly gauge the reliability of an annotation effort, chance-corrected measures of inter-annotator agreement should be used. With this in mind, it is striking that virtually all evaluations of syntactic annotation efforts use uncor-rected parser evaluation metrics such as bracket F 1 (for phrase structure) and accuracy scores (for dependencies). In this work we present a chance-corrected metric based on Krippendorff&apos;s α, adapted to the structure of syntactic annotations and applicable both to phrase structure and dependency annotation without any modifications. To evaluate our metric we first present a number of synthetic experiments to better control the sources of noise and gauge the metric&apos;s responses, before finally contrasting the behaviour of our chance-corrected metric with that of un-corrected parser evaluation metrics on real corpora. 1</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>It is a truth universally acknowledged that an an- notation task in good standing be in possession of a measure of inter-annotator agreement (IAA). However, no such measure is in widespread use for the task of syntactic annotation. This is due to a mismatch between the formulation of the agree- ment measures, which assumes that the annota- tions have no or relatively little internal structure, and syntactic annotation where structure is the en- tire point of the annotation. For this reason efforts to gauge the quality of syntactic annotation are hampered by the need to fall back to simple ac- curacy measures. As shown in <ref type="bibr" target="#b0">Artstein and Poesio (2008)</ref>, such measures are biased in favour of an- notation schemes with fewer categories and do not account for skewed distributions between classes, which can give high observed agreement, even if the annotations are inconsistent.</p><p>In this article we propose a family of chance- corrected measures of agreement, applicable to both dependency-and constituency-based syntac- tic annotation, based on Krippendorff's α and tree edit distance. First we give an overview of tradi- tional agreement measures and why they are insuf- ficient for syntax, before presenting our proposed metrics. Next, we present a number of synthetic experiments performed in order to find the best distance function for this kind of annotation; fi- nally we contrast our new metric and simple accu- racy scores as applied to real-world corpora before concluding and presenting some potential avenues for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Previous work</head><p>The definitive reference for agreement measures in computational linguistics is <ref type="bibr" target="#b0">Artstein and Poesio (2008)</ref>, who argue forcefully in favour of the use of chance-corrected measures of agreement over simple accuracy measures. However, most evaluations of syntactic treebanks use simple ac- curacy measures such as bracket F 1 scores for constituent trees <ref type="bibr">(NEGRA, Brants, 2000</ref>; TIGER, <ref type="bibr" target="#b6">Brants and Hansen, 2002;</ref><ref type="bibr">Cat3LB, Civit et al., 2003</ref>; The Arabic Treebank, <ref type="bibr" target="#b23">Maamouri et al., 2008)</ref> or labelled or unlabelled attachment scores for dependency syntax <ref type="bibr">(PDT, Hajič, 2004;</ref><ref type="bibr">PCEDT Mikulová andŠtěpánekandˇandŠtěpánek, 2010;</ref><ref type="bibr">Norwegian Dependency Treebank, Skjaerholt, 2013</ref>). The only work we know of using chance-corrected metrics is <ref type="bibr" target="#b31">Ragheb and Dickinson (2013)</ref>, who use MASI ( <ref type="bibr" target="#b30">Passonneau, 2006</ref>) to measure agreement on de- pendency relations and head selection in multi- headed dependency syntax, and <ref type="bibr" target="#b3">Bhat and Sharma (2012)</ref>, who compute Cohen's κ <ref type="bibr" target="#b12">(Cohen, 1960)</ref> on dependency relations in single-headed depen- dency syntax. A limitation of the first approach is that token ID becomes the relevant category for the purposes of agreement, while the second ap- proach only computes agreements on relations, not on structure.</p><p>In grammar-driven treebanking (or parsebank- ing), the problems encountered are slightly differ- ent. In HPSG and LFG treebanking annotators do not annotate structure directly. Instead, the gram- mar parses the input sentences, and the annotator selects the correct parse (or rejects all the candi- dates) based on discriminants 2 of the parse forest. In this context, de Castro (2011) developed a vari- ant of κ that measures agreement over discrimi- nant selection. This is different from our approach in that agreement is computed on annotator deci- sions rather than on the treebanked analyses, and is only applicable to grammar-based approaches such as HPSG and LFG treebanking.</p><p>The idea of using edit distance as the basis for an inter-annotator agreement metric has previ- ously been explored by <ref type="bibr" target="#b16">Fournier (2013)</ref>. However that work used a boundary edit distance as the ba- sis of a metric for the task of text segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Notation</head><p>In this paper, we mostly follow the notation and terminology of <ref type="bibr" target="#b0">Artstein and Poesio (2008)</ref>, with some additions. The key components in an agree- ment study are the items annotated, the coders who make judgements on individual items, and the an- notations created for the items. We denote these as follows:</p><p>• The set of items I = {i 1 , i 2 , . . . }</p><p>• The set of coders C = {c 1 , c 2 , . . . }</p><p>• The set of annotations X is a set of sets X = {X i |i ∈ I} where each set X i = {x ic |c ∈ C} contains the annotations for each item. If not all coders annotate all items, the different X i will be of different sizes.</p><p>In the case of nominal categorisation we will also use the set K of possible categories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The metric</head><p>The most common metrics used in computational linguistics are the metrics κ (Cohen, 1960, in- troduced to computational linguistics by <ref type="bibr" target="#b10">Carletta, 1996</ref>) and π <ref type="bibr" target="#b33">(Scott, 1955)</ref>. These metrics express agreement on a nominal coding task as the ra- tio κ, π = Ao−Ae /1−Ae where A o is the observed agreement and A e the expected agreement accord- ing to some model of "random" annotation. Both metrics have essentially the same model of ex- pected agreement:</p><formula xml:id="formula_0">A e = k∈K P (k|c 1 )P (k|c 2 )<label>(1)</label></formula><p>differing only in how they estimate the probabil- ities: κ assigns separate probability distributions to each coder based on their observed behaviour, while π uses the same distribution for both coders based on their aggregate behaviour. Now, if we want to perform this same kind of evaluation on syntactic annotation it is not possible to use κ or π directly. In the case of dependency- based syntax we could conceivably use a variant of these metrics by considering the ID of a to- ken's head as a categorical variable (the approach taken in <ref type="bibr" target="#b31">Ragheb and Dickinson, 2013</ref>), but we ar- gue that this is not satisfactory. This use of the metrics would consider agreement on categories such as "tokens whose head is token number 24", which is obviously not a linguistically informative category. Thus we have to reject this way of as- sessing the reliability of dependency syntax anno- tation. Also, this approach is not directly general- isable to constituency-based syntax.</p><p>For dependency syntax we could generalise these metrics similarly to how κ is generalised to κ w to handle partial credit for overlapping annota- tions. Let the function LAS(t 1 , t 2 ) be the number of tokens with the same head and label in the two trees t 1 and t 2 , T (i) the set of trees possible for an item i ∈ I, and tokens the number of tokens in the corpus. Then we can compute an expected agreement as follows: We see three problems with this approach. First of all the number of possible trees for a sentence grows exponentially with sentence length, which means that explicitly iterating over all possible such pairs is computationally intractable, nor have we been able to easily derive an algorithm for this particular problem from standard algorithms.</p><formula xml:id="formula_1">A e = 1 tokens i∈I t 1 ,t 2 ∈T (i) 2 LAS e (t 1 , t 2 ) (2) LAS e (t 1 , t 2 ) = P (t 1 |c 1 )P (t 2 |c 2 )LAS(t 1 , t 2 )</formula><p>Second, the question of which model to use for P (t|c) is not straightforward. It is possible to use generative parsing models such as PCFGs or the generative dependency models of <ref type="bibr" target="#b14">Eisner (1996)</ref>, but agreement metrics require a model of random annotation, and as such using models designed for parsing runs the risk of over-estimating A e , result- ing in artificially low agreement scores.</p><p>Finally, it may be hard to establish a consensus in the field of which particular metric to use. As shown by the existence of three different metrics <ref type="bibr">(κ, π and S (Bennett et al., 1954)</ref>) for the rela- tively simple task of nominal coding, the choice of model for P (t|c) will not be obvious, and thus differing choices of generative model as well as different choices for parameters such as smooth- ing will result in subtly different agreement met- rics. The results of these different metrics will not be directly comparable, which will make the re- sults of groups using different metrics unnecessar- ily hard to compare.</p><p>Instead, we propose to use an agreement mea- sure based on Krippendorff's α ( <ref type="bibr" target="#b21">Krippendorff, 1970;</ref><ref type="bibr" target="#b22">Krippendorff, 2004</ref>) and tree edit distance. In this approach we compare tree structures di- rectly, which is extremely parsimonious in terms of assumptions, and furthermore sidesteps the problem of probabilistically modelling annotators' behaviour entirely. Krippendorff's α is not as com- monly used as κ and π, but it has the advantage of being expressed in terms of an arbitrary distance function δ.</p><p>A full derivation of α is beyond the scope of this article, and we will simply state the formula used to compute the agreement. Krippendorff's α is normally expressed in terms of the ratio of observed and expected disagreements: α = 1 − Do /De, where D o is the mean squared distance be- tween annotations of the same item and D e the mean squared distance between all pairs of anno- tations:</p><formula xml:id="formula_2">D o = i∈I 1 |X i | − 1 c∈C c ∈C δ(x ic , x ic ) 2 D e = 1 i∈I |X i | − 1 i∈I c∈C i ∈I c ∈C δ(x ic , x i c ) 2</formula><p>Note that in the expression for D e , we are com- puting the difference between annotations for dif- ferent items; thus, our distance function for syn- tactic trees needs to be able to compute the differ- ence between arbitrary trees for completely unre- lated sentences. The function δ can be any func- tion as long as it is a metric; that is, it must be (1) non-negative, (2) symmetric, (3) zero only for identical inputs, and <ref type="formula">(4)</ref>  uncorrected accuracy measure and thus unsuitable for our purposes. <ref type="bibr">3</ref> When comparing syntactic trees, we only want to compare dependency relations or non-terminal categories. Therefore we remove the leaf nodes in the case of phrase structure trees, and in the case of dependency trees we compare trees whose edges are unlabelled and nodes are labelled with the de- pendency relation between that word and its head; the root node receives the label . An example of this latter transformation is shown in <ref type="figure" target="#fig_0">Figure 1</ref>.</p><p>We propose three different distance functions for the agreement computation: the unmodified tree edit distance function, denoted δ plain , a sec- ond function δ dif f (x, y) = TED(x, y)−abs(|x|− |y|), the edit distance minus the difference in length between the two sentences, and finally δ norm (x, y) = TED(x,y) /|x|+|y|, the edit distance normalised to the range <ref type="bibr">[0,</ref><ref type="bibr">1]</ref>. <ref type="bibr">4</ref> The plain TED is the simplest in terms of parsi- mony assumptions, however it may overestimate the difference between sentences, we intuitively find to be syntactically similar. For example the only difference between the two leftmost trees in <ref type="figure" target="#fig_1">Figure 2</ref> is a modifier, but δ plain gives them dis- tance 4 and δ dif f 0. On the other hand, δ dif f might underestimate some distances as well; for exam-ple the leftmost and rightmost trees also have dis- tance zero using δ dif f , despite our syntactic intu- ition that the difference between a transitive and an intransitive should be taken account of.</p><p>The third distance function, δ norm , takes into account a slightly different concern; namely that when comparing a long sentence and a short sen- tence, the distance has to be quite large simply to account for the difference in number of nodes, un- like comparing two short or two long sentences. Normalising to the range <ref type="bibr">[0,</ref><ref type="bibr">1]</ref> puts all pairs on an equal footing.</p><p>However, we cannot a priori say which of the three functions is the optimal choice of distance functions. The different functions have different properties, and different advantages and draw- backs, and the nature of their strengths and weak- nesses differ. We will therefore perform a number of synthetic experiments to investigate their prop- erties in a controlled environment, before applying them to real-world data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Synthetic experiments</head><p>In the previous section, we proposed three different agreement metrics α plain , α dif f and α norm , each involving different trade-offs. Decid- ing which of these metrics is the best one for our purposes of judging the consistency of syntactic annotation poses a bit of a conundrum. We could at this point apply our metrics to various real cor- pora and compare the results, but since the consis- tency of the corpora is unknown, it's impossible to say whether the best metric is the one resulting in the highest scores, the lowest scores or somewhere in the middle. To properly settle this question, we first performed a number of synthetic experiments to gauge how the different metrics respond to dis- agreement.</p><p>The general approach we take is based on that used by <ref type="bibr" target="#b25">Mathet et al. (2012)</ref>, adapted to depen- dency trees. An already annotated corpus, in our case 100 randomly selected sentences from the Norwegian Dependency Treebank ( <ref type="bibr" target="#b35">Solberg et al., 2014</ref>), are taken as correct and then permuted to produce "annotations" of different quality. For de- pendency trees, the input corpus is permuted as follows:</p><p>1. Each token has a probability p relabel of being assigned a different label uniformly at ran- dom from the set of labels used in the corpus. Each token has a probability p reattach of be- ing assigned a new head uniformly at random from the set of tokens not dominated by the token.</p><p>The second permutation process is dependent on the order the tokens are processed, and we con- sider the tokens in the post-order 5 as dictated by the original tree. This way tokens close to the root have a fair chance of having candidate heads if they are selected. A pre-order traversal would re- sult in tokens close to the root having few options, and in particular if the root has a single child, that node has no possible new heads unless one of its children has been assigned the root as its new head first. For example in the trees in <ref type="figure" target="#fig_1">figure 2</ref>, assign- ing any other head than the root to the PRED nodes directly dominated by the root will result in in- valid (cyclic and unconnected) dependency trees. Traversing the tokens in the linear order dictated by the sentence has similar issues for tokens close to the root and close to the start of the sentence. For our first set of experiments, we set p relabel = p reattach and evaluated the different agreement metrics for 10 evenly spaced p-values between 0.1 and 1.0. Initial exploration of the data showed that the mean follows the median very closely regardless of metric and perturbation level, and therefore we only report the mean scores across runs in this paper. The results of these ex- periments are shown in <ref type="figure">Figure 3</ref>, with the labelled attachment score 6 (LAS) for comparison. <ref type="bibr">5</ref> That is, the child nodes of a node are all processed before the node itself. Nodes on the same level are traversed from left to right. <ref type="bibr">6</ref> The de facto standard parser evaluation metric in depen- The α dif f metric is clearly extremely sensitive to noise, with p = 0.1 yielding mean α dif f = 15.8%, while α norm is more lenient than both LAS and α plain , with mean α norm = 14.5% at p = 1, quite high compared to LAS = 0.9%, α plain = −6.8% and α dif f = −246%. To fur- ther study the sensitivity of the metrics to the two kinds of noise, we performed an additional set of experiments, setting one p = 0 while varying the other over the same range as in the previous exper- iment, the results of which are shown in Figures 4 and 5.</p><p>The LAS curves are mostly unremarkable, with one exception: Mean LAS at p reattach = 1 of Fig- ure 5 is 23.9%, clearly much higher than we would expect if the trees were completely random. In comparison, mean LAS when only labels are per- turbed is 4.1%, and since the sample space of trees of size n is clearly much larger than that of rela- bellings, a uniform random selection of tree would yield a LAS much closer to 0. This shows that our tree shuffling algorithm has a non-uniform distri- bution over the sample space.</p><p>While the behaviour of our alphas and LAS are relatively similar in <ref type="figure" target="#fig_3">Figure 3, Figures 4 and 5</ref> show that they do in fact have important differences. Whereas LAS responds linearly to perturbation of both labels and structure, with its parabolic be- haviour in <ref type="figure">Figure 3</ref> being simply the product of these two linear responses, the α metrics respond differently to structural noise and label noise, with label disagreements being penalised less harshly dency parsing: the percentage of tokens that receive the cor- rect head and dependency relation.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Real-world corpora</head><p>Synthetic experiments do not always fully re- flect real-world behaviour, however. Therefore we will also evaluate our metrics on real-world inter- annotator agreement data sets. In our evaluation, we will contrast labelled accuracy, the standard parser evaluation metric, and our three α metrics. In particular, we are interested in the correlation (or lack thereof) between LAS and the alphas, and whether the results of our synthetic experi- ments correspond well with the results on real- world IAA sets. Finally, we also evaluate the met- ric on both dependency and phrase structure data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">The corpora</head><p>We obtained <ref type="bibr">7</ref>   (NDT, CDT, PCEDT) and one phrase structure treebank (SSD), and of the dependency tree- banks the PCEDT contains semantic dependen- cies, while the other two have traditional syntac- tic dependencies. The number of annotators and sizes of the different data sets are summarised in <ref type="table" target="#tab_1">Table 1</ref>.</p><p>NDT The Norwegian Dependency Treebank ( <ref type="bibr" target="#b35">Solberg et al., 2014</ref>) is a dependency treebank constructed at the National Library of Norway. The data studied in this work has previously been used by <ref type="bibr" target="#b34">Skjaerholt (2013)</ref> to study agreement, but using simple accuracy measures (UAS, LAS) rather than chance-corrected measures. The IAA data set is divided into three parts, corresponding to different parsers used to preprocess the data be- fore annotation; what we term NDT 1 through 3 correspond to what Skjaerholt (2013) labels Dan- ish, Swedish and Norwegian, respectively.</p><p>CDT The Copenhagen Dependency Treebanks (Buch- <ref type="bibr" target="#b9">Kromann et al., 2009;</ref><ref type="bibr" target="#b8">Buch-Kromann and Korzen, 2010</ref>) is a collection of parallel depen- dency treebanks, containing data from the Danish PAROLE corpus <ref type="bibr" target="#b20">(Keson, 1998b;</ref><ref type="bibr" target="#b19">Keson, 1998a</ref>) in the original Danish and translated into English, Italian and Spanish. Czech translations of the English data. The syn- tactic annotations are layered and consist of an analytical layer similar to the annotations in most other dependency treebanks, and a more semantic tectogrammatical layer.</p><p>Our data set consists of a common set of analyt- ical annotations shared by all the annotators, and the tectogrammatical analyses built on top of this common foundation. A distinguishing feature of the tectogrammatical analyses, vis a vis the other treebanks we are using, is that semantically empty words only take part in the analytical annotation layer and nodes are inserted at the tectogrammat- ical layer to represent covert elements of the sen- tence not present in the surface syntax of the ana- lytical layer. Thus, inserting and deleting nodes is a central part of the task of tectogrammatical an- notation, unlike the more surface-oriented annota- tion of our other treebanks, where the tokenisation is fixed before the text is annotated.</p><p>SSD The Star-Sem Data is a portion of the dataset released for the *SEM 2012 shared task <ref type="bibr" target="#b27">(Morante and Blanco, 2012)</ref>, parsed using the LinGO English Resource Grammar <ref type="bibr">(ERG, Flickinger, 2000</ref>) and the resulting parse forest disambiguated based on discriminants. The ERG is an HPSG-based grammar, and as such its analy- ses are attribute-value matrices (AVMs); an AVM is not a tree but a directed acyclic graph however, and for this reason we compute agreement not on the AVM but the so-called derivation tree. This tree describes the types of the lexical items in the sentence and the bottom-up ordering of rule ap- plications used to produce the final analysis and can be handled by our procedure like any phrase- structure tree.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Agreement results</head><p>To evaluate our corpora, we compute the three α variants described in the previous two sections, and compare these with labelled accuracy scores.</p><p>When there are more than two annotators, we generalise the metric to be the average pairwise LAS for each sentence, weighted by the length of the sentence. Let LAS(t 1 , t 2 ) be the fraction of to- kens with identical head and label in the trees t 1 and t 2 ; the pairwise labelled accuracy LAS p (X) of a set of annotations X as described in section  </p><formula xml:id="formula_3">LAS p (X) = 1 i |x i1 | |x i1 |Λ(X i ) |X i |(|X i |−1) /2 (3) Λ(X i ) = |C| c=1 |C| c =c+1 LAS(x ic , x ic )</formula><p>This is equivalent to the traditional metric in the case where there are only two annotators. As our uncorrected metric for comparing two phrase structure trees we do not use the traditional bracket F 1 as it does not generalise well to more than two annotators, but rather Jaccard similarity. The Jaccard similarity of two sets A and B is the ratio of the size of their intersection to the size of their union: J(A, B) = |A∩B| /|A∪B|, and we use the Jaccard similarity of the sets of labelled bracketings of two trees as our uncorrected mea- sure. To compute the similarity for a complete set of annotations we use the mean pairwise Jaccard similarity weighted by sentence length; that is, the same procedure as in 3, but using Jaccard similar- ity rather than LAS.</p><p>Since LAS assumes that both of the sentences compared have identical sets of tokens, we had to exclude a number of sentences from the LAS computation in the cases of the English and Ital- ian CDT corpora, and especially the PCEDT. The large number of sentences excluded in the PCEDT is due to the fact that in the tectogrammatical anal- ysis of the PCEDT, inserting and deleting nodes is an important part of the annotation task.</p><p>Looking at the results in <ref type="table" target="#tab_3">Table 2</ref> two things. Most obvious, is the extremely large gap between the LAS and α metrics for the PCEDT data. However, there is a more subtle point; the orderings of the corpora by the differ- ent metrics are not the same. LAS order the cor- pora NDT 3, 2, 1, CDT da, en, it, es, PCEDT, whereas α dif f and α norm gives the order NDT 2, 1, 3, PCEDT, CDT da, en, it, es, and α plain gives the same order as the other alphas but with CDT es and it changing places. Furthermore, as the scatter- plot in <ref type="figure" target="#fig_7">Figure 6</ref> shows, there is a clear correlation between the α metrics and LAS, if we disregard the PCEDT results. The reason the PCEDT gets such low LAS is essentially the same as the reason many sentences had to be excluded from the computation in the first place; since inserting and deleting nodes is an integral part of the tectogrammatical annotation task, the assumption implicit in the LAS computa- tion that sentences with the same number of nodes have the same nodes in the same order is obviously false, resulting in a very low LAS.</p><p>The corpus that scores the highest for all three metrics is the SSD corpus; the reason for this is uncertain, as our corpora differ along many dimen- sions, but the fact that the annotation was done by professional linguists who are very familiar with the grammar used to parse the data is likely a contributing factor. The difference between the α metrics and the Jaccard similarity is larger than the difference between α and LAS for our depen- dency corpora, however the two similarity metrics are not comparable, and it is well known that for phrase structures single disagreements such as a PP-attachment disagreement can result in multiple disagreeing bracketings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>The most important conclusion we draw from this work is the most appropriate agreement metric for syntactic annotation. First of all, we disqualify the LAS metric, primarily due to the methodologi- cal inadequacies of using an uncorrected measure. While our experiments did not reveal any seri- ous shortcomings (unlike those of <ref type="bibr" target="#b25">Mathet et al., 2012</ref> who in the case of categorisation showed that for large p the uncorrected measure can be increasing), the methodological problems of un- corrected metrics makes us wary of LAS as an agreement metric. Next, of the three α metrics, α plain is clearly the best; α dif f is extremely sen- sitive to even moderate amounts of disagreement, while α norm is overly lenient.</p><p>Looking solely at <ref type="figure">Figure 3</ref>, one might be led to believe that LAS and α plain are interchangeable, but this is not the case. As shown by Figures 4 and 5, the paraboloid shape of the LAS curve in <ref type="figure">Figure 3</ref> is simply the combination of the met- ric's linear responses to both label and structural perturbations. The behaviour of α on the other hand is more complex, with structural noise be- ing penalised harder than perturbations of the la- bels. Thus, the similarity of LAS and α plain is not at all assured when the amounts of structural and labelling disagreements differ. Additionally, we consider this imbalanced weighting of structural and labelling disagreements a benefit, as structure is the larger part of syntactic annotation compared to the labelling of the dependencies/bracketings. Finally our experiments show that α is a single metric that is applicable to both dependencies and phrase structure trees.</p><p>Furthermore, α metrics are far more flexible than simple accuracy metrics. The use of a dis- tance function to define the metric means that more fine-grained distinctions can be made; for example, if the set of labels on the structures is highly structured, partial credit can be given for differing annotations that overlap. For example, if different types of adverbials (temporal, negation, etc.) receive different relations, as is the case in the Swedish Talbanken05 ( <ref type="bibr" target="#b28">Nivre et al., 2006</ref>) cor- pus, confusion of different adverbial types can be given less weight than confusion between subject and object. The α-based metrics are also far easier to apply to a more complex annotation task such as the tectogrammatical annotation of the PCEDT. In this task inserting and deleting nodes is an in- tegral part of the annotation, and if two annotators insert or delete different nodes the all-or-nothing requirement of identical yield of the LAS metric makes it impossible as an evaluation metric in this setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Future work</head><p>In future work, we would like to investigate the use of other distance functions, in particular the use of approximate tree edit distance functions such as the pq-gram algorithm ( <ref type="bibr" target="#b1">Augsten et al., 2005</ref>). For large data sets such as the PCEDT set used in this work, computing α with tree edit distance as the distance measure can take a very long time. 8 This is due to the fact that α requires O(n 2 ) com- parisons to be made, each of which is O(n 2 ) us- ing our current approach. The problem of directed graph edit distance is NP-hard, which means that to apply our method to HPSG analyses directly ap- proximate algorithms are a requirement.</p><p>Another avenue for future work is improved synthetic experiments. As we saw, our implemen- tation of tree perturbations was biased towards trees similar in shape to the source tree, and an im- proved permutation algorithm may reveal interest- ing edge-case behaviour in the metrics. A method for perturbing phrase structure trees would also be interesting, as this would allow us to repeat the synthetic experiments performed here using phrase structure corpora to compare the behaviour of the metrics on the two types of corpus.</p><p>Finally, annotator modelling techniques like that presented in <ref type="bibr" target="#b29">Passonneau and Carpenter (2013)</ref> has obvious advantages over agreement coeffi- cients such as α. These techniques are interpreted more easily than agreement coefficients, and they allow us to assess the quality of individual annota- tors, a crucial property in crowd-sourcing settings and something that's impossible using agreement coefficients.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Transformation of dependency trees before comparison</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Three trees with distance zero using δ dif f</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>p</head><label></label><figDesc>Figure 3: Mean agreement over ten runs</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Mean agreement over ten runs, p reattach = 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Mean agreement over ten runs, p relabel = 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>PCEDT</head><label></label><figDesc>The Prague Czech-English Depen- dency Treebank 2.0 Hajič et al. (2012) is a par- allel corpus of English and Czech, consisting of English data from the Wall Street Journal Section of the Penn Treebank (Marcus et al., 1993) and</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Correlation of LAS with α</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>data from four different corpora. Three of the data sets are dependency treebanks</figDesc><table>Corpus 
Sentences Tokens 

NDT 1 a 
130 
1674 
NDT 2 a 
110 
1594 
NDT 3 a 
150 
1997 

CDT (da) a 
162 
2394 
CDT (en) a 
264 
5528 
CDT (es) b 
55 
924 
CDT (it) c 
136 
3057 

PCEDT d 
3531 
61737 

SSD e 
96 
1581 

a 2 annotators 
b 4 annotators, avg. 2.8 annotators/text (min. 2, max. 4) 
c 3 annotators, avg. 2.7 annotators/text 
d 11 annotators, avg. 2.5 annotators/text (min. 2, max. 6) 
e 3 annotators, avg. 2.9 annotators/sent. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 : Sizes of the different IAA corpora</head><label>1</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Agreement scores on real-world corpora 

1.2 is: 

</table></figure>

			<note place="foot" n="1"> The code used to produce the data in this paper, and some of the datasets used, are available to download at https://github.com/arnsholt/syn-agreement/</note>

			<note place="foot" n="2"> A discriminant is an attribute of the analyses produced by the grammar where some of the analyses differ, e.g. is the word jump a noun or a verb, or does a PP attach to a VP or the VP&apos;s object NP.</note>

			<note place="foot" n="2">. ∀x, y : δ(x, y) = δ(x, y) 3. ∀x, y : δ(x, y) = 0 ⇔ x = y 4. ∀x, y, z : δ(x, y) + δ(y, z) ≥ δ(x, z) This immediately excludes metrics like ParsEval (Black et al., 1991) and Leaf-Ancestor (Sampson and Babarczy, 2003), since they assume that the trees being compared are parses of the same sentence. Instead, we base our work on tree edit distance. The tree edit distance (TED) problem is defined analogously to the more familiar problem of string edit distance: what is the minimum number of edit operations required to transform one tree into the other? See Bille (2005) for a thorough introduction to the tree edit distance problem and other related problems. For this work, we used the algorithm of Zhang and Shasha (1989). Tree edit distance has previously been used in the TEDEVAL software (Tsarfaty et al., 2011; Tsarfaty et al., 2012) for parser evaluation agnostic to both annotation scheme and theoretical framework, but this by itself is still an</note>

			<note place="foot" n="3"> While it is quite different from other parser evaluation schemes, TEDEVAL does not correct for chance agreement and is thus an uncorrected metric. It could of course form the basis for a corrected metric, given a suitable measure of expected agreement. 4 We can easily show that |x| + |y| is an upper bound on the TED, corresponding to deleting all nodes in the source tree and inserting all the nodes in the target.</note>

			<note place="foot" n="7"> We contacted a number of treebank projects, among them the Penn Treebank and the Prague Dependency Treebank, but not all of them had data available.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>I would like to thank Jaň Stěpánek at Charles Uni-versity for data from the PCEDT and help with the conversion process, the CDT project for pub-lishing their agreement data, Per Erik Solberg at <ref type="bibr">8</ref> The Python implementation used in this work, using NumPy and the PyPy compiler, took seven and a half hours compute a single α for the PCEDT data set on an Intel Core i7 2.9 GHz computer. The program is single-threaded. the Norwegian National Library for data from the NDT, and Emily Bender at the University of Washington for the SSD data.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Inter-Coder Agreement for Computational Linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><surname>Artstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimo</forename><surname>Poesio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="555" to="596" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Approximate Matching of Hierarchical Data Using pq-Grams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolaus</forename><surname>Augsten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Böhlen</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johann</forename><surname>Gamper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st international conference on Very large data bases</title>
		<meeting>the 31st international conference on Very large data bases<address><addrLine>Trondheim</addrLine></address></meeting>
		<imprint>
			<publisher>VLDB Endowment</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="301" to="312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Communications Through Limited-Response Questioning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Alpert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Goldstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Public Opinion Quarterly</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="303" to="308" />
			<date type="published" when="1954" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A Dependency Treebank of Urdu and its Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmad</forename><surname>Riyaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipti Misri</forename><surname>Bhat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sharma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Linguistic Annotation Workshop</title>
		<meeting>the Sixth Linguistic Annotation Workshop<address><addrLine>Jeju</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="157" to="165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A survey on tree edit distance and related problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Bille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">337</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="217" to="239" />
			<date type="published" when="2005-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A Procedure for Quantitatively Comparing the Syntactic Coverage of English Grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ezra</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Abney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Flickinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudia</forename><surname>Gdaniec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><surname>Hindle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Ingria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederick</forename><surname>Jelinek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judith</forename><surname>Klavans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Liberman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><forename type="middle">P</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatrice</forename><surname>Santorini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomek</forename><surname>Strzalkowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the workshop on Speech and Natural Language</title>
		<meeting>the workshop on Speech and Natural Language<address><addrLine>Pacific Grove, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="page" from="306" to="311" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Developments in the TIGER Annotation Scheme and their Realization in the Corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabine</forename><surname>Brants</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvia</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third International Conference on Language Resources and Evaluation</title>
		<meeting>the Third International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="1643" to="1649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Inter-Annotator Agreement for a German Newspaper Corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><surname>Brants</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second International Conference on Language Resources and Evaluation</title>
		<meeting>the Second International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The unified annotation of syntax and discourse in the Copenhagen Dependency Treebanks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Buch-Kromann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iørn</forename><surname>Korzen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Linguistic Annotation Workshop</title>
		<meeting>the Fourth Linguistic Annotation Workshop<address><addrLine>Uppsala</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="127" to="131" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Uncovering the &apos;lost&apos; structure of translations with parallel treebanks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Buch-Kromann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iørn</forename><surname>Korzen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henrik</forename><forename type="middle">Høeg</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Methodology, Technology and Innovation in Translation Process Research</title>
		<editor>Fabio Alves, Susanne Göpferich, and Inger Mees</editor>
		<meeting><address><addrLine>Frederiksberg</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="199" to="224" />
		</imprint>
	</monogr>
	<note>Samfundslitteratur</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Assessing Agreement on Classification Tasks: The Kappa Statistic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Carletta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="249" to="254" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Qualitative and Quantitative Analysis of Annotators&apos; Agreement in the Development of</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Montserrat</forename><surname>Civit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alicia</forename><surname>Ageno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Borja</forename><surname>Navarro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Núria</forename><surname>Bufí</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Antònia</forename><surname>Martí</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Workshop on Treebanks and Linguistic Theories</title>
		<meeting>the Second Workshop on Treebanks and Linguistic Theories<address><addrLine>Växjö</addrLine></address></meeting>
		<imprint>
			<publisher>Växjö University Press</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="21" to="32" />
		</imprint>
	</monogr>
	<note>Joakim Nivre and Erhard Hinrichs</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A Coefficient of Agreement for Nominal Scales</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Educational and Psychological Measurement</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="37" to="46" />
			<date type="published" when="1960-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Developing reliability metrics and validation tools for datasets with deep linguistic information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sérgio Ricardo De Castro</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
		<respStmt>
			<orgName>Universidade de Lisboa</orgName>
		</respStmt>
	</monogr>
	<note>Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Three New Probabilistic Models for Dependency Parsing: An Exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><forename type="middle">M</forename><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th International Conference on Computational Linguistics</title>
		<meeting>the 16th International Conference on Computational Linguistics<address><addrLine>Stroudsburg</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="340" to="345" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">On building a more efficient grammar by exploiting types</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Flickinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="15" to="28" />
			<date type="published" when="2000-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Evaluating Text Segmentation using Boundary Edit Distance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Fournier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1702" to="1712" />
		</imprint>
	</monogr>
	<note>Sofia. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Hajič</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eva</forename><surname>Hajičová</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jarmila</forename><surname>Panevová</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petr</forename><surname>Sgall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvie</forename><surname>Cinková</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eva</forename><surname>Fučíková</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie</forename><surname>Mikulová</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petr</forename><surname>Pajas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Popelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiří</forename><surname>Semeck´ysemeck´y</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaň</forename><surname>Janašindlerovájanaˇjanašindlerová</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Stěpánek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zdeňka</forename><surname>Toman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zděněkzděněkˇzděněkžabokrtsk´zděněkžabokrtsk´y</forename><surname>Urešová</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Prague Czech-English</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Complex Corpus Annotation: The Prague Dependency Treebank</title>
	</analytic>
	<monogr>
		<title level="j">Jazykovedn´yústavˇLJazykovedn´yJazykovedn´y´Jazykovedn´yústav Jazykovedn´yústavˇ Jazykovedn´yústavˇL. ˇ Stúra, SAV</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">The Danish Morphosyntactically Tagged PAROLE Corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Britt</forename><surname>Keson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>Danish Society for Literature and Language</publisher>
			<pubPlace>Copenhagen</pubPlace>
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Vejledning til det danske morfosyntaktisk taggede PAROLE-korpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Britt</forename><surname>Keson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>Danish Society for Literature and Language</publisher>
			<pubPlace>Copenhagen</pubPlace>
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Estimating the Reliability, Systematic Error and Random Error of Interval Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Krippendorff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Educational and Psychological Measurement</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="70" />
			<date type="published" when="1970-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Content Analysis: An introduction to its methodology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Krippendorff</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Sage Publications</publisher>
			<pubPlace>Thousand Oaks</pubPlace>
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Enhancing the Arabic Treebank : A Collaborative Effort toward New Annotation Guidelines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Maamouri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ann</forename><surname>Bies</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seth</forename><surname>Kulick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth International Conference on Language Resources and Evaluation</title>
		<meeting>the Sixth International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="3192" to="3196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Building a large annotated corpus of English: The Penn Treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><forename type="middle">P</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatrice</forename><surname>Santorini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><forename type="middle">Ann</forename><surname>Marcinkiewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="313" to="330" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Manual Corpus Annotation : Giving Meaning to the Evaluation Metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Mathet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Widlöcher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karën</forename><surname>Fort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>François</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Galibert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cyril</forename><surname>Grouin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juliette</forename><surname>Kahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sophie</forename><surname>Rosset</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Zweigenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2012</title>
		<meeting>COLING 2012<address><addrLine>Mumbai</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="809" to="818" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Ways of Evaluation of the Annotators in Building the Prague Czech-English Dependency Treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie</forename><surname>Mikulová</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaň</forename><surname>Stěpánek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh International Conference on Language Resources and Evaluation</title>
		<meeting>the Seventh International Conference on Language Resources and Evaluation<address><addrLine>Valletta</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1836" to="1839" />
		</imprint>
	</monogr>
	<note>European Language Resources Association</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">*SEM 2012 Shared Task : Resolving the Scope and Focus of Negation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roser</forename><surname>Morante</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduardo</forename><surname>Blanco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The First Joint Conference on Lexical and Computational Semantics</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="265" to="274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Talbanken05 : A Swedish Treebank with Phrase Structure and Dependency Annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Nilsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Hall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth International Conference on Language Resources and Evaluation</title>
		<meeting>the Fifth International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The Benefits of a Model of Annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><forename type="middle">J</forename><surname>Passonneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bob</forename><surname>Carpenter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse</title>
		<meeting>the 7th Linguistic Annotation Workshop and Interoperability with Discourse<address><addrLine>Sofia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="187" to="195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Measuring Agreement on Set-valued Items (MASI) for Semantic and Pragmatic Annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><forename type="middle">J</forename><surname>Passonneau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth International Conference on Language Resources and Evaluation</title>
		<meeting>the Fifth International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="831" to="836" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Interannotator Agreement for Dependency Annotation of Learner Language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marwa</forename><surname>Ragheb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Dickinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth Workshop on Innovative Use of NLP for Building Educational Applications</title>
		<meeting>the Eighth Workshop on Innovative Use of NLP for Building Educational Applications<address><addrLine>Atlanta</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="169" to="179" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A test of the leaf-ancestor metric for parse accuracy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Sampson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Babarczy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="365" to="380" />
			<date type="published" when="2003-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Reliability of Content Analysis: The Case of Nominal Scale Coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">A</forename><surname>Scott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Public Opinion Quarterly</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="321" to="325" />
			<date type="published" when="1955-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Influence of preprocessing on dependency syntax annotation: speed and agreement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arne</forename><surname>Skjaerholt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse</title>
		<meeting>the 7th Linguistic Annotation Workshop and Interoperability with Discourse<address><addrLine>Sofia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="28" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The Norwegian Dependency Treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Per</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arne</forename><surname>Solberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lilja</forename><surname>Skjaerholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristin</forename><surname>Øvrelid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janne</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bondi Johannesen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International Conference on Language Resources and Evaluation, Reykjavik. European Language Resources Association</title>
		<meeting>the Ninth International Conference on Language Resources and Evaluation, Reykjavik. European Language Resources Association</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Evaluating Dependency Parsing: Robust and Heuristics-Free Cross-Annotation Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reut</forename><surname>Tsarfaty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evelina</forename><surname>Andersson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Edinburgh</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="385" to="396" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Cross-Framework Evaluation for Statistical Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reut</forename><surname>Tsarfaty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evelina</forename><surname>Andersson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 13th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="44" to="54" />
		</imprint>
	</monogr>
	<note>Avignon. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Simple Fast Algorithms for the Editing Distance between Trees and Related Problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaizhong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dennis</forename><surname>Shasha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1245" to="1262" />
			<date type="published" when="1989-12" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
