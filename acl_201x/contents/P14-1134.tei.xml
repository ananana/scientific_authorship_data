<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:57+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Discriminative Graph-Based Parser for the Abstract Meaning Representation</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>June 23-25 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Flanigan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Language Technologies Institute Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15213</postCode>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Thomson</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Language Technologies Institute Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15213</postCode>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Language Technologies Institute Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15213</postCode>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Language Technologies Institute Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15213</postCode>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Language Technologies Institute Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15213</postCode>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Discriminative Graph-Based Parser for the Abstract Meaning Representation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1426" to="1436"/>
							<date type="published">June 23-25 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Meaning Representation (AMR) is a semantic formalism for which a growing set of annotated examples is available. We introduce the first approach to parse sentences into this representation , providing a strong baseline for future improvement. The method is based on a novel algorithm for finding a maximum spanning, connected subgraph, embedded within a Lagrangian relaxation of an optimization problem that imposes linguistically inspired constraints. Our approach is described in the general framework of structured prediction, allowing future incorporation of additional features and constraints, and may extend to other formalisms as well. Our open-source system , JAMR, is available at: http://github.com/jflanigan/jamr</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Semantic parsing is the problem of mapping nat- ural language strings into meaning representa- tions. Abstract Meaning Representation (AMR) ( <ref type="bibr" target="#b2">Banarescu et al., 2013;</ref><ref type="bibr" target="#b12">Dorr et al., 1998</ref>) is a semantic formalism in which the meaning of a sentence is encoded as a rooted, directed, acyclic graph. Nodes represent concepts, and labeled di- rected edges represent the relationships between them-see <ref type="figure" target="#fig_1">Figure 1</ref> for an example AMR graph. The formalism is based on propositional logic and neo-Davidsonian event representations <ref type="bibr" target="#b31">(Parsons, 1990;</ref><ref type="bibr" target="#b10">Davidson, 1967)</ref>. Although it does not encode quantifiers, tense, or modality, the set of semantic phenomena included in AMR were se- lected with natural language applications-in par- ticular, machine translation-in mind.</p><p>In this paper we introduce JAMR, the first pub- lished system for automatic AMR parsing. The system is based on a statistical model whose pa- rameters are trained discriminatively using anno- tated sentences in the AMR Bank corpus ( <ref type="bibr" target="#b2">Banarescu et al., 2013</ref>). We evaluate using the Smatch score , establishing a baseline for future work.</p><p>The core of JAMR is a two-part algorithm that first identifies concepts using a semi-Markov model and then identifies the relations that ob- tain between these by searching for the maximum spanning connected subgraph (MSCG) from an edge-labeled, directed graph representing all pos- sible relations between the identified concepts. To solve the latter problem, we introduce an appar- ently novel O(|V | 2 log |V |) algorithm that is sim- ilar to the maximum spanning tree (MST) algo- rithms that are widely used for dependency pars- ing ( <ref type="bibr" target="#b30">McDonald et al., 2005</ref>). Our MSCG algo- rithm returns the connected subgraph with maxi- mal sum of its edge weights from among all con- nected subgraphs of the input graph. Since AMR imposes additional constraints to ensure seman- tic well-formedness, we use Lagrangian relaxation <ref type="bibr" target="#b17">(Geoffrion, 1974;</ref><ref type="bibr" target="#b16">Fisher, 2004</ref>) to augment the MSCG algorithm, yielding a tractable iterative al- gorithm that finds the optimal solution subject to these constraints. In our experiments, we have found this algorithm to converge 100% of the time for the constraint set we use.</p><p>The approach can be understood as an alterna- tive to parsing approaches using graph transduc- ers such as (synchronous) hyperedge replacement grammars ( <ref type="bibr" target="#b5">Chiang et al., 2013;</ref><ref type="bibr" target="#b20">Jones et al., 2012</ref>; <ref type="bibr" target="#b13">Drewes et al., 1997)</ref>, in much the same way that spanning tree algorithms are an alternative to us- ing shift-reduce and dynamic programming algo- rithms for dependency parsing. <ref type="bibr">1</ref> While a detailed  comparison of these two approaches is beyond the scope of this paper, we emphasize that-as has been observed with dependency parsing-a diver- sity of approaches can shed light on complex prob- lems such as semantic parsing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Notation and Overview</head><p>Our approach to AMR parsing represents an AMR parse as a graph G = V, E; vertices and edges are given labels from sets L V and L E , respec- tively. G is constructed in two stages. The first stage identifies the concepts evoked by words and phrases in an input sentence w = w 1 , . . . , w n , each w i a member of vocabulary W . The second stage connects the concepts by adding L E -labeled edges capturing the relations between concepts, and selects a root in G corresponding to the focus of the sentence w. Concept identification ( §3) involves segmenting w into contiguous spans and assigning to each span a graph fragment corresponding to a concept from a concept set denoted F (or to ∅ for words that evoke no concept). In §5 we describe how F is constructed. In our formulation, spans are contiguous subsequences of w. For example, the words "New York City" can evoke the fragment represented by (c / city :name (n / name :op1 "New" :op2 "York" :op3 "City"))))</p><p>We use a sequence labeling algorithm to identify concepts. The relation identification stage ( §4) is similar to a graph-based dependency parser. Instead of finding the maximum-scoring tree over words, it finds the maximum-scoring connected subgraph that preserves concept fragments from the first stage, links each pair of vertices by at most one edge, and is deterministic 2 with respect to a spe- cial set of edge labels</p><formula xml:id="formula_0">L * E ⊂ L E . The set L * E</formula><p>consists of the labels ARG0-ARG5, and does not include labels such as MOD or MANNER, for ex- ample. Linguistically, the determinism constraint enforces that predicates have at most one semantic argument of each type; this is discussed in more detail in §4.</p><p>To train the parser, spans of words must be la- beled with the concept fragments they evoke. Al- though AMR Bank does not label concepts with the words that evoke them, it is possible to build an automatic aligner ( §5). The alignments are used to construct the concept lexicon and to train the concept identification and relation identifica- tion stages of the parser ( §6). Each stage is a discriminatively-trained linear structured predic- tor with rich features that make use of part-of- speech tagging, named entity tagging, and depen- dency parsing.</p><p>In §7, we evaluate the parser against gold- standard annotated sentences from the AMR Bank corpus ( <ref type="bibr" target="#b2">Banarescu et al., 2013</ref>) under the Smatch score , presenting the first published results on automatic AMR parsing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Concept Identification</head><p>The concept identification stage maps spans of words in the input sentence w to concept graph fragments from F , or to the empty graph fragment ∅. These graph fragments often consist of just one labeled concept node, but in some cases they are larger graphs with multiple nodes and edges. <ref type="bibr">3</ref> Concept identification is illustrated in <ref type="figure">Figure 2</ref> us- ing our running example, "The boy wants to visit New York City."</p><p>Let the concept lexicon be a mapping clex : W * → 2 F that provides candidate graph frag- ments for sequences of words. (The construc- tion of F and clex is discussed below.) Formally, a concept labeling is (i) a segmentation of w into contiguous spans represented by boundaries b, giving spans w b 0 :b 1 , w b 1 :b 2 , . . . w b k−1 :b k , with b 0 = 0 and b k = n, and (ii) an assignment of each phrase</p><formula xml:id="formula_1">w b i−1 :b i to a concept graph fragment c i ∈ clex (w b i−1 :b i ) ∪ ∅.</formula><p>Our approach scores a sequence of spans b and a sequence of concept graph fragments c, both of arbitrary length k, using the following locally de- composed, linearly parameterized function:</p><formula xml:id="formula_2">score(b, c; θ) = k i=1 θ f (w b i−1 :b i , b i−1 , b i , c i ) (1)</formula><p>where f is a feature vector representation of a span and one of its concept graph fragments in context. The features are:</p><p>• Fragment given words: Relative frequency es- timates of the probability of a concept graph fragment given the sequence of words in the span. This is calculated from the concept-word alignments in the training corpus ( §5).</p><p>• Length of the matching span (number of to- kens).</p><p>• NER: 1 if the named entity tagger marked the span as an entity, 0 otherwise.</p><p>• Bias: 1 for any concept graph fragment from F and 0 for ∅.</p><p>Our approach finds the highest-scoring b and c using a dynamic programming algorithm: the zeroth-order case of inference under a semi- Markov model <ref type="bibr" target="#b19">(Janssen and Limnios, 1999)</ref>. Let S(i) denote the score of the best labeling of the first i words of the sentence, w 0:i ; it can be calcu- lated using the recurrence:</p><formula xml:id="formula_3">S(0) = 0 S(i) = max j:0≤j&lt;i, c∈clex (w j:i )∪∅ S(j) + θ f (w j:i , j, i, c)</formula><p>The best score will be S(n), and the best scor- ing concept labeling can be recovered using back- pointers, as in typical implementations of the Viterbi algorithm. Runtime is O(n 2 ).</p><p>clex is implemented as follows. When clex is called with a sequence of words, it looks up the sequence in a table that contains, for every word sequence that was labeled with a concept fragment in the training data, the set of concept fragments it was labeled with. clex also has a set of rules for generating concept fragments for named entities and time expressions. It generates a concept frag- ment for any entity recognized by the named entity tagger, as well as for any word sequence matching a regular expression for a time expression. clex returns the union of all these concept fragments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Relation Identification</head><p>The relation identification stage adds edges among the concept subgraph fragments identified in the first stage ( §3), creating a graph. We frame the task as a constrained combinatorial optimization problem.</p><p>Consider the fully dense labeled multigraph D = V D , E D that includes the union of all la- beled vertices and labeled edges in the concept graph fragments, as well as every possible labeled edge u</p><formula xml:id="formula_4">− → v, for all u, v ∈ V D and every ∈ L E . 4</formula><p>We require a subgraph G = V G , E G that re- spects the following constraints:</p><p>1. Preserving: all graph fragments (including la- bels) from the concept identification phase are subgraphs of G.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.</head><p>Simple: for any two vertices u and v ∈ V G , E G includes at most one edge between u and v. This constraint forbids a small number of perfectly valid graphs, for example for sentences such as "John hurt himself"; however, we see that &lt; 1% of training instances violate the constraint. We found in preliminary experiments that including the constraint increases overall performance. <ref type="bibr">5</ref> 3. Connected: G must be weakly connected (ev- ery vertex reachable from every other vertex, ig- noring the direction of edges). This constraint follows from the formal definition of AMR and is never violated in the training data.</p><p>4. Deterministic: For each node u ∈ V G , and for each label ∈ L * E , there is at most one outgoing edge in E G from u with label . As discussed in §2, this constraint is linguistically motivated. "City" name op1 op2 op3</p><p>Figure 2: A concept labeling for the sentence "The boy wants to visit New York City."</p><p>One constraint we do not include is acyclicity, which follows from the definition of AMR. In practice, graphs with cycles are rarely produced by JAMR. In fact, none of the graphs produced on the test set violate acyclicity. Given the constraints, we seek the maximum- scoring subgraph. We define the score to decom- pose by edges, and with a linear parameterization:</p><formula xml:id="formula_5">score(E G ; ψ) = e∈E G ψ g(e)<label>(2)</label></formula><p>The features are shown in <ref type="table">Table 1</ref>. Our solution to maximizing the score in Eq. 2, subject to the constraints, makes use of (i) an al- gorithm that ignores constraint 4 but respects the others ( §4.1); and (ii) a Lagrangian relaxation that iteratively adjusts the edge scores supplied to (i) so as to enforce constraint 4 ( §4.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Maximum Preserving, Simple, Spanning, Connected Subgraph Algorithm</head><p>The steps for constructing a maximum preserving, simple, spanning, connected (but not necessar- ily deterministic) subgraph are as follows. These steps ensure the resulting graph G satisfies the constraints: the initialization step ensures the pre- serving constraint is satisfied, the pre-processing step ensures the graph is simple, and the core al- gorithm ensures the graph is connected.</p><p>1. (Initialization) Let E (0) be the union of the concept graph fragments' weighted, labeled, di- rected edges. Let V denote its set of vertices.</p><p>Note that V, E (0) is preserving (constraint 4), as is any graph that contains it. It is also sim- ple (constraint 4), assuming each concept graph fragment is simple.</p><p>2. (Pre-processing) We form the edge set E by in- cluding just one edge from E D between each pair of nodes:</p><p>• For any edge e = u − → v in E (0) , include e in E, omitting all other edges between u and v.</p><p>• For any two nodes u and v, include only the highest scoring edge between u and v.</p><p>Note that without the deterministic constraint, we have no constraints that depend on the label of an edge, nor its direction. So it is clear that the edges omitted in this step could not be part of the maximum-scoring solution, as they could be replaced by a higher scoring edge without vi- olating any constraints.</p><p>Note also that because we have kept exactly one edge between every pair of nodes, V, E is sim- ple and connected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">(Core algorithm) Run Algorithm 1, MSCG, on</head><p>V, E and E (0) . This algorithm is a (to our knowledge novel) modification of the minimum spanning tree algorithm of <ref type="bibr" target="#b23">Kruskal (1956)</ref>. Note that the directions of edges do not matter for MSCG.</p><p>Steps 1-2 can be accomplished in one pass through the edges, with runtime O(|V | 2 ). MSCG can be implemented efficiently in O(|V | 2 log |V |) time, similarly to Kruskal's algorithm, using a disjoint-set data structure to keep track of con- nected components. <ref type="bibr">6</ref> The total asymptotic runtime complexity is O(|V | 2 log |V |).</p><p>The details of MSCG are given in Algorithm 1. In a nutshell, MSCG first adds all positive edges to the graph, and then connects the graph by greedily adding the least negative edge that connects two previously unconnected components. Theorem 1. MSCG finds a maximum spanning, connected subgraph of V, E Proof. We closely follow the original proof of cor- rectness of Kruskal's algorithm. We first show by induction that, at every iteration of MSCG, there exists some maximum spanning, connected sub- graph that contains</p><formula xml:id="formula_6">G (i) = V, E (i) : Name Description Label</formula><p>For each ∈ LE, 1 if the edge has that label Self edge 1 if the edge is between two nodes in the same fragment Tail fragment root 1 if the edge's tail is the root of its graph fragment Head fragment root 1 if the edge's head is the root of its graph fragment Path Dependency edge labels and parts of speech on the shortest syntactic path between any two words in the two spans Distance Number of tokens (plus one) between the two concepts' spans (zero if the same) Distance indicators A feature for each distance value, that is 1 if the spans are of that distance Log distance Logarithm of the distance feature plus one. Bias 1 for any edge. <ref type="table">Table 1</ref> input : weighted, connected graph V, E and set of edges E (0) ⊆ E to be preserved output: maximum spanning, connected subgraph of V, E that preserves</p><formula xml:id="formula_7">E (0) let E (1) = E (0) ∪ {e ∈ E | ψ g(e) &gt; 0};</formula><p>create a priority queue Q containing {e ∈ E | ψ g(e) ≤ 0} prioritized by scores; i = 1; while Q nonempty and V,</p><formula xml:id="formula_8">E (i)</formula><p>is not yet spanning and connected do i = i + 1;</p><formula xml:id="formula_9">E (i) = E (i−1) ; e = arg max e ∈Q ψ g(e )</formula><p>; remove e from Q; if e connects two previously unconnected components of V,</p><formula xml:id="formula_10">E (i) then add e to E (i) end end return G = V, E (i) ;</formula><p>Algorithm 1: MSCG algorithm.</p><p>Base case: Consider G (1) , the subgraph contain- ing E (0) and every positive edge. Take any maxi- mum preserving spanning connected subgraph M of V, E. We know that such an M exists be- cause V, E itself is a preserving spanning con- nected subgraph. Adding a positive edge to M would strictly increase M 's score without discon- necting M , which would contradict the fact that M is maximal. Thus M must contain G (1) .</p><p>Induction step: By the inductive hypothesis, there exists some maximum spanning connected</p><formula xml:id="formula_11">subgraph M = V, E M that contains G (i) .</formula><p>Let e be the next edge added to E (i) by MSCG. If e is in E M , then E (i+1) = E (i) ∪ {e} ⊆ E M , and the hypothesis still holds.</p><p>Otherwise, since M is connected and does not contain e, E M ∪ {e} must have a cycle containing e. In addition, that cycle must have some edge e that is not in E (i) . Otherwise, E (i) ∪ {e} would contain a cycle, and e would not connect two un- connected components of G (i) , contradicting the fact that e was chosen by MSCG.</p><p>Since e is in a cycle in E M ∪ {e}, removing it will not disconnect the subgraph, i.e. (E M ∪{e})\ {e } is still connected and spanning. The score of e is greater than or equal to the score of e , oth- erwise MSCG would have chosen e instead of e. Thus, V, (E M ∪ {e}) \ {e }} is a maximum span- ning connected subgraph that contains E (i+1) , and the hypothesis still holds.</p><p>When the algorithm completes, G = V, E (i) is a spanning connected subgraph. The maximum spanning connected subgraph M that contains it cannot have a higher score, because G contains every positive edge. Hence G is maximal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Lagrangian Relaxation</head><p>If the subgraph resulting from MSCG satisfies con- straint 4 (deterministic) then we are done. Oth- erwise we resort to Lagrangian relaxation (LR). Here we describe the technique as it applies to our task, referring the interested reader to <ref type="bibr" target="#b37">Rush and Collins (2012)</ref> for a more general introduction to Lagrangian relaxation in the context of structured prediction problems.</p><p>In our case, we begin by encoding a graph G = V G , E G as a binary vector. For each edge e in the fully dense multigraph D, we associate a bi-nary variable z e = 1{e ∈ E G }, where 1{P } is the indicator function, taking value 1 if the propo- sition P is true, 0 otherwise. The collection of z e form a vector z ∈ {0, 1} |E D | .</p><p>Determinism constraints can be encoded as a set of linear inequalities. For example, the con- straint that vertex u has no more than one outgoing ARG0 can be encoded with the inequality:</p><formula xml:id="formula_12">v∈V 1{u ARG0 −−−→ v ∈ E G } = v∈V z u ARG0 −−−→v ≤ 1.</formula><p>All of the determinism constraints can collectively be encoded as one system of inequalities:</p><formula xml:id="formula_13">Az ≤ b,</formula><p>with each row A i in A and its corresponding entry b i in b together encoding one constraint. For the previous example we have a row A i that has 1s in the columns corresponding to edges outgoing from u with label ARG0 and 0's elsewhere, and a corresponding element b i = 1 in b.</p><p>The score of graph G (encoded as z) can be written as the objective function φ z, where φ e = ψ g(e). To handle the constraint Az ≤ b, we in- troduce multipliers µ ≥ 0 to get the Lagrangian relaxation of the objective function:</p><formula xml:id="formula_14">L µ (z) = max z (φ z + µ (b − Az)), z * µ = arg max z L µ (z).</formula><p>And the dual objective:</p><formula xml:id="formula_15">L(z) = min µ≥0 L µ (z), z * = arg max z L(z).</formula><p>Conveniently, L µ (z) decomposes over edges:</p><formula xml:id="formula_16">L µ (z) = max z (φ z + µ (b − Az)) = max z (φ z − µ Az) = max z ((φ − A µ) z).</formula><p>So for any µ, we can find z * µ by assigning edges the new Lagrangian adjusted weights φ − A µ and reapplying the algorithm described in §4.1. We can find z * by projected subgradient descent, by starting with µ = 0, and taking steps in the direction:</p><formula xml:id="formula_17">− ∂L µ ∂µ (z * µ ) = Az * µ .</formula><p>If any components of µ are negative after taking a step, they are set to zero. L(z) is an upper bound on the unrelaxed ob- jective function φ z, and is equal to it if and only if the constraints Az ≤ b are satisfied. If L(z * ) = φ z * , then z * is also the optimal solu- tion to the constrained solution. Otherwise, there exists a duality gap, and Lagrangian relaxation has failed. In that case we still return the sub- graph encoded by z * , even though it might vio- late one or more constraints. Techniques from in- teger programming such as branch-and-bound or cutting-planes methods could be used to find an optimal solution when LR fails ( <ref type="bibr" target="#b8">Das et al., 2012</ref>), but we do not use these techniques here. In our experiments, with a stepsize of 1 and max number of steps as 500, Lagrangian relaxation succeeds 100% of the time in our data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Focus Identification</head><p>In AMR, one node must be marked as the focus of the sentence. We notice this can be accomplished within the relation identification step: we add a special concept node root to the dense graph D, and add an edge from root to every other node, giving each of these edges the label FOCUS. We require that root have at most one outgoing FO- CUS edge. Our system has two feature types for this edge: the concept it points to, and the shortest dependency path from a word in the span to the root of the dependency tree.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Automatic Alignments</head><p>In order to train the parser, we need alignments be- tween sentences in the training data and their an- notated AMR graphs. More specifically, we need to know which spans of words invoke which con- cept fragments in the graph. To do this, we built an automatic aligner and tested its performance on a small set of alignments we annotated by hand.</p><p>The automatic aligner uses a set of rules to greedily align concepts to spans. The list of rules is given in <ref type="table">Table 2</ref>. The aligner proceeds down the list, first aligning named-entities exactly, then fuzzy matching named-entities, then date-entities, etc. For each rule, an entire pass through the AMR graph is done. The pass considers every concept in the graph and attempts to align a concept fragment rooted at that concept if the rule can apply. Some rules only apply to a particular type of concept fragment, while others can apply to any concept. For example, rule 1 can apply to any NAME con- cept and its OP children. It searches the sentence for a sequence of words that exactly matches its OP children and aligns them to the NAME and OP children fragment.</p><p>Concepts are considered for alignment in the or- der they are listed in the AMR annotation (left to right, top to bottom). Concepts that are not aligned in a particular pass may be aligned in subsequent passes. Concepts are aligned to the first match- ing span, and alignments are mutually exclusive. Once aligned, a concept in a fragment is never re- aligned. <ref type="bibr">7</ref> However, more concepts can be attached to the fragment by rules 8-14.</p><p>We use WordNet to generate candidate lemmas, and we also use a fuzzy match of a concept, de- fined to be a word in the sentence that has the longest string prefix match with that concept's la- bel, if the match length is ≥ 4. If the match length is &lt; 4, then the concept has no fuzzy match. For example the fuzzy match for ACCUSE-01 could be "accusations" if it is the best match in the sen- tence. WordNet lemmas and fuzzy matches are only used if the rule explicitly uses them. All to- kens and concepts are lowercased before matches or fuzzy matches are done.</p><p>On the 200 sentences of training data we aligned by hand, the aligner achieves 92% preci- sion, 89% recall, and 90% F 1 for the alignments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Training</head><p>We now describe how to train the two stages of the parser. The training data for the concept identifi- cation stage consists of (X, Y ) pairs:</p><p>• Input: X, a sentence annotated with named entities (person, organization, location, mis- ciscellaneous) from the Illinois Named Entity Tagger ( <ref type="bibr" target="#b34">Ratinov and Roth, 2009)</ref>, and part-of- speech tags and basic dependencies from the Stanford Parser ( <ref type="bibr" target="#b22">Klein and Manning, 2003;</ref><ref type="bibr" target="#b11">de Marneffe et al., 2006</ref>).</p><p>• Output: Y , the sentence labeled with concept subgraph fragments.</p><p>The training data for the relation identification stage consists of (X, Y ) pairs:</p><p>3. (Date Entity) Applies to date-entity concepts and their day, month, year children (if exist). Matches any permutation of day, month, year, (two digit or four digit years), with or without spaces.</p><p>4. (Minus Polarity Tokens) Applies to -concepts, and matches "no", "not", "non." 7. (U.S.) Applies to name if its op1 child is united and its op2 child is states. Matches a word that matches "us", "u.s." (no space), or "u. s." (with space).</p><p>8. (Entity Type) Applies to concepts with an outgoing name edge whose head is an aligned fragment. Up- dates the fragment to include the unaligned concept.</p><p>Ex: continent in (continent :name (name :op1 "Asia")) aligned to "asia."</p><p>9. (Quantity) Applies to . * -quantity concepts with an outgoing unit edge whose head is aligned. Up- dates the fragment to include the unaligned concept. Ex: distance-quantity in (distance-quantity :unit kilometer) aligned to "kilometres." 12. (Goverment Organization) Applies to concepts with an incoming ARG. * -of edge whose tail is an aligned government-organization concept. Up- dates the fragment to include the unaligned concept. Ex: govern-01 in (government-organization :ARG0-of govern-01) aligned to "government."</p><p>13. (Minus Polarity Prefixes) Applies to -concepts with an incoming polarity edge whose tail is aligned to a word beginning with "un", "in", or "il." Up- dates the fragment to include the unaligned concept.</p><p>Ex: -in (employ-01 :polarity -) aligned to "unemployment."</p><p>14. (Degree) Applies to concepts with an incoming degree edge whose tail is aligned to a word ending is "est." Updates the fragment to include the unaligned concept. Ex: most in (large :degree most) aligned to "largest." <ref type="table">Table 2</ref>: Rules used in the automatic aligner.</p><p>• Input: X, the sentence labeled with graph frag- ments, as well as named enties, POS tags, and basic dependencies as in concept identification.</p><p>• Output: Y , the sentence with a full AMR parse. 8</p><p>Alignments are used to induce the concept label- ing for the sentences, so no annotation beyond the automatic alignments is necessary.</p><p>We train the parameters of the stages separately using AdaGrad <ref type="bibr" target="#b14">(Duchi et al., 2011</ref>) with the per- ceptron loss function <ref type="bibr" target="#b36">(Rosenblatt, 1957;</ref><ref type="bibr" target="#b7">Collins, 2002</ref>). We give equations for concept identifica- tion parameters θ and features f (X, Y ). For a sentence of length k, and spans b labeled with a sequence of concept fragments c, the features are:</p><formula xml:id="formula_18">f (X, Y ) = k i=1 f (w b i−1 :b i , b i−1 , b i , c i )</formula><p>To train with AdaGrad, we process examples in the training data ((X 1 , Y 1 ), . . . , (X N , Y N )) one at a time. At time t, we decode ( §3) to getˆYgetˆ getˆY t and compute the subgradient:</p><formula xml:id="formula_19">s t = f (X t , ˆ Y t ) − f (X t , Y t )</formula><p>We then update the parameters and go to the next example. Each component i of the parameter vec- tor gets updated like so:</p><formula xml:id="formula_20">θ t+1 i = θ t i − η t t =1 s t i s t i</formula><p>η is the learning rate which we set to 1. For relation identification training, we replace θ and f (X, Y ) in the above equations with ψ and</p><formula xml:id="formula_21">g(X, Y ) = e∈E G g(e).</formula><p>We ran AdaGrad for ten iterations for concept identification, and five iterations for relation iden- tification. The number of iterations was chosen by early stopping on the development set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Experiments</head><p>We evaluate our parser on the newswire section of LDC2013E117 (deft-amr-release-r3-proxy.txt). Statistics about this corpus and our train/dev./test splits are given in <ref type="table" target="#tab_1">Table 3</ref>. <ref type="table" target="#tab_2">Train  1995-2006  4.0k  79k  Dev.  2007  2.1k  40k  Test  2008</ref> 2.1k 42k  For the performance of concept identification, we report precision, recall, and F 1 of labeled spans using the induced labels on the training and test data as a gold standard <ref type="table" target="#tab_2">(Table 4)</ref>. Our concept identifier achieves 84% F 1 on the test data. Pre- cision is roughly the same between train and test, but recall is worse on test, implicating unseen con- cepts as a significant source of errors on test data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Split Document Years Sentences Tokens</head><p>We evaluate the performance of the full parser using Smatch v1.0 , which counts the precision, recall and F 1 of the concepts and relations together. Using the full pipeline (concept identification and relation identification stages), our parser achieves 58% F 1 on the test data <ref type="table" target="#tab_4">(Table 5)</ref>. Using gold concepts with the re- lation identification stage yields a much higher Smatch score of 80% F 1 . As a comparison, AMR Bank annotators have a consensus inter-annotator agreement Smatch score of 83% F 1 . The runtime of our system is given in <ref type="figure" target="#fig_5">Figure 3</ref>.</p><p>The large drop in performance of 22% F 1 when moving from gold concepts to system concepts suggests that joint inference and training for the two stages might be helpful.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Related Work</head><p>Our approach to relation identification is inspired by graph-based techniques for non-projective syn- tactic dependency parsing.</p><p>Minimum span- ning tree algorithms-specifically, the optimum branching algorithm of Chu and <ref type="bibr" target="#b6">Liu (1965)</ref> and <ref type="bibr" target="#b15">Edmonds (1967)</ref>-were first used for dependency parsing by <ref type="bibr" target="#b30">McDonald et al. (2005</ref>   The task of concept identification is similar in form to the problem of Chinese word segmenta- tion, for which semi-Markov models have success- fully been used to incorporate features based on entire spans <ref type="bibr" target="#b1">(Andrew, 2006</ref>).</p><p>While all semantic parsers aim to transform nat- ural language text to a formal representation of its meaning, there is wide variation in the mean- ing representations and parsing techniques used. Space does not permit a complete survey, but we note some connections on both fronts.</p><p>Interlinguas <ref type="bibr" target="#b4">(Carbonell et al., 1992</ref>) are an im- portant precursor to AMR. Both formalisms are intended for use in machine translation, but AMR has an admitted bias toward the English language.</p><p>First-order logic representations (and exten- sions using, e.g., the λ-calculus) allow variable quantification, and are therefore more power- ful. In recent research, they are often associ- ated with combinatory categorial grammar <ref type="bibr" target="#b38">(Steedman, 1996)</ref>. There has been much work on sta- tistical models for CCG parsing <ref type="bibr" target="#b40">(Zettlemoyer and Collins, 2005;</ref><ref type="bibr" target="#b41">Zettlemoyer and Collins, 2007;</ref><ref type="bibr" target="#b24">Kwiatkowski et al., 2010</ref>, inter alia), usually using chart-based dynamic programming for inference.</p><p>Natural language interfaces for querying databases have served as another driving applica- tion ( <ref type="bibr" target="#b39">Zelle and Mooney, 1996;</ref><ref type="bibr" target="#b21">Kate et al., 2005;</ref><ref type="bibr" target="#b25">Liang et al., 2011</ref>, inter alia). The formalisms used here are richer in logical expressiveness than AMR, but typically use a smaller set of concept types-only those found in the database.</p><p>In contrast, semantic dependency parsing-in which the vertices in the graph correspond to the words in the sentence-is meant to make semantic parsing feasible for broader textual domains. <ref type="bibr" target="#b0">Alshawi et al. (2011)</ref>, for example, use shift-reduce parsing to map sentences to natural logical form.</p><p>AMR parsing also shares much in common with tasks like semantic role labeling and frame- semantic parsing ( <ref type="bibr" target="#b18">Gildea and Jurafsky, 2002;</ref><ref type="bibr" target="#b33">Punyakanok et al., 2008;</ref><ref type="bibr">Das et al., 2014, inter alia)</ref>. In these tasks, predicates are often disambiguated to a canonical word sense, and roles are filled by spans (usually syntactic constituents). They consider each predicate separately, and produce a disconnected set of shallow predicate-argument structures. AMR, on the other hand, canonical- izes both predicates and arguments to a common concept label space. JAMR reasons about all con- cepts jointly to produce a unified representation of the meaning of an entire sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusion</head><p>We have presented the first published system for automatic AMR parsing, and shown that it pro- vides a strong baseline based on the Smatch eval- uation metric. We also present an algorithm for finding the maximum, spanning, connected sub- graph and show how to incorporate extra con- straints with Lagrangian relaxation. Our feature- based learning setup allows the system to be easily extended by incorporating new feature sources.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Two equivalent ways of representing the AMR parse for the sentence, "The boy wants to visit New York City."</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>: Features used in relation identification. In addition to the features above, the following conjunctions are used (Tail and Head concepts are elements of LV ): Tail concept ∧ Label, Head concept ∧ Label, Path ∧ Label, Path ∧ Head concept, Path ∧ Tail concept, Path ∧ Head concept ∧ Label, Path ∧ Tail concept ∧ Label, Path ∧ Head word, Path ∧ Tail word, Path ∧ Head word ∧ Label, Path ∧ Tail word ∧ Label, Distance ∧ Label, Distance ∧ Path, and Distance ∧ Path ∧ Label. To conjoin the distance feature with anything else, we multiply by the distance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>5 .</head><label>5</label><figDesc>(Single Concept) Applies to any concept. Strips off trailing '-[0-9]+' from the concept (for example run-01 → run), and matches any exact matching word or WordNet lemma. 6. (Fuzzy Single Concept) Applies to any concept. Strips off trailing '-[0-9]+', and matches the fuzzy match of the concept.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>10 .</head><label>10</label><figDesc>(Person-Of, Thing-Of) Applies to person and thing concepts with an outgoing . * -of edge whose head is aligned. Updates the fragment to include the unaligned concept. Ex: person in (person :ARG0-of strike-02) aligned to "strikers." 11. (Person) Applies to person concepts with a sin- gle outgoing edge whose head is aligned. Updates the fragment to include the unaligned concept. Ex: person in (person :poss (country :name (name :op1 "Korea")))</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Runtime of JAMR (all stages).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 3 : Train/dev./test split.</head><label>3</label><figDesc></figDesc><table>Train 
Test 
P 
R F 1 
P 
R F 1 
.92 .90 .91 .90 .79 .84 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Concept identification performance. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>). Later ex-</head><label></label><figDesc></figDesc><table>Train 
Test 
concepts 
P 
R F 1 
P 
R F 1 
gold 
.85 .95 .90 .76 .84 .80 
automatic .69 .78 .73 .52 .66 .58 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Parser performance. 

1433 

</table></figure>

			<note place="foot" n="1"> To date, a graph transducer-based semantic parser has not been published, although the Bolinas toolkit (http://www.isi.edu/publications/ licensed-sw/bolinas/) contains much of the necessary infrastructure.</note>

			<note place="foot" n="2"> By this we mean that, at each node, there is at most one outgoing edge with that label type. 3 About 20% of invoked concept fragments are multiconcept fragments.</note>

			<note place="foot" n="4"> To handle numbered OP labels, we pre-process the training data to convert OPN to OP, and post-process the output by numbering the OP labels sequentially. 5 In future work it might be treated as a soft constraint, or the constraint might be refined to specific cases.</note>

			<note place="foot" n="6"> For dense graphs, Prim&apos;s algorithm (Prim, 1957) is asymptotically faster (O(|V | 2 )). We conjecture that using Prim&apos;s algorithm instead of Kruskall&apos;s to connect the graph could improve the runtime of MSCG.</note>

			<note place="foot" n="7"> As an example, if &quot;North Korea&quot; shows up twice in the AMR graph and twice in the input sentence, then the first &quot;North Korea&quot; concept fragment listed in the AMR gets aligned to the first &quot;North Korea&quot; mention in the sentence, and the second fragment to the second mention (because the first span is already aligned when the second &quot;North Korea&quot; concept fragment is considered, so it is aligned to the second matching span). 1. (Named Entity) Applies to name concepts and their opn children. Matches a span that exactly matches its opn children in numerical order. 2. (Fuzzy Named Entity) Applies to name concepts and their opn children. Matches a span that matches the fuzzy match of each child in numerical order.</note>

			<note place="foot" n="8"> Because the alignments are automatic, some concepts may not be aligned, so we cannot compute their features. We remove the unaligned concepts and their edges from the full AMR graph for training. Thus some graphs used for training may in fact be disconnected.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors gratefully acknowledge helpful cor-respondence from Kevin Knight, Ulf Hermjakob, and André Martins, and helpful feedback from Nathan Schneider, Brendan O'Connor, Waleed Ammar, and the anonymous reviewers. This work was sponsored by the U. S. Army Research Laboratory and the U. S. Army Research Office under contract/grant number W911NF-10-1-0533 and DARPA grant FA8750-12-2-0342 funded un-der the DEFT program.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deterministic statistical mapping of sentences to underspecified semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiyan</forename><surname>Alshawi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pi-Chuan</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Ringgaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICWS</title>
		<meeting>of ICWS</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A hybrid markov/semi-markov conditional random field for sequence segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Galen</forename><surname>Andrew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Abstract meaning representation for sembanking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Banarescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Bonial</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Madalina</forename><surname>Georgescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kira</forename><surname>Griffitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulf</forename><surname>Hermjakob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Schneider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Linguistic Annotation Workshop and Interoperability with Discourse</title>
		<meeting>of the Linguistic Annotation Workshop and Interoperability with Discourse</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Smatch: an evaluation metric for semantic feature structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The KANT perspective: A critique of pure transfer (and pure interlingua, pure transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><forename type="middle">G</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teruko</forename><surname>Mitamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">H</forename><surname>Nyberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Fourth International Conference on Theoretical and Methodological Issues in Machine Translation: Empiricist vs</title>
		<meeting>of the Fourth International Conference on Theoretical and Methodological Issues in Machine Translation: Empiricist vs</meeting>
		<imprint>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
	<note>Rationalist Methods in MT</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Parsing graphs with hyperedge replacement grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><forename type="middle">Moritz</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bevan</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">On the shortest arborescence of a directed graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">J</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science Sinica</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1396" to="1400" />
			<date type="published" when="1965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Discriminative training methods for hidden Markov models: Theory and experiments with perceptron algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An exact dual decomposition algorithm for shallow semantic parsing with constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">T</forename><surname>André</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Joint Conference on Lexical and Computational Semantics</title>
		<meeting>of the Joint Conference on Lexical and Computational Semantics</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Frame-semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Desai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">T</forename><surname>André</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="9" to="56" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The logical form of action sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><surname>Davidson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Logic of Decision and Action</title>
		<editor>Nicholas Rescher</editor>
		<imprint>
			<publisher>Pittsburgh Press</publisher>
			<date type="published" when="1967" />
			<biblScope unit="page" from="81" to="120" />
		</imprint>
		<respStmt>
			<orgName>Univ</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Generating typed dependency parses from phrase structure parses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Catherine</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Maccartney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of LREC</title>
		<meeting>of LREC</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A thematic hierarchy for efficient generation from lexical-conceptual structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Dorr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nizar</forename><surname>Habash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Traum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Translation and the Information Soup: Proc. of AMTA</title>
		<editor>David Farwell, Laurie Gerber, and Eduard Hovy</editor>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Hyperedge replacement graph grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Drewes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Jörg</forename><surname>Kreowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Annegret</forename><surname>Habel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Graph Grammars</title>
		<imprint>
			<publisher>World Scientific</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="95" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Adaptive subgradient methods for online learning and stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2121" to="2159" />
			<date type="published" when="2011-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Optimum branchings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Edmonds</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1967" />
		</imprint>
		<respStmt>
			<orgName>National Bureau of Standards</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The Lagrangian relaxation method for solving integer programming problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marshall</forename><forename type="middle">L</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Science</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1861" to="1871" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Lagrangean relaxation for integer programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Arthur M Geoffrion</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1974" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Automatic labeling of semantic roles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="245" to="288" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">SemiMarkov Models and Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacques</forename><surname>Janssen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolaos</forename><surname>Limnios</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<publisher>October</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Semantics-based machine translation with hyperedge replacement grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bevan</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><forename type="middle">Moritz</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of COLING</title>
		<meeting>of COLING</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning to transform natural to formal languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rohit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuk</forename><forename type="middle">Wah</forename><surname>Kate</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of AAAI</title>
		<meeting>of AAAI</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Accurate unlexicalized parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">On the shortest spanning subtree of a graph and the traveling salesman problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">B</forename><surname>Kruskal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the</title>
		<meeting>of the</meeting>
		<imprint>
			<publisher>American Mathematical Society</publisher>
			<date type="published" when="1956" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">48</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Inducing probabilistic CCG grammars from logical form with higherorder unification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Goldwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning dependency-based compositional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Concise integer linear programming formulations for dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">T</forename><surname>André</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Dual decomposition with many overlapping components</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">T</forename><surname>André</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro</forename><forename type="middle">M Q</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Aguiar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">T</forename><surname>Mário</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Figueiredo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Turning on the turbo: Fast third-order non-projective Turbo parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">T</forename><surname>André</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Online learning of approximate dependency parsing algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EACL</title>
		<meeting>of EACL</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="81" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Non-projective dependency parsing using spanning tree algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiril</forename><surname>Ribarov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Events in the Semantics of English: A study in subatomic semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terence</forename><surname>Parsons</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Shortest connection networks and some generalizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">C</forename><surname>Prim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bell System Technology Journal</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="1389" to="1401" />
			<date type="published" when="1957" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The importance of syntactic parsing and inference in semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasin</forename><surname>Punyakanok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="257" to="287" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Design challenges and misconceptions in named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CoNLL</title>
		<meeting>of CoNLL</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Incremental integer linear programming for non-projective dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Clarke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">The perceptron-a perceiving and recognizing automaton</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Rosenblatt</surname></persName>
		</author>
		<idno>85- 460-1</idno>
		<imprint>
			<date type="published" when="1957" />
		</imprint>
		<respStmt>
			<orgName>Cornell Aeronautical Laboratory</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A tutorial on dual decomposition and Lagrangian relaxation for inference in natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="305" to="362" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Surface structure and interpretation. Linguistic inquiry monographs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Learning to parse database queries using inductive logic programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Zelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of AAAI</title>
		<meeting>of AAAI</meeting>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of UAI</title>
		<meeting>of UAI</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Online learning of relaxed CCG grammars for parsing to logical form</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP-CoNLL</title>
		<meeting>of EMNLP-CoNLL</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
