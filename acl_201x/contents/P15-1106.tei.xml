<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:41+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Driving ROVER with Segment-based ASR Quality Estimation</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shahab</forename><surname>Jalalvand</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Trento</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Negri</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniele</forename><surname>Falavigna</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Turchi</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">)</forename><surname>Fbk -Fondazione</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bruno</forename><surname>Kessler</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<address>
									<addrLine>Via Sommarive 18</addrLine>
									<postCode>38123</postCode>
									<settlement>Trento</settlement>
									<country>Italy (</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Driving ROVER with Segment-based ASR Quality Estimation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1095" to="1105"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>ROVER is a widely used method to combine the output of multiple automatic speech recognition (ASR) systems. Though effective, the basic approach and its variants suffer from potential drawbacks: i) their results depend on the order in which the hypotheses are used to feed the combination process, ii) when applied to combine long hypotheses, they disregard possible differences in transcription quality at local level, iii) they often rely on word confidence information. We address these issues by proposing a segment-based ROVER in which hypothesis ranking is obtained from a confidence-independent ASR quality estimation method. Our results on English data from the IWSLT2012 and IWSLT2013 evaluation campaigns significantly outperform standard ROVER and approximate two strong oracles.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In automatic speech recognition (ASR), the com- bination of transcription hypotheses produced by multiple systems usually leads to significant word error rate (WER) reductions compared to the out- put of each individual system. Systems' diversity and complementarity have been exploited in dif- ferent ways to synthetically obtain more accurate transcriptions. Recognizer output voting error re- duction -ROVER <ref type="bibr" target="#b14">(Fiscus, 1997)</ref>, the most widely used method, performs hypothesis fusion in two steps. First, the 1-best transcriptions from multi- ple systems are aligned by means of dynamic pro- gramming to build a single, minimal word tran- sition network. Then, the resulting network is searched to select the best scoring word at each node. The final hypothesis is constructed via a ma- jority voting mechanism and, if available, by using word confidence measures.</p><p>This general strategy has been improved in sev- eral ways but, despite their proven effectiveness, ROVER and its variants have three potential draw- backs. The first one is intrinsic to their implemen- tation: the fusion process starts from one of the input hypotheses, which is used as "skeleton" for the greedy alignment of the others. The order in which the hypotheses are used to feed the process can hence determine significant variations in the WER of the resulting combination. This calls for automatic methods for ranking the hypotheses to initialise and carry on the fusion process.</p><p>The second drawback is inherent to the way ROVER is usually run: the fusion process is typi- cally fed with transcriptions of entire audio record- ings (lasting up to hours). With this level of granu- larity, the skeleton used as basis for the alignment may consist of long transcriptions whose quality can considerably vary at local level. For instance, the worst transcription of an entire audio recording (globally) could be the best one for some passages (locally). This calls for solutions capable to op- erate at higher granularity levels (e.g. segments lasting up to few seconds) to better exploit the local diversity of the combined transcriptions.</p><p>The third drawback relates to the applicability of ROVER-like fusion methods: their common trait is the reliance on information about the in- ner workings of the combined systems. Indeed, the standard voting scheme with confidence scores is usually much more reliable than the simpler frequency-based voting. The access to confidence scores, however, is a too rigid constraint in ap- plication scenarios where the hypotheses to be combined come from unknown ("black-box") sys- tems. <ref type="bibr">1</ref> This calls for confidence-independent fu- sion methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>L3</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>L4</head><p>L5 L6 L7 L8 SysO 12.2 11.7 11.8 11.9 12.1 12.1 InSysO 19.8 16.6 15.1 13.9 13.4 13.3 SegO 10.5 11.0 11.4 11.6 11.7 11.7 InSegO 22.9 19.6 17.4 15.8 14.4 13.0 <ref type="table">Table 1</ref>: Motivation: the influence of hypothesis order and granularity on standard ROVER results.</p><p>The impact of the first two issues is evident from the figures provided in <ref type="table">Table 1</ref>. The results refer to the WER achieved by different "oracles" obtained from the output of eight ASR systems that partici- pated in the IWSLT2013 campaign ( <ref type="bibr" target="#b9">Cettolo et al., 2013</ref>). 2 Such oracles combine:</p><p>• Different numbers of transcriptions (from three -L3 to eight -L8);</p><p>• At different granularity levels (whole utter- ance -SysO and segment -SegO);</p><p>• In different orders (best to worst -SysO, SegO and inverse -InSysO, InSegO).</p><p>As shown in the table, the gap between utterance-based (SysO) and segment-based (SegO) is evident at all levels: WER differences vary from 0.3 (11.9 vs. 11.6 at L6) to 1.7 points (12.2 vs. 10.5 at L3). Another gap is evident between best-to-worst and inverse rankings, with WER differences up to 7.6 points at whole utterance level (SysO vs. InSysO at L3) and 12.4 points at segment level (SegO vs. InSegO at L3). Another interesting observation is that top results (i.e. lower WER) are obtained when combining a subset of the outputs (respectively four at utterance level and three at segment level). Referring to this analysis, the goal of computing ROVER based on hypothesis ranking at higher granularity levels is well motivated.</p><p>A crucial need to achieve this goal is the avail- ability of a confidence-independent method to pre- dict the quality of ASR transcriptions at segment level. This "quality estimation" (QE) task has been recently addressed in <ref type="bibr" target="#b6">C. de Souza et al., 2015</ref>) as a supervised regres- sion problem in which transcriptions' WER is pre- dicted without having access to reference tran- scripts. <ref type="bibr">3</ref> Different feature sets have been evalu- ated, showing that even with those extracted only from the signal and the transcription (i.e. disre- garding information about the decoding process) the prediction error is sufficiently low to open to real applications. However, though promising, ex- perimental results stem from an intrinsic evalua- tion in which QE is only addressed in isolation.</p><p>By applying it to inform ROVER, we pro- pose for the first time an application-oriented ex- trinsic evaluation of ASR QE (our first contri- bution). To this aim, we extend previous ASR QE methods with new features (second contribu- tion), and report significant improvements over standard ROVER on a shared dataset (third con- tribution). For the sake of brevity, our compar- ison is performed only against standard ROVER and in "black-box" conditions. However it's worth remarking that our approach can be straightfor- wardly applied to any ROVER-like variant and, if available, by exploiting confidence features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>This paper gathers three main research strands to- gether: ASR system combination, ASR quality es- timation and machine-learned ranking. <ref type="bibr" target="#b14">Fiscus (1997)</ref> proposed ROVER as an approach to produce a composite ASR output. The basic ap- proach has been extended in several ways. N-Best ROVER ( <ref type="bibr">Stolcke et al., 2000</ref>) improves the orig- inal method by combining multiple alternatives from each combined system. <ref type="bibr" target="#b30">Schwenk and Gauvain (2000)</ref> exploit a secondary language model to rescore the final n-best hypotheses generated by ROVER. iROVER ( <ref type="bibr" target="#b19">Hillard et al., 2007</ref>) exploits a classifier to choose the system that is most likely to be correct at each word location. cROVER (Abida et al., 2011) integrates a semantic pre-filtering step in which the word transition network is scanned to flag and eliminate erroneous words to facilitate the voting. Other approaches to ASR system combi- nation make use of word lattices or confusion net- works <ref type="bibr" target="#b22">(Mangu, 2000;</ref><ref type="bibr" target="#b21">Li et al., 2002;</ref><ref type="bibr" target="#b12">Evermann and Woodland, 2000;</ref><ref type="bibr" target="#b20">Hoffmeister et al., 2006;</ref><ref type="bibr">Bougares et al., 2013, inter alia)</ref>. Note that all these combination methods require to have access to the inner structure of the ASR decoder, while ASR systems, especially the commercial ones, of- ten do not provide this information.</p><p>ASR quality estimation allows us to overcome this problem and obtain confidence-independent estimates of ASR output quality. Based on the positive intrinsic evaluation results reported in <ref type="bibr" target="#b6">C. de Souza et al., 2015</ref>), here we extend the approach with new features and per- form an extrinsic evaluation in a real application scenario. Our new features are inspired by re- search on ASR error detection at word level <ref type="bibr" target="#b17">(Goldwater et al., 2010;</ref><ref type="bibr" target="#b29">Pellegrini and Trancoso, 2010)</ref>.</p><p>Machine-learned ranking (MLR) or learning to rank <ref type="bibr" target="#b18">(Hang, 2011</ref>) is widely used in information retrieval to order the answers to a user's query <ref type="bibr" target="#b7">(Cao et al., 2007;</ref><ref type="bibr" target="#b23">McFee and Lanckriet, 2010;</ref><ref type="bibr" target="#b24">McSherry and Najork, 2008)</ref>. We use it to order the transcription hypotheses produced by multiple ASR systems and feed ROVER with the resulting ranked lists.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>Given an utterance and a set of M transcription hypotheses produced by M different (possibly un- known) ASR systems, our goal is to:</p><p>1. Split the utterance into segments (ideally at sentence level);</p><p>2. For each segment, automatically estimate the quality (e.g. in terms of WER) of the corre- sponding M (segment-level) hypotheses;</p><p>3. Use the estimates to rank the hypotheses and feed ROVER based on the ranking;</p><p>4. Reconstruct the entire utterance transcrip- tion by concatenating the combined segment- level transcriptions produced by ROVER;</p><p>5. Measure the overall WER differences against standard ROVER and other oracles.</p><p>Step 1 is performed by a start-end point detection module based on signal energy, which is followed by a segment classification module based on Gaus- sian Mixture Models similar to <ref type="bibr" target="#b8">(Cettolo and Federico, 2000</ref>). Although the comparison with al- ternative splitting methods might lead to different results, this is not the main focus of the paper and is left as future work. Steps 2-4, instead, repre- sent the core of our contribution and are described in the following sections.</p><p>4 Segment-based QE-informed ROVER ROVER uses iterative dynamic programming to build a word transition network (WTN) from mul- tiple ASR output hypotheses. The resulting WTN can be seen as a confusion network with an equal number of word arc hypotheses (one for each ASR system entering the combination) in each corre- spondence slot. The best word sequence is deter- mined from the WTN via majority voting among the words in each slot. Most of the extensions of ROVER, such as iROVER ( <ref type="bibr" target="#b19">Hillard et al., 2007</ref>), cROVER (Abida et al., 2011) and the one de- scribed in ( <ref type="bibr" target="#b36">Zhang and Rudnicky, 2006</ref>), aim to learn a scoring function that allows improving the reordering of words inside each slot. In particu- lar, iROVER reorders the words in each slot by means of a classifier trained with features that characterize the individual ASR systems. This ap- proach, however, needs first to properly normal- ize the word lattices generated by each system, in order to exhibit the same vocabulary and similar densities, and to generate a unified segmentation for joining the lattices. In a similar way, motivated by the analysis shown in <ref type="table">Table 1</ref>, our method applies reordering of the ASR hypotheses at segment level. However, differently from iROVER, it does not require to access the inner components of the decoders (e.g. word lattices or word confidences), nor to apply pre-processing steps that can distort the outputs of individual ASR components. </p><formula xml:id="formula_0">T 2 C T n C SRV(T 1 A , T 1 B , T 1 C ) SRV(T 2 A , T 2 C , T 2 B ) SRV(T n B , T n A , T n C ) RV(T 1..n A , T 1..n B , T 1..n C )</formula><p>Figure 1: Segment-based ROVER <ref type="figure">Figure 1</ref> illustrates the difference between stan- dard ROVER (RV, shown at the rightmost verti- cal) which works at the utterance level (lasting up to few hours) and the segment-based ROVER (SRV, shown at the bottom horizontal) that works at the segment level (lasting up to few seconds). RV keeps the order of the systems static along the whole utterance (A B C, i.e. system A has generated a better transcription than sys- tem B which, in turn is better than system C) for all the segments RV (T A 1..n , T B 1..n , T C 1..n ). SRV, in- stead, dynamically changes the system order from one segment to the other. For example, the system order for the first segment is A B C, while for the next segment it is A C B. Our hy- pothesis is that, with a proper segment-based rank- ing, SRV will result in lower WER scores than RV.</p><p>Note that, as depicted in <ref type="figure">Figure 1</ref>, segment- based ROVER requires that all the ASR systems share a common segmentation. This is easy to ob- tain by force-aligning the transcriptions of each system with a given segmentation (e.g. one ran- domly chosen among those employed by each ASR system).</p><p>In this paper we approach segment-level ASR QE as a supervised learning task, by comparing two alternative strategies: ranking by regression (Section 4.1) and machine-learned ranking (Sec- tion 4.2). Both methods rely on the features used in ( ), extended with a new set of word-level features described in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Ranking by regression (RR)</head><p>The first ranking strategy is based on training a re- gressor on a set of (signal, transcription, WER) triples, and use it to predict the WER score for new, unseen (signal, transcription) test instances. Then, based on the predicted WERs, a ranked list is produced for each segment to feed ROVER.</p><p>To train the regressor, we are given N seg-</p><formula xml:id="formula_1">ments (S i , 1 ≤ i ≤ N ), their automatic transcrip- tions ({T 1 i . . . T M i } i=N i=1</formula><p>) produced by M ASR sys- tems, and manual references from which the true</p><formula xml:id="formula_2">WERs ({T W 1 i . . . T W M i } i=N i=1</formula><p>) can be computed for each segment i. The whole set of train- ing data is hence represented by instances:</p><formula xml:id="formula_3">I = {(S i , T j i , T W j i ), 1 ≤ j ≤ M, 1 ≤ i ≤ N }.</formula><p>Training is performed with two alternative strate- gies, which differ in the amount of training data used. The first one, RR1, employs the whole train- ing set I. The second one, RR2, uses only one transcription for each segment, randomly chosen from the M available. In this case, the training set becomes:</p><formula xml:id="formula_4">I = {(S i , T j i , T W j i ), 1 ≤ i ≤ N, j = rnd(M )} where rnd(M )</formula><p>is a random number be- tween 1 to M . In practice, RR2 learns from a smaller but more diverse training set compared to RR1. On the one side, in fact, RR1 deals with a larger number of training instances (M times more), but the feature vectors will share the same values for the features extracted from the signal of each utterance. On the other side, RR2 reduces the size of the training set I down to 1 M of I, but only one feature vector is extracted for each utterance. The unpredictable effect of such differences on QE results motivates experiments with both methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Machine-learned ranking (MLR)</head><p>The second strategy relies on directly training a ranking model from a set of instances </p><formula xml:id="formula_5">I = {(S i , T j i , T R j i ), 1 ≤ i ≤ N, 1 ≤ j ≤ M },</formula><formula xml:id="formula_6">j i T R k i , if T W j i ≤ T W k i .</formula><p>It is worth to note that MLR, differently from the two regression methods described above, per- forms a pairwise comparison between the seg- ment candidates. That is, for each pair of seg- ment transcriptions, the algorithm processes their corresponding feature vectors against each other and decides to place one transcription ahead of the other, as long as returning a score for this decision. Based on this score, the algorithm is then able to rank more than two candidates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Features</head><p>We use two sets of features. One consists of the basic features described in ( ); the other includes several word-based features specif- ically introduced for our ranking task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Basic features</head><p>Basic features can be further divided in three groups:</p><p>Signal features (16 in total) aim to capture the difficulty to transcribe a given input by looking at the signal as a whole. They are obtained by analyzing the audio waveform with a window of 20ms at a frame rate of 10ms. For each analysed window, 12 Mel Frequency Cepstral Coefficients (MFCCs) are evaluated (MFCC of order 0 is dis- carded) plus log energy. Then, to form the signal feature vector for each given segment, we com- pute the mean/min/max values of raw energy, as well as the mean MFCCs values and total segment duration.</p><p>Hybrid features (26) provide a more fine- grained way to capture the difficulty of transcrib- ing the signal. They are computed based on the forced alignment between the M given auto- matic transcriptions of each segment and the cor- responding acoustic observations obtained from raw features. For each transcription hypothesis hybrid features are: signal to noise ratio (SNR), mean/min/max noise energy, mean/min/max word energy, (max word</p><note type="other">-min noise) energy, number of silences (#sil), #sil per second, number of words (#wrd) per second, #sil #wrd , total duration of words (D wrd ), total duration of silences (D sil ), mean du- ration of words, mean duration of silences, D sil D wrd , D wrd − D sil , standard deviation (std) of word du- ration, std of silence duration, mean/std/min/max of pitch 4 , number of hesitations, frequency of hes- itations.</note><p>Textual features (10) aim to capture the plausi- bility (i.e. the fluency) of a transcription. For each hypothesis textual features are: number of words, LM log probability, LM log probability of part of speech (POS), log perplexity, LM log perplexity of POS, percentage (%) of numbers, % of tokens which do not contain only "[a-z]", % of content words, % of nouns, % of verbs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Word-based features</head><p>To compensate the absence of ASR confidence in- formation, we also designed a set of "word-based" features inspired by previous approaches to ASR error detection ( <ref type="bibr" target="#b10">Chieu and Ng, 2002;</ref><ref type="bibr" target="#b29">Pellegrini and Trancoso, 2010;</ref><ref type="bibr" target="#b17">Goldwater et al., 2010;</ref><ref type="bibr" target="#b34">Tam et al., 2014</ref>). They aim to capture words' pronun- ciation difficulty, which is determined by the num- ber of lexical neighbors (similar pronunciations) and the types of phonemes that form the words. From the ASR error detection field we also borrow additional language model features based on re- current neural network language model (RNNLM) probability ( <ref type="bibr" target="#b26">Mikolov et al., 2010</ref>).</p><p>Word-based features (22) are: POS tag and score of the previous/current/next words (6), RNNLM probabilities (2) given by models trained on in-domain and out-of-domain data, in- domain/out-of-domain 4-gram LM probability (2), number of phoneme classes (including fricatives, liquids, nasals, stops and vowels) (5), number of homophones (1), number of lexical neighbors (1) and binary features answering the three questions: "is stop word?" (1), "is before/after repetition?" <ref type="bibr">4</ref> Pitch features have been computed with the Praat soft- ware tool <ref type="bibr" target="#b2">(Boersma and Weenink, 2005</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset duration sent token voc talks tst2012 1h45m</head><p>1,124 19.2k 2.8k 11 tst2013 4h50m 2,246 41.6k 5.6k 28  (2), "is before/after silence?" (2). Since the ASR hypotheses of a given segment might contain dif- ferent numbers of words, we average the values of the word-based features for each hypothesis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experimental setup</head><p>In this section we illustrate the audio data used in our experiments, the methods used to inform and run ROVER, the evaluation metric and the signifi- cance testing method applied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Data</head><p>We experiment with two sets of speech recordings collected from English TED talks and used for the <ref type="bibr">2012</ref>   <ref type="table" target="#tab_2">Table 3</ref>. For detailed system descrip- tions we refer the reader to the IWSLT2012 5 and IWSLT2013 6 proceedings.</p><p>In the experiments, we used tst2012 for train- ing with 4-fold cross-validation, and tst2013 for testing purposes. Note that cross-validation was applied ensuring that a given speaker does not ap-pear simultaneously both in the training and vali- dation sets. The same condition holds for the test set: speakers in tst2012 do not occur in tst2013. These conditions, and the use of two different sets of talks (acquired in different IWSLT editions and transcribed by different sets of ASR systems), make our task particularly difficult and guarantee the congruence with real-life scenarios in which training and test data are totally independent.</p><p>As previously mentioned, a common segmenta- tion needs to be shared among the various ASR components. To do this we decided to use the one provided by our internal ASR system, and to force-align to it all the other ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Terms of comparison</head><p>We compare our segment-based QE-informed ROVER against three methods that differ in the granularity of the combined hypotheses and in the way they are ranked:</p><p>Random ROVER. It is obtained by averaging the results of 100 runs of standard, system-level ROVER (i.e. the WTN is obtained by com- bining transcriptions of the whole utterance) in which the systems to be combined are ranked ran- domly. Note that this is the only possible way to run ROVER in absence of information about the reliability of the combined systems. Random ROVER is the standard fusion method adopted in IWSLT2013 to produce the final transcriptions that are sent to the machine translation phase.</p><p>System-based Oracle (SysO). It is obtained by computing the standard, system-level ROVER based on the true system ranking (i.e. the actual ranking of the IWSLT2013 participants). We con- sider it as an oracle since the true ranking repre- sents prior knowledge about systems' reliability which is not available in real testing conditions. Segment-based Oracle (SegO). It is obtained by computing ROVER at segment-level, using the true system ranking for each segment. Also this oracle relies on information about systems' rank- ing (at a higher granularity level), which is not available in real testing conditions. As shown in <ref type="table">Table 1</ref>, this is the strongest term of comparison and actually represents out upper bound.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Evaluation metric and significance test</head><p>As usually done in ASR evaluation, performance results are measured in terms of WER. <ref type="bibr">7</ref> Our segment-based, QE-informed ROVER is hence compared against the other methods based on the WER computed on the test set (tst2013).</p><p>To measure if two methods produce statistically different results, we run the matched-pairs signif- icance test <ref type="bibr" target="#b16">(Gillick and Cox, 1989)</ref>. It is based on averaging the differences between the number of errors (insertions, deletions and substitutions) produced by the two approaches for the individual segments. If the average falls in the [-0.05,+0.05] interval, then the global WER difference between the two methods is not statistically significant.</p><p>In terms of results' significance tests, our suc- cess criteria are: i) a statistically significant im- provement over random ROVER, and ii) non- significant differences with respect to the two strong oracles. For the sake of comparison, we define three symbols for the evaluation results re- ported in <ref type="table" target="#tab_5">Table 4:</ref> 1. " †" indicates that the corresponding WER score is not significantly different from ran- dom ROVER (a negative result);</p><p>2. "•" indicates that the WER score is not sig- nificantly different from the system-based ROVER oracle (a positive result);</p><p>3. "" indicates that the WER score is not sig- nificantly different from the segment-based ROVER oracle (the best result).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Ranking Models</head><p>Ranking by regression (see Section 4.1) is per- formed using the implementation of the extremely randomized trees algorithm ( <ref type="bibr" target="#b15">Geurts et al., 2006</ref>) provided by the Scikit-learn package <ref type="bibr" target="#b28">(Pedregosa et al., 2011</ref>). Extra-trees are a tree-based ensemble method for supervised classification and regres- sion, which we successfully used in the past both for MT (de <ref type="bibr" target="#b11">Souza et al., 2013</ref>) and ASR quality estimation (   <ref type="table" target="#tab_5">Table 4</ref>: WER[%] (↓) of random, oracle and QE-informed ROVERs. The symbols assigned to some scores indicate their statistical significance (p ≤ 0.05 computed with the matched-pairs test). In particu- lar: " †" = the result is not statistically different from random ROVER; "•" = the result is not statistically different from SysO; "" the result is not statistically different from SegO.</p><p>ensemble method <ref type="bibr" target="#b4">(Breiman, 2001)</ref> provided in the RankLib library. <ref type="bibr">8</ref> As mentioned in Section 6.1, all the ranking models are trained in 4-fold cross validation. RR1 uses all the instances in tst2012 (i.e. 1,124 seg- ments transcribed by 6 ASR systems, which re- sults in a total of 6,744 training instances). RR2 uses only one instance per segment, which is ran- domly selected among the 6 automatic transcrip- tions available in tst2012 (resulting in a total of 1,124 training instances). Similar to RR1, MLR uses all the instances in tst2012 (6,744 in total). The learning parameters of each model (number of bags, number of trees per bag, number of leaves per tree and minimum number of instances per leaf) are tuned by maximising Mean Average Pre- cision as the objective function <ref type="bibr" target="#b18">(Hang, 2011)</ref>.</p><p>All the models are trained using the ba- sic features (+Basic), the word-based ones (+WordBased) and their combination (+Ba- sic+WordBased). The first three rows present the results achieved by our terms of comparison: random ROVER, the segment-based oracle (SegO) and the system- based oracle (SysO). As anticipated when moti- vating our work (see <ref type="table">Table 1</ref>), the WER achieved by SegO is always lower than the scores achieved by SysO. Note also that the performance of SegO decreases as the number of combined hypotheses increases, due to the introduction in the input of progressively worse transcripts. Instead, SysO ex- hibits a less coherent behaviour, with close WER values at all levels, and a minimum in correspon- dence of column L4 (the combination of four transcriptions of the whole utterance). We inter- pret these results as a further motivation for our work: feeding ROVER with a good ranking that exploits local (segment-level) differences between the combined hypotheses seems to be more reli- able than relying on system-level ranks based on global WER scores. A theoretical analysis of the relation between the diversity of the combined hy- potheses and ROVER results is presented in ( <ref type="bibr" target="#b1">Audhkhasi et al., 2014</ref>). In light of this analysis, our results open an interesting issue concerning the trade-offs between optimal hypothesis ranking and their (local) diversity. We initially explore this problem in Section 7.1, but leave for future work a more systematic investigation. Rows 4-6 show the results achieved by RR1 (ranking by regression, trained with all the tran-scriptions for each input segment). When trained only with basic features, it always outperforms random ROVER. At L8 the gain is not statisti- cally significant but, at the same time, also the WER difference with SysO is not significant. Note that, proceeding from L3 to L8, the WER differ- ence between RR1+Basic and random ROVER de- creases from 0.7 to 0.1. This can be explained by the fact that when the number of candidates in- creases, then the role of majority voting dominates the role of hypothesis ranking. Similar trends are shown by all other approaches, including the or- acles. RR1+WordBased slightly improves over RR1+Basic, indicating the possible usefulness of this new set of features. However, when used in combination (RR1+Basic+WordBased), the two feature sets do not yield further WER reductions. Nevertheless, what is worth to remark is that at L7 and L8 the distance from Sys0 is not statistically significant (a positive result).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Results and discussion</head><p>As shown in rows 7-9, the situation changes with RR2 (ranking by regression, trained with one transcription per segment). When trained with the combined feature sets (RR2+Basic+WordBased), the model always leads to slight WER reductions over RR2+Basic. Also in this case, the gains over random ROVER are consistent (they range from 0.9 at L3 to 0.2 at L8), and the difference with re- spect to SysO is not statistically significant at L7 and L8 (a positive result).</p><p>As shown in rows 10-12, results are further im- proved by MLR. Except for L8, the improvement over random ROVER is statistically significant, large and consistent with all feature sets. The WER reduction obtained by MLR+Basic varies from 1.7 to 0.2 WER points, indicating a higher ef- fectiveness of machine-learned ranking compared to ranking by regression. MLR+WordBased pro- duces further WER reductions, with differences with SysO that become statistically not-significant at four levels (L3, L6, L7 and L8). Finally, when trained with the combined feature sets, the ranking model leads to the lowest WER scores. Notice- ably, such results are not only on par with SysO (the difference is statistically significant only at L4), but in one case (L6) they even reach those of SegO, the strongest competitor (best result).</p><p>Overall, as evidenced by the L8 column, when the number of input components becomes large our QE-informed approaches are not significantly better than random ROVER and SysO. This raises the need of a stopping criterion to avoid entering useless inputs into the ROVER combination. To- gether with the trade-off between ranking perfor- mance and hypotheses' diversity, this represents an interesting topic for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">The role of hypotheses' diversity</head><p>To gain further insights on our results, and as a first step along the research directions previ- ously outlined, we analysed the relation between ROVER results and hypotheses' diversity. To this aim, <ref type="figure" target="#fig_2">Figure 2</ref> plots the WER of our best method (MLR+Basic+WordBased) and the two oracles as a function of hypotheses' diversity at L6, for which we obtain the best results.  Diversity is measured by computing the difference between the maximum and the minimum WERs of the input transcriptions. All the segments are then grouped with regard to this difference. For example 10 on the x-axis refers to the group of segments whose diversities lay in the interval of <ref type="bibr">[0,</ref><ref type="bibr">10)</ref>; 20 refers to the segments whose diversities are in <ref type="bibr">[10,</ref><ref type="bibr">20)</ref> and consequently, 100 represents the segments whose diversities lay in <ref type="bibr">[90,</ref><ref type="bibr">100]</ref>. This latter means that for each segment there is at least one transcription that is perfect or close to perfec- tion, and one that is (almost completely) wrong.</p><p>For segments with diversity smaller than 70, the performance of the system-based oracle (line with circle marks) and our segment-level QE-informed ROVER (line with triangle marks) is almost iden- tical. Instead, for segments with a "high" level of diversity (in the interval <ref type="bibr">[70,</ref><ref type="bibr">100]</ref>), our method significantly outperforms the system-based oracle. With a maximum gain larger than 3 WER points, it approaches the strong segment-based oracle (line with asterisk marks). Remarkably, for diversity values in the interval <ref type="bibr">[90,</ref><ref type="bibr">100]</ref>, our method is able to halve the distance that separates the two oracles.</p><p>The considerable WER reductions observed for diversity values larger than 70 shed new light on the global results reported in <ref type="table" target="#tab_5">Table 4</ref>. The fact that such performance gains are hidden in the global scores can be explained by looking at the dashed line in <ref type="figure" target="#fig_2">Figure 2</ref>, which shows the percentage of segments belonging to each diversity level. As it can be observed, the vast majority of the seg- ments (∼95%) falls in diversity bins in the inter- val <ref type="bibr">[10,</ref><ref type="bibr">70)</ref>. The large WER reductions obtained on the few remaining segments are definitely not enough to boost global results. Overall, this find- ing suggests that our segment-level QE-informed ROVER can fully unfold its potential in applica- tion scenarios featuring high diversity among the transcriptions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Prediction of overall ranks</head><p>Since our results strongly depend on the reliabil- ity of hypothesis ranking, our final analysis fo- cuses on the correlation between QE-based rank- ing methods and the "true" ranks used as prior knowledge by the system-based oracle (the official ranking of the IWSLT2013 participants). In order to predict the overall IWSLT2013 ranking, we first run our QE models on each segment. Systems are then ordered based on the average ranking score received by their transcriptions. Finally, the alter- native QE-based methods (RR1, RR2 and MLR) are compared by measuring their Spearman corre- lation with the TRUE systems' order. <ref type="table" target="#tab_7">Table 5</ref> reports the resulting rankings and the corresponding correlation with the true, official one. Among all the possible combinations (8 fac- torial), our two best methods (RR2 and MLR) re- sult in a systems' ordering with high correlation with the official IWSLT2013 ranking. In particu- lar, MLR achieves correlation of 0.905 with three out of eight systems (1, 2 and 8) that are correctly positioned. The correlation values of the differ- ent approaches reflect the performance reported in <ref type="table" target="#tab_5">Table 4</ref>, in which the WER achieved by us- ing MLR is usually better than the ones obtained from RR1 and RR2. It is interesting to note in the last column of <ref type="table" target="#tab_7">Table 5</ref> that the ranking errors are represented by switches between systems with similar WERs, while it seems easier to discrimi- nate between systems with more distant WER val- ues. This consideration is in line with the findings of Section 7.1 concerning the higher potential of segment-level QE-informed ROVER in scenarios featuring a higher diversity between the combined systems.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusions</head><p>We presented a novel approach to improve the combination of multiple automatic transcription hypotheses using ROVER. Our method is based on informing the fusion process with accurate word error rate predictions obtained from ASR quality estimation models. First, to exploit the possible local diversity among the combined hypotheses, it performs quality prediction and ranking at seg- ment level. Then, the predicted ranks for each segment are used to feed ROVER. Finally, the combined hypotheses are concatenated to recon- struct the entire utterance transcription. To rank predictions, we compared two different regression models with a machine-learned ranking method. We carried out experiments on a set of English TED talks collected for two editions of the IWSLT ASR evaluation campaign. Results show that our segment-level QE-informed ROVER outperforms the standard random ROVER and performs on par (differences are not statistically significant) with a system-based ROVER oracle that exploits prior knowledge about systems' reliability. Moreover, compared to a very strong segment-based ROVER oracle, in one case the performance of our method is not statistically different. These results are par- ticularly encouraging, especially in light of the fact that our approach does not exploit confidence information related to the internal behaviour of the ASR decoders. Overall, this represents the first confirmation, obtained in an extrinsic evaluation setting, of the good potential of reference-free and system-agnostic ASR quality estimation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Results on tst2013 of the oracles and our best model, as functions of hypotheses' diversity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 2 : Dataset statistics: duration, number of sentences, number of tokens, vocabulary size, number of talks.</head><label>2</label><figDesc></figDesc><table>System tst2012 tst2013 
FBK 
16.8 
23.2 
KIT 
12.7 
14.4 
MITLL 13.3 
15.9 
NAIST 
-
16.2 
NICT 
12.4 
13.5 
PRKE 
-
27.2 
RWTH 
13.6 
16.0 
UEDIN 14.4 
22.1 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Official WER[%] scores of the partic-
ipants in the IWSLT2012 and IWSLT2013 ASR 
evaluations. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 reports</head><label>4</label><figDesc></figDesc><table>the WER results obtained on 
tst2013 by ROVER methods fed with: different 
numbers of hypotheses (from 3 to 8), at different 
granularity levels (whole utterance vs. segment), 
ranked with different models (random, RR1, RR2 
and MLR) trained with different sets of features 

8 http://sourceforge.net/p/lemur/wiki/ 
RankLib/ 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>True and predicted IWSLT2013 system 
ranks (correct predictions are shown in bold). 

</table></figure>

			<note place="foot" n="1"> One example, among the many possible ones, is the scenario in which an array of microphones (e.g. in a room or a vehicle) sends input to one or more commercial ASR systems which do not provide confidence information.</note>

			<note place="foot" n="2"> Details about this dataset will be provided in Section 6.1. 3 This formulation is very similar to the machine translation counterpart of the task (Specia et al., 2009; Mehdad et al., 2012; Turchi et al., 2014; C. de Souza et al., 2014).</note>

			<note place="foot" n="5"> http://workshop2012.iwslt.org 6 http://workshop2013.iwslt.org</note>

			<note place="foot" n="7"> The word error rate is the minimum edit distance between an hypothesis and the reference transcription. Edit distance is calculated as the number of edits (word insertions, deletions, substitutions) divided by the number of words in the reference. Lower WERs (↓) indicate better transcriptions.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">cROVER: Improving ROVER using Automatic Error Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kacem</forename><surname>Abida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fakhri</forename><surname>Karray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wafa</forename><surname>Abida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing</title>
		<meeting>the IEEE International Conference on Acoustics, Speech, and Signal Processing<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-05" />
			<biblScope unit="page" from="1753" to="1756" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Theoretical analysis of diversity in an ensemble of automatic speech recognition systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kartik</forename><surname>Audhkhasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><forename type="middle">M</forename><surname>Zavou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Panayiotis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Georgiou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shrikanth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Narayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on Audio, Speech &amp; Language Processing</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="711" to="726" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Boersma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Weenink</surname></persName>
		</author>
		<ptr target="http://www.praat.org/" />
		<title level="m">Praat: Doing Phonetics by Computer</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>Version 4.3.01</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">LIUM ASR System for Etape French Evaluation Campaign: Experiments on System Combination using Open-source Recognizers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Estève</forename><surname>Deléglise</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannick</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mickael</forename><surname>Rouvier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th International Conference on Text, Speech, and Dialogue</title>
		<meeting>the 16th International Conference on Text, Speech, and Dialogue<address><addrLine>Pilsen, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-09" />
			<biblScope unit="page" from="319" to="326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Random forests. Machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leo</forename><surname>Breiman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="5" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Machine Translation Quality Estimation Across Domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">C</forename><surname>José</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Turchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Negri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on Computational Linguistics (COLING 2014): Technical Papers</title>
		<meeting>the 25th International Conference on Computational Linguistics (COLING 2014): Technical Papers<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-08" />
			<biblScope unit="page" from="409" to="420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Multitask Learning for Adaptive Quality Estimation of Automatically Transcribed Utterances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">C</forename><surname>José</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamed</forename><surname>De Souza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Zamani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniele</forename><surname>Turchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Falavigna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics-Human Language Technologies (NAACL HLT 2015</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics-Human Language Technologies (NAACL HLT 2015<address><addrLine>Denver, Colorado, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning to Rank: from Pairwise Approach to Listwise Approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Feng</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on Machine learning (ICML-07)</title>
		<meeting>the 24th International Conference on Machine learning (ICML-07)<address><addrLine>Corvalis, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="129" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Model Selection Criteria for Acoustic Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mauro</forename><surname>Cettolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ASR2000-Automatic Speech Recognition: Challenges for the new Millenium ISCA Tutorial and Research Workshop</title>
		<imprint>
			<publisher>ITRW</publisher>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Report on the 10th IWSLT Evaluation Campaign</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mauro</forename><surname>Cettolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Niehues</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Stüker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luisa</forename><surname>Bentivogli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Workshop on Spoken Language Translation (IWSLT 2013)</title>
		<meeting>the International Workshop on Spoken Language Translation (IWSLT 2013)<address><addrLine>Heidelberg, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Named Entity Recognition: A Maximum Entropy Approach Using Global Information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Leong Chieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee Tou</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th International Conference on Computational Linguistics</title>
		<meeting>the 19th International Conference on Computational Linguistics<address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
	<note>COLING &apos;02</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">FBK-UEdin participation to the WMT13 quality estimation shared task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">C</forename><surname>José</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Buck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Turchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Negri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth Workshop on Statistical Machine Translation</title>
		<meeting>the Eighth Workshop on Statistical Machine Translation<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-08" />
			<biblScope unit="page" from="352" to="358" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Posterior Probability Decoding, Confidence Estimation and System Combination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gunnar</forename><surname>Evermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIST Speech Transcription Workshop</title>
		<meeting>NIST Speech Transcription Workshop<address><addrLine>College Park, MD, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Overview of the IWSLT 2012 Evaluation Campaign</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luisa</forename><surname>Bentivogli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Stüker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Workshop on Spoken Language Translation (IWSLT 2012)</title>
		<meeting>the International Workshop on Spoken Language Translation (IWSLT 2012)<address><addrLine>Hong Kong</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-12" />
			<biblScope unit="page" from="11" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A Post-processing System to Yield Reduced Word Error Rates: Recognizer Output Voting Error Reduction (ROVER)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Jonathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fiscus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Workshop on Automatic Speech Recognition and Understanding</title>
		<meeting>the IEEE Workshop on Automatic Speech Recognition and Understanding<address><addrLine>Santa Barbara, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="347" to="354" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Extremely randomized trees. Machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Geurts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Damien</forename><surname>Ernst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Louis</forename><surname>Wehenkel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="3" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Some Statistical Issues in the Comparison of Speech Recognition Algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurence</forename><surname>Gillick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing</title>
		<meeting>the IEEE International Conference on Acoustics, Speech, and Signal Processing<address><addrLine>Glasgow, Scotland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1989" />
			<biblScope unit="page" from="532" to="535" />
		</imprint>
	</monogr>
	<note>ICASSP 1989</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Which words are hard to recognize? prosodic, lexical, and disfluency factors that increase speech recognition error rates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Goldwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Speech Communication</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="181" to="200" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A short introduction to learning to rank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">I</forename><surname>Hang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEICE TRANSACTIONS on Information and Systems</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1854" to="1862" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">iROVER: Improving System Combination with Classification. In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Companion Volume, Short Papers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dustin</forename><surname>Hillard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bjoern</forename><surname>Hoffmeister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mari</forename><surname>Ostendorf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralf</forename><surname>Schlueter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007-04" />
			<biblScope unit="page" from="65" to="68" />
			<pubPlace>Rochester, New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Frame Based System Combination and a Comparison with Weighted ROVER and CNC</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Björn</forename><surname>Hoffmeister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralf</forename><surname>Schlüter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Spoken Language Processing (Interspeech 2006-ICSLP)</title>
		<meeting>the International Conference on Spoken Language Processing (Interspeech 2006-ICSLP)<address><addrLine>Pittsburgh, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="537" to="540" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Lattice Combination for Improved Speech Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rita</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">M</forename><surname>Stern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference of Spoken Language Processing</title>
		<meeting>the International Conference of Spoken Language Processing<address><addrLine>Denver, CO, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Finding Consensus in Speech Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidia</forename><surname>Mangu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
		<respStmt>
			<orgName>John Hopkins University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">PhD Thesis</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Metric Learning to Rank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Mcfee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gert</forename><forename type="middle">R</forename><surname>Lanckriet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Machine Learning (ICML10)</title>
		<meeting>the 27th International Conference on Machine Learning (ICML10)<address><addrLine>Haifa, Israel</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-06" />
			<biblScope unit="page" from="775" to="782" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Computing information retrieval performance measures efficiently in the presence of tied scores</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Mcsherry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Najork</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in information retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="414" to="421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Match without a Referee: Evaluating MT Adequacy without Reference Translations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yashar</forename><surname>Mehdad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Machine Translation Workshop (WMT2012)</title>
		<meeting>the Machine Translation Workshop (WMT2012)</meeting>
		<imprint>
			<date type="published" when="2012-06" />
			<biblScope unit="page" from="171" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Recurrent Neural Network Based Language Model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Karafiát</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Burget</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of INTERSPEECH 2010, 11th Annual Conference of the International Speech Communication Association</title>
		<meeting>INTERSPEECH 2010, 11th Annual Conference of the International Speech Communication Association<address><addrLine>Makuhari, Chiba, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-01" />
			<biblScope unit="page" from="1045" to="1048" />
		</imprint>
	</monogr>
	<note>Cernock`Cernock`y, and Sanjeev Khudanpur</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Quality Estimation for Automatic Speech Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Turchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">C</forename><surname>José</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Falavigna</forename><surname>De Souza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daniele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers</title>
		<meeting>COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-08" />
			<biblScope unit="page" from="1813" to="1823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaël</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bertrand</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Dubourg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Improving ASR Error Detection with Non-decoder Based Features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Pellegrini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabel</forename><surname>Trancoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of INTERSPEECH 2010, 11th Annual Conference of the International Speech Communication Association</title>
		<meeting>INTERSPEECH 2010, 11th Annual Conference of the International Speech Communication Association<address><addrLine>Makuhari, Chiba, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-09" />
			<biblScope unit="page" from="1950" to="1953" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Improved ROVER using Language Model Information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Luc</forename><surname>Gauvain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ASR2000-Automatic Speech Recognition: Challenges for the new Millenium ISCA Tutorial and Research Workshop</title>
		<imprint>
			<publisher>ITRW</publisher>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Estimating the Sentence-Level Quality of Machine Translation Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Cancedda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Dymetman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Turchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nello</forename><surname>Cristianini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th</title>
		<meeting>the 13th</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<title level="m">Annual Conference of the European Association for Machine Translation (EAMT&apos;09)</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="28" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Stolcke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harry</forename><surname>Bratt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Butzberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horacio</forename><surname>Franco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Madelaine</forename><surname>Venkata Ramana Gadde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colleen</forename><surname>Plauche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elizabeth</forename><surname>Richey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shriberg</surname></persName>
		</author>
		<title level="m">Kemal Sonmez, F Weng, and Jing Zheng. 2000. The SRI march 2000 HUB5 conversational speech transcription system</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">ASR Error Detection using Recurrent Neural Network Language Model and Complementary ASR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yik-Cheung</forename><surname>Tam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing</title>
		<meeting>the IEEE International Conference on Acoustics, Speech, and Signal Processing<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-05" />
			<biblScope unit="page" from="2312" to="2316" />
		</imprint>
	</monogr>
	<note>ICASSP 2014</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Adaptive Quality Estimation for Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Turchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonios</forename><surname>Anastasopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">C</forename><surname>José</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>De Souza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Negri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="710" to="720" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Investigations of Issues for Using Multiple Acoustic Models to Improve Continuous Speech Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">I</forename><surname>Rudnicky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of INTERSPEECH</title>
		<meeting>INTERSPEECH<address><addrLine>Pittsburgh, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-09" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
