<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:01+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Search-based Neural Structured Learning for Sequential Question Answering</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">UMIACS University of Maryland</orgName>
								<address>
									<settlement>College Park</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research Redmond</orgName>
								<address>
									<postCode>98052</postCode>
									<region>WA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Search-based Neural Structured Learning for Sequential Question Answering</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</title>
						<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1821" to="1831"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-1167</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Recent work in semantic parsing for question answering has focused on long and complicated questions, many of which would seem unnatural if asked in a normal conversation between two humans. In an effort to explore a conversational QA setting, we present a more realistic task: answering sequences of simple but interrelated questions. We collect a dataset of 6,066 question sequences that inquire about semi-structured tables from Wikipedia, with 17,553 question-answer pairs in total. To solve this sequential question answering task, we propose a novel dynamic neural semantic parsing framework trained using a weakly supervised reward-guided search. Our model effectively leverages the sequential context to outperform state-of-the-art QA systems that are designed to answer highly complex questions.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Semantic parsing, which maps natural language text to meaning representations in formal logic, has emerged as a key technical component for building question answering systems <ref type="bibr" target="#b10">(Liang, 2016)</ref>. Once a natural language question has been mapped to a for- mal query, its answer can be retrieved by executing the query on a back-end structured database.</p><p>One of the main focuses of semantic parsing research is how to address compositionality in lan- guage, and complicated questions have been specif- ically targeted in the design of a recently-released QA dataset <ref type="bibr" target="#b15">(Pasupat and Liang, 2015)</ref>. Take for ex- ample the following question: "of those actresses who won a Tony after 1960, which one took the most amount of years after winning the Tony to * Work done during an internship at Microsoft Research win an Oscar?" The corresponding logical form is highly compositional; in order to answer it, many sub-questions must be implicitly answered in the process (e.g., "who won a Tony after 1960?").</p><p>While we agree that semantic parsers should be able to answer very complicated questions, in re- ality these questions are rarely issued by users. <ref type="bibr">1</ref> Because users can interact with a QA system re- peatedly, there is no need to assume a single-turn QA setting where the exact question intent has to be captured with just one complex question. The same intent can be more naturally expressed through a sequence of simpler questions, as shown below:</p><p>1. What actresses won a Tony after 1960? 2. Of those, who later won an Oscar? 3. Who had the biggest gap between their two award wins? Decomposing complicated intents into multiple re- lated but simpler questions is arguably a more ef- fective strategy to explore a topic of interest, and it reduces the cognitive burden on both the person who asks the question and the one who answers it. <ref type="bibr">2</ref> In this work, we study semantic parsing for answering sequences of simple related ques- tions. We collect a dataset of question sequences called SequentialQA (SQA; Section 2) <ref type="bibr">3</ref> by asking crowdsourced workers to decompose complicated questions sampled from the WikiTableQuestions dataset <ref type="bibr" target="#b15">(Pasupat and Liang, 2015</ref>) into multiple easier ones. SQA, which contains 6,066 question sequences with 17,553 total question-answer pairs, is to the best of our knowledge the first semantic parsing dataset for sequential question answering. Section 3 describes our novel dynamic neural se- mantic parsing framework (DynSP), a weakly su- 1 For instance, there are only 3.75% questions with more than 15 words in <ref type="bibr">WikiAnswers (Fader et al., 2014)</ref>.</p><p>2 Studies have shown increased sentence complexity links to longer reading times <ref type="bibr" target="#b5">(Hale, 2006;</ref><ref type="bibr" target="#b8">Levy, 2008;</ref><ref type="bibr" target="#b4">Frank, 2013</ref> 2. Which of them come from Earth?</p><p>3. Of those, who appeared most recently?</p><p>Original intent: What super hero from Earth appeared most recently? pervised structured-output learning approach based on reward-guided search that is designed for solv- ing sequential QA. We demonstrate in Section 4 that DynSP achieves higher accuracies than exist- ing systems on SQA, and we offer a qualitative analysis of question types that our method answers effectively, as well as those on which it struggles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Legion of Super Heroes Post-Infinite Crisis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">A Dataset of Question Sequences</head><p>We collect the SequentialQA (SQA) dataset via crowdsourcing by leveraging WikiTableQues- tions (Pasupat and Liang, 2015, henceforth WTQ), which contains highly compositional questions as- sociated with HTML tables from Wikipedia. Each crowdsourcing task contains a long, complex ques- tion originally from WTQ as the question intent. The workers are asked to compose a sequence of simpler questions that lead to the final intent; an example of this process is shown in <ref type="figure" target="#fig_0">Figure 1</ref>. To simplify the task for workers, we only use questions from WTQ whose answers are cells in the table, which excludes those involving arithmetic and counting. We likewise also restrict the ques- tions our workers can write to those answerable by only table cells. These restrictions speed the an- notation process because workers can just click on the table to answer their question. They also allow us to collect answer coordinates (row and column in the table) as opposed to answer text, which re- moves many normalization issues for answer string matching in evaluation. Finally, we only use long questions that contain nine or more words as in- tents; shorter questions tend to be simpler and are thus less amenable to decomposition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Properties of SQA</head><p>In total, we used 2,022 question intents from the train and test folds of the WTQ for decomposi- tion. We had three workers decompose each intent, resulting in 6,066 unique questions sequences con- taining 17,553 total question-answer pairs (for an average of 2.9 questions per sequence). We divide the dataset into train and test using the original WTQ folds, resulting in an 83/17 train/test split. Importantly, just like in WTQ, none of the tables in the test set are seen in the training set.</p><p>We identify three frequently-occurring question classes: column selection, subset selection, and row selection. <ref type="bibr">4</ref> In column selection questions, the answer is an entire column of the table; these ques- tions account for 23% of all questions in SQA. Sub- set and row selection are more complicated than column selection, as they usually contain corefer- ences to the previous question's answer. In subset selections, the answer is a subset of the previous question's answer; similarly, the answers to row selections occur in the same row(s) as the previous answer but in a different column. Subset selections make up 27% of SQA, while row selections are an additional 19%. The remaining 31% contains more complex combinations of these three types.</p><p>We also observe dramatic differences in the types of questions that are asked at each position of the sequence. For example, 51% of the first questions in the sequences are column selections (e.g., "what are all of the teams?"). This number dwindles to just 18% when we look at the second question of each sequence, which indicates that the collected sequences start with general questions and progress to more specific ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Dynamic Neural Semantic Parsing</head><p>The unique setting of SQA provides both opportu- nities and challenges. On the one hand, it contains short questions with less compositionality, which in theory should reduce the difficulty of the se- mantic parsing problem; on the other hand, the additional contextual dependencies of the preced- ing questions and their answers increase modeling complexity. These observations lead us to pro- pose a dynamic neural semantic parsing framework (DynSP) trained using a reward-guided search pro-cedure for solving SQA.</p><p>Given a question (optionally along with previous questions and answers) and a table, DynSP formu- lates the semantic parsing problem as a state-action search problem. Each state represents a complete or partial parse, while each action corresponds to an operation to extend a parse. The goal during inference is to find an end state with the highest score as the predicted parse.</p><p>The quality of the induced semantic parse ob- viously depends on the scoring function. In our design, the score of a state is determined by the scores of actions taken from the initial state to the target state, which are predicted by differ- ent neural network modules based on action type. By leveraging a margin-based objective function, the model learning procedure resembles several structured-output learning algorithms such as struc- tured SVMs ( <ref type="bibr" target="#b19">Tsochantaridis et al., 2005</ref>), but can take either strong or weak supervision seamlessly.</p><p>DynSP is inspired by STAGG, a search-based semantic parser ( <ref type="bibr" target="#b21">Yih et al., 2015)</ref>, as well as the dy- namic neural module network (DNMN) of <ref type="bibr" target="#b0">Andreas et al. (2016)</ref>. Much like STAGG, DynSP chains together different modules as search progresses; however, these modules are implemented as neural networks, which enables end-to-end training as in DNMN. The key difference between DynSP and DNMN is that in DynSP the network structure of an example is not predetermined. Instead, different network structures are constructed dynamically as our learning procedure explores the state space. It is straightforward to answer sequential questions using our framework: we allow the model to take the previous question and its answers as input, with a slightly modified action space to reflect a depen- dent semantic parse. The same search / learning procedure is then able to effortlessly adapt to the new setting. In this section, we first describe the formal language underlying DynSP, followed by the model formulation and learning algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Semantic parse language</head><p>Because tables are used as the data source to an- swer questions in SQA, we decide to form our semantic parses in an SQL-like language <ref type="bibr">5</ref> . Our parses consist of two parts: a select statement and conjunctions of zero or more conditions. <ref type="bibr">5</ref> Our framework is not restricted to the formal language we use in this work. In addition, the structured query can be straightforwardly represented in other formal languages, such as the lambda DCS logic used in <ref type="bibr" target="#b15">(Pasupat and Liang, 2015).</ref> A select statement is associated with a column name, which is referred to as the answer column. Conditions enforce additional constraints on which cells in the answer column can be chosen; a se- lect statement without any conditions indicates that an entire column of the table is the answer to the question. In particular, each condition con- tains a column name as the condition column and an operator with zero or more arguments. The operators in this work include: =, =, &gt;, ≥, &lt;, ≤, arg min, arg max. A cell in the answer column is only a legitimate answer if the cell of the cor- responding row in the condition column satisfies the constraint defined by the operator and its argu- ments. As a concrete example, suppose the data source is the same table in <ref type="figure" target="#fig_0">Fig. 1</ref>. The semantic parse of the question "Which super heroes came from Earth and first appeared after 2009?" is "Se- lect Character Where {Home World = Earth} ∧ {First Appeared &gt; 2009}" and the answers are {Dragonwing, Harmonia}.</p><p>In order to handle the sequential aspect of SQA, we extend the semantic parse language by adding a preamble statement subsequent. A subsequent statement contains only conditions, as it essentially adds constraints to the semantic parse of the previ- ous question. For instance, if the follow-up ques- tion is "Which of them breathes fire?", then the cor- responding semantic parse is "Subsequent Where {Powers = Fire breath}". The answer to this ques- tion is {Dragonwing}, a subset of the previous answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Model formulation</head><p>We start introducing our model design by first defin- ing the state and action space. Let S be the set of states and A the set of all actions. A state s ∈ S is simply a sequence of variable length of actions {a 1 , a 2 , a 3 , · · · , a t }, where a i ∈ A. An empty sequence, s 0 = φ, is a special state used as the starting point of search.</p><p>As mentioned earlier, a state represents a (partial) semantic parse of one question. Each action is thus a legitimate operation that can be added to grow the semantic parse. Our action space design is tied closely to the statements defined by our parse lan- guage; in particular, an action instance is either a complete or partial statement, and action instances are grouped by type. For example, select and subse- quent operations are two action types. A condition statement is formed by two different action types: <ref type="table">Table 1</ref>: Types of actions and the number of action instances in each type. Numbers / datetimes are the mentions discovered in the question (plus the previous question if it is a subsequent condition).</p><formula xml:id="formula_0">Id Type # Action instances A1 Select-column # columns A2 Cond-column # columns A3 Op-Equal (=) # rows A4 Op-NotEqual ( =) # rows A5 Op-GT (&gt;) # numbers / datetimes A6 Op-GE (≥) # numbers / datetimes A7 Op-LT (&lt;) # numbers / datetimes A8 Op-LE (≤) # numbers / datetimes A9 Op-ArgMin # numbers / datetimes A10 Op-ArgMax # numbers / datetimes A11 Subsequent 1 A12 S-Cond-column # columns A13 S-Op-Equal (=) # rows A14 S-Op-NotEqual ( =) # rows A15 S-Op-GT (&gt;) # numbers / datetimes A16 S-Op-GE (≥) # numbers / datetimes A17 S-Op-LT (&lt;) # numbers / datetimes A18 S-Op-LE (≤) # numbers / datetimes A19 S-Op-ArgMin # numbers / datetimes A20 S-Op-ArgMax # numbers / datetimes</formula><p>(1) selection of the condition column, and (2) the comparison operator. The instances of each action type differ in their arguments (e.g., column names, or specific cells in a column). Because conditions in a subsequent parse rely on previous questions and answers, they belong to different action types from regular conditions. <ref type="table">Table 1</ref> summarizes the action space defined in this work. Any state that represents a complete and legit- imate parse is an end state. Notice that search does not necessarily need to stop at an end state, because adding more actions (e.g., condition state- ments) can lead to another end state. Take the same example question from before: "Which su- per heroes came from Earth and first appeared after 2009?". One action sequence that represents the parse is</p><formula xml:id="formula_1">{(A 1 ) select-column Character, (A 2 ) cond-column Home World, (A 3 ) op-equal Earth, (A 2 ) cond-column First Appeared, (A 5 ) op-gt 2009}.</formula><p>Notice that many states represent semantically equivalent parses (e.g., those with the same ac- tions ordered differently, or states with repeated conditions). To prune the search space, we intro- duce the function Act(s) ⊂ A, which defines the actions that can be taken when given a state s. Bor- rowing the idea of staged state generation in <ref type="bibr" target="#b21">(Yih et al., 2015)</ref>, we choose a default ordering of ac- tions based on their types, dictating that a select action must be picked first and that a condition-  Figure 2: Possible action transitions based on their types (see <ref type="table">Table 1</ref>). Shaded circles are end states.</p><p>column needs to be determined before the operator is chosen. The full transition diagram is presented in <ref type="figure">Fig. 2</ref>. Note that to implement this transition order, we only need to check the last action in the state. In addition, we also disallow adding dupli- cates of actions that already exist in the state. We use beam search to find an end state with the highest score for inference. Let s t be a state consisting of a sequence of actions a 1 , a 2 , · · · , a t . The state value function V is defined recursively as</p><formula xml:id="formula_2">V (s t ) = V (s t−1 ) + π(s t−1 , a t ), V (s 0 ) = 0,</formula><p>where the policy function π(s, a) scores an action a ∈ Act(s) given the current state.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Policy function</head><p>The intuition behind the policy function can be summarized as follows. Halfway through the con- struction of a semantic parse, the policy function measures the quality of an immediate action that can be taken next given the current state (i.e., the question and actions that have previously been cho- sen). To enable integrated, end-to-end learning, the policy function in our framework is parameterized using neural networks. Because each action type has very different semantics, we design different network structures (i.e., modules) accordingly.</p><p>Most of our network structures encourage learn- ing semantic matching functions between the words in the question and table (either the column names or cells). Here we illustrate the design using the select-column action type (A 1 ). Conceptually, the corresponding module is a combination of vari- ous matching scores. Let W Q be the embeddings of words in the question and W C be the embed- dings of words in the target column name. The component matching functions are:</p><formula xml:id="formula_3">fmax = 1 |WC | wc∈W C max wq ∈W Q w T q wc favg =   1 |WC | wc∈W C wc   T   1 |WQ| wq ∈W Q wq  </formula><p>Essentially, for each word in the column name, f max finds the highest matching question word and outputs the average score. Conversely, f avg simply uses the average word vectors of the question and column name and returns their inner product. In another variant of f avg , we replace the question representation with the output of a bi-directional LSTM model. These matching component func- tions are combined by a 2-layer feed-forward neu- ral network, which outputs a scalar value as the action score. Details of the neural module design for other action types can be found in Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Model learning</head><p>Because the state value function V is defined re- cursively as the sum of scores of actions in the se- quence, the goal of model optimization is to learn the parameters in the neural networks behind the policy function. Let θ be the collection of all the model parameters. Then the state value function can be written as:</p><formula xml:id="formula_4">V θ (s t ) = t i=1 π θ (s i−1 , a i ).</formula><p>In a fully supervised setting where the correct se- mantic parse of each question is available, learning the policy function can be reduced to a sequence prediction problem. However, while having full supervision leads to a better semantic parser, col- lecting the correct parses requires a much more sophisticated UI design ( <ref type="bibr" target="#b22">Yih et al., 2016)</ref>. In many scenarios, such as the one in the SQA dataset, it is often the case that only the answers to the questions are available. Adapting a learning algorithm to this weakly supervised setting is thus critical.</p><p>Generally speaking, weakly supervised semantic parsers operate on one assumption -a candidate semantic parse is treated as a correct one if it results in answers that are identical to the gold answers. Therefore, a straightforward modification of exist- ing structured learning algorithms in our setting is to use any semantic parse found to evaluate to the correct answers during beam search as a reference parse, and then update the model parameters ac- cordingly. In practice, however, this approach is often problematic: the search space can grow enor- mously, and when coupled with poor model per- formance early during training, this leads to beams that contain no parses evaluating to the correct an- swer. As a result, learning becomes inefficient and takes a long time to converge.</p><p>In this work, we propose a conceptually simple learning algorithm for weakly supervised training that sidesteps the inefficient learning problem. Our key insight is to conduct inference using a beam search procedure guided by an approximate reward function. The search procedure is executed twice for each training example, one for finding the best possible reference semantic parse and the other for finding the predicted semantic parse to update the model. Our framework is suitable for learning from either implicit or explicit supervision, and is detailed in a companion paper <ref type="figure" target="#fig_0">(Peng et al., 2017)</ref>. Below we describe how we adapt it to the semantic parsing problem in this work.</p><p>Approximate reward Let A(s) be the answers retrieved by executing the semantic parse repre- sented by state s, and let A * be the set of gold answers of a given question. We define the reward R(s; A * ) = 1[A(s) = A * ], or the accuracy of the retrieved answers. We use R(s) as the abbreviation for R(s; A * ). A state s with R(s) = 1 is called a goal state. Directly using this reward function in search of goal states can be difficult, as rewards of most states are 0. However, even when the an- swers from a semantic parse are not completely correct, some overlap with the gold answers can still hint that the state is close to a goal state, thus providing useful information to guide search. To formalize this idea, we define an approximated reward˜Rreward˜ reward˜R(s) in this work using the Jaccard coef- ficient ( ˜ R(s) = |A(s) ∩ A * |/|A(s) ∪ A * |). If s is a goal state, then obviously˜Robviously˜ obviously˜R(s) = R(s) = 1. Also because our actions effectively add additional constraints to exclude some table cells, any suc- ceeding states of s with˜Rwith˜ with˜R(s ) = 0 will also have 0 approximate reward and can be pruned from search immediately.</p><p>We use the approximate reward˜Rreward˜ reward˜R to guide our beam search to find the reference parses (i.e., goal states). Some variations of the approximate reward can be used to make learning more efficient. For instance, we use the model score for tie-breaking, effectively making the approximate reward func- tion depend on the model parameters:</p><formula xml:id="formula_5">˜ R θ (s) = |A(s) ∩ A * |/|A(s) ∪ A * | + V θ (s), (1)</formula><p>where is a small constant. When a goal state is not found, the state with the highest approximate reward can still be used as a surrogate reference.</p><p>Updating parameters The model parameters are updated by first finding the most violated statêstatê s and then comparingˆscomparingˆ comparingˆs with a reference state s * to compute a loss. The idea of finding the most vio- lated state comes from <ref type="bibr" target="#b18">Taskar et al. (2004)</ref>, with the Algorithm 1 Model parameter updates 1: for pick a labeled data (x, A * ) do 2:</p><formula xml:id="formula_6">s * ← arg max s∈E(x) ˜ R(s; A * ) 3: ˆ s ← arg max s∈E(x) V θ (s) − ˜ R(s; A * ) 4:</formula><p>update θ by minimizing max(L(s), 0) 5: end for intuition that the learning algorithm should make the state value function behave similarly to the re- ward. Formally, for every state s, we would like the value function to satisfy the following constraint:</p><formula xml:id="formula_7">V θ (s * ) − V θ (s) ≥ R(s * ) − R(s)<label>(2)</label></formula><p>R(s * ) − R(s) is thus the margin. As discussed above, we use approximate reward functioñ R θ instead of the true reward. We want to update the model parameters θ to make sure that the constraint is satisfied. When the constraint is violated, the degree of violation can be written as:</p><formula xml:id="formula_8">L(s) = V θ (s) − V θ (s * ) − ˜ R θ (s) + ˜ R θ (s * )<label>(3)</label></formula><p>In the algorithm, we want to find the state such that the corresponding constraint is most violated. Finding the most violated state is then equivalent to finding the state with the highest value of V θ (s) − ˜ R θ (s) as the other two terms are constant. Algorithm 1 sketches the key steps of our method in each iteration. It first picks a training instance (x and y), where x represents the table and the question, and y is the gold answer set. The approximate reward functioñ R is defined by y, while E(x) is the set of end states for this instance. Line 2 finds the best reference and Line 3 finds the most violated state, both relying on beam search for approximate inference. Line 4 computes the gradient of the loss in Eq. <ref type="formula" target="#formula_8">(3)</ref>, which is then used in backpropagation to update the model parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>Since the questions in SQA are decomposed from those in WTQ, we compare our method, DynSP, to two existing semantic parsers designed for WTQ: (1) the floating parser (FP) of <ref type="bibr" target="#b15">Pasupat and Liang (2015)</ref>, and (2) the neural programmer (NP) of <ref type="bibr" target="#b13">Neelakantan et al. (2017)</ref>. We describe below each system's configurations in more detail and qualita- tively compare and contrast their performance on SQA.</p><p>Floating parser: The floating parser <ref type="bibr" target="#b15">(Pasupat and Liang, 2015</ref>) maps questions to logical forms and then executes them on the table to retrieve the answers. It was designed specifically for the WTQ task (achieving 37.0% accuracy on the WTQ test set) and differs from other semantic parsers by not anchoring predicates to tokens in the question, re- lying instead on typing constraints to reduce the search space. Using FP as-is results in poor perfor- mance on SQA because the system is configured for questions with single answers, while SQA con- tains many questions with multiple-cell answers. We address this issue by removing a pruning hyper- parameter (tooManyValues) and features that add bias on the denotation size.</p><p>Neural programmer: The neural programmer proposed by <ref type="bibr" target="#b13">Neelakantan et al. (2017)</ref> has shown promising results on WTQ, achieving accuracies on par with those of FP. Similar to our method, NP contains specialized neural modules that perform discrete operations such as argmax and argmin, and it is able to chain together multiple modules to answer a single question. However, module se- lection in NP is computed via soft attention ( <ref type="bibr" target="#b2">Cho et al., 2014)</ref>, and information is propagated from one module to the next using a recurrent neural network. Since module selection is not tied to a pre-defined parse language like DynSP, NP sim- ply runs for a fixed number of recurrent timesteps per question rather than growing a parse until it is complete.</p><p>Comparing the baseline systems: FP and NP exemplify two very different paradigms for design- ing a semantic parsing system to answer questions using structured data. FP is a feature-rich system that aims to output the correct semantic parse (in a logical parse language) for a given question. On the other hand, the end-to-end neural network of NP relies on its modular architectures to output a probability distribution over cells in a table given a question. While NP can learn more powerful neural matching functions between questions and tables than FP's simpler feature-based matching, NP can- not produce a complete, discrete semantic parse, which means that its actions can only be interpreted coarsely by looking at the order of the modules se- lected at each timestep. <ref type="bibr">6</ref> Furthermore, FP's design theoretically allows it to operate on partial tables indirectly through an API, which is necessary if tables are large and stored in a backend database, while NP requires upfront access to the full tables to facilitate end-to-end model differentiability. <ref type="bibr">7</ref> Even though FP and NP are powerful systems designed for the more difficult, compositional ques- tions in WTQ, our method outperforms both sys- tems on SQA when we consider all questions within a sequence independently of each other (a fair comparison), demonstrating the power of our search-based semantic parsing framework. More interestingly, when we leverage the sequential in- formation by including the subsequent action, our method improves almost 3% in absolute accuracy.</p><p>DynSP combines the best parts of both FP and NP. Given a question, we try to generate its correct semantic parse in a formal language that can be predefined by the choice of structured data source (e.g., SQL). However, we push the burden of fea- ture engineering to neural networks as in NP. Our framework is easier to extend to the sequential set- ting of SQA than either baseline system, requir- ing just the additional subsequent action. FP's reliance on a hand-designed grammar necessitates extra rules that operate over partial tables from the previous question, which if added would blow up the search space. Meanwhile, modifying NP to han- dle sequential QA is non-trivial due to soft module and answer selection; it is not immediately clear how to constrain predictions for one question based on the probability distribution over table cells from the previous question in the sequence.</p><p>To more fairly compare DynSP to the baseline systems, we also experiment with a "concatenated questions" setting, which allows the baselines to access sequential context. Here, we treat concate- nated question prefixes of a sequence as additional training examples, where a question prefix includes all questions prior to the current question in the se- quence.</p><p>For example, suppose the question sequence is: 1. what are all of the teams? 2. of those, which won championships? For the second question, in addi- tion to the original question-answer pair, we add the concatenated question sequence "what are all of the teams? of those, which won championships?" paired with the second question's answer. We refer to these concatenated question baselines as FP + and NP + .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">DynSP implementation details</head><p>Unlike previous dynamic neural network frame- works ( <ref type="bibr" target="#b0">Andreas et al., 2016;</ref><ref type="bibr" target="#b12">Looks et al., 2017)</ref>, where each example can have different but prede- termined structure, DynSP needs to dynamically explores and constructs different neural network structures for each question. Therefore, we choose DyNet ( <ref type="bibr">Neubig et al., 2017)</ref> as our implementation platform for its flexibility in composing computa- tion graphs. We optimize our model parameters using standard stochastic gradient descent. The word embeddings are initialized with 100-d pre- trained GloVe vectors ( <ref type="bibr" target="#b17">Pennington et al., 2014</ref>) and fine-tuned during training with dropout rate 0.5. For follow-up questions, we choose uniformly at random to use either gold answers to the previous question or the model's previous predictions. <ref type="bibr">8</ref> We constrain the maximum length of actions to 3 for computational efficiency and set the beam size to 15 in our reported models, as accuracy gains are negligible with larger beam sizes. We train our model for 30 epochs, although the best model on the validation set is usually found within the first 20 epochs. Only CPU is used in model training, and each epoch in the beam size 15 setting takes about 30 minutes to complete. <ref type="table" target="#tab_3">Table 2</ref> shows the results of the baseline systems as well as our method on SQA's test set. For each system, we show both the overall accuracy, the sequence accuracy (the percentage of sequences for which every question was answered correctly), and the accuracy at each position in the sequence. Our method without any sequential information (DynSP) outperforms the standard baselines, and when the subsequent action is added (DynSP * ), we improve both overall and sequence accuracy over the concatenated-question baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results &amp; Analysis</head><p>With that said, all of the systems struggle to answer all questions within a sequence correctly, despite the fact that each individual question is simpler on average than those in WTQ. Most of the errors made by our system are due to either semantic matching challenges or limitations of the underlying parse language. In the middle example of <ref type="figure" target="#fig_2">Figure 3</ref>, the first question asks for a list of super heroes; from the model's point of view, Real name is a more relevant column than Character, although the latter is correct. The second question also con-  tains a challenging matching problem where the unlisted home worlds referred to in the question are marked as Unknown in the table. Many of these matching issues are resolved by humans using com- mon sense, which for computers requires far more data than is available in SQA to learn. Even when there are no tricky discrepancies be- tween question and table text, questions are often complex enough that their semantic parses cannot be expressed in our parse language. Although triv- ial on the surface, the final question in the bottom sequence of <ref type="figure" target="#fig_2">Figure 3</ref> is one such example; the cor- rect semantic parse requires access to the answers of both the first and second question, actions that we have not currently implemented in our language due to concerns with the search space size. In- creasing the number of complex actions requires designing smarter optimization procedures, which we leave to future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Previous work on conversational QA has focused on small, single-domain datasets. Perhaps most re- lated to our task is the context-dependent sentence analysis described in <ref type="bibr" target="#b23">(Zettlemoyer and Collins, 2009)</ref>, where conversations between customers and travel agents are mapped to logical forms after re- solving referential expressions. Another dataset of travel booking conversations is used by <ref type="bibr" target="#b1">Artzi and Zettlemoyer (2011)</ref> to learn a semantic parser for complicated queries given user clarifications. More recently, <ref type="bibr" target="#b11">Long et al. (2016)</ref> collect three con- textual semantic parsing datasets (from synthetic domains) that contain coreferences to entities and 1. Which nations competed in the FINA women's water polo cup? 2. Of these nations, which ones took home at least one gold medal?</p><p>3. Of those, which ranked in the top 2 positions? actions. We differentiate ourselves from these prior works in two significant ways: first, our dataset is not restricted to a particular domain, and second, a major goal of our work is to analyze the different types of sequence progressions people create when they are trying to express a complicated intent. Complex, interactive QA tasks have also been proposed in the information retrieval community, where the data source is a corpus of newswire text <ref type="bibr" target="#b7">(Kelly and Lin, 2007</ref>). We also build on aspects of some existing interactive question-answering systems. For example, the system of <ref type="bibr" target="#b6">Harabagiu et al. (2005)</ref> includes a module that predicts what a user will ask next given their current question.</p><p>Other than FP and NP, the work of Neural Symbolic Machines (NSM) ( <ref type="bibr" target="#b9">Liang et al., 2017)</ref> is perhaps the closest to ours. NSM aims to generate formal semantic parses of questions that can be executed on Freebase to retrieve an- swers, and is trained using the REINFORCE algo- rithm <ref type="bibr" target="#b20">(Williams, 1992)</ref> augmented with approxi- mate gold parses found in a separate curriculum learning stage. In comparison, finding reference parses is an integral part of our algorithm. Our non-probabilistic, margin-based objective function also helps avoid the need for empirical tricks to han- dle normalization and proper sampling, which are crucial when applying REINFORCE in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion &amp; Future Work</head><p>In this work we move towards a conversational, multi-turn QA scenario in which systems must rely on prior context to answer the user's cur- rent question. To this end, we introduce SQA, a dataset that consists of 6,066 unique sequences of inter-related questions about Wikipedia tables, with 17,553 questions-answer pairs in total. To the best of our knowledge, SQA is the first semantic parsing dataset that addresses sequential question answering. We propose DynSP, a dynamic neu- ral semantic parsing framework, for solving SQA. By formulating semantic parsing as a state-action search problem, our method learns modular neu- ral network models through reward-guided search. DynSP outperforms existing state-of-the-art sys- tems designed for answering complex questions when applied to SQA, and increases the gain after incorporating the subsequent actions.</p><p>In the future, we plan to investigate several in- teresting research questions triggered by this work. For instance, although our current formal language design covers most question types in SQA, it is nevertheless important to extend it further to make the semantic parser more robust (e.g., by includ- ing UNION or allowing comparison of multiple previous answers). Practically, allowing a more complicated semantic parse structure-either by in- creasing the number of primitive statements or the length of the parse-poses serious computational challenges in both model learning and inference. Because of the dynamic nature of our framework, it is not trivial to leverage the computational capabili- ties of GPUs using minibatched training; we plan to investigate ways to take full advantage of modern computing machinery in the near future. Finally, better resolution of semantic matching errors is a top priority, and unsupervised learning from large external corpora is one way to make progress in this direction.</p><p>A 4 Op-NotEqual The neural module for this ac- tion extends the design for A 3 . It first uses a max function similar to f max in A 3 to compare the vec- tor of the negation word "not", and the question words. This score is combined with the f max score in A 3 using a 2-layer feed-forward neural network as the final module score.</p><p>A 5 -A 8 Op-GT, Op-GE, Op-LT, Op-LE The ar- guments of these comparison operations are ex- tracted from question in advance. Therefore, the action modules just need to decide whether such relations are indeed used in the question. We take a simple strategy by initialing a special word vector that tries to capture the semantics of the relation. Take op-gt, greater than, for example. We use the average of the vectors of words like more, greater and larger to initialize the special word vector, de- noted as w gt . Let w arg be the averaged vectors of words within a [−2, +2] window centered at the argument in the question. The inner product of w gt and w arg is then used as the scoring function.</p><p>A 9 -A 10 Op-ArgMin, Op-ArgMax We handle ArgMin and ArgMax similarly to the comparison operations. The difference is that we compare the special word vector to the averaged vector of all the question words, instead of a short subsequence of words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Subsequent actions</head><p>The modules in subsequent actions use basically the same design as their coun- terparts in the independent question setting. The main difference is that we extend the question repre- sentation to words from not just the target question, but also the question that immediately precedes it.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example question sequence created from a compositional question intent. Workers must write questions whose answers are subsets of cells in the table.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>A</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Parses computed by DynSP for three test sequences (actions in blue boxes, values from table in white boxes). Top: all three questions are parsed correctly. Middle: semantic matching errors cause the model to select incorrect columns and conditions. Bottom: The final question is unanswerable due to limitations of our parse language.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Harmonia Character Teleporting Gates Earth Home World Super strength 2007 Vyrga Powers Kathoon</head><label></label><figDesc></figDesc><table>). 
3 Available at http://aka.ms/sqa 

1821 

2010 

Night Girl 

Earth 
Fire breath 

2011 

2009 

Elemental 

Aarok 

First 
Appeared 

XS 
Super 
speed 

2009 

Dragonwing 

1. Who are all of the 
super heroes? 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Accuracies of all systems on SQA; the 
models in the first half of the table treat questions 
independently, while those in the second half con-
sider sequential context. Our method outperforms 
existing ones both in terms of overall accuracy as 
well as sequence accuracy. 

</table></figure>

			<note place="foot" n="4"> In the example sequence &quot;what are all of the tournaments? in which one did he score the least points? on what date was that?&quot;, the first question is a column selection, the second is a subset selection, and the last one is a row selection.</note>

			<note place="foot" n="6"> Since NP uses a fixed number of timesteps for each question, the module order is not guaranteed to correspond to a complete parse.</note>

			<note place="foot" n="7"> In fact, NP is restricted during training to only questions whose associated tables have fewer than a certain threshold of rows and columns due to computational constraints.</note>

			<note place="foot" n="8"> Only predicted answers are used at test time.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the anonymous reviewers for their insight-ful comments. We are also grateful to Panupong Pa-supat for his help in configuring the floating parser baseline, and to Arvind Neelakantan for his help with the neural programmer model.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Action Neural Module Design</head><p>We describe here the neural module design for each action. As most actions try to match question text to column names or table entries, the neural net- work architectures are essentially various kinds of semantic similarity matching functions.</p><p>A 1 Select-column Conceptually, the correspond- ing module is a combination of various matching scores. Let W Q be the embeddings of words in the question and W C be the embeddings of words in the target column name. The component matching functions are:</p><p>Essentially, for each word in the column name, f max finds the highest matching question word and outputs the average score. Conversely, f avg simply uses the average word vectors of the question and column name and returns their inner product. In another variant of f avg , we replace the question rep- resentation with the output of a bidirectional LSTM model. These matching component functions are combined by a 2-layer feed-forward neural net- work, which outputs a scalar value as the action score.</p><p>A 2 Cond-column Because this action also tries to find the correct column (but for conditions), we use the same matching scoring functions as in A 1 module. However, a different 2-layer feed-forward neural network is used to combine the scores, as well as two binary features that indicate whether all the cells in this column are numeric values or not. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning to compose neural networks for question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Bootstrapping semantic parsers from conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Empirical Methods in Natural Language Processing</title>
		<meeting>Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Empirical Methods in Natural Language Processing</title>
		<meeting>Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Open question answering over curated and extracted knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1156" to="1165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Uncertainty reduction as a measure of cognitive load in sentence comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Stefan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Topics in Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Uncertainty about the rest of the sentence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Hale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Experiments with interactive question-answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanda</forename><surname>Harabagiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Hickl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Moldovan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Association for Computational Linguistics</title>
		<meeting>the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Overview of the trec 2006 ciqa task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGIR Forum</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="107" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Expectation-based syntactic comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Levy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Neural symbolic machines: Learning semantic parsers on Freebase with weak supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><forename type="middle">D</forename><surname>Forbus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ni</forename><surname>Lao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning executable semantic parsers for natural language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="68" to="76" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Simpler context-dependent logical forms via model projections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reginald</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panupong</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Association for Computational Linguistics</title>
		<meeting>the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deep learning with dynamic computation graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moshe</forename><surname>Looks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Herreshoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Delesley</forename><surname>Hutchins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Norvig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations</title>
		<meeting>the International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning a natural language interface with neural programmer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations</title>
		<meeting>the International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Austin</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Waleed</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonios</forename><surname>Anastasopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Clothiaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cynthia</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Garrette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingpeng</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adhiguna</forename><surname>Kuncoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaurav</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaitanya</forename><surname>Malaviya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuke</forename><surname>Oda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naomi</forename><surname>Saphra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.03980</idno>
		<title level="m">Swabha Swayamdipta, and Pengcheng Yin. 2017. DyNet: The dynamic neural network toolkit</title>
		<imprint/>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Compositional semantic parsing on semi-structured tables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panupong</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Association for Computational Linguistics</title>
		<meeting>the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Maximum margin reward networks for learning from explicit and implicit supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoruo</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Manuscript Submitted for Publication</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">GloVe: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Empirical Methods in Natural Language Processing</title>
		<meeting>Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Max-margin Markov networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Taskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daphne</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Advances in Neural Information Processing Systems</title>
		<meeting>Advances in Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Large margin methods for structured and interdependent output variables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Tsochantaridis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasemin</forename><surname>Altun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1453" to="1484" />
			<date type="published" when="2005-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Simple statistical gradientfollowing algorithms for connectionist reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ronald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="229" to="256" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Semantic parsing via staged query graph generation: Question answering with knowledge base</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1321" to="1331" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The value of semantic parse labeling for knowledge base question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingwei</forename><surname>Meek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jina</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Suh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="201" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning context-dependent mappings from sentences to logical form</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Association for Computational Linguistics</title>
		<meeting>the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
