<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:15+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">WebChild 2.0 : Fine-Grained Commonsense Knowledge Distillation</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niket</forename><surname>Tandon</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>De Melo</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Allen Institute for Artificial Intelligence Seattle</orgName>
								<address>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Max Planck Institute for Informatics Saarbrücken</orgName>
								<orgName type="institution">Rutgers University Piscataway</orgName>
								<address>
									<region>NJ</region>
									<country>USA, Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">WebChild 2.0 : Fine-Grained Commonsense Knowledge Distillation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of ACL 2017, System Demonstrations</title>
						<meeting>ACL 2017, System Demonstrations <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="115" to="120"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-4020</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Despite important progress in the area of intelligent systems, most such systems still lack commonsense knowledge that appears crucial for enabling smarter, more human-like decisions. In this paper, we present a system based on a series of algorithms to distill fine-grained disam-biguated commonsense knowledge from massive amounts of text. Our WebChild 2.0 knowledge base is one of the largest commonsense knowledge bases available, describing over 2 million disambiguated concepts and activities, connected by over 18 million assertions.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>With the continued advances in natural language processing and artificial intelligence, the general public is increasingly coming to expect that sys- tems exhibit what may be considered intelligent behavior. While machine learning allows us to learn models exploiting increasingly subtle pat- terns in data, our systems still lack more abstract, generic forms of commonsense knowledge. Exam- ples of such knowledge include the fact that fire causes heat, the property of ice being cold, as well as relationships such as that a bicycle is gener- ally slower than a car. Previous work in this area has mostly relied on handcrafted or crowdsourced data, consisting of ambiguous assertions, and lack- ing multimodal data. The seminal work on Con- ceptNet ( <ref type="bibr" target="#b1">Havasi et al., 2007)</ref>, for instance, relied on crowdsourcing to obtain an important collec- tion of commonsense data. However, it conflates different senses of ambiguous words (e.g., "hot" in the sense of temperature vs. "hot" in the sense of being trendy). It also lacks fine-grained details such as specific kinds of properties, comparisons between objects, and detailed knowledge of activ- ities. We attempt to fill these significant gaps.</p><p>This paper presents automated methods target- ing the acquisition of large-scale, semantically organized commonsense knowledge. This goal poses challenges because commonsense knowl- edge is: (i) implicit and sparse, as humans tend not to explicitly express the obvious, (ii) multi- modal, as it is spread across textual and visual sources, (iii) affected by reporting bias, as uncom- mon facts are reported disproportionally, and (iv) context dependent, which implies, among other things, that at an abstract level it is perhaps best described as merely holding with a certain con- fidence. Prior state-of-the-art methods to acquire commonsense are either not automated or based on shallow representations. Thus, they cannot au- tomatically produce large-scale, semantically or- ganized commonsense knowledge.</p><p>To achieve this challenging goal, we divide the problem space into three research directions.</p><p>• Properties of objects: acquisition of properties like hasSize, hasShape, etc. We develop a transductive approach to compile semanti- cally organized properties.</p><p>• Relationships between objects: acquisition of relations like largerThan, partOf, memberOf, etc. We develop a linear- programming based method to compile com- parative relations, and, we further develop a method based on statistical and logical infer- ence to compile part-whole relations.</p><p>• Their interactions: acquisition of knowledge about activities such as drive a car, park a car, etc., with expressive frame based representa- tion including temporal and spatial attributes. For this, our Knowlywood approach is based on semantic parsing and probabilistic graphi- cal models to compile activity knowledge.</p><p>Together, these methods result in the construc- tion of a large, clean and semantically organized Commonsense Knowledge Base that we call the WebChild 2.0 knowledge base.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Web-Scale Fact Extraction</head><p>Our framework consists of two parts. First, we rely on massive amounts of text to extract substan- tial amounts of raw extractions. Subsequently, in Section 3, we will present a series of algorithms to distill fine-grained disambiguated knowledge from raw extractions of this sort. For details on the input dataset leading to raw extractions, refer to the original publications, cited through each sub- section in Section 3.</p><p>Pattern-Based Information Extraction. For knowledge acquisition, it is well-known that one can attempt to induce patterns based on matches of seed facts, and then use pattern matches to mine new knowledge. Unfortunately, this bootstrapping approach suffers from significant noise a) when using a very large number of seeds, and b) when applied to large Web-scale data <ref type="bibr" target="#b5">(Tandon et al., 2011</ref>), which appears necessary to mine adequate amounts of training data. Specifically, for many of our extractions, Google's large Web N-Gram dataset, which provides Web-scale data. Addition- ally, many of our experiments use a large subset of ConceptNet as seed facts, resulting in a seed set that is many orders of magnitude larger than the typical set of perhaps 10 seeds used in most other bootstrapped information extraction systems. This problem is exacerbated by the fact that we are aim- ing at commonsense knowledge, which is not typ- ically expressed using explicit relational phrases. We thus devise a custom bootstrapping approach designed to minimize noise when applied to Web- scale data.</p><p>We assume that we have a set of relations R, a set of seed facts S(r) for a given r ∈ R, as well as a domain(r) and range(r), specified manually to provide the domain and range of a given r as its type signature. For pattern induction, we look for co-occurrences of words in the seed facts within the n-grams data (for n = 3,4,5). Any match is converted into a pattern based on the words be- tween the two occurrences, e.g. "that apple is red" would become "&lt;x&gt; is &lt;y&gt;".</p><p>Pattern Scoring. The acquired patterns are still rather noisy and moreover very numerous, due to our large set of seeds. To score the reliability of patterns, we invoke a ranking function that re- wards patterns with high distinct seed support but also discounts patterns that occur across multiple dissimilar relations <ref type="bibr" target="#b5">(Tandon et al., 2011</ref>). The in- tuition is that a good pattern should match many of the seed facts (reward function), but must be dis- counted at matching too many relations (discount function). As, e.g., the pattern "&lt;x&gt; and &lt;y&gt;" is unreliable because it matches seeds from too many relations.</p><p>This discount must be softened when the pat- tern matches related relations. To allow for this, we first define a relatedness score between rela- tions. We can either provide these scores man- ually, or consider Jaccard overlap statistics com- puted directly from the seed assertion data. Let p be a candidate pattern and r ∈ R be the rela- tion under consideration. We define |S(r, p)| as the number of distinct seeds s ∈ S(r) under the relation r that p matches. We then define the dis- count score of the pattern p for relation r as:</p><formula xml:id="formula_0">φ(r, p) = r ∈R,r =r |S(r, p)| |S(r)| −(1−sim(r, r )) |S(r , p)| |S(r )|</formula><p>where sim(r, r ) is the similarity between relations r and r . The final score is a combination of the discount score φ(r, p) and the judiciously calcu- lated reward score. At the end, we choose the top- k ranked patterns as the relevant patterns for the extraction phase.</p><p>Assertion Extraction. We apply the chosen pat- terns to find new occurrences in our (Google Web N-grams) data. For instance, "&lt;x&gt; is &lt;y&gt;" could match "the sun is bright", yielding ("sun", "bright") as an assertion for the hasProperty re- lation. To filter out noise from these candidate as- sertions, we check if the extracted words match the required domain and range specification for the relation, using WordNet's hypernym taxon- omy. Finally, we rank the candidate assertions analogously to the candidate patterns, but treating the patterns as seeds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Distilling Fine-Grained Knowledge</head><p>The techniques described above provide a sizable set of extractions that serve as the the basis for WebChild 2.0. Next, we consider a family of al- gorithms that take raw extractions of this form and exploit them to distill detailed fine-grained knowl- edge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Fine-Grained Properties</head><p>The first algorithm we consider ( <ref type="bibr" target="#b4">Tandon et al., 2014a</ref>) aims at compiling a large and clean set of fine-grained commonsense properties, connect- ing noun senses with adjective senses by a va- riety of relations. In contrast to prior work that only dealt with a generic hasProperty relation, we use 19 different (sub-)relations such as hasShape, hasSize, hasTaste, hasAbility, evokesEmotion, etc. This list is systematically derived from WordNet based on its attribute information.</p><p>Moreover, our goal is to distinguish the spe- cific senses (e.g. green 2 a , or green#a#2 refers to the second sense of WordNet adjective green) of the arguments of these relations as well. For ex- ample, for plant hasProperty green, there are two competing interpretations with very different meanings: industrial-plant hasQuality green- environmental vs. botanical-plant hasColor green-color.</p><p>We start out by constructing the range and do- main of the property relations with a small set of seed examples. Such seeds would normally be gathered manually, but in our work, we ob- served that an ensemble of two very different, au- tomated, and noisy sources can also produce high- quality seeds. We construct a graph where the nodes are words and word senses and the edge weights are computed based on taxonomic and distributional similarities (these edge weights are depicted in <ref type="figure" target="#fig_0">Figure 1</ref>). We then use a judiciously designed form of label propagation <ref type="bibr" target="#b2">(Talukdar and Crammer, 2009</ref>) to learn the domain set, the range set, and the extension of such relations, at large scale and in terms of specific word senses. An example of a range graph is given in <ref type="figure" target="#fig_0">Figure 1</ref>. The highlighted seed nodes mark specific senses of words as pertaining to a specific relation (e.g., hasTemperature). Via label propagation, we can infer such information for additional nodes, such as the "pleasantly cold" sense of "crisp" (for the range of the relation), but not other irrelevant senses of "crisp". The same label propagation technique can then also be applied to infer entire relation tuples.</p><p>Our graph-based semi-supervised approach is generic enough to extract any type of fine-grained sub-property or attribute, for which we need only a few seeds to begin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Comparative Knowledge</head><p>The second algorithm ( <ref type="bibr" target="#b6">Tandon et al., 2014b</ref>) aims at extracting and organizing large-scale compar- ative commonsense knowledge. Prior to our work, semantically organized comparative com- monsense knowledge had not been studied or compiled before.</p><p>We first gather a set of new raw extractions us- ing patterns targeting comparisons. These include the word "to be" followed by comparative forms of adjectives (e.g. "smaller than", "more educated than"). While we again follow a Web-scale ex- traction strategy as in Section 2, note that these patterns are generic in the sense that they cover all words identified as adjectives. Thus, this con- stitutes a form of open information extraction for comparative knowledge.</p><p>The next step is to refine and extend these ex- tractions. The constituents of a comparative asser- tion are strongly related (e.g., car, fast, and bike in car faster than bike); our method builds upon this observation to jointly disambiguate and con- nect these assertions, while inferring additional ones. Disambiguation is important because rela- tionships such as "richer than" could refer to fi- nancial assets or to calories. The joint algorithm is also necessary to exploit dependencies and transi- tivity between extractions (e.g., "is smaller than", "is larger than", "is not bigger than"), with the goal of validating input extractions as well as in- ferring new relationships. This is achieved via a custom Integer Linear Program with constraints accounting for the coherence and logical consis- tency of the interpretation .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Detailed Part-Whole Relationships</head><p>The third algorithm ( ) focuses on extracting and organizing large- scale part-whole commonsense knowledge. In contrast to prior work, our algorithm dis- tinguishes physicalPartOf (e.g., wheel physicalPartOf bike), memberOf (e.g., cyclist memberOf team), and substanceOf (e.g., rubber substanceOf wheel), and the arguments are disambiguated. We also estimate cardinality, describing the typical number of parts in a whole, and visibility information, i.e., whether the part can be perceived visually.</p><p>We again rely on raw assertions extracted from text, but distill these via statistical scoring com- bined with logical inference to account for tran-  sitivity and inheritance of assertions (via Word- Net's hypernym hierarchy). To estimate visibil- ity, we verify the assertions in images (we call this quasi-visual verification). Quasi-visual verifi- cation leverages the best of text-only verification (which is inaccurate due to reporting bias), and visual-only verification (which is inaccurate due to the object detectors' inaccuracies).</p><p>Our method generalizes to any relation with finer-grained sub-relations.</p><p>This spe- cific multimodal approach generalizes to any commonsense relation that has multiple sub- relations and is verifiable in images, e.g., hasLocation relation (with sub-relations hasLocationAbove/Below, etc.).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Activity Knowledge</head><p>The fourth algorithm ( <ref type="bibr" target="#b3">Tandon et al., 2015</ref>) is a novel method for a new task to extract and or- ganize semantic frames of human activities, to- gether with their visual content. The Knowl- ywood pipeline, illustrated in <ref type="figure" target="#fig_1">Figure 2</ref>, distills such knowledge from raw text, rather than start- ing with the extractions from Section 2. In par- ticular, we acquire knowledge about human ac- tivities from narrative text, focusing in particular on movie scripts, which are structured in terms of scenes, and provide descriptions of scene set- tings/locations, speakers, etc. Moreover, when scripts come with representative images or time points in the movie, it is possible to align a scene description with the actual visual contents of the movie. The main difficulty, however, is that all this rich contents in movie scripts is merely in textual form -still far from structured KB representation. Our method considers joint semantic role la- beling and word sense disambiguation for pars- ing these scripts to generate candidate items for the activity frames. In particular, we rely on  a semantic parsing like approach that fills the slot values of such frames (activity type, loca- tion, participants, etc.), while also jointly disam- biguating the verb and the slot fillers with re- spect to WordNet. This is achieved by comput- ing strong priors that are fed into an integer lin- ear program. In the example in <ref type="table" target="#tab_0">Table 1</ref>, we see how this process also jointly relies on information from VerbNet. For the WordNet verb sense num- ber 2: shoot#2 (killing), VerbNet provides a role restriction Agent.animate V Patient.animate PP Instrument.solid, where animate refers to living beings, as opposed to inanimate objects. This allows us to infer that this shoot#2 sense is not compatible with the argument "the video", which is not animate. This way, we can disqual- ify the incorrect interpretation of "shoot".</p><p>We then perform inference using probabilistic graphical models that can encode joint dependen- cies among different candidate activity frames. Unlike the previous contribution, this method goes beyond disambiguation of the arguments of an assertion; and, additionally assign roles to these arguments. A final taxonomy construction step groups together similar activity frames and forms a hierarchy of activities. For movie scripts with aligned movie data, we associate the correspond video key frames with our activities. <ref type="figure" target="#fig_2">Figure 3</ref> pro- vides an example of the resulting activity frames.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and Demonstration</head><p>Together, these methods have been used to create the WebChild 2.0 KB, which is one of the largest commonsense knowledge bases available, describ- ing over 2 million disambiguated concepts and ac- tivities, connected by over 18 million assertions.</p><p>Among this data, we highlight the Knowlywood pipeline that produced 964,758 unique activity in- stances, grouped into 505,788 activity synsets. In addition to the edges mentioned above, we also obtain 581, <ref type="bibr">438 location, 71,346 time, and 5,196,156</ref> participant attribute entries over all activities. This is much larger than other com- monsense KBs such as ConceptNet, refer <ref type="table" target="#tab_1">Table 2</ref>.</p><p>The WebChild 2.0 KB is bigger and richer than any other automatically constructed commonsense KB. It can also be viewed as an extended Word- Net (comprising not just words, but also activi- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>From a resource perspective, people looking for commonsense knowledge bases had few options available before our construction of the WebChild 2.0 knowledge base. The available alternatives do not offer the same level of size, richness and semantic rigor over multiple modalities. In on- going work, we are developing improved algo- rithms to prune noisy extractions, and computing the weights for the inference steps to distill cleaner knowledge.</p><p>WebChild 2.0 has already been effective in providing background knowledge to applications such as visual question answering ( <ref type="bibr" target="#b7">Wang et al., 2016)</ref> and neural relation prediction <ref type="bibr" target="#b0">(Chen et al., 2016</ref>). The WebChild 2.0 data is freely down- loadable at http://www.mpi-inf.mpg. de/yago-naga/webchild/, and browsable at https://gate.d5.mpi-inf.mpg.de/ webchild/.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Inferring range of hasTemperature. Violet nodes indicate noisy candidate range. Starting with seeds (yellow single outlined), the algorithm enforces that similar nodes have similar labels, and infers range (yellow double outlined). For details on edge weights, see (Tandon et al., 2014a).</figDesc><graphic url="image-1.png" coords="4,140.03,62.80,317.47,164.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Knowlywood pipeline to extract activity frames.</figDesc><graphic url="image-2.png" coords="4,72.00,290.02,453.54,107.01" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Example of an activity frame</figDesc><graphic url="image-3.png" coords="5,128.69,62.81,340.15,191.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: WebChild 2.0 browser results for mountain. It presents semantic knowledge for concepts, comparisons, and activities. For more examples, visit gate.d5.mpi-inf.mpg.de/webchild</figDesc><graphic url="image-4.png" coords="6,117.36,62.81,362.84,226.77" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 : Semantic Parse Example</head><label>1</label><figDesc></figDesc><table>Input 
WordNet 
VerbNet 
Expected Frame 
Mapping 
Mapping 

the man 
man#1 
Agent . animate 
Agent: man#1 
begin to shoot 
shoot#4 
shoot#vn#3 
Action: shoot#4 
a video 
video#1 
Patient . solid 
Patient:video#1 
in 
in 
PP . in 
the moving bus 
bus#1 
NP . Location . solid 
Location: moving bus#1 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 2 : Knowlywood Coverage and Precision: manual assessments over a sample of 100 activity frames</head><label>2</label><figDesc></figDesc><table>Source 
#Scenes 
#Unique 
Parent 
Parti. 
Prev 
Next 
Loc. 
Time 
Avg. 
Activities 

Movie scripts 
148,296 
244,789 
0.87 
0.86 
0.78 
0.85 
0.79 
0.79 
0.84 
TV series 
886,724 
565,394 
0.89 
0.85 
0.81 
0.84 
0.82 
0.84 
0.86 
Sitcoms 
286,266 
200,550 
0.88 
0.85 
0.81 
0.87 
0.81 
0.83 
0.87 
Novels 
383,795 
137,365 
0.84 
0.84 
0.78 
0.88 
0.85 
0.72 
0.84 
Crowdsrc. 
3,701 
9,575 
0.82 
0.91 
0.91 
0.87 
0.74 
0.40 
0.86 

Knowlywood 
1,708,782 
964,758 
0.87 
0.86 
0.84 
0.85 
0.78 
0.84 
0.85±0.01 

ConceptNet 5 
-
4,757 
0.15 
0.81 
0.92 
0.91 
0.33 
N/A 
0.46±0.02 

</table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Webbrain: Joint neural learning of large-scale commonsense knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaqiang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niket</forename><surname>Tandon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><forename type="middle">Darwis</forename><surname>Hariman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>De Melo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ISWC</title>
		<meeting>ISWC</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Conceptnet 3: a flexible, multilingual semantic network for common sense knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catherine</forename><surname>Havasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Speer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Alonso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of RANLP</title>
		<meeting>RANLP</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">New regularized algorithms for transductive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><forename type="middle">P</forename><surname>Talukdar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ECML/PKDD</title>
		<meeting>ECML/PKDD</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Knowlywood: Mining activity knowledge from hollywood narratives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niket</forename><surname>Tandon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abir</forename><surname>Gerard De Melo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CIKM</title>
		<meeting>CIKM</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Webchild: Harvesting and organizing commonsense knowledge from the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niket</forename><surname>Tandon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Gerard De Melo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Suchanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WSDM</title>
		<meeting>WSDM</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deriving a web-scale commonsense fact database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niket</forename><surname>Tandon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Gerard De Melo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Commonsense in parts: Mining part-whole relations from the web and image tags</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niket</forename><surname>Tandon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><forename type="middle">De</forename><surname>Melo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI. Niket Tandon, Charles Hariman, Jacopo Urbani</title>
		<meeting>AAAI. Niket Tandon, Charles Hariman, Jacopo Urbani<address><addrLine>Anna Rohrbach, Marcus Rohrbach, and Gerhard Weikum</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Proceedings of AAAI</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">FVQA: fact-based visual question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Van Den Hengel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><forename type="middle">R</forename><surname>Dick</surname></persName>
		</author>
		<idno>CoRR abs/1606.05433</idno>
		<ptr target="http://arxiv.org/abs/1606.05433" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
