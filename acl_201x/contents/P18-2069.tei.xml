<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:17+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Large-Scale Multi-Domain Belief Tracking with Knowledge Sharing</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 15-20, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Osman</forename><surname>Ramadan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Engineering</orgName>
								<orgName type="institution">University of Cambridge</orgName>
								<address>
									<country key="GB">U.K</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paweł</forename><surname>Budzianowski</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Engineering</orgName>
								<orgName type="institution">University of Cambridge</orgName>
								<address>
									<country key="GB">U.K</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><forename type="middle">Gaši´</forename><surname>Gaši´c</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Engineering</orgName>
								<orgName type="institution">University of Cambridge</orgName>
								<address>
									<country key="GB">U.K</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Large-Scale Multi-Domain Belief Tracking with Knowledge Sharing</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="volume">432</biblScope>
							<biblScope unit="page" from="432" to="437"/>
							<date type="published">July 15-20, 2018. 2018</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Robust dialogue belief tracking is a key component in maintaining good quality dialogue systems. The tasks that dialogue systems are trying to solve are becoming increasingly complex, requiring scalabil-ity to multi-domain, semantically rich dialogues. However, most current approaches have difficulty scaling up with domains because of the dependency of the model parameters on the dialogue ontology. In this paper, a novel approach is introduced that fully utilizes semantic similarity between dialogue utterances and the ontol-ogy terms, allowing the information to be shared across domains. The evaluation is performed on a recently collected multi-domain dialogues dataset, one order of magnitude larger than currently available corpora. Our model demonstrates great capability in handling multi-domain dialogues, simultaneously outperforming existing state-of-the-art models in single-domain dialogue tracking tasks.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Spoken Dialogue Systems (SDS) are computer programs that can hold a conversation with a hu- man. These can be task-based systems that help the user achieve specific goals, e.g. finding and booking hotels or restaurants. In order for the SDS to infer the user goals/intentions during the conversation, its Belief Tracking (BT) component maintains a distribution of states, called a belief state, across dialogue turns ( <ref type="bibr" target="#b18">Young et al., 2010)</ref>. The belief state is used by the system to take ac- tions in each turn until the conversation is con- cluded and the user goal is achieved. In order to extract these belief states from the conversation, traditional approaches use a Spoken Language Understanding (SLU) unit that utilizes a seman- tic dictionary to hold all the key terms, rephras- ings and alternative mentions of a belief state. The SLU then delexicalises each turn using this seman- tic dictionary, before it passes it to the BT compo- nent ( <ref type="bibr" target="#b12">Wang and Lemon, 2013;</ref><ref type="bibr" target="#b2">Henderson et al., 2014b;</ref><ref type="bibr" target="#b16">Williams, 2014;</ref><ref type="bibr" target="#b19">Zilka and Jurcicek, 2015;</ref><ref type="bibr" target="#b9">Perez and Liu, 2016;</ref><ref type="bibr" target="#b10">Rastogi et al., 2017)</ref>. How- ever, this approach is not scalable to multi-domain dialogues because of the effort required to de- fine a semantic dictionary for each domain. More advanced approaches, such as the Neural Belief Tracker (NBT), use word embeddings to alleviate the need for delexicalisation and combine the SLU and BT into one unit, mapping directly from turns to belief states . Nevertheless, the NBT model does not tackle the problem of mixing different domains in a conversation. More- over, as each slot is trained independently without sharing information between different slots, scal- ing such approaches to large multi-domain sys- tems is greatly hindered.</p><p>In this paper, we propose a model that jointly identifies the domain and tracks the belief states corresponding to that domain. It uses semantic similarity between ontology terms and turn utterances to allow for parameter sharing between different slots across domains and within a single domain. In addition, the model parameters are independent of the ontology/belief states, thus the dimensionality of the parameters does not increase with the size of the ontology, making the model practically feasible to deploy in multi- domain environments without any modifications. Finally, we introduce a new, large-scale corpora of natural, human-human conversations providing new possibilities to train complex, neural-based models. Our model systematically improves upon state-of-the-art neural approaches both in single and multi-domain conversations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>The belief states of the BT are defined based on an ontology -the structured representation of the database which contains entities the system can talk about. The ontology defines the terms over which the distribution is to be tracked in the dialogue. This ontology is constructed in terms of slots and values in a single domain set- ting. Or, alternatively, in terms of domains, slots and values in a multi-domain environment. Each domain consists of multiple slots and each slot contains several values, e.g. domain=hotel, slot=price, value=expensive. In each turn, the BT fits a distribution over the values of each slot in each domain, and a none value is added to each slot to indicate if the slot is not mentioned so that the distribution sums up to 1. The BT then passes these states to the Policy Op- timization unit as full probability distributions to take actions. This allows robustness to noisy envi- ronments ( <ref type="bibr" target="#b18">Young et al., 2010)</ref>. The larger the on- tology, the more flexible and multi-purposed the system is, but the harder it is to train and maintain a good quality BT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Related Work</head><p>In recent years, a plethora of research has been generated on belief tracking ( <ref type="bibr" target="#b15">Williams et al., 2016)</ref>. For the purposes of this paper, two pre- viously proposed models are particularly relevant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Neural Belief Tracker (NBT)</head><p>The main idea behind the NBT ) is to use semantically specialized pre- trained word embeddings to encode the user ut- terance, the system act and the candidate slots and values taken from the ontology. These are fed to semantic decoding and context modeling modules that apply a three-way gating mechanism and pass the output to a non-linear classifier layer to pro- duce a distribution over the values for each slot. It uses a simple update rule, p(s t ) = βp(s t−1 ) + λy, where p(s t ) is the belief state at time step t, y is the output of the binary decision maker of the NBT and β and λ are tunable parameters.</p><p>The NBT leverages semantic information from the word embeddings to resolve lexi- cal/morphological ambiguity and maximize the shared parameters across the values of each slot. However, it only applies to a single domain and does not share parameters across slots.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Multi-domain Dialogue State Tracking</head><p>Recently, <ref type="bibr" target="#b10">Rastogi et al. (2017)</ref> proposed a multi- domain approach using delexicalized utterances fed to a two layer stacked bi-directional GRU net- work to extract features from the user and the sys- tem utterances. These, combined with the candi- date slots and values, are passed to a feed-forward neural network with a softmax in the last layer. The candidate set fed to the network consists of the selected candidates from the previous turn and candidates from the ontology to a limit K, which restricts the maximum size of the chosen set. Con- sequently, the model does not need an ad-hoc be- lief state update mechanism like in the NBT.</p><p>The parameters of the GRU network are de- fined for the domain, whereas the parameters of the feed-forward network are defined per slot, al- lowing transfer learning across different domains. However, the model relies on delexicalization to extract the features, which limits the performance of the BT, as it does not scale to the rich variety of the language. Moreover, the number of parameters increases with the number of slots.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Method</head><p>The core idea is to leverage semantic similarities between the utterances and ontology terms to com- pute the belief state distribution. In this way, the model parameters only learn to model the interac- tions between turn utterances and ontology terms in the semantic space, rather than the mapping from utterances to states. Consequently, informa- tion is shared between both slots and across do- mains. Additionally, the number of parameters does not increase with the ontology size. Do- main tracking is considered as a separate task but is learned jointly with the belief state tracking of the slots and values. The proposed model uses semantically specialized pre-trained word embed- dings ( <ref type="bibr" target="#b14">Wieting et al., 2015)</ref>. To encode the user and system utterances, we employed 7 indepen- dent bi-directional LSTMs ( <ref type="bibr" target="#b0">Graves and Schmidhuber, 2005</ref>). Three of them are used to encode the system utterance for domain, slot and value tracking respectively. Similarly, three Bi-LSTMs encode the user utterance while and the last one is used to track the user affirmation. A variant of the CNNs as a feature extractor, similar to the one used in the NBT-CNN ) is also employed.  <ref type="bibr" target="#b5">(Kim, 2014;</ref><ref type="bibr" target="#b3">Kalchbrenner et al., 2014</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Domain Tracking</head><p>Figure 1 presents the system architecture with two bi-directional LSTM networks as information en- coders running over the word embeddings of the user and system utterances. The last hidden states of the forward and backward layers are concate- nated to produce h d usr , h d sys of size L for the user and system utterances respectively. In the second variant of the model, CNNs are used to produce these vectors <ref type="bibr" target="#b5">(Kim, 2014;</ref><ref type="bibr" target="#b3">Kalchbrenner et al., 2014</ref>). To detect the presence of the domain in the dialogue turn, element-wise multiplication is used as a similarity metric between the hidden states and the ontology embeddings of the domain:</p><formula xml:id="formula_0">d k = h d k tanh(W d e d + b d ),</formula><note type="other">where k ∈ {usr, sys}, e d is the embedding vector of the domain and W d ∈ R L×D</note><p>transforms the domain word embeddings of dimension D to the hidden representation. The information about se- mantic similarity is held by d usr and d sys , which are fed to a non-linear layer to output a binary de- cision:</p><formula xml:id="formula_1">P t (d) = σ(w d {d usr ⊕ d sys } + b d ),</formula><p>where w d ∈ R 2L and b d are learnable parameters that map the semantic similarity to a belief state probability P t (d) of a domain d at a turn t.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Candidate Slots and Values Tracking</head><p>Slots and values are tracked using a similar archi- tecture as for domain tracking <ref type="figure" target="#fig_0">(Figure 1)</ref>. How- ever, to correctly model the context of the system- user dialogue at each turn, three different cases are considered when computing the similarity vectors:</p><p>1. Inform: The user is informing the system about his/her goal, e.g. 'I am looking for a restaurant that serves Turkish food'. 2. Request: The system is requesting informa- tion by asking the user about the value of a specific slot. If the system utterance is: 'When do you want the taxi to arrive?' and the user answers with '19:30'. 3. Confirm: The system wants to confirm in- formation about the value of a specific slot. If the system asked: 'Would you like free park- ing?', the user can either affirm positively or negatively. The model detects the user affir- mation, using a separate bi-directional LSTM or CNN to output h a usr . The three cases are modelled as following:</p><formula xml:id="formula_2">y s,v inf = w inf {s usr ⊕ v usr } + b inf , y s,v req = w req {s sys ⊕ v usr } + b req , y s,v af = w af {s sys ⊕ v sys ⊕ h a usr } + b af ,</formula><p>where s k , v k for k ∈ {usr, sys} represent seman- tic similarity between the user and system utter- ances and the ontology slot and value terms re- spectively computed as shown in <ref type="figure" target="#fig_0">Figure 1</ref>, and w and b are learnable parameters. The distribution over the values of slot s in do- main d at turn t can be computed by summing the unscaled states, y inf , y req and y af for each value v in s, and applying a softmax to normalize the distribution:</p><formula xml:id="formula_3">P t (s, v) = softmax(y s,v inf + y s,v req + y s,v af ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Belief State Update</head><p>Since dialogue systems in the real-world operate in noisy environments, a robust BT should utilize the flow of the conversation to reduce the uncer- tainty in the belief state distribution. This can be achieved by passing the output of the deci- sion maker, at each turn, as an input to an RNN that runs over the dialogue turns as shown in <ref type="figure" target="#fig_0">Fig- ure 1</ref>, which allows the gradients to be propagated across turns. This alleviates the problem of tun- ing hyper-parameters for rule-based updates. To avoid the vanishing gradient problem, three net- works were tested: a simple RNN, an RNN with a memory cell ( <ref type="bibr" target="#b1">Henderson et al., 2014a</ref>) and a LSTM. The RNN with a memory cell proved to give the best results. In addition to the fact that it reduces the vanishing gradient problem, this vari- ant is less complex than an LSTM, which makes training easier. Furthermore, a variant of RNN used for domain tracking has all its weights of the form: W i = α i I, where α i is a distinct learn- able parameter for hidden, memory and previous state layers and I is the identity matrix. Similarly, weights of the RNN used to track the slots and val- ues is of the form: W j = γ j I + λ j (1 − I), where γ j and λ j are the learnable parameters. These two variants of RNN are a combination of <ref type="bibr" target="#b1">Henderson et al. (2014a)</ref> and Mrkvsi´cMrkvsi´c and Vuli´cVuli´c (2018) previ- ous works. The output is P 1:T (d) and P 1:T (s, v), which represents the joint probability distribution of the domains and slots and values respectively over the complete dialogue. Combining these to- gether produces the full belief state distribution of the dialogue:</p><formula xml:id="formula_4">P 1:T (d, s, v) = P 1:T (d)P 1:T (s, v).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Training Criteria</head><p>Domain tracking and slots and values tracking are trained disjointly. Belief state labels for each turn are split into domains and slots and values. Thanks to the disjoint training, the learning of slot and value belief states are not restricted to a specific domain. Therefore, the model shares the knowl- edge of slots and values across different domains. The loss function for the domain tracking is:</p><formula xml:id="formula_5">L d = − N n=1 d∈D t n (d)logP n 1:T (d),</formula><p>where d is a vector of domains over the dialogue, t n (d) is the domain label for the dialogue n and N is the number of dialogues. Similarly, the loss function for the slots and values tracking is:</p><formula xml:id="formula_6">L s,v = − N n=1 s,v∈S,V t n (s, v)logP n 1:T (s, v),</formula><p>where s and v are vectors of slots and values over the dialogue and t n (s, v) is the joint label vector for the dialogue n.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Datasets and Baselines</head><p>Neural approaches to statistical dialogue develop- ment, especially in a task-oriented paradigm, are greatly hindered by the lack of large scale datasets. That is why, following the Wizard-of-Oz (WOZ) approach <ref type="bibr" target="#b4">(Kelley, 1984;</ref>), we ran text-based multi-domain corpus data collec- tion scheme through Amazon MTurk. The main goal of the data collection was to acquire human- human conversations between a tourist visiting a city and a clerk from an information center. At the beginning of each dialogue the user (visitor) was given explicit instructions about the goal to ful- fill, which often spanned multiple domains. The task of the system (wizard) is to assist a visitor having an access to databases over domains. The WOZ paradigm allowed us to obtain natural and semantically rich multi-topic dialogues spanning over multiple domains such as hotels, attractions, restaurants, booking trains or taxis. The dialogues cover from 1 up to 5 domains per dialogue greatly varying in length and complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Data Structure</head><p>The and wizards respectively. The combined ontol- ogy consists of 5 domains, 27 slots and 663 val- ues making it significantly larger than observed in other datasets. To enforce reproducibility of re- sults, we distribute the corpus with a pre-specified train/test/development random split. The test and development sets contain 1k examples each. Each dialogues consists of a goal, user and system ut- terances and a belief state per turn. The data and model is publicly available. 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Evaluation</head><p>We also used the extended WOZ 2.0 dataset ). 2 WOZ2 dataset consists of 1200 sin- gle topic dialogues constrained to the restaurant domain. All the weights were initialised using nor- mal distribution of zero mean and unit variance and biases were initialised to zero. ADAM op- timizer ( <ref type="bibr" target="#b6">Kingma and Ba, 2014</ref>) (with 64 batch size) is used to train all the models for 600 epochs. Dropout ( <ref type="bibr" target="#b11">Srivastava et al., 2014</ref>) was used for reg- ularisation (50% dropout rate on all the intermedi- ate representations). For each of the two datasets we compare our proposed architecture (using ei- ther Bi-LSTM or CNN as encoders) to the NBT model 3 ).  This is because the dialogues in the new dataset are richer and more noisier, as a closer resem- blance to real environment dialogues. <ref type="table" target="#tab_2">Table 2</ref> presents the results on multi-domain di- alogues from the new dataset described in Sec- tion 5. To demonstrate the difficulty of the multi- domain belief tracking problem, values of a the- oretical baseline that samples the belief state uni- formly at random are also presented. Our model gracefully handles such a difficult task. In most of the cases, CNNs demonstrate better perfor- mance than Bi-LSTMs. We hypothesize that this comes from the effectiveness of extracting local and position-invariant features, which are crucial for semantic similarities <ref type="bibr" target="#b17">(Yin et al., 2017</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>In this paper, we proposed a new approach that tackles the issue of multi-domain belief tracking, such as model parameter scalability with the ontol- ogy size. Our model shows improved performance in single-domain tasks compared to the state-of- the-art NBT method. By exploiting semantic sim- ilarities between dialogue utterances and ontology terms, the model alleviates the need for ontology- dependent parameters and maximizes the amount of information shared between slots and across do- mains. In future, we intend to investigate introduc- ing new domains and ontology terms without fur- ther training thus performing zero-shot learning.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The proposed model architecture, using Bi-LSTMs as encoders. Other variants of the model use CNNs as feature extractors (Kim, 2014; Kalchbrenner et al., 2014).</figDesc><graphic url="image-1.png" coords="3,94.68,62.81,408.20,263.17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 shows</head><label>1</label><figDesc></figDesc><table>the performance of our model in 
tracking the belief state of single-domain dia-
logues, compared to the NBT-CNN variant of the 
NBT discussed in Section 3.1. Our model outper-
forms NBT in all the three slots and the joint goals 
for the two datasets. NBT previously achieved 
state-of-the-art results (Mrkši´Mrkši´c et al., 2017). More-
over, the performance of all models is worse on the 
new dataset for restaurant compared to WOZ 2.0. 

1 http://dialogue.mi.eng.cam.ac.uk/index.php/corpus/ 
2 Publicly available at https://mi.eng.cam.ac. 
uk/ ˜ nm480/woz_2.0.zip. 
3 Publicly available at https://github.com/ 
nmrksic/neural-belief-tracker. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>The overall F1 score and accuracy for the 
multi-domain dialogues test set. 4 

</table></figure>

			<note place="foot" n="4"> F1-score is computed by considering all the values in each slot of each domain as positive and the &quot;none&quot; state of the slot as negative.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors would like to thank Nikola Mrkši´Mrkši´c, Jacquie Rowe, the Cambridge Dialogue Systems Group and the ACL reviewers for their construc-tive feedback. Paweł Budzianowski is supported by EPSRC Council and Toshiba Research Eu-rope Ltd, Cambridge Research Laboratory. The data collection was funded through Google Fac-ulty Award.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Framewise phoneme classification with bidirectional lstm and other neural network architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5-6</biblScope>
			<biblScope unit="page" from="602" to="610" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Robust dialog state tracking using delexicalised recurrent neural networks and unsupervised adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blaise</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Spoken Language Technology Workshop (SLT)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="360" to="365" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Word-based dialog state tracking with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blaise</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL)</title>
		<meeting>the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="292" to="299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A convolutional neural network for modelling sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">An iterative design methodology for user-friendly natural language office information applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kelley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="26" to="41" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>ICLR</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Neural belief tracker: Data-driven dialogue state tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Mrkši´mrkši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diarmuid´odiarmuid´</forename><forename type="middle">Diarmuid´o</forename><surname>Séaghdha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Hsien</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blaise</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1777" to="1788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fully statistical neural belief tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Mrkvsi´cmrkvsi´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vuli´cvuli´c</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Dialog state tracking, a machine reading approach using memory network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.04052</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Heck</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.10224</idno>
		<title level="m">Scalable multi-domain dialogue state tracking</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A simple and generic belief tracking mechanism for the dialog state tracking challenge: On the believability of observed information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuoran</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Lemon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGDIAL 2013 Conference</title>
		<meeting>the SIGDIAL 2013 Conference</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="423" to="432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A networkbased end-to-end trainable task-oriented dialogue system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Tsung-Hsien Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Gaši´gaši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lina</forename><forename type="middle">M</forename><surname>Mrkši´mrkši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei-Hao</forename><surname>Rojas-Barahona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Ultes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Vandyke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings on EACL</title>
		<meeting>on EACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">From paraphrase database to compositional paraphrase model and back</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Wieting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Livescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="345" to="358" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The dialog state tracking challenge series: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Raux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Henderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dialogue &amp; Discourse</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="4" to="33" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Web-style ranking and slu combination for dialog state tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason D</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL)</title>
		<meeting>the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="282" to="291" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenpeng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katharina</forename><surname>Kann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.01923</idno>
		<title level="m">Comparative study of cnn and rnn for natural language processing</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The hidden information state model: A practical framework for pomdp-based spoken dialogue management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Gaši´gaši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Keizer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Mairesse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jost</forename><surname>Schatzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blaise</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="150" to="174" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Incremental lstm-based dialog state tracker</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Zilka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Jurcicek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automatic Speech Recognition and Understanding (ASRU), 2015 IEEE Workshop on. IEEE</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="757" to="762" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
