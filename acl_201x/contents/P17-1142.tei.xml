<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:41+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Combating Human Trafficking with Multimodal Deep Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edmund</forename><surname>Tong</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Zadeh</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cara</forename><surname>Jones</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Louis-Philippe</forename><surname>Morency</surname></persName>
						</author>
						<title level="a" type="main">Combating Human Trafficking with Multimodal Deep Models</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</title>
						<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1547" to="1556"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-1142</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Human trafficking is a global epidemic affecting millions of people across the planet.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Human trafficking "a crime that shames us all" <ref type="bibr" target="#b17">(UNODC, 2008)</ref>, has seen a steep rise in the United States since 2012. The number of cases reported rose from 3,279 in 2012 to 7,572 in 2016-more than doubling over the course of five years (Hot- line). Sex trafficking is a form of human trafficking, and is a global epidemic affecting millions of peo- ple each year <ref type="bibr" target="#b8">(McCarthy, 2014</ref>). Victims of sex trafficking are subjected to coercion, force, and con- trol, and are not able to ask for help. Put plainly, sex trafficking is modern-day slavery and is one of the top priorities of law enforcement agencies at all levels.</p><p>A major advertising ground for human traffickers is the World Wide Web. The Internet has brought * Authors contributed equally.</p><p>traffickers the ability to advertise online and has fostered the growth of numerous adult escort sites. Each day, there are tens of thousands of Internet advertisements posted in the United States and Canada that market commercial sex. Hiding among the noise of at-will adult escort ads are ads posted by sex traffickers. Often long undetected, traffick- ing rings and escort websites form a profit cycle that fuels the increase of both trafficking rings and escort websites.</p><p>For law enforcement, this presents a significant challenge: how should we identify advertisements that are associated with sex trafficking? Police have limited human and technical resources, and manually sifting through thousands of ads in the hopes of finding something suspicious is a poor use of those resources, even if they know what they are looking for. Leveraging state-of-the-art machine learning approaches in Natural Language Processing and computer vision to detect and re- port advertisements suspected of trafficking is the main focus of our work. In other words, we strive to find the victims and perpetrators of trafficking who hide in plain sight in the massive amounts of data online. By narrowing down the number of advertisements that law enforcement must sift through, we endeavor to provide a real opportunity for law enforcement to intervene in the lives of victims. However, there are non-trivial challenges facing this line of research:</p><p>Adversarial Environment. Human trafficking rings are aware that law enforcement monitors their online activity. Over the years, law enforcement officers have populated lists of keywords that fre- quently occur in trafficking advertisements. How- ever, these simplistic queries fail when traffickers use complex obfuscation. Traffickers, again aware of this, move to new keywords to blend in with the at-will escort advertisements. This trend creates an adversarial environment for any machine learning system that attempts to find trafficking rings hiding in plain sight.</p><p>Defective Language Compositionality. Online escort advertisements are difficult to analyze, be- cause they lack grammatical structures such as constituency. Therefore, any form of inference must rely more on context than on grammar. This presents a significant challenge to the NLP commu- nity. Furthermore, the majority of the ads contain emojis and non-English characters.</p><p>Generalizable Language Context. Machine learning techniques can easily learn unreliable cues in training sets such as phone numbers, keywords, and other forms of semantically unreliable discrim- inators to reduce the training loss. Due to limited similarity between the training and test data due to the large number of ads available online, relying on these cues is futile. Learned discriminative features should be generalizable and model semantics of trafficking.</p><p>Multimodal Nature. Escort advertisements are composed of both textual and visual information. Our model should treat these features interdepen- dently. For instance, if the text indicates that the escort is in a hotel room, our model should con- sider the effect that such knowledge may have on the importance of certain visual features.</p><p>We believe that studying human trafficking ad- vertisements can be seen as a fundamental chal- lenge to the NLP, computer vision, and machine learning communities dealing with language and vi- sion problems. In this paper, we present the follow- ing contributions to this research direction. First, we study the language and vision modalities of the escort advertisements through deep neural model- ing. Second, we take a significant step in automatic detection of advertisements suspected of sex traf- ficking. While previous methods  have used simplistic classifiers, we build an end-to-end-trained multimodal deep model called the Human Trafficking Deep Network (HTDN). The HTDN uses information from both text and images to extract cues of human trafficking, and shows outstanding performance compared to pre- viously used models. Third, we present the first rigorously annotated dataset for detection of human trafficking, called Trafficking-10k, which includes more than 10,000 trafficking ads labeled with like- lihoods of having been posted by traffickers. <ref type="bibr">1</ref> Automatic detection of human trafficking has been a relatively unexplored area of machine learning research. Very few machine learning approaches have been proposed to detect signs of human traf- ficking online. Most of these approaches use sim- plistic methods such as multimedia matching ( <ref type="bibr" target="#b24">Zhou et al., 2016</ref>), text-based filtering classifiers such as random forests, logistic regression, and SVMs ( , and named-entity recog- nition to isolate the instances of trafficking ( <ref type="bibr" target="#b10">Nagpal et al., 2015)</ref>. Studies have suggested using statis- tical methods to find keywords and signs of traf- ficking from data to help law enforcement agencies <ref type="bibr" target="#b5">(Kennedy, 2012)</ref> as well as adult content filtering using textual information ( <ref type="bibr" target="#b24">Zhou et al., 2016)</ref>.</p><p>Multimodal approaches have gained popularity over the past few years. These multimodal models have been used for medical purposes, such as detec- tion of suicidal risk, PTSD and depression ( <ref type="bibr" target="#b19">Venek et al., 2016;</ref><ref type="bibr" target="#b21">Yu et al., 2013;</ref><ref type="bibr" target="#b18">Valstar et al., 2016)</ref>; sentiment analysis ( <ref type="bibr" target="#b23">Zadeh et al., 2016b;</ref><ref type="bibr" target="#b13">Poria et al., 2016;</ref><ref type="bibr" target="#b22">Zadeh et al., 2016a</ref>); emotion recognition ( <ref type="bibr" target="#b12">Poria et al., 2017)</ref>; image cap- tioning and media description ( <ref type="bibr" target="#b20">You et al., 2016;</ref><ref type="bibr" target="#b1">Donahue et al., 2015)</ref>; question answering ( <ref type="bibr" target="#b0">Antol et al., 2015)</ref>; and multimodal translation ( <ref type="bibr" target="#b16">Specia et al., 2016)</ref>.</p><p>To the best of our knowledge, this paper presents the first multimodal and deep model for detection of human trafficking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Trafficking-10k Dataset</head><p>In this section, we present the dataset for our stud- ies. We formalize the problem of recognizing sex trafficking as a machine learning task. The input data is text and images; this is mapped to a measure of how suspicious the advertisement is with regards to human trafficking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data Acquisition and Preprocessing</head><p>A subset of 10,000 ads were sampled randomly from a large cache of escort ads for annotation in Trafficking-10k dataset. The distribution of adver- tisements across the United States and Canada is shown in <ref type="figure" target="#fig_0">Figure 1</ref>, which indicates the diversity of advertisements in Trafficking-10k. This diversity ensures that models trained on Trafficking-10k can be applicable nationwide. The 10,000 collected ads are provided only to scientific community. each consist of text and zero or more images. The text in the dataset is in plain text format, derived by stripping the HTML tags from the raw source of the ads. The set of characters in each advertise- ment is encoded as UTF-8, because there is ample usage of smilies and non-English characters. Ad- vertisements are truncated to the first 184 words, as this covers more than 90% of the ads. Images are resized to 224 × 224 pixels with RGB channels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Trafficking Annotation</head><p>Detecting whether or not an advertisement is suspi- cious requires years of practice and experience in working closely with law enforcement. As a result, annotation is a highly complicated and expensive process, which cannot be scaled using crowdsourc- ing. In our dataset, annotation is carried out by two expert annotators, each with at least five years of experience, in detection of human trafficking and another annotator with one year of experience. In our dataset, annotations were done by three experts. One expert has over a year of experience, and the other two have over five years of experience in the human trafficking domain. To calculate the inter- annotator agreement, each annotator is given the same set of 1000 ads to annotate and the nomi- nal agreement is found: there was a 83% pairwise agreement (0.62 Krippendorff's alpha). Also, to make sure that annotations are generalizable across the annotators and law enforcement officers, two law enforcement officers annotated, respectively, a subset of 500 and 100 of the advertisements. We found a 62% average pairwise agreement (0.42 Krippendorff's alpha) with our annotators. This gap is reasonable, as law enforcement officers only have experience with local advertisements, while Trafficking-10k annotators have experience with cases across the United States.</p><p>Annotators used an annotation interface specifi- cally designed for the Trafficking-10k dataset. In the annotation interface, each advertisement was displayed on a separate webpage. The order of the advertisements is determined uniformly ran- domly, and annotators were unable to move to the next advertisement without labeling the cur- rent one. For each advertisement, the annotator was presented with the question: "In your opin- ion, would you consider this advertisement suspi- cious of human trafficking?" The annotator is pre- sented with the following options: "Certainly no," "Likely no," "Weakly no," "Unsure," 2 "Weakly yes," "Likely yes," and "Certainly yes." Thus, the degree to which advertisements are suspicious is quantized into seven levels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Analysis of Language</head><p>The language used in these advertisements intro- duces fundamental challenges to the field of NLP. The nature of the textual content in these adver- tisements raises the question of how we can make inferences in a linguistic environment with a con- stantly evolving lexicon. Language used in the Trafficking-10k dataset is highly inconsistent with standard grammar. Often, words are obfuscated by emojis and symbols. The word ordering is in- consistent, and there is rarely any form of con- stituency. This form of language is completely different from spoken and written English. These attributes make escort advertisements appear some- what similar to tweets, specifically since these ads are normally short (more than 90% of the ads have at most 184 words). Another point of complex- ity in these advertisements is the high number of unigrams, due to usage of uncommon words and obfuscation. On top of unigram complexity, ad- vertisers continuously change their writing pattern, making this problem more complex. The length of suspected advertisements is 134 unigrams; the standard deviation is 39, the mini- mum is 12, and the maximum is 666. The length of non-suspected ads is 141; the standard deviation is 85, the minimum is 7, and the maximum is 1810. The total number of suspected ads is 3257; and the total number of non-suspected ads is 6992. <ref type="figure" target="#fig_1">Fig- ure 2</ref> shows the histogram of number of ads based on their length. Both the positive and negative dis- tributions are similar. This means that there is no obvious length difference between the two classes. Most of the ads have a length of 80-180 words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Dataset Statistics</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Model</head><p>In this section, we present our deep multimodal net- work called the Human Trafficking Deep Network (HTDN). The HTDN is a multimodal network with language and vision components. The input to the HTDN is an ad, text and images. The HTDN is shown in <ref type="figure" target="#fig_2">Figure 3</ref>. In the remainder of this section, we will outline the different parts of the HTDN, and the input features to each component.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Trafficking Word Embeddings</head><p>Our approach to deal with the adversarial environ- ment of escort ads is to use word vectors, defining words not based on their constituent characters, but rather based on their context. For instance, consider the two unigrams "cash" and "©a$h." While these contain different characters, semantically they are the same, and they occur in the same context. Thus, our expectation is that both the unigrams will be mapped to similar vectors. Word embeddings pre- trained on general domains do not cover most of the unigrams in Trafficking-10k. For instance, the GloVe embedding ( <ref type="bibr" target="#b11">Pennington et al., 2014</ref>) trained on Wikipedia covers only 49.7% of our unigrams. The first step of the HTDN pipeline is to train word vectors ( <ref type="bibr" target="#b9">Mikolov et al., 2013</ref>) based on the skip-gram model. This is especially suitable for escort ads, because skip-gram mod- els are able to capture context without relying on word order. We train the word embedding using 1,000,000 unlabeled ads from a dataset that does not include the Trafficking-10k data. For each ad- vertisement, the input to the trained embedding is a sequence of wordsˆwwordsˆ wordsˆw = [ ˆ w 1 , . . . , ˆ w t ], and the out- put is a sequence of 100-dimensional word vectors w = [w 1 , . . . , w t ], where t is the size of the adver- tisement and w i ∈ R 100 . Our trained word vectors cover 94.9% of the unigrams in the Trafficking-10k dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Language Network</head><p>Our language network is designed to deal with two challenging aspects of escort advertisements: (1) violation of constituency, and (2) presence of irrelevant information not related to trafficking but present in ads. We address both of these issues by learning a time dependent embedding at word level. This allows the model to not rely on con- stituency and also remember useful information from the past, should the model get overwhelmed by irrelevant information. Our proposed language network, F l , takes as input a sequence of word vectors w = [w 1 , . . . , w t ], and outputs a neural language representation h l . As a first step, F l uses the word embeddings as input to a Long-Short Term Memory (LSTM) network and produces a new supervised context-aware word embedding u = [u 1 , . . . , u t ] where u i ∈ R 300 is the output of the LSTM at time i. Then, u is fed into a fully connected layer with dropout p = 0.5 to produce the neural language representation h l ∈ R 300 ac- cording to the following formulas with weights W l for the LSTM and implicit weights in the fully</p><formula xml:id="formula_0">Language Network F l d0ll@r to . . . g r 8 skype · · · LSTM · · · LSTM · · · LSTM · · · LSTM h l ∈ R 300</formula><p>Trafficking embedding</p><formula xml:id="formula_1">. . . . . . . . . 300σ Visual Network F v ˆ ı 1 ˆ ı 2 ˆ ı 3 ˆ ı 4 ˆ ı 5</formula><p>Trafficking VGG</p><p>. . . . . . . . . </p><formula xml:id="formula_2">u i = LSTM (i, w i ; W l ) (1) u = [u 1 , . . . , u t ]<label>(2)</label></formula><formula xml:id="formula_3">h l = FC (u).<label>(3)</label></formula><p>The generated h l is then used as part of the HTDN pipeline, and is also trained independently to as- sess the performance of the language-only model. The language network F l is the combination of the LSTM and the fully-connected network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Vision Network</head><p>Parallel to the language network, the vision net- work F v takes as input advertisement images and extracts visual representations h v . The vision net- work takes at most five images; the median num- ber of images per advertisement in Trafficking-10k is 5. To learn contextual and abstract information from images, we use a deep convolutional neural network called Trafficking-VGG (T-VGG), a fine- tuned instance of the well-known VGG network <ref type="bibr" target="#b15">(Simonyan and Zisserman, 2014)</ref>. T-VGG is a deep model with 13 consecutive convolutional layers fol- lowed by 2 fully connected layers; it does not in- clude the softmax layer of VGG. The procedure for fine-tuning T-VGG maps each individual image to a label that comes from the advertisement, and then performs end-to-end training. For example, if there are five images in an advertisement with positive label, all five images are mapped to positive label. After fine-tuning, three fully connected layers of 200 neurons with dropout p = 0.5 are added to the network. The combination of T-VGG and the fully connected layers is the vision network F l . We consider five imagesˆıimagesˆimagesˆı = {ˆı{ˆı 1 , . . . , ˆ ı 5 } from each input advertisement. If the advertisement has fewer than five images, zero-filled images are added. For each image, the output of F v is a representation of five images i = {i 1 , . . . , i 5 }. The visual repre- sentation h v ∈ R 5×200 is a matrix with a size-200 representation of each of the 5 images:</p><formula xml:id="formula_4">h v = F v (ˆ ı; W v ).<label>(4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Multimodal Fusion</head><p>Escort advertisements have complex dynamics be- tween text and images. Often, neither linguistic nor visual cues alone can suffice to classify whether an ad is suspicious. Interactions between linguistic and visual cues can be non-trivial, so this requires an explicit joint representation for each neuron in the linguistic and visual representations. In our multimodal fusion approach we address this by cal- culating an outer product between language and visual representations h l and h v to build the full space of possible outcomes: where ⊗ is an outer product of the two representa- tions. This creates a joint multimodal tensor called h m for language and visual modalities. In this ten- sor, every neuron in the language representation is multiplied by every neuron in vision representa- tion, thus creating a new representation containing the information of both of them. Thus, the final fusion tensor h m ∈ R 5×200×300 contains informa- tion from the joint interaction of the language and visual modalities.</p><formula xml:id="formula_5">h m = h l ⊗ h v ,<label>(5)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Convolutional Decision Network</head><p>The multimodal representation h m is used as the input to the convolutional decision network F d . F d has two layers of convolution and max pooling with a dropout rate of p = 0.5, followed by a fully con- nected layer of 150 neurons with a dropout rate of p = 0.5. Performing convolutions in this space en- ables the model to attend to small areas of linguistic and visual cues. It can thus find correspondences between specific combinations of the linguistic and visual representations. The final decision is made by a single sigmoid neuron.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>In our experiments, we compare the HTDN with previously used approaches for detection of traf- ficking suspicious ads. Furthermore, we compare the HTDN to the performance of its unimodal com- ponents. In all our experiments we perform binary classification of whether the advertisement is sus- pected of being related to trafficking. The main comparison method that we use is the weighted ac- curacy and F1-score (due to imbalance it dataset).</p><p>The formulation for weighted accuracy is as fol- lows: where TP (resp. TN) is true positive (resp. true negative) predictions, and P (resp. N) is the total number of positive (resp. negative) examples.</p><formula xml:id="formula_6">Wt. Acc. = TP × N/P + TN 2N (6) Model Wt. Acc. (%) F1 (%) Acc. (%) Precision (%) Recall (%)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Baselines</head><p>We compare the performance of the HTDN network with baseline models divided in 4 major categories Bag-of-Words Baselines. This set of baselines is designed to assess performance of off-the-shelf basic classifiers and basic language features. We train random forest, logistic regression and linear SVMs to show the performance of simple language- only models.</p><p>Keyword Baselines. These demonstrate the per- formance of models that use a set of 108 keywords, all highly related to trafficking, provided by law enforcement officers. 3 A binary one-hot vector representing these keywords is used to train the 3 Not presented in this paper due to sensitive nature of these keywords. random forest, logistic regression, and linear SVM models.</p><p>108 One-Hot Baselines. Similar to Keywords Baseline, we use feature selection technique to fil- ter the most informative 108 words for detection of trafficking. We compare the performance of this baseline to Keywords baseline to evaluate the use- fulness of expert knowledge in keywords selection vs automatic data-driven keyword selection.</p><p>Average Trafficking Vectors Baselines. We as- sess the magnitude of success for the trafficking word embeddings for different classifiers. For the random forest, logistic regression, and linear SVM models, the average word vector is calculated and used as input.</p><p>HTDN Unimodal. These baselines show the performance of unimodal components of HTDN. For language we only use F l component of the pipeline and for visual we use F v , using both pre- trained a VGG and finetuned T-VGG.</p><p>Random and Human. Random is based on as- signing the more frequent class in training set to all the test data, and can be considered a lower bound for our model. Human performance metrics are upper bounds for this task's metrics.</p><p>We visualize the different inputs to our baseline models to show the complexity of the dataset when using different feature sets. <ref type="figure" target="#fig_3">Figure 4</ref> shows the 2D t-SNE <ref type="bibr" target="#b7">(Maaten and Hinton, 2008)</ref> representation of the training data in our dataset according to the Bag-of-Words (top right) models, expert keywords (top left), average word vectors (bottom right), and the visual representation h v bottom left. The distri- bution of points suggests that none of the feature representations make the classification task trivial.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Training Parameters</head><p>All the models in our experiments are trained on the Trafficking-10k designated training set and tested on the designated test set. Hyperparameter eval- uation is performed using a subset of training set as validation set. The HTDN model is trained us- ing the Adam optimizer ( <ref type="bibr" target="#b6">Kingma and Ba, 2014</ref>). The neural weights were initialized randomly using Xavier initialization technique <ref type="bibr" target="#b3">(Glorot and Bengio, 2010)</ref>. The random forest model uses 10 estimators, with no maximum depth, and minimum-samples- per-split value of 2. The linear SVM model uses an 2 -penalty and a square hinge loss with C = 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results and Discussion</head><p>The results of our experiments are shown in <ref type="table">Table 1</ref>. We report the results on three metrics: F1-score, weighted accuracy, and accuracy. Due to the imbal- ance between the numbers of positive and negative samples, weighted accuracy is more informative than unweighted accuracy, so we focus on the for- mer.</p><p>HTDN. The first observation from <ref type="table">Table 1</ref> is that the HTDN model outperforms all the pro- posed baselines. There is a significant gap between the HTDN (and variants) and other non-neural ap- proaches. This better performance is an indicator of complex interactions in detecting dynamics of human trafficking, which is captured by the HTDN.</p><p>Both Modalities are Helpful. Both modalities are helpful in predicting signs of trafficking (F l and F v <ref type="bibr">[T-VGG]</ref>). Fine-tuning VGG network param- eters shows improvement over pre-trained VGG parameters.</p><p>Language is More Important. Since F l shows better performance than F v <ref type="bibr">[T-VGG]</ref>, the language modality appears to be the more informative modal- ity for detecting trafficking suspicious ads.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion and Future Work</head><p>In this paper, we took a major step in multimodal modeling of suspected online trafficking advertise- ments. We presented a novel dataset, Trafficking- 10k, with more than 10,000 advertisements anno- tated for this task. The dataset contains two modal- ities of information per advertisement: text and im- ages. We designed a deep multimodal model called the Human Trafficking Deep Network <ref type="figure">(HTDN)</ref>. We compared the performance of the HTDN to various models that use language and vision alone. The HTDN outperformed all of these, indicating that using information from both sources may be more helpful than using just one.</p><p>Exploring language through character mod- eling. In order to eliminate the need for retraining the word vectors as the language of the domain evolves, we plan to use character models to learn a better language model for trafficking. As new obfuscated words are introduced in escort adver- tisements, our hope is that character models will stay invariant to these obfuscations.</p><p>Understanding images. While CNNs have proven to be useful for many different computer vision tasks, we seek to improve the learning ca- pability of the visual network. Future direction involves using graphical modeling to understand in- teractions in the scene. Another direction involves working to understand text in images, which can provide more information about the subjects of the images.</p><p>Given that the current state of the art in this area generally does not use deep models, this may be a major opportunity for improvement. To this end, we encourage the research community to reach out to Cara Jones, an author of this paper, to obtain a copy of Trafficking-10k and other training data. ments for the dataset, and for allowing us to use their advertisement data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Distribution of advertisements in Trafficking-10k dataset across United States and Canada.</figDesc><graphic url="image-1.png" coords="3,72.00,62.81,226.77,137.31" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Distribution of the length of advertisements in Trafficking-10k. There is no significant difference between positive and negative cases purely based on length.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Overview of our proposed Human Trafficking Deep Network (HTDN). The input to HTDN is text and a set of 5 images. The text goes through the Language Network F l to get the language representation h l and the set of 5 images go through the Vision Network F v to get the visual representation h v. h l and h v are then fused together to get the multimodal representation h m. The Convolutional Decision Network F d conditioned on the h m makes inference about whether or not the advertisement is suspected of trafficking</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: 2D t-SNE representation of different input features for baseline models. Clockwise from top left: one hot vectors with expert data, one hot vectors without expert data, visual features from Vision Network F v , and average word vectors. These representations show that inference is not trivial in Trafficking-10k dataset.</figDesc><graphic url="image-4.png" coords="6,72.00,239.85,226.75,170.06" type="bitmap" /></figure>

			<note place="foot" n="1"> Due to the sensitive nature of this dataset, access can only be granted by emailing Cara Jones. Different levels of access 2 Related Works</note>

			<note place="foot" n="2"> This option is greyed out for 10 seconds to encourage annotators to make an intuitive decision.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to thank William Chargin for creat-ing figures and revising this paper. We would also like to thank Torsten Wörtwein for his assistance in visualizing our data. Furthermore, we would like to thank our anonymous reviewers for their valuable feedback. Finally, we would like to acknowledge collaborators from Marinus Analytics for the time and effort that they put into annotating advertise-</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Vqa: Visual question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislaw</forename><surname>Antol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aishwarya</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiasen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2425" to="2433" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Long-term recurrent convolutional networks for visual recognition and description</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lisa</forename><forename type="middle">Anne</forename><surname>Hendricks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhashini</forename><surname>Venugopalan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><forename type="middle">Darrell</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2625" to="2634" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Leveraging publicly available data to discern patterns of human-trafficking activity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Artur</forename><surname>Dubrawski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyle</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benedikt</forename><surname>Boecking</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Human Trafficking</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="65" to="85" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Understanding the difficulty of training deep feedforward neural networks. In Aistats</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="249" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">National Human Trafficking Hotline</title>
	</analytic>
	<monogr>
		<title level="m">Hotline statistics</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Predictive patterns of sex trafficking online. Dietrich College Honors Theses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Kennedy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Human trafficking and the new slavery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lauren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mccarthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual Review of Law and Social Science</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="221" to="242" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">An entity resolution approach to isolate instances of human trafficking online</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chirag</forename><surname>Nagpal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyle</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benedikt</forename><surname>Boecking</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Artur</forename><surname>Dubrawski</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1509.06659</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">GloVe: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A review of affective computing: From unimodal analysis to multimodal fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soujanya</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajiv</forename><surname>Bajpai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Hussain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Fusion</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">34</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Convolutional mkl based multimodal emotion recognition and sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soujanya</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iti</forename><surname>Chaturvedi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Hussain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE 16th International Conference on Data Mining (ICDM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="439" to="448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Self-reported symptoms of depression and ptsd are associated with reduced vowel space in screening interviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Scherer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><forename type="middle">Skip</forename><surname>Gratch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Louis-Philippe</forename><surname>Rizzo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Morency</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Affective Computing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="59" to="73" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<title level="m">Very deep convolutional networks for large-scale image recognition</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A shared task on multimodal machine translation and crosslingual image description</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stella</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khalil</forename><surname>Sima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Desmond</forename><surname>Elliott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Conference on Machine Translation</title>
		<meeting>the First Conference on Machine Translation<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Human trafficking: An overview. Web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Unodc</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Avec 2016: Depression, mood, and emotion recognition workshop and challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Valstar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Gratch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Björn</forename><surname>Schuller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabien</forename><surname>Ringeval</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dennis</forename><surname>Lalanne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mercedes</forename><forename type="middle">Torres</forename><surname>Torres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Scherer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giota</forename><surname>Stratou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roddy</forename><surname>Cowie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maja</forename><surname>Pantic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Workshop on Audio/Visual Emotion Challenge</title>
		<meeting>the 6th International Workshop on Audio/Visual Emotion Challenge</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Adolescent suicidal risk assessment in clinician-patient interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Verena</forename><surname>Venek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Scherer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Louis-Philippe</forename><surname>Morency</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Rizzo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Pestian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Affective Computing</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Image captioning with semantic attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanzeng</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hailin</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaowen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiebo</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4651" to="4659" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Multimodal prediction of psychological disorders: Learning verbal and nonverbal commonalities in adjacency pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhou</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefen</forename><surname>Scherer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Devault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Gratch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giota</forename><surname>Stratou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Louis-Philippe</forename><surname>Morency</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justine</forename><surname>Cassell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Semdial 2013 DialDam: Proceedings of the 17th Workshop on the Semantics and Pragmatics of Dialogue</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="160" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Mosi: Multimodal corpus of sentiment intensity and subjectivity analysis in online opinion videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Zadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rowan</forename><surname>Zellers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eli</forename><surname>Pincus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Louisphilippe</forename><surname>Morency</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.06259</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Multimodal sentiment intensity analysis in videos: Facial gestures and verbal messages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Zadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rowan</forename><surname>Zellers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eli</forename><surname>Pincus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Louisphilippe</forename><surname>Morency</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="82" to="88" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Multimedia metadata-based forensics in human trafficking web data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Jie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiyun</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lewis John</forename><surname>Mcgibbney</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">10</biblScope>
			<pubPlace>Vanessa Murdock, Charles LA Clarke</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
