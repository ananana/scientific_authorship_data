<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:11+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Supervised Learning of Automatic Pyramid for Optimization-Based Multi-Document Summarization</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxime</forename><surname>Peyrard</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judith</forename><surname>Eckle-Kohler</surname></persName>
						</author>
						<title level="a" type="main">Supervised Learning of Automatic Pyramid for Optimization-Based Multi-Document Summarization</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</title>
						<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1084" to="1094"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-1100</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present a new supervised framework that learns to estimate automatic Pyramid scores and uses them for optimization-based extractive multi-document summa-rization. For learning automatic Pyramid scores, we developed a method for automatic training data generation which is based on a genetic algorithm using automatic Pyramid as the fitness function. Our experimental evaluation shows that our new framework significantly outperforms strong baselines regarding automatic Pyramid , and that there is much room for improvement in comparison with the upper-bound for automatic Pyramid.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>We consider extractive text summarization, the task of condensing a textual source, e.g., a set of source documents in multi-document summariza- tion (MDS), into a short summary text. The qual- ity of an automatic system summary is tradition- ally evaluated by comparing it against one or more reference summaries written by humans. This comparison is performed by means of an evalua- tion metric measuring indicators of summary qual- ity and combining them into an aggregated score.</p><p>Many state-of-the-art summarization systems cast extractive summarization as an optimization problem and maximize an objective function in or- der to create good, i.e., high-scoring summaries. To this end, optimization-based systems com- monly use an objective function which encodes exactly those quality indicators which are mea- sured by the particular evaluation metric being used. Some systems even employ an approxima- tion of the evaluation metric as objective function.</p><p>Consider as an example the ROUGE metric which has become a de-facto standard for sum- mary evaluation <ref type="bibr" target="#b9">(Lin, 2004)</ref>. ROUGE computes the n-gram overlap between a system summary and a pool of reference summaries. There are sev- eral previous approaches which have used an ap- proximation of ROUGE as the optimization objec- tive (e.g., <ref type="bibr" target="#b22">Sipos et al. (2012)</ref>; <ref type="bibr">Peyrard and EckleKohler (2016a)</ref>).</p><p>However, ROUGE has been widely criticized for being too simplistic and not suitable for captur- ing important quality aspects we are interested in. In particular, ROUGE does not capture sentences which are semantically equivalent but expressed with different words ( <ref type="bibr" target="#b14">Nenkova et al., 2007)</ref>.</p><p>Ideally, we would like to evaluate our sum- maries based on human judgments. A well-known example of such a human evaluation method is the so-called Pyramid method ( <ref type="bibr" target="#b14">Nenkova et al., 2007)</ref>: it evaluates the particular quality aspect of content selection and is based on a manual comparison of Summary Content Units (SCUs) in reference sum- maries against SCUs in system summaries. While the resulting Pyramid score is much more mean- ingful and informative than ROUGE, it is very ex- pensive to obtain, and -worse -not reproducible.</p><p>These issues have been addressed by a line of research aimed at automating the Pyramid evalua- tion ( <ref type="bibr" target="#b5">Harnly et al., 2005;</ref><ref type="bibr" target="#b17">Passonneau et al., 2013)</ref>. Recently, <ref type="bibr" target="#b24">Yang et al. (2016)</ref> developed a freely available off-the-shelf system for automatic Pyra- mid scoring called PEAK, which uses open Infor- mation Extraction (open IE) propositions as SCUs and relies on proposition comparison. Automatic Pyramid (AP) scores are reproducible, and unlike ROUGE, they are based on semantically motivated content units (SCUs) rather than word n-grams. Moreover, they correlate better with human judg- ments than ROUGE ( <ref type="bibr" target="#b24">Yang et al., 2016)</ref>.</p><p>Given these recent advances in the automatic evaluation of summaries regarding content selec- tion, we believe that research in optimization- based summarization should move away from ROUGE towards AP as a more meaningful eval- uation metric to approximate and to optimize. In our work, we are the first to explore this new direction and to systematically investigate the use of AP in optimization-based extractive sum- marization. We make the following contributions:</p><p>• We compute an upper-bound for AP with a Genetic Algorithm (GA), and compare it to the ROUGE upper-bound.</p><p>• We develop a new extractive MDS system specifically optimizing for an approximation of AP. Our system uses a supervised learning setup to learn an approximation of AP from automatically generated training data. We constrain the learned approximation of AP to be linear so that we can extract summaries efficiently via Integer Linear Programming (ILP). Our experimental evaluation shows that our approach significantly outperforms strong baselines on the AP metric.</p><p>The code both for the new upper-bound and for our ILP is available at github.com/UKPLab/ acl2017-optimize_pyramid.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>In this section, we summarize the Pyramid method and the PEAK system, the automated version of Pyramid we consider in this work.</p><p>Pyramid The Pyramid method ( <ref type="bibr" target="#b14">Nenkova et al., 2007</ref>) is a manual evaluation method which deter- mines to what extent a system summary covers the content expressed in a set of reference summaries. The comparison of system summary content to reference summary content is performed on the basis of SCUs which correspond to semantically motivated, subsentential units, such as phrases or clauses.</p><p>The Pyramid method consists of two steps: the creation of a Pyramid set from reference sum- maries, and second, Pyramid scoring of system summaries based on the Pyramid set. In the first step, humans annotate phrasal content units in the reference summaries and group them into clusters of semantically equivalent phrases. The resulting clusters are called SCUs and the annotators as- sign an SCU label to each cluster, which is a sen- tence describing the cluster content in their own words. The final set of SCUs forms the Pyramid set. Each SCU has a weight corresponding to the number of reference summaries in which the SCU appears. Since each SCU must not appear more than once in each reference summary, the maxi- mal weight of an SCU is the total number of refer- ence summaries. In the second step, humans anno- tate phrasal content units in a system summary and align them to the corresponding SCUs in the Pyra- mid set. The Pyramid score of a system summary is then calculated as the sum of the SCU weights for all Pyramid set SCUs being aligned to anno- tated system summary phrases. PEAK The AP system PEAK by <ref type="bibr" target="#b24">Yang et al. (2016)</ref> uses clauses as the content expressing units and represents them as propositions in the open IE paradigm. An open IE proposition is a triple of subject, predicate and object phrases. PEAK uses the state-of-the-art system clausIE <ref type="bibr" target="#b2">(Del Corro and Gemulla, 2013</ref>) for proposition extraction.</p><p>While PEAK includes the automatic creation of Pyramid sets from reference summaries, as well as automatic Pyramid scoring of system summaries, in this work, we use PEAK for automatic scoring only. As for the Pyramid sets, we can assume that these have already been created, either via PEAK or by humans (e.g., using the TAC 2009 data 1 ).</p><p>Since automatic scoring with PEAK requires that the Pyramid sets consist of representative open IE propositions which constitute the auto- mated counterparts of the SCUs, we first need to represent the manually constructed SCUs as open IE propositions, too. To this end, we use clausIE to extract an open IE proposition from each SCU label -a sentence describing the cluster content. As a result, each pyramid set is represented as a list of propositions {p j } with a weight taken from the underlying SCU.</p><p>For scoring, PEAK processes a system sum- mary with clausIE, converting it from a list of sentences to a list of propositions {s i }. A bi- partite graph G is constructed, where the two sets of nodes are the summary propositions {s i } and the pyramid propositions {p j }. An edge is drawn between s i and p j if the similarity is above a given threshold. PEAK computes the similar- ity with the ADW system (Align, Disambiguate and Walk), a system for computing text similar- ity based on WordNet, which reaches state-of-the-art performance but is slow ( <ref type="bibr" target="#b20">Pilehvar et al., 2013</ref>). Since each system summary unit can be aligned to at most one SCU, the alignment of the sum- mary propositions {s i } and the pyramid propo- sitions {p j } is equivalent to finding a maximum weight matching, which PEAK solves using the Munkres-Kuhn bipartite graph algorithm. From the matched pyramid propositions {p j } the final pyramid score is computed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Approach</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Upper-bound for Automatic Pyramid</head><p>We start by computing upper-bound summaries according to AP in order to gain a better under- standing of the metric.</p><p>Notations Let D = {s i } be a document collec- tion considered as a set of sentences. A summary S is simply a subset of D. We use p pyr to de- note the set of propositions in the Pyramid sets ex- tracted from the SCU labels using clausIE.</p><p>The upper-bound is the set of sentences S * with the best AP score.</p><p>Method The task is to extract the set of sen- tences which contains the propositions matching most of the highest-weighted SCUs, thus resulting in the best matching of propositions, i.e., the high- est AP score possible. Formally, we have to solve the following optimization problem:</p><formula xml:id="formula_0">S * = argmax S AutoP yr(S)<label>(1)</label></formula><p>Unfortunately, it cannot be solved directly via ILP because of the Munkres-Kuhn bipartite graph algorithm within AP. While Munkres-Kuhn is an ILP, we solve a different problem. In our problem, Munkres-Kuhn would act as constraint because we are looking for the best matching among all valid matchings. Munkres-Kuhn only yields the valid matching for one particular set of sentences. One global ILP can be written down by enumerating all possible matchings in the constraints but it will have a completely unrealistic runtime.</p><p>Instead, we have to rely on search-based algo- rithms and compute summaries close to the upper- bound. We search for such an approximate so- lution by employing a meta-heuristic solver in- troduced recently for extractive MDS by <ref type="bibr" target="#b18">Peyrard and Eckle-Kohler (2016a)</ref>. Specifically, we use the tool published with their paper. <ref type="bibr">2</ref> Their meta-heuristic solver implements a Genetic Algorithm (GA) to create and iteratively optimize summaries over time.</p><p>In this implementation, the individuals of the population are the candidate solutions which are valid extractive summaries. Valid means that the summary meets the length constraint. Each sum- mary is represented by a binary vector indicating for each sentence in the source document whether it is included in the summary or not. The size of the population is a hyper-parameter that we set to 100. Two evolutionary operators are applied: the mutation and the reproduction. The mutation happens to several randomly chosen summaries by randomly removing one of its sentences and adding a new one that does not violate the length constraint. The reproduction is performed by ran- domly extracting a valid summary from the union of sentences of randomly selected parent sum- maries. Both operators are controlled by hyper- parameters which we set to their default values.</p><p>In our scenario, the fitness function is the AP metric, which takes a summary S as input and outputs its AP score. S is converted into a list of propositions p S by looking-up the propositions of each sentence in S from a pre-computed hash- map. For all sentences in the document collection D, the hash-map stores the corresponding propo- sitions. Then the Munkres-Kuhn algorithm is ap- plied to p S and p pyr in order to find matching propositions, and finally the scores of their corre- sponding SCUs are used to evaluate the fitness of the summary.</p><p>The runtime might become an issue, because the similarity computation between propositions via ADW is slow. However, all the necessary in- formation is present in the similarity matrix A de- fined by:</p><formula xml:id="formula_1">A ij = ADW (p D i , p pyr j )<label>(2)</label></formula><p>Here A ij is the semantic similarity between the proposition p D i from the source document i and the proposition p P j from the Pyramid set j. A has dimensions m × n if m is the number of proposi- tions in the document collection and n the number of propositions in the Pyramid set. We keep the runtime low by pre-computing the similarity ma- trix A.</p><p>With a population of 100 summaries in the GA, the algorithm converges in less than a minute to high scoring summaries, which we can expect to be close to the real upper-bound.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Supervised Setup to Learn an Approximation of AP</head><p>We denote the true AP scoring function by π * . π * scores summaries by matching the summary propositions to the Pyramid propositions in P pyr as described before. In this work, we aim to learn a function π, which approximates π * without hav- ing access to P pyr , but only to the document col- lection D.</p><p>Formally, it means that over all document col- lections D and all summaries S, we look for π which minimizes the following loss:</p><formula xml:id="formula_2">L(π) = D∈D S∈S π(D, S) − π * (P pyr , S) 2 (3)</formula><p>This states that the learned π minimizes the squared distance from π * over the available train- ing data.</p><p>Model Note that we simply denote π(D, S) by π(S) as it is not ambiguous which document col- lection is used when S is a summary of D.</p><p>In order to be able to use an exact and efficient solver like ILP, we constrain π to be a linear func- tion. Therefore, we look for π of the following form:</p><formula xml:id="formula_3">π(S) = s∈S f θ (s) − i&gt;j g γ (s i ∩ s j )<label>(4)</label></formula><p>Two functions are jointly learned: f θ is a function scoring individual sentences, and g γ is a function scoring the intersection of sentences. θ ∪ γ is the set of learned paramaters. We can interpret this learning scenario as jointly learning the sentence importance and the redun- dancy to get π as close as possible to the true AP π * . f θ represents the notion of importance learned in the context of AP, while g γ contains notions of coherence and redundancy by scoring sentence in- tersections. This scenario is intuitive and inspired by previous work on summarization <ref type="bibr" target="#b12">(McDonald, 2007)</ref>. Now, we explain how to learn these two func- tions while enforcing π to be linear. Suppose each sentence is represented by a feature set φ and each sentence intersections is represented by φ ∩ , then the set of features for a summary S is:</p><formula xml:id="formula_4">Φ(S) = { s∈S φ(s) ∪ i&gt;j φ ∩ (s i ∩ s j )} (5)</formula><p>It is clear that the number of features is vari- able and depends on the number m of sentences in S. In order to deal with a variable number of sentences as input, one could use recurrent neural networks, but at the cost of loosing linearity.</p><p>Instead, to keep the linearity and to cope with variable sized inputs, we employ linear models for both f θ and g γ :</p><formula xml:id="formula_5">π(S) = s∈S θ · φ(s) − i&gt;j γ · φ ∩ (s i ∩ s j ) (6)</formula><p>By leveraging the properties of linear models we end-up with the following formulation:</p><formula xml:id="formula_6">π(S) = θ · s∈S φ(s) − γ · i≥j φ ∩ (s i ∩ s j ) (7)</formula><p>Because of the linear models, we can sum fea- tures over sentences and over sentence intersec- tions to obtain a fixed size feature set:</p><formula xml:id="formula_7">Φ (S) = {φ (S) ∪ φ ∩ (S)}<label>(8)</label></formula><p>where we introduced the following notations:</p><formula xml:id="formula_8">φ (S) = s∈S φ(s) φ ∩ (S) = i&gt;j φ(s i ∩ s j )</formula><p>Suppose φ is composed of k features and φ ∩ of n features. Then φ (S) is a vector of dimension k, and similarly φ ∩ (S) is of dimension n. Finally, Φ is a fixed size feature set of dimension k + n.</p><p>The function π as defined in equation 6 is still linear with respect to sentence and sentence inter- section features, which is convenient for the sub- sequent summary extraction stage.</p><p>Features While any feature set for sentences φ and for sentence intersections φ ∩ could be used, we focused on simple ones in this work.</p><p>For a sentence s, φ(s) consists of the following features:</p><p>• Sentence length in number of words.</p><p>• Sentence position as an integer number start- ing from 0.</p><p>• Word overlap with title: Jaccard similarity between the unigrams in the title t and a sen- tence s:</p><formula xml:id="formula_9">Jaccard(s, t) = |t ∩ s| |t ∪ s|<label>(9)</label></formula><p>• Sum of frequency of unigrams and bigrams in the sentence.</p><p>• Sum of TF*IDF of unigrams and bigrams in the sentence. The idf of unigrams and bi- grams is trained on a background corpus of DBpedia articles. 3</p><p>• Centrality of the sentence computed via PageRank: A similarity matrix is built be- tween sentences in the document collection based on their TF*IDF vector similarity. Then a power method is applied on the sim- ilarity matrix to get PageRank scores of in- dividual sentences. It is similar to the clas- sic LexRank algorithm ( <ref type="bibr" target="#b3">Erkan and Radev, 2004</ref>).</p><p>• Propositions centrality: We also use the centrality feature for propositions. Each sen- tence is scored by the sum of the centrality of its propositions. As PEAK is based on propo- sitions, we expect proposition-level features to provide a useful signal.</p><p>Finally, φ ∩ (s i ∩ s j ) consists of the unigram, bi- gram and trigram overlap between the two sen- tences s i and s j .</p><p>Training The model is trained with a stan- dard linear least squares regression using pairs of (Φ(S), π * (S)) as training examples. Because our approach relies on an automatic metric, an arbi- trarily large number of summaries and their corre- sponding scores can be generated. In contrast, get- ting manual Pyramid annotations for a large num- ber of summaries would be expensive and time- consuming. As training examples we take the population of scored summaries created by the same GA we use for computing upper-bound summaries. It is im- portant to note that this GA is also a perfect gen- erator of training instances: the summaries in its population are already scored because the fitness function is the AP metric. Indeed, for each topic, an arbitrarily large amount of scored summaries can be generated by adjusting the size of the popu- lation. Moreover, the summaries in the population are very diverse and have a wide range of scores, from almost upper-bound to completely random.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Optimization-based Summary Extraction</head><p>Since the function π is constrained to be linear, we can extract the best scoring summary by solving an ILP. Let x be a binary vector indicating whether sen- tence i is in the summary or not. Similarly, let α be a binary matrix indicating whether both sen- tence i and j are in the summary. Finally, let K be the length constraint. With these notations, the best summary is extracted by solving the follwo- gin ILP:</p><formula xml:id="formula_10">argmax S s i ∈S x i * θ ·φ(s i )− i≥j α i,j * γ ·φ ∩ (s i ∩s j ) m i=1 x i * len(s i ) ≤ K ∀(i, j), α i,j − x i ≤ 0 ∀(i, j), α i,j − x j ≤ 0 ∀(i, j), x i + x j − α i,j ≤ 1</formula><p>Which is the ILP directly corresponding to maxi- mizing π as defined by equation 6. Note that · is the dot product while * is the scalar multiplication in R.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Setup</head><p>Dataset We perform our experiments on a multi- document summarization dataset from the Text Analysis Conference (TAC) shared task in 2009, TAC-2009. <ref type="bibr">4</ref> TAC-2009 contains 44 topics, each consisting of 10 news articles to be summarized in a maximum of 100 words. In our experiments, we use only the so-called initial summaries (A sum- maries), but not the update summaries. For each topic, there are 4 human reference summaries and a manually created Pyramid set. As described in section 2, we pre-processed these Pyramid sets with clausIE in order to make them compatible with PEAK.</p><p>Metrics We primarily evaluate our system via automatic Pyramid scoring from PEAK, after pre- processing the summaries with clausIE. PEAK has a parameter t which is the minimal similarity value required for matching a summary proposition and a Pyramid proposition. We use two different val- ues: t = 0.6 (AP-60) and t = 0.7 (AP-70).</p><p>For completeness, we also report the ROUGE scores identified by <ref type="bibr" target="#b15">Owczarzak et al. (2012a)</ref> as strongly correlating with human evaluation meth- ods: ROUGE-1 (R-1) and ROUGE-2 (R-2) recall with stemming and stopwords not removed.</p><p>Finally, we perform significance testing with t- test to compare differences between two means. <ref type="bibr">5</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Automatic Evalution</head><p>Upper-bound Comparison We compute the set of upper-bound summaries for both ROUGE-2 (R- UB) and for AP (AP-UB). <ref type="bibr">6</ref> Both sets of upper- bound summaries are evaluated with ROUGE and AP, and the results are reported in <ref type="table">Table 1</ref> Interestingly, we observe significant differences between the two upper-bounds. While it is ob- vious that each set of upper-bound summaries reaches the best score on the metric it maximizes, the same summary set scores much worse when evaluated with the other metric. This observation empirically confirms that the two metrics measure different properties of system summaries.</p><p>Moreover, the upper-bound for AP gives us in- formation about the room for improvement that summarization systems have with respect to AP. This is relevant in the next paragraph, where we compare systems in an end-to-end evaluation.</p><p>End-to-end Evaluation We evaluate the qual- ity of the summaries extracted by the summarizer π − ILP in a standard end-to-end evaluation sce- nario. π − ILP is the system composed of the learned function π and the ILP defined in the pre- vious section.</p><p>Learning π Using our GA data generation method, we produce 100 scored summaries for each of the 44 topics in TAC2009 while comput- ing the upper-bound. We use the threshold value of 0.65 as a compromise between AP-60 and AP- 70. The data generated have scores ranging from 0. to 0.4627 with an average of 0.1615. The data is well distributed because the standard deviation is 0.1449. A highly diverse set of summaries is pro- duced, because on average two summaries in the training set only have 1.5% sentences in common, and most of the sentences of the source documents are contained in at least one summary.</p><p>The model is then trained in a leave-one-out cross-validation setup. The parameters θ and γ are the previous best baseline is significant with p ≤ 0.05. <ref type="bibr">6</ref> We use the parameter t = 0.6 during the upper-bound computation of AP-UB.  trained on all topics but one. The trained model is used to extract a high-scoring summary on the re- maining topic by solving the ILP defined above. Our framework is compared to the following baselines:</p><p>TF*IDF weighting A simple heuristic intro- duced by <ref type="bibr" target="#b11">Luhn (1958)</ref> where each sentence re- ceives a score from the TF*IDF of its terms. The best sentences are greedily extracted until the length constraint is met. We use the implementa- tion available in the sumy package. <ref type="bibr">7</ref> LexRank ( <ref type="bibr" target="#b3">Erkan and Radev, 2004</ref>) is a pop- ular graph-based approach. A similarity graph G(V, E) is constructed where V is the set of sen- tences and an edge e ij is drawn between sentences v i and v j if and only if the cosine similarity be- tween them is above a given threshold. Sentences are scored according to their PageRank score in G. It is also available in the sumy package.</p><p>ICSI <ref type="bibr" target="#b4">(Gillick and Favre, 2009</ref>) is a recent sys- tem that has been identified as one of the state- of-the-art systems by <ref type="bibr" target="#b6">Hong et al. (2014)</ref>. It is an ILP framework that extracts a summary by solv- ing a maximum coverage problem considering the most frequent bigrams in the source documents. We use the Python implementation released by <ref type="bibr" target="#b1">Boudin et al. (2015)</ref>.</p><p>JS-Gen ( <ref type="bibr" target="#b18">Peyrard and Eckle-Kohler, 2016a</ref>) is a recent approach which uses a GA to minimize the Jensen-Shannon (JS) divergence between the extracted summary and the source documents. JS divergence measures the difference between prob- ability distributions of words in the source docu- ments and in the summary.</p><p>Results We report the performance of π − ILP in comparison to the baselines in <ref type="table" target="#tab_2">Table 2</ref>.</p><p>The results confirm an expected behavior. Our supervised framework which aims at approximat- ing and maximizing AP, easily and significantly outperforms all the other baselines when evaluated with AP for both values of the threshold. While the system is not designed with ROUGE in mind, it still performs reasonably well in the ROUGE evaluation, even though it does not outperform previous works.</p><p>In general, the two metrics ROUGE and AP do not produce the same rankings of systems. This is another piece of empirical evidence that they mea- sure different properties of summaries.</p><p>When we compare the system performances to the upper-bound scores reported in <ref type="table">Table 1</ref>, we see that there is still a large room for improvements. We take a closer look at this performance gap in the next paragraph where we evaluate the learning component of our approach.</p><p>Evaluation of Learned π In this paragraph, we evaluate the learning of π as an approximation of π * . We do so by measuring the correlation be- tween π and the true AP π * .</p><p>We report three correlation metrics to evaluate and compare the ranking of summaries induced by π and π * : Pearson's r, Spearman's ρ and NDCG. Pearson's r is a value correlation metric which de- picts linear relationship between the scores pro- duced by two ranking lists.</p><p>Spearman's ρ is a rank correlation metric which compares the ordering of systems induced by the two ranking lists.</p><p>NDCG is a metric from information retrieval which compares ranked lists and puts a special emphasis on the top elements by applying loga- rithm decay weighting for elements further down in the list. Intuitively, it describes how well the π function is able to recognize the best scoring summaries. In our case, it is particularly desir- able to have a high NDCG score, because the op- timizer extracts summaries with high π scores; we want to confirm that top scoring summaries are also among top scoring summaries according to the true π * .</p><p>For comparison, we report how well our base- lines correlate with π * . For this, we consider the scoring function for summaries which is part of all our baselines, and which they explicitly or implicitly optimize: TF*IDF greedily maximizes f T F * IDF , the sum of the frequency of the words in the summary. ICSI maximizes the sum of the doc- ument frequency of bigrams (f ICSI ). LexRank maximizes f LexRank , the sum of the PageRank of sentences in the summary, and f JS is the JS diver- gence between the summary and the source docu-  <ref type="table">Table 3</ref>: Performance of the supervised learn- ing of π on TAC-2009 in a leave-one-out cross- validation.</p><note type="other">Pearson's r Spearman's ρ NDCG fT F</note><p>ments optimized by JS-Gen.</p><p>For our supervised learning of π, the training procedure is the same as described in the previous section. The correlation scores are averaged over topics and reported in <ref type="table">Table 3</ref>.</p><p>We observe that π is able to approximate AP significantly better than any baseline for all met- rics. This explains why optimizing π with ILP out- performs the baseline systems in the end-to-end evaluation ( <ref type="table" target="#tab_2">Table 2)</ref>.</p><p>The learned π achieves a high NDCG, indicat- ing that optimizing π produces summaries very likely to have high π * scores. This means that π is capable of accurately identifying high-scoring summaries, which again explains the strong per- formance of π − ILP . The fact that the overall correlations are lower for every system shows that it is difficult to predict π for poor and average qual- ity summaries.</p><p>It is interesting to observe that features such as unigram and bigram frequency, which are known to be strong features to approximate ROUGE, are less useful to approximate the more complex AP.</p><p>Feature Weights The advantage of linear mod- els is their interpretability. One can investigate the contribution of each feature by looking at its corre- sponding weight learned during training. The sign of the weight indicates whether the feature corre- lates positively or negatively with the results, and its amplitude determines the importance of this feature in the final estimation.</p><p>We observe that the most useful feature is the proposition centrality, which confirms our expec- tation that proposition-based features are useful for approximating PEAK. The bigram coverage has also a high weight explaining the strong per- formance of ICSI. The least useful feature is the sentence position, even if it still contains some useful signal.</p><p>Interestingly, the analysis of features from the Pearson's r Spearman's ρ NDCG ROU GE − 1 0.3292 0.3187 0.7195 ROU GE − 2 0.3292 0.2936 0.7259 <ref type="table">Table 4</ref>: Correlation between ROUGE-1 and ROUGE-2 with AP on the automatically generated training data for TAC-2009.</p><p>sentence intersection reveals a slightly positive correlation for the unigram and bigram overlap, but a negative correlation for trigram overlap. Our interpretation is that the model learns that good summaries tend to have repeated unigrams and bigrams to ensure some coherence, while the re- peated trigrams are more indicative of undesired redundancy.</p><p>Agreement between ROUGE and AP In the previous paragraphs, we already saw that differ- ent metrics produce different rankings of systems. We want to investigate this further and understand to what extent ROUGE and AP disagree. To that end, we use the summaries automatically gener- ated by the genetic algorithm during the upper- bound computation. Remember that for each topic of TAC-2009 it produces 100 summaries with a wide range of AP scores. We then score these summaries with both ROUGE-1 and ROUGE-2 and compare how ROUGE metrics correlate with AP. In order to get a meaningful picture, we use the same three correlation metrics as above: Pear- son's, Spearman's ρ and NDCG. The results are presented in <ref type="table">Table 4</ref>. We observe a low correlation between ROUGE metrics and AP in terms of both rank correlation (Spearman's ρ) and value correlation (Pearson's r). Even though the NDCG numbers are better, the correlation is also relatively low given that higher numbers are usually expected for NDCG (also ob- served in <ref type="table">Table 3</ref>).</p><p>This analysis confirms the initial claim that ROUGE and AP behave quite differently and mea- sure different aspects of summary quality. There- fore, we believe systems developed and trained for AP are worth studying because they necessarily capture different aspects of summarization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>We discuss (i) related work in extractive summa- rization where an approximation of an automatic evaluation metric was optimized, and (ii) work re- lated to AP specifically.</p><p>As ROUGE is the metric predominantly used for evaluation of extractive summarization, there are several previous optimization-based ap- proaches which included an approximation of ROUGE in the objective function to maximize. For example, <ref type="bibr" target="#b23">Takamura and Okumura (2010)</ref> and <ref type="bibr" target="#b22">Sipos et al. (2012)</ref> performed structured out- put learning (using pairs of summaries and their ROUGE scores available in benchmark datasets as training examples) and thereby learned to maxi- mize the ROUGE scores of the system summaries. <ref type="bibr" target="#b19">Peyrard and Eckle-Kohler (2016b)</ref> on the other hand, learned an approximation of ROUGE scores for individual sentences in a supervised setup, and subsequently employed these estimated sentence scores in an ILP formulation to extract summaries.</p><p>There is also recent work on considering fully automatic evaluation metrics (not relying on hu- man reference summaries), such as the JS di- vergence as optimization objective. <ref type="bibr" target="#b18">Peyrard and Eckle-Kohler (2016a)</ref> used metaheuristics to min- imize JS divergence in a multi-document summa- rization approach and showed that the resulting ex- tractive summaries also scored competitively us- ing ROUGE.</p><p>Regarding AP, there is not much prior work apart from the papers where the different variants of AP have been presented <ref type="bibr" target="#b5">(Harnly et al., 2005;</ref><ref type="bibr" target="#b17">Passonneau et al., 2013;</ref><ref type="bibr" target="#b24">Yang et al., 2016)</ref>. Espe- cially, there is no prior work in optimization-based extractive summarization which has developed an approximation of AP and used it in an objective function.</p><p>However, AP as an evaluation metric is becom- ing ever more important in the context of abstrac- tive summarization, a research topic which has been gaining momentum in the last few years. For example <ref type="bibr" target="#b8">Li (2015)</ref> and <ref type="bibr" target="#b0">Bing et al. (2015)</ref> use an earlier version of AP based on distributional se- mantics ( <ref type="bibr" target="#b17">Passonneau et al., 2013</ref>) to evaluate ab- stractive multi-document summarization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion and Future Work</head><p>We presented a supervised framework that learns automatic Pyramid scores and uses them for optimization-based summary extraction.</p><p>Us- ing the TAC-2009 multi-document summarization dataset, we performed an upper-bound analysis for AP, and we evaluated the summaries extracted with our framework in an end-to-end evaluation using automatic evaluation metrics. We observed that the summaries extracted with our framework achieve significantly better AP scores than several strong baselines, but compared to the upper-bound for AP, there is still a large room for improvement.</p><p>We show that AP and ROUGE catch differ- ent aspects of summary quality, but further work would be needed in order to substantiate the claim that AP is indeed better than ROUGE. One way of doing so would be to perform a human evaluation of high-scoring summaries ac- cording to ROUGE and AP. In general, ROUGE- 1 and ROUGE-2 were considered as the base- lines for validating the performance of AP be- cause these variants strongly correlate with human evaluation methods <ref type="figure">(Owczarzak et al., 2012a,b)</ref>. However, the comparison could be repeated with ROUGE-3, ROUGE-4 and ROUGE-BE, which have been found to predict manual Pyramid bet- ter than ROUGE-1 and ROUGE-2 ( <ref type="bibr" target="#b21">Rankel et al., 2013)</ref>.</p><p>More generally, we see two main directions for future research: (i) the more specific question on how to improve the approximation of AP and (ii) the general need for more research on AP.</p><p>There are several possible ways how to improve the approximation of AP. First, more semantically- oriented features could be developed, e.g., fea- tures based on propositions rather than sentences or n-grams, or word embedding features encoding a large amount of distributional semantic knowl- edge ( <ref type="bibr" target="#b13">Mikolov et al., 2013)</ref>. Second, the linear- ity constraint we used for efficiency reasons could be relaxed. Modeling AP as a non-linear func- tion will presumably enhance the approximation. For the extraction of summaries based on a non- linear function, greedy algorithms or search-based strategies could be used, e.g., the GA we used in this work for the upper-bound computation.</p><p>We see a general need for more research on AP, because the way AP measures the quality aspect of content selection is not only more meaningful than ROUGE, but also applicable to the growing field of abstractive summarization.</p><p>An important direction would be the improve- ment of AP itself, both in terms of methods used to compute AP, and in terms of tools: while the current off-the-shelf system PEAK is a promising start, it is very slow and therefore difficult to apply in practice.</p><p>In this context, we would like to stress that our GA-based method to create training data for learn- ing a model of AP can easily be adapted to any au- tomatic scoring metric, and specifically to other or future AP variants. Finally, we hope to encourage the community to move away from ROUGE and instead consider AP as the main summary evaluation metric. This would be especially interesting for optimization- based approaches, since the quality of the sum- maries created by such approaches depends on the quality of the underlying scoring metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We presented the first work on AP in optimization- based extractive summarization. We computed an upper-bound for AP and developed a super- vised framework which learns an approximation of AP based on automatically generated training instances. We could access a large number of high-quality training data by using the population of a genetic algorithm. Our end-to-end evaluation showed that of our framework significantly outper- forms strong baselines on the AP metric, but also revealed a large room for improvement in compar- ison to the upper-bound, which motivates future work on developing systems with better perfor- mance on the semantically motivated AP metric.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>.</head><label></label><figDesc></figDesc><table>R-1 
R-2 
AP-60 
AP-70 

R-UB 
0.4722 * 0.2062 * 0.5088 
0.3074 
AP-UB 0.3598 
0.1057 
0.5789 * 0.3790 * 

Table 1: Upper bound comparison between 
ROUGE and Automatic Pyramid (AP). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>End-to-end evaluation of our approach on 
TAC-2009. 

</table></figure>

			<note place="foot" n="1"> http://tac.nist.gov/2009/ Summarization</note>

			<note place="foot" n="2"> https://github.com/UKPLab/ coling2016-genetic-swarm-MDS</note>

			<note place="foot" n="3"> http://wiki.dbpedia.org/ nif-abstract-datasets</note>

			<note place="foot" n="4"> http://tac.nist.gov/2009/ Summarization/ 5 The symbol * indicates that the difference compared to</note>

			<note place="foot" n="7"> https://github.com/miso-belica/sumy</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work has been supported by the German Re-search Foundation (DFG) as part of the Research Training Group "Adaptive Preparation of Informa-tion from Heterogeneous Sources" (AIPHES) un-der grant No. GRK 1994/1, and via the German-Israeli Project Cooperation (DIP, grant No. GU 798/17-1).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Abstractive MultiDocument Summarization via Phrase Selection and Merging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidong</forename><surname>Bing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piji</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wai</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Passonneau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1587" to="1597" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Concept-based Summarization using Integer Linear Programming: From Concept Pruning to Multiple Optimal Solutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Boudin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Mougard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoit</forename><surname>Favre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1914" to="1918" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">ClausIE: Clause-based Open Information Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luciano</forename><surname>Del Corro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rainer</forename><surname>Gemulla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22Nd International Conference on World Wide Web</title>
		<meeting>the 22Nd International Conference on World Wide Web<address><addrLine>Rio de Janeiro, Brazil</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="355" to="366" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">LexRank: Graph-based Lexical Centrality As Salience in Text Summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Günes</forename><surname>Erkan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><forename type="middle">R</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="page" from="457" to="479" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A Scalable Global Model for Summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Gillick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoit</forename><surname>Favre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Integer Linear Programming for Natural Language Processing. Association for Computational Linguistics</title>
		<meeting>the Workshop on Integer Linear Programming for Natural Language Processing. Association for Computational Linguistics<address><addrLine>Boulder, Colorado</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="10" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Automation of Summary Evaluation by the Pyramid Method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Harnly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Passonneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Owen</forename><surname>Rambow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference Recent Advances in Natural Language Processing (RANLP)</title>
		<meeting>the International Conference Recent Advances in Natural Language Processing (RANLP)<address><addrLine>Borovets, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="226" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A Repository of State of the Art and Competitive Baseline Summaries for Generic News Summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Conroy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Benoit Favre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nenkova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC&apos;14)</title>
		<meeting>the Ninth International Conference on Language Resources and Evaluation (LREC&apos;14)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iceland</forename><surname>Reykjavik</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="1608" to="1616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Abstractive Multi-document Summarization with Semantic Information Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, Lisbon, Portugal</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, Lisbon, Portugal</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1908" to="1913" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">ROUGE: A Package for Automatic Evaluation of Summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text Summarization Branches Out: Proceedings of the ACL-04</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Association for Computational Linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Workshop</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="74" to="81" />
			<pubPlace>Barcelona, Spain</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The Automatic Creation of Literature Abstracts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans</forename><surname>Peter Luhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Journal of Research Development</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="159" to="165" />
			<date type="published" when="1958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A study of global inference algorithms in multi-document summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th European Conference on IR Research</title>
		<meeting>the 29th European Conference on IR Research<address><addrLine>Rome, Italy, ECIR&apos;07</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="557" to="564" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Distributed Representations of Words and Phrases and their Compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The Pyramid Method: Incorporating Human Content Selection Variation in Summarization Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Passonneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><surname>Mckeown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Speech and Language Processing</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>TSLP)</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">An Assessment of the Accuracy of Automatic Evaluation in Summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karolina</forename><surname>Owczarzak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">M</forename><surname>Conroy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoa</forename><forename type="middle">Trang</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Workshop on Evaluation Metrics and System Comparison for Automatic Summarization. Association for Computational Linguistics</title>
		<meeting>Workshop on Evaluation Metrics and System Comparison for Automatic Summarization. Association for Computational Linguistics<address><addrLine>Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Assessing the Effect of Inconsistent Assessors on Summarization Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karolina</forename><surname>Owczarzak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">A</forename><surname>Rankel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoa</forename><forename type="middle">Trang</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">M</forename><surname>Conroy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="359" to="362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Automated Pyramid Scoring of Summaries using Distributional Semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Passonneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dolores</forename><surname>Perin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="143" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A General Optimization Framework for MultiDocument Summarization Using Genetic Algorithms and Swarm Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxime</forename><surname>Peyrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judith</forename><surname>Eckle-Kohler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on Computational Linguistics</title>
		<meeting>the 26th International Conference on Computational Linguistics<address><addrLine>Osaka, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="247" to="257" />
		</imprint>
	</monogr>
	<note>The COLING 2016 Organizing Committee</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Optimizing an Approximation of ROUGE-a ProblemReduction Approach to Extractive Multi-Document Summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxime</forename><surname>Peyrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judith</forename><surname>Eckle-Kohler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1825" to="1836" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Align, Disambiguate and Walk: A Unified Approach for Measuring Semantic Similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Taher Pilehvar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Jurgens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1341" to="1351" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A Decade of Automatic Content Evaluation of News Summaries: Reassessing the State of the Art</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">M</forename><surname>Rankel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoa</forename><forename type="middle">Trang</forename><surname>Conroy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nenkova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="131" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Large-margin Learning of Submodular Summarization Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruben</forename><surname>Sipos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pannaga</forename><surname>Shivaswamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics. Association for Computational Linguistics</title>
		<meeting>the 13th Conference of the European Chapter of the Association for Computational Linguistics. Association for Computational Linguistics<address><addrLine>Avignon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="224" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning to Generate Summary as Structured Output</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroya</forename><surname>Takamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manabu</forename><surname>Okumura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM international Conference on Information and Knowledge Management</title>
		<meeting>the 19th ACM international Conference on Information and Knowledge Management<address><addrLine>Toronto , ON, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1437" to="1440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">PEAK: Pyramid Evaluation via Automated Knowledge Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Passonneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>De Melo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th AAAI Conference on Artificial Intelligence (AAAI 2016)</title>
		<meeting>the 30th AAAI Conference on Artificial Intelligence (AAAI 2016)<address><addrLine>Phoenix, AZ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
