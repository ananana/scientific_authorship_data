<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:33+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Simple Learning and Compositional Application of Perceptually Grounded Word Meanings for Incremental Reference Resolution</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 26-31, 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Casey</forename><surname>Kennington</surname></persName>
							<email>ckennington@cit-ec. uni-bielefeld.de</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">CITEC</orgName>
								<orgName type="institution" key="instit2">Bielefeld University Universitätsstraße</orgName>
								<address>
									<postCode>25 33615</postCode>
									<settlement>Bielefeld</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Schlangen</surname></persName>
							<email>david.schlangen@ uni-bielefeld.de</email>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">CITEC</orgName>
								<orgName type="institution" key="instit2">Bielefeld University Universitätsstraße</orgName>
								<address>
									<addrLine>25</addrLine>
									<postCode>33615</postCode>
									<settlement>Bielefeld</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Simple Learning and Compositional Application of Perceptually Grounded Word Meanings for Incremental Reference Resolution</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="292" to="301"/>
							<date type="published">July 26-31, 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>An elementary way of using language is to refer to objects. Often, these objects are physically present in the shared environment and reference is done via mention of perceivable properties of the objects. This is a type of language use that is modelled well neither by logical semantics nor by distributional semantics, the former focusing on inferential relations between expressed propositions, the latter on similarity relations between words or phrases. We present an account of word and phrase meaning that is perceptually grounded, trainable, compositional, and &apos;dialogue-plausible&apos; in that it computes meanings word-byword. We show that the approach performs well (with an accuracy of 65% on a 1-out-of-32 reference resolution task) on direct descriptions and target/landmark descriptions, even when trained with less than 800 training examples and automatically transcribed utterances.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The most basic, fundamental site of language use is co-located dialogue <ref type="bibr" target="#b5">(Fillmore, 1975;</ref><ref type="bibr" target="#b2">Clark, 1996)</ref> and referring to objects, as in Example (1), is a common occurrence in such a co-located set- ting.</p><p>(1)</p><p>The green book on the left next to the mug.</p><p>Logical semantics <ref type="bibr" target="#b21">(Montague, 1973;</ref><ref type="bibr" target="#b7">Gamut, 1991;</ref><ref type="bibr" target="#b23">Partee et al., 1993</ref>) has little to say about this process -its focus is on the construction of syntactically manipulable objects that model infer- ential relations; here, e.g. the inference that there are (at least) two objects. Vector space approaches to distributional semantics ( <ref type="bibr" target="#b28">Turney and Pantel, 2010</ref>) similarly focuses on something else, namely semantic similarity relations between words or phrases (e.g. finding closeness for "coloured tome on the right of the cup"). Neither approach by it- self says anything about processing; typically, the assumption in applications is that fully presented phrases are being processed. Lacking in these approaches is a notion of grounding of symbols in features of the world <ref type="bibr" target="#b9">(Harnad, 1990)</ref>. <ref type="bibr">1</ref> In this paper, we present an ac- count of word and phrase meaning that is (a) per- ceptually grounded in that it provides a link be- tween words and (computer) vision features of real images, (b) trainable, as that link is learned from examples of language use, (c) compositional in that the meaning of phrases is a function of that of its parts and composition is driven by structural analysis, and (d) 'dialogue-plausible' in that it computes meanings incrementally, word-by-word and can work with noisy input from an automatic speech recogniser (ASR). We show that the ap- proach performs well (with an accuracy of 65% on a reference resolution task out of 32 objects) on direct descriptions as well as target/landmark de- scriptions, even when trained with little data (less than 800 training examples).</p><p>In the following section we will give a back- ground on reference resolution, followed by a de- scription of our model. We will then describe the data we used and explain our evaluations. We fin- ish by giving results, providing some additional analysis, and discussion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background: Reference Resolution</head><p>Reference resolution (RR) is the task of resolving referring expressions (REs; as in Example <ref type="formula" target="#formula_0">(1)</ref>) to a referent, the entity to which they are intended to refer. Following <ref type="bibr" target="#b13">Kennington et al. (2015a)</ref>, this can be formalised as a function f rr that, given a representation U of the RE and a representation W of the (relevant aspects of the) world, returns I * , the identifier of one the objects in the world that is the referent of the RE. A number of recent papers have used stochastic models for f rr where, given W and U , a distribution over a specified set of can- didate entities in W is obtained and the probabil- ity assigned to each entity represents the strength of belief that it is the referent. The referent is then the argmax:</p><formula xml:id="formula_0">I * = argmax I P (I|U, W )<label>(1)</label></formula><p>Recently, generative approaches, including our own, have been presented ( <ref type="bibr" target="#b6">Funakoshi et al., 2012;</ref><ref type="bibr" target="#b11">Kennington et al., 2013;</ref><ref type="bibr" target="#b12">Kennington et al., 2014;</ref><ref type="bibr" target="#b14">Kennington et al., 2015b;</ref><ref type="bibr" target="#b3">Engonopoulos et al., 2013</ref>) which model U as words or ngrams and the world W as a set of objects in a virtual game board, represented as a set properties or concepts (in some cases, extra-linguistic or discourse as- pects were also modelled in W , such as deixis). In <ref type="bibr" target="#b19">Matuszek et al. (2014)</ref>, W was represented as a distribution over properties of tangible objects and U was a Combinatory Categorical Grammar parse. In all of these approaches, the objects are distinct and represented via symbolically specified prop- erties, such as colour and shape. The set of prop- erties is either read directly from the world if it is virtual, or computed (i.e., discretised) from the real world objects.</p><p>In this paper, we learn a mapping from W to U directly, without mediating symbolic properties; such a mapping is a kind of perceptual ground- ing of meaning between W and U . Situated RR is a convenient setting for learning perceptually- grounded meaning, as objects that are referred to are physically present, are described by the RE, and have visual features that can be computation- ally extracted and represented.</p><p>Further comparison to related work will be dis- cussed in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Modelling Reference to Visible Objects</head><p>Overview As a representative of the kind of model explained above with formula (1), we want our model to compute a probability distribution over candidate objects, given a RE (or rather, pos- sibly just a prefix of it). We break this task down into components: The basis of our model is a model of word meaning as a function from per- ceptual features of a given object to a judgement about how well a word and that object "fit to- gether". (See Section 5 for discussion of prior uses of this "words as classifiers"-approach.) This can (loosely) be seen as corresponding to the inten- sion of a word, which for example in Montague's approach is similarly modelled as a function, but from possible worlds to extensions <ref type="bibr" target="#b7">(Gamut, 1991)</ref>. We model two different types of words / word meanings: those picking out properties of single objects (e.g., "green" in "the green book"), follow- ing <ref type="bibr" target="#b13">Kennington et al. (2015a)</ref>, and those picking out relations of two objects (e.g., "next to" in (1)), going beyond <ref type="bibr" target="#b13">Kennington et al. (2015a)</ref>. These word meanings are learned from instances of lan- guage use.</p><p>The second component then is the application of these word meanings in the context of an actual reference and within a phrase. This application gives the desired result of a probability distribu- tion over candidate objects, where the probability expresses the strength of belief in the object falling in the extension of the expression. Here we model two different types of composition, of what we call simple references and relational references. These applications are strictly compositional in the sense that the meanings of the more complex construc- tions are a function of those of their parts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Word Meanings</head><p>The first type of word (or rather, word meaning) we model picks out a sin- gle object via its visual properties. (At least, this is what we use here; any type of feature could be used.) To model this, we train for each word w from our corpus of REs a binary logistic regression classifier that takes a representation of a candidate object via visual features (x) and returns a proba- bility p w for it being a good fit to the word (where w is the weight vector that is learned and σ is the logistic function):</p><formula xml:id="formula_1">p w (x) = σ(w x + b)<label>(2)</label></formula><p>Formalising the correspondence mentioned above, the intension of a word can in this approach then be seen as the classifier itself, a function from a representation of an object to a probability:</p><formula xml:id="formula_2">[[w]] obj = λx.p w (x)<label>(3)</label></formula><p>(Where <ref type="bibr">[[w]</ref>] denotes the meaning of w, and x is of the type of feature given by f obj , the function computing a feature representation for a given ob- ject.)</p><p>We train these classifiers using a corpus of REs (further described in Section 4), coupled with rep- resentations of the scenes in which they were used and an annotation of the referent of that scene. The setting was restricted to reference to single ob- jects. To get positive training examples, we pair each word of a RE with the features of the refer- ent. To get negative training examples, we pair the word with features of (randomly picked) other ob- jects present in the same scene, but not referred to by it. This selection of negative examples makes the assumption that the words from the RE apply only to the referent. This is wrong as a strict rule, as other objects could have similar visual features as the referent; for this to work, however, this has to be the case only more often than it is not.</p><p>The second type of word that we model ex- presses a relation between objects. Its meaning is trained in a similar fashion, except that it is pre- sented a vector of features of a pair of objects, such as their euclidean distance, vertical and hor- izontal differences, and binary features denoting higher than/lower than and left/right relationships.</p><p>Application and Composition The model just described gives us a prediction for a pair of word and object (or pair of objects). What we wanted, however, is a distribution over all candidate ob- jects in a given utterance situation, and not only for individual words, but for (incrementally growing) REs. Again as mentioned above, we model two types of application and composition. First, what we call 'simple references'-which roughly cor- responds to simple NPs-that refer only by men- tioning properties of the referent (e.g. "the red cross on the left"). To get a distribution for a sin- gle word, we apply the word classifier (the inten- sion) to all candidate objects and normalise; this can then be seen as the extension of the word in a given (here, visual) discourse universe W , which provides the candidate objects (x i is the feature vector for object i, normalize() vectorized nor- malisation, and I a random variable ranging over the candidates):</p><formula xml:id="formula_3">[[w]] W obj = normalize(([[w]] obj (x1), . . . , [[w]] obj (x k ))) = normalize((pw(x1), . . . , pw(x k ))) = P (I|w) (4)</formula><p>In effect, this combines the individual classifiers into something like a multi-class logistic regres- sion / maximum entropy model-but, nota bene, only for application. The training regime did not need to make any assumptions about the number of objects present, as it trained classifiers for a 2- class problem (how well does this given object fit to the word?). The multi-class nature is also indi- cated in <ref type="figure">Figure 1</ref>, which shows multiple applica- tions of the logistic regression network for a word, and a normalisation layer on top.</p><formula xml:id="formula_4">(w | x 1 + b) (w | x 2 + b) (w | x 3 + b) x 1 x 2 x 3</formula><p>Figure 1: Representation as network with normalisation layer.</p><p>To compose the evidence from individual words w 1 , . . . , w k into a prediction for a 'simple' RE [ sr w 1 , . . . , w k ] (where the bracketing indicates the structural assumption that the words belong to one, possibly incomplete, 'simple reference'), we average the contributions of its constituent words. The averaging function avg() over distributions then is the contribution of the construction 'sim- ple reference (phrase)', sr, and the meaning of the whole phrase is the application of the meaning of the construction to the meaning of the words:</p><formula xml:id="formula_5">[[[srw1, . . . , w k ]]] W = [[sr]] W [[w1, . . . , w k ]] W = avg([[w1]] W , . . . , [[w k ]] W ) (5)</formula><p>where avg() is defined as <ref type="bibr">w2)</ref> with</p><formula xml:id="formula_6">avg([[w1]] W , [[w2]] W ) = Pavg(I|w1,</formula><formula xml:id="formula_7">Pavg(I = i|w1, w2) = 1 2 (P (I = i|w1) + P (I = i|w2)) for i ∈ I (6)</formula><p>The averaging function is inherently incre- mental, in the sense that avg(a, b, c) = avg(avg(a, b), c) and hence it can be extended "on the right". This represents an incremental model where new information from the current increment is added to what is already known, resulting in an intersective way of composing the meaning of the phrase. This cannot account for all constructions (such as negation or generally quantification), of course; we leave exploring other constructions that could occur even in our 'simple references' to fu- ture work.</p><p>Relational references such as in Exam- ple (1) from the introduction have a more complex structure, being a relation between a (simple) reference to a landmark and a (sim- ple) reference to a target. This structure is indicated abstractly in the following 'parse':</p><formula xml:id="formula_8">[ rel [ sr w 1 , . . . , w k ][ r r 1 , . . . , r n ][ sr w 1 , . . . , w m ]]</formula><p>, where the w are the target words, r the relational expression words, and w the landmark words.</p><p>As mentioned above, the relational expression similarly is treated as a classifier (in fact, techni- cally we contract expressions such as "to the left of" into a single token and learn one classifier for it), but expressing a judgement for pairs of objects. It can be applied to a specific scene with a set of candidate objects (and hence, candidate pairs) in a similar way by applying the classifier to all pairs and normalising, resulting in a distribution over pairs:</p><formula xml:id="formula_9">[[r]] W = P (R1, R2|r)<label>(7)</label></formula><p>We expect the meaning of the phrase to be a function of the meaning of the constituent parts (the simple references, the relation expression, and the construction), that is:</p><formula xml:id="formula_10">[[[ rel [srw1, . . . , w k ][rr][srw 1 , . . . , w m ]]]] = [[rel]]([[sr]][[w1 . . . w k ]], [[r]], [[sr]][[w 1 . . . w m ]])<label>(8)</label></formula><p>(dropping the indicator for concrete application,</p><formula xml:id="formula_11">W on [[ ]]</formula><p>, for reasons of space and readability).</p><p>What is the contribution of the relational con- struction, <ref type="bibr">[[rel]</ref>]? Intuitively, what we want to express here is that the belief in an object be- ing the intended referent should combine the ev- idence from the simple reference to the land- mark object (e.g., "the mug" in (1)), from the simple (but presumably deficient) reference to the target object ("the green book on the left"), and that for the relation between them ("next to"). Instead of averaging (that is, combining additively), as for sr, we combine this evidence multiplicatively here: If the target constituent contributes P (I t |w 1 , . . . , w k ), the landmark con- stituent P (I l |w 1 , . . . , w m ), and the relation ex- pression P (R 1 , R 2 |r), with I l , I t , R 1 and R 2 all having the same domain, the set of all candidate objects, then the combination is</p><formula xml:id="formula_12">P (R1|w1, . . . , w k , r, w 1 , . . . , w m ) = R 2 I l I t P (R1, R2|r) * P (I l |w 1 , . . . , w m ) * P (It|w1, . . . , w k ) * P (R1|It) * P (R2|I l )<label>(9)</label></formula><p>The last two factors force identity on the elements of the pair and target and landmark, respectively (they are not learnt, but rather set to be 0 unless the values of R and I are equal), and so effectively reduce the summations so that all pairs need to be evaluated only once. The contribution of the con- struction then is this multiplication of the contri- butions of the parts, together with the factors en- forcing that the pairs being evaluated by the rela- tion expression consist of the objects evaluated by target and landmark expression, respectively.</p><p>In the following section, we will explain the data we collected and used to evaluate our model, the evaluation procedure, and the results. Data We evaluated our model using data we col- lected in a Wizard-of-Oz setting (that is, a hu- man/computer interaction setting where parts of the functionality of the computer system were pro- vided by a human experimentor). Participants were seated in front of a table with 36 Pen- tomino puzzle pieces that were randomly placed with some space between them, as shown in <ref type="figure" target="#fig_0">Figure 2</ref>. Above the table was a camera that recorded a video feed of the objects, processed using OpenCV ( <ref type="bibr" target="#b24">Pulli et al., 2012</ref>) to segment the objects (see below for details); of those, one (or one pair) was chosen randomly by the experiment software. The video image was presented to the participant on a display placed behind the table, but with the randomly selected piece (or pair of pieces) indicated by an overlay).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>The task of the participant was to refer to that object using only speech, as if identifying it for a friend sitting next to the participant. The wizard (experimentor) had an identical screen depicting the scene but not the selected object. The wiz- ard listened to the participant's RE and clicked on the object she thought was being referred on her screen. If it was the target object, a tone sounded and a new object was randomly chosen. This con- stituted a single episode. If a wrong object was clicked, a different tone sounded, the episode was flagged, and a new episode began. At varied in- tervals, the participant was instructed to "shuffle" the board between episodes by moving around the pieces.</p><p>The first half of the allotted time constituted phase-1. After phase-1 was complete, instructions for phase-2 were explained: the screen showed the target and also a landmark object, outlined in blue, near the target (again, see <ref type="figure" target="#fig_0">Figure 2</ref>). The partici- pant was to refer to the target using the landmark. (In the instructions, the concepts of landmark and target were explained in general terms.) All other instructions remained the same as phase-1. The target's identifier, which was always known be- forehand, was always recorded. For phase-2, the landmark's identifier was also recorded.</p><p>Nine participants (6 female, 3 male; avg. age of 22) took part in the study; the language of the study was German. Phase-1 for one partici- pant and phase-2 for another participant were not used due to misunderstanding and a technical diffi- culty. This produced a corpus of 870 non-flagged episodes in total. Even though each episode had 36 objects in the scene, all objects were not always recognised by the computer vision processing. On average, 32 objects were recognized.</p><p>To obtain transcriptions, we used Google Web Speech (with a word error rate of 0.65, as deter- mined by comparing to a hand transcribed sample) This resulted in 1587 distinct words, with 15.53 words on average per episode. The objects were not manipulated in any way during an episode, so the episode was guaranteed to remain static during a RE and a single image is sufficient to represent the layout of one episode's scene. Each scene was processed using computer vision techniques to ob- tain low-level features for each (detected) object in the scene which were used for the word classifiers.</p><p>We annotated each episode's RE with a simple tagging scheme that segmented the RE into words that directly referred to the target, words that di- rectly referred to the landmark (or multiple land- marks, in some cases) and the relation words. For certain word types, additional information about the word was included in the tag if it described colour, shape, or spatial placement (denoted con- tributing REs in the evaluations below). The direc- tion of certain relation words was normalised (e.g., left-of should always denote a landmark-target re- lation). This represents a minimal amount of "syn- tactic" information needed for the application of the classifiers and the composition of the phrase meanings. We leave applying a syntactic parser to future work. An example RE in the original Ger- man (as recognised by the ASR), English gloss, and tags for each word is given in <ref type="bibr">(2)</ref>. <ref type="formula" target="#formula_1">(2)</ref> a. grauer steinüberstein¨steinüber dem grünen m unten links b.</p><p>gray block above the green m bottom left c.</p><p>tc ts r l lc ls tf tf</p><p>To obtain visual features of each object, we used the same simple computer-vision pipeline of ob- ject segmentation and contour reconstruction as used by <ref type="bibr" target="#b13">Kennington et al. (2015a)</ref>, providing us with RGB representations for the colour and fea- tures such as skewness, number of edges etc. for the shapes.</p><p>Procedure We break down our data as follows: episodes where the target was referred directly via a 'simple reference' construction (DD; 410 episodes) and episodes where a target was referred via a landmark relation (RD; 460 episodes). We also test with either knowledge about structure (simple or relational reference) provided (ST) or not (WO, for "words-only"). All results shown are from 10-fold cross validations averaged over 10 runs; where for evaluations labelled RD the train- ing data always includes all of <ref type="bibr">DD</ref>  Words were stemmed using the NLTK <ref type="bibr" target="#b18">(Loper and Bird, 2002</ref>) Snowball Stemmer, reducing the vocabulary size to 1306. Due to sparsity, for rela- tion words with a token count of less than 4 (found by ranging over values in a held-out set) relational features were piped into an UNK relation, which was used for unseen relations during evaluation (we assume the UNK relation would learn a gen- eral notion of 'nearness'). For the individual word classifiers, we always paired one negative example with one positive example.</p><p>For this evaluation, word classifiers for sr were given the following features: RGB values, HSV values, x and y coordinates of the centroids, eu- clidean distance of centroid from the center, and number of edges. The relation classifiers received information relating two objects, namely the eu- clidean distance between them, the vertical and horizontal distances, and two binary features that denoted if the landmark was higher than/lower than or left/right of the target. Metrics for Evaluation To give a picture of the overall performance of the model, we report accu- racy (how often was the argmax the gold target) and mean reciprocal rank (MRR) of the gold tar- get in the distribution over all the objects (like ac- curacy, higher MRR values are better; values range between 0 and 1). The use of MRR is motivated by the assumption that in general, a good rank for the correct object is desirable, even if it doesn't reach the first position, as when integrated in a dialogue system this information might still be useful to for- mulate clarification questions.</p><p>Results <ref type="figure" target="#fig_1">Figure 3</ref> shows the results. (Random baseline of 1/32 or 3% not shown in plot.) DD.WO shows how well the sr model performs using the whole utterances and not just the REs. (Note that all evaluations are on noisy ASR transcriptions.) DD.ST adds structure by only considering words that are part of the actual RE, improving the re- sults further. The remaining sets evaluate the con- tributions of the rr model. RD.ST (sr) does this indirectly, by including the target and landmark simple references, but not the model for the rela- tions; the task here is to resolve target and land- mark SRs as they are. This provides the baseline for the next two evaluations, which include the re- lation model. In RD.ST (sr+r), the model learns SRs from DD data and only relations from RD. The performance is substantially better than the base- line without the relation model. Performance is best finally for RD.ST (rr), where the landmark and target SRs in the training portion of RD also contribute to the word models.</p><p>The mean reciprocal rank scores follow a sim- ilar pattern and show that even though the target object was not the argmax of the distribution, on average it was high in the distribution. For all eval- uations, the average standard deviation across the 10 runs was very small (0.01), meaning the model was fairly stable, despite the possibility of one run having randomly chosen more discriminating neg- ative examples. Our conclusion from these exper- iments is that despite the small amount of training data and noise from ASR as well as the scene, the model is robust and yields respectable results. Incremental Results <ref type="figure" target="#fig_2">Figure 5</ref> shows how our rr model processes incrementally, by giving the average rank of the (gold) target at each increment for the REs with the most common length in our data (13 words, of which there were 64 examples). A system that works incrementally would have a monotonically decreasing average rank as the ut- terance unfolds. The overall trend as shown in that 297 100 200 300 400 500 600 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9</p><note type="other">100 200 300 400 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.</note><p>Figure 4: Each plot represents how well selected words fit assumptions about their lexical semantics: the leftmost plot ecke (corner) yields higher probabilities as objects are closer to the corner; the middle plot grün (green) yields higher probabilities when the colour spectrum values are nearer to green; the rightmost plotüberplot¨plotüber (above) yields higher probabilities when targets are nearer to a landmark set in the middle.</p><p>Figure is as expected. There is a slight increase between 6-7, though very small (a difference of 0.09). Overall, these results seem to show that our model indeed works intersectively and "zooms in" on the intended referent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Further Analysis</head><p>Analysis of Selected Words We analysed sev- eral individual word classifiers to determine how well their predictions match assumptions about their lexical semantics. For example, for the spa- tial word Ecke (corner), we would expect its clas- sifier to return high probabilities if features related to an object's position (e.g., x and y coordinates, distance from the center) are near corners of the scene. The leftmost plot in <ref type="figure">Figure 4</ref> shows that this is indeed the case; by holding all non-position features constant and ranging over all points on the screen, we can see that the classifier gives high probabilities around the edges, particularly in the four corners, and very low probabilities in the mid- dle region. Similarly for the colour word grün, the centre plot in <ref type="figure">Figure 4</ref> (overlaid with a colour spectrum) shows high probabilities are given when presented with the colour green, as expected. Sim- ilarly, for the relational wordüberword¨wordüber (above), by treating the center point as the landmark and rang- ing over all other points on the plot for the target, thë uber classifier gives high probabilities when directly above the center point, with linear nega- tive growth as the distance from the landmark in- creases.</p><p>Note that we selected the type of feature to vary here for presentation; all classifiers get the full fea- ture set and learn automatically to "ignore" the ir- relevant features (e.g., that for grün does not re- spond to variations in positional features). They do this wuite well, but we noticed some 'blurring', due to not all combinations of colours and shape being represented in the objects in the training set. <ref type="figure" target="#fig_4">Figure 6</ref> finally shows the interpretation of the RE in Ex- ample (2) in the scene from <ref type="figure" target="#fig_0">Figure 2</ref>. The top row depicts the distribution over objects (true tar- get shown in red) after the relation word unten (bottom) is uttered; the second row that for land- mark objects, after the landmark description be- gins (dem grünen m / the green m). The third row (target objects), ceases to change after the rela- tional word is uttered, but continues again as ad- ditional target words are uttered (unten links / bot- tom left). While the true target is ranked highly already on the basis of the target SR alone, it is only when the relational information is added (top row) that it becomes argmax.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis of Incremental Processing</head><p>Discussion We did not explore how well our model could handle generalised quantifiers, such as all (e.g., all the red objects) or a specific num- ber of objects (e.g., the two green Ts). We specu- late that one could see as the contribution of words such as all or two a change to how the distribution is evaluated ("return the n top candidates"). Our model also doesn't yet directly handle more de- scriptive REs like the cross in the top-right corner on the left, as left is learned as a global term, or negation (the cross that's not red). We leave ex- ploring such constructions to future work. <ref type="bibr" target="#b10">Kelleher et al. (2005)</ref> approached RR us- ing perceptually-grounded models, focusing on saliency and discourse context. In <ref type="bibr" target="#b8">Gorniak and Roy (2004)</ref>, descriptions of objects were used to learn a perceptually-grounded meaning with focus on spatial terms such as on the left. Steels and <ref type="bibr" target="#b27">Belpaeme (2005)</ref> used neural networks to connect language with colour terms by interacting with hu- mans. <ref type="bibr" target="#b16">Larsson (2013)</ref> is closest in spirit to what we are attempting here; he provides a detailed grauer stein über dem grünen m unten links formal semantics for similarly descriptive terms, where parts of the semantics are modelled by a perceptual classifier. These approaches had lim- ited lexicons (where we attempt to model all words in our corpus), and do not process incrementally, which we do here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Recent efforts in multimodal distributional se- mantics have also looked at modelling word mean- ing based on visual context. Originally, vector space distributional semantics focused words in the context of other words <ref type="bibr" target="#b28">(Turney and Pantel, 2010)</ref>; recent multimodal approaches also con- sider low-level features from images. <ref type="bibr" target="#b0">Bruni et al. (2012)</ref> and <ref type="bibr" target="#b1">Bruni et al. (2014)</ref> for example model word meaning by word and visual con- text; each modality is represented by a vector, fused by concatenation. <ref type="bibr">Socher et al. (2014)</ref> and <ref type="bibr" target="#b15">Kiros et al. (2014)</ref> present approaches where words/phrases and images are mapped into the same high-dimensional space. While these ap- proaches similarly provide a link between words and images, they are typically tailored towards a different setting (the words being descriptions of the whole image, and not utterance intended to perform a function within a visual situation). We leave more detailed exploration of similarities and differences to future work and only note for now that our approach, relying on much simpler classifiers (log-linear, basically), works with much smaller data sets and additionally seem to pro- vide an easier interface to more traditional ways of composition (see Section 3 above).</p><p>The issue of semantic compositionality is also actively discussed in the distributional semantics literature (see, e.g., <ref type="bibr" target="#b20">(Mitchell and Lapata, 2010;</ref><ref type="bibr" target="#b4">Erk, 2013;</ref><ref type="bibr" target="#b17">Lewis and Steedman, 2013;</ref><ref type="bibr" target="#b22">Paperno et al., 2014)</ref>), investigating how to combine vec- tors. This could be seen as composition on the level of intensions (if one sees distributional rep- resentations as intensions, as is variously hinted at, e.g. <ref type="bibr" target="#b4">Erk (2013)</ref>). In our approach, composition is done on the extensional level (by interpolating distributions over candidate objects).</p><p>We do not see our approach as being in op- position to these attempts. Rather, we envision a system of semantics that combines traditional symbolic expressions (on which inferences can be modelled via syntactic calculi) with distributed representations (which model conceptual knowl- edge / semantic networks, as well as encyclopedic knowledge) and with our action-based (namely, identification in the environment via perceptual information) semantics. This line of approach is connected to a number of recent works (e.g., <ref type="bibr" target="#b4">(Erk, 2013;</ref><ref type="bibr" target="#b17">Lewis and Steedman, 2013;</ref><ref type="bibr" target="#b16">Larsson, 2013)</ref>); for now, exploring its ramifications is left for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we presented a model of reference resolution that learns a perceptually-grounded meaning of words, including relational words. The model is simple, compositional, and robust despite low amounts of training data and noisy modalities. Our model is not without limitations; it so far only handles definite descriptions, yet there are other ways to refer to real-world objects, such as via pro- nouns and deixis. A unified model that can handle all of these, similar in spirit perhaps to <ref type="bibr" target="#b6">Funakoshi et al. (2012)</ref>, but with perceptual groundings, is left for future work. Our approach could also ben- efit from improved object segmentation and repre-sentation.</p><p>Our next steps with this model is to handle com- positional structures without relying on our closed tag set (e.g., using a syntactic parser). We also plan to test our model in a natural, interactive dia- logue system.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Example episode for phase-2 where the target is outlined in green (solid arrow added here for presentation), the landmark outlined in blue (dashed arrow).</figDesc><graphic url="image-18.png" coords="4,323.96,304.11,182.48,146.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Results of our evaluation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Incremental results: average rank improves over time</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: A depiction of the model working incrementally for the RE in Example (2): the distribution over objects for relation is row 1, landmark is row 2, target is row 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>plus 9 folds of RD, testing on RD. The sets address the following questions:</figDesc><table>• how well does the sr model work on its own 
with just words? -DD.WO 
• how well does the sr model work when it 
knows about REs? -DD.ST 
• how well does the sr model work when it 
knows about REs, but not about relations? -
RD.ST (sr) 
• how well does the model learn relation words 
after it has learned about sr? RD.ST (r) 
• how well does the rr model work (together 
with the sr)? RD.ST with DD.ST (rr) 

</table></figure>

			<note place="foot" n="1"> But see discussion below of recent extensions of these approaches taking this into account.</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Distributional semantics in technicolor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elia</forename><surname>Bruni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gemma</forename><surname>Boleda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Namkhanh</forename><surname>Tran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="136" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Multimodal distributional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elia</forename><surname>Bruni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nam</forename><forename type="middle">Khanh</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="1" to="47" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Using Language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Herbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Clark</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<publisher>Cambridge University Press</publisher>
			<biblScope unit="volume">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Predicting the resolution of referring expressions from user behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Engonopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Villalba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMLNP</title>
		<meeting>EMLNP<address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1354" to="1359" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Towards a semantics for distributional representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katrin</forename><surname>Erk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IWCS</title>
		<meeting>IWCS<address><addrLine>Potsdam, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Pragmatics and the description of discourse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fillmore</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975" />
			<biblScope unit="page" from="143" to="166" />
		</imprint>
	</monogr>
	<note>Radical pragmatics</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A Unified Probabilistic Approach to Referring Expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kotaro</forename><surname>Funakoshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikio</forename><surname>Nakano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takenobu</forename><surname>Tokunaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryu</forename><surname>Iida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGDial</title>
		<meeting>SIGDial<address><addrLine>Seoul, South Korea</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012-07" />
			<biblScope unit="page" from="237" to="246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Logic, Language and Meaning: Intensional Logic and Logical Grammar</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L T F</forename><surname>Gamut</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991" />
			<publisher>Chicago University Press</publisher>
			<biblScope unit="volume">2</biblScope>
			<pubPlace>Chicago</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Grounded semantic composition for visual scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Gorniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deb</forename><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="429" to="470" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The Symbol Grounding Problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stevan</forename><surname>Harnad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physica D</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="335" to="346" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Dynamically structuring, updating and interrelating representations of visual and linguistic discourse context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Kelleher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fintan</forename><surname>Costello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jofsef</forename><surname>Van Genabith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">167</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="62" to="102" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Interpreting Situated Dialogue Utterances: an Update Model that Uses Speech, Gaze, and Gesture Information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Casey</forename><surname>Kennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyros</forename><surname>Kousidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Schlangen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGdial</title>
		<meeting>SIGdial</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Situated Incremental Natural Language Understanding using a Multimodal, Linguistically-driven Update Model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Casey</forename><surname>Kennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyros</forename><surname>Kousidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Schlangen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoLing</title>
		<meeting>CoLing</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A Discriminative Model for PerceptuallyGrounded Incremental Reference Resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Casey</forename><surname>Kennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Livia</forename><surname>Dia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Schlangen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IWCS. Association for Computational Linguistics</title>
		<meeting>IWCS. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Incrementally Tracking Reference in Human/Human Dialogue Using Linguistic and Extra-Linguistic Information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Casey</forename><surname>Kennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryu</forename><surname>Iida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takenobu</forename><surname>Tokunaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Schlangen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">.A. Association for Computational Linguistics</title>
		<meeting><address><addrLine>Denver, U.S</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>NAACL</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS 2014 Deep Learning Workshop</title>
		<meeting>NIPS 2014 Deep Learning Workshop</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Formal semantics for perceptual classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Staffan Larsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Logic and Computation</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Combined Distributional and Logical Semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the ACL</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="179" to="192" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">NLTK: The natural language toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Loper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL-02 Workshop on Effective tools and methodologies for teaching natural language processing and computational linguistics</title>
		<meeting>the ACL-02 Workshop on Effective tools and methodologies for teaching natural language processing and computational linguistics</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="63" to="70" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning from Unscripted Deictic Gesture and Language for Human-Robot Interactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cynthia</forename><surname>Matuszek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liefeng</forename><surname>Bo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dieter</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Composition in distributional models of semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive science</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1388" to="1429" />
			<date type="published" when="2010-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The Proper Treatment of Quantifikation in Ordinary English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Montague</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Approaches to Natural Language: Proceedings of the 1970 Stanford Workshop on Grammar and Semantics</title>
		<editor>J Hintikka, J Moravcsik, and P Suppes</editor>
		<meeting><address><addrLine>Dordrecht</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1973" />
			<biblScope unit="page" from="221" to="242" />
		</imprint>
	</monogr>
	<note>Reidel</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A practical and linguistically-motivated approach to compositional distributional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denis</forename><surname>Paperno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nghia The</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="90" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Mathematical Methods in Linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alice</forename><surname>Barbara H Partee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">E</forename><surname>Ter Meuelen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wall</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>Kluwer Academic Publishers</publisher>
			<pubPlace>Dordrecht</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Real-time computer vision with OpenCV</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kari</forename><surname>Pulli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anatoly</forename><surname>Baksheev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kirill</forename><surname>Kornyakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Eruhimov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="61" to="69" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Y</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<title level="m">Grounded Compositional Semantics for Finding and Describing Images with Sentences. Transactions of the Association for Computational Linguistics (TACL)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="207" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Coordinating perceptually grounded categories through language: a case study for colour. The Behavioral and brain sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Steels</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tony</forename><surname>Belpaeme</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="489" to="529" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">From Frequency to Meaning: Vector Space Models of Semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Turney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pantel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="141" to="188" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
