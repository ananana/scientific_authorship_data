<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:27+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Hierarchical Summarization: Scaling Up Multi-Document Summarization</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>June 23-25 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janara</forename><surname>Christensen</surname></persName>
							<email>janara@cs.washington.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computer Science &amp; Engineering</orgName>
								<orgName type="department" key="dep2">Mausam Computer Science &amp; Engineering</orgName>
								<orgName type="institution">University of Washington Seattle</orgName>
								<address>
									<country>USA, India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
							<email>soderlan@cs.washington.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computer Science &amp; Engineering</orgName>
								<orgName type="department" key="dep2">Mausam Computer Science &amp; Engineering</orgName>
								<orgName type="institution">University of Washington Seattle</orgName>
								<address>
									<country>USA, India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gagan</forename><surname>Bansal</surname></persName>
							<email>gaganbansal1993@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computer Science &amp; Engineering</orgName>
								<orgName type="department" key="dep2">Mausam Computer Science &amp; Engineering</orgName>
								<orgName type="institution">University of Washington Seattle</orgName>
								<address>
									<country>USA, India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Hierarchical Summarization: Scaling Up Multi-Document Summarization</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="902" to="912"/>
							<date type="published">June 23-25 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Multi-document summarization (MDS) systems have been designed for short, un-structured summaries of 10-15 documents, and are inadequate for larger document collections. We propose a new approach to scaling up summarization called hierarchical summarization, and present the first implemented system, SUMMA. SUMMA produces a hierarchy of relatively short summaries, in which the top level provides a general overview and users can navigate the hierarchy to drill down for more details on topics of interest. SUMMA optimizes for coherence as well as coverage of salient information. In an Amazon Mechanical Turk evaluation, users pref-ered SUMMA ten times as often as flat MDS and three times as often as timelines.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The explosion in the number of documents on the Web necessitates automated approaches that organize and summarize large document col- lections on a complex topic. Existing methods for multi-document summarization (MDS) are de- signed to produce short summaries of 10-15 doc- uments. <ref type="bibr">1</ref> MDS systems do not scale to data sets ten times larger and proportionately longer sum- maries: they either cannot run on large input or produce a disorganized summary that is difficult to understand.</p><p>We present a novel MDS paradigm, hierarchi- cal summarization, which operates on large doc- ument collections, creating summaries that orga- nize the information coherently. It mimics how someone with a general interest in a complex topic would learn about it from an expert -first, the ex- pert would provide an overview, and then more</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The explosion in the number of documents over the Web necessitates automated approaches that organize and summarize large document collec- tions on a complex topic. Existing methods for multi-document summarization (MDS) can handle 10-15 documents and create a short flat summary, but are insufficient for large-scale summarization. For large-scale summarization, we need summa- rizers that organize the information coherently and enable personalized interaction with the summary so that users can explore the various aspects of in- formation in different levels of detail based on in- dividual interest.</p><p>To this end, we present a novel MDS paradigm, hierarchical summarization. Hierarchical summa- rization is designed to operate on large document collections. It mimics how someone with a gen- eral interest in a complex topic would learn about Figure 1: An example of a hierarchical summary for the 1998 embassy bombings, with one branch of the hierarchy high- lighted. Each rectangle represents a summary and each x i,j represents a sentence within a summary. The root summary provides an overview of the events of August 1998. When the last sentence is selected, a more detailed summary of the mis- sile strikes is produced, and when the middle sentence of that summary is selected, a more detailed summary bin Laden's escape is produced.</p><p>it from an expert -first, the expert would give an overview, and then more specific information about various aspects. It has the following novel characteristics:</p><p>Figure 1: A hierarchical summary of the 1998 embassy bombings. Each rectangle represents a summary and each xi,j is a sentence within a summary. The root summary pro- vides an overview of the events of August 1998. When the third sentence is selected, a more detailed summary of the missile strikes is displayed. Selecting the second sentence of that summary produces a more detailed summary of the US' options.</p><p>specific information about various aspects. Hi- erarchical summarization has the following novel characteristics:</p><p>• The summary is hierarchically organized along one or more organizational principles such as time, location, entities, or events.</p><p>• Each non-leaf summary is associated with a set of child summaries where each gives de- tails of an element (e.g. sentence) in the par- ent summary.</p><p>• A user can navigate within the hierarchical summary by clicking on an element of a par- ent summary to view the associated child summary. For example, given the topic, "1998 embassy bombings," the first summary <ref type="figure">(Figure 1</ref>) might mention that the US retaliated by striking Afghanistan and Sudan. The user can click on this information to learn more about these attacks. In this way, the system can present large amounts of information without overwhelming the user, and the user can tailor the output to their interests.</p><p>In this paper, we describe SUMMA, the first hierarchical summarization system for multi- document summarization. <ref type="bibr">2</ref> It operates on a corpus of related news articles. SUMMA hierarchically clusters the sentences by time, and then summa- rizes the clusters using an objective function that optimizes salience and coherence.</p><p>We conducted an Amazon Mechanical Turk (AMT) evaluation where AMT workers compared the output of SUMMA to that of timelines and flat summaries. SUMMA output was judged superior more than three times as often as timelines, and users learned more in twice as many cases. Users overwhelmingly preferred hierarchical summaries to flat summaries (92%) and learned just as much.</p><p>Our main contributions are as follows:</p><p>• We introduce and formalize the novel task of hierarchical summarization.</p><p>• We present SUMMA, the first hierarchical summarization system, which operates on news corpora and summarizes over an or- der of magnitude more documents than tra- ditional MDS systems, producing summaries an order of magnitude larger.</p><p>• We present a user study which demonstrates the value of hierarchical summarization over timelines and flat multi-document summaries in learning about a complex topic. In the next section, we formalize hierarchical summarization. We then describe our methodol- ogy to implement the SUMMA hierarchical sum- marization system: hierarchical clustering in Sec- tion 3 and creating summaries based on that clus- tering in Section 4. We discuss our experiments in Section 5, related work in Section 6, and conclu- sions in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Hierarchical Summarization</head><p>We propose a new task for large-scale summariza- tion called hierarchical summarization. Input to a hierarchical summarization system is a set of re- lated documents D and a budget b for each sum- mary within the hierarchy (in bytes, words, or sen- tences). The output is the hierarchical summary H, which we define formally as follows.</p><p>Definition A hierarchical summary H of a docu- ment collection D is a set of summaries X orga- nized into a hierarchy. The top of the hierarchy is a summary X 1 representing all of D, and each summary X i consists of summary units x i,j (e.g. the jth sentence of summary i) that point to a child summary, except at the leaf nodes of the hierarchy.</p><p>A child summary adds more detail to the infor- mation in its parent summary unit. The child sum- mary may include sub-events or background and reactions to the event or topic in the parent.</p><p>We define several metrics in Section 4 for a well-constructed hierarchical summary. Each summary should maximize coverage of salient in- formation; it should minimize redundancy; and it should have intra-cluster coherence as well as parent-to-child coherence.</p><p>Hierarchical summarization has two important strengths in the context of large-scale summariza- tion. First, the information presented at the start is small and grows only as the user directs it, so as not to overwhelm the user. Second, each user directs his or her own experience, so a user inter- ested in one aspect need only explore that section of the data without having to view or understand the entire summary. The parent-to-child links pro- vide a means for a user to navigate, drilling down for more details on topics of interest.</p><p>There are several possible organizing principles for the hierarchy -by date, by entities, by loca- tions, or by events. Some organizing principles will fit the data in a document collection better than others. A system may select different orga- nization for different portions of the hierarchy, for example, organizing first by location or prominent entity and then by date for the next level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Hierarchical Clustering</head><p>Having defined the task, we now describe the methodology behind our implementation, SUMMA. In future work we intend to design a system that dynamically selects the best organiz- ing principle for each level of the hierarchy. In this first implementation, we have opted for tem- poral organization, since this is generally the most appropriate for news events.</p><p>The problem of hierarchical summarization as described in Section 2 has all of the requirements of MDS, and additional complexities of inducing a hierarchical structure, processing an order of mag- nitude bigger input, generating a much larger out- put, and enforcing coherence between parent and Figure 2: Examples of a hierarchical clustering and a hier- archical summary, where the input sentences are s 2 S, the number of input sentences is N , and the summary sentences are x 2 X. The hierarchical clustering determines the struc- ture of the hierarchical summary.</p><p>hierarchical structure, processing an order of mag- nitude bigger input, generating a much larger out- put, and enforcing coherence between parent and child summaries. We simplify the problem by decomposing it into two steps: hierarchical clustering and summariz- ing over the clustering (see <ref type="figure" target="#fig_0">Figure 2</ref> for an exam- ple). A hierarchical clustering is a tree in which if a cluster g p is the parent of cluster g c , then each sentence in g c is also in g p . This organizes the information into manageable, semantically-related sections and induces a hierarchical structure over the input.</p><p>The hierarchical clustering serves as input to the second step -summarizing given the hierarchy. The hierarchical summary follows the hierarchi- cal structure of the clustering. Each node in the hierarchy has an associated flat summary, which summarizes the sentences in that cluster. More- over, the number of sentences in a flat summary is exactly equal to the number of child clusters of the node, since the user will click a sentence to get to the child summary. See <ref type="figure" target="#fig_0">Figure 2</ref> for an illustration of this correspondence.</p><p>Because we are interested in temporal hierar- chical summarization, we hierarchically cluster all the sentences in the input documents by time. Unfortunately, neither agglomerative nor divisive clustering is suitable, since both assume a binary split at each node <ref type="bibr" target="#b1">(Berkhin, 2006</ref>). The number of clusters at each split should be what is most natural for the input data. We design a recursive clustering algorithm that automatically chooses the appropri- ate number of clusters at each split.</p><p>Before clustering, we timestamp all sentences. We use SUTime ( <ref type="bibr" target="#b5">Chang and Manning, 2012</ref>) to normalize temporal references, and we parse the sentences with the Stanford parser ( <ref type="bibr" target="#b12">Klein and Manning, 2003)</ref> and use a set of simple heuristics to determine if the timestamps in the sentence re- fer to the root verb. If no timestamp is given, we use the article date.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Temporal Clustering</head><p>After acquiring the timestamps, we must hierar- chically cluster the sentences into sets that make sense to summarize together. Since we wish to partition along the temporal dimension, our prob- lem reduces to identifying the best dates at which to split a cluster into subclusters. We identify these dates by looking for bursts of activity.</p><p>News tends to be bursty -many articles on a topic appear at once and then taper out <ref type="bibr" target="#b13">(Kleinberg, 2002)</ref>. For example, <ref type="figure" target="#fig_1">Figure 3</ref> shows the number of articles per day related to 1998 embassy bombings published in the New York Times (identified using a key word search). There were two main events -on the 7th, the embassies were bombed and on the 20th, US retaliated through missile strikes. The figure shows a correspondence between these events and news spikes.</p><p>Ideal splits for this example would occur just before each spike in coverage. However, when there is little differentiation in news coverage, we prefer clusters evenly spaced across time. We thus choose clusters C = {c 1 , . . . , c k } as follows:</p><formula xml:id="formula_0">maximize C B(C) + ↵E(C) (1)</formula><p>where C is a clustering, B(C) is the burstiness of the set of clusters, E(C) is the evenness of the clusters, and ↵ is the tradeoff parameter.</p><formula xml:id="formula_1">B(C) = X c2C burst(c)<label>(2)</label></formula><p>burst(c) is the difference in the number of sen- tences published the day before the first date in c and the average number of sentences published on the first and second date of c:</p><formula xml:id="formula_2">burst(c) = pub(di) + pub(di+1) 2 pub(di1) (3)</formula><p>where d is a date indexed over time, such that d j is a day before d j+1 , and d i is the first date in c. child summaries. We simplify the problem by decomposing it into two steps: hierarchical clustering and summariz- ing over the clustering (see <ref type="figure" target="#fig_0">Figure 2</ref> for an exam- ple). A hierarchical clustering is a tree in which if a cluster g p is the parent of cluster g c , then each sentence in g c is also in g p . This organizes the information into manageable, semantically-related sections and induces a hierarchical structure over the input.</p><p>The hierarchical clustering serves as input to the second step -summarizing given the hierarchy. The hierarchical summary follows the hierarchi- cal structure of the clustering. Each node in the hierarchy has an associated flat summary, which summarizes the sentences in that cluster. More- over, the number of sentences in a flat summary is exactly equal to the number of child clusters of the node, since the user will click a sentence to get to the child summary. See <ref type="figure" target="#fig_0">Figure 2</ref> for an illustration of this correspondence.</p><p>Because we are interested in temporal hierar- chical summarization, we hierarchically cluster all the sentences in the input documents by time. Unfortunately, neither agglomerative nor divisive clustering is suitable, since both assume a binary split at each node <ref type="bibr" target="#b1">(Berkhin, 2006</ref>). The number of clusters at each split should be what is most natural for the input data. We design a recursive clustering algorithm that automatically chooses the appropri- ate number of clusters at each split.</p><p>Before clustering, we timestamp all sentences. We use SUTime ( <ref type="bibr" target="#b5">Chang and Manning, 2012</ref>) to normalize temporal references, and we parse the sentences with the Stanford parser ( <ref type="bibr" target="#b12">Klein and Manning, 2003)</ref> and use a set of simple heuristics to determine if the timestamps in the sentence re- fer to the root verb. If no timestamp is given, we use the article date.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Temporal Clustering</head><p>After acquiring the timestamps, we must hierar- chically cluster the sentences into sets that make sense to summarize together. Since we wish to partition along the temporal dimension, our prob- lem reduces to identifying the best dates at which to split a cluster into subclusters. We identify these dates by looking for bursts of activity.</p><p>News tends to be bursty -many articles on a topic appear at once and then taper out <ref type="bibr" target="#b13">(Kleinberg, 2002)</ref>. For example, <ref type="figure" target="#fig_1">Figure 3</ref> shows the number of articles per day related to the 1998 embassy bomb- ings published in the New York Times (identified using a key word search). There were two main events -on the 7th, the embassies were bombed and on the 20th, the US retaliated through mis- sile strikes. The figure shows a correspondence between these events and news spikes.</p><p>Ideal splits for this example would occur just before each spike in coverage. However, when there is little differentiation in news coverage, we prefer clusters evenly spaced across time. We thus choose clusters C = {c 1 , . . . , c k } as follows:</p><formula xml:id="formula_3">maximize C B(C) + αE(C)<label>(1)</label></formula><p>where C is a clustering, B(C) is the burstiness of the set of clusters, E(C) is the evenness of the clusters, and α is the tradeoff parameter.</p><formula xml:id="formula_4">B(C) = c∈C burst(c)<label>(2)</label></formula><p>burst(c) is the difference in the number of sen- tences published the day before the first date in c and the average number of sentences published on the first and second date of c:</p><formula xml:id="formula_5">burst(c) = pub(di) + pub(di+1) 2 − pub(di−1) (3)</formula><p>where d is a date indexed over time, such that d j is a day before d j+1 , and d i is the first date in c. pub(d i ) is the number of sentences published on d i . The evenness of the split is measured by:</p><formula xml:id="formula_6">E(C) = min c∈C size(c)<label>(4)</label></formula><p>where size(c) is the number of dates in cluster c.</p><p>We perform hierarchical clustering top-down, at each point solving for Equation 1. α was set using a grid-search over a development set. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Choosing the number of clusters</head><p>We cannot know a priori the number of clusters for a given topic. However, when the number of clusters is too large for the given summary budget, the sentences will have to be too short, and when the number of clusters is too small, we will not use enough of the budget. We set the maximum num- ber of clusters k max and minimum number of clus- ters k min to be a function of the budget b and the average sentence length in the cluster s avg , such that k max · s avg ≤ b and</p><formula xml:id="formula_7">k min · s avg ≥ b/2.</formula><p>Given a maximum and minimum number of clusters, we must determine the appropriate num- ber of clusters. At each level, we cluster the sen- tences by the method described above and choose the number of clusters k according to the gap statistic ( <ref type="bibr" target="#b29">Tibshirani et al., 2000</ref>). Specifically, for each level, the algorithm will cluster repeatedly with k varying from the minimum to the maxi- mum. The algorithm will return the k that max- imizes the gap statistic:</p><formula xml:id="formula_8">Gap n (k) = E * n {log(W k )} − log(W k )<label>(5)</label></formula><p>where W k is the score for the clusters computed with Equation 1, and E * n is the expectation under a sample of size n from a reference distribution.</p><p>Ideally, the maximum depth of the clustering would be a function of the number of sentences in each cluster, but in our implementation, we set the maximum depth to three, which works well for the size of the datasets we use (300 articles).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Summarizing within the Hierarchy</head><p>After the sentences are clustered, we have a struc- ture for the hierarchical summary that dictates the number of summaries and the number of sentences in each summary. We also have the set of sen- tences from which each summary is drawn.</p><p>Intuitively, each cluster summary in the hierar- chical summary should convey the most salient information in that cluster. Furthermore, the hier- archical summary should not include redundant sentences. A hierarchical summary that is only salient and nonredundant may still not be suitable if the sentences within a cluster summary are dis- connected or if the parent sentence for a summary does not relate to the child summary. Thus, a hi- erarchical summary must also have intra-cluster coherence and parent-to-child coherence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Salience</head><p>Salience is the value of each sentence to the topic from which the documents are drawn. We measure salience of a summary (Sal(X)) as the sum of the saliences of individual sentences ( i Sal(x i )). Following previous research in MDS, we com- puted individual saliences using a linear regres- sion classifier trained on ROUGE scores over the DUC'03 dataset <ref type="bibr" target="#b18">(Lin, 2004;</ref><ref type="bibr" target="#b7">Christensen et al., 2013)</ref>. This method finds those sentences more salient that mention nouns or verbs that occur fre- quently in the cluster.</p><p>In preliminary experiments, we noticed that many sentences that were reaction sentences were given a higher salience than action sentences. For example, the reaction sentence, "President Clinton vowed to track down the perpetrators behind the bombs that exploded outside the embassies in Tan- zania and Kenya on Friday," would have a higher score than the action sentence, "Bombs exploded outside the embassies in Tanzania and Kenya on Friday." This problem occurs because the first sen- tence has a higher ROUGE score (it covers more important words than the second sentence). To ad- just for this problem, we use only words identified in the main clause (heuristically identified via the parse tree) to compute our salience scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Redundancy</head><p>We identify redundant sentences using a linear regression classifier trained on a manually la- beled subset of the DUC'03 sentences. The fea- tures include shared noun counts, sentence length, TF*IDF cosine similarity, timestamp difference, and features drawn from information extraction such as number of shared tuples in Open IE ( <ref type="bibr" target="#b19">Mausam et al., 2012</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Summary Coherence</head><p>We require two types of coherence: coherence be- tween the parent and child summaries and coher- ence within each summary X i .</p><p>We rely on the approximate discourse graph (ADG) that was proposed in <ref type="bibr" target="#b7">(Christensen et al., 2013)</ref> as the basis for measuring coherence. Each node in the ADG is a sentence from the dataset. An edge from sentence s i to s j with positive weight indicates that s j may follow s i in a coher- ent summary, e.g. continued mention of an event or entity, or coreference link between s i and s j . A negative edge indicates an unfulfilled discourse cue or co-reference mention. Parent-to-Child Coherence: Users navigate the hierarchical summary from parent sentence to child summary, so if the parent sentence bears no relation to the child summary, the user will be un- derstandably confused. The parent sentence must have positive evidence of coherence with the sen- tences in its child summary.</p><p>We estimate parent to child coherence as the co- herence between a parent sentence and each sen- tence in its child summary as:</p><formula xml:id="formula_9">P Coh(X) = c∈C i=1..|Xc| w G+ (x p c , x c,i )) (6)</formula><p>where x p c is the parent sentence for cluster c and w G+ (x p c , x c,i ) is the sum of the positive edge weights from x p c to x c,i in the ADG G. Intra-cluster Coherence: In traditional MDS, the documents are usually quite focused, allowing for highly focused summaries. In hierarchical sum- marization, however, a cluster summary may span hundreds of documents and a wide range of infor- mation. For this reason, we may consider a sum- mary acceptable even if it has limited positive evi- dence of coherence in the ADG, as long as there is no negative evidence in the form of negative edges. For example, the following is a reasonable summary for events spanning two weeks: s 1 Bombs exploded at two US embassies. s 2 US missiles struck in Afghanistan and Sudan. Our measure of intra-cluster coherence mini- mizes the number of missing references. These are coreference mentions or discourse cues where none of the sentences read before (either in an an- cestor summary or in the current summary) con- tain an antecedent:</p><formula xml:id="formula_10">CCoh(X) = − c∈C i=1..|Xc| #missingRef (xc,i) (7)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Objective Function</head><p>Having estimated salience, redundancy, and two forms of coherence, we can now put this informa- tion together into a single objective function that measures the quality of a candidate hierarchical summary.</p><p>Intuitively, the objective function should bal- ance salience and coherence. Furthermore, the summary should not contain redundant informa- tion and each cluster summary should honor the given budget, i.e., maximum summary length b. We treat redundancy and budget as hard con- straints and coherence and salience as soft con- straints. Lastly, we require that sentences are drawn from the cluster that they represent and that the number of sentences in the summary corre- sponding to each non-leaf cluster c is equivalent to the number of child clusters of c. We optimize:</p><formula xml:id="formula_11">maximize: F (x) Sal(X) + βP Coh(X) + γCCoh(X) s.t. ∀c ∈ C : i=1..|Xc| len(xc,i) &lt; b ∀xi, xj ∈ X : redundant(xi, xj) = 0 ∀c ∈ C, ∀xc ∈ Xc : xc ∈ c ∀c ∈ C : |Xc| = #children(c)</formula><p>The tradeoff parameters β and γ were set based on a development set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Algorithm</head><p>Optimizing this objective function is NP-hard, so we approximate a solution by using beam search over the space of partial hierarchical summaries. Notice the contribution from a sentence depends on individual salience, coherence (CCoh) based on sentences visible on the user path down the hi- erarchy to this sentence, and coherence (P Coh) based on its parent sentence and its child sum- mary. Since most of the sentence contributions de- pend on the path from the root to the sentence, we build our partial summary by incrementally adding a sentence top-down in the hierarchy and from first sentence to last within a cluster summary.</p><p>To account for P Coh, we estimate the contribu- tion of the sentence by jointly identifying its best child summary. However, we do not fix the child summary at this time -we simply use it to estimate P Coh when using that sentence. Since computing the best child summary is also intractable we ap- proximate a solution by a local search algorithm over the child cluster.</p><p>Overall, our algorithm is a two level nested search algorithm -beam search in the outer loop to search through the space of partial summaries and local search (hill climbing with random restarts) in the inner loop to pick the best sentence to add to the existing partial summary. We use a beam of size ten in our implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>Our experiments are designed to evaluate how ef- fective hierarchical summarization is in summa- rizing a large, complex topic and how well this helps users learn about the topic. Our evaluation addresses the following questions:</p><p>• Do users prefer hierarchical summaries for topic exploration? (Section 5.1)</p><p>• Are hierarchical summaries more effective than other methods for learning about com- plex events? (Section 5.2)</p><p>• How informative are the hierarchical sum- maries compared to the other methods? (Sec- tion 5.3)</p><p>• How coherent is the hierarchical structure in the summaries? (Section 5.4)</p><p>We compared SUMMA against two baseline sys- tems which represent the main NLP methods for large-scale summarization: an algorithm for cre- ating timelines over sentences ( <ref type="bibr" target="#b6">Chieu and Lee, 2004</ref>), <ref type="bibr">3</ref> and a state-of-the-art flat MDS system (Lin and Bilmes, 2011). <ref type="bibr">4</ref> Each system was given the same budget (over 10 times the traditional MDS budget, which is 665 bytes).</p><p>We evaluated the questions on ten news topics, representing a range of tasks: <ref type="formula" target="#formula_3">(1)</ref>  We chose topics containing a set of related events that unfolded over several months and were promi- nent enough to be reported in at least 300 articles.</p><p>We drew our articles from the Gigaword corpus, which contains articles from the New York Times and other major newspapers. For each topic, we used the 300 documents that best matched a key word search. We selected topics which were be- tween five and fifteen years old so that evaluators would have relatively less pre-existing knowledge about the topic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">User Preference</head><p>In our first experiment, we simply wished to eval- uate which system users most prefer. We hired Amazon Mechanical Turk (AMT) workers and as- signed two topics to each worker. We paired up workers such that one worker would see output from SUMMA for the first topic and a competing system for the second and the other worker would see the reverse. For quality control, we asked workers to complete a qualification task first, in which they were required to write a short summary of a news article. We also manually removed spam from our results. Previous work has used AMT workers for summary evaluations and has shown high correlations with expert ratings <ref type="bibr" target="#b7">(Christensen et al., 2013)</ref>. Five workers were hired to view each topic-system pair.</p><p>We asked the workers to choose which format they preferred and to explain why. The results are as follows:</p><p>SUMMA 76% TIMELINE 24% SUMMA 92% FLAT-MDS 8%</p><p>Users preferred the hierarchical summaries three times more often than timelines and over ten times more often than flat summaries. When we examined the reasons given by the users, we found that the people who preferred the hierar- chical summaries liked that they gave a big pic- ture overview and were then allowed to drill down deeper. Some also explained that it was eas- ier to remember information when presented with the overview first. Typical responses included, "Could gather and absorb the information at my own pace," and, "Easier to follow and understand." When users preferred the timelines, they usually remarked that it was more familiar, i.e. "I liked the familiarity of the format. I am used to these timelines and they feel comfortable." Users com- plained that the flat summaries were disjointed, confusing, and very frustrating to read.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Knowledge Acquisition</head><p>Evaluating how much a user learned is inherently difficult, more so when the goal is to allow the user the freedom to explore information based on indi- vidual interest. For this reason, instead of asking a set of predefined questions, we assess the knowl-edge gain by following the methodology of <ref type="bibr" target="#b26">(Shahaf et al., 2012</ref>) -asking users to write a paragraph summarizing the information learned.</p><p>Using the same setup as in the previous exper- iment, for each topic, five AMT workers spent three minutes reading through a timeline or sum- mary and were then asked to write a description of what they had learned. Workers were not al- lowed to see the timeline or summary while writ- ing. We collected five descriptions for each topic- system combination. We then asked other AMT workers to read and compare the descriptions writ- ten by the first set of workers. Each evaluator was presented with a corresponding Wikipedia article and descriptions from a pair of users (timeline vs. SUMMA or flat MDS vs. SUMMA). The descrip- tions were randomly ordered to remove bias. The workers were asked which user appeared to have learned more and why. For each pair of descrip- tions, four workers evaluated the pair. Standard checks such as approval rating, location filtering, etc. were used for removing spam. The results of this experiment are as follows:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prefer</head><p>Indiff. Prefer SUMMA 58% 17% TIMELINE 25% SUMMA 40% 22% FLAT-MDS 38%</p><p>Descriptions written by workers using SUMMA were preferred over twice as often as those from timelines. We looked more closely at those cases where the participants either preferred the time- lines or were indifferent and found that this pref- erence was most common when the topic was not dominated by a few major events, but was instead a series of similarly important events. For exam- ple, in the kidnapping and beheading of Daniel Pearl there were two or three obviously major events, whereas in the Kargil War there were many smaller important events. In latter cases, the hier- archical summaries provided little advantage over the timelines because it was more difficult to ar- range the sentences hierarchically.</p><p>Since SUMMA was judged to be so much supe- rior to flat MDS systems in Section 5.1, it is sur- prising that users descriptions from flat MDS were preferred nearly as often as those from SUMMA. While the flat summaries were disjointed, they were good at including salient information, with the most salient tending to be near the start of the summary. Thus, descriptions from both SUMMA and flat MDS generally covered the most salient information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Informativeness</head><p>In this experiment, we assess the salience of the information captured by the different systems, and the ability of SUMMA to organize the information so that more important information is placed at higher levels. ROUGE Evaluation: We first automatically assessed informativeness by calculating the ROUGE-1 scores of the output of each of the sys- tems. For the gold standard comparison summary, we use the Wikipedia articles for the topics. <ref type="bibr">5</ref> Note that there is no good translation of ROUGE for hierarchical summarization. Thus, we simply use the traditional ROUGE metric, which will not capture any of the hierarchical format. This score will essentially serve as a rough measure of coverage of the entire summary to the Wikipedia article. The scores for each of the systems are as follows:</p><formula xml:id="formula_12">P R F1 SUMMA 0.25 0.67 0.31 TIMELINE 0.28 0.65 0.33 FLAT-MDS 0.30 0.64 0.34</formula><p>None of the differences are significant. From this evaluation, one can gather that the systems have similar coverage of the Wikipedia articles. Manual Evaluation: While ROUGE serves as a rough measure of coverage, we were interested in gathering more fine-grained information on the in- formativeness of each system. We performed an additional manual evaluation that assesses the re- call of important events for each system.</p><p>We first identified which events were most im- portant in a news story. Because reading 300 arti- cles per topic is impractical, we asked AMT work- ers to read a Wikipedia article on the same topic and then identify the three most important events and the five most important secondary events. We aggregated responses from ten workers per topic and chose the three most common primary and five most common secondary events.</p><p>One of the authors then manually identified the presence of these events in the hierarchical sum- maries, the timelines and the flat MDS summaries. Below we show event recall (the percentage of the events that were mentioned).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Events SUMMA TIMELINE FLAT-MDS Prim.</head><p>96% 74% 93% Sec. 76% 53% 64%</p><p>The difference in recall between SUMMA and TIMELINE was significant in both cases, and the difference between SUMMA and FLAT-MDS was not. In general, the flat summaries were quite re- dundant, which contributed to the slightly lower event recall. The timelines, on the other hand, were both incoherent and at the same time re- ported less important facts.</p><p>We also evaluated at what level in the hierar- chy the events were identified for the hierarchical summaries. The event recall shows the percentage of events mentioned at that level or above in the hierarchical summary:</p><formula xml:id="formula_13">Events Level 1 Level 2 Level 3 Prim. 63% 81% 96% Sec. 27% 51% 76%</formula><p>81% of the primary events are present in the first or second level, and 76% of the secondary events are mentioned by the third level. While recog- nizing primary events is relatively simple because they are repeated frequently, identification of im- portant secondary events often requires external knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Parent-to-Child Coherence</head><p>We next tested the hierarchical coherence. One of the authors graded how much each non-leaf sen- tence in a summary was coherent with its child summary on a scale of one to five, with one be- ing incoherent and five being perfectly coherent. We used the coherence scale from DUC'04. <ref type="bibr">6</ref> Level 1 Level 2 Coherence 3.8 3.4</p><p>We found that for the top level of the summary, the parent sentence generally represented the most important event in the cluster and the child sum- mary usually expressed details or reactions of the event. The lower coherence scores were often the result of too few lexical connections or lack of a theme or story. While the facts of the sentences made sense together, the summaries sometimes did not read as if they were written by a human, but as a series of disparate sentences.</p><p>For the second level, the problems were more basic. The parent sentence occasionally expressed a less important fact that the child summary did <ref type="bibr">6</ref> http://duc.nist.gov/duc2004/quality.questions.txt not then expand on or, more commonly, the child summary was not focused enough. This result stems from two problems in our algorithm. First, summarizing sentences are rare, making good choices for parent sentences difficult to find. The second problem relates to the difficulty in identify- ing whether two sentences are on the same topic. For example, suppose the parent sentence is, "A Swissair plane Wednesday night crashed off Nova Scotia, Canada." A very good child sentence is, "The airline confirmed that all passengers died." However, based on their surface features, the sen- tence, "A plane made an unscheduled landing after a Swissair plane crashed off the coast of Canada," appears to be a better choice.</p><p>Even though there is scope for improvement, we find these coherence scores encouraging for a first algorithm for the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Traditional approaches to large-scale summariza- tion have included flat summaries and timelines. There are two primary shortcomings to these ap- proaches: first, they require the user to sort through large amounts of potentially overwhelm- ing information, and second, the output is static -users with different interests will see the same information. Below we describe related work on traditional MDS, structured summaries, timelines, discovering threads of documents and the uses of hierarchies in generating summaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Traditional MDS</head><p>Traditionally, MDS systems have focused on three to six sentence summaries covering 10-15 docu- ments. Most extractive summarization research aims to maximize coverage while reducing redun- dancy (e.g. ( <ref type="bibr" target="#b3">Carbonell and Goldstein, 1998;</ref><ref type="bibr" target="#b23">Saggion and Gaizauskas, 2004;</ref><ref type="bibr" target="#b22">Radev et al., 2004)</ref>). Lin and Bilmes (2011) proposed a state-of-the-art system that uses submodularity in sentence selec- tion to accomplish these goals. <ref type="bibr" target="#b7">Christensen et al. (2013)</ref> presented an algorithm for coherent MDS, but it does not scale to larger output. Structured Summaries: Some research has ex- plored generating structured summaries. These approaches attempt to identify major aspects of a topic, but do not compile content to describe those aspects. Rather, they rely on pre-existing, la- beled paragraphs (for example, a paragraph titled, "Symptoms of Meningitis"). Aspects are identi- fied either by a training corpus of articles in the same domain <ref type="bibr" target="#b24">(Sauper and Barzilay, 2009)</ref>, by an entity-aspect LDA model ( <ref type="bibr" target="#b16">Li et al., 2010)</ref>, or by Wikipedia templates of related topics <ref type="bibr" target="#b34">(Yao et al., 2011</ref>). These methods assume a common struc- ture for all topics in a category, and do not allow for more than two levels in the structure. Timeline Generation: Recent papers in timeline generation have emphasized the relationship with summarization. <ref type="bibr" target="#b32">Yan et al. (2011b)</ref> balanced co- herence and diversity to create timelines, <ref type="bibr" target="#b31">Yan et al. (2011a)</ref> used inter-date and intra-date sentence dependencies, and <ref type="bibr" target="#b6">Chieu and Lee (2004)</ref> used sen- tence similarity. Others have emphasized identify- ing important dates, primarily by bursts of news <ref type="bibr" target="#b27">(Swan and Allen, 2000;</ref><ref type="bibr" target="#b0">Akcora et al., 2010;</ref><ref type="bibr" target="#b10">Hu et al., 2011;</ref><ref type="bibr">Kessler et al., 2012)</ref>. While time- lines can be useful for understanding events, they do not generalize to other domains. Additionally, long timelines can be overwhelming, short time- lines have low information content, and there is no method for personalized exploration. Document Threads: A related track of research investigates discovering threads of documents. While we aim to summarize collections of infor- mation, this track seeks to identify relationships between documents. This research operates on the document level, while ours operates on the sen- tence level. <ref type="bibr" target="#b25">Shahaf and Guestrin (2010)</ref> formal- ized the characteristics of a good chain of articles and proposed an algorithm to connect two speci- fied articles. <ref type="bibr" target="#b8">Gillenwater et al. (2012)</ref> proposed a probabilistic technique for extracting a diverse set of threads from a given collection. <ref type="bibr" target="#b26">Shahaf et al. (2012)</ref> extended work on coherent threads to finding coherent maps of documents, where a map is set of intersecting threads representing how the threads interact and relate. Summarization and Hierarchies: A few papers have examined the relationship between summa- rization and hierarchies. Some focused on cre- ating a hierarchical summary of a single docu- ment ( <ref type="bibr" target="#b2">Buyukkokten et al., 2001;</ref><ref type="bibr" target="#b20">Otterbacher et al., 2006</ref>), relying on the structure inherent in sin- gle documents. Others investigated creating hier- archies of words or phrases to organize documents ( <ref type="bibr" target="#b14">Lawrie et al., 2001;</ref><ref type="bibr" target="#b15">Lawrie, 2003;</ref><ref type="bibr" target="#b28">Takahashi et al., 2007;</ref><ref type="bibr" target="#b9">Haghighi and Vanderwende, 2009)</ref>.</p><p>Other research identifies the hierarchical struc- ture of the documents and generates a summary that prioritizes more general information accord- ing to the structure ( <ref type="bibr" target="#b21">Ouyang et al., 2009;</ref><ref type="bibr" target="#b4">Celikyilmaz and Hakkani-Tur, 2010</ref>), or gains coverage by drawing sentences from different parts of the hier- archy ( <ref type="bibr" target="#b33">Yang and Wang, 2003;</ref><ref type="bibr" target="#b30">Wang et al., 2006</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>We have introduced a new paradigm for large- scale summarization called hierarchical summa- rization, which allows a user to navigate a hier- archy of relatively short summaries. We present SUMMA, an implemented hierarchical news sum- marization system, 7 and demonstrate its effective- ness in a user study that compares SUMMA with a timeline system and a flat MDS system. When compared to timelines, users learned more with SUMMA in twice as many cases, and SUMMA was preferred more than three times as often. When compared to flat summaries, users overwhelming preferred SUMMA and learned just as much.</p><p>This first implementation performs temporal clustering -in future work, we will investigate dy- namically selecting an organizing principle that is best suited to the data at each level of the hierar- chy: by entity, by location, by event, or by date. We also intend to scale the system to even larger document collections, and explore joint clustering and summarization. Lastly, we plan to research hierarchical summarization in other domains.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Examples of input and output to hierarchical summarization. The input sentences are s ∈ S, the number of input sentences is N , and the summary sentences are x ∈ X.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: News coverage by date for the embassy bombings in Tanzania and Kenya. There are spikes in the number of articles published at the two major events.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Pope John Paul II's death and the 2005 Papal Conclave, (2) Bush v. Gore, (3) the Tulip Revolution, (4) Daniel Pearl's kidnapping, (5) the Lockerbie bombing handover of suspects, (6) the Kargil War, (7) NATO's bomb- ing of Yugoslavia in 1999, (8) Pinochet's arrest in London, (9) the 2005 London bombings, and (10) the crash and investigation of SwissAir Flight 111.</figDesc></figure>

			<note place="foot" n="1"> In the DUC evaluations, summaries have a budget of 665 bytes and cover 10 documents.</note>

			<note place="foot" n="2"> http://knowitall.cs.washington.edu/summa/</note>

			<note place="foot" n="3"> Unfortunately, we were unable to obtain more recent timeline systems from authors of the systems. 4 (Christensen et al., 2013) is a state-of-the-art coherent MDS system, but does not scale to 300 documents.</note>

			<note place="foot" n="5"> We excluded one topic (the handover of the Lockerbie bombing suspects) because the corresponding Wikipedia article had insufficient information.</note>

			<note place="foot" n="7"> http://knowitall.cs.washington.edu/summa/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Amitabha Bagchi, Niranjan Balasubra-manian, Danish Contractor, Oren Etzioni, Tony Fader, Carlos Guestrin, Prachi Jain, Lucy Van-derwende, Luke Zettlemoyer, and the anonymous reviewers for their helpful suggestions and feed-back. We thank Hui Lin and Jeff Bilmes for providing us with their code. This research was supported in part by ARO contract W911NF-13-1-0246, DARPA Air Force Research Labora-tory (AFRL) contract FA8750-13-2-0019, UW-IITD subcontract RP02815, and the Yahoo! Fac-ulty Research and Engagement Award. This pa-per is also supported in part by the Intelligence Advanced Research Projects Activity (IARPA) via AFRL contract number FA8650-10-C-7058. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation thereon. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of IARPA, AFRL, or the U.S. Government.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Identifying breakpoints in public opinion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">G</forename><surname>Akcora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Bayir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Demirbas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ferhatosmanoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">1st KDD Workshop on Social Media Analytics</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">A survey of clustering data mining techniques. Grouping Multidimensional Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Berkhin Berkhin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="25" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Seeing the whole in parts: Text summarization for web browsing on handheld devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Orkut</forename><surname>Buyukkokten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hector</forename><surname>Garcia-Molina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Paepcke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WWW 2001</title>
		<meeting>WWW 2001</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="652" to="662" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The use of MMR, diversity-based reranking for reordering documents and producing summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jade</forename><surname>Goldstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGIR 1998</title>
		<meeting>SIGIR 1998</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="335" to="336" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A hybrid hierarchical model for multi-document summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asli</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2010</title>
		<meeting>ACL 2010</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="815" to="824" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">SUTime: A library for recognizing and normalizing time expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angel</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC 2012</title>
		<meeting>LREC 2012</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Query based event extraction along a timeline</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Leong Chieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoong Keok</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGIR</title>
		<meeting>SIGIR</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="425" to="432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Towards coherent multidocument summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janara</forename><surname>Christensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Mausam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL 2013</title>
		<meeting>NAACL 2013</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Discovering diverse and salient threads in document collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Gillenwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Taskar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLPCoNLL 2012</title>
		<meeting>EMNLPCoNLL 2012</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="710" to="720" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Exploring content models for multi-document summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aria</forename><surname>Haghighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucy</forename><surname>Vanderwende</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL 2009</title>
		<meeting>NAACL 2009</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="362" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Generating breakpoint-based timeline overview for news topic retrospection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Po</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weichang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><forename type="middle">K</forename><surname>Usadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyan</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICDM</title>
		<meeting>ICDM</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Véronique Moriceau, and André Bittar. 2012. Finding salient dates for building thematic timelines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Remy</forename><surname>Kessler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Tannier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caroline</forename><surname>Hagège</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2012</title>
		<meeting>ACL 2012</meeting>
		<imprint>
			<biblScope unit="page" from="730" to="739" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Accurate unlexicalized parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st Meeting of the Association for Computational Linguistics</title>
		<meeting>the 41st Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="423" to="430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Bursty and hierarchical structure in streams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;02</title>
		<meeting>the Eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;02</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="91" to="101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Finding topic words for hierarchical summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawn</forename><surname>Lawrie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnold</forename><surname>Rosenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGIR &apos;01</title>
		<meeting>SIGIR &apos;01</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="349" to="357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Language models for hierarchical summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawn</forename><forename type="middle">J</forename><surname>Lawrie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
		<respStmt>
			<orgName>University of Massachusetts Amherst</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Generating templates of entity summaries with an entityaspect model and pattern mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinglin</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2010</title>
		<meeting>ACL 2010</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="640" to="649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A class of submodular functions for document summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Bilmes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2011</title>
		<meeting>ACL 2011</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="510" to="520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">ROUGE: A package for automatic evaluation of summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text Summarization Branches Out: Proceedings of the ACL-04 Workshop</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="74" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Open language learning for information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mausam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Schmitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Bart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2012</title>
		<meeting>EMNLP 2012</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="523" to="534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">News to go: Hierarchical text summarization for mobile devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jahna</forename><surname>Otterbacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Kareem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGIR 2006</title>
		<meeting>SIGIR 2006</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="589" to="596" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An integrated multi-document summarization approach based on word hierarchical representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">You</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenji</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qin</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACLShort</title>
		<meeting>the ACLShort</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="113" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Centroid-based summarization of multiple documents. Information Processing and Management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dragomir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyan</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malgorzata</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Stys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tam</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="919" to="938" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Multidocument summarization by cluster/profile relevance and redundancy removal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horacio</forename><surname>Saggion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Gaizauskas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of DUC</title>
		<meeting>DUC</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Automatically generating Wikipedia articles: A structureaware approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christina</forename><surname>Sauper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2009</title>
		<meeting>ACL 2009</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="208" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Connecting the dots between news articles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dafna</forename><surname>Shahaf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of KDD 2010</title>
		<meeting>KDD 2010</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="623" to="632" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Trains of thought: Generating information maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dafna</forename><surname>Shahaf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Horvitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WWW 2012</title>
		<meeting>WWW 2012</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Automatic generation of overview timelines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Russell</forename><surname>Swan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Allen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGIR 2000</title>
		<meeting>SIGIR 2000</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="49" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Hierarchical summarizing and evaluating for web pages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kou</forename><surname>Takahashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takao</forename><surname>Miura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isamu</forename><surname>Shioya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st workshop on emerging research opportunities for Web Data Management</title>
		<meeting>the 1st workshop on emerging research opportunities for Web Data Management</meeting>
		<imprint>
			<publisher>EROW</publisher>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Estimating the number of clusters in a dataset via the gap statistic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guenther</forename><surname>Walther</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Hastie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society, Series B</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="411" to="423" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Multi-document summarization for terrorism information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fu Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ISI&apos;06</title>
		<meeting>ISI&apos;06</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Timeline generation through evolutionary trans-temporal summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Congrui</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2011</title>
		<meeting>EMNLP 2011</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="433" to="443" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Evolutionary timeline summarization: A balanced optimization framework via iterative substitution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jahna</forename><surname>Otterbacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of SIGIR 2011</title>
		<meeting>eeding of SIGIR 2011</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="745" to="754" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Fractal summarization: summarization based on fractal theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fu Lee</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGIR 2003</title>
		<meeting>SIGIR 2003</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="391" to="392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Autopedia: Automatic domain-independent wikipedia article generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Conglei</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sicong</forename><surname>Shou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shicong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WWW 2011</title>
		<meeting>WWW 2011</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="161" to="162" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
