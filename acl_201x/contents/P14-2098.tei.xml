<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:06+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Improved Correction Detection in Revised ESL Sentences</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>June 23-25 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huichao</forename><surname>Xue</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Pittsburgh</orgName>
								<address>
									<addrLine>210 S Bouquet St</addrLine>
									<postCode>15260</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Hwa</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Pittsburgh</orgName>
								<address>
									<addrLine>210 S Bouquet St</addrLine>
									<postCode>15260</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Improved Correction Detection in Revised ESL Sentences</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="599" to="604"/>
							<date type="published">June 23-25 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This work explores methods of automatically detecting corrections of individual mistakes in sentence revisions for ESL students. We have trained a classifier that specializes in determining whether consecutive basic-edits (word insertions, deletions, substitutions) address the same mistake. Experimental result shows that the proposed system achieves an F 1-score of 81% on correction detection and 66% for the overall system, out-performing the baseline by a large margin.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Quality feedback from language tutors can help English-as-a-Second-Language (ESL) stu- dents improve their writing skills. One of the tu- tors' tasks is to isolate writing mistakes within sentences, and point out (1) why each case is considered a mistake, and (2) how each mistake should be corrected. Because this is time consum- ing, tutors often just rewrite the sentences with- out giving any explanations <ref type="bibr" target="#b4">(Fregeau, 1999</ref>). Due to the effort involved in comparing revisions with the original texts, students often fail to learn from these revisions <ref type="bibr" target="#b15">(Williams, 2003)</ref>.</p><p>Computer aided language learning tools offer a solution for providing more detailed feedback. Programs can be developed to compare the stu- dent's original sentences with the tutor-revised sentences. <ref type="bibr" target="#b13">Swanson and Yamangil (2012)</ref> have proposed a promising framework for this purpose. Their approach has two components: one to de- tect individual corrections within a revision, which they termed correction detection; another to deter- mine what the correction fixes, which they termed error type selection. Although they reported a high accuracy for the error type selection classifier alone, the bottleneck of their system is the other component -correction detection. An analysis of their system shows that approximately 70% of the system's mistakes are caused by mis-detections in the first place. Their correction detection al- gorithm relies on a set of heuristics developed from one single data collection (the FCE corpus <ref type="bibr" target="#b16">(Yannakoudakis et al., 2011)</ref>). When determining whether a set of basic-edits (word insertions, dele- tions, substitutions) contributes to the same cor- rection, these heuristics lack the flexibility to adapt to a specific context. Furthermore, it is not clear if the heuristics will work as well for tutors trained to mark up revisions under different guidelines.</p><p>We propose to improve upon the correction de- tection component by training a classifier that de- termines which edits in a revised sentence address the same error in the original sentence. The classi- fier can make more accurate decisions adjusted to contexts. Because the classifier were trained on re- visions where corrections are explicitly marked by English experts, it is also possible to build systems adjusted to different annotation standards.</p><p>The contributions of this paper are: (1) We show empirically that a major challenge in correction detection is to determine the number of edits that address the same error. (2) We have developed a merging model that reduces mis-detection by 1/3, leading to significant improvement in the accu- racies of combined correction detection and er- ror type selection. (3) We have conducted experi- ments across multiple corpora, indicating that the proposed merging model is generalizable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Correction Detection</head><p>Comparing a student-written sentence with its re- vision, we observe that each correction can be de- composed into a set of more basic edits such as word insertions, word deletions and word substi- tutions. In the example shown in <ref type="figure">Figure 1</ref>, the correction "to change ⇒ changing" is composed of a deletion of to and a substitution from change <ref type="figure">Figure 1</ref>: Detecting corrections from revisions. Our system detects individual corrections by comparing the original sentence with its revision, so that each correction addresses one error. Each polygon corresponds to one correction; the labels are codes of the error types. The codes follow the annotation standard in FCE corpus <ref type="bibr" target="#b10">(Nicholls, 2003)</ref>. In this example, W is incorrect Word order; UT is Unnecessary preposiTion; FV is wrong Verb Form; RN is Nnoun needs to be Replaced; ID is IDiom error. to changing; the correction "moment ⇒ minute" is itself a single word substitution. Thus, we can build systems to detect corrections which operates in two steps: (1) detecting the basic edits that took place during the revision, and (2) merging those basic edits that address the same error. <ref type="figure">Figure 2</ref> il- lustrates the process for a fragment of the example sentence from <ref type="figure">Figure 1</ref>. In practice, however, this two-step approach may result in mis-detections due to ambiguities. Mis-detections may be introduced from either steps. While detecting basic edits, <ref type="figure">Figures 3</ref> gives an example of problems that might arise. Because the Levenshtein algorithm only tries to minimize the number of edits, it does not care whether the edits make any linguistic sense. For merging basic edits, Swanson and Yamangil applied a distance heuristic -basic-edits that are close to each other (e.g. basic edits with at most one word lying in between) are merged. <ref type="figure" target="#fig_2">Figure 4</ref> shows cases for which the heuristic results in the wrong scope.</p><p>These errors caused their system to mis-detect 30% of the corrections. Since mis-detected cor- rections cannot be analyzed down the pipeline,  the correction detection component became the bottle-neck of their overall system. Out of the 42% corrections that are incorrectly analyzed 1 , 30%/42%≈70% are caused by mis-detections in the first place. An improvement in correction de- tection may increase the system accuracy overall.</p><p>We conducted an error analysis to attribute er- rors to either step when the system detects a wrong set of corrections for a sentence. We examine the first step's output. If the resulting basic ed- its do not match with those that compose the ac- tual corrections, we attribute the error to the first step. Otherwise, we attribute the error to the sec- ond step. Our analysis confirms that the merging step is the bottleneck in the current correction de- tection system -it accounts for 75% of the mis- detections. Therefore, to effectively reduce the algorithm's mis-detection errors, we propose to build a classifier to merge with better accuracies.</p><p>Other previous tasks also involve comparing two sentences. Unlike evaluating grammar er- ror correction systems <ref type="bibr" target="#b1">(Dahlmeier and Ng, 2012)</ref>, correction detection cannot refer to a gold stan- dard. Our error analysis above also highlights our task's difference with previous work that identify corresponding phrases between two sentences, in- cluding phrase extraction ( <ref type="bibr" target="#b8">Koehn et al., 2003</ref>) and paraphrase extraction ( <ref type="bibr" target="#b0">Cohn et al., 2008)</ref>. They are fundamentally different in that the granularity of the extracted phrase pairs is a major concern in our work -we need to guarantee each detected phrase pair to address exactly one writing prob- lem. In comparison, phrase extraction systems aim to improve the end-to-end MT or paraphrasing systems. A bigger concern is to guarantee the ex- tracted phrase pairs are indeed translations or para- phrases. Recent work therefore focuses on identi- fying the alignment/edits between two sentences <ref type="bibr" target="#b12">(Snover et al., 2009;</ref><ref type="bibr" target="#b7">Heilman and Smith, 2010</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">A Classifier for Merging Basic-Edits</head><p>Figures 4 highlights the problems with indiscrimi- nantly merging basic-edits that are adjacent. Intu- itively, it seems that the decision should be more context dependent. Certain patterns may indicate that two adjacent basic-edits are a part of the same correction while others may indicate that they each address a different problem. For example, in <ref type="figure">Fig- ure 5a</ref>, when the insertion of one word is followed by the deletion of the same word, the insertion and deletion are likely addressing one single error. This is because these two edits would combine to- gether as a word-order change. On the other hand, in <ref type="figure">Figure 5b</ref>, if one edit includes a substitution be- tween words with the same POS's, then it is likely fixing a word choice error by itself. In this case, it should not be merged with other edits.</p><p>To predict whether two basic-edits address the same writing problem more discriminatively, we train a Maximum Entropy binary classifier based on features extracted from relevant contexts for the basic edits. We use features in <ref type="table" target="#tab_0">Table 1</ref> in the proposed classifier. We design the features to in- dicate: (A) whether merging the two basic-edits matches the pattern for a common correction. (B) whether one basic-edit addresses one single error.</p><p>We train the classifier using samples extracted from revisions where individual corrections are explicitly annotated. We first extract the basic-  goal is to train classifiers to tell if two basic edits should be merged (True or False). We break each correction (outer polygons, also colored in red) in the training corpus into a set of basic edits (black polygons). We construct an instance for each consecutive pair of basic edits. If two basic edits were extracted from the same correction, we will mark the outcome as True, otherwise we will mark the outcome as False.</p><p>edits that compose each correction. We then create a training instance for each pair of two consecutive basic edits: if two consecutive basic edits need to be merged, we will mark the outcome as True, oth- erwise it is False. We illustrate this in <ref type="figure" target="#fig_4">Figure 6</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Setup</head><p>We combine Levenshtein algorithm with different merging algorithms for correction detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset</head><p>An ideal data resource would be a real-world col- lection of student essays and their revisions ( <ref type="bibr" target="#b14">Tajiri et al., 2012</ref>). However, existing revision corpora do not have the fine-grained annotations necessary for our experimental gold standard. We instead use error annotated data, in which the corrections were provided by human experts. We simulate the revisions by applying corrections onto the original sentence. The teachers' annotations are treated as gold standard for the detailed corrections.</p><p>We considered four corpora with different ESL populations and annotation standards, including FCE corpus (Yannakoudakis et al., 2011), NU- CLE corpus <ref type="bibr" target="#b2">(Dahlmeier et al., 2013</ref>), UIUC cor- pus 2 (Rozovskaya and Roth, 2010) and HOO2011 corpus ( <ref type="bibr" target="#b3">Dale and Kilgarriff, 2011</ref>). These corpora all provide experts' corrections along with error Type name description A gap-between-edits Gap between the two edits. In particular, we use the number of words between the two edits' original words, as well as the revised words. Note that Swanson and Yamangil's approach is a special case that only considers if the basic-edits have zero gap in both sentences. tense-change</p><p>We detect patterns such as: if the original-revision pair matches the pattern "V-ing⇒to V". word-order-error</p><p>Whether the basic-edits' original word set and the revised word set are the same (one or zero). same-word-set If the original sentence and the revised sentence have the same word set, then it's likely that all the edits are fixing the word order error. revised-to</p><p>The phrase comprised of the two revised words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B editdistance=1</head><p>If one basic-edit is a substitution, and the original/revised word only has 1 edit distance, it indicates that the basic-edit is fixing a misspelling error. not-in-dict</p><p>If the original word does not have a valid dictionary entry, then it indicates a misspelling error. word-choice</p><p>If the original and the revised words have the same POS, then it is likely fixing a word choice error. preposition-error</p><p>Whether the original and the revised words are both prepositions.  type mark-ups. The basic statistics of the corpora are shown in <ref type="table" target="#tab_1">Table 2</ref>. In these corpora, around half of revised sentences contains multiple corrections. We have split each corpus into 11 equal parts. One part is used as the development dataset; the rest are used for 10-fold cross validation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation Metrics</head><p>In addition to evaluating the merging algorithms on the stand-alone task of correction detection, we have also plugged in the merging algorithms into an end-to-end system in which every automati- cally detected correction is further classified into an error type. We replicated the error type selector described in <ref type="bibr" target="#b13">Swanson and Yamangil (2012)</ref>. The error type selector's accuracies are shown in <ref type="table" target="#tab_3">Table  3</ref> 3 . We compare two merging algorithms, com- bined with Levenshtein algorithm:</p><p>S&amp;Y The merging heuristic proposed by Swan- son and Yamangil, which merges the adjacent ba- sic edits into single corrections.</p><p>MaxEntMerger We use the Maximum Entropy classifier to predict whether we should merge the two edits, as described in Section 3 4 . We evaluate extrinsically the merging compo- nents' effect on overall system performance by <ref type="bibr">3</ref> Our replication has a slightly lower error type selection accuracy on FCE (80.02%) than the figure reported by Swan- son and Yamangil (82.5%). This small difference on error type selection does not affect our conclusions about correc-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Corpus</head><p>Error  comparing the boundaries of system's detected corrections with the gold standard. We evaluate both (1) the F-score in detecting corrections (2) the F-score in correctly detecting both the correc- tions' and the error types they address.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>We design experiments to answer two questions:</p><p>1. Do the additional contextual information about correction patterns help guide the merging decisions? How much does a classifier trained for this task improve the system's overall accuracy?</p><p>2. How well does our method generalize over re- visions from different sources? Our major experimental results are presented in <ref type="table" target="#tab_5">Table 4 and Table 6</ref>. <ref type="table" target="#tab_5">Table 4</ref> compares the over- all educational system's accuracies with different merging algorithms. <ref type="table" target="#tab_7">Table 6</ref> shows the system's F 1 score when trained and tested on different cor- pora. We make the following observations:</p><p>First, <ref type="table" target="#tab_5">Table 4</ref> shows that by incorporating cor- rection patterns into the merging algorithm, the tion detection.errors in correction detection step were reduced. This led to a significant improvement on the over- all system's F 1 -score on all corpora. The improve- ment is most noticeable on FCE corpus, where the error in correction detection step was reduced by 9%. That is, one third of the correction mis- detections were eliminated. <ref type="table" target="#tab_6">Table 5</ref> shows that the number of merging errors are significantly reduced by the new merging algorithm. In particular, the number of false positives (system proposes merges when it should not) is significantly reduced.</p><p>Second, our proposed model is able to gener- alize over different corpora. As shown in <ref type="table" target="#tab_7">Table  6</ref>. The models built on corpora can generally im- prove the correction detection accuracy 5 . Mod- els built on the same corpus generally perform the best. Also, as suggested by the experimental result, among the four corpora, FCE corpus is a comparably good resource for training correction detection models with our current feature set. One reason is that FCE corpus has many more training instances, which benefits model training. We tried varying the training dataset size, and test it on dif- ferent corpora. <ref type="figure" target="#fig_6">Figure 7</ref> suggests that the model's accuracies increase with the training corpus size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>A revision often contains multiple corrections that address different writing mistakes. We explore building computer programs to accurately detect individual corrections in one single revision. One major challenge lies in determining whether con- secutive basic-edits address the same mistake. We propose a classifier specialized in this task. Our experiments suggest that: (1) the proposed classi- fier reduces correction mis-detections in previous systems by 1/3, leading to significant overall sys- tem performance. <ref type="formula">(2)</ref>       </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>Figure 2: A portion of the example from Figure 1 undergoing the two-step correction detection process. The basic edits are indicated by black polygons. The corrections are shown in red polygons.</figDesc><graphic url="image-1.png" coords="2,106.02,169.43,385.51,58.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>(</head><label></label><figDesc>a) The basic edits are addressing the same problem. But these basic edits are non-adjacent, and therefore not merged by S&amp;Y's algorithm. (b) The basic edits in the above two cases address different problems though they are adjacent. S&amp;Y's merging algorithm incorrectly merges them.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Merging mistakes by the algorithm proposed in Swanson and Yamangil (2012) (S&amp;Y), which merges adjacent basic edits.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>(</head><label></label><figDesc>Figure 5: Patterns indicating whether two edits address the same writing mistake.</figDesc><graphic url="image-8.png" coords="3,307.28,187.02,226.78,51.89" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Extracting training instances for the merger. Our</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: We illustrate the performance of correction detection systems trained on subsets of FCE corpus. Each curve in this figure represents the F1-scores for correction detection of the model trained on a subset of FCE and tested on different corpora. When testing on FCE, we used 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Features used in our proposed classifier. 

corpus 
sentences sentences with ≥ 2 corrections 

revised sentences 

FCE 
33,900 
53.45% 
NUCLE 
61,625 
48.74% 
UIUC 
883 
61.32% 
HOO2011 
966 
42.05% 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Basic statistics of the corpora that we consider.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Error type selection accuracies on different cor-

pora. We use a Maximum Entropy classifier along with fea-
tures suggested by Swanson and Yamangil for this task. The 
reported figures come from 10-fold cross validations on dif-
ferent corpora. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head></head><label></label><figDesc>our method is generalizable over different data collections.</figDesc><table>Method 
Corpus 
Correction 
Detection F1 
Overall 
F1-score 
S&amp;Y 
FCE 
70.40% 
57.10% 
MaxEntMerger 
FCE 
80.96% 
66.36% 
S&amp;Y 
NUCLE 
61.18% 
39.32% 
MaxEntMerger 
NUCLE 
63.88% 
41.00% 
S&amp;Y 
UIUC 
76.57% 
65.08% 
MaxEntMerger 
UIUC 
82.81% 
70.55% 
S&amp;Y 
HOO2011 
68.73% 
50.95% 
MaxEntMerger 
HOO2011 
75.71% 
56.14% 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Extrinsic evaluation, where we plugged the two 

merging models into an end-to-end feedback detection sys-
tem by Swanson and Yamangil. 

Merging algorithm TP 
FP 
FN 
TN 
S&amp;Y 
33.73% 13.46% 5.71% 47.10% 
MaxEntMerger 
36.04% 3.26% 
3.41% 57.30% 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Intrinsic evaluation, where we evaluate the pro-

posed merging model's prediction accuracy on FCE corpus. 
This table shows a breakdown of true-positives (TP), false-
positives (FP), false-negatives (FN) and true-negatives (TN) 
for the system built on FCE corpus. 

training 
testing FCE 
NUCLE UIUC 
HOO2011 

S&amp;Y 
70.44 
61.18% 
76.57% 
68.73% 
FCE 
80.96% 61.26% 
83.07% 75.43% 
NUCLE 
74.53% 
63.88% 78.57% 
74.73% 
UIUC 
77.25% 
58.21% 
82.81% 
70.83% 
HOO2011 
71.94% 
54.99% 
71.19% 
75.71% 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Correction detection experiments by building the 

model on one corpus, and applying it onto another. We 
evaluate the correction detection performance with F1 score. 
When training and testing on the same corpus, we run a 10-
fold cross validation. 

</table></figure>

			<note place="foot" n="1"> Swanson and Yamangil reported an overall system with 58% F-score.</note>

			<note place="foot" n="2"> UIUC corpus contains annotations of essays collected from ICLE (Granger, 2003) and CLEC (Gui and Yang, 2003).</note>

			<note place="foot" n="4"> We use the implementation at http://homepages. inf.ed.ac.uk/lzhang10/maxent_toolkit. html.</note>

			<note place="foot" n="5"> We currently do not evaluate the end-to-end system over different corpora. This is because different corpora employ different error type categorization standards.</note>

			<note place="foot" n="11"> of the FCE corpus, which we kept as development data.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work is supported by U.S. National Sci-ence Foundation Grant IIS-0745914. We thank the anonymous reviewers for their suggestions; we also thank Homa Hashemi, Wencan Luo, Fan Zhang, Lingjia Deng, Wenting Xiong and Yafei Wei for helpful discussions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Constructing corpora for the development and evaluation of paraphrase systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="597" to="614" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Better evaluation for grammatical error correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Dahlmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee Tou</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012-06" />
			<biblScope unit="page" from="568" to="572" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Building a large annotated corpus of learner english: The NUS corpus of learner english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Dahlmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee</forename><forename type="middle">Tou</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siew Mei</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth Workshop on Innovative Use of NLP for Building Educational Applications</title>
		<meeting>the Eighth Workshop on Innovative Use of NLP for Building Educational Applications</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="22" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Helping our own: The HOO 2011 pilot shared task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Dale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Kilgarriff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th European Workshop on Natural Language Generation</title>
		<meeting>the 13th European Workshop on Natural Language Generation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="242" to="249" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Preparing ESL students for college writing: Two case studies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Laureen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fregeau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Internet TESL Journal</title>
		<imprint>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The International Corpus of Learner English: a new resource for foreign language learning and teaching and second language acquisition research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylviane</forename><surname>Granger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tesol Quarterly</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="538" to="546" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Zhongguo xuexizhe yingyu yuliaohu.(chinese learner english corpus)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shicun</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huizhong</forename><surname>Yang</surname></persName>
		</author>
		<editor>. Shanghai: Shanghai Waiyu Jiaoyu Chubanshe</editor>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Tree edit models for recognizing textual entailments, paraphrases, and answers to questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Heilman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1011" to="1019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Statistical phrase-based translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">J</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Conference of the North American Chapter</title>
		<meeting>the 2003 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="48" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Binary codes capable of correcting deletions, insertions, and reversals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">I</forename><surname>Levenshtein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soviet Physics Doklady</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">707710</biblScope>
			<date type="published" when="1966" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The Cambridge Learner Corpus: Error coding and analysis for lexicography and ELT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Nicholls</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Corpus Linguistics 2003 conference</title>
		<meeting>the Corpus Linguistics 2003 conference</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="572" to="581" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Annotating ESL errors: Challenges and rewards</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alla</forename><surname>Rozovskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL HLT 2010 fifth workshop on innovative use of NLP for building educational applications</title>
		<meeting>the NAACL HLT 2010 fifth workshop on innovative use of NLP for building educational applications</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="28" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">TER-Plus: paraphrase, semantic, and alignment enhancements to translation edit rate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitin</forename><surname>Snover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Madnani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Dorr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Translation</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="117" to="127" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Correction detection and error type selection as an ESL educational aid</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Swanson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elif</forename><surname>Yamangil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012-06" />
			<biblScope unit="page" from="357" to="361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Tense and aspect error correction for ESL learners using global context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshikazu</forename><surname>Tajiri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mamoru</forename><surname>Komachi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="198" to="202" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Providing feedback on ESL students written assignments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><forename type="middle">Gordon</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Williams</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Internet TESL Journal</title>
		<imprint>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A new dataset and method for automatically grading esol texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helen</forename><surname>Yannakoudakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ted</forename><surname>Briscoe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Medlock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="180" to="189" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
