<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:20+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Using Discourse Structure Improves Machine Translation Evaluation</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>June 23-25 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Guzmán</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">ALT Research Group</orgName>
								<orgName type="institution">Qatar Computing Research Institute</orgName>
								<address>
									<country>Qatar Foundation</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shafiq</forename><forename type="middle">Joty</forename><surname>Lluís</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">ALT Research Group</orgName>
								<orgName type="institution">Qatar Computing Research Institute</orgName>
								<address>
									<country>Qatar Foundation</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">`</forename><surname>Arquez</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">ALT Research Group</orgName>
								<orgName type="institution">Qatar Computing Research Institute</orgName>
								<address>
									<country>Qatar Foundation</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">ALT Research Group</orgName>
								<orgName type="institution">Qatar Computing Research Institute</orgName>
								<address>
									<country>Qatar Foundation</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Using Discourse Structure Improves Machine Translation Evaluation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="687" to="698"/>
							<date type="published">June 23-25 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present experiments in using discourse structure for improving machine translation evaluation. We first design two discourse-aware similarity measures, which use all-subtree kernels to compare discourse parse trees in accordance with the Rhetorical Structure Theory. Then, we show that these measures can help improve a number of existing machine translation evaluation metrics both at the segment-and at the system-level. Rather than proposing a single new metric, we show that discourse information is complementary to the state-of-the-art evaluation metrics, and thus should be taken into account in the development of future richer evaluation metrics.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>From its foundations, Statistical Machine Transla- tion (SMT) had two defining characteristics: first, translation was modeled as a generative process at the sentence-level. Second, it was purely statisti- cal over words or word sequences and made lit- tle to no use of linguistic information. Although modern SMT systems have switched to a discrim- inative log-linear framework, which allows for ad- ditional sources as features, it is generally hard to incorporate dependencies beyond a small window of adjacent words, thus making it difficult to use linguistically-rich models.</p><p>Recently, there have been two promising re- search directions for improving SMT and its eval- uation: (a) by using more structured linguistic information, such as syntax ( <ref type="bibr">Galley et al., 2004;</ref><ref type="bibr" target="#b24">Quirk et al., 2005</ref>), hierarchical structures <ref type="bibr" target="#b6">(Chiang, 2005</ref>), and semantic roles ( <ref type="bibr" target="#b33">Wu and Fung, 2009;</ref><ref type="bibr" target="#b16">Lo et al., 2012)</ref>, and (b) by going beyond the sentence-level, e.g., translating at the docu- ment level <ref type="bibr">(Hardmeier et al., 2012</ref>).</p><p>Going beyond the sentence-level is important since sentences rarely stand on their own in a well-written text. Rather, each sentence follows smoothly from the ones before it, and leads into the ones that come afterwards. The logical rela- tionship between sentences carries important in- formation that allows the text to express a meaning as a whole beyond the sum of its separate parts.</p><p>Note that sentences can be made of several clauses, which in turn can be interrelated through the same logical relations. Thus, in a coherent text, discourse units (sentences or clauses) are logically connected: the meaning of a unit relates to that of the previous and the following units.</p><p>Discourse analysis seeks to uncover this coher- ence structure underneath the text. Several formal theories of discourse have been proposed to de- scribe the coherence structure <ref type="bibr" target="#b17">(Mann and Thompson, 1988;</ref><ref type="bibr" target="#b0">Asher and Lascarides, 2003;</ref><ref type="bibr" target="#b31">Webber, 2004</ref>). For example, the Rhetorical Structure The- ory ( <ref type="bibr" target="#b17">Mann and Thompson, 1988)</ref>, or RST, repre- sents text by labeled hierarchical structures called Discourse Trees (DTs), which can incorporate sev- eral layers of other linguistic information, e.g., syntax, predicate-argument structure, etc.</p><p>Modeling discourse brings together the above research directions (a) and (b), which makes it an attractive goal for MT. This is demonstrated by the establishment of a recent workshop dedicated to Discourse in Machine Translation ( <ref type="bibr">Webber et al., 2013)</ref>, collocated with the 2013 annual meeting of the Association of Computational Linguistics.</p><p>The area of discourse analysis for SMT is still nascent and, to the best of our knowledge, no previous research has attempted to use rhetorical structure for SMT or machine translation evalua- tion. One possible reason could be the unavailabil- ity of accurate discourse parsers. However, this situation is likely to change given the most recent advances in automatic discourse analysis <ref type="bibr" target="#b11">(Joty et al., 2012;</ref><ref type="bibr" target="#b12">Joty et al., 2013</ref>).</p><p>We believe that the semantic and pragmatic in- formation captured in the form of DTs (i) can help develop discourse-aware SMT systems that pro- duce coherent translations, and (ii) can yield bet- ter MT evaluation metrics. While in this work we focus on the latter, we think that the former is also within reach, and that SMT systems would bene- fit from preserving the coherence relations in the source language when generating target-language translations.</p><p>In this paper, rather than proposing yet another MT evaluation metric, we show that discourse information is complementary to many existing evaluation metrics, and thus should not be ignored. We first design two discourse-aware similarity measures, which use DTs generated by a publicly- available discourse parser ( <ref type="bibr" target="#b11">Joty et al., 2012)</ref>; then, we show that they can help improve a number of MT evaluation metrics at the segment-and at the system-level in the context of the WMT11 and the WMT12 metrics shared tasks <ref type="bibr" target="#b1">(Callison-Burch et al., 2011;</ref><ref type="bibr" target="#b2">Callison-Burch et al., 2012</ref>).</p><p>These metrics tasks are based on sentence-level evaluation, which arguably can limit the benefits of using global discourse properties. Fortunately, several sentences are long and complex enough to present rich discourse structures connecting their basic clauses. Thus, although limited, this setting is able to demonstrate the potential of discourse- level information for MT evaluation. Furthermore, sentence-level scoring (i) is compatible with most translation systems, which work on a sentence-by- sentence basis, (ii) could be beneficial to mod- ern MT tuning mechanisms such as PRO <ref type="bibr">(Hopkins and May, 2011</ref>) and MIRA ( <ref type="bibr" target="#b29">Watanabe et al., 2007;</ref><ref type="bibr" target="#b5">Chiang et al., 2008)</ref>, which also work at the sentence-level, and (iii) could be used for re- ranking n-best lists of translation hypotheses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Addressing discourse-level phenomena in ma- chine translation is relatively new as a research di- rection. Some recent work has looked at anaphora resolution <ref type="bibr">(Hardmeier and Federico, 2010)</ref> and discourse connectives <ref type="bibr" target="#b4">(Cartoni et al., 2011;</ref><ref type="bibr" target="#b19">Meyer, 2011)</ref>, to mention two examples. 1 However, so far the attempts to incorporate discourse-related knowledge in MT have been only moderately suc- cessful, at best. A common argument, is that current automatic evaluation metrics such as BLEU are inadequate to capture discourse-related aspects of translation quality <ref type="bibr">(Hardmeier and Federico, 2010;</ref><ref type="bibr" target="#b18">Meyer et al., 2012</ref>). Thus, there is consensus that discourse- informed MT evaluation metrics are needed in or- der to advance research in this direction. Here we suggest some simple ways to create such metrics, and we also show that they yield better correlation with human judgments.</p><p>The field of automatic evaluation metrics for MT is very active, and new metrics are contin- uously being proposed, especially in the context of the evaluation campaigns that run as part of the Workshops on Statistical Machine Transla- tion <ref type="bibr">(WMT 2008</ref><ref type="bibr">(WMT -2012</ref>, and NIST Metrics for Machine Translation Challenge (MetricsMATR), among others. For example, at WMT12, 12 met- rics were compared <ref type="bibr" target="#b2">(Callison-Burch et al., 2012</ref>), most of them new.</p><p>There have been several attempts to incorpo- rate syntactic and semantic linguistic knowledge into MT evaluation. For instance, at the syn- tactic level, we find metrics that measure the structural similarity between shallow syntactic se- quences ( <ref type="bibr">Giménez and M` arquez, 2007;</ref><ref type="bibr" target="#b23">Popovic and Ney, 2007)</ref> or between constituency trees (Liu and <ref type="bibr" target="#b15">Gildea, 2005</ref>). In the semantic case, there are metrics that exploit the similarity over named en- tities and predicate-argument structures ( <ref type="bibr">Giménez and M` arquez, 2007;</ref><ref type="bibr" target="#b16">Lo et al., 2012</ref>).</p><p>In this work, instead of proposing a new metric, we focus on enriching current MT evaluation met- rics with discourse information. Our experiments show that many existing metrics can benefit from additional knowledge about discourse structure.</p><p>In comparison to the syntactic and semantic ex- tensions of MT metrics, there have been very few attempts to incorporate discourse information so far. One example are the semantics-aware metrics of <ref type="bibr">Giménez and M` arquez (2009)</ref> and <ref type="bibr" target="#b8">Comelles et al. (2010)</ref>, which use the Discourse Representa- tion Theory ( <ref type="bibr" target="#b13">Kamp and Reyle, 1993)</ref> and tree- based discourse representation structures (DRS) produced by a semantic parser. They calculate the similarity between the MT output and references based on DRS subtree matching, as defined in (Liu and <ref type="bibr" target="#b15">Gildea, 2005</ref>), DRS lexical overlap, and DRS morpho-syntactic overlap. However, they could not improve correlation with human judgments, as evaluated on the MetricsMATR dataset.</p><p>Compared to the previous work, (i) we use a different discourse representation (RST), (ii) we compare discourse parses using all-subtree ker- nels <ref type="bibr" target="#b7">(Collins and Duffy, 2001</ref>), (iii) we evaluate on much larger datasets, for several language pairs and for multiple metrics, and (iv) we do demon- strate better correlation with human judgments. <ref type="bibr" target="#b32">Wong and Kit (2012)</ref> recently proposed an extension of MT metrics with a measure of document-level lexical cohesion <ref type="bibr">(Halliday and Hasan, 1976)</ref>. Lexical cohesion is achieved using word repetitions and semantically similar words such as synonyms, hypernyms, and hyponyms. For BLEU and TER, they observed improved correlation with human judgments on the MTC4 dataset when linearly interpolating these metrics with their lexical cohesion score. Unlike their work, which measures lexical cohesion at the document-level, here we are concerned with co- herence (rhetorical) structure, primarily at the sentence-level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Our Discourse-Based Measures</head><p>Our working hypothesis is that the similarity be- tween the discourse structures of an automatic and of a reference translation provides additional in- formation that can be valuable for evaluating MT systems. In particular, we believe that good trans- lations should tend to preserve discourse relations.</p><p>As an example, consider the three discourse trees (DTs) shown in <ref type="figure" target="#fig_1">Figure 1</ref>: (a) for a reference (human) translation, and (b) and (c) for transla- tions of two different systems on the WMT12 test dataset. The leaves of a DT correspond to con- tiguous atomic text spans, called Elementary Dis- course Units or EDUs (three in <ref type="figure" target="#fig_1">Figure 1a</ref>). Ad- jacent spans are connected by certain coherence relations (e.g., Elaboration, Attribution), forming larger discourse units, which in turn are also sub- ject to this relation linking. Discourse units linked by a relation are further distinguished based on their relative importance in the text: nuclei are the core parts of the relation while satellites are supportive ones. Note that the nuclearity and re- lation labels in the reference translation are also realized in the system translation in (b), but not in (c), which makes (b) a better translation com- pared to (c), according to our hypothesis. We ar- gue that existing metrics that only use lexical and syntactic information cannot distinguish well be- tween (b) and (c).</p><p>In order to develop a discourse-aware evalua- tion metric, we first generate discourse trees for the reference and the system-translated sentences using a discourse parser, and then we measure the similarity between the two discourse trees. We de- scribe these two steps below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Generating Discourse Trees</head><p>In Rhetorical Structure Theory, discourse analysis involves two subtasks: (i) discourse segmentation, or breaking the text into a sequence of EDUs, and (ii) discourse parsing, or the task of linking the units (EDUs and larger discourse units) into la- beled discourse trees. Recently, Joty et al. <ref type="formula">(2012)</ref> proposed discriminative models for both discourse segmentation and discourse parsing at the sen- tence level. The segmenter uses a maximum en- tropy model that achieves state-of-the-art accuracy on this task, having an F 1 -score of 90.5%, while human agreement is 98.3%.</p><p>The discourse parser uses a dynamic Condi- tional Random Field ( <ref type="bibr" target="#b27">Sutton et al., 2007</ref>) as a pars- ing model in order to infer the probability of all possible discourse tree constituents. The inferred (posterior) probabilities are then used in a proba- bilistic CKY-like bottom-up parsing algorithm to find the most likely DT. Using the standard set of 18 coarse-grained relations defined in <ref type="bibr" target="#b3">(Carlson and Marcu, 2001</ref>), the parser achieved an F 1 -score of 79.8%, which is very close to the human agree- ment of 83%. These high scores allowed us to de- velop successful discourse similarity metrics. <ref type="bibr">2</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Measuring Similarity</head><p>A number of metrics have been proposed to mea- sure the similarity between two labeled trees, e.g., Tree Edit Distance <ref type="bibr" target="#b28">(Tai, 1979)</ref> and Tree Kernels ( <ref type="bibr" target="#b7">Collins and Duffy, 2001;</ref><ref type="bibr" target="#b20">Moschitti and Basili, 2006</ref>). Tree kernels (TKs) provide an effective way to integrate arbitrary tree structures in kernel- based machine learning algorithms like SVMs.</p><p>In the present work, we use the convolution TK defined in <ref type="bibr" target="#b7">(Collins and Duffy, 2001</ref>), which effi- ciently calculates the number of common subtrees in two trees. Note that this kernel was originally designed for syntactic parsing, where the subtrees are subject to the constraint that their nodes are taken with either all or none of the children. This constraint of the TK imposes some limitations on the type of substructures that can be compared. (a) A reference (human) translation.</p><p>(b) A higher quality system translation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SPAN ROOT</head><p>In Germany the ECB should be for the creditors of last resort .</p><p>(c) A lower quality system translation. One way to cope with the limitations of the TK is to change the representation of the trees to a form that is suitable to capture the relevant infor- mation for our task. We experiment with TKs ap- plied to two different representations of the dis- course tree: non-lexicalized (DR), and lexicalized (DR-LEX). In <ref type="figure" target="#fig_2">Figure 2</ref> we show the two represen- tations for the subtree that spans the text: "sug- gest the ECB should be the lender of last resort", which is highlighted in <ref type="figure" target="#fig_1">Figure 1b</ref>.</p><p>As shown in <ref type="figure" target="#fig_2">Figure 2a</ref>, DR does not include any lexical item, and therefore measures the similar- ity between two translations in terms of their dis- course structures only. On the contrary, DR-LEX includes the lexical items to account for lexical matching; moreover, it separates the structure (the skeleton) of the tree from its labels, i.e. the nucle- arity and the relations, in order to allow the tree kernel to give partial credit to subtrees that differ in labels but match in their skeletons. More specif- ically, it uses the tags SPAN and EDU to build the skeleton of the tree, and considers the nuclearity and/or the relation labels as properties, added as children, of these tags.</p><p>For example, a SPAN has two properties (its nuclearity and its relation), and an EDU has one property (its nuclearity). The words of an EDU are placed under the predefined children NGRAM. In order to allow the tree kernel to find subtree matches at the word level, we include an additional layer of dummy leaves as was done in ( <ref type="bibr" target="#b21">Moschitti et al., 2007)</ref>; not shown in <ref type="figure" target="#fig_2">Figure 2</ref>, for simplicity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Setup</head><p>In our experiments, we used the data available for the WMT12 and the WMT11 metrics shared tasks for translations into English. <ref type="bibr">3</ref> This included the output from the systems that participated in the WMT12 and the WMT11 MT evaluation cam- paigns, both consisting of 3,003 sentences, for four different language pairs: Czech-English (CS- EN), French-English (FR-EN), German-English (DE-EN), and Spanish-English (ES-EN); as well as a dataset with the English references.</p><p>We measured the correlation of the metrics with the human judgments provided by the organizers. The judgments represent rankings of the output of five systems chosen at random, for a particu- lar sentence, also chosen at random. Note that each judgment effectively constitutes 10 pairwise system rankings. The overall coverage, i.e. the number of unique sentences that were evaluated, was only a fraction of the total; the total number of judgments, along with other information of the datasets are shown in <ref type="table" target="#tab_1">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">MT Evaluation Metrics</head><p>In this study, we evaluate to what extent existing evaluation metrics can benefit from additional dis- course information. To do so, we contrast different MT evaluation metrics with and without discourse information. The evaluation metrics we used are described below.   Metrics from ASIYA. We used the freely avail- able version of the ASIYA toolkit 4 in order to ex- tend the set of evaluation measures contrasted in this study beyond those from the WMT12 metrics task. ASIYA ( <ref type="bibr">Giménez and M` arquez, 2010a</ref>) is a suite for MT evaluation that provides a large set of metrics that use different levels of linguistic infor- mation. For reproducibility, below we explain the individual metrics with the exact names required by the toolkit to calculate them.</p><p>First, we used ASIYA's ULC (Giménez and M` arquez, 2010b), which was the best performing metric at the system and the segment levels at the WMT08 and WMT09 metrics tasks. This is a uni- form linear combination of 12 individual metrics. From the original ULC, we only replaced TER and Meteor individual metrics by newer versions tak- ing into account synonymy lookup and paraphras- ing: TERp-A and METEOR-pa in ASIYA's termi- nology. We will call this combined metric Asiya- 0809 in our experiments.</p><p>To complement the set of individual metrics that participated at the WMT12 metrics task, we also computed the scores of other commonly- 4. Asiya-SEM. Combination of two metrics variants based on semantic parsing: 6 'DR- Or(*)' and 'DR-Orp(*)'.</p><p>All uniform linear combinations are calculated outside ASIYA. In order to make the scores of the different metrics comparable, we performed a min-max normalization, for each metric, and for each language pair combination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Human Judgements and Learning</head><p>The human-annotated data from the WMT cam- paigns encompasses series of rankings on the out- put of different MT systems for every source sen- tence. Annotators rank the output of five systems according to perceived translation quality. The or- ganizers relied on a random selection of systems, and a large number of comparisons between pairs of them, to make comparisons across systems fea- sible <ref type="bibr" target="#b2">(Callison-Burch et al., 2012)</ref>. As a result, for each source sentence, only relative rankings were available. As in the WMT12 experimen- tal setup, we use these rankings to calculate cor- relation with human judgments at the sentence- level, i.e. Kendall's Tau; see (Callison-Burch et al., <ref type="bibr">2012</ref>) for details.</p><p>For the experiments reported in Section 5.4, we used pairwise rankings to discriminatively learn the weights of the linear combinations of indi- vidual metrics. In order to use the WMT12 data for training a learning-to-rank model, we trans- formed the five-way relative rankings into ten pairwise comparisons. For instance, if a judge ranked the output of systems A, B, C, D, E as A &gt; B &gt; C &gt; D &gt; E, this would entail that A &gt; B, A &gt; C, A &gt; D and A &gt; E, etc.</p><p>To determine the relative weights for the tuned combinations, we followed a similar approach to the one used by PRO to tune the relative weights of the components of a log-linear SMT model <ref type="bibr">(Hopkins and May, 2011</ref>), also using Maximum En- tropy as the base learning algorithm. Unlike PRO, (i) we use human judgments, not automatic scores, and (ii) we train on all pairs, not on a sub- sample.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Results</head><p>In this section, we explore how discourse informa- tion can be used to improve machine translation evaluation metrics. Below we present the evalua- tion results at the system-and segment-level, using our two basic metrics on discourse trees (Section 3.1), which are referred to as DR and DR-LEX.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Evaluation</head><p>In our experiments, we only consider translation into English, and use the data described in <ref type="table" target="#tab_1">Table 1</ref>. For evaluation, we follow the setup of the metrics task of WMT12 <ref type="bibr" target="#b2">(Callison-Burch et al., 2012</ref>): at the system-level, we use the official script from WMT12 to calculate the Spearman's correlation, where higher absolute values indicate better met- rics performance; at the segment-level, we use Kendall's Tau for measuring correlation, where negative values are worse than positive ones. <ref type="bibr">7</ref> In our experiments, we combine DR and DR-LEX to other metrics in two different ways: using uniform linear interpolation (at system-and segment-level), and using a tuned linear interpo- lation for the segment-level. We only present the average results over all four language pairs. For simplicity, in our tables we show results divided into evaluation groups:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Group I: contains our evaluation metrics, DR</head><p>and DR-LEX.</p><p>2. Group II: includes the metrics that partici- pated in the WMT12 metrics task, excluding metrics which did not have results for all lan- guage pairs.</p><p>3. Group III: contains other important evalu- ation metrics, which were not considered in the WMT12 metrics task: NIST and ROUGE for both system-and segment-level, and BLEU and TER at segment-level.</p><p>4. Group IV: includes the metric combinations calculated with ASIYA and described in Sec- tion 4.</p><p>For each metric in groups II, III and IV, we present the results for the original metric as well for the linear interpolation of that metric with DR and with DR-LEX. The combinations with DR and DR-LEX that improve over the original met- rics are shown in bold, and those that degrade are in italic. Furthermore, we also present overall re- sults for: (i) the average score over all metrics, ex- cluding DR and DR-LEX, and (ii) the differences in the correlations for the DR/DR-LEX-combined and the original metrics.   Results on WMT12 at the system-level. Spearman's correlation with human judgments. <ref type="table" target="#tab_3">Table 2</ref> shows the system-level experimental re- sults for WMT12. We can see that DR is already competitive by itself: on average, it has a cor- relation of .807, very close to BLEU and TER scores (.810 and .812, respectively). Moreover, DR yields improvements when combined with 15 of the 19 metrics; worsening only four of the met- rics. Overall, we observe an average improvement of +.024, in the correlation with the human judg- ments. This suggests that DR contains information that is complementary to that used by the other metrics. Note that this is true both for the indi- vidual metrics from groups II and III, as well as for the metric combinations in group IV. Combi- nations in the last group involve several metrics that already use linguistic information at different levels and are hard to improve over; yet, adding DR does improve, which shows that it has some complementary information to offer. As expected, DR-LEX performs better than DR since it is lexicalized (at the unigram level), and also gives partial credit to correct structures. Indi- vidually, DR-LEX outperforms most of the metrics from group II, and ranks as the second best metric in that group. Furthermore, when combined with individual metrics in group II, DR-LEX is able to improve consistently over each one of them.  Note that, even though DR-LEX has better indi- vidual performance than DR, it does not yield im- provements when combined with most of the met- rics in group IV. 8 However, over all metrics and all language pairs, DR-LEX is able to obtain an aver- age improvement in correlation of +.035, which is remarkably higher than that of DR. Thus, we can conclude that at the system-level, adding discourse information to a metric, even using the simplest of the combination schemes, is a good idea for most of the metrics, and can help to significantly im- prove the correlation with human judgments. <ref type="table" target="#tab_5">Table 3</ref> shows the results for WMT12 at the segment-level. We can see that DR performs badly, with a high negative Kendall's Tau of -.433. This should not be surprising: (a) the discourse tree structure alone does not contain enough infor- mation for a good evaluation at the segment-level, and (b) this metric is more sensitive to the quality of the DT, which can be wrong or void.   Additionally, DR is more likely to produce a high number of ties, which is harshly penalized by WMT12's definition of Kendall's Tau. Con- versely, ties and incomplete discourse analysis were not a problem at the system-level, where ev- idence from all 3,003 test sentences is aggregated, and allows to rank systems more precisely. Due to the low score of DR as an individual metric, it fails to yield improvements when uniformly combined with other metrics. Again, DR-LEX is better than DR; with a pos- itive Tau of +.133, yet as an individual metric, it ranks poorly compared to other metrics in group II. However, when linearly combined with other metrics, DR-LEX outperforms 14 of the 19 met- rics in <ref type="table" target="#tab_5">Table 3</ref>. Across all metrics, DR-LEX yields an average Tau improvement of +.026, i.e. from .165 to .190. This is a large improvement, taking into account that the combinations are just uniform linear combinations. In subsection 5.4, we present the results of tuning the linear combination in a discriminative way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">System-level Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Segment-level Results: Non-tuned</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Segment-level Results: Tuned</head><p>We experimented with tuning the weights of the individual metrics in the metric combinations, us- ing the learning method described in Section 4.2.</p><p>First, we did this using cross-validation to tune and test on WMT12. Later we tuned on WMT12 and evaluated on WMT11. For cross-validation in WMT12, we used ten folds of approximately equal sizes, each containing about 300 sentences: we constructed the folds by putting together en- tire documents, thus not allowing sentences from a document to be split over two different folds. During each cross-validation run, we trained our pairwise ranker using the human judgments cor- responding to nine of the ten folds. We aggre- gated the data for different language pairs, and produced a single set of tuning weights for all lan- guage pairs. <ref type="bibr">9</ref> We then used the remaining fold for evaluation</p><p>The results are shown in <ref type="table" target="#tab_7">Table 4</ref>. As in previ- ous sections we present the average results over all four language pairs. We can see that the tuned combinations with DR-LEX improve over most of the individual metrics in groups II and III. Inter- estingly, the tuned combinations that include the much weaker metric DR now improve over 12 out of 13 of the individual metrics in groups II and III, and only slightly degrades the score of the 13th one (SPEDE07PP).</p><p>Note that the ASIYA metrics are combinations of several metrics, and these combinations (which exclude DR and DR-LEX) can be also tuned; this yields sizable improvements over the untuned ver- sions as column three in the table shows. Com- pared to this baseline, DR improves for three of the six ASIYA metrics, while DR-LEX improves for four of them. Note that improving over the last two ASIYA metrics is very hard: they have very high scores of .296 and .295; for compar- ison, the best segment-level system at WMT12 (SPEDE07PP) achieved a Tau of .254.</p><p>On average, DR improves Tau from .165 to .201, which is +.036, while DR-LEX improves to .222, or +.057. These much larger improvements highlight the importance of tuning the linear com- bination when working at the segment-level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.1">Testing on WMT11</head><p>In order to rule out the possibility that the im- provement of the tuned metrics on WMT12 comes from over-fitting, and to verify that the tuned met- rics do generalize when applied to other sentences, we also tested on a new test set: WMT11. Therefore, we tuned the weights on all WMT12 pairwise judgments (no cross-validation), and we evaluated on WMT11. Since the metrics that par- ticipated in WMT11 and WMT12 are different (and even when they have the same name, there is no guarantee that they have not changed from 2011 to 2012), we only report results for the ver- sions of NIST, ROUGE, TER, and BLEU available in ASIYA, as well as for the ASIYA metrics, thus ensuring that the metrics in the experiments are consistent for 2011 and 2012.</p><p>The results are shown in <ref type="table" target="#tab_9">Table 5</ref>. Once again, tuning yields sizable improvements over the sim- ple combination for the ASIYA metrics (third col- umn in <ref type="table" target="#tab_9">Table 5</ref>). Adding DR and DR-LEX to the combinations manages to improve over five and four of the six tuned ASIYA metrics, respectively. However, some of the differences are very small. On the contrary, DR and DR-LEX significantly im- prove over NIST, ROUGE, TER, and BLEU. Over- all, DR improves the average Tau from .207 to .244, which is +.037, while DR-LEX improves to .267 or +.061. These improvements are very close to those for the WMT12 cross-validation. This shows that the weights learned on WMT12 gen- eralize well, as they are also good for WMT11.</p><p>What is also interesting to note is that when tun- ing is used, DR helps achieve sizeable improve- ments, even if not as strong as for DR-LEX. This is remarkable given that DR has a strong negative Tau as an individual metric at the sentence-level. This suggests that both DR and DR-LEX contain information that is complementary to that of the individual metrics that we experimented with.</p><p>Overall, from the experimental results in this section, we can conclude that discourse structure is an important information source to be taken into account in the automatic evaluation of machine translation output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions and Future Work</head><p>In this paper we have shown that discourse struc- ture can be used to improve automatic MT evalua- tion. First, we defined two simple discourse-aware similarity metrics (lexicalized and un-lexicalized), which use the all-subtree kernel to compute sim- ilarity between discourse parse trees in accor- dance with the Rhetorical Structure Theory. Then, after extensive experimentation on WMT12 and WMT11 data, we showed that a variety of ex- isting evaluation metrics can benefit from our  discourse-based metrics, both at the segment-and the system-level, especially when the discourse in- formation is incorporated in an informed way (i.e. using supervised tuning). Our results show that discourse-based metrics can improve the state-of- the-art MT metrics, by increasing correlation with human judgments, even when only sentence-level discourse information is used. Addressing discourse-level phenomena in MT is a relatively new research direction. Yet, many of the ongoing efforts have been moderately suc- cessful according to traditional evaluation met- rics. There is a consensus in the MT community that more discourse-aware metrics need to be pro- posed for this area to move forward. We believe this work is a valuable contribution towards this longer-term goal.</p><p>The tuned combined metrics tested in this pa- per are just an initial proposal, i.e. a simple ad- justment of the relative weights for the individ- ual metrics in a linear combination. In the fu- ture, we plan to work on integrated representations of syntactic, semantic and discourse-based struc- tures, which would allow us to train evaluation metrics based on more fine-grained features. Ad- ditionally, we propose to use the discourse infor- mation for MT in two different ways. First, at the sentence-level, we can use discourse information to re-rank alternative MT hypotheses; this could be applied either for MT parameter tuning, or as a post-processing step for the MT output. Second, we propose to move in the direction of using dis- course information beyond the sentence-level. <ref type="bibr">George Doddington. 2002. Automatic evaluation</ref> of machine translation quality using n-gram co- occurrence statistics. <ref type="table" target="#tab_1">In Proceedings of the Sec- ond International Conference on Human Language  Technology Research, HLT '02, pages 138-</ref> </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Elaboration ROOT SPAN Nucleus Attribution Satellite Voices are coming from Germany , SPAN Satellite SPAN Nucleus suggesting that ECB be the last resort creditor .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example of three different discourse trees for the translations of a source sentence. (a) The reference, (b) A higher quality translation, (c) A lower quality translation.</figDesc><graphic url="image-1.png" coords="4,164.35,184.01,224.40,60.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Two different DT representations for the highlighted subtree shown in Figure 1b.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>used evaluation metrics: BLEU (Papineni et al., 2002), NIST (Doddington, 2002), TER (Snover et al., 2006), ROUGE-W (Lin, 2004), and three METEOR variants (Denkowski and Lavie, 2011): METEOR-ex (exact match), METEOR-st (+stem- ming) and METEOR-sy (+synonyms). The uni- form linear combination of the previous 7 indi- vidual metrics plus the 12 from Asiya-0809 is re- ported as Asiya-ALL in the experimental section. The individual metrics combined in Asiya-ALL can be naturally categorized according to the type of linguistic information they use to compute the quality scores. We grouped them in the follow- ing four families and calculated the uniform linear combination of the metrics in each group: 5 1. Asiya-LEX. Combination of five metrics based on lexical similarity: BLEU, NIST, METEOR-ex, ROUGE-W, and TERp-A. 2. Asiya-SYN. Combination of four met- rics ba-sed on syntactic information from constituency and dependency parse trees: 'CP-STM-4', 'DP-HWCM c-4', 'DP- HWCM r-4', and 'DP-Or(*)'. 3. Asiya-SRL. Combination of three metric variants based on predicate argument struc- tures (semantic role labeling): 'SR-Mr(*)', 'SR-Or(*)', and 'SR-Or'.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Metrics</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Tuned</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Number of systems (systs), judgments 
(ranks), unique sentences (sents), and different 
judges (judges) for the different language pairs, for 
the human evaluation of the WMT12 and WMT11 
shared tasks. 

Metrics from WMT12. We used the publicly 
available scores for all metrics that participated 
in the WMT12 metrics task (Callison-Burch et 
al., 2012): SPEDE07PP, AMBER, METEOR, 
TERRORCAT, 
SIMPBLEU, XENERRCATS, 
WORDBLOCKEC, BLOCKERRCATS, and POSF. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Results on WMT12 at the segment-level. 
Kendall's Tau with human judgments. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Results on WMT12 at the segment-
level: tuning with cross-validation on WMT12. 
Kendall's Tau with human judgments. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Results on WMT11 at the segment-level: 
tuning on the entire WMT12. Kendall's Tau with 
human judgments. 

</table></figure>

			<note place="foot" n="1"> We refer the reader to (Hardmeier, 2012) for an in-depth overview of discourse-related research for MT.</note>

			<note place="foot" n="2"> The discourse parser is freely available from http://alt.qcri.org/tools/</note>

			<note place="foot" n="3"> http://www.statmt.org/wmt{11,12}/results.html</note>

			<note place="foot" n="4"> http://nlp.lsi.upc.edu/asiya/</note>

			<note place="foot" n="5"> A detailed description of every individual metric can be found at (Giménez and M` arquez, 2010b). For a more up-todate description, see the User Manual from ASIYA&apos;s website. 6 In ASIYA the metrics from this family are referred to as &quot;Discourse Representation&quot; metrics. However, the structures they consider are actually very different from the discourse structures exploited in this paper. See the discussion in Section 2. For clarity, we will refer to them as semantic parsing metrics.</note>

			<note place="foot" n="7"> We have fixed a bug in the scoring tool from WMT12, which was making all scores positive. This made TERRORCAT&apos;s score negative, as we present it in Table 3.</note>

			<note place="foot" n="8"> In this work, we have not investigated the reasons behind this phenomenon. We speculate that this might be caused by the fact that the lexical information in DR-LEX is incorporated only in the form of unigram matching at the sentencelevel, while the metrics in group IV are already complex combined metrics, which take into account stronger lexical models. Note, however, that the variations are very small and might not be significant.</note>

			<note place="foot" n="9"> Tuning separately for each language pair yielded slightly lower results.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Logics of Conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Asher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Lascarides</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Findings of the 2011 workshop on statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omar</forename><surname>Zaidan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Workshop on Statistical Machine Translation</title>
		<meeting>the Sixth Workshop on Statistical Machine Translation<address><addrLine>Edinburgh</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-07" />
			<biblScope unit="page" from="22" to="64" />
		</imprint>
	</monogr>
	<note>Scotland</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Findings of the 2012 workshop on statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Workshop on Statistical Machine Translation</title>
		<meeting>the Seventh Workshop on Statistical Machine Translation<address><addrLine>Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-06" />
			<biblScope unit="page" from="10" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Discourse Tagging Reference Manual</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lynn</forename><surname>Carlson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
		<idno>ISI-TR- 545</idno>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
		<respStmt>
			<orgName>University of Southern California Information Sciences Institute</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">How comparable are parallel corpora? measuring the distribution of general vocabulary and connectives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bruno</forename><surname>Cartoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandrine</forename><surname>Zufferey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Popescu-Belis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Workshop on Building and Using Comparable Corpora: Comparable Corpora and the Web</title>
		<meeting>the 4th Workshop on Building and Using Comparable Corpora: Comparable Corpora and the Web<address><addrLine>Portland, Oregon</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-06" />
			<biblScope unit="page" from="78" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Online large-margin training of syntactic and structural translation features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuval</forename><surname>Marton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing (EMNLP&apos;08)</title>
		<meeting>the 2008 Conference on Empirical Methods in Natural Language Processing (EMNLP&apos;08)<address><addrLine>Honolulu, Hawaii, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A hierarchical phrase-based model for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, ACL &apos;05</title>
		<meeting>the 43rd Annual Meeting on Association for Computational Linguistics, ACL &apos;05<address><addrLine>Ann Arbor, Michigan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="263" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Convolution Kernels for Natural Language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nigel</forename><surname>Duffy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems, NIPS&apos;01</title>
		<meeting><address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="625" to="632" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisabet</forename><surname>Comelles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesús</forename><surname>Giménez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lluís</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irene</forename><surname>Castellón</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victoria</forename><surname>Arranz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Document-level automatic mt evaluation based on discourse representations</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR</title>
		<meeting>the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="333" to="338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Meteor 1.3: Automatic metric for reliable optimization and evaluation of machine translation systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Denkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Workshop on Statistical Machine Translation</title>
		<meeting>the Sixth Workshop on Statistical Machine Translation<address><addrLine>Edinburgh</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-07" />
			<biblScope unit="page" from="85" to="91" />
		</imprint>
	</monogr>
	<note>Scotland</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A Novel Discriminative Framework for Sentence-Level Discourse Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shafiq</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Carenini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">T</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning<address><addrLine>Jeju Island, Korea. ACL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="904" to="915" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Combining Intra-and Multi-sentential Rhetorical Parsing for Documentlevel Discourse Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shafiq</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Carenini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">T</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yashar</forename><surname>Mehdad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, ACL &apos;13</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics, ACL &apos;13<address><addrLine>Sofia, Bulgaria. ACL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="486" to="496" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">From Discourse to Logic: Introduction to Model theoretic Semantics of Natural Language, Formal Logic and Discourse Representation Theory. Number 42 in Studies in Linguistics and Philosophy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans</forename><surname>Kamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uwe</forename><surname>Reyle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>Kluwer Academic Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">ROUGE: A Package for Automatic Evaluation of Summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Workshop on Text Summarization Branches Out</title>
		<meeting>Workshop on Text Summarization Branches Out<address><addrLine>Barcelona</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="74" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Syntactic features for evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ding</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization</title>
		<meeting>the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization<address><addrLine>Ann Arbor, Michigan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-06" />
			<biblScope unit="page" from="25" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Fully automatic semantic mt evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Kiu</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anand</forename><forename type="middle">Karthik</forename><surname>Tumuluru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekai</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Workshop on Statistical Machine Translation</title>
		<meeting>the Seventh Workshop on Statistical Machine Translation<address><addrLine>Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-06" />
			<biblScope unit="page" from="243" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Rhetorical Structure Theory: Toward a Functional Theory of Text Organization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandra</forename><surname>Thompson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Text</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="243" to="281" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Machine translation of labeled discourse connectives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Popescu-Belis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Najeh</forename><surname>Hajlaoui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Gesmundo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth Biennial Conference of the Association for Machine Translation in the Americas (AMTA)</title>
		<meeting>the Tenth Biennial Conference of the Association for Machine Translation in the Americas (AMTA)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Disambiguating temporalcontrastive connectives for machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Meyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2011 Student Session</title>
		<meeting>the ACL 2011 Student Session<address><addrLine>Portland, OR, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-06" />
			<biblScope unit="page" from="46" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A Tree Kernel approach to Question and Answer Classification in Question Answering Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Basili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th international conference on Language Resources and Evaluation</title>
		<meeting>the 5th international conference on Language Resources and Evaluation<address><addrLine>Genoa, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Exploiting Syntactic and Shallow Semantic Kernels for Question/Answer Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvia</forename><surname>Quarteroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Basili</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suresh</forename><surname>Manandhar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL-2007</title>
		<meeting>the ACL-2007<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="776" to="783" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">BLEU: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Association for Computational Linguistics (ACL&apos;02)</title>
		<meeting>the Association for Computational Linguistics (ACL&apos;02)<address><addrLine>Philadelphia, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Word error rates: Decomposition over POS classes and applications for error analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maja</forename><surname>Popovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Workshop on Statistical Machine Translation</title>
		<meeting>the Second Workshop on Statistical Machine Translation<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2007-06" />
			<biblScope unit="page" from="48" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Dependency treelet translation: Syntactically informed phrasal smt</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Quirk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arul</forename><surname>Menezes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd</title>
		<meeting>the 43rd</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<title level="m">Annual Meeting on Association for Computational Linguistics, ACL &apos;05</title>
		<meeting><address><addrLine>Ann Arbor, Michigan</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="271" to="279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A study of translation edit rate with targeted human annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Snover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Dorr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linnea</forename><surname>Micciulla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Makhoul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Biennial Conference of the Association for Machine Translation in the Americas, AMTA &apos;06</title>
		<meeting>the 7th Biennial Conference of the Association for Machine Translation in the Americas, AMTA &apos;06<address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Dynamic Conditional Random Fields: Factorized Probabilistic Models for Labeling and Segmenting Sequence Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khashayar</forename><surname>Rohanimanesh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="693" to="723" />
			<date type="published" when="2007" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The tree-to-tree correction problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuo-Chung</forename><surname>Tai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="422" to="433" />
			<date type="published" when="1979-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Online large-margin training for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taro</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hajime</forename><surname>Tsukada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hideki</forename><surname>Isozaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, EMNLP-CoNLL &apos;07</title>
		<meeting>the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, EMNLP-CoNLL &apos;07<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<title level="m">Proceedings of the Workshop on Discourse in Machine Translation. ACL</title>
		<editor>Bonnie Webber, Andrei Popescu-Belis, Katja Markert, and Jörg Tiedemann</editor>
		<meeting>the Workshop on Discourse in Machine Translation. ACL<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">D-LTAG: Extending Lexicalized TAG to Discourse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Webber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="751" to="779" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Extending machine translation evaluation metrics with lexical cohesion to document level</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Billy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyu</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-07" />
			<biblScope unit="page" from="1060" to="1068" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Semantic roles for smt: A hybrid two-pass model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technologies: The</title>
		<meeting>Human Language Technologies: The</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<title level="m">Annual Conference of the North American Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers</title>
		<meeting><address><addrLine>Boulder, Colorado</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="13" to="16" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
