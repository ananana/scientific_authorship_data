<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:42+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Point Process Modelling of Rumour Dynamics in Social Media</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Lukasik</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
							<email>t.cohn@unimelb.edu.au</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computing and Information Systems</orgName>
								<orgName type="institution">The University of Melbourne</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kalina</forename><surname>Bontcheva</surname></persName>
							<email>{m.lukasik, k.bontcheva}@shef.ac.uk</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">The University of Sheffield</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Point Process Modelling of Rumour Dynamics in Social Media</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="518" to="523"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Rumours on social media exhibit complex temporal patterns. This paper develops a model of rumour prevalence using a point process, namely a log-Gaussian Cox process , to infer an underlying continuous temporal probabilistic model of post frequencies. To generalize over different rumours , we present a multi-task learning method parametrized by the text in posts which allows data statistics to be shared between groups of similar rumours. Our experiments demonstrate that our model outperforms several strong baseline methods for rumour frequency prediction evaluated on tweets from the 2014 Ferguson riots.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The ability to model rumour dynamics helps with identifying those, which, if not debunked early, will likely spread very fast. One such example is the false rumour of rioters breaking into McDon- ald's during the 2011 England riots. An effective early warning system of this kind is of interest to government bodies and news outlets, who struggle with monitoring and verifying social media posts during emergencies and social unrests. Another application of modelling rumour dynamics could be to predict the prevalence of a rumour through- out its lifespan, based on occasional spot checks by journalists.</p><p>The challenge comes from the observation that different rumours exhibit different trajectories. <ref type="figure">Figure 1</ref> shows two example rumours from our dataset (see Section 3): online discussion of ru- mour #10 quickly drops away, whereas rumour #37 takes a lot longer to die out. Two charac- teristics can help determine if a rumour will con- tinue to be discussed. One is the dynamics of post occurrences, e.g. if the frequency profile decays quickly, chances are it would not attract further attention. A second factor is text from the posts themselves, where phrases such as not true, un- confirmed, or debunk help users judge veracity and thus limit rumour spread ( <ref type="bibr" target="#b15">Zhao et al., 2015)</ref>. This paper considers the problem of modelling temporal frequency profiles of rumours by taking into account both the temporal and textual infor- mation. Since posts occur at continuous times- tamps, and their density is typically a smooth func- tion of time, we base our model on point pro- cesses, which have been shown to model well such data in epidemiology and conflict mapping <ref type="bibr" target="#b4">(Brix and Diggle, 2001;</ref><ref type="bibr" target="#b14">Zammit-Mangion et al., 2012)</ref>. This framework models count data in a continuous time through the underlying intensity of a Poisson distribution. The posterior distribution can then be used for several inference problems, e.g. to query the expected count of posts, or to find the probability of a count of posts occurring during an arbitrary time interval. We model frequency profiles using a log-Gaussian Cox process <ref type="bibr" target="#b7">(Møller and Syversveen, 1998</ref>), a point process where the log-intensity of the Poisson distribution is mod- elled via a Gaussian Process (GP). GP is a non- parametric model which allows for powerful mod- elling of the underlying intensity function.</p><p>Modelling the frequency profile of a rumour based on posts is extremely challenging, since many rumours consist of only a small number of posts and exhibit complex patterns. To overcome this difficulty we propose a multi-task learning ap- proach, where patterns are correlated across mul- tiple rumours. In this way statistics over a larger training set are shared, enabling more reliable pre- dictions for distant time periods, in which no posts from the target rumour have been observed. We demonstrate how text from observed posts can be used to weight influence across rumours. Using a set of Twitter rumours from the 2014 Ferguson un- rest, we demonstrate that our models provide good  <ref type="table">1  3  5  7  9  11  13  15</ref> LGCP</p><p>LGCPICM LGCPTXT  <ref type="table">1  3  5  7  9  11  13  15  17  LGCP  LGCPICM</ref> LGCPTXT (b) rumour #10</p><p>Figure 1: Predicted frequency profiles for example rumours. Black bars denote training intervals, white bars denote test intervals. Dark-coloured lines correspond to mean predictions by the models, light shaded areas denote the 95% confidence interval, µ ± 2σ. This figure is best viewed in colour.</p><p>prediction of rumour popularity. This paper makes the following contributions: 1. Introduces the problem of modelling rumour frequency profiles, and presents a method based on a log-Gaussian Cox process; 2. Incorporates multi-task learning to generalize across disparate rumours; and 3. Demonstrates how incorporating text into multi-task learning improves results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>There have been several descriptive studies of ru- mours in social media, e.g. <ref type="bibr" target="#b10">Procter et al. (2013)</ref> analyzed rumours in tweets about the 2011 Lon- don riots and showed that they follow similar life- cycles. <ref type="bibr" target="#b6">Friggeri et al. (2014)</ref> showed how Face- book constitutes a rich source of rumours and con- versation threads on the topic. However, none of these studies tried to model rumour dynamics.</p><p>The problem of modelling the temporal nature of social media explicitly has received little at- tention. The work most closely related modelled hash tag frequency time-series in Twitter using GP <ref type="bibr" target="#b9">(Preotiuc-Pietro and Cohn, 2013)</ref>. It made several simplifications, including discretising time and treating the problem of modelling counts as regression, which are both inappropriate. In con- trast we take a more principled approach, using a point process. We use the proposed GP-based method as a baseline to demonstrate the benefit of using our approaches.</p><p>The log-Gaussian Cox process has been applied for disease and conflict mapping, e.g. Zammit- Mangion et al. (2012) developed a spatio-temporal model of conflict events in Afghanistan. In contrast here we deal with temporal text data, and model several correlated outputs rather than their single output. Related also is the extensive work done in spatio-temporal modelling of meme spread. One example is application of Hawkes processes <ref type="bibr" target="#b13">(Yang and Zha, 2013</ref>), a probabilistic framework for modelling self-excitatory phenom- ena. However, these models were mainly used for network modelling rather than revealing complex temporal patterns, which may emerge only implic- itly, and are more limited in the kinds of temporal patterns that may be represented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data &amp; Problem</head><p>In this section we describe the data and we formal- ize the problem of modelling rumour popularity.</p><p>Data We use the Ferguson rumour data set ( <ref type="bibr" target="#b16">Zubiaga et al., 2015</ref>), consisting of tweets collected in August and September 2014 during the Fergu- son unrest. It contains both source tweets and the conversational threads around these (where avail- able). All source tweets are categorized as ru- mour vs non-rumour, other tweets from the same thread are assigned automatically as belonging to the same event as the source tweet. Since some rumours have few posts, we consider only those with at least 15 posts in the first hour as rumours of particular interest. This results in 114 rumours consisting of a total of 4098 tweets.</p><p>Problem Definition Let us consider a time in- terval <ref type="bibr">[0, l]</ref> of length l=2 hours, a set of n rumours</p><formula xml:id="formula_0">R = {E i } n i=1</formula><p>, where rumour E i consists of a set of m i posts</p><formula xml:id="formula_1">E i = {p i j } m i j=1 . Posts are tuples p i j = (x i j , t i j )</formula><p>, where x i j is text (in our case a bag of words text representation) and t i j is a timestamp describing post p i j , measured in time elapsed since the first post on rumour E i .</p><p>Posts occur at different timestamps, yielding varying density of posts over time, which we are interested in estimating. To evaluate the predicted density for a given rumour E i we leave out posts from a set of intervals</p><formula xml:id="formula_2">T te = {[s i k , e i k ]} K i k=1</formula><p>(where s i k and e i k are respectively start and end points of interval k for rumour i) and estimate performance at predicting counts in them by the trained model. The problem is considered in supervised settings, where posts on this rumour out- side of these intervals form the training set</p><formula xml:id="formula_3">E O i = {p i j : t i j ∈ K i k=1 [s i k , e i k ]}. Let the number of elements in E O i be m O i .</formula><p>We also consider a do- main adaptation setting, where additionally posts from other rumours are observed R O i = R\E i . Two instantiations of this problem formulation are considered. The first is interpolation, where the test intervals are not ordered in any particular way. This corresponds to a situation, e.g., when a journalist analyses a rumour during short spot checks, but wants to know the prevalence of the rumour at other times, thus limiting the need for constant attention. The second formulation is that of extrapolation, where all observed posts occur before the test intervals. This corresponds to a scenario where the user seeks to predict the future profile of the rumour, e.g., to identify rumours that will attract further attention or wither away.</p><p>Although our focus here is on rumours, our model is more widely applicable. For example, one could use it to predict whether an advertise- ment campaign would be successful or how a po- litical campaign would proceed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Model</head><p>We consider a log-Gaussian Cox process (LGCP) <ref type="bibr" target="#b7">(Møller and Syversveen, 1998</ref>), a generalization of inhomogeneous Poisson process. In LGCP the intensity function is assumed to be a stochas- tic process which varies over time. In fact, the intensity function λ(t) is modelled using a la- tent function f (t) sampled from a Gaussian pro- cess <ref type="bibr" target="#b11">(Rasmussen and Williams, 2005</ref>), such that λ(t) = exp (f (t)) (exponent ensures positivity). This provides a non-parametric approach to model the intensity function. The intensity function can be automatically learned from the data set and its complexity depends on the data points.</p><p>We model the occurrence of posts in a rumour E i to follow log-Gaussian Cox process (LGCP) with intensity λ i (t), where λ i (t) = exp(f i (t)). We associate a distinct intensity function with each rumour as they have varying temporal pro- files.</p><p>LGCP models the likelihood that a single tweet occurs at time t in the interval [s, t] for a ru- mour E i given the latent function f i (t) as</p><formula xml:id="formula_4">p(y = 1|f i ) = exp(f i (t)) exp(− t s exp(f i (u))du).</formula><p>Then, the likelihood of posts E O i in time interval T given a latent function f i can be obtained as <ref type="bibr" target="#b7">and Syversveen, 1998;</ref><ref type="bibr" target="#b12">Vanhatalo et al., 2013</ref>) to overcome com- putational difficulties arising due to integration. Following this, we approximate the likelihood as</p><formula xml:id="formula_5">p(E O i |f i ) = exp   − T −Tte exp (f i (u)) du + m O i j=1 f i (t i j )   (1)</formula><note type="other">The likelihood of posts in the rumour data is obtained by taking the product of the likelihoods over individual rumours. The likelihood (1) is commonly approximated by considering sub- regions of T and assuming constant intensities in sub-regions of T (Møller</note><formula xml:id="formula_6">p(E O i |f i ) = S s=1 Poisson(y s | l s exp f i ( ˙ t s ) ).</formula><p>Here, time is divided into S intervals indexed by s, ˙ t s is the centre of the s th interval, l s is the length of the s th interval and y s is number of tweets posted during this interval.</p><p>The latent function f is modelled via a Gaussian process (GP) <ref type="bibr" target="#b11">(Rasmussen and Williams, 2005</ref>): f (t) ∼ GP(m(t), k(t, t )), where m is the mean function (equal 0) and k is the kernel specifying how outputs covary as a function of the inputs. We use a Radial Basis Function (RBF) kernel, k(t, t ) = a exp(−(t − t ) 2 /l), where lengthscale l controls the extent to which nearby points influ- ence one another and a controls the scale of the function.</p><p>The distribution of the posterior p(f i (t)|E O i ) at an arbitrary timestamp t is calculated based on the specified prior and the Poisson likelihood. It is intractable and approximation techniques are re- quired. There exist various methods to deal with calculating the posterior; here we use the Laplace approximation, where the posterior is approxi- mated by a Gaussian distribution based on the first 2 moments. For more details about the model and inference we refer the reader to <ref type="bibr" target="#b11">(Rasmussen and Williams, 2005</ref>). The predictive distribution over time t * is obtained using the approximated poste- rior. This predictive distribution is then used to obtain the intensity function value at the point t * :</p><formula xml:id="formula_7">λ i (t * |E O i ) = exp (f i (t)) p f i (t)|E O i df i .</formula><p>The predictive distribution over counts at a par- ticular time interval of length w with a mid-point t * for rumour E i is Poisson distributed with rate wλ i (t * |E O i ).</p><p>Multi-task learning and incorporating text In order to exploit similarities across rumours we propose a multi-task approach where each rumour represents a task. We consider two approaches. First, we employ a multiple output GP based on the Intrinsic Coregionalization Model (ICM) <ref type="bibr">( ´ Alvarez et al., 2012</ref>). It is a method which has been successfully applied to a range of NLP tasks <ref type="bibr" target="#b3">(Beck et al., 2014;</ref><ref type="bibr" target="#b5">Cohn and Specia, 2013)</ref>. ICM parametrizes the kernel by a matrix representing similarities between pairs of tasks. We expect it to find correlations between rumours exhibiting sim- ilar temporal patterns. The kernel takes the form</p><formula xml:id="formula_8">k ICM ((t, i), (t , i )) = k time (t, t )B i,i ,</formula><p>where B is a square coregionalization matrix (rank 1, B = κI + vv T ), i and i denote the tasks of the two inputs, k time is a kernel for comparing inputs t and t (here RBF) and κ is a vector of values modulating the extent of each task independence.</p><p>In a second approach, we parametrize the inter- task similarity measures by incorporating text of the posts. The full multi-task kernel takes form</p><formula xml:id="formula_9">k TXT ((t, i), (t , i )) = k time (t, t ) × k text p i j ∈E O i x i j , p i j ∈E O i x i j .</formula><p>We compare text vectors using cosine similar- ity, k text (x, y) = b + c x T y xy , where the hyper- parameters b &gt; 0 and c &gt; 0 modulate between text similarity and a global constant similarity. We also consider combining both multi-task kernels, yielding k ICM+TXT = k ICM + k TXT .</p><p>Optimization All hyperparameters are opti- mized by maximizing the marginal likelihood of the data L(E O i |θ), where θ = (a, l, κ, v, b, c) or a subset thereof, depending on the choice of kernel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Setup</head><p>Evaluation metric We use mean squared error (MSE) to measure the difference between true counts and predicted counts in the test intervals. Since probabilistic models (GP, LGCP) return dis- tributions over possible outputs, we also evalu- ate them via the log-likelihood (LL) of the true counts under the returned distributions (respec- tively Gaussian and Poisson distribution).</p><p>Baselines We use the following baselines. The first is the Homogenous Poisson Process (HPP) trained on the training set of the rumour. We se- lect its intensity λ using maximum likelihood esti- mate, which equals to the mean frequency of posts in the training intervals. The second baseline is Gaussian Process (GP) used for predicting hash- tag frequencies in Twitter by <ref type="bibr" target="#b9">Preotiuc-Pietro and Cohn (2013)</ref>. Authors considered various kernels in their experiments, most notably periodic ker- nels. In our case it is not apparent that rumours exhibit periodic characteristics, as can be seen in <ref type="figure">Figure 1</ref>. We restrict our focus to RBF kernel and leave inspection of other kernels such as periodic ones for both GP and LGCP models for future. The third baseline is to always predict 0 posts in all intervals. The fourth baseline is tailored for the interpolation setting, and uses simple interpolation by averaging over the frequencies of the closest left and right intervals, or the frequency of the closest interval for test intervals on a boundary.</p><p>Data preprocessing In our experiments, we consider the first two hours of each rumour lifes- pan, which we split into 20 evenly spaced inter- vals. This way, our dataset consists in total of 2280 intervals. We iterate over rumours using a form of folded cross-validation, where in each iteration we exclude some (but not all) time intervals for a single target rumour. The excluded time intervals form the test set: either by selecting half at random (interpolation); or by taking only the second half for testing (extrapolation). To ameliorate the prob- lems of data sparsity, we replace words with their Brown cluster ids, using 1000 clusters acquired on a large scale Twitter corpus ( <ref type="bibr" target="#b8">Owoputi et al., 2013)</ref>.</p><p>The mean function for the underlying GP in LGCP methods is assumed to be 0, which results in intensity function to be around 1 in the absence of nearby observations. This prevents our method from predicting 0 counts in these regions. We add 1 to the counts in the intervals to deal with this problem as a preprocessing step. The original counts can be obtained by decrementing 1 from the predicted counts. Instead, one could use a GP with a non-zero mean function and learn the mean function, a more elegant way of approaching this problem, which we leave for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head><p>The left columns of <ref type="table">Table 1</ref>  proaches. This is due to GP modelling a dis- tribution with continuous support, which is inap- propriate for modelling discrete counts. Chang- ing the model from a GP to a better fitting to the modelling temporal count data LGCP gives a big improvement, even when a point estimate of the prediction is considered (MSE). The 0 baseline is very strong, since many rumours have compara- tively little discussion in the second hour of their lifespan relative to the first hour. Incorporating in- formation about other rumours helps outperform this method. ICM, TXT and ICM+TXT multi- task learning approaches achieve the best scores and significantly outperform all baselines. TXT turns out to be a good approach to multi-task learn- ing and outperforms ICM. In <ref type="figure">Figure 1a</ref> we show an example rumour frequency profile for the ex- trapolation setting. TXT makes a lower error than LGCP and LGCPICM, both of which underesti- mate the counts in the second hour.</p><p>Next, we move to the interpolation setting. Un- surprisingly, Interpolate is the strongest baseline, and outperforms the raw LGCP method. Again, HPP and GP are outperformed by LGCP in terms of both MSE and LL. Considering the output dis- tributions (LL) the difference in performance be- tween the Poisson Process based approaches and GP is especially big, demonstrating how well the principled models handle uncertainty in the pre- dictive distributions. As for the multi-task meth- ods, we notice that text is particularly useful, with TXT achieving the highest MSE score out of all considered models. ICM turns out to be not very helpful in this setting. For example, ICM (just as</p><p>LGCP) does not learn there should be a peak at the beginning of a rumour frequency profile depicted in <ref type="figure">Figure 1b</ref>. TXT manages to make a signifi- cantly smaller error by predicting a large posting frequency there. We also found, that for a few ru- mours ICM made a big error by predicting a high frequency at the start of a rumour lifespan when there was no such peak. We hypothesize ICM per- forms poorly because it is hard to learn correct cor- relations between frequency profiles when training intervals do not form continuous segments of sig- nificant sizes. ICM manages to learn correlations more properly in extrapolation setting, where the first hour is fully observed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>This paper introduced the problem of modelling frequency profiles of rumours in social media. We demonstrated that joint modelling of collec- tive data over multiple rumours using multi-task learning resulted in more accurate models that are able to recognise and predict commonly occurring temporal patterns. We showed how text data from social media posts added important information about similarities between different rumours. Our method is generalizable to problems other than modelling rumour popularity, such as predicting success of advertisement campaigns.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>report the results for the extrapolation experiments, showing the mean and variance of results across the 114 ru- mours. According to log likelihood evaluation metric, GP is the worst from the probabilistic ap-</figDesc><table>Extrapolation 

Interpolation 
MSE 
LL 
MSE 
LL 

HPP 
7.14±10.1 
-23.5±10.1 
7.66±7.55 -25.8±11.0 
GP 
4.58±11.0 
-34.6±8.78 
6.13±6.57 -90.1±198 
Interpolate 
4.90±13.1 
-
5.29±6.06 
-
0 
2.76±7.81 
-
7.65±11.0 
-

LGCP 
3.44±9.99 
-15.8±11.6 † 6.01±6.29 -21.0±8.77 † 
LGCP ICM 
2.46±7.82 † -14.8±11.2 † 8.59±19.9 -20.7±9.87 † 
LGCP TXT 
2.32±7.06 † 
-14.7±9.12 † 
3.66±5.67 † -16.9±5.91 † 
LGCP ICM+TXT 2.31±7.80 † 
-14.6±10.8 † 
3.92±5.20 † -16.8±5.34 † 

Table 1: MSE between the true counts and the predicted counts (lower is better) and predictive log likelihood of the true 
counts from probabilistic models (higher is better) for test intervals over the 114 Ferguson rumours for extrapolation (left) and 
interpolation (right) settings, showing mean ± std. dev. Baselines are shown above the line, with LGCP models below. Key: 
 † denotes significantly better than the best baseline; denotes significantly worse than LGCP TXT, according to one-sided 
Wilcoxon signed rank test p &lt; 0.05. 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Acknowledgments</head><p>We would like to thank Srijith P. K. for helpful comments. This work was funded by the PHEME FP7 project (grant No. 611233) and partially sup-ported by the Australian Research Council.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mauricio</forename><forename type="middle">A</forename><surname>Alvarez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Rosasco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><forename type="middle">D</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Kernels for vector-valued functions: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lawrence</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Found. Trends Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="195" to="266" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The GPy authors</title>
		<ptr target="http://github.com/SheffieldML/GPy" />
	</analytic>
	<monogr>
		<title level="m">GPy: A Gaussian process framework in Python</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Joint emotion analysis via multi-task Gaussian processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;14</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;14</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1798" to="1803" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Spatiotemporal prediction for log-gaussian cox processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Brix</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Diggle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society Series B</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="823" to="841" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Modelling annotator bias with multi-task Gaussian processes: An application to machine translation quality estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">51st Annual Meeting of the Association for Computational Linguistics, ACL &apos;13</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="32" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Rumor cascades</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrien</forename><surname>Friggeri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lada</forename><surname>Adamic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dean</forename><surname>Eckles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International AAAI Conference on Weblogs and Social Media</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Log Gaussian Cox processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesper</forename><surname>Møller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anne</forename><forename type="middle">Randi</forename><surname>Syversveen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scandinavian Journal of Statistics</title>
		<imprint>
			<biblScope unit="page" from="451" to="482" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Improved part-of-speech tagging for online conversational text with word clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olutobi</forename><surname>Owoputi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="380" to="390" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A temporal model of text periodicities using Gaussian processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Preotiuc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Pietro</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;13</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;13</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="977" to="988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Reading the riots: What were the police doing on twitter? Policing and society</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Procter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Crump</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susanne</forename><surname>Karstedt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><surname>Cantijoch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="413" to="436" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Gaussian Processes for Machine Learning (Adaptive Computation and Machine Learning)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><forename type="middle">Edward</forename><surname>Rasmussen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">K I</forename><surname>Williams</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Gpstuff: Bayesian modeling with Gaussian processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jarno</forename><surname>Vanhatalo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaakko</forename><surname>Riihimäki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jouni</forename><surname>Hartikainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pasi</forename><surname>Jylänki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ville</forename><surname>Tolvanen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aki</forename><surname>Vehtari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1175" to="1179" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Mixture of mutually exciting processes for viral diffusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Shuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Point process modelling of the Afghan War Diary</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zammit-Mangion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Dewar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Visakan</forename><surname>Kadirkamanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guido</forename><surname>Sanguinetti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences of the United States of America</title>
		<meeting>the National Academy of Sciences of the United States of America</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="page" from="12414" to="12419" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Early detection of rumors in social media from enquiry posts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Resnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaozhu</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International World Wide Web Conference Committee (IW3C2)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Towards detecting rumours in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arkaitz</forename><surname>Zubiaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Liakata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Procter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kalina</forename><surname>Bontcheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Tolmie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Workshop on AI for Cities</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
