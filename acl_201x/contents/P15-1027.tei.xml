<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:09+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Hubness and Pollution: Delving into Cross-Space Mapping for Zero-Shot Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 26-31, 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angeliki</forename><surname>Lazaridou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Mind/Brain Sciences</orgName>
								<orgName type="institution">University of Trento</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgiana</forename><surname>Dinu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Mind/Brain Sciences</orgName>
								<orgName type="institution">University of Trento</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Mind/Brain Sciences</orgName>
								<orgName type="institution">University of Trento</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Hubness and Pollution: Delving into Cross-Space Mapping for Zero-Shot Learning</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="270" to="280"/>
							<date type="published">July 26-31, 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Zero-shot methods in language, vision and other domains rely on a cross-space mapping function that projects vectors from the relevant feature space (e.g., visual-feature-based image representations) to a large semantic word space (induced in an unsupervised way from corpus data), where the entities of interest (e.g., objects images depict) are labeled with the words associated to the nearest neighbours of the mapped vectors. Zero-shot cross-space mapping methods hold great promise as a way to scale up annotation tasks well beyond the labels in the training data (e.g., recognizing objects that were never seen in training). However, the current performance of cross-space mapping functions is still quite low, so that the strategy is not yet usable in practical applications. In this paper, we explore some general properties, both theoretical and empirical, of the cross-space mapping function, and we build on them to propose better methods to estimate it. In this way, we attain large improvements over the state of the art, both in cross-linguistic (word translation) and cross-modal (image labeling) zero-shot experiments.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In many supervised problems, the parameters of a classification function are estimated on (x, y) pairs, where x is a vector representing a training instance in some feature space, and y is the label assigned to the instance. For example, in image labeling x contains visual features extracted from a picture and y is the name of the object depicted in the picture ( <ref type="bibr" target="#b10">Grauman and Leibe, 2011</ref>). Since each label is treated as an unanalyzed primitive, this approach requires ad-hoc annotation for each label of interest, and it will not scale up to chal- lenges where the potential label set is vast (for ex- ample, bilingual dictionary induction, where the label set corresponds to the full vocabulary of the target language).</p><p>Zero-shot methods ( <ref type="bibr" target="#b19">Palatucci et al., 2009</ref>) ad- dress the scalability problem by building on the observation that the labels of interest are often words (or longer linguistic expressions), which stand in a semantic similarity relation to each other. Moreover, distributional approaches allow us to estimate very large semantic word spaces in an efficient and unsupervised manner, using just unannotated text corpora as input <ref type="bibr" target="#b29">(Turney and Pantel, 2010)</ref>. Extensive evidence has shown that the similarity estimates obtained by representing words as vectors in such corpus-induced seman- tic spaces are extremely accurate ( ). Under the assumption that the domain of interest (e.g., objects in pictures, words in a source language) exhibits comparable similarity structure to that manifested in language, we can rephrase the learning task, from inducing multiple functions from the source feature space onto independent atomic labels, to that of estimating a single cross- space mapping function from vectors in the source feature space onto vectors for the corresponding word labels in distributional semantic space. The induced function can then also be applied to a data-point whose label was not used for training. The word corresponding to the nearest neighbour of the mapped vector in the latter space is used as the label of the data point. Zero-shot learn- ing using distributional semantic spaces was origi- nally proposed for brain signal decoding ( <ref type="bibr" target="#b17">Mitchell et al., 2008)</ref>, but it has since been extensively ap- plied in other domains, including image labeling ( <ref type="bibr" target="#b8">Frome et al., 2013;</ref><ref type="bibr" target="#b13">Lazaridou et al., 2014;</ref><ref type="bibr" target="#b24">Socher et al., 2013)</ref> and bilingual dictionary/phrase table induction ( <ref type="bibr" target="#b15">Mikolov et al., 2013a</ref>), the two applications we focus on here.</p><p>Effective zero-shot learning by cross-space mapping could get us through the manual anno- tation bottleneck that hampers many applications. However, in practice, the accuracy in label re- trieval with current mapping methods is still too low for practical uses. In image labeling, when a search space of realistic size is considered, ac- curacy is just above 1% (which is still well above chance for large search spaces). In bilingual lex- icon induction, accuracy reaches values around 30% (across words of varying frequency), which are definitely more encouraging, but still indicate that only 1 word in 3 will be translated correctly.</p><p>In this article, we look at some general prop- erties of the linear cross-modal mapping function standardly used for zero-shot learning, in order to achieve a better understanding of its shortcom- ings, and improve its quality by devising meth- ods to overcome them. First, when the mapping function is estimated with least-squares error tech- niques, we observe a systematic increase in hub- ness <ref type="bibr" target="#b21">(Radovanovi´cRadovanovi´c et al., 2010b)</ref>, that is, in the tendency of some vectors ("hubs") to appear in the top neighbour lists of many test items. We connect hubness to least-squares estimation, and we show how it is greatly mitigated when the mapping func- tion is estimated with a max-margin ranking loss instead. Still, switching to max-margin greatly improves accuracy in the cross-linguistic context, but not for vision-to-language mapping. In the cross-modal setting, we observe indeed a differ- ent problem, that we name (training instance) pol- lution: The neighbourhoods of mapped test items are "polluted" by the target vectors used in train- ing. This suggests that cross-modal mapping suffers from overfitting issues, and consequently from poor generalization power. Taking inspi- ration from domain adaptation, which addresses similar generalization concerns, and self-learning, we propose a technique to augment the training data with automatically constructed examples that force the function to generalize better. Having shown the advantages of a ranking loss, our fi- nal contribution is the adaptation of some insights from the max-margin literature to our setting, in particular concerning the choice of negative ex- amples. This leads to further accuracy improve- ments. We thus conclude the paper by reporting zero-shot performances in both cross-modal and cross-language settings that are well above the cur- cross-linguistic cross-modal former state of art 33.0 0.5 standard mapping 29.7 1.1 max-margin - §3</p><p>39.4</p><p>1.9 data augmentation - §4 NA 3.7 negative evidence - §5</p><p>40.2 5.6 <ref type="table">Table 1</ref>: Roadmap. Proposed changes to cross- space mapping training and resulting percentage Precision @1 in our two experimental setups.</p><p>rent state of the art. <ref type="table">Table 1</ref> provides a roadmap and summary of our results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Experimental Setup</head><p>Cross-linguistic experiments In the cross- linguistic experiments, we learn a mapping from the semantic space of language A to the semantic space of language B, which can then be used for translating words outside the training set. Specifi- cally, given the vector representation of a word in language A, we apply the mapping to obtain an estimate of the vector representation of its mean- ing in language B, returning the nearest neigh- bour of the mapped vector in the B space as can- didate translation. We focus on translating from English to Italian and adopt the setup (word vec- tors, training and test data) of <ref type="bibr" target="#b5">Dinu et al. (2015)</ref>. For a set of 200K words, 300-dimensional vectors were built using the word2vec toolkit, 1 choosing the CBOW method. 2 CBOW, which learns to pre- dict a target word from the ones surrounding it, produces state-of-the-art results in many linguis- tic tasks ( ). The word vectors were induced from corpora of 2.8 and 1.6 billion tokens, respectively, for English and Italian. <ref type="bibr">3</ref> The train and test English-to-Italian translation pairs were extracted from a Europarl-derived dictionary (Tiedemann, 2012). <ref type="bibr">4</ref> The 5K most frequent trans- lation pairs were used for training, while the test set includes 1.5K English words equally split into 5 frequency bins. The search for the correct trans- lation is performed in a semantic space of 200K</p><p>Italian words. 5</p><p>Cross-modal experiments In the cross-modal experiments, we induce a mapping from visual to linguistic space. Specifically, given an image, we apply the mapping to its visual vector repre- sentation to obtain an estimate of its representa- tion in linguistic space, where the word associated to the nearest neighbour is retrieved as the image label. Similarly to translation pairs in the cross- linguistic setup, we create a list of "visual transla- tion" pairs between images and their correspond- ing noun labels. Our starting point are the 5.1K labels in ImageNet ( <ref type="bibr" target="#b3">Deng et al., 2009</ref>) that oc- cur at least 500 times in our English corpus and have concreteness score ≥5, according to <ref type="bibr" target="#b30">Turney et al. (2011)</ref>. For each label, we sample 100 pic- tures from its ImageNet entry, and associate each picture with the 4094-dimensional layer (fc7) at the top of the pre-trained convolutional neural net- work model of <ref type="bibr" target="#b12">Krizhevsky et al. (2012)</ref>, using the Caffe toolkit ( <ref type="bibr" target="#b11">Jia et al., 2014</ref>). The target word space is identical to the English space used in the cross-linguistic experiment. Finally, we use 75% of the labels (and the respective images) for train- ing and the remaining 25% of the labels for test- ing. <ref type="bibr">6</ref> From the 127.5K images corresponding to test labels, we sample 1K images as our test set. For zero-shot evaluation purposes, the search for the correct label is performed in the space of 5.1K possible labels, unless otherwise specified. How- ever, when quantifying hubness and pollution, in order to have a setting comparable to that of cross- language mapping, we use the full set of 200K En- glish words as search space.</p><p>Learning objectives We assume that we have cross-space "translation" pairs available for a set of |T r| items (</p><formula xml:id="formula_0">x i , y i ) = {x i ∈ R d1 , y i ∈ R d2 }.</formula><p>Moreover, following previous work, we assume that the mapping function is linear. For estimat- ing its parameters W ∈ R d1×d2 , we consider two objectives. The first is L2-penalized least squares <ref type="bibr">5</ref> Faithful to the zero-shot setup, in our experiments there is never any overlap between train and test words; however, to make the task more challenging, we include the train words in the search space, except where expressly indicated. <ref type="bibr">6</ref> At training time, we average the 100 vectors associated to a label into a single representation, to reduce training set size while minimizing information loss. At test time, as nor- mally done, we present the model with single image visual vectors.</p><p>(ridge):</p><formula xml:id="formula_1">ˆ W = argmin W∈R d1×d2 XW − Y + λW,</formula><p>which has an analytical solution.</p><p>The second objective is a margin-based rank- ing loss (max-margin) similar in spirit to the one used in similar cross-modal experiments with WS- ABIE (Weston et al., 2011) and DeViSE ( <ref type="bibr" target="#b8">Frome et al., 2013)</ref>. The loss for a given pair of train- ing items (x i , y i ) and the corresponding mapping- based predictionˆypredictionˆ predictionˆy i = Wx i is defined as</p><formula xml:id="formula_2">k j =i max{0, γ + dist(ˆ y i , y i ) − dist(ˆ y i , y j )},</formula><p>where dist is a distance measure, in our case the inverse cosine, and γ and k are tunable hyperpa- rameters denoting the margin and the number of negative examples, respectively. Intuitively, the goal of the max-margin objective is to rank the correct translation y i of x i higher than any other possible translation y j . In theory, the summation in the equation could range over all possible la- bels, but in practice this is too expensive (e.g., in the cross-linguistic experiments the search space contains 200K candidate labels!), and it is usually computed over just a portion of the label space. In <ref type="bibr" target="#b31">Weston et al. (2011)</ref>, the authors propose an efficient way of selecting negative examples, in which they randomly sample, for each training item, labels from the complete set, and pick as negative sample the first label violating the mar- gin. This guarantees that there will be exactly as many weight updates as training items. Another possibility is proposed in <ref type="bibr" target="#b16">Mikolov et al. (2013b)</ref>, where negative samples are picked from a non- item specific distribution (e.g., the uniform distri- bution). <ref type="bibr">7</ref> For the experiments in Sections 3 and 4, we follow a more general setup in which the size of the margin and number of negative sam- ples is tuned for each task. In this way, for a sufficiently large margin and number of negative samples, we increase the probability of perform- ing a weight update per training item. We estimate the mapping parameters W with stochastic gradi- ent descent and per-parameter learning rates tuned with Adagrad ( <ref type="bibr" target="#b7">Duchi et al., 2011</ref>). The tuning of hyperparameters γ and k is performed on a ran- dom 25% subset of the training data.   ridge max−margin gold <ref type="figure">Figure 1</ref>: Hubness distribution in cross-linguistic (left) and cross-modal (right) search spaces. The hubness score <ref type="bibr">(N 20</ref> ) is computed on the top-20 neighbour lists of the test items, using their original (gold), ridge-or max-margin-mapped vectors as query terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Hubness</head><p>High-dimensional spaces are often affected by hubness <ref type="bibr" target="#b21">(Radovanovi´cRadovanovi´c et al., 2010b;</ref><ref type="bibr" target="#b20">Radovanovi´cRadovanovi´c et al., 2010a)</ref>, that is, they contain certain ele- ments -hubs -that are near many other points in space without being similar to the latter in any meaningful way. As recently noted by <ref type="bibr" target="#b5">Dinu et al. (2015)</ref>, the hubness problem is greatly exacer- bated when one looks at the nearest neighbours of vectors that have been mapped across spaces with ridge. 8 Given a set of query vectors with the cor- responding top-k nearest neighbour lists, we can quantify the degree of hubness of an item in the search space (parameterized by k) by the number of lists in which it occurs. N k (y), the hubness at k of an item y, is computed as follows:</p><formula xml:id="formula_3">N k (y) = |{x ∈ T|y ∈ NN k (x, S)}|,</formula><p>where S denotes the search space, T denotes the set of query items and NN k (x, S) denotes the k nearest neighbors of x in S. <ref type="figure">Figure 1</ref> reports N 20 distributions across the cross-linguistic and cross-modal search spaces, using the respective test items as query vectors. The blue line shows the distributions for the "gold" vectors (that is, the vectors in the target space we would like to approximate). The red line shows the same distributions when neighbours are 8 <ref type="bibr" target="#b5">Dinu et al. (2015)</ref> observe, but do not attempt to under- stand hubness, as we do here. They propose to address it with methods to re-rank neighbour lists, which are less general and should be largely complementary to our effort to improve es- timation of the cross-mapping function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cross-linguistic</head><p>Cross-modal blockmonthon <ref type="formula">(50)</ref> smilodon <ref type="formula">(40)</ref> hashim <ref type="formula">(28)</ref> pintle <ref type="formula">(33)</ref> akayev <ref type="formula">(27)</ref> knurled <ref type="formula">(27)</ref> autogiustificazione <ref type="formula">(27)</ref> handwheel <ref type="formula">(24)</ref> limassol <ref type="formula">(26)</ref> circlip <ref type="formula">(23)</ref> regulars <ref type="formula">(26)</ref> black-footed <ref type="formula">(23)  18 (25)</ref> flatbread <ref type="formula">(22)</ref> Table 2: Top ridge hubs, together with N 20 scores. Note that cross-linguistic hubs are sup- posed to be Italian words.</p><p>queried for the ridge-mapped test vectors (ignore black lines for now). In both spaces, when the query vectors are mapped, hubness increases dra- matically. The largest hubs for the original test items occur in 15 neighbour lists or less. With the mapped vectors, we find hubs occurring in 40 lists or more. The figure also shows that, in both spaces, we observe more points with smaller but non-negligible N 20 (e.g., around 10) when mapped vectors are queried. In both spaces, the difference in hubness is very significant according to a cross-tab test (p&lt;10 −30 ). Finally, as <ref type="table">Table 2</ref> shows, the largest hubs are by no means terms that we might expect to occur as neighbours of many other items on semantic grounds (e.g., very gen- eral terms), but rather very specific and rare words whose high hubness cannot possibly be a genuine semantic property.</p><p>Causes of hubness Why should the mapping function lead to an increase in hubness? We con- jecture that this is due to an intrinsic property of least-squares estimation. Given the training ma-trices X and Y, and the projection matrix W ob- tained by minimizing squared error, each columnˆy columnˆ columnˆy * ,i ofˆYofˆ ofˆY = XW is the orthogonal projection of y * ,i , the corresponding Y column onto the col- umn space of X (Strang, 2003, Ch. 4). Conse- quently,</p><formula xml:id="formula_4">y * ,i = i + ˆ y * ,i ,</formula><note type="other">where the i error vector is orthogonal tô y * ,i . It follows that ||y * ,i || 2 ≥= ||ˆy||ˆy * ,i || 2 . Since y * ,i andˆyandˆ andˆy * ,i have equal means (be- cause the error terms in i must sum to 0), it imme- diately follows from the squared length inequality thatˆythatˆ thatˆy * ,i has lower or equal variance to y * ,i . Since this holds for all columns ofˆYofˆ ofˆY, it follows in turn that the set of mapped vectors inˆYinˆ inˆY has lower or equal variance to the corresponding set of origi- nal vectors in Y. Coming back to hubness, a set of lower variance points (such as the mapped vec- tors) will result in higher hubness since the points will on average be closer to each other. The prob- lem is likely to be further exacerbated by the prop- erty of least-squares to ignore relative distances between points (the objective only aims at mak- ing predicted and observed vectors look like each other),</note><p>Strictly, the theoretical result only holds for the training points. However, to the extent that the training set is representative of what will be en- countered in the test set, it should also extend to test data (and if training and testing data are very different, the mapping function will gener- alize very poorly anyway). Moreover, the result holds for a pure least-squares solution, without the ridge L2 regularization term. Whether it also ap- plies to ridge-based estimates will depend on the relative impact of the least-squares and L2 terms on the final solution (and it is not excluded that the L2 term might also independently reduce vari- ance, of course). Empirically, we find that, in- deed, lower variance also characterizes test vectors mapped with a ridge-estimated function.</p><p>Interestingly, in the literature on cross-space mapping we find that authors choose a different cost function than ridge, without motivating the choice. <ref type="bibr" target="#b25">Socher et al. (2014)</ref> mention in pass- ing that max-margin outperforms a least-squared- error cost for cross-modal mapping.</p><p>Max-margin as a solution to hubness Re- ferring back to <ref type="figure">Figure 1</ref>, we see that when ridge estimation is replaced by max-margin (black line), there is a considerable decrease in hub- ness in both settings. This is directly reflected in a large increase in performance in our cross- linguistic (English-to-Italian) zero-shot task (left two columns of <ref type="table" target="#tab_2">Table 3)</ref>, with the largest im- provement for the all important P@1 measure (equivalent to accuracy). <ref type="bibr">9</ref> These results are well above the current best cross-language accuracy for cross-modal mapping without added orthographic cues (33%), attained by <ref type="bibr" target="#b15">Mikolov et al. (2013a)</ref>. <ref type="bibr">10</ref> The absolute performance figures are low in the challenging cross-modal setting, but here too we observe a considerable improvement in accuracy when max-margin is applied. Indeed, we are al- ready above the cross-modal zero-shot mapping state of the art for a search space of similar size (0.5% accuracy in <ref type="bibr" target="#b8">Frome et al. (2013)</ref>). Still, the improvement over ridge (while present) is not as large for the less strict (higher ranks) performance scores. <ref type="table" target="#tab_3">Table 4</ref> confirms that the improvement brought about by max-margin is indeed (at least partially) due to hubness reduction. A large proportion of vectors retrieved as top-1 predictions (trans- lations/labels) are hubs when mapping is trained with ridge, but the proportion drops dramatically with max-margin. Still, more than 1/5 top predic- tions for cross-modal mapping with max-margin are hubs (vs. less than 1/10 for the original vec- tors). Now, the mathematical properties we re- viewed above suggest that, for least-squares es- timation, hubness is caused by general reduced variance of the space after mapping. Thus, hubs should be vectors that are near the mean of the space. The first row of <ref type="table">Table 5</ref> confirms that the hubs found in the neighbourhoods of ridge- mapped query terms are items that tend to be closer to the search space mean vector, and that this effect is radically reduced with max-margin estimation. However, the second row of the table shows another factor at play, that has a major role in the cross-modal setting, and it is only partially addressed by max-margin estimation: Namely, in vision-to-language mapping, there is a strong ten- dency for hubs (that, recall, have an important ef- fect on performance, as they enter many nearest neighbour lists) to be close to a training data point.     <ref type="table">Table 5</ref>: Properties of hubs. Spearman ρ of N 20 scores with cosines to mean vector of full search space (top) and nearest training item (bot- tom), across all search space elements. All corre- lations significant (p&lt;0.001) except cross-modal max-margin hubness/full-space mean.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Pollution</head><p>The quantitative results and post-hoc analysis of hubs in Section 3 suggest that cross-modal map- ping is facing a serious generalization problem. To get a better grasp of the phenomenon, we define a binary measure of (training data) pollution for a queried item x and parameterized by k, such that pollution is 1 if x has a (target) training item y among its k nearest neighbours, 0 otherwise. For- mally:</p><formula xml:id="formula_5">N pol k,S (x) = [[∃y ∈ Y T r : y ∈ NN k,S (x)]],</formula><p>where Y T r is the matrix of target vectors used in training, NN k,S (y) denotes the top k neighbors of y in search space S, and <ref type="bibr">[[z]</ref>] is an indicator func- tion. 11 <ref type="bibr">11</ref> Pollution is of course an effect of overfitting, but we use this more specific term to refer to the tendency of training vectors to "pollute" nearest neighbour lists of mapped vec- tors.</p><p>The average pollution N pol 1,S of all test items in the cross-modal experiment, when |S|=200K is 18%, which indicates that in 1/5 of cases the re- turned label is that of a training point. The equiv- alent statistic in the cross-linguistic experiment drops to 8.7% (words tend to be more varied than the set of concrete, imageable concepts used for image annotation tasks, and so the cross-linguistic training set is probably less uniform than the one used in the vision-to-language setting).</p><p>The real extent of the generalization problem in the cross-modal setup becomes more obvious if we restrict the search space to labels effectively associated to an image in our data set (|S|=5.1K). In this case, the average pollution N pol 1,S across all test items jumps to 88%, that is, the vast major- ity of test images are annotated with a label com- ing from the training data. Clearly, there is a seri- ous problem of overfitting to the training subspace. While we came to this observation by inspecting the properties of hubs, other work in zero-shot for image labeling has indirectly noted the same. <ref type="bibr" target="#b8">Frome et al. (2013)</ref> empirically showed that the performance of the system is higher when remov- ing training labels from the search space, while <ref type="bibr" target="#b18">Norouzi et al. (2014)</ref> proposed a zero-shot method that avoids explicit cross-modal mapping.</p><p>Adapting to the full search space by data augmentation High training-data pollution in- dicates that cross-modal mapping does not gener- alize well beyond the kind of data points it encoun- tered in learning. This is a special case of the data- set bias problem ( <ref type="bibr" target="#b28">Torralba and Efros, 2011</ref>) and, given that the latter has been addressed as a do- main adaptation problem ( <ref type="bibr" target="#b9">Gong et al., 2012;</ref><ref type="bibr" target="#b6">Donahue et al., 2013)</ref>, we adopt here a similar view. Self-training has been successfully used for do- main adaptation in NLP, e.g., in syntactic parsing. Given the limited amount of syntactically anno- tated data coming from monotonous sources (e.g., the Wall Street Journal), parsers show a big drop in performance when applied to different domains (e.g., reviews), since training and test domains dif- fer dramatically, thus affecting their generalization performance. In a nutshell, the idea behind self- training ( <ref type="bibr" target="#b14">McClosky et al., 2006;</ref><ref type="bibr" target="#b22">Reichart and Rappoport, 2007</ref>  <ref type="table">Table 6</ref>: Visual chimeras for dolphin, tarantula and highland.</p><p>with a combination of "clean" data from domain A and "noisy" data from domain B.</p><p>In our setup, self-training would be applied by labeling a larger set of images with a cross-modal mapping function estimated on the initial train- ing data, and then using both sources of labeled data to retrain the function. Although the idea of self-training for inducing cross-modal map- ping functions is appealing, especially given the vast amount of unlabeled data available out there, the very low performance of current cross-modal mapping functions makes the effort questionable. We would like to exploit unannotated data repre- sentative of the search space, without relying on the output of cross-modal mapping for their an- notation. One way to achieve this is to use data augmentation techniques that are representative of the search space. Data augmentation is popular in computer vision, where it is performed (among others) by data jittering, visual sampling or image perturbations. It has proven beneficial for both "deep" ( <ref type="bibr" target="#b12">Krizhevsky et al., 2012;</ref><ref type="bibr" target="#b32">Zeiler and Fergus, 2014</ref>) and "shallow" ( <ref type="bibr" target="#b1">Chatfield et al., 2014</ref>) systems, and it was recently introduced to NLP tasks ( <ref type="bibr" target="#b33">Zhang and LeCun, 2015)</ref>.</p><p>Specifically, in order to train the mapping func- tion using both annotated data and points that are representative of the full search space, we rely on a form of data augmentation that we call visual chimera creation. For every item y i / ∈ Y T r in the search space S, we use linguistic similarity as a proxy of visual similarity, and create its visual vec- torˆxtorˆ torˆx i by averaging the visual vectors correspond- ing to the nearest words in language space that do occur as labels in the training set. <ref type="table">Table 6</ref> presents some examples of visual chimeras. For y i =dol- phin, the visual vectors of other cetacean mam- none chimera-5 chimera-10 P@1</p><p>1.9 3.7 3.2 P@5</p><p>5.4 10.9 10.5 P@10 9.0 15.8 15.9 <ref type="table">Table 7</ref>: Cross-modal zero-shot experiment with data augmentation. Labeling precision @N with no data augmentation (none) and when us- ing top 5 (chimera-5) and top 10 (chimera-10) near- est neighbors from training set of each item in the search space to build the corresponding chimeras (1K test items, 5.1K search space).</p><p>mals are averaged to create the chimerâ x i . Since linguistic similarity is not always determined by visual factors, the method also produces noisy data points. For y i =tarantula, opossums enter the pic- ture, while for y i =highland images of "topically" similar concepts are used (e.g., bagpipe). <ref type="table">Table 7</ref> reports cross-modal zero-shot labeling when training with max-margin and data augmen- tation. We experiment with visual chimeras con- structed using 5 vs. 10 nearest neighbours. While the examples above suggest that the process injects some noise in the training data, we also observe a decrease of pollution N pol 1,S from 88% when using the "clean" training data, to 71% and 73% when expanding them with chimeras (for chimera-5 and chimera-10, respectively). Reflecting this drop in pollution, we see large improvements in precision at all levels, when chimeras are used (no big dif- ferences between 5 or 10 neighbours).</p><p>The improvements brought about by the chimera method are robust. First, <ref type="table" target="#tab_6">Table 8</ref> reports performance when the search space excludes the training labels, showing that data augmentation is beneficial beyond mitigating the bias in favor of the latter. In this setup, chimera-5 is clearly out- performing chimera-10 (longer neighbour lists will include more noise), and we focus on it from here on.</p><p>All experiments up to here follow the stan- dard cross-modal zero-shot protocol, in which the search space is given by the union of the test and training labels, or a subset thereof. Next, we make the task more challenging by increasing it with 1K extra elements acting as distractors. The distrac- tors are either randomly sampled from our usual 200K English word space, or, in the most chal- lenging scenario, picked among those words, in the same space, that are among the top-5 near-none chimera-5 chimera-10</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>P@1</head><p>6   <ref type="table">Table 9</ref>: Cross-modal zero-shot experiment with data augmentation, enlarged search space.</p><p>Labeling precision @N with no data augmenta- tion (none) and when using top 5 (chimera-5) near- est neighbors from training set of each item in the search space to build the corresponding chimeras. est neighbours of a training element. Again, we create one visual chimera for each label in the search space. Results are presented in <ref type="table">Table 9</ref>.</p><p>As expected, performance is negatively affected with both plain and data-augmented models, but the latter is still better in absolute terms. While chimera-5 undergoes a larger drop when the search contains many elements similar to the training data ("related" column), which is explained by the fact that visual chimeras will often include the distrac- tor items of this setup, it appears to be more resis- tant against random labels, which in many cases are words that bear no resemblance to the training data (e.g., naushad, yamato, 13-14). The picture when using no data augmentation is exactly the opposite, with the model being more harmed, at P@1, by the random labels. Finally, <ref type="table">Table 10</ref> presents results in the cross- linguistic setup, when applying the same data aug- mentation technique. In this case, we augment the 5K training elements with 11.5K chimeras, for the 1.5K test elements and 10K randomly sam- pled distractors. For these 11.5K elements, we as- sociate their Italian (target space) label y i with a none chimera-5</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>P@1</head><p>38.4 31.1 P@5 54.2 46.1 P@10 60.4</p><p>51.3 <ref type="table">Table 10</ref>: Cross-linguistic zero-shot experiment with data augmentation. Translation precision @N when learning with max-margin and no data augmentation (none) or data augmentation using the top 5 (chimera-5) nearest neighbors of 11.5K items in the 200K-word search space (1.5K test items).  <ref type="table">Table 10</ref>, show that in this case our data augmentation method is ac- tually hampering performance. We saw that pol- lution affects the cross-linguistic setup much less than it affects the cross-modal one, and we con- jecture that, consequently, in the translation task, there is not a large-enough generalization gain to make up for the extra noise introduced by augmen- tation.  a first step towards engineering the negative evi- dence exploited by this method, in the context of inducing cross-space mapping functions. In par- ticular, our idea is that, given a training instance x i , an informative negative example would be near the mapped vectorˆyvectorˆ vectorˆy i , but far from the actual gold target space vector y i . Intuitively, such "intruders" correspond to cases where the mapping function is getting the predictions seriously wrong, and thus they should be very informative in "correcting" the function mapping trajectories. This can seen as a vector-space interpretation of the max-loss update protocol ( <ref type="bibr" target="#b2">Crammer et al., 2006</ref>) that picks nega- tive samples expected to harm performance more. <ref type="figure" target="#fig_4">Figure 2</ref> illustrates the idea with a cartoon exam- ple. If cat is the gold target vector y i andˆyandˆ andˆy i the corresponding mapped vector, then we are going to pick truck as negative example, since it is an in- truder (near the mapped vector, far from the gold one).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Picking informative negative examples</head><p>More formally, at each step of stochastic gra- dient descent, given a source space vector x i , its target gold label/translation y i in Y T r and the mapped vectorˆyvectorˆ vectorˆy i , we compute s j = cos( ˆ y i , y j ) − cos(y i , y j ), for all vectors y j in Y T r s.t. j = i, and pick as negative example for x i the vector with the largest s j . <ref type="table" target="#tab_8">Table 11</ref> presents zero-shot mapping results when intruding negative examples are used for max-margin estimation. For cross-modal map- ping, we apply data augmentation as described in the previous section. While the absolute perfor- mance increase is relatively small (less than 2% in both setups), it is consistent. Furthermore, the pro- posed protocol results in lower N pol 1,S pollution in the cross-modal setup (from 71% to 63%). Finally, we observe that the learning behaviour of the two protocols (intruders vs. random) is different; the intruder approach is already achieving good perfor- mance after just few training epochs, since it can rely on more informative negative samples (see <ref type="figure" target="#fig_5">Figure 3</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We have considered some general mathemati- cal and empirical properties of linear cross-space mapping functions, suggesting one well-known (max-margin estimation) and two new (chimera augmentation and "intruder" negative sample ad- justment) methods to improve their performance. With them, we achieve results well above the state of the art in both the cross-linguistic and the cross- modal setting. Both chimera and the intruder methods are flexible, and we plan to explore them further in future research. In particular, we want to devise more semantically-motivated methods to select chimera components and negative samples.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>0</head><label>0</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Test items: 1K. Search space: 5.1K+1K extra dis- tractors from a 200K word space, either randomly picked (random), or related to the training items.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Looking for intruders. We pick truck rather than dog as negative example for cat.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Learning curve with random or intruding negative samples in the cross-linguistic experiment.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>max-margin ridge max-margin</figDesc><table>P@1 
29.7 
38.4 
1.1 
1.9 
P@5 
44.2 
54.2 
4.8 
5.4 
P@10 49.1 
60.4 
7.9 
9.0 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Ridge vs. max-margin in zero-
shot experiments. Precision @N results cross-
linguistically (test items: 1.5K, search space: 
200K) and cross-modally (test items: 1K, search 
space: 5.1K). 

Cross-linguistic 
Cross-modal 

ridge max-margin gold ridge max-margin gold 

19.6 
9.8 0.6 55.8 
21.6 7.8 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Hubs as top predictions. Percentage of 
top-1 neighbours of test vectors in zero-shot ex-
periments of Table 3 with N 20 &gt; 5. 

Cross-linguistic 
Cross-modal 
cosine with 
ridge max-margin ridge max-margin 
full-space mean 0.21 
0.06 
0.13 
-0.01 
training point 
0.15 
0.12 
0.34 
0.24 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 8 :</head><label>8</label><figDesc></figDesc><table>Cross-modal zero-shot experiment 
with data augmentation, disjoint train/search 
spaces. Same setup as Table 8, but search space 
excludes training elements (1K test items, 1K 
search space). 

random 
related 

none chimera-5 none chimera-5 

P@1 
0.8 
3.3 
1.9 
2.8 
P@5 
5.3 
9.0 
4.8 
8.8 
P@10 8.8 
13.3 
7.9 
12.6 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 11 :</head><label>11</label><figDesc></figDesc><table>Random vs. intruding negative exam-
ples. Zero-shot precision @N results when cross-
space function is estimated using max-margin with 
random or "intruder" negative examples, cross-
linguistically (test items: 1.5K, search space: 
200K) and cross-modally (test items: 1K, search 
space: 5.1K). 

</table></figure>

			<note place="foot" n="1"> https://code.google.com/p/word2vec/ 2 Other hyperparameters, which we adopted without further tuning, include a context window size of 5 words to either side of the target, setting the sub-sampling option to 1e-05 and estimating the probability of target words by negative sampling, drawing 10 samples from the noise distribution (Mikolov et al., 2013b). 3 Corpus sources: http://wacky.sslmit.unibo. it, http://www.natcorp.ox.ac.uk 4 http://opus.lingfil.uu.se/</note>

			<note place="foot" n="7"> The notion of negative samples is not unique to marginbased learning; in Mikolov et al. (2013b), the authors used it to efficiently estimate a word probability distribution.</note>

			<note place="foot" n="9"> We have no realistic upper-bound estimate, but due to different word senses, synonymy, etc., it is certainly not 100%. 10 Although the numbers are not fully comparable because of different language pairs and various methodological details, their method is essentially equivalent to our ridge approach we are clearly outperforming.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Adam Liska, Yoav Goldberg and the anonymous reviewers for useful comments. We acknowledge ERC 2011 Starting Independent Re-search Grant n. 283554 (COMPOSES).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Don&apos;t count, predict! a systematic comparison of context-counting vs. context-predicting semantic vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgiana</forename><surname>Dinu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Germán</forename><surname>Kruszewski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL<address><addrLine>Baltimore, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="238" to="247" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ken</forename><surname>Chatfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1405.3531</idno>
		<title level="m">Return of the devil in the details: Delving deep into convolutional nets</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Shai Shalev-Shwartz, and Yoram Singer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ofer</forename><surname>Dekel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Keshet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="551" to="585" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note>Online passive-aggressive algorithms</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lia-Ji</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR<address><addrLine>Miami Beach, FL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">How to make words with vectors: Phrase generation in distributional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgiana</forename><surname>Dinu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL<address><addrLine>Baltimore, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="624" to="633" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Improving zero-shot learning by mitigating the hubness problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgiana</forename><surname>Dinu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angeliki</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<ptr target="http://www.iclr.cc/doku.php?id=iclr2015:main" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR Workshop Track</title>
		<meeting>ICLR Workshop Track<address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Published online</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Semi-supervised domain adaptation with instance constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Rodner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="668" to="675" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Adaptive subgradient methods for online learning and stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2121" to="2159" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">DeViSE: A deep visual-semantic embedding model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Frome</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Marc&amp;apos;aurelio Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS<address><addrLine>Lake Tahoe, NV</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2121" to="2129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Geodesic flow kernel for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristen</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2066" to="2073" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Visual Object Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristen</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Leibe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Morgan &amp; Claypool</publisher>
			<pubPlace>San Francisco</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Karayev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1408.5093</idno>
		<title level="m">Caffe: Convolutional architecture for fast feature embedding</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">ImageNet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS<address><addrLine>Lake Tahoe, Nevada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Is this a wampimuk? cross-modal mapping between distributional semantics and the visual world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angeliki</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elia</forename><surname>Bruni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL<address><addrLine>Baltimore, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1403" to="1414" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Effective self-training for parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of HLT-NAACL</title>
		<meeting>HLT-NAACL</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="152" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Exploiting similarities among languages for machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sutskever</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1309.4168</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Linguistic regularities in continuous space word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL<address><addrLine>Atlanta, Georgia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="746" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Predicting human brain activity associated with the meanings of nouns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svetlana</forename><surname>Shinkareva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Carlson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Min</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincente</forename><surname>Malave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Mason</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcel</forename><surname>Just</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">320</biblScope>
			<biblScope unit="page" from="1191" to="1195" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Zero-shot learning by convex combination of semantic embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Frome</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Zero-shot learning with semantic output codes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Palatucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dean</forename><surname>Pomerleau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1410" to="1418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Hubs in space: Popular nearest neighbors in high-dimensional data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miloš</forename><surname>Radovanovi´cradovanovi´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandros</forename><surname>Nanopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirjana</forename><surname>Ivanovi´civanovi´c</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="2487" to="2531" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">On the existence of obstinate results in vector space models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miloˇs</forename><surname>Radovanovi´cradovanovi´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandros</forename><surname>Nanopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirjana</forename><surname>Ivanovi´civanovi´c</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGIR</title>
		<meeting>SIGIR<address><addrLine>Geneva, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="186" to="193" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Self-training for enhancement and domain adaptation of statistical parsers trained on small datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Rappoport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="616" to="623" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Contrastive estimation: Training log-linear models on unlabeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="354" to="362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Zero-shot learning through cross-modal transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milind</forename><surname>Ganjoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS<address><addrLine>Lake Tahoe, NV</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="935" to="943" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Grounded compositional semantics for finding and describing images with sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="207" to="218" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Introduction to linear algebra</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gilbert</forename><surname>Strang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<publisher>Wellesley-Cambridge Press</publisher>
			<pubPlace>Wellesley, MA</pubPlace>
		</imprint>
	</monogr>
	<note>3d edition</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Parallel data, tools and interfaces in OPUS</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jörg</forename><surname>Tiedemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC</title>
		<meeting>LREC</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2214" to="2218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Unbiased look at dataset bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1521" to="1528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">From frequency to meaning: Vector space models of semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Turney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Pantel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="141" to="188" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Literal and metaphorical sense identification through concrete and abstract context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Turney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yair</forename><surname>Neuman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Assaf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yohai</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP<address><addrLine>Edinburgh, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="680" to="690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Wsabie: Scaling up to large vocabulary image annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI</title>
		<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2764" to="2770" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Visualizing and understanding convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ECCV</title>
		<meeting>ECCV<address><addrLine>Zurich, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="818" to="833" />
		</imprint>
	</monogr>
	<note>Part 1</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.01710</idno>
		<title level="m">Text understanding from scrath</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
