<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:07+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Neural Semantic Parsing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 15-20, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Allen Institute for Artificial Intelligence</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pradeep</forename><surname>Dasigi</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Srinivasan Iyer ♣</roleName><forename type="first">Alane</forename><surname>Suhr</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Cornell University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Neural Semantic Parsing</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics-Tutorial Abstracts</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics-Tutorial Abstracts <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="17" to="18"/>
							<date type="published">July 15-20, 2018</date>
						</imprint>
					</monogr>
					<note>17</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Semantic parsers translate natural language utter- ances into machine-executable logical forms or programs, and are thus key components in nat- ural language understanding systems. Semantic parsing is a well-established research area, with application in tasks such as question answering, instruction following, voice assistants, and code generation. In the last two years, the models used for semantic parsing have changed dramatically, with the introduction of neural methods that allow us to rethink many of the previous assumptions un- derlying semantic parsing.</p><p>Traditionally, the executable formalisms and models used in semantic parsing research have been heavily reliant on notions of formal seman- tics in linguistics, such as λ-calculus generated by a CCG parser. However, recent work with neural encoder-decoder semantic parsers allow for more accessible formalisms, such as standard program- ming languages, and NMT-style models that are much more approachable to a broader NLP au- dience. We will present an overview of modern neural methods for semantic parsing and how they have changed semantic parsing research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Description</head><p>This tutorial will cover how the transition to neu- ral encoder-decoder models has changed seman- tic parsing research. We aim to both inform those already interested in semantic parsing research of new developments in the field, as well as introduce the topic as an exciting research area to those who are unfamiliar with it.</p><p>Current semantic parsing research uses encoder-decoder models that are very similar to machine translation systems. The key differ- ence between these two fields is that semantic parsing translates natural language into a formal language, while machine translation translates natural language into a different natural language. The formal language used in semantic parsing research allows for constrained decoding, where the model is constrained to only produce outputs that are valid formal statements. We will describe how this is done, and the various approaches researchers have taken to model this constrained decoding.</p><p>Encoder-decoder semantic parsing models also allow us to drop our reliance on linguistic for- malisms, and much recent work has explored re- placing λ-calculus and λ-DCS with standard pro- gramming languages like SQL, python, or java. This has the promise of dramatically decreasing annotation costs, allowing researchers to collect much larger and more varied semantic parsing datasets than have previously been available. In our tutorial, we will describe recent efforts in this direction and why programming languages are a natural target for future semantic parsing research.</p><p>Neural models also allow representation of con- tinuous, diverse, and less well-defined contexts (e.g., photographs), with methods for representing these contexts that generalize better to new envi- ronments (e.g., they don't necessarily require sym- bolic representations of the environments). The last section of our tutorial will cover recent work on these more complex semantic parsing tasks.</p><p>Much of the content covered in this tutorial will have corresponding implementations in the Al- lenNLP toolkit for NLP research. We will provide a brief overview at the end of the tutorial outlining how to use this toolkit to get started with semantic parsing research. decoder models have changed semantic pars- ing research. We will briefly discuss the com- plexity of prior systems, and how new models can be seen as very similar to neural machine translation models, with the addition of con- strained decoding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Datasets: Before talking about modern</head><p>methods, we will spend some time discussing what you can do with semantic parsing, and which datasets and tasks are most exciting for current research.</p><p>3. Constrained Decoding: Current semantic parsing models use an encoder-decoder ar- chitecture with constrained decoding. This section will first describe the basic encoder- decoder architecture, then describe how con- strained decoding works. There are many ways to parameterize the decoder; we will discuss a simple method in-depth, to give the audience a detailed understanding of the ba- sic model architecture, then describe several other model structures and how they relate to the simple architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Break</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Semantic Parsing as Code Generation:</head><p>This section will discuss the choice of formal languages used by semantic parsers, and de- scribe why much recent work has chosen to use standard programming languages instead of more linguistically-motivated representa- tions.</p><p>5. Grounded and Context-Dependent Se- mantic Parsing: This section will describe a particularly challenging setting for seman- tic parsing: where there is additional context or interaction that the parser must take into account when translating natural language to formal language. Neural models provide a natural way to include this context, and we will give an overview of recent work in this direction.</p><p>6. Building Semantic Parsers with Al- lenNLP: A brief demonstration of the tools available in the AllenNLP toolkit for doing semantic parsing research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Instructors</head><p>Matt Gardner is a research scientist at the Allen Institute for Artificial Intelligence. His research focuses on question answering and semantic pars- ing. He is the lead maintainer of the AllenNLP toolkit and a host of the NLP Highlights podcast. Pradeep Dasigi is a PhD student at the Lan- guage Technologies Institute in Carnegie Mellon University. His research interest lies in build- ing knowledge-aware language understanding sys- tems, with a recent focus on neural semantic pars- ing.</p><p>Srinivasan Iyer is a graduate student in the Nat- ural Language Processing group at the University of Washington, Seattle. His main research area is context dependent semantic parsing directly from natural language to general purpose programming source code. Other aspects of his research are learning semantic parsers from massive online re- sources and incorporating user feedback for model improvement.</p><p>Alane Suhr is a PhD student in Computer Science at Cornell University. Alane's research interests include developing machine learning methods for understanding natural language grounded in com- plex environments and interactions. She is a recip- ient of an NSF Graduate Research Fellowship, the Best Resource Paper award at ACL 2017, and an Outstanding Paper Award at NAACL 2018. Luke Zettlemoyer Luke Zettlemoyer is an As- sociate Professor in the Paul G. Allen School of Computer Science &amp; Engineering at the Univer- sity of Washington. He has a been doing research in semantic parsing for many years, and recently shifted to studying neural models for this problem. Luke's honors include multiple best paper awards, a PECASE award, and an Allen Distinguished In- vestigator award.</p></div>
			<note place="foot" n="3"> Outline 1. Introduction: This section will introduce the theme of the tutorial: how neural encoder</note>
		</body>
		<back>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
