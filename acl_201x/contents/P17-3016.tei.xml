<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:03+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Accent Adaptation for the Air Traffic Control Domain</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Garber</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meital</forename><surname>Singer</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Ward</surname></persName>
						</author>
						<title level="a" type="main">Accent Adaptation for the Air Traffic Control Domain</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of ACL 2017, Student Research Workshop</title>
						<meeting>ACL 2017, Student Research Workshop <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="95" to="99"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-3016</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Automated speech recognition (ASR) plays a significant role in training and simulation systems for air traffic controllers. However, because English is the default language used in air traffic control (ATC), ASR systems often encounter difficulty with speakers&apos; non-native accents, for which there is a paucity of data. This paper examines the effects of accent adaptation on the recognition of non-native En-glish speech in the ATC domain. Accent adaptation has been demonstrated to be an effective way to model under-resourced speech, and can be applied to a variety of models. We use Subspace Gaus-sian Mixture Models (SGMMs) with the Kaldi Speech Recognition Toolkit to adapt acoustic models from American English to German-accented English, and compare it against other adaptation methods. Our results provide additional evidence that SGMMs can be an efficient and effective way to approach this problem, particularly with smaller amounts of accented training data.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>As the field of speech recognition has developed, ASR systems have grown increasingly useful for the ATC domain. The majority of air traffic communication is verbal <ref type="bibr" target="#b3">(Hofbauer et al., 2008)</ref>, meaning ASR has the potential to be an invalu- able tool not just in assisting air traffic controllers in their daily operations, but also for training purposes and workload analysis ( <ref type="bibr" target="#b0">Cordero et al., 2012)</ref>.</p><p>Due to a constrained grammar and vocabulary, ATC ASR systems have relatively low word er- ror rates (WER) when compared to other domains, such as broadcast news <ref type="bibr" target="#b2">(Geac˘ ar, 2010)</ref>. These sys- tems can also be limited at run-time by location (e.g. place names, runway designations), further constraining these parameters and increasing ac- curacy.</p><p>Despite the effectiveness of existing systems, air traffic control has little tolerance for mis- takes in day-to-day operations <ref type="bibr" target="#b3">(Hofbauer et al., 2008)</ref>. Furthermore, these systems generally per- form worse in real-world conditions, where they have to contend with confounding factors such as noise and speaker accents <ref type="bibr" target="#b2">(Geac˘ ar, 2010)</ref>.</p><p>In this paper, we attempt to ameliorate the is- sue of speaker accents by examining the useful- ness of accent adaptation in the ATC domain. We compare the relatively new innovation of SGMMs ( <ref type="bibr">Povey et al., 2011a</ref>) against older adaptation tech- niques, such as maximum a posteriori (MAP) es- timation, as well as pooling, a type of multi- condition training.</p><p>We perform experiments using out-of-domain American English data from the HUB4 Broad- cast News Corpus ( <ref type="bibr" target="#b1">Fiscus et al., 1998)</ref>, as well as German-accented English data taken from the AT- COSIM corpus <ref type="bibr" target="#b3">(Hofbauer et al., 2008</ref>) and pro- vided by UFA, Inc., a company specializing in ATC training and simulation.</p><p>The paper is organized as follows: in Section 2, we describe previous accent adaptation techniques as well as the structure of SGMMs and how they can be adapted on new data. In Section 3, we out- line our experiments and show how accent adap- tation with SGMMs outperforms other methods when using smaller amounts of data. Section 4 concludes the paper and presents paths for future study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>95</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Accent Adaptation</head><p>The ideal ASR system for non-native accented speech is one trained on many hours of speech in the target accent. However, for a variety of rea- sons, there is often a paucity of such data. Several different techniques have been employed to model accented speech in spite of this lack of data.</p><p>One method is to manually adjust the pronun- ciation lexicon to match the accented phone set ( <ref type="bibr" target="#b4">Humphries et al., 1996)</ref>. Unfortunately, this is both time-and labor-intensive as it requires mappings to be generated from one phoneset to another, either probabilistically or using expert knowledge.</p><p>Another technique is interpolate models, with one trained on native accented speech and the other trained on non-native accented speech <ref type="bibr" target="#b10">(Witt and Young, 1999</ref>). While this has been shown to reduce word error rate ( <ref type="bibr" target="#b9">Wang et al., 2003</ref>), it does not fully adapt the native model to the new accent.</p><p>An effective and versatile method, and the one we implement here, is to directly adapt a native acoustic model on the non-native speech. There exist a few different ways to accomplish this, such as MAP estimation for HMM-GMMs, Max- imum Likelihood Linear Regression (MLLR) for Gaussian parameters <ref type="bibr" target="#b10">(Witt and Young, 1999)</ref>, and re-estimating the state-specific parameters of an SGMM. These techniques have the advantage of requiring little other than a trained native accent model and a non-trivial amount of non-native ac- cented data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">SGMM Adaptation</head><p>Unlike a typical GMM, the parameters of an SGMM are determined by a combination of globally-shared parameters and state-specific pa- rameters. The model can be expressed as follows:</p><formula xml:id="formula_0">p(x|j) = Σ M j m=1 c jm Σ I i=1 w jmi N (x; µ jmi , Σ i ) µ jmi = M i v jm w jmi = exp w T i v jm Σ I l=1 exp w T l v jm</formula><p>where x is the feature vector, j is the speech state, c jm is the state-specific weight, v jm is the state-specific vector, and µ jmi , M i , and w i are all globally-shared parameters. SGMMs are gen- erally initialized using a Universal Background Model (UBM), which is trained separately from the SGMM. SGMMs can be further extended beyond the model described above to include speaker-specific vectors and projections. Other speaker adaptation techniques, such as feature-space Maximum Like- lihood Linear Regression (fMLLR, also known as CMLLR), can be applied on top of these exten- sions to further increase the accuracy of the model.</p><p>Though it is possible to perform MAP adapta- tion using SGMMs, their unique structure allows a different and more effective technique to be ap- plied ( <ref type="bibr">Povey et al., 2011a</ref>). Initially, all of the model's state-specific and globally-shared param- eters are trained on out-of-domain data. The state- specific parameter v jm can then be re-estimated on the non-native speech using maximum like- lihood. This adaptation method has been suc- cessfully applied to multi-lingual SGMMs ( <ref type="bibr">Povey et al., 2011a</ref>) as well as different native accents of the same language ( <ref type="bibr" target="#b6">Motlicek et al., 2013)</ref>, and is the technique we use here to adapt the native- accented SGMMs on non-native speech.</p><p>Though there exist other ways of adapting SG- MMs ( <ref type="bibr" target="#b5">Juan et al. (2015)</ref> created a multi-accent SGMM by combining UBMs that had been sep- arately trained on the native and non-native data), we do not implement those methods here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>All experiments were performed using the Kaldi Speech Recognition Toolkit (Povey et al., 2011b).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Speech Data</head><p>For acoustic model training, data was taken from three separate sources:</p><p>• Approximately 75 hours of US English audio was taken from the 1997 English Broadcast News Corpus (HUB4), which consists of var- ious radio and television news broadcasts.</p><p>• About 20 hours of German-accented data, which is purely in-domain ATC speech, was supplied by UFA.</p><p>• An additional 6 hours of German-accented speech was taken from the ATCOSIM cor- pus, which consists of audio recorded during real-time ATC simulations.</p><p>Native (Unadapted) Non-native Only Pooled (Unadapted) Native (Adapted) Pooled <ref type="table">(Adapted)  System  WER  SER  WER  SER  WER  SER  WER  SER  WER  SER  HMM-GMM</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Language Model Data</head><p>We interpolated a language model trained on the UFA and ATCOSIM utterances with one trained on sentences generated from an ATC grammar supplied by UFA. Both LMs were 5-gram mod- els with Witten-Bell smoothing. The interpolated model was heavily weighted towards the natural utterances (with λ = 0.95), since the main pur- pose of the generated utterances was to add cov- erage for words and n-grams that were not present in the natural data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lexicon</head><p>The lexicon was largely derived from the CMU Pronouncing Dictionary. Additional pronuncia- tions were supplied by UFA, and several were written by hand.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experimental Setup</head><p>The baseline acoustic model was a regular HMM- GMM and was trained with the usual 39 MFCC features, including delta and acceleration features. Experiments were conducted both with and with- out pooling the adaptation data with the US En- glish data, since pooling data prior to adaptation has been shown to give better results for both MAP and SGMM maximum likelihood adaptation <ref type="bibr" target="#b6">(Motlicek et al., 2013)</ref>, as well as for other adap- tation techniques <ref type="bibr" target="#b10">(Witt and Young, 1999</ref>). We conducted two experiments, each with a dif- ferent amount of adaptation data. The first exper- iment included only a 6.5-hour subset of the total adaptation data, which was created by randomly selecting speakers from both the ATCOSIM cor- pus and the UFA data. The second included all 26 hours of adaptation data. HMM-GMM models were adapted using MAP estimation and SGMMs were adapted using the method outlined above.</p><p>For each amount of adaptation data, we trained several different models, testing all combinations of the following variables:</p><p>• Whether the model was trained solely on the native-accented data, trained solely on the adaptation data, trained on the combined data but not adapted, trained of the native data and then adapted, or trained on the combined data and then adapted.</p><p>• Whether an HMM-GMM or SGMM was used (as well as the corresponding adaptation method).</p><p>• Whether the model was trained with speaker- dependent fMLLR transforms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Experimental Results</head><p>With 6.5 hours of German accented data, both the MAP-adapted and SGMM-adapted pooled sys- tems saw modest reductions in word error rate, as can be seen in <ref type="table">Table 1</ref>. MAP adaptation pro- vided a 6.3% relative improvement over the corre- sponding accented-only model 1 , though WER was reduced by only 2.8% when fMLLR was imple- mented. Pooled SGMMs were more versatile and amenable to adaptation, with a relative reduction in WER of 10.6%, and a relative improvement of 6.1% when using fMLLR. Changes in sentence er- ror rate (SER) between models correlated with the changes in WER, reaching a minimum of 22.38% with the adapted SGMM-fMLLR system, a rela- tive reduction of just over 5%. Including the full 26 hours of non-native speech in the training and adaptation data generally re- sulted in higher error rates in the adapted sys- tems than the corresponding accented-only mod- els, as seen in <ref type="table" target="#tab_1">Table 2</ref>. This decrease in per- formance approached 10% for the HMM-GMM systems. Though the SGMM-fMLLR adapted system experienced a relative reduction in per- formance of about 4%, the performance of the non-fMLLR SGMM increased by about the same amount. Changes in SER again correlated with the changes in WER, with the adapted speaker inde- pendent SGMM possessing a slight edge (about 1%) over its accented-only counterpart.</p><p>It is not clear from this experiment why the speaker independent SGMM system was the only one to undergo an increase in performance when adapted with the full dataset. A possible explana- tion is that, with enough data, the speaker adap- tive techniques were simply more robust than the accent-adaptation method.</p><p>Unsurprisingly, the unadapted native-accented systems had the worst performance out of all of the models, with word error rates that were more than double than that of next best corresponding system.</p><p>The unadapted pooled models and the adapted native models were usually the second-and third- worst performing groups of models, though their ranking depended on the amount of adaptation data used. The pooled models generally gave bet- ter results when more adaptation data was pro- vided, while the adapted native models had an ad- vantage with less adaptation data.</p><p>Interestingly, fMLLR had relatively little effect when used with the adapted native SGMMs, re- gardless of the amount of adaptation data used. WER was reduced by only about 1 to 2% com- pared to the models' non-fMLLR counterparts. This stands in contrast with the gains that virtu- ally every other model saw with the introduction of fMLLR. It is not clear why this was the case, though it might relate to some overlap between the SGMM adaptation method and fMLLR.</p><p>While it is possible that training the pooled model with in-domain English speech could in- crease performance, it seems unlikely that it would be superior to either the accented-only model or the adapted pooled model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we explored how non-native accent adaptation can be applied using SGMMs to yield notable improvements over the baseline model, particularly when there exists only limited in- domain data. We also demonstrated that this tech- nique can achieve as high as a 10% relative im- provement in WER in the ATC domain, where the baseline model is already highly accurate. Even with large amounts of adaptation data, speaker in- dependent SGMMs saw a minor increase in per- formance when adapted, compared to when they were trained only with in-domain data.</p><p>Future avenues of research include whether the SGMM adaptation technique used here could be successfully combined with the UBM-focused adaptation method used by <ref type="bibr" target="#b5">Juan et al. (2015)</ref> to achieve even further reductions in WER.</p><p>Furthermore, future work could explore whether smaller error rates could be achieved by training the original acoustic models on speech from the ATC domain, rather than from broadcast news, and whether the increases in perfomance found here still hold between more distantly re- lated and phonologically dissimilar languages. It should be noted, however, that this may necesitate the creation of new corpora, as the few non-native ATC corpora that exist seem to only include European accents.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 2 : Error rates of different models trained with 26 hours of adaptation data.</head><label>2</label><figDesc></figDesc><table>Test data consisted of just under 4 hours of 
German-accented speech provided by UFA. All 
audio was downsampled to 16 kHz. 

</table></figure>

			<note place="foot" n="1"> Unless otherwise specified, reduction in error rate is relative to the model with the same parameters (SGMM, fMLLR, etc.) but trained on the non-native accented data only, rather than relative to a single baseline.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Automated speech recognition in atc environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">José Manuel</forename><surname>Cordero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuel</forename><surname>Dorado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">José</forename><surname>Miguel De</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ATACCS 2012, the 2nd International Conference on Application and Theory of Automation in Command and Control Systems</title>
		<meeting>ATACCS 2012, the 2nd International Conference on Application and Theory of Automation in Command and Control Systems</meeting>
		<imprint>
			<publisher>IRIT Press</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="46" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Fiscus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Garofolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Przybocki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Pallett</surname></persName>
		</author>
		<title level="m">English Broadcast News Speech (HUB4) LDC98S71. Linguistic Data Consortium</title>
		<meeting><address><addrLine>Philadelphia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Reducing pilot/atc communication errors using voice recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Claudiu-Mihai Geac˘ Ar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICAS 2010, the 27th Congress of the Internation Council of the Aeronautical Sciences</title>
		<meeting>ICAS 2010, the 27th Congress of the Internation Council of the Aeronautical Sciences</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The atcosim corpus of non-prompted clean 98 air traffic control speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konrad</forename><surname>Hofbauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Petrik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horst</forename><surname>Hering</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC 2008, the Sixth International Conference on Language Resources and Evaluation</title>
		<meeting>LREC 2008, the Sixth International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Using accent-specific pronunciation modelling for robust speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><forename type="middle">J</forename><surname>Humphries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">C</forename><surname>Woodland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pearce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICSPL 96, Fourth International Conference on Spoken Language</title>
		<meeting>ICSPL 96, Fourth International Conference on Spoken Language</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1996" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="2324" to="2327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Merging of native and non-native speech for low-resource accented asr</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Sarah Samson Juan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Besacier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tien-Ping</forename><surname>Lecouteux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SLSP 2015, the Third International Conference on Statistical Language and Speech Processing</title>
		<meeting>SLSP 2015, the Third International Conference on Statistical Language and Speech Processing</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="255" to="266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Accent adaptation using subspace gaussian mixture models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petr</forename><surname>Motlicek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">N</forename><surname>Garner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Namhoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeongmi</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICASSP 2013, IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<meeting>ICASSP 2013, IEEE International Conference on Acoustics, Speech and Signal Processing</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="7170" to="7174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Ariya Rastrow, et al. 2011a. The subspace gaussian mixture modela structured model for speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Povey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukáš</forename><surname>Burget</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pinar</forename><surname>Akyazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Kai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnab</forename><surname>Ghoshal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Glembek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nagendra</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Karafiát</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="404" to="439" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The kaldi speech recognition toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Povey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnab</forename><surname>Ghoshal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gilles</forename><surname>Boulianne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Burget</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Glembek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nagendra</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirko</forename><surname>Hannemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petr</forename><surname>Motlicek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanmin</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petr</forename><surname>Schwarz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 2011 workshop on Automatic Speech Recognition and Understanding. IEEE Signal Processing Society</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page">192584</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Comparison of acoustic model adaptation techniques on non-native speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhirong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tanja</forename><surname>Schultz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Waibel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICASSP 2003, IEEE International Conference on Acoustics, Speech, and Signal Processing</title>
		<meeting>ICASSP 2003, IEEE International Conference on Acoustics, Speech, and Signal Processing</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="540" to="543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Off-line acoustic modelling of non-native accents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Silke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><forename type="middle">J</forename><surname>Witt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th European Conference on Speech Communication and Technology</title>
		<meeting>the 6th European Conference on Speech Communication and Technology</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="1367" to="1370" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
