<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:36+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Discriminative Deep Random Walk for Network Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juzheng</forename><surname>Li</surname></persName>
							<email>lijuzheng09@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Comp. Sci. &amp; Tech</orgName>
								<orgName type="institution">State Key Lab of Intell. Tech. &amp; Sys. Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Comp. Sci. &amp; Tech</orgName>
								<orgName type="institution">State Key Lab of Intell. Tech. &amp; Sys. Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Comp. Sci. &amp; Tech</orgName>
								<orgName type="institution">State Key Lab of Intell. Tech. &amp; Sys. Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Discriminative Deep Random Walk for Network Classification</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1004" to="1013"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Deep Random Walk (DeepWalk) can learn a latent space representation for describing the topological structure of a network. However, for relational network classification , DeepWalk can be suboptimal as it lacks a mechanism to optimize the objective of the target task. In this paper, we present Discriminative Deep Random Walk (DDRW), a novel method for re-lational network classification. By solving a joint optimization problem, DDRW can learn the latent space representations that well capture the topological structure and meanwhile are discriminative for the network classification task. Our experimental results on several real social networks demonstrate that DDRW significantly outperforms DeepWalk on multi-label network classification tasks, while retaining the topological structure in the latent space. DDRW is stable and consistently outperforms the baseline methods by various percentages of labeled data. DDRW is also an online method that is scalable and can be naturally parallelized.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Categorization is an important task in natural lan- guage processing, especially with the growing scale of documents in the Internet. As the doc- uments are often not isolated, a large amount of the linguistic materials present a network structure such as citation, hyperlink and social networks. The large size of networks calls for scalable ma- chine learning methods to analyze such data. Re- cent efforts have been made in developing statis- tical models for various network analysis tasks, such as network classification <ref type="bibr" target="#b23">(Neville and Jensen, 2000</ref>), content recommendation ( <ref type="bibr" target="#b4">Fouss et al., 2007)</ref>, link prediction ( <ref type="bibr" target="#b0">Adamic and Adar, 2003)</ref>, and anomaly detection ( <ref type="bibr" target="#b26">Savage et al., 2014</ref>). One common challenge of statistical network models is to deal with the sparsity of networks, which may prevent a model from generalizing well.</p><p>One effective strategy to deal with network sparsity is to learn a latent space representation for the entities in a network ( <ref type="bibr" target="#b11">Hoff et al., 2002;</ref><ref type="bibr" target="#b29">Tang and Liu, 2011;</ref><ref type="bibr" target="#b30">Tang et al., 2015</ref>). Among various approaches, DeepWalk <ref type="bibr" target="#b25">(Perozzi et al., 2014</ref>) is a recent method that embeds all the entities into a continuous vector space using deep learning methods. DeepWalk captures entity fea- tures like neighborhood similarity and represents them by Euclidean distances (See <ref type="figure">Figure 1(b)</ref>). Furthermore, since entities that have closer rela- tionships are more likely to share the same hobbies or belong to the same groups, such an embedding by DeepWalk can be useful for network classifica- tion, where the topological information is explored to encourage a globally consistent labeling.</p><p>Although DeepWalk is effective on learning embeddings of the topological structure, when dealing with a network classification task, it lacks a mechanism to optimize the objective of the tar- get task and thus often leads to suboptimal embed- dings. In particular, for our focus of relational net- work classification, we would like the embeddings to be both representing the topological structure of the network actors and discriminative in predicting the class labels of actors.</p><p>To address the above issues, we present Dis- criminative Deep Random Walk (DDRW) for re- lational network classification. DDRW extends DeepWalk by jointly optimizing the classification objective and the objective of embedding entities in a latent space that maintains the topological structure. Under this joint learning framework, DDRM manages to learn the latent representations 1.2</p><p>1.3</p><p>1.4</p><p>1.5</p><p>1.6</p><p>(c) DDRW Embedding <ref type="figure">Figure 1</ref>: Different experimental results of embedding a network into a two dimensional real space. We use Karate Graph ( <ref type="bibr" target="#b14">Macskassy and Provost, 1977)</ref> for this example. Four different colors stand for the classes of the vertices. In (b), vertices which have stronger relations in the network are more likely to be closer in the embedding latent space. While in (c), besides the above-mentioned property, DDRW makes vertices in different classes more separated.</p><p>that are strongly associated with the class labels (See <ref type="figure">Figure 1(c)</ref>), making it easy to find a separat- ing boundary between the classes, and the actors that are connected in the original network are still close to each other in the latent social space. This idea of combining task-specific and representation objectives has been widely explored in other re- gions such as MedLDA ( ) and Su- pervised Dictionary Learning ( <ref type="bibr" target="#b17">Mairal et al., 2009</ref>).</p><p>Technically, to capture the topological struc- ture, we follow the similar idea of Deep- Walk by running truncated random walks on the original network to extract sequences of ac- tors, and then building a language model (i.e., <ref type="bibr">Word2Vec (Mikolov et al., 2013b)</ref>) to project the actors into a latent space. To incorporate the super- vising signal in network classification, we build a classifier based on the latent space representations. By sharing the same latent social space, the two objectives are strongly coupled and the latent so- cial space is guided by both the network topology and class labels. DDRW optimizes the joint objec- tive by using stochastic gradient descent, which is scalable and embarrassingly parallizable.</p><p>We evaluate the performance on several real- world social networks, including BlogCatalog, Flickr and YouTube. Our results demonstrate that DDRW significantly boosts the classification ac- curacy of DeepWalk in multi-label network clas- sification tasks, while still retaining the topolog- ical structure in the learnt latent social space. We also show that DDRW is stable and consis- tently outperforms the baseline methods by var- ious percentages of labeled data. Although the networks we use only bring topological informa- tion for clarity, DDRW is flexible to consider addi- tional attributes (if any) of vertices. For example, DDRW can be naturally extended to classify docu- ments/webpages, which are often represented as a network (e.g., citation/hyperlink network), by con- joining with a word2vec component to embed the documents/webpages into the same latent space, similar as previous work on extending DeepWalk to incorporate attributes ( <ref type="bibr" target="#b34">Yang et al., 2015</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Problem Definition</head><p>We consider the network classification problem, which classifies entities from a given network into one or more categories from a set Y. Let G = (V, E, Y ) denote a network, where V is the set of vertices, representing the entities of the network; E ⊆ (V × V ) is the set of edges, representing the relations between the entities; and Y ⊆ R|V |×|Y| denotes the labels of entities. We also consider YU as a set of unknown labels in the same graph G. The target of the classification task is to learn a model from labeled data and generate a label set YP to be the prediction of YU . The difference be- tween YP and YU indicates the classification qual- ity.</p><p>When classifying elements X ∈ Rn, traditional machine learning methods learn a weight matrix H to minimize the difference between YP = F(X, H) and YU , where F is any known fixed function. In network aspect, we will be able to utilize well-developed machine learning meth- ods if adequate information of G is embedded into a corresponding form as X. By this mo- tivation, relational learning <ref type="bibr" target="#b8">(Getoor and Taskar, 2007;</ref><ref type="bibr" target="#b23">Neville and Jensen, 2000</ref>) methods are pop-ularly employed. In network classification, the internal structure of a network is resolved to ex- tract the neighboring features of the entities <ref type="bibr" target="#b16">(Macskassy and Provost, 2007;</ref><ref type="bibr" target="#b32">Wang and Sukthankar, 2013)</ref>. Accordingly, the core problem is how to describe the irregular networks within formal fea- ture spaces. A variety of approaches have been proposed with the purpose of finding effective statistical information through the network <ref type="bibr" target="#b9">Henderson et al., 2011;</ref><ref type="bibr" target="#b29">Tang and Liu, 2011</ref>).</p><p>DeepWalk ( <ref type="bibr" target="#b25">Perozzi et al., 2014</ref>) is an outstand- ing method for network embedding, which uses truncated random walks to capture the explicit structure of the network and applies language models to learn the latent relationships between the actors. When applied to the network classifica- tion task, DeepWalk first learns X which describes the topological structure of G and then learns a subsequent classifier H. One obvious shortcom- ing of this two-step procedure is that the embed- ding step is unaware of the target class label in- formation and likely to learn embeddings that are suboptimal for classification.</p><p>We present Discriminative Deep Random Walk (DDRW) to enhance the effect of DeepWalk by learning X ∈ R |V |×d and H ∈ R d×|Y| jointly. By using topological and label information of a certain network simultaneously, we will show that DDRW improves the classification accuracy significantly compared with most recent related methods. Furthermore, we will also show that the embedded result X produced by DDRW is able to retain the structure of G well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Discriminative Deep Random Walk</head><p>In this section, we present the details of Discrimi- native Deep Random Walk (DDRW). DDRW has both embedding and classification objectives. We optimize the two objectives jointly to learn latent representations that are strongly associated with the class labels in the latent space. We use stochas- tic gradient descent ( <ref type="bibr" target="#b18">Mikolov et al., 1991)</ref> as our optimization method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Embedding Objective</head><p>Let θ = (θ 1 , θ 2 , . . . , θ |V | ) denote the embedded vectors in the latent space, and α denote the topo- logical structure of the graph. The embedding ob- jective can be described as an optimization prob- lem as follows:</p><formula xml:id="formula_0">min θ Lr(θ, α),<label>(1)</label></formula><p>where Lr indicates the difference between the em- bedded representations θ and original topologi- cal structure α. For this objective, we use trun- cated random walks to capture the topological structure of the graph and the language model Word2Vec ( <ref type="bibr" target="#b20">Mikolov et al., 2013b</ref>) to learn the la- tent representations. Below, we explain each in turn.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Random Walk</head><p>Random Walk has been used in different regions in network analysis to capture the topological structure of graphs ( <ref type="bibr" target="#b4">Fouss et al., 2007;</ref><ref type="bibr" target="#b1">Andersen et al., 2006</ref>). As the name suggests, Random Walk chooses a certain vertex in the graph for the first step and then randomly migrates through the edges. Truncated random walk defines a maxi- mum length s for all walk streams. In our implementation, we shuffle the whole vertices V in the graph for τ times to build the sample set W . After each time of shuffling, we take the permutation list of vertices as the starting points of walks. Every time a walk stream starts at one element in order, randomly chooses an ad- jacent vertex to move, and ends when this stream reaches s vertices. By this procedure we get totally τ |V | samples (i.e. walk streams) from the graph. Thus our sample set W ∈ R τ |V |×s is obtained as the training materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Word2Vec</head><p>Existing work has shown that both the vertices in truncated random walks and the words in text arti- cles follow similar power-law distributions in fre- quency, and then the idea of reshaping a social network into a form of corpus is very straight- forward ( <ref type="bibr" target="#b25">Perozzi et al., 2014</ref>). Corresponding to linguistic analysis region, the objective is to find an embedding for a corpus to show the latent sig- nificances between the words. Words which have closer meanings are more likely to be embedded into near positions. Word2Vec ( <ref type="bibr" target="#b20">Mikolov et al., 2013b</ref>) is an appropriate tool for this problem. We use the Skip-gram ( <ref type="bibr" target="#b19">Mikolov et al., 2013a</ref>) strat- egy in Word2Vec, which uses the central word in a sliding window with radius R to predict other words in the window and make local optimiza- tions. Specifically, let ω = rw(α) denote the full walk streams obtained from truncated random walks in Section 3.1.1. Then by Skip-gram we can get the objective function</p><formula xml:id="formula_1">L r (θ, α) = − τ i=1 1 s s t=1 −R≤j≤R,j =0 log p(ω i,t+j |ω i,j ).<label>(2)</label></formula><p>The standard Skip-gram method defines p(ω i,t+j |ω i,j ) in Eq.(2) as follows:</p><formula xml:id="formula_2">p(ω O |ω I ) = exp(θ T ω O ˆ θ ω I ) |V | i=1 exp(θ T i ˆ θ ω I ) ,<label>(3)</label></formula><p>wherê θ i and θ i are the input and output represen- tations of the ith vertex, respectively.</p><p>One shortcoming of the standard form is that the summation in Eq. <ref type="formula" target="#formula_2">(3)</ref> is very inefficient. To reduce the time consumption, we use the Hierar- chical Softmax ( <ref type="bibr" target="#b21">Mnih and Hinton, 2009;</ref><ref type="bibr" target="#b22">Morin and Bengio, 2005</ref>) which is included in Word2Vec packages * . In Hierarchical Softmax, the Huffman binary tree is employed as an alternative represen- tation for the vocabulary. The gradient descent step will be faster thanks to the Huffman tree struc- ture which allows a reduction of output units nec- essarily evaluated. * https://code.google.com/archive/p/word2vec/</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Classification Objective</head><p>Let y = (y 1 , y 2 , . . . , y |V | ) denote the labels, and β denote the subsequent classifier. The classifica- tion objective can be described as an optimization problem: min</p><formula xml:id="formula_3">θ,β L c (θ, β, y).<label>(4)</label></formula><p>In DDRW, we use existing classifiers and do not attempt to extend them.</p><p>Although SVM multicalss <ref type="bibr" target="#b2">(Crammer and Singer, 2002</ref>) often shows good performance in multi-class tasks em- pirically, we choose the classifier being referred to as L2-regularized and L2-loss Support Vector Classification <ref type="bibr" target="#b3">(Fan et al., 2008</ref>) to keep pace with the baseline methods to be mentioned in Section 4.</p><p>In L2-regularized and L2-loss SVC, the loss function is</p><formula xml:id="formula_4">L c (θ, β, y) =C |V | i=1 (σ(1 − y i β T θ i )) 2 + 1 2 β T β,<label>(5)</label></formula><p>where C is the regularization parameter, σ(x) = x if x &gt; 0 and σ(x) = 0 otherwise. Eq. <ref type="formula" target="#formula_4">(5)</ref> is for binary classification problems, and is extended to multi-class problems following the one-against- rest strategy (Fan et al., 2008).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Joint Learning</head><p>The main target of our method is to classify the unlabeled vertices in the given network. We achieve this target with the help of intermediate embeddings which latently represent the network structure. We simultaneously optimize two ob- jectives in Section 3.1 and 3.2. Specifically, let L(θ, β, α, y) = ηL r (θ, α) + L c (θ, β, y), where η is a key parameter that balances the weights of the two objectives. We solve the joint optimization problem: min</p><formula xml:id="formula_5">θ,β L(θ, β, α, y).<label>(6)</label></formula><p>We use stochastic gradient descent ( <ref type="bibr" target="#b18">Mikolov et al., 1991)</ref> to solve the optimization problem in Eq.(6). In each gradient descent step, we have</p><formula xml:id="formula_6">θ ← θ − δ ∂L ∂θ = θ − δ(η ∂L r ∂θ + ∂L c ∂θ ), β ← β − δ ∂L ∂β = β − δ ∂L c ∂β ,<label>(7)</label></formula><p>where δ is the learning rate for stochastic gradient descent. In our implementation, δ is initially set to 0.025 and linearly decreased with the steps, same as the default setting of Word2Vec. The deriva- tives in Eq. <ref type="formula" target="#formula_6">(7)</ref> are estimated by local slopes. In Eq. <ref type="formula" target="#formula_6">(7)</ref>, the latent representations adjust them- selves according to both topological information (∂L r /∂θ) and label information (∂L c /∂θ). This process intuitively makes vertices in the same class closer and those in different classes farther, and this is also proved by experiments ( <ref type="figure">See Fig- ure 1)</ref>. Thus by joint learning, DDRW can learn the latent space representations that well capture the topological structure and meanwhile are dis- criminative for the network classification task.</p><p>We take each sample W i from walk streams W to estimate the local derivatives of the loss func- tion for a descent step. Stochastic gradient descent enables DDRW to be an online algorithm, and thus our method is easy to be parallelized. Besides, a vertex may repeatedly appear for numerous times in W produced by random walks. This repeat is superfluous for classifiers and there is a consider- able possibility to arise overfitting. Inspired from DropOut ( <ref type="bibr" target="#b10">Hinton et al., 2012</ref>) ideas, we randomly ignore the label information to control the opti- mization process in an equilibrium state.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Setup</head><p>In this section we present an overview of the datasets and baseline methods which we will com- pare with in the experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>We use three popular social networks, which are exactly same with those used in some of the base- line methods. <ref type="table">Table 1</ref> summarizes the statistics of the data.</p><p>• BlogCatalog: a network of social relation- ships provided by blog authors. The labels of this graph are the topics specified by the uploading users.</p><p>• Flickr: a network of the contacts between users of the Flickr photo sharing website. The labels of this graph represent the interests of users towards certain categories of photos.</p><p>• YouTube: a network between users of the Youtube video sharing website. The labels stand for the groups of the users interested in different types of videos.  <ref type="table">Table 1</ref>: Statistics of the three networks. Sparsity indicates the ratio of the actual links and links in a complete graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Baseline Methods</head><p>We evaluate our proposed method by comparing it with some significantly related methods.</p><p>• LINE (Tang et al., 2015) † : This method takes the edges of a graph as samples to train the first-order and second-order prox- imity seprately and integrate the results as an embedding of the graph. This method can handle both graphs with unweighted and weighted and is especially efficient in large networks.</p><p>• DeepWalk ( <ref type="bibr" target="#b25">Perozzi et al., 2014</ref>): This method employs language models to learn latent relations between the vertices in the graph. The basic assumption is that the closer two vertices are in the embedding space, the deeper relationships they have and there is higher possibility that they are in the same categories.</p><p>• SpectralClustering (Tang and Liu, 2011): This method finds out that graph cuts are use- ful for the classification task. This idea is implemented by finding the eigenvectors of a normalized graph Laplacian of the original graph.</p><p>• EdgeCluster (Tang and Liu, 2009b): This method uses k-means clustering algorithm to segment the edges of the graph into pieces. Then it runs iterations on the small clusters to find the internal relationships separately. The core idea is to scale time-consuming work into tractable sizes.</p><p>• Majority: This baseline method simply chooses the most frequent labels. It does not use any structural information of the graph. † Although LINE also uses networks from Flickr and YouTube in its experiments, the networks are different from this paper.</p><p>As the datasets are not only multi-class but also multi-label, we usually need a thresholding method to test the results. But literature gives a negative opinion of arbitrarily choosing threshold- ing methods because of the considerably different performances. To avoid this, we assume that the number of the labels is already known in all the test processes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>In this section, we present the experimental results and analysis on both network classification and la- tent space learning. We thoroughly evaluate the performance on the three networks and analyze the sensitivity to key parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Classification Task</head><p>We first represent the results on multi-class clas- sification and compare with the baseline methods.</p><p>To have a direct and fair comparison, we use the same data sets, experiment procedures and test- ing points as in the reports of our relevant base- lines ( <ref type="bibr" target="#b25">Perozzi et al., 2014;</ref><ref type="bibr" target="#b29">Tang and Liu, 2011;</ref><ref type="bibr" target="#b28">Tang and Liu, 2009b</ref>). The training set of a spec- ified graph consists of the vertices, the edges and the labels of a certain percentage of labeled ver- tices. The testing set consists of the rest of the la- bels. We employ Macro-F 1 and Micro-F 1 (Yang, 1999) as our measurements. Micro-F 1 computes F 1 score globally while Macro-F 1 caculates F 1 score locally and then average them globally. All the results reported are averaged from 10 repeated processes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">BlogCatalog</head><p>BlogCatalog is the smallest dataset among the three. In BlogCatalog we vary the percentage of labeled data from 10% to 90%. Our results are presented in <ref type="table" target="#tab_2">Table 2</ref>. We can see that DDRW performs consistently better than all the baselines on both Macro-F 1 and Micro-F 1 with the increas- ing percentage of labeled data. When compared with DeepWalk, DDRW obtains larger improve- ment when the percentage of labeled nodes is high. This improvement demonstrates the significance of DDRW on learning discriminative latent em- beddings that are good for classification tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Flickr</head><p>Flickr is a larger dataset with quite a number of classes. In this experiment we vary the percentage of labeled data from 1% to 10%. Our results are presented in <ref type="table" target="#tab_3">Table 3</ref>. We can see that DDRW still performs better than the baselines significantly on both Macro-F 1 and Micro-F 1 , and the results are consistent with what in BlogCatalog.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3">YouTube</head><p>YouTube is an even larger dataset with fewer classes than Flickr. In YouTube we vary the per- centage of labeled data from 1% to 10%. Our re- sults are presented in <ref type="table" target="#tab_4">Table 4</ref>. In YouTube, LINE shows its strength in large sparse networks, proba- bly because the larger scale of samples reduces the discrepancy from actual distributions. But from a general view, DDRW still performs better at most of the test points thanks to the latent representa- tions when links are not sufficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Parameter Sensitivity</head><p>We now present an analysis of the sensitivity with respect to several important parameters. We mea- sure our method with changing parameters to eval- uate its stability. Despite the parameters which are unilateral to classification performance, the two main bidirectional parameters are η and the di- mension d of embedding space in different per- centages of labeled data. We use BlogCatalog and Flickr networks for the experiments, and fix pa- rameters of random walks (τ = 30, s = 40, R = 10). We do not represent the effects of changing parameters of random walks because results usu- ally show unilateral relationships with them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Effect of η</head><p>The key parameter η in our algorithm adjusts the weights of two objectives (Section 3.3). We rep- resent the effect of changing η in <ref type="figure">Figure 3</ref>(a) and 3(b). We fix d = 128 in these experiments. Al- though rapid gliding can be observed on either sides, there are still sufficient value range where DDRW keeps the good performance. These ex- periments also show that η is not very sensitive towards the percentage of labeled data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Effect of Dimensionality</head><p>We represent the effect of changing dimension d of the embedding space in <ref type="figure">Figure 3(c) and 3(d)</ref>. We fix η = 1.0 in these experiments. There is de- cline when the dimension is high, but this decrease is not very sharp. Besides, when the dimension is high, the percentage of labeled data has more ef- fect on the performance.      <ref type="table">Table 5</ref>: Adjacency Predict Accuracy(%) in Blog- Catalog.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Representation Efficiency</head><p>Finally, we examine the quality of the latent em- beddings of entities discovered by DDRW. For network data, our major expectation is that the em- bedded social space should maintain the topologi- cal structure of the network. A visualization of the topological structure in a social space is showed in <ref type="figure">Figure 1</ref>. Besides, we examine the neighborhood structure of the vertices. Specifically, we check the top-K nearest vertices for each vertex in the embedded social space and calculate how many of the vertex pairs have edges between them in the observed network. We call this Adjacency Pre- dict Accuracy. <ref type="table">Table 5</ref> shows the results, where DDRW with different percentages of labeled data, DeepWalk and Random are compared in BlogCat- alog dataset. The baseline method Random maps all the vertices equably randomly into a fixed-size space. The experiments show that although Deep- Walk outperforms on the whole, the performance of DDRW is approximate. DDRW is proved to inherit some important properties in latent repre- sentations of the network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Relational classification <ref type="bibr" target="#b7">(Geman and Geman, 1984;</ref><ref type="bibr" target="#b23">Neville and Jensen, 2000;</ref><ref type="bibr" target="#b8">Getoor and Taskar, 2007</ref>) is a class of methods which in- volve the data item relation links during classi- fication. A number of researchers have studied different methods for network relational learning.</p><p>( <ref type="bibr" target="#b15">Macskassy and Provost, 2003)</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>This paper presents Discriminative Deep Random Walk (DDRW), a novel approach for relational multi-class classification on social networks. By simultaneously optimizing embedding and classi- fication objectives, DDRW gains significantly bet- ter performances in network classification tasks than baseline methods. Experiments on differ- ent real-world datasets represent adequate stabil- ity of DDRW. Furthermore, the representations produced by DDRW is both an intermediate vari- able and a by-product. Same as other embedding methods like DeepWalk, DDRW can provide well- formed inputs for statistical analyses other than classification tasks. DDRW is also naturally an online algorithm and thus easy to parallel. The future work has two main directions. One is semi-supervised learning. The low proportion of labeled vertices is a good platform for semi- supervised learning. Although DDRW has already combined supervised and unsupervised learning together, better performance can be expected after introducing well-developed methods. The other direction is to promote the random walk step. Lit- erature has represented the good combination of random walk and language models, but this com- bination may be unsatisfactory for classification. It would be great if a better form of random walk is found.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: A part of Random Walk process in an undirected graph. Every time an adjacent vertex is chosen randomly (no matter visited or not) as the arrows indicate, until reaching the maximum length s.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Labeled</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>present a simple weighted vote relational neighborhood classifier. (Xu et al., 2008) leverage the nonparametric infi- nite hidden relational model to analyze social net- works. (Neville and Jensen, 2005) propose a la- tent group model for relational data, which dis- covers and exploits the hidden structures respon- sible for the observed autocorrelation among class labels. (Tang and Liu, 2009a) propose the latent social dimensions which are represented as con- tinuous values and allow each node to involve at different dimensions in a flexible manner. (Gal- lagher et al., 2008) propose a method that learn sparsely labeled network data by adding ghost edges between neighbor vertices, and (Lin and Co- hen, 2010) by using PageRank. (Wang and Suk- thankar, 2013) extend the conventional relational classification to consider more additional features. (Gallagher and Eliassi-Rad, 2008) propose a com- plimentary approach to within-network classifica- tion based on the use of label-independent fea- tures. (Henderson et al., 2011) propose a re- gional feature generating method and demonstrate the usage of the regional feature in within-network and across-network classification. (Tang and Liu, 2009b) propose an edge-centric clustering scheme to extract sparse social dimensions for collective behavior prediction. (Tang and Liu, 2011) propose the concept of social dimensions to represent the latent affiliations of the entities. (Vishwanathan et al., 2010) propose Graph Kernels to use rela- tional data during classification process and (Kang et al., 2012) propose a faster approximated method of Graph Kernels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 2 : Multi-class classification results in BlogCatalog.</head><label>2</label><figDesc></figDesc><table>Labeled Nodes 
1% 
2% 
3% 
4% 
5% 
6% 
7% 
8% 
9% 
10% 

Micro-F1(%) 

DDRW 
33.61 35.20 36.72 37.43 38.31 38.89 39.33 39.64 39.85 40.02 
LINE 
31.65 33.98 35.46 36.63 37.53 38.20 38.47 38.74 39.07 39.25 
DeepWalk 
32.40 34.60 35.90 36.70 37.20 37.70 38.10 38.30 38.50 38.70 
SpecClust 
27.43 30.11 31.63 32.69 33.31 33.95 34.46 34.81 35.14 35.41 
EdgeClust 
25.75 28.53 29.14 30.31 30.85 31.53 31.75 31.76 32.19 32.84 
Majority 
16.34 16.31 16.34 16.46 16.65 16.44 16.38 16.62 16.67 16.71 

Macro-F1(%) 

DDRW 
14.49 17.81 20.05 21.40 22.91 23.84 25.12 25.79 26.28 26.43 
LINE 
13.69 17.77 19.88 21.07 22.36 23.62 24.78 25.11 25.69 25.90 
DeepWalk 
14.00 17.30 19.60 21.10 22.10 22.90 23.60 24.10 24.60 25.00 
SpecClust 
13.84 17.49 19.44 20.75 21.60 22.36 23.01 23.36 23.82 24.05 
EdgeClust 
10.52 14.10 15.91 16.72 18.01 18.54 19.54 20.18 20.78 20.85 
Majority 
0.45 
0.44 
0.45 
0.46 
0.47 
0.44 
0.45 
0.47 
0.47 
0.47 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 3 : Multi-class classification results in Flickr.</head><label>3</label><figDesc></figDesc><table>Labeled Nodes 
1% 
2% 
3% 
4% 
5% 
6% 
7% 
8% 
9% 
10% 

Micro-F1(%) 

DDRW 
38.18 39.46 40.17 41.09 41.76 42.31 42.80 43.29 43.81 44.12 
LINE 
38.06 39.36 40.30 41.14 41.58 41.93 42.22 42.67 43.09 43.55 
DeepWalk 
37.95 39.28 40.08 40.78 41.32 41.72 42.12 42.48 42.78 43.05 
SpecClust 
26.61 35.16 37.28 38.35 38.90 39.51 40.02 40.49 40.86 41.13 
EdgeClust 
23.90 31.68 35.53 36.76 37.81 38.63 38.94 39.46 39.92 40.07 
Majority 
24.90 24.84 25.25 25.23 25.22 25.33 25.31 25.34 25.38 25.38 

Macro-F1(%) 

DDRW 
29.35 32.07 33.56 34.41 34.89 35.38 35.80 36.15 36.36 36.72 
LINE 
27.36 31.08 32.51 33.39 34.26 34.81 35.27 35.52 35.95 36.14 
DeepWalk 
29.22 31.83 33.06 33.90 34.35 34.66 34.96 35.22 35.42 35.67 
SpecClust 
24.62 29.33 31.30 32.48 33.24 33.89 34.15 34.47 34.77 34.98 
EdgeClust 
19.48 25.01 28.15 29.17 29.82 30.65 30.75 31.23 31.45 31.54 
Majority 
6.12 
5.86 
6.21 
6.10 
6.07 
6.19 
6.17 
6.16 
6.18 
6.19 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Multi-class classification results in YouTube. 

1010 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The work was supported by the National Ba-</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Friends and neighbors on the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eytan</forename><surname>Adamic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social Networks</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="211" to="230" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Local graph partitioning using pagerank vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reid</forename><surname>Andersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><forename type="middle">J</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Foundations of Computer Science</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="476" to="486" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">On the algorithmic implementation of multiclass kernel-based vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="265" to="292" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">LIBLINEAR: A library for large linear classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Wei</forename><surname>Rong-En Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho-Jui</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangrui</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Jen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1871" to="1874" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Random-walk computation of similarities between nodes of a graph with application to collaborative recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Fouss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alain</forename><surname>Pirotte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Michel</forename><surname>Renders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Saerens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="355" to="369" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Leveraging label-independent features for classification in sparsely labeled networks: An empirical study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tina</forename><surname>Eliassi-Rad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second International Conference on Advances in Social Network Mining and Analysis</title>
		<meeting>the Second International Conference on Advances in Social Network Mining and Analysis</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Using ghost edges for classification in sparsely labeled networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanghang</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tina</forename><surname>Eliassi-Rad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Faloutsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="256" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Stochastic relaxation, gibbs distributions, and the bayesian restoration of images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stuart</forename><surname>Geman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><surname>Geman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="721" to="741" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Introduction to statistical relational learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lise</forename><surname>Getoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Taskar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">It&apos;s who you know: graph mining using recursive structural features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leman</forename><surname>Akoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tina</forename><surname>Eliassi-Rad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanghang</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Faloutsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="663" to="671" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Improving neural networks by preventing co-adaptation of feature detectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<idno>abs/1207.0580</idno>
		<imprint>
			<date type="published" when="2012" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
	<note>Ilya Sutskever, and Ruslan Salakhutdinov</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Latent space approaches to social network analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrian</forename><forename type="middle">E</forename><surname>Hoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><forename type="middle">S</forename><surname>Raftery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Handcock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="1090" to="1098" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Fast random walk graph kernel</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanghang</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimeng</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SDM</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="828" to="838" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Semisupervised classification of network data using very few labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 International Conference on Advances in Social Networks Analysis and Mining</title>
		<meeting>the 2010 International Conference on Advances in Social Networks Analysis and Mining</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="192" to="199" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">An information flow model for conflict and fission in small groups</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sofus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Foster</forename><forename type="middle">J</forename><surname>Macskassy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Provost</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Anthropological Research</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="452" to="473" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A simple relational classifier</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sofus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Foster</forename><surname>Macskassy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Provost</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the MultiRelational Data Mining Workshop at the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the MultiRelational Data Mining Workshop at the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Classification in networked data: A toolkit and a univariate case study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sofus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Foster</forename><forename type="middle">J</forename><surname>Macskassy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Provost</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="935" to="983" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Supervised dictionary learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Ponce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillermo</forename><surname>Sapiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><forename type="middle">R</forename><surname>Bach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1033" to="1040" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Stochastic gradient learning in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Neuro-NˆımesNˆımes 91</title>
		<meeting>Neuro-NˆımesNˆımes 91</meeting>
		<imprint>
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A scalable hierarchical distributed language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1081" to="1088" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Hierarchical probabilistic neural network language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederic</forename><surname>Morin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Workshop on Artificial Intelligence and Statistics</title>
		<meeting>the International Workshop on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="246" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Iterative classification in relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Neville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Jensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI-2000 Workshop on Learning Statistical Models from Relational Data</title>
		<meeting>AAAI-2000 Workshop on Learning Statistical Models from Relational Data</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="13" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Leveraging relational autocorrelation with latent group models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Neville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Jensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th International Workshop on Multi-relational Mining</title>
		<meeting>the 4th International Workshop on Multi-relational Mining</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="49" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">DeepWalk: online learning of social representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="701" to="710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Anomaly detection in online social networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Savage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiuzhen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinghuo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pauline</forename><forename type="middle">Lienhua</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingmai</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social Networks</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="62" to="70" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Relational learning via latent social dimensions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="817" to="826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Scalable learning of collective behavior based on sparse social dimensions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th ACM Conference on Information and Knowledge Management</title>
		<meeting>the 18th ACM Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1107" to="1116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Leveraging social media networks for classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="447" to="478" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">LINE: Large-scale information network embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingzhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaozhu</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on World Wide Web</title>
		<meeting>the 24th International Conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1067" to="1077" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Graph kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">V N</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicol</forename><forename type="middle">N</forename><surname>Schraudolph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Risi</forename><surname>Kondor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karsten</forename><forename type="middle">M</forename><surname>Borgwardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1201" to="1242" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Multi-label relational neighbor classification using social context features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gita</forename><surname>Sukthankar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="464" to="472" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Nonparametric relational learning for social network analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volker</forename><surname>Tresp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shipeng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the 2nd SNA-KDD Workshop on Social Network Mining and Analysis</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Network representation learning with rich text information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deli</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><forename type="middle">Y</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 24th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2111" to="2117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">An evaluation of statistical approaches to text categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="69" to="90" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">MedLDA: maximum margin supervised topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amr</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="2237" to="2278" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Max-margin nonparametric latent feature models for link prediction</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th International Conference on Machine Learning</title>
		<meeting>the 29th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="719" to="726" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
