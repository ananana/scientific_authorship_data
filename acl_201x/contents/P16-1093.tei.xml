<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:41+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A CALL System for Learning Preposition Usage</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>August 7-12, 2016. 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lee</surname></persName>
							<email>jsylee@cityu.edu.hk</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Linguistics and Translation City</orgName>
								<orgName type="department" key="dep2">Fairbank Center for Chinese Studies</orgName>
								<orgName type="department" key="dep3">Department of Linguistics and Translation City</orgName>
								<orgName type="institution" key="instit1">University of Hong Kong</orgName>
								<orgName type="institution" key="instit2">Harvard University</orgName>
								<orgName type="institution" key="instit3">University of Hong Kong</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><surname>Sturgeon</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Linguistics and Translation City</orgName>
								<orgName type="department" key="dep2">Fairbank Center for Chinese Studies</orgName>
								<orgName type="department" key="dep3">Department of Linguistics and Translation City</orgName>
								<orgName type="institution" key="instit1">University of Hong Kong</orgName>
								<orgName type="institution" key="instit2">Harvard University</orgName>
								<orgName type="institution" key="instit3">University of Hong Kong</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengqi</forename><surname>Luo</surname></persName>
							<email>mengqluo@cityu.edu.hk</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Linguistics and Translation City</orgName>
								<orgName type="department" key="dep2">Fairbank Center for Chinese Studies</orgName>
								<orgName type="department" key="dep3">Department of Linguistics and Translation City</orgName>
								<orgName type="institution" key="instit1">University of Hong Kong</orgName>
								<orgName type="institution" key="instit2">Harvard University</orgName>
								<orgName type="institution" key="instit3">University of Hong Kong</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A CALL System for Learning Preposition Usage</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="984" to="993"/>
							<date type="published">August 7-12, 2016. 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Fill-in-the-blank items are commonly featured in computer-assisted language learning (CALL) systems. An item displays a sentence with a blank, and often proposes a number of choices for filling it. These choices should include one correct answer and several plausible distractors. We describe a system that, given an English corpus , automatically generates distractors to produce items for preposition usage. We report a comprehensive evaluation on this system, involving both experts and learners. First, we analyze the difficulty levels of machine-generated carrier sentences and distractors, comparing several methods that exploit learner error and learner revision patterns. We show that the quality of machine-generated items approaches that of human-crafted ones. Further , we investigate the extent to which mismatched L1 between the user and the learner corpora affects the quality of dis-tractors. Finally, we measure the system&apos;s impact on the user&apos;s language proficiency in both the short and the long term.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Fill-in-the-blank items, also known as gap-fill or cloze items, are a common form of exercise in computer-assisted language learning (CALL) ap- plications. <ref type="table">Table 1</ref> shows an example item de- signed for teaching English preposition usage. It contains a sentence, "The objective is to kick the ball into the opponent's goal", with the preposi- tion "into" blanked out; this sentence serves as the stem (or carrier sentence). It is followed by four choices for the blank, one of which is the key (i.e., the correct answer), and the other three are dis- tractors. These choices enable the CALL applica- tion to provide immediate and objective feedback to the learner.</p><p>A high-quality item must meet multiple re- quirements. It should have a stem that is fluent and matches the reading ability of the learner; a blank that is appropriate for the intended peda- gogical goal; exactly one correct answer among the choices offered; and finally, a number of dis- tractors that seem plausible to the learner, and yet would each yield an incorrect sentence. Relying on language teachers to author these items is time consuming. Automatic generation of these items would not only expedite item authoring, but also potentially provide personalized items to suit the needs of individual learners. This paper addresses two research topics:</p><p>• How do machine-generated items compare with human-crafted items in terms of their quality?</p><p>• Do these items help improve the users' lan- guage proficiency?</p><p>For the first question, we focus on automatic generation of preposition distractors, comparing three different methods for distractor generation. One is based on word co-occurrence in standard</p><p>The objective is to kick the ball the opponent's goal. (A) in (B) into (C) to (D) with <ref type="table">Table 1</ref>: An automatically generated fill-in-the- blank item, where "into" is the key, and the other three choices are distractors. corpora; a second leverages error annotations in learner corpora; the third, a novel method, exploits learners' revision behavior. Further, we investi- gate the effect of tailoring distractors to the user's native language (L1). For the second question, we measure users' performance in the short and in the long term, through an experiment involving ten subjects, in multiple sessions tailored to their proficiency and areas of weakness.</p><p>Although a previous study has shown that learner error statistics can produce competitive items for prepositions on a narrow domain ( <ref type="bibr" target="#b12">Lee and Seneff, 2007)</ref>, a number of research questions still await further investigation. Through both expert and learner evaluation, we will compare the quality of carrier sentences and the plausibil- ity of automatically generated distractors against human-crafted ones. Further, we will measure the effect of mismatched L1 between the user and the learner corpora, and the short-and long-term im- pact on the user's preposition proficiency. To the best of our knowledge, this paper offers the most detailed evaluation to-date covering all these as- pects.</p><p>The rest of the paper is organized as follows. Section 2 reviews previous work. Section 3 out- lines the algorithms for generating the fill-in-the- blank items. Section 4 gives details about the ex- perimental setup and evaluation procedures. Sec- tion 5 analyzes the results. Section 6 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Previous Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Distractor generation</head><p>Most research effort on automatic generation of fill-in-the-blank items has focused on vocabulary learning. In these items, the key is typically from an open-class part-of-speech (POS), e.g., nouns, verbs, or adjectives.</p><p>To ensure that the distractor results in an incor- rect sentence, the distractor must rarely, or never, collocate with other words in the carrier sen- tence ( <ref type="bibr" target="#b16">Liu et al., 2005</ref>). To ensure the plausibility of the distractor, most approaches require it to be semantically close to the key, as determined by a thesaurus ( <ref type="bibr" target="#b22">Sumita et al., 2005;</ref><ref type="bibr" target="#b21">Smith et al., 2010)</ref>, an ontology ( <ref type="bibr" target="#b10">Karamanis et al., 2006</ref>), rules hand- crafted by experts ( <ref type="bibr" target="#b2">Chen et al., 2006</ref>), or context- sensitive inference rules <ref type="bibr" target="#b25">(Zesch and Melamud, 2014)</ref>; or to have similar word frequency <ref type="bibr" target="#b20">(Shei, 2001;</ref><ref type="bibr" target="#b0">Brown et al., 2005</ref>). <ref type="bibr" target="#b19">Sakaguchi et al. (2013)</ref> applied machine learning methods to select verb distractors, and showed that they resulted in items that can better predict the user's English profi- ciency level.</p><p>Less attention has been paid to items for closed- class POS, such as articles, conjunctions and prepositions, which learners also often find dif- ficult ( <ref type="bibr" target="#b3">Dahlmeier et al., 2013)</ref>. For these POS, the standard algorithms based on semantic relat- edness for open-class POS are not applicable. <ref type="bibr" target="#b12">Lee and Seneff (2007)</ref> reported the only previous study on using learner corpora to generate items for a closed-class POS. They harvested the most fre- quent preposition errors in a corpus of Japanese learners of English ( <ref type="bibr" target="#b9">Izumi et al., 2003</ref>), but per- formed an empirical evaluation with native Chi- nese speakers on a narrow domain.</p><p>We expand on this study in several dimensions. First, carrier sentences, selected from the general domain rather than a specific one, will be analyzed in terms of their difficulty level. Second, distrac- tor quality will be evaluated not only by learners but also by experts, who give scores based on their plausibility; in contrast to most previous studies, their quality will be compared with the human gold standard. Thirdly, the effect of mismatched L1 will also be measured.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Learner error correction</head><p>There has been much recent research on auto- matic correction of grammatical errors. Correc- tion of preposition usage errors, in particular, has received much attention. Our task can be viewed as the inverse of error correction -ensuring that the distractor yields an incorrect sentence -with the additional requirement on the plausibility of the distractor.</p><p>Most approaches in automatic grammar correc- tion can be classified as one of three types, ac- cording to the kind of statistics on which the sys- tem is trained. Some systems are trained on ex- amples of correct usage <ref type="bibr" target="#b23">(Tetreault and Chodorow, 2008;</ref><ref type="bibr" target="#b5">Felice and Pulman, 2009)</ref>. Others are trained on examples of pairs of correct and incor- rect usage, either retrieved from error-annotated learner corpora ( <ref type="bibr" target="#b8">Han et al., 2010;</ref><ref type="bibr" target="#b3">Dahlmeier et al., 2013</ref>) or simulated ( <ref type="bibr" target="#b13">Lee and Seneff, 2008;</ref><ref type="bibr" target="#b6">Foster and Andersen, 2009)</ref>. More recently, a sys- tem has been trained on revision statistics from Wikipedia ( <ref type="bibr" target="#b1">Cahill et al., 2013)</ref>. We build on all three paradigms, using standard English cor-... kick the ball into the opponent's goal VP head prep obj prep pobj <ref type="figure">Figure 1</ref>: Parse tree for the carrier sentence in Ta- ble 1. Distractors are generated on the basis of the prepositional object ("obj") and the NP/VP head to which the prepositional phrase is attached (Sec- tion 3).</p><p>pora (Section 3.1), error-annotated learner corpora (Section 3.2) and learner revision corpora (Sec- tion 3.3) as resources to predict the most plausible distractors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Item generation</head><p>The system assumes as input a set of English sen- tences, which are to serve as candidates for carrier sentences. In each candidate sentence, the system scans for prepositions, and extracts two features from the linguistic context of each preposition:</p><p>• The prepositional object. In <ref type="figure">Figure 1</ref>, for example, the word "goal" is the prepositional object of the key, "into".</p><p>• The head of the noun phrase or verb phrase (NP/VP head) to which the prepositional phrase (PP) is attached. In <ref type="figure">Figure 1</ref>, the PP "into the opponent's goal" is attached to the VP head "kick".</p><p>The system passes these two features to the following methods to generate distractors. 1 If all three methods are able to return a distractor, the preposition qualifies to serve as the key. If more than one key is found, the system randomly chooses one of them.</p><p>In the rest of this paper, we will sometimes ab- breviate these three methods as the "Co-occur" (Section 3.1), "Error" (Section 3.2), and "Revi- sion" (Section 3.3) methods, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Co-occurrence method</head><p>Proposed by <ref type="bibr" target="#b12">Lee and Seneff (2007)</ref>, this method requires co-occurrence statistics from a large cor- pus of well-formed English sentences.</p><p>Co-occurrence method ("Co-occur") ... kicked the chair with ... ... kicked the can with ... ... with the goal of ... Learner error method ("Error") ... kicked it &lt;error&gt;in&lt;/error&gt; the goal. ... kick the ball &lt;error&gt;in&lt;/error&gt; the other team's goal. Learner revision method ("Revision") ... kick the ball to into his own goal. ... kick the ball to towards his own goal. <ref type="table">Table 2</ref>: The Co-occurrence Method (Section 3.1) generates "with" as the distractor for the carrier sentence in <ref type="figure">Figure 1</ref>; the Learner Error Method (Section 3.2) generates "in"; the Learner Revision Method (Section 3.3) generates "to".</p><p>This method first retrieves all prepositions that co-occur with both the prepositional object and the NP/VP head in the carrier sentence. These prepo- sitions are removed from consideration as distrac- tors, since they would likely yield a correct sen- tence. The remaining candidates are those that co- occur with either the prepositional object or the NP/VP head, but not both. The more frequently the candidate co-occurs with either of these words, the more plausible it is expected to appear to a learner. Thus, the candidate with the highest co- occurrence frequency is chosen as the distractor. As shown in <ref type="table">Table 2</ref>, this method generates the distractor "with" for the carrier sentence in <ref type="figure">Fig- ure 1</ref>, since many instances of "kick ... with" and "with ... goal" are attested.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Learner error method</head><p>This method requires examples of English sen- tences from an error-annotated learner corpus. The corpus must mark wrong preposition usage, but does not need to provide corrections for the errors.</p><p>This method first retrieves all PPs that have the given prepositional object and are attached to the given NP/VP head. It then computes the frequency of prepositions that head these PPs and are marked as wrong. The one that is most frequently marked as wrong is chosen as the distractor. As shown in <ref type="table">Table 2</ref>, this method generates the distractor "in" for the carrier sentence in <ref type="figure">Figure 1</ref>, since it is often marked as an error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Learner revision method</head><p>It is expensive and time consuming to annotate learner errors. As an alternative, we exploit the revision behavior of learners in their English writ- ing. This method requires draft versions of texts written by learners. In order to compute statis- tics on how often a preposition in an earlier draft ("draft n") is replaced with another one in the later draft ("draft n + 1"), the sentences in successive drafts must be sentence-and word-aligned.</p><p>This method scans for PPs that have the given prepositional object and are attached to the given NP/VP head. For all learner sentences in draft n that contain these PPs, it consults the sentences in draft n+1 to which they are aligned; it retains only those sentences whose prepositional object and the NP/VP head remain unchanged, but whose prepo- sition has been replaced by another one. Among these sentences, the method selects the preposition that is most frequently edited between two drafts. Our assumption is that frequent editing implies a degree of uncertainty on the part of the learner as to which of these prepositions is in fact correct, thus suggesting that they may be effective distrac- tors. As shown in <ref type="table">Table 2</ref>, this method generates the distractor "to" for the carrier sentence in <ref type="figure">Fig- ure 1</ref>, since it is most often edited in the given lin- guistic context. This study is the first to exploit a corpus of learner revision history for item genera- tion. <ref type="bibr">2</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental setup</head><p>In this section, we first describe our datasets (Sec- tion 4.1) and the procedure for item generation (Section 4.2). We then give details on the expert evaluation (Section 4.3) and the learner evaluation (Section 4.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data</head><p>Carrier sentences. We used sentences in the English portion of the Wikicorpus ( <ref type="bibr" target="#b18">Reese et al., 2010)</ref> as carrier sentences. To avoid selecting stems with overly difficult vocabulary, we ranked the sentences in terms of their most difficult word. We measured the difficulty level of a word firstly with the graded English vocabulary lists com- piled by the Hong Kong Education Bureau (EDB, 2012); and secondly, for words not occurring in any of these lists, with frequency counts derived from the Google Web Trillion Word Corpus. <ref type="bibr">3</ref> In order to retrieve the prepositional object and the NP/VP head (cf. Section 3), we parsed the Wiki- corpus, as well as the corpora mentioned below, with the Stanford parser ( <ref type="bibr" target="#b17">Manning et al., 2014</ref>).</p><p>Co-occurrence method ("Co-occur"). The statistics for the Co-occurrence method were also based on the English portion of Wikicorpus.</p><p>Learner Revision method ("Revision"). We used an 8-million-word corpus of essay drafts written by Chinese learners of English ( <ref type="bibr" target="#b15">Lee et al., 2015)</ref>. This corpus contains over 4,000 essays, with an average of 2.7 drafts per essay. The sen- tences and words between successive drafts have been automatically aligned.</p><p>Learner Error method ("Error"). In addition to the corpus of essay drafts mentioned above, we used two other error-annotated learner corpora. The NUS Corpus of Learner English (NUCLE) contains one million words of academic writing by students at the National University of Singa- pore ( <ref type="bibr" target="#b3">Dahlmeier et al., 2013</ref>). The EF-Cambridge Open Language Database (EFCAMDAT) contains over 70 million words from 1.2 million assign- ments written by learners from a variety of lin- guistic background <ref type="bibr" target="#b7">(Geertzen et al., 2013)</ref>. A sub- set of the database has been error-annotated. We made use of the writings in this subset that were produced by students from China and Russia.</p><p>Human items ("Textbook"). To provide a com- parison with human-authored items, we used the practise tests for preposition usage offered in an English exercise book designed for intermediate and advanced learners <ref type="bibr" target="#b24">(Watcyn-Jones and Allsop, 2000</ref>). From the 50 tests in a variety of for- mats, we harvested 56 multiple-choice items, all of which had one key and three distractors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Item generation procedure</head><p>We gathered three sets of 400 carrier sentences, for use in three evaluation sessions (see Section 4.4). Each sentence in Set 1 has one counterpart in Set 2 and one counterpart in Set 3 that have the same key, NP/VP head and prepositional object. We will refer to the items created from these counterpart carrier sentences as "similar" items. We will use these "similar" items to measure the learning im- pact on the subjects.</p><p>Each item has one key and distractors generated by each of the three methods. For about half of the items, the three methods complemented one an- other to offer three distinct distractors. In the other half, two of the methods yielded the same dis- tractor, resulting in only two distractors for those items. In Set 1, for control purposes, 56 of the items were replaced with the human items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Expert evaluation procedure</head><p>Two professional English teachers (henceforth, the "experts") examined each of the 400 items in Set 1. They annotated each item, and each choice in the item, as follows.</p><p>For each item, the experts labeled its diffi- culty level in terms of the preposition usage be- ing tested in the carrier sentence. They did not know whether the item was human-authored or machine-generated. Based on their experience in teaching English to native speakers of Chi- nese, they labeled each item as suitable for those in "Grades 1-3", "Grades 4-6", "Grades 7-9", "Grades 10-12", or "&gt;Grade 12". We mapped these five categories to integers -2, 5, 8, 11 and 13, respectively -for the purpose of calculating difficulty scores.</p><p>For each choice in the item, the experts judged whether it is correct or incorrect. They did not know whether each choice was the key or a dis- tractor. They may judge one, multiple, or none of the choices as correct. For an incorrect choice, they further assessed its plausibility as a distractor, again from their experience in teaching English to native speakers of Chinese. They may label it as "Plausible", "Somewhat plausible", or "Obviously wrong".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Learner evaluation procedure</head><p>Ten university students (henceforth, the "learn- ers") took part in the evaluation. They were all native Chinese speakers who did not major in En- glish. The evaluation consisted of three one-hour sessions held on different days. At each session, the learner attempted 80 items on a browser-based application <ref type="figure" target="#fig_0">(Figure 2</ref>). The items were distributed in these sessions as follows.</p><p>Session 1. The 400 items in Set 1 were divided into 5 groups of 80 items, with 11 to 12 human items in each group. The items in each group had comparable difficulty levels as determined by the experts, with average scores ranging from 7.9 to 8.1. Each group was independently attempted by two learners. The system recorded the items to which the learner gave wrong answers; these will be referred to as the "wrong items". Among the items to which the learner gave correct answers, the system randomly set aside 10 items; these will be referred to as "control items". Session 2. To measure the short-term impact, Session 2 was held on the day following Session 1. Each learner attempted 80 items, drawn from Set 2. These items were personalized according to the "wrong items" of the individual learner. For exam- ple, if a learner had 15 "wrong items" from Ses- sion 1, he or she then received 15 similar items <ref type="bibr">4</ref> from Set 2. In addition, he or she also received ten items that were similar to the "control items" from Session 1. The remaining items were drawn randomly from Set 2. As in Session 1, the system noted the "wrong items" and set aside ten "control items". Session 3. To test the long-term effect of these exercises, Session 3 was held two weeks after Ses- sion 2. Each learner attempted another 80 items, drawn from Set 3. These 80 items were chosen in the same manner as in Session 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>We first report inter-annotator agreement between the two experts on the difficulty levels of the car- rier sentences and the distractors (Section 5.1). We then compare the difficulty levels of the human- and machine-generated items <ref type="bibr">(Section 5.2)</ref>. Next, we analyze the reliability and difficulty 5 of the automatically generated distractors (Sections 5.3 and 5.4), and the role of the native language (Sec- tion 5.5). Finally, we measure the impact on the learners' preposition proficiency (Section 5.6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Inter-annotator agreement</head><p>For estimating the difficulty level of the prepo- sition usage in the carrier sentences, the experts reached "substantial" agreement with kappa at 0.765 <ref type="bibr" target="#b11">(Landis and Koch, 1977)</ref>. In deciding whether a choice is correct or incorrect, the experts reached "almost perfect" agreement with kappa at 0.977. On the plausibility of the distractors, they reached "moderate" agreement with kappa at 0.537. The main confusion was between the cate- gories "Obviously wrong" and "Somewhat plausi- ble".</p><p>On the whole, expert judgment tended to cor- relate with actual behavior of the learners. For distractors considered "Plausible" by both experts, 63.6% were selected by the learners. In contrast, for those considered "Obviously wrong" by both experts, only 11.8% attracted any learner. <ref type="figure" target="#fig_1">Figure 3</ref> shows the distribution of difficulty level scores for the preposition usage in carrier sen- tences. Most items were rated as "Grades 7-9", with "Grades 4-6" being the second largest group.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Carrier sentence difficulty</head><p>A common concern over machine-generated items is whether the machine can create or select the kind of carrier sentences that illustrate chal- lenging or advanced preposition usage, compared to those crafted by humans. In our system, the preposition errors and revisions in the learner cor- pora -as captured by the NP/VP head and the assessment purposes ( <ref type="bibr" target="#b0">Brown et al., 2005;</ref><ref type="bibr" target="#b19">Sakaguchi et al., 2013</ref>) rather than self-learning. prepositional object -effectively served as the filter for selecting carrier sentences. Some of these errors and revisions may well be careless or triv- ial mistakes, and may not necessarily lead to the selection of appropriate carrier sentences.</p><p>To answer this question, we compared the diffi- culty levels of preposition usage in the machine- generated and human-crafted items. The aver- age difficulty score for the human items was 8.7, meaning they were suitable for those in Grade 8. The average for the machine-generated items were lower, at 7.2. This result suggests that our system can select carrier sentences that illustrate challeng- ing preposition usage, at a level that is only about 1.5 grade points below those designed by humans.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Distractor reliability</head><p>A second common concern over machine- generated items is whether their distractors might yield correct sentences. When taken out of con- text, a carrier sentence often admits multiple pos- sible answers <ref type="bibr" target="#b23">(Tetreault and Chodorow, 2008;</ref><ref type="bibr" target="#b14">Lee et al., 2009)</ref>. In this section, we compare the per- formance of the automatic distractor generation methods against humans.</p><p>A distractor is called "reliable" if it yields an incorrect sentence. The Learner Revision method generated the most reliable distractors 6 ; on aver- age, 97.4% of the distractors were judged incor- rect by both experts <ref type="table">(Table 3)</ref>. The Co-occurrence method ranked second at 96.1%, slightly better than those from the Learner Error method. Many distractors from the Learner Error method indeed led to incorrect sentences in their original con- texts, but became acceptable when their carrier sentences were read in isolation. Items with un- reliable distractors were excluded from the learner evaluation.</p><p>Surprisingly, both the Learner Revision and Co- occurrence methods outperformed the humans. Distractors in some of the human items did in- deed yield sentences that were technically correct, and were therefore deemed "unreliable" by the ex- perts. In many cases, however, these distractors were accompanied with keys that provided more natural choices. These items, therefore, remained valid.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reliable distractor</head><p>Co-occur 96.1% Error 95.6% Revision 97.4% Textbook 95.8% <ref type="table">Table 3</ref>: Distractors judged reliable by both ex- perts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Distractor difficulty</head><p>In the context of language learning, an item can be considered more useful if one of its distractors elicits a wrong choice from the learner, who would then receive corrective feedback. In this section, we compare the "difficulty" of the distractor gen- erated by the various methods, in terms of their ability to attract the learners. Expert evaluation. The two methods based on learner statistics produced the highest-quality dis- tractors <ref type="table">(Table 4</ref>). The Learner Error method had the highest rate of plausible distractors (51.2%) and the lowest rate of obviously wrong ones (22.0%). In terms of the number of distractors considered "Plausible", this method significantly outperformed the Learner Revision method. <ref type="bibr">7</ref> According to <ref type="table">Table 4</ref>, all three automatic meth- ods outperformed the humans in terms of the num- ber of distractors rated "Plausible". This compari- son, however, is not entirely fair, since the human items always supplied three distractors, whereas about half of the machine-generated items sup- plied only two, when two of the methods returned the same distractor.</p><p>An alternate metric is to compute the average number of distractors rated "Plausible" per item. On average, the human items had 0.91 plausible distractors; in comparison, the machine-generated items had 1.27. This result suggests that automatic generation of preposition distractors can perform at the human level.</p><p>Learner evaluation. The most direct way to evaluate the difficulty of a distractor is to mea- sure how often a learner chose it. The contrast is less clear cut in this evaluation. Overall, the learners correctly answered 76.2% of the machine- generated items, and 75.5% of the human items, suggesting that the human distractors were more challenging. One must also take into account, however, the fact that the carrier sentences are 7 p &lt; 0.05 by McNemar's test, for both expert annotators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Plausible  <ref type="table">Table 4</ref>: Plausibility judgment of distractors by ex- perts.</p><p>more difficult in the human items than in the machine-generated ones. Broadly speaking, the machine-generated distractors were almost as suc- cessful as those authored by humans. Consistent with the experts' opinion <ref type="table">(Table 4)</ref>, the Learner Error method was most successful among the three automatic methods ( <ref type="table" target="#tab_2">Table 5</ref>). The learner selection rate of its distractors was 13.5%, which was significantly higher 8 than its closest competitor, the Learner Revision method, at 9.5%. The Co-occurrence method ranked last, at 9.2%. It is unfortunately difficult to directly compare these rates with that of the human distractors, which they were offered in different carrier sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Impact of L1</head><p>We now turn our attention to the relation between the native language (L1) of the user, and that of the learner corpora used for training the system. Specifically, we wish to measure the gain, if any, in matching the L1 of the user with the L1 of the learner corpora. To this end, for the Learner Er- ror method, we generated distractors from the EF- Cambridge corpus with two sets of statistics: one harvested from the portion of the corpus with writ- ings by Chinese students, the others from the por- tion by Russian students.</p><p>Expert evaluation.   <ref type="table" target="#tab_1">Table 6</ref>: Plausibility judgment of distractors gen- erated from the Chinese and Russian portions of the EF-Cambridge corpus, by experts.</p><p>slightly more likely to be rated "plausible" than the Russian ones, and less likely to be rated "ob- viously wrong". <ref type="bibr">9</ref> The gap between the two sets of distractors was smaller than may be expected.</p><p>Learner evaluation. The difference was some- what more pronounced in terms of the learners' behavior. The learners selected Chinese distrac- tors, which matched their L1, 29.9% of the time over the three sessions. In contrast, they fell for the Russian distractors, which did not match their L1, only 25.1% of the time. This result confirms the intuition that matching L1 improves the plau- sibility of the distractors, but the difference was nonetheless relatively small. This result suggets that it might be worth paying the price for mis- matched L1s, in return for a much larger pool of learner statistics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Impact on learners</head><p>In this section, we consider the impact of these ex- ercises on the learners. The performance of the learners was rather stable across all sessions; their average scores in the three sessions were 73.0%, 73.6% and 69.9%, respectively. It is difficult, how- ever, to judge from these scores whether the learn- ers benefited from the exercises, since the compo- sition of the items differed for each session.</p><p>Instead, we measured how often the learners re- tain the system feedback. More specifically, if the learner chose a distractor and received feedback (cf. <ref type="figure" target="#fig_0">Figure 2)</ref>, how likely would he or she suc- ceed in choosing the key in a "similar" 10 item in a subsequent session.</p><p>We compared the learners' responses between Sessions 1 and 2 to measure the short-term impact, and between Sessions 2 and 3 to measure the long- term impact. In Session 2, when the learners at- 9 Data sparseness prevented us from generating both Chi- nese and Russian distractors for the same carrier sentences for evaluation. These statistics are therefore not controlled with regard to the difficulty level of the sentences. <ref type="bibr">10</ref> See definition of "similar" in Section 4.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Difficulty level Retention rate</head><p>Below 6 74.0% 6-8 71.3% 9-11 60.0% 12 or above 25% <ref type="table">Table 7</ref>: Retention rate for items at different levels of difficulty.</p><p>tempted items that were "similar" to their "wrong items" from Session 1, they succeeded in choos- ing the key in 72.4% of the cases. <ref type="bibr">11</ref> We refer to this figure as the "retention rate", in this case over the one-day period between the two sessions. The retention rate deteriorated over a longer term. In Session 3, when the learners attempted items that were "similar" to their "wrong items" from Ses- sion 2, which took place two weeks before, they succeeded only in 61.5% of the cases. <ref type="bibr">12</ref> Further, we analyzed whether the difficulty level of the items affected their retention rate. Statistics in <ref type="table">Table 7</ref> show that the rate varied widely according to the difficulty level of the "wrong items". Difficult items, at Grade 12 or beyond, proved hardest to learn, with a retention rate of only 25%. At the other end of the spec- trum, those below Grade 6 were retained 74% of the time. This points to the need for the system to reinforce difficult items more frequently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>We have presented a computer-assisted language learning (CALL) system that automatically cre- ates fill-in-the-blank items for prepositions. We found that the preposition usage tested in au- tomatically selected carrier sentences were only slightly less challenging than those crafted by hu- mans. We compared the performance of three methods for distractor generation, including a novel method that exploits learner revision statis- tics. The method based on learner error statistics yielded the most plausible distractors, followed by the one based on learner revision statistics. The items produced jointly by these automatic meth- ods, in both expert and learner evaluations, ri- valled the quality of human-authored items. Fur- ther, we evaluated the extent to which mismatched native language (L1) affects distractor plausibility. Finally, in a study on the short-and long-term im- pact on the learners, we showed that difficult items had lower retention rate. In future work, we plan to conduct larger-scale evaluations to further vali- date these results, and to apply these methods on other common learner errors.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Interface for the learner evaluation. On the left, the learner selects a choice by tapping on it; on the right, the learner receives feedback.</figDesc><graphic url="image-1.png" coords="5,307.28,62.81,218.27,149.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The difficulty level of the items in Set 1, as annotated by the experts.</figDesc><graphic url="image-2.png" coords="6,72.00,62.81,218.27,131.14" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 6 contrasts</head><label>6</label><figDesc></figDesc><table>the ex-
perts' plausibility judgment on distractors gener-
ated from these two sets. Chinese distractors were 

8 p &lt; 0.05 by McNemar's test. 

Method Learner selection rate 
Co-occur 
9.2% 
Error 
13.5% 
Revision 
9.5% 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Percentage of distractors selected by 
learners. </table></figure>

			<note place="foot" n="1"> We do not consider errors where a preposition should be inserted or deleted.</note>

			<note place="foot" n="2"> A similar approach, using revision statistics in Wikipedia, has been used for the purpose of correcting preposition errors (Cahill et al., 2013).</note>

			<note place="foot" n="3"> http://norvig.com/ngrams/</note>

			<note place="foot" n="4"> See definition of &quot;similar&quot; in Section 4.2. 5 Another metric, &quot;validity&quot;, measures the ability of the distractor to discriminate between students of different proficiency levels. This metric is relevant for items intended for</note>

			<note place="foot" n="6"> The difference with the Co-occurrence method is not statistically significant, in part due to the small sample size.</note>

			<note place="foot" n="11"> As a control, the retention rate for correctly answered items in Session 1 was 80% in Session 2. 12 As a control, the retention rate for correctly answered items in Session 2 was 69.0% in Session 3.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank NetDragon Websoft Holding Limited for their assistance with system evaluation, and the reviewers for their very helpful comments. This work was partially supported by an Applied Re-search Grant (Project no. 9667115) from City University of Hong Kong.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Automatic Question Generation for Vocabulary Assessment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">C</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gwen</forename><forename type="middle">A</forename><surname>Frishkoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxine</forename><surname>Eskenazi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. HLT-EMNLP</title>
		<meeting>HLT-EMNLP</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Robust Systems for Preposition Error Correction using Wikipedia Revisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aoife</forename><surname>Cahill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitin</forename><surname>Madnani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Tetreault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><surname>Napolitano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">FAST: An Automatic Generation System for Grammar Tests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chia-Yin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsien-Chin</forename><surname>Liou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><forename type="middle">S</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. COLING/ACL Interactive Presentation Sessions</title>
		<meeting>COLING/ACL Interactive Presentation Sessions</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Building a Large Annotated Corpus of Learner English: The NUS Corpus of Learner English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Dahlmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee</forename><forename type="middle">Tou</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siew Mei</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 8th Workshop on Innovative Use of NLP for Building Educational Applications</title>
		<meeting>8th Workshop on Innovative Use of NLP for Building Educational Applications</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Enhancing English Vocabulary Learning and Teaching at Secondary Level</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edb</forename></persName>
		</author>
		<ptr target="http://www.edb.gov.hk/vocablearningsec" />
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Automatic Detection of Preposition Errors in Learner Writing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachele</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felice</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Pulman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CALICO Journal</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="512" to="528" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">GenERRate: Generating Errors for Use in Grammatical Error Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Øistein</forename><forename type="middle">E</forename><surname>Andersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 4th Workshop on Innovative Use of NLP for Building Educational Applications</title>
		<meeting>4th Workshop on Innovative Use of NLP for Building Educational Applications</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Automatic Linguistic Annotation of Large Scale L2 Databases: The EF-Cambridge Open Language Database (EFCAMDAT)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeroen</forename><surname>Geertzen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theodora</forename><surname>Alexopoulou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 31st Second Language Research Forum (SLRF)</title>
		<meeting>31st Second Language Research Forum (SLRF)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Using Error-annotated ESL Data to Develop an ESL Error Correction System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Na-Rae</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Tetreault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soo-Hwa</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinyoung</forename><surname>Ha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. LREC</title>
		<meeting>LREC</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Automatic Error Detection in the Japanese Learners&apos; English Spoken Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emi</forename><surname>Izumi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiyotaka</forename><surname>Uchimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toyomi</forename><surname>Saiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thepchai</forename><surname>Supnithi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hitoshi</forename><surname>Isahara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Generating Multiple-Choice Test Items from Medical Text: A Pilot Study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikiforos</forename><surname>Karamanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><forename type="middle">An</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Mitkov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 4th International Natural Language Generation Conference</title>
		<meeting>4th International Natural Language Generation Conference</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The Measurement of Observer Agreement for Categorical Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Landis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary</forename><forename type="middle">G</forename><surname>Koch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="159" to="174" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Automatic generation of cloze items for prepositions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephanie</forename><surname>Seneff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Correcting Misuse of Verb Forms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephanie</forename><surname>Seneff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Human Evaluation of Article and Noun Number Usage: Influences of Context and Construction Variability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Tetreault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Chodorow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Linguistic Annotation Workshop</title>
		<meeting>Linguistic Annotation Workshop</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">CityU Corpus of Essay Drafts of English Language Learners: a Corpus of Textual Revision in Second Language Writing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Zeldes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Reznicek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anke</forename><surname>Lüdeling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Webster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language Resources and Evaluation</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="659" to="683" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Applications of Lexical Information for Algorithmically Composing Multiple-Choice Cloze Items</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao-Lin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Hung</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhao-Ming</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shang-Ming</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2nd Workshop on Building Educational Applications Using NLP</title>
		<meeting>2nd Workshop on Building Educational Applications Using NLP</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP Natural Language Processing Toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL System Demonstrations</title>
		<meeting>ACL System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Wikicorpus: A Word-Sense Disambiguated Multilingual Wikipedia Corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Reese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gemma</forename><surname>Boleda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Montse</forename><surname>Cuadros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lluís</forename><surname>Padró</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">German</forename><surname>Rigau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. LREC</title>
		<meeting>LREC</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Discriminative Approach to Fill-inthe-Blank Quiz Generation for Language Learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keisuke</forename><surname>Sakaguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuki</forename><surname>Arase</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mamoru</forename><surname>Komachi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">FollowYou!: An Automatic Language Lesson Generation System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Chiang</forename><surname>Shei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Assisted Language Learning</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="129" to="144" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Gap-fill Tests for Language Learners: Corpus-Driven Item Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">V S</forename><surname>Avinesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Kilgarriff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 8th International Conference on Natural Language Processing (ICON)</title>
		<meeting>8th International Conference on Natural Language essing (ICON)</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Measuring Non-native Speakers Proficiency of English by Using a Test with Automatically-Generated Fill-in-the-Blank Questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eiichiro</forename><surname>Sumita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fumiaki</forename><surname>Sugaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seiichi</forename><surname>Yamamoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2nd Workshop on Building Educational Applications using NLP</title>
		<meeting>2nd Workshop on Building Educational Applications using NLP</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The Ups and Downs of Preposition Error Detection in ESL Writing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Tetreault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Chodorow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. COLING</title>
		<meeting>COLING</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Test Your Prepositions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Watcyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Jones</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Allsop</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>Penguin Books Ltd</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Automatic Generation of Challenging Distractors Using Context-Sensitive Inference Rules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torsten</forename><surname>Zesch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Melamud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Workshop on Innovative Use of NLP for Building Educational Applications (BEA)</title>
		<meeting>Workshop on Innovative Use of NLP for Building Educational Applications (BEA)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
