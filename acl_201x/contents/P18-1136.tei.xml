<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:59+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Mem2Seq: Effectively Incorporating Knowledge Bases into End-to-End Task-Oriented Dialog Systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 15-20, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Madotto</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Human Language Technology Center Center for Artificial Intelligence Research (CAiRE) Department of Electronic and Computer Engineering</orgName>
								<orgName type="institution">The Hong Kong University of Science and Technology</orgName>
								<address>
									<addrLine>Clear Water Bay</addrLine>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chien-Sheng</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Human Language Technology Center Center for Artificial Intelligence Research (CAiRE) Department of Electronic and Computer Engineering</orgName>
								<orgName type="institution">The Hong Kong University of Science and Technology</orgName>
								<address>
									<addrLine>Clear Water Bay</addrLine>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascale</forename><surname>Fung</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Human Language Technology Center Center for Artificial Intelligence Research (CAiRE) Department of Electronic and Computer Engineering</orgName>
								<orgName type="institution">The Hong Kong University of Science and Technology</orgName>
								<address>
									<addrLine>Clear Water Bay</addrLine>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Mem2Seq: Effectively Incorporating Knowledge Bases into End-to-End Task-Oriented Dialog Systems</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1468" to="1478"/>
							<date type="published">July 15-20, 2018. 2018</date>
						</imprint>
					</monogr>
					<note>1468</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>End-to-end task-oriented dialog systems usually suffer from the challenge of incorporating knowledge bases. In this paper , we propose a novel yet simple end-to-end differentiable model called memory-to-sequence (Mem2Seq) to address this issue. Mem2Seq is the first neural gen-erative model that combines the multi-hop attention over memories with the idea of pointer network. We empirically show how Mem2Seq controls each generation step, and how its multi-hop attention mechanism helps in learning correlations between memories. In addition, our model is quite general without complicated task-specific designs. As a result, we show that Mem2Seq can be trained faster and attain the state-of-the-art performance on three different task-oriented dialog datasets.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Task-oriented dialog systems help users to achieve specific goals with natural language such as restaurant reservation and schedule arrangement. Traditionally, they have been built with several pipelined modules: language understanding, dia- log management, knowledge query, and language generation ( <ref type="bibr" target="#b38">Williams and Young, 2007;</ref><ref type="bibr" target="#b13">Hori et al., 2009;</ref><ref type="bibr" target="#b16">Lee et al., 2009</ref>; <ref type="bibr" target="#b17">Levin et al., 2000;</ref><ref type="bibr" target="#b42">Young et al., 2013)</ref>. Moreover, the ability to query exter- nal Knowledge Bases (KBs) is essential in task- oriented dialog systems, since the responses are guided not only by the dialog history but also by the query results (e.g. <ref type="table" target="#tab_2">Table 1</ref>). However, despite the stability of such pipelined systems via com- bining domain-specific knowledge and slot-filling * * These two authors contributed equally. DRIVER Where can I get tea? Seq2Seq I have a away from away would you like the address +Attn I have a listing for a place that serves tea that is 5 miles away Ptr-Unk There is a away you like would you like more info</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mem2Seq</head><p>The  techniques, modeling the dependencies between modules is complex and the KB interpretation re- quires human effort.</p><p>Recently, end-to-end approaches for dialog modeling, which use recurrent neural networks (RNN) encoder-decoder models, have shown promising results ( <ref type="bibr" target="#b36">Wen et al., 2017;</ref>). Since they can directly map plain text dialog history to the output re- sponses, and the dialog states are latent, there is no need for hand-crafted state labels. Moreover, attention-based copy mechanism ( <ref type="bibr" target="#b9">Gulcehre et al., 2016;</ref> have been recently introduced to copy words directly from the input sources to the output responses. Using such mech- anism, even when unknown tokens appear in the dialog history, the models are still able to produce correct and relevant entities.</p><p>However, although the above mentioned ap- proaches were successful, they still suffer from two main problems: 1) They struggle to effec- tively incorporate external KB information into the RNN hidden states <ref type="bibr" target="#b31">(Sukhbaatar et al., 2015</ref>), since RNNs are known to be unstable over long sequences. 2) Processing long sequences is very time-consuming, especially when using attention mechanisms.</p><p>On the other hand, end-to-end memory networks (MemNNs) are recurrent attention models over a possibly large external mem- ory ( <ref type="bibr" target="#b31">Sukhbaatar et al., 2015)</ref>. They write exter- nal memories into several embedding matrices, and use query vectors to read memories repeat- edly. This approach can memorize external KB in- formation and rapidly encode long dialog history. Moreover, the multi-hop mechanism of MemNN has empirically shown to be essential in achiev- ing high performance on reasoning tasks <ref type="bibr" target="#b1">(Bordes and Weston, 2017)</ref>. Nevertheless, MemNN sim- ply chooses its responses from a predefined candi- date pool rather than generating word-by-word. In addition, the memory queries need explicit design rather than being learned, and the copy mechanism is absent.</p><p>To address these problems, we present a novel architecture that we call Memory-to-Sequence (Mem2Seq) to learn task-oriented dialogs in an end-to-end manner. In short, our model augments the existing MemNN framework with a sequen- tial generative architecture, using global multi- hop attention mechanisms to copy words directly from dialog history or KBs. We summarize our main contributions as such: 1) Mem2Seq is the first model to combine multi-hop attention mech- anisms with the idea of pointer networks, which allows us to effectively incorporate KB informa- tion. 2) Mem2Seq learns how to generate dynamic queries to control the memory access. In addi- tion, we visualize and interpret the model dynam- ics among hops for both the memory controller and the attention. 3) Mem2Seq can be trained faster and achieve state-of-the-art results in several task-oriented dialog datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Model Description</head><p>Mem2Seq 1 is composed of two components: the MemNN encoder, and the memory decoder as shown in <ref type="figure" target="#fig_0">Figure 1</ref>. The MemNN encoder cre- ates a vector representation of the dialog history. Then the memory decoder reads and copies the memory to generate a response. We define all the words in the dialog history as a sequence of to- kens X = {x 1 , . . . , x n , $}, where $ is a special charter used as a sentinel, and the KB tuples as B = {b 1 , . . . , b l }. We further define U = [B; X] as the concatenation of the two sets X and B, Y = {y 1 , . . . , y m } as the set of words in the expected system response, and P T R = {ptr 1 , . . . , ptr m } as the pointer index set:</p><formula xml:id="formula_0">ptr i = max(z) if ∃z s.t. y i = u z n + l + 1 otherwise (1)</formula><p>where u z ∈ U is the input sequence and n + l + 1 is the sentinel position index.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Memory Encoder</head><p>Mem2Seq uses a standard MemNN with adjacent weighted tying ( <ref type="bibr" target="#b31">Sukhbaatar et al., 2015)</ref> as an en- coder. The input of the encoder is word-level in- formation in U . The memories of MemNN are represented by a set of trainable embedding matri- ces C = {C 1 , . . . , C K+1 }, where each C k maps tokens to vectors, and a query vector q k is used as a reading head. The model loops over K hops and it computes the attention weights at hop k for each memory i using:</p><formula xml:id="formula_1">p k i = Softmax((q k ) T C k i ),<label>(2)</label></formula><p>where</p><formula xml:id="formula_2">C k i = C k (x i )</formula><p>is the memory content in po- sition i, and Softmax(z i ) = e z i /Σ j e z j . Here, p k is a soft memory selector that decides the mem- ory relevance with respect to the query vector q k . Then, the model reads out the memory o k by the weighted sum over C k+1 2 ,</p><formula xml:id="formula_3">o k = i p k i C k+1 i .<label>(3)</label></formula><p>Then, the query vector is updated for the next hop by using q k+1 = q k + o k . The result from the encoding step is the memory vector o K , which will become the input for the decoding step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Memory Decoder</head><p>The decoder uses RNN and MemNN. The MemNN is loaded with both X and B, since we use both dialog history and KB information to generate a proper system response. A Gated Re- current Unit (GRU) ( <ref type="bibr" target="#b2">Chung et al., 2014)</ref>, is used as a dynamic query generator for the MemNN. At each decoding step t, the GRU gets the previously generated word and the previous query as input, and it generates the new query vector. Formally:</p><formula xml:id="formula_4">h t = GRU(C 1 (ˆ y t−1 ), h t−1 );<label>(4)</label></formula><p>Then the query h t is passed to the MemNN which will produce the token, where h 0 is the encoder vector o K . At each time step, two distribution are generated: one over all the words in the vocabu- lary (P vocab ), and one over the memory contents (P ptr ), which are the dialog history and KB inofr- mation. The first, P vocab , is generated by concate- nating the first hop attention read out and the cur- rent query vector.</p><formula xml:id="formula_5">P vocab ( ˆ y t ) = Softmax(W 1 [h t ; o 1 ])<label>(5)</label></formula><p>where W 1 is a trainable parameter. On the other hand, P ptr is generated using the attention weights at the last MemNN hop of the decoder: P ptr = p K t . Our decoder generates tokens by pointing to the input words in the memory, which is a simi- lar mechanism to the attention used in pointer net- works ( <ref type="bibr" target="#b33">Vinyals et al., 2015</ref>).</p><p>We designed our architecture in this way be- cause we expect the attention weights in the first and the last hop to show a "looser" and "sharper" distribution, respectively. To elaborate, the first hop focuses more on retrieving mem- ory information and the last one tends to choose the exact token leveraging the pointer supervi- sion. Hence, during training all the parameters are jointly learned by minimizing the sum of two stan- dard cross-entropy losses: one between P vocab ( ˆ y t ) and y t ∈ Y for the vocabulary distribution, and one between P ptr ( ˆ y t ) and ptr t ∈ P T R for the memory distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Sentinel</head><p>If the expected word is not appearing in the mem- ories, then the P ptr is trained to produce the sen- tinel token $, as shown in Equation 1. Once the sentinel is chosen, our model generates the token from P vocab , otherwise, it takes the memory con- tent using the P ptr distribution. Basically, the sen- tinel token is used as a hard gate to control which distribution to use at each time step. A similar ap- proach has been used in ( <ref type="bibr" target="#b22">Merity et al., 2017)</ref> to control a soft gate in a language modeling task. With this method, the model does not need to learn a gating function separately as in <ref type="bibr" target="#b9">Gulcehre et al. (2016)</ref>, and is not constrained by a soft gate func- tion as in See et al. (2017).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Memory Content</head><p>We store word-level content X in the memory module. Similar to <ref type="bibr" target="#b1">Bordes and Weston (2017)</ref>, we add temporal information and speaker information in each token of X to capture the sequential depen- dencies. For example, "hello t1 $u" means "hello" at time step 1 spoken by a user.</p><p>On the other hand, to store B, the KB informa- tion, we follow the works of <ref type="bibr" target="#b23">Miller et al. (2016)</ref>;  that use a (subject, relation, ob- ject) representation. For example, we represent the information of The Westin in <ref type="table" target="#tab_2">Table 1</ref>: (The Westin, Distance, 5 miles). Thus, we sum word embeddings of the subject, relation, and object to obtain each KB memory representation. During decoding stage, the object part is used as the gen- erated word for P ptr . For instance, when the KB tuple (The Westin, Distance, 5 miles) is pointed, our model copies "5 miles" as an output word. No- tice that only a specific section of the KB, relevant to a specific dialog, is loaded into the memory. <ref type="table" target="#tab_2">Task 1  2  3  4  5</ref> DSTC2 In-Car Avg. User turns 4 6.5 6.4 3.5 12.9 6.7 2.6 Avg. Sys turns 6 9.5 9.9 3.5 18.  3 Experimental Setup</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset</head><p>We use three public multi-turn task-oriented dia- log datasets to evaluate our model: the bAbI dia- log (Bordes and Weston, 2017), DSTC2 <ref type="bibr" target="#b12">(Henderson et al., 2014</ref>) and In-Car Assistant ( . The train/validation/test sets of these three datasets are split in advance by the providers. The dataset statistics are reported in <ref type="table" target="#tab_4">Table 2</ref>.</p><p>The bAbI dialog includes five end-to-end dia- log learning tasks in the restaurant domain, which are simulated dialog data. Task 1 to 4 are about API calls, refining API calls, recommending op- tions, and providing additional information, re- spectively. Task 5 is the union of tasks 1-4. There are two test sets for each task: one follows the same distribution as the training set and the other has out-of-vocabulary (OOV) entity values that does not exist in the training set.</p><p>We also used dialogs extracted from the Di- alog State Tracking Challenge 2 (DSTC2) with the refined version from <ref type="bibr" target="#b1">Bordes and Weston (2017)</ref>, which ignores the dialog state annotations. The main difference with bAbI dialog is that this dataset is extracted from real human-bot dialogs, which is noisier and harder since the bots made mistakes due to speech recognition errors or mis- interpretations.</p><p>Recently, In-Car Assistant dataset has been re- leased. which is a human-human, multi-domain dialog dataset collected from Amazon Mechan- ical Turk. It has three distinct domains: cal- endar scheduling, weather information retrieval, and point-of-interest navigation. This dataset has shorter conversation turns, but the user and system behaviors are more diverse. In addition, the sys- tem responses are variant and the KB information is much more complicated. Hence, this dataset re- quires stronger ability to interact with KBs, rather than dialog state tracking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Training</head><p>We trained our model end-to-end using Adam op- timizer ( <ref type="bibr" target="#b15">Kingma and Ba, 2015)</ref>, and chose learn- ing rate between [1e −3 , 1e −4 ]. The MemNNs, both encoder and decoder, have hops K = 1, 3, 6 to show the performance difference. We use sim- ple greedy search and without any re-scoring tech- niques. The embedding size, which is also equiv- alent to the memory size and the RNN hidden size (i.e., including the baselines), has been selected between <ref type="bibr">[64,</ref><ref type="bibr">512]</ref>. The dropout rate is set between [0.1, 0.4], and we also randomly mask some in- put words into unknown tokens to simulate OOV situation with the same dropout ratio. In all the datasets, we tuned the hyper-parameters with grid- search over the validation set, using as measure to the Per-response Accuracy for bAbI dialog and DSTC2, and BLEU score for the In-Car Assistant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Evaluation Metrics</head><p>Per-response/dialog Accuracy: A generative re- sponse is correct only if it is exactly the same as the gold response. A dialog is correct only if ev- ery generated responses of the dialog are correct, which can be considered as the task-completion rate. Note that Bordes and Weston (2017) tests their model by selecting the system response from predefined response candidates, that is, their sys- tem solves a multi-class classification task. Since Mem2Seq generates each token individually, eval- uating with this metric is much more challenging for our model. BLEU: It is a measure commonly used for ma- chine translation systems ( <ref type="bibr" target="#b24">Papineni et al., 2002</ref>), but it has also been used in evaluating dialog sys- tems (  and chat-bots ( <ref type="bibr" target="#b26">Ritter et al., 2011;</ref>. Moreover, BLEU score is a relevant measure in task-oriented dialog as there is not a large vari- ance between the generated answers, unlike open domain generation ( ). Hence, we include BLEU score in our evaluation (i.e. using Moses multi-bleu.perl script). Entity F1: We micro-average over the entire set of system responses and compare the entities in plain text. The entities in each gold system response are selected by a predefined entity list. This metric evaluates the ability to generate relevant entities from the provided KBs and to capture the seman- tics of the dialog ( . Note that the original In-Car Assis- <ref type="formula">(100)</ref> 100 <ref type="formula">(100)</ref> 100 <ref type="formula">(100)</ref> 100 <ref type="formula">(100)</ref> 100 <ref type="formula">(100)</ref> 100 <ref type="formula">(100)</ref> 100 (100) T2 99.5 (-) 100 <ref type="formula">(100)</ref> 100 <ref type="formula">(100)</ref> 100 <ref type="formula">(100)</ref> 100 <ref type="formula">(100)</ref> 100 <ref type="formula">(100)</ref> 100 <ref type="formula">(100)</ref> 100 <ref type="formula">(100)</ref> 100 (100) T3 74.8 (-) 74.9 (2.0) 74.9 (0) 74.8 (0) 74.8 (0) 85.1 (19.0) 87.0 (25.2) 94.5 (59.6) 94.7 (62.1) T4 57.2 (-) 59.5 (3.0) 57.2 (0) 57.2 (0) 57.2 (0) 100 (100) 97.6 (91.7) 100 (100) 100 (100) T5 99.6 (-) 96.1 (49.4) 96.3 (52.5) 98.8 (81.5)</p><note type="other">Task QRN MemNN GMemNN Seq2Seq Seq2Seq+Attn Ptr-Unk Mem2Seq H1 Mem2Seq H3 Mem2Seq H6 T1 99.4 (-) 99.9 (99.6) 100</note><p>98.4 (87.3) 99.4 (91.5) 96.1 (45.3) 98.2 (72.9) 97.9 (69.6) T1-OOV 83.1 (-) 72.3 (0) 82.4 (0) 79.9 (0) 81.7 (0) 92.5 (54.7) 93.4 (60.4) 91.3 (52.0) 94.0 (62.2) T2-OOV 78.9 <ref type="table">(-)</ref> 78.9 (0) 78.9 (0) 78.9 (0) 78.9 (0) 83.2 (0) 81.7 (1.2) 84.7 (7.3) 86.5 (12.   </p><note type="other">4) T3-OOV 75.2 (-) 74.4 (0) 75.3 (0) 74.3 (0) 75.3 (0) 82.9 (13.4) 86.6 (26.2) 93.2 (53.3) 90.3 (38.7) T4-OOV 56.9 (-) 57.6 (0) 57.0 (0) 57.0 (0) 57.0 (0) 100 (100) 97.3 (90.6) 100 (100) 100 (100) T5-OOV 67.8 (-) 65.5 (0) 66.7 (0) 67.4 (0) 65.7 (0) 73.6 (0) 67.6 (0) 78.1 (0.4) 84.5 (2.3)</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Results</head><p>We mainly compare Mem2Seq with hop 1,3,6 with several existing models: query-reduction networks (QRN, <ref type="bibr" target="#b28">Seo et al. (2017)</ref>), end-to- end memory networks (MemNN, Sukhbaatar et al. <ref type="formula" target="#formula_1">(2015)</ref>), and gated end-to-end memory net- works (GMemNN, <ref type="bibr" target="#b20">Liu and Perez (2017)</ref>). We also implemented the following baseline models: standard sequence-to-sequence (Seq2Seq) models with and without attention ( <ref type="bibr" target="#b21">Luong et al., 2015)</ref>, and pointer to unknown (Ptr-Unk, <ref type="bibr" target="#b9">Gulcehre et al. (2016)</ref>). Note that the results we listed in <ref type="table" target="#tab_5">Table 3</ref> and <ref type="table" target="#tab_6">Table 4</ref> for QRN are different from the origi- nal paper, because based on their released code, <ref type="bibr">3</ref> we discovered that the per-response accuracy was not correctly computed. bAbI Dialog: In <ref type="table" target="#tab_5">Table 3</ref>, we follow Bordes <ref type="bibr">3</ref> We simply modified the evaluation part and reported the results. (https://github.com/uwnlp/qrn) and Weston (2017) to compare the performance based on per-response and per-dialog accuracy. Mem2Seq with 6 hops can achieve per-response 97.9% and per-dialog 69.6% accuracy in T5, and 84.5% and 2.3% for T5-OOV, which surpass ex- isting methods by far. One can find that in T3 es- pecially, which is the task to recommend restau- rant based on their ranks, our model can achieve promising results due to the memory pointer. In terms of per-response accuracy, this indicates that our model can generalize well with few perfor- mance loss for test OOV data, while others have around 15-20% drop. The performance gain in OOV data is also mainly attributed to the use of copy mechanism. In addition, the effectiveness of hops is demonstrated in tasks 3-5, since they re- quire reasoning ability over the KB information. Note that QRN, MemNN and GMemNN viewed bAbI dialog tasks as classification problems. Al- though their tasks are easier compared to our gen- erative methods, Mem2Seq models can still over- pass the performance. Finally, one can find that Seq2Seq and Ptr-Unk models are also strong base- lines, which further confirms that generative meth- ods can also achieve good performance in task- oriented dialog systems ( ). <ref type="table" target="#tab_6">Table 4</ref>, the Seq2Seq models from  and the rule-based from <ref type="bibr" target="#b1">Bordes and Weston (2017)</ref> are reported. Mem2Seq has the highest 75.3% entity F1 score and an high of 55.3 BLEU score. This further con- firms that Mem2Seq can perform well in retrieving the correct entity, using the multiple hop mecha- nism without losing language modeling. Here, we do not report the results using match type <ref type="bibr" target="#b1">(Bordes and Weston, 2017)</ref> or entity type ) feature, since this meta-information are not commonly available and we want to have an evaluation on plain input output couples. One can also find out that, Mem2Seq comparable per- response accuracy (i.e. 2% margin) among other existing solution. Note that the per-response ac- curacy for every model is less than 50% since the dataset is quite noisy and it is hard to generate a response that is exactly the same as the gold one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DSTC2: In</head><p>In-Car Assistant: In <ref type="table" target="#tab_7">Table 5</ref>, our model can achieve highest 12.6 BLEU score. In addition, Mem2Seq has shown promising results in terms of Entity F1 scores (33.4%), which are, in general, much higher than those of other baselines. Note that the numbers reported from  are not directly comparable to ours as we mention below. The other baselines such as Seq2Seq or Ptr- Unk especially have worse performances in this dataset since it is very inefficient for RNN meth- ods to encode longer KB information, which is the advantage of Mem2Seq.</p><p>Furthermore, we observe an interesting phe- nomenon that humans can easily achieve a high entity F1 score with a low BLEU score. This im- plies that stronger reasoning ability over entities (hops) is crucial, but the results may not be similar to the golden answer. We believe humans can pro- duce good answers even with a low BLEU score, since there could be different ways to express the same concepts. Therefore, Mem2Seq shows the potential to successfully choose the correct enti- ties.</p><p>Note that the results of KV Retrieval Net base- line reported in <ref type="table" target="#tab_7">Table 5</ref> come from the original pa- per (  of In-Car Assistant, where they simplified the task by mapping the expression of entities to a canonical form using named entity recognition (NER) and linking. Hence the eval- uation is not directly comparable to our system. For example, their model learned to generate re- sponses such as "You have a football game at foot-  ball time with football party," instead of generat- ing a sentence such as "You have a football game at 7 pm with John." Since there could be more than one football party or football time, their model does not learn how to access the KBs, but it rather learns the canonicalized language model. Time Per-Epoch: We also compare the train- ing time <ref type="bibr">4</ref> in <ref type="figure" target="#fig_1">Figure 2</ref>. The experiments are set with batch size 16, and we report each model with the hyper-parameter that can achieved the highest performance. One can observe that the training time is not that different for short in- put length (bAbI dialog tasks 1-4) and the gap becomes larger as the maximal input length in- creases. Mem2Seq is around 5 times faster in In- Car Assistant and DSTC2 compared to Seq2Seq with attention. This difference in training effi- ciency is mainly attributed to the fact that Seq2Seq models have input sequential dependencies which limit any parallelization. Moreover, it is unavoid- able for Seq2Seq models to encode KBs, instead Mem2Seq only encodes with dialog history.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Analysis and Discussion</head><p>Memory Attention: Analyzing the attention weights has been frequently used to show the memory read-out, since it is an intuitive way to un- derstand the model dynamics. <ref type="figure" target="#fig_3">Figure 3</ref> shows the attention vector at the last hop for each generated token. Each column represents the P ptr vector at the corresponding generation step. Our model has a sharp distribution over the memory, which im-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="0">1 2 3 4 5 6 7 8 9 111 12 13</head><p>Generation Step  plies that it is able to select the right token from the memory. For example, the KB information "270 altarie walk" was retrieved at the sixth step, which is an address for "civic center garage". On the other hand, if the sentinel is triggered, then the generated word comes from vocabulary distribu- tion P vocab . For instance, the third generation step triggered the sentinel, and "is" is generated from the vocabulary as the word is not present in the dialog history.</p><note type="other">rd address ravenswood shopping center shopping center poi type ravenswood shopping center heavy traffic traffic info ravenswood shopping center 4 miles distance ravenswood shopping center ravenswood shopping center poi shopping center heavy traffic 4 miles Memory Content COR: the closest parking garage is civic center garage located 4 miles away at 270 altaire walk GEN: the closest parking garage is civic center garage at 270 altaire walk 4 miles away through</note><p>Multiple Hops: Mem2Seq shows how multiple hops improve the model performance in several datasets. Task 3 in the bAbI dialog dataset serves as an example, in which the systems need to rec- ommend restaurants to users based on restaurant ranking from highest to lowest. Users can reject the recommendation and the system has to rea- son over the next highest restaurant. We found out there are two common patterns between hops among different samples: 1) the first hop is usu- ally used to score all the relevant memories and   retrieve information; 2) the last hop tends to focus on a specific token and makes mistakes when the attention is not sharp. Such mistakes can be at- tributed to lack of hops, for some samples. For more information, we report two figures in the supplementary material. Query Vectors: In <ref type="figure" target="#fig_4">Figure 4</ref>, the principal com- ponent analysis of Mem2Seq queries vectors is shown for different hops. Each dot is a query vec- tor h t during each decoding time step, and it has its corresponding generated word y t . The blue dots are the words generated from P vocab , which trig- gered the sentinel, and orange ones are from P ptr . One can find that in (a) hop 1, there is no clear sep- aration of two different colors but each of which tends to group together. On the other hand, the separation becomes clearer in (b) hop 6 as each color clusters into several groups such as location, cuisine, and number. Our model tends to retrieve more information in the first hop, and points into the memories in the last hop.</p><p>Examples: <ref type="table" target="#tab_2">Table 1 and 6</ref> show the generated re- sponses of different models in the two test set sam- ples from the In-Car Assistant dataset. We report examples from this dataset since their answers are more human-like and not as structured and repet- itive as others. Seq2Seq generally cannot pro- duce related information, and sometimes fail in language modeling. Instead, using attention helps with this issue, but it still rarely produces the cor- rect entities. For example, Seq2Seq with atten- tion generated 5 miles in <ref type="table" target="#tab_2">Table 1</ref> but the correct one is 4 miles. In addition, Ptr-Unk often cannot copy the correct token from the input, as shown by "PAD" in <ref type="table" target="#tab_2">Table 1</ref>. On the other hand, Mem2Seq is able to produce the correct responses in this two examples. In particular in the navigation domain, shown in <ref type="table" target="#tab_2">Table 1</ref>, Mem2Seq produces a different but still correct utterance. We report further ex- amples from all the domains in the supplementary material.</p><p>Discussions: Conventional task-oriented dialog systems <ref type="bibr" target="#b38">(Williams and Young, 2007)</ref>, which are still widely used in commercial systems, require a multitude of human efforts in system designing and data collection. On the other hand, although end-to-end dialog systems are not perfect yet, they require much less human interference, especially in the dataset construction, as raw conversational text and KB information can be used directly with- out the need of heavy preprocessing (e.g. NER, dependency parsing). To this extent, Mem2Seq is a simple generative model that is able to in- corporate KB information with promising gener- alization ability. We also discovered that the en- tity F1 score may be a more comprehensive evalu- ation metric than per-response accuracy or BLEU score, as humans can normally choose the right entities but have very diversified responses. In- deed, we want to highlight that humans may have a low BLEU score despite their correctness because there may not be a large n-gram overlap between the given response and the expected one. How- ever, this does not imply that there is no correla- tion between BLEU score and human evaluation. In fact, unlike chat-bots and open domain dialogs where BLEU score does not correlate with hu- man evaluation ( , in task-oriented dialogs the answers are constrained to particular entities and recurrent patterns. Thus, we believe BLEU score still can be considered as a relevant measure. In future works, several methods could be applied (e.g. Reinforcement <ref type="bibr">Learning (Ranzato et al., 2016)</ref>, Beam Search ( <ref type="bibr" target="#b39">Wiseman and Rush, 2016)</ref>) to improve both responses relevance and entity F1 score. However, we preferred to keep our model as simple as possible in order to show that it works well even without advanced training methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Works</head><p>End-to-end task-oriented dialog systems train a single model directly on text transcripts of di- alogs ( <ref type="bibr" target="#b36">Wen et al., 2017;</ref><ref type="bibr" target="#b37">Williams et al., 2017;</ref><ref type="bibr" target="#b28">Seo et al., 2017;</ref><ref type="bibr" target="#b30">Serban et al., 2017)</ref>. Here, RNNs play an important role due to their ability to create a la- tent representation, avoiding the need for artificial state labels. End-to-End Memory Networks <ref type="bibr" target="#b1">(Bordes and Weston, 2017;</ref><ref type="bibr" target="#b31">Sukhbaatar et al., 2015)</ref>, and its variants ( <ref type="bibr" target="#b20">Liu and Perez, 2017;</ref><ref type="bibr" target="#b40">Wu et al., 2017</ref><ref type="bibr" target="#b41">Wu et al., , 2018</ref>) have also shown good results in such tasks. In each of these architectures, the output is produced by generating a sequence of tokens, or by selecting a set of predefined utterances. Sequence-to-sequence (Seq2Seq) models have also been used in task-oriented dialog sys- tems ( . These architectures have better language modeling ability, but they do not work well in KB retrieval. Even with sophisticated attention models ( <ref type="bibr" target="#b21">Luong et al., 2015;</ref><ref type="bibr" target="#b0">Bahdanau et al., 2015)</ref>, Seq2Seq fails to map the correct en- tities to the generated input. To alleviate this prob- lem, copy augmented Seq2Seq models , were used. These models out- perform utterance selection methods by copying relevant information directly from the KBs. Copy mechanisms has also been used in question an- swering tasks <ref type="bibr" target="#b3">(Dehghani et al., 2017;</ref><ref type="bibr" target="#b11">He et al., 2017)</ref>, neural machine translation ( <ref type="bibr" target="#b9">Gulcehre et al., 2016;</ref><ref type="bibr" target="#b8">Gu et al., 2016)</ref>, language modeling ( <ref type="bibr" target="#b22">Merity et al., 2017)</ref>, and summarization ( <ref type="bibr" target="#b27">See et al., 2017)</ref>.</p><p>Less related to dialog systems, but related to our work, are the memory based decoders and the non- recurrent generative models: 1) Mem2Seq query generation phase used to access our memories can be seen as the memory controller used in Memory Augmented Neural Networks (MANN) ( <ref type="bibr" target="#b6">Graves et al., 2014</ref><ref type="bibr" target="#b7">Graves et al., , 2016</ref>. Similarly, memory en- coders have been used in neural machine transla- tion ( <ref type="bibr" target="#b35">Wang et al., 2016)</ref>, and meta-learning appli- cation ( . However, Mem2Seq differs from these models as such: it uses multi-hop attention in combination with copy mecha- nism, whereas other models use a single matrix representation. 2) non-recurrent generative mod- els ( <ref type="bibr" target="#b32">Vaswani et al., 2017)</ref>, which only rely on self- attention mechanism, are related to the multi-hop attention mechanism used in MemNN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this work, we present an end-to-end trainable Memory-to-Sequence model for task-oriented di- alog systems. Mem2Seq combines the multi-hop attention mechanism in end-to-end memory net- works with the idea of pointer networks to incor- porate external information. We empirically show our model's ability to produce relevant answers us- ing both the external KB information and the pre- defined vocabulary, and visualize how the multi- hop attention mechanisms help in learning corre- lations between memories. Mem2Seq is fast, gen- eral, and able to achieve state-of-the-art results in three different datasets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The proposed Mem2Seq architecture for task-oriented dialog systems. (a) Memory encoder with 3 hops; (b) Memory decoder over 2 step generation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Training time per-epoch for different tasks (lower is better). The speed difference becomes larger as the maximal input length increases.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>783 arcadia pl address chevron gas station poi type chevron moderate traffic traffic info chevron 3 miles distance chevron chevron poi gas station moderate traffic 3 miles 271 springer street address mandarin roots chinese restaurant poi type mandarin roots moderate traffic traffic info mandarin roots 4 miles distance mandarin roots mandarin roots poi chinese restaurant moderate traffic 4 miles 408 university ave address trader joes grocery store poi type trader joes no traffic traffic info trader joes 5 miles distance trader joes trader joes poi grocery store no traffic 5 miles 638 amherst st address sigona farmers market grocery store poi type sigona farmers market no traffic traffic info sigona farmers market 4 miles distance sigona farmers market sigona farmers market poi grocery store no traffic 4 miles 347 alta mesa ave address jills house friends house poi type jills house heavy traffic traffic info jills house 4 miles distance jills house jills house poi friends house heavy traffic 4 miles 270 altaire walk address civic center garage parking garage poi type civic center garage no traffic traffic info civic center garage 4 miles distance civic center garage civic center garage poi parking garage no traffic 4 miles 434 arastradero</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Last hop memory attention visualization from the In-Car dataset. COR and GEN on the top are the correct response and our generated one.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Principal component analysis of query vectors in hop (a) 1 and (b) 6 for bAbI dialog.</figDesc><graphic url="image-43.png" coords="7,307.28,62.81,218.27,174.89" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Example of generated responses for the 
In-Car Assistant on the navigation domain. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Dataset statistics for 3 different datasets. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Per-response and per-dialog (in the parentheses) accuracy on bAbI dialogs. Mem2Seq achieves 
the highest average per-response accuracy and has the least out-of-vocabulary performance drop. 

Ent. F1 BLEU 
Per-
Resp. 

Per-
Dial. 
Rule-Based 
-
-
33.3 
-
QRN 
-
-
43.8 
-
MemNN 
-
-
41.1 
0.0 
GMemNN 
-
-
47.4 
1.4 
Seq2Seq 
69.7 
55.0 
46.4 
1.5 
+Attn 
67.1 
56.6 
46.0 
1.4 
+Copy 
71.6 
55.4 
47.3 
1.3 
Mem2Seq H1 
72.9 
53.7 
41.7 
0.0 
Mem2Seq H3 
75.3 
55.3 
45.0 
0.5 
Mem2Seq H6 
72.8 
53.6 
42.8 
0.7 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Evaluation on DSTC2. 
Seq2Seq (+attn and +copy) is reported 
from Eric and Manning (2017). 

BLEU Ent. F1 Sch. F1 Wea. F1 Nav. F1 
Human* 
13.5 
60.7 
64.3 
61.6 
55.2 
Rule-Based* 
6.6 
43.8 
61.3 
39.5 
40.4 
KV Retrieval Net* 
13.2 
48.0 
62.9 
47.0 
41.3 
Seq2Seq 
8.4 
10.3 
09.7 
14.1 
07.0 
+Attn 
9.3 
19.9 
23.4 
25.6 
10.8 
Ptr-Unk 
8.3 
22.7 
26.9 
26.7 
14.9 
Mem2Seq H1 
11.6 
32.4 
39.8 
33.6 
24.6 
Mem2Seq H3 
12.6 
33.4 
49.3 
32.8 
20.0 
Mem2Seq H6 
9.9 
23.6 
34.3 
33.0 
4.4 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Evaluation on In-Car Assistant. Human, rule-
based and KV Retrieval Net evaluation (with *) are reported 
from (Eric et al., 2017), which are not directly comparable. 
Mem2Seq achieves highest BLEU and entity F1 score over 
baselines. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Example of generated responses for the 
In-Car Assistant on the scheduling domain. 

</table></figure>

			<note place="foot" n="1"> The code is available at https://github.com/ HLTCHKUST/Mem2Seq</note>

			<note place="foot" n="2"> Here is C k+1 since we use adjacent weighted tying.</note>

			<note place="foot" n="4"> Intel(R) Core(TM) i7-3930K CPU@3.20GHz, using a GeForce GTX 1080 Ti</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning end-to-end goal-oriented dialog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<idno>abs/1605.07683</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Empirical evaluation of gated recurrent neural networks on sequence modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyoung</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Deep Learning and Representation Learning Workshop</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning to attend, copy, and generate for session-based query suggestion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sascha</forename><surname>Rothe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enrique</forename><surname>Alfonseca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fleury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM on Conference on Information and Knowledge Management, CIKM &apos;17</title>
		<meeting>the 2017 ACM on Conference on Information and Knowledge Management, CIKM &apos;17<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1747" to="1756" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Key-value retrieval networks for task-oriented dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihail</forename><surname>Eric</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lakshmi</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francois</forename><surname>Charette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue</title>
		<meeting>the 18th Annual SIGdial Meeting on Discourse and Dialogue</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="37" to="49" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A copyaugmented sequence-to-sequence architecture gives good performance on task-oriented dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihail</forename><surname>Eric</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="468" to="473" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Wayne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivo</forename><surname>Danihelka</surname></persName>
		</author>
		<title level="m">Neural turing machines. CoRR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Hybrid computing using a neural network with dynamic external memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Wayne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malcolm</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Harley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivo</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agnieszka</forename><surname>Grabskabarwi´nskabarwi´nska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><forename type="middle">Gómez</forename><surname>Colmenarejo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiago</forename><surname>Ramalho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Agapiou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">538</biblScope>
			<biblScope unit="issue">7626</biblScope>
			<biblScope unit="page" from="471" to="476" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Incorporating copying mechanism in sequence-to-sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiatao</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><forename type="middle">O K</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1631" to="1640" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Pointing the unknown words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungjin</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th</title>
		<meeting>the 54th</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<title level="m">Annual Meeting of the Association for Computational Linguistics</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="140" to="149" />
		</imprint>
	</monogr>
	<note>Long Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Generating natural answers by incorporating copying and retrieving mechanisms in sequence-tosequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cao</forename><surname>Shizhu He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="199" to="208" />
		</imprint>
	</monogr>
	<note>Long Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The second dialog state tracking challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blaise</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason D</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL)</title>
		<meeting>the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="263" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Statistical dialog management applied to wfst-based dialog systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiori</forename><surname>Hori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiyonori</forename><surname>Ohtake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teruhisa</forename><surname>Misu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hideki</forename><surname>Kashioka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Nakamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="4793" to="4796" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ofir</forename><surname>Nachum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurko</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<title level="m">Learning to remember rare events. International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Example-based dialog modeling for practical multi-domain dialog system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheongjae</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangkeun</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seokhwan</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary Geunbae</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Speech Communication</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="466" to="484" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A stochastic model of human-machine interaction for learning dialog strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esther</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Pieraccini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wieland</forename><surname>Eckert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on speech and audio processing</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="11" to="23" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A diversity-promoting objective function for neural conversation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="110" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">How not to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chia-Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iulian</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Noseworthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2122" to="2132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Gated end-to-end memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Perez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter</title>
		<meeting>the 15th Conference of the European Chapter<address><addrLine>Long Papers; Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Effective approaches to attention-based neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1412" to="1421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Pointer sentinel mixture models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Merity</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Key-value memory networks for directly reading documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Dodge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1400" to="1409" />
		</imprint>
	</monogr>
	<note>AmirHossein Karimi, Antoine Bordes, and Jason Weston</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 40th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>40th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Philadelphia, Pennsylvania, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Marc&amp;apos;aurelio Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zaremba</surname></persName>
		</author>
		<title level="m">Sequence level training with recurrent neural networks. International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Data-driven response generation in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">B</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Edinburgh, Scotland, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="583" to="593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Get to the point: Summarization with pointergenerator networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abigail</forename><surname>See</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1073" to="1083" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Query-reduction networks for question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Building end-to-end dialogue systems using generative hierarchical neural network models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Iulian Vlad Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Aaron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3776" to="3784" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A hierarchical latent variable encoder-decoder model for generating dialogues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Iulian Vlad Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Aaron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3295" to="3301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">End-to-end memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sainbayar</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2440" to="2448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6000" to="6010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Pointer networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meire</forename><surname>Fortunato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navdeep</forename><surname>Jaitly</surname></persName>
		</author>
		<editor>C. Cortes, N. D</editor>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">D</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Garnett</surname></persName>
		</author>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="2692" to="2700" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Memory-enhanced decoder for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="278" to="286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A network-based end-to-end trainable task-oriented dialogue system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Tsung-Hsien Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Gasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lina</forename><forename type="middle">Maria</forename><surname>Mrksic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei</forename><forename type="middle">Hao</forename><surname>Rojas-Barahona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Ultes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><forename type="middle">J</forename><surname>Vandyke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EACL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Hybrid code networks: practical and efficient end-to-end dialog control with supervised and reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kavosh</forename><surname>Jason D Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Asadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="665" to="677" />
		</imprint>
	</monogr>
	<note>Long Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Partially observable markov decision processes for spoken dialog systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jason</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="393" to="422" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Sequence-to-sequence learning as beam-search optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Wiseman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1296" to="1306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">End-to-end recurrent entity network for entity-value independent goal-oriented dialog learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chien-Sheng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Madotto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Genta</forename><surname>Winata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Dialog System Technology Challenges Workshop</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">End-to-end dynamic query memory network for entity-value independent taskoriented dialog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chien-Sheng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Madotto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Genta</forename><surname>Winata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>ICASSP</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Pomdp-based statistical spoken dialog systems: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Gaši´gaši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blaise</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason D</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1160" to="1179" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Generative encoder-decoder models for task-oriented spoken dialog systems with chatting capability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiancheng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyusong</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxine</forename><surname>Eskenazi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue</title>
		<meeting>the 18th Annual SIGdial Meeting on Discourse and Dialogue</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="27" to="36" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
