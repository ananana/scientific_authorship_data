<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:15+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">How to Speak a Language without Knowing It</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>June 23-25 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Shi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Information Sciences Institute Computer Science Department</orgName>
								<orgName type="department" key="dep2">Computer Science Department</orgName>
								<orgName type="institution" key="instit1">University of Southern California</orgName>
								<orgName type="institution" key="instit2">Rensselaer Polytechnic Institute Troy</orgName>
								<address>
									<postCode>12180</postCode>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Information Sciences Institute Computer Science Department</orgName>
								<orgName type="department" key="dep2">Computer Science Department</orgName>
								<orgName type="institution" key="instit1">University of Southern California</orgName>
								<orgName type="institution" key="instit2">Rensselaer Polytechnic Institute Troy</orgName>
								<address>
									<postCode>12180</postCode>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Information Sciences Institute Computer Science Department</orgName>
								<orgName type="department" key="dep2">Computer Science Department</orgName>
								<orgName type="institution" key="instit1">University of Southern California</orgName>
								<orgName type="institution" key="instit2">Rensselaer Polytechnic Institute Troy</orgName>
								<address>
									<postCode>12180</postCode>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">How to Speak a Language without Knowing It</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="278" to="282"/>
							<date type="published">June 23-25 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We develop a system that lets people overcome language barriers by letting them speak a language they do not know. Our system accepts text entered by a user, translates the text, then converts the translation into a phonetic spelling in the user&apos;s own orthography. We trained the system on phonetic spellings in travel phrasebooks .</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Can people speak a language they don't know? Actually, it happens frequently. Travel phrase- books contain phrases in the speaker's language (e.g., "thank you") paired with foreign-language translations (e.g., " спасибо"). Since the speaker may not be able to pronounce the foreign-language orthography, phrasebooks additionally provide phonetic spellings that approximate the sounds of the foreign phrase. These spellings employ the fa- miliar writing system and sounds of the speaker's language. Here is a sample entry from a French phrasebook for English speakers:</p><p>English:</p><p>Leave me alone. French:</p><p>Laissez-moi tranquille. Franglish: Less-ay mwah trahn-KEEL. The user ignores the French and goes straight to the Franglish. If the Franglish is well designed, an English speaker can pronounce it and be under- stood by a French listener. <ref type="figure">Figure 1</ref> shows a sample entry from another book-an English phrasebook for Chinese speak- ers. If a Chinese speaker wants to say "非 常 感 谢 你 这 顿 美 餐", she need only read off the Chinglish "三可 油 否 热斯 弯德否 米欧", which approximates the sounds of "Thank you for this wonderful meal" using Chinese characters.</p><p>Phrasebooks permit a form of accurate, per- sonal, oral communication that speech-to-speech <ref type="figure">Figure 1</ref>: Snippet from phrasebook translation devices lack. However, the user is lim- ited to a small set of fixed phrases. In this paper, we lift this restriction by designing and evaluating a software program with the following:</p><p>• Input: Text entered by the speaker, in her own language.</p><p>• Output: Phonetic rendering of a foreign- language translation of that text, which, when pronounced by the speaker, can be under- stood by the listener.</p><p>The main challenge is that different languages have different orthographies, different phoneme inventories, and different phonotactic constraints, so mismatches are inevitable. Despite this, the system's output should be both unambiguously pronounceable by the speaker and readily under- stood by the listener.</p><p>Our goal is to build an application that covers many language pairs and directions. The current paper describes a single system that lets a Chinese person speak English.</p><p>We take a statistical modeling approach to this problem, as is done in two lines of research that are most related. The first is machine transliteration <ref type="bibr" target="#b2">(Knight and Graehl, 1998)</ref>, in which names and technical terms are translated across languages with different sound systems. The other is re- spelling generation <ref type="bibr" target="#b1">(Hauer and Kondrak, 2013)</ref>, where an English speaker is given a phonetic hint about how to pronounce a rare or foreign word to another English speaker. By contrast, we aim Chinese 已经八点了 English It's eight o'clock now Chinglish 意思埃特额克劳克闹 (yi si ai te e ke lao ke nao) Chinese 这件衬衫又时髦又便宜 English this shirt is very stylish and not very expensive Chinglish 迪思舍特意思危锐思掉利失安的闹特危锐伊克思班西五 Chinese 我们外送的最低金额是15美金 English our minimum charge for delivery is fifteen dollars Chinglish 奥儿米尼们差只佛低利沃锐意思发五听到乐思 <ref type="table">Table 1</ref>: Examples of &lt;Chinese, English, Chinglish&gt; tuples from a phrasebook.</p><p>to help people issue full utterances that cross lan- guage barriers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Evaluation</head><p>Our system's input is Chinese. The output is a string of Chinese characters that approximate English sounds, which we call Chinglish. We build several candidate Chinese-to-Chinglish sys- tems and evaluate them as follows:</p><p>• We compute the normalized edit distance between the system's output and a human- generated Chinglish reference.</p><p>• A Chinese speaker pronounces the system's output out loud, and an English listener takes dictation. We measure the normalized edit distance against an English reference.</p><p>• We automate the previous evaluation by re- place the two humans with: (1) a Chinese speech synthesizer, and (2) a English speech recognizer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data</head><p>We seek to imitate phonetic transformations found in phrasebooks, so phrasebooks themselves are a good source of training data. We obtained a col- lection of 1312 &lt;Chinese, English, Chinglish&gt; phrasebook tuples 1 (see <ref type="table">Table 1</ref>). We use 1182 utterances for training, 65 for de- velopment, and 65 for test. We know of no other computational work on this type of corpus.</p><p>Our Chinglish has interesting gross empirical properties. First, because Chinglish and Chinese are written with the same characters, they render the same inventory of 416 distinct syllables. How- ever, the distribution of Chinglish syllables differs a great deal from Chinese ( <ref type="table" target="#tab_1">Table 2)</ref>. Syllables "si" and "te" are very popular, because while conso- nant clusters like English "st" are impossible to re- produce exactly, the particular vowels in "si" and "te" are fortunately very weak.  We find that multiple occurrences of an English word type are generally associated with the same Chinglish sequence. Also, Chinglish characters do not generally span multiple English words. It is reasonable for "can I" to be rendered as "kan nai", with "nai" spanning both English words, but this is rare.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Model</head><p>We model Chinese-to-Chinglish translation with a cascade of weighted finite-state transducers (wFST), shown in <ref type="figure" target="#fig_0">Figure 2</ref>. We use an online MT system to convert Chinese to an English word sequence (Eword), which is then passed through FST A to generate an English sound sequence (Epron). FST A is constructed from the CMU Pro- nouncing Dictionary <ref type="bibr" target="#b5">(Weide, 2007)</ref>.</p><p>Next, wFST B translates English sounds into Chinese sounds (Pinyin-split). Pinyin is an official syllable-based romanization of Mandarin Chinese characters, and Pinyin-split is a standard separa- tion of Pinyin syllables into initial and final parts. Our wFST allows one English sound token to map to one or two Pinyin-split tokens, and it also allows two English sounds to map to one Pinyin-split to- ken.</p><p>Finally, FST C converts Pinyin-split into Pinyin, and FST D chooses Chinglish characters. We also experiment with an additional wFST E that trans- lates English words directly into Chinglish.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Training</head><p>FSTs A, C, and D are unweighted, and remain so throughout this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Phoneme-based model</head><p>We must now estimate the values of FST B pa- rameters, such as P(si|S). To do this, we first take our phrasebook triples and construct sample string pairs &lt;Epron, Pinyin-split&gt; by pronounc- ing the phrasebook English with FST A, and by pronouncing the phrasebook Chinglish with FSTs D and C. Then we run the EM algorithm to learn FST B parameters (  Here, "ae n" should be decoded as "uan" when preceded by "r". Following phrase-based meth- ods in statistical machine translation ( <ref type="bibr" target="#b3">Koehn et al., 2003</ref>) and machine transliteration <ref type="bibr" target="#b0">(Finch and Sumita, 2008)</ref>, we model substitution of longer se- quences. First, we obtain Viterbi alignments using the phoneme-based model, e.g.: Second, we extract phoneme phrase pairs con- sistent with these alignments. We use no phrase- size limit, but we do not cross word boundaries. From the example above, we pull out phrase pairs like:</p><p>g → g e g r → g e r ... r → r r ae n → r uan ...</p><p>We add these phrase pairs to FST B, and call this the phoneme-phrase-based model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Word-based model</head><p>We now turn to WFST E, which short-cuts di- rectly from English words to Pinyin. We create &lt;English, Pinyin&gt; training pairs from our phrase- book simply by pronouncing the Chinglish with FST D. We initially allow each English word type to map to any sequence of Pinyin, up to length 7, with uniform probability. EM learns values for pa- rameters like P (nai te|night), plus Viterbi align- ments such as:   Notice that this model makes alignment errors due to sparser data (e.g., the word "tips" and "ti pu si" only appear once each in the training data).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Hybrid training</head><p>To improve the accuracy of word-based EM align- ment, we use the phoneme based model to de- code each English word in the training data to Pinyin. From the 100-best list of decodings, we collect combinations of start/end Pinyin syllables for the word. We then modify the initial, uniform English-to-Pinyin mapping probabilities by giving higher initial weight to mappings that respect ob- served start/end pairs. When we run EM, we find that alignment errors for "tips" in section 5.3 are fixed:</p><p>accept tips a ke sha pu te ti pu si</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Hybrid decoding</head><p>The word-based model can only decode 29 of the 65 test utterances, because wFST E fails if an ut- terance contains a new English word type, pre- viously unseen in training. The phoneme-based models are more robust, able to decode 63 of the 65 utterances, failing only when some English word type falls outside the CMU pronouncing dic- tionary (FST A).</p><p>Our final model combines these two, using the word-based model for known English words, and the phoneme-based models for unknown English words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head><p>Our first evaluation <ref type="table" target="#tab_5">(Table 4)</ref> is intrinsic, measur- ing our Chinglish output against references from the test portion of our phrasebook, using edit dis- tance. Here, we start with reference English and measure the accuracy of Pinyin syllable produc- tion, since the choice of Chinglish character does not affect the Chinglish pronunciation. We see that the Word-based method has very high accuracy, but low coverage. Our best system uses the Hy- brid training/decoding method. As <ref type="table" target="#tab_7">Table 6</ref> shows, the ratio of unseen English word tokens is small, thus large portion of tokens are transformed us- ing word-based method. The average edit dis- tance of phoneme-phrase model and that of hy- brid training/decoding model are close, indicating that long phoneme-phrase pairs can emulate word- pinyin mappings.   <ref type="table">Table 7</ref>: Chinglish-to-English accuracy in dicta- tion task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Unseen Total Ratio</head><p>Our second evaluation is a dictation task. We speak our Chinglish character sequence output aloud and ask an English monolingual person to transcribe it. (Actually, we use a Chinese synthe- sizer to remove bias.) Then we measure edit dis- tance between the human transcription and the ref- erence English from our phrasebook. Results are shown in <ref type="table">Table 7</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Chinese</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>年夜饭都要吃些什么</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reference English what do you have for the Reunion dinner Reference Chinglish</head><p>沃特 杜 又 海夫 佛 则 锐又尼恩 低呢 Hybrid training/decoding Chinglish 我忒 度 优 嗨佛 佛 得 瑞优你恩 低呢 Dictation English what do you have for the reunion dinner ASR English what do you high for 43 Union Cena Chinese 等等我 Reference English wait for me Reference Chinglish 唯特 佛 密 (wei te fo mi) Hybrid training/decoding Chinglish 位忒 佛 密 (wei te fo mi) Dictation English wait for me ASR English wait for me  <ref type="table">Table 8</ref>: Chinglish-to-English accuracy in auto- matic synthesis-recognition (ASR) task. Numbers are average edit distance between recognized En- glish and reference English.</p><p>Finally, we repeat the last experiment, but re- moving the human from the loop, using both automatic Chinese speech synthesis and English speech recognition. Results are shown in <ref type="table">Table 8</ref>. Speech recognition is more fragile than human transcription, so edit distances are greater. <ref type="table" target="#tab_8">Table 5</ref> shows a few examples of the Chinglish generated by the hybrid training and decoding method, as well as the recognized English from the dictation and ASR tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>Our work aims to help people speak foreign lan- guages they don't know, by providing native pho- netic spellings that approximate the sounds of for- eign phrases. We use a cascade of finite-state transducers to accomplish the task. We improve the model by adding phrases, word boundary con- straints, and improved alignment.</p><p>In the future, we plan to cover more language pairs and directions. Each target language raises interesting new challenges that come from its nat- ural constraints on allowed phonemes, syllables, words, and orthography.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Finite-state cascade for modeling the relation between Chinese and Chinglish.</figDesc><graphic url="image-2.png" coords="3,90.57,62.81,181.13,217.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Model</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Top 5 frequent syllables in Chinese 
(McEnery and Xiao, 2004) and Chinglish 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 )</head><label>3</label><figDesc></figDesc><table>and Viterbi align-
ments, such as: 

g 
r ae n d 
g e r uan d e 

5.2 Phoneme-phrase-based model 

Mappings between phonemes are context-
sensitive. For example, when we decode English 
"grandmother", we get: 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Learned translation tables for the 
phoneme based model 

g 
r ae n d 
m 
ah dh er 
g e r an 
d e m u e 
d 
e 
where as the reference Pinyin-split sequence is: 

g e r uan d e m a d e 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>English-to-Pinyin decoding accuracy on a test set of 65 utterances. Numbers are average edit 
distances between system output and Pinyin references. Valid average edit distance is calculated based 
only on valid outputs (e.g. 29 outputs for word based model). 

accept 
tips 
a ke sha pu te ti pu si 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Unseen English word type and tokens in 
test data. 

Model 
Valid Average 
Edit Distance 
Reference English 
0.477 
Phoneme based 
0.696 
Hybrid training and decoding 
0.496 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Chinglish generated by hybrid training and decoding method and corresponding recognized 
English by dictation and automatic synthesis-recognition method. 

Model 
Valid Average 
Edit Distance 
Word based 
0.925 
Word-based hybrid training 
0.925 
Phoneme based 
0.937 
Phoneme-phrase based 
0.896 
Hybrid training and decoding 
0.898 

</table></figure>

			<note place="foot" n="1"> Dataset can be found at http://www.isi.edu/ natural-language/mt/chinglish-data.txt</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Phrasebased machine transliteration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Finch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eiichiro</forename><surname>Sumita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Technologies and Corpora for AsiaPacific Speech Translation (TCAST)</title>
		<meeting>the Workshop on Technologies and Corpora for AsiaPacific Speech Translation (TCAST)</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="13" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Automatic generation of English respellings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bradley</forename><surname>Hauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Kondrak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="634" to="643" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Machine transliteration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Graehl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="599" to="612" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Statistical phrase-based translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz</forename><forename type="middle">Josef</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology</title>
		<meeting>the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="48" to="54" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">The lancaster corpus of Mandarin Chinese: A corpus for monolingual and contrastive language study. Religion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Mcenery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhonghua</forename><surname>Xiao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="3" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">The CMU pronunciation dictionary, release 0.7a</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Weide</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
