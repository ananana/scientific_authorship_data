<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:37+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Content Models for Survey Generation: A Factoid-Based Evaluation</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Jha</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catherine</forename><surname>Finegan-Dollak</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reed</forename><surname>Coke</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>King</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Information</orgName>
								<orgName type="institution">University of Michigan</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of EECS</orgName>
								<orgName type="institution">University of Michigan</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Content Models for Survey Generation: A Factoid-Based Evaluation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="441" to="450"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present a new factoid-annotated dataset for evaluating content models for scientific survey article generation containing 3,425 sentences from 7 topics in natural language processing. We also introduce a novel HITS-based content model for automated survey article generation called HITSUM that exploits the lexical network structure between sentences from citing and cited papers. Using the factoid-annotated data, we conduct a pyramid evaluation and compare HITSUM with two previous state-of-the-art content models: C-Lexrank, a network based content model, and TOPICSUM, a Bayesian content model. Our experiments show that our new content model captures useful survey-worthy information and outper-forms C-Lexrank by 4% and TOPICSUM by 7% in pyramid evaluation.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Survey article generation is the task of automat- ically building informative surveys for scientific topics. Given the rapid growth of publications in scientific fields, the development of such systems is crucial as human-written surveys exist for a lim- ited number of topics and get outdated quickly. In this paper, we investigate content models for extracting survey-worthy information from scien- tific papers. Such models are an essential com- ponent of any system for automatic survey arti- cle generation. Earlier work in the area of survey article generation has investigated content mod- els based on lexical networks ( <ref type="bibr" target="#b16">Mohammad et al., 2009;</ref><ref type="bibr" target="#b21">Qazvinian and Radev, 2008)</ref>. These mod- els take as input citing sentences that describe important papers on the topic and assign them a salience score based on centrality in a lexical net- work formed by the input citing sentences. In this</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Factoid</head><p>Weight Question Answering answer extraction 6 question classification 6 definition of question answering 5 TREC QA track 5 information retrieval 5 Dependency Parsing non-projective dependency structures / trees 6 projectivity / projective dependency trees 6 deterministic parsing approaches: Nivre's algorithm 5</p><p>terminology: head -dependent 4 grammar driven approaches for dependency parsing 4 <ref type="table">Table 1</ref>: Sample factoids from the topics of ques- tion answering and dependency parsing along with their factoid weights.</p><p>paper, we propose a new content model based on network structure previously unexplored for this task that exploits the lexical relationship between citing sentences and the sentences from the origi- nal papers that they cite. Our new formulation of the lexical network structure fits nicely with the hubs and authorities model for identifying impor- tant nodes in a network <ref type="bibr" target="#b12">(Kleinberg, 1999</ref>), leading to a new content model called HITSUM. In addi- tion to this new content model, we also describe how Bayesian content models previously explored in the news domain can be adapted for the content modeling task for survey generation. For the task of evaluating various content mod- els discussed in this paper, we have annotated a total of 3,425 sentences across 7 topics in the field of natural language processing with factoids from each of the topics. The factoids we use were ex- tracted from existing survey articles and tutorials on each topic ( <ref type="bibr" target="#b8">Jha et al., 2013)</ref>, and thus repre- sent information that must be captured by a survey article on the corresponding topic. Each of the fac- toids is assigned a weight based on its frequency in the surveys/tutorials, which allows us to do pyra-  <ref type="table" target="#tab_1">dependency parsing  487  named entity recognition  383  question answering  452  semantic role labeling  466  sentiment analysis  613  summarization  507  word sense disambiguation 425   Table 2</ref>: List of seven NLP topics used in our ex- periments along with input size. mid evaluation of our content models. Some sam- ple factoids are shown in <ref type="table">Table 1</ref>. Evaluation using factoids extracted from existing survey articles can help us understand the limits of automated survey article generation and how well these systems can be expected to perform. For example, if certain kinds of factoids are missing consistently from our input sentences, improvements in content models are unlikely to get us closer to the goal of generat- ing survey articles that match those generated by humans, and effort must be directed to extracting text from other sources that will contain the miss- ing information. On the other hand, if most of the factoids exist in the input sentences but important factoids are not found by the content models, we can think of strategies for improving these models by doing error analysis.</p><p>The main contributions of this paper are:</p><p>• HITSUM, a new HITS-based content model for automatic survey generation for scientific topics.</p><p>• A new dataset of 3,425 factoid-annotated sentences for scientific articles in 7 topics.</p><p>• Experimental results for pyramid evalua- tion comparing three existing content models (Lexrank, C-Lexrank, TOPICSUM) with HIT- SUM.</p><p>The rest of this paper is organized as follows. Section 2 describes the dataset used in our exper- iment and the factoid annotation process. Sec- tion 3 describes each of the content models used in our experiments including HITSUM. Section 4 describes our experiments and Section 5 summa- rizes the results. We summarize the related work in Section 6 and conclude in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data</head><p>Prior research in automatic survey generation has explored using text from different parts of scien- tific papers. Some of the recent work has treated survey generation as a direct extension of sin- gle paper summarization <ref type="bibr" target="#b21">(Qazvinian and Radev, 2008)</ref> and used citing sentences to a set of relevant papers as the input for the summarizer <ref type="bibr" target="#b16">(Mohammad et al., 2009;</ref><ref type="bibr" target="#b22">Qazvinian et al., 2013)</ref>. How- ever, in our prior work, we have observed that it's difficult to generate coherent and readable sum- maries using just citing sentences and have pro- posed the use of sentences from introductory texts of papers that cite a number of important papers on a topic ( <ref type="bibr" target="#b9">Jha et al., 2015)</ref>. The use of full text allows for the use of discourse structure of these documents in framing coherent and readable sur- veys. Since the content models we explore are meant to be part of a larger system that should be able to generate coherent and readable survey ar- ticles, we use the introduction sentences for our experiments as well.</p><p>The corpus we used for extracting our experi- mental data was the ACL Anthology Network, a comprehensive bibliographic dataset that contains full text and citations for papers in most of the important venues in natural language processing ). An oracle method is used for selecting the initial set of papers for each topic. For each topic, the bibliographies of at least three human-written surveys were extracted, and any papers that appeared in more than one survey were added to the target document set for the topic.</p><p>The text for summarization is extracted from in- troductory sections of papers that cite papers in the target document set. The intuition behind this is that the introductory sections of papers that cite these target document summarize the research in papers from the target document set as well as the relationships between these papers. Thus, these introductions can be thought of as mini-surveys for specific aspects of the topic; combining text from these introductory sections should allow us to generate good comprehensive survey articles for the topic <ref type="bibr">1</ref> . For our experiments, we sort the cit- ing papers based on the number of papers they cite Input sentence Factoids According to <ref type="bibr">[1]</ref> , the corpus based supervised machine learning methods are the most successful approaches to WSD where contextual features have been used mainly to distinguish ambiguous words in these methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>supervised wsd, corpus based wsd</head><p>Compared with supervised methods, unsupervised methods do not require tagged corpus, but the precision is usually lower than that of the supervised methods. supervised wsd, unsupervised wsd Word sense disambiguation (WSD) has been a hot topic in natural language processing, which is to determine the sense of an ambiguous word in a specific context. definition of word sense disambiguation Improvement in the accuracy of identifying the correct word sense will result in better machine translation systems, information retrieval systems, etc.</p><p>wsd for machine translation, wsd for in- formation retrieval The SENSEVAL evaluation framework <ref type="bibr">( Kilgarriff 1998</ref> ) was a DARPA-style competition designed to bring some conformity to the field of WSD, although it has yet to achieve that aim completely. senseval <ref type="table">Table 3</ref>: Sample input sentences from the topic of word sense disambiguation annotated with factoids.</p><p>in the target document set, pick the top 20 papers, and extract sentences from their introductions to form the input text for the summarizer. The seven topics used in our experiments and input size for each topic are shown in <ref type="table">Table 2</ref>.</p><p>Once the input text for each topic has been ex- tracted, we annotate the sentences in the input text with factoids for that topic. Some annotated sentences in the topic of word sense disambigua- tion are shown in <ref type="table">Table 3</ref>. Given this new an- notated data, we can compare how the factoids are distributed across different citing sentences (as annotated by <ref type="bibr" target="#b8">Jha et al. (2013)</ref>) and introduction sentences that we have annotated. For this, we divide the factoids into five categories: defini- tions, venue, resources, methodology, and appli- cations. The fractional distribution of factoids in these categories is shown in <ref type="table" target="#tab_1">Table 4</ref>. We can see that the distribution of factoids relating to venues, methodology and applications is similar for the two datasets. However, factoids related to defini- tional sentences are almost completely missing in the citing sentences data. This lack of background information in citing sentences is one of the moti- vations for using introduction sentences for survey article generation as opposed to previous work.</p><p>The complete set of factoids as well as annotated sentences for all the top- ics is available for download at http: //clair.si.umich.edu/corpora/ Surveyor_CM_Data.tar.gz.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Content Models</head><p>We now describe each of the content models used in our experiments.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Factoid category % Citing % Intro</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Lexrank</head><p>Lexrank is a network-based content selection al- gorithm that serves as a baseline for our experi- ments. Given an input set of sentences, it first cre- ates a network using these sentences where each node represents a sentence and each edge repre- sents the tf-idf cosine similarity between the sen- tences. Two methods for creating the network are possible. First, we can remove all edges that are lower than a certain threshold of similarity (gener- ally set to 0.1). The Lexrank value for a node p(u) in this case is calculated as:</p><formula xml:id="formula_0">1 − d N + d v∈adj[u] p(v) deg(v)</formula><p>Where N is the total number of sentences, d is the damping factor that controls the probability of a random jump (usually set to 0.85), deg(v) is the degree of the node v, and adj <ref type="bibr">[u]</ref> is the set of nodes connected to the node u. A different way of creat- ing the network is to treat the sentence similarities as edge weights and use the adjacency matrix as a transition matrix after normalizing the rows; the formula then becomes:</p><p>A dictionary such as the LDOCE has broad coverage of word senses, useful for WSD . This paper describes a program that disambiguates English word senses in unrestricted text using statistical models of the major Roget's Thesaurus categories. Our technique offers benefits both for online semantic processing and for the challenging task of mapping word senses across multiple MRDs in creating a merged lexical database. The words in the sentences may be any of the 28,000 headwords in Longman's Dictionary of Contemporary English (LDOCE) and are disambiguated relative to the senses given in LDOCE. This paper describes a heuristic approach to automatically identifying which senses of a machine- readable dictionary (MRD) headword are semantically related versus those which correspond to fundamentally different senses of the word. <ref type="figure">Figure 1</ref>: A sentence from P citing with a high hub score (bolded) and some of sentences from P cited that it links to (italicised). The sentence from P citing obtain a high hub score by being connected to the sentences with high authority scores.</p><formula xml:id="formula_1">1 − d N + d v∈adj[u] cos(u, v) T otalCos v p(v)</formula><p>Where cos(u, v) gives the tf-idf cosine similar- ity between sentence u and v and T otalCos v = z∈adj <ref type="bibr">[v]</ref> cos(z, v). In our experiments, we em- ploy this second formulation. The above equation can be solved efficiently using the power method <ref type="bibr" target="#b19">(Newman, 2010)</ref> to obtain p(u) for each node, which is then used as the score for ordering the sentences. The final Lexrank values p(u) for a node represent the stationary distribution of the Markov chain represented by the transition matrix. Lexrank has been shown to perform well in sum- marization experiments ( <ref type="bibr" target="#b4">Erkan and Radev, 2004</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">C-Lexrank</head><p>C-Lexrank is a clustering-based summarization system that was proposed by <ref type="bibr" target="#b21">Qazvinian and Radev (2008)</ref> to summarize different perspectives in cit- ing sentences that reference a paper or a topic. To create summaries, C-LexRank constructs a fully connected network in which vertices are sen- tences, and edges are cosine similarities calculated using the tf-idf vectors of citation sentences. It then employs a hierarchical agglomeration clus- tering algorithm proposed by <ref type="bibr" target="#b1">Clauset et al. (2004)</ref> to find communities of sentences that discuss the same scientific contributions. Once the graph is clustered and communities are formed, the method extracts sentences from different clusters to build a summary. It iterates through the clusters from largest to smallest, choosing the most salient sen- tence of each cluster, until the summary length limit is reached. The salience of a sentence in its cluster is defined as its Lexrank value in the lexical network formed by sentences in the cluster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">HITSUM</head><p>The input set of sentences in our data come from introductory sections of papers that cite important papers on a topic. We'll refer to the set of cit- ing papers that provide the input text for the sum- marizer as P citing and the set of important papers that represent the research we are trying to sum- marize as P cited . Both Lexrank and C-Lexrank work by finding central sentences in a network formed by the input sentences and thus, only use the lexical information present in P citing , while ig- noring additional lexical information from the pa- pers in P cited . We now present a formulation that uses the network structure that exists between the sentences in the two sets of papers to incorporate additional lexical information into the summariza- tion system. This system is based on the hubs and authorities or the HITS model <ref type="bibr" target="#b12">(Kleinberg, 1999)</ref> and hence is called HITSUM.</p><p>HITSUM, in addition to the sentences from the introductory sections of papers in P citing , also uses sentences from the abstracts of P cited . It starts by computing the tf-idf cosine similarity between the sentences of each paper p i ∈ P citing with the sentences in the abstracts of each paper p j ∈ P cited that is directly cited by p i . A directed edge is cre- ated between every sentence s i in p i and s j in p j if sim(s i , s j ) &gt; s min , where s min is a similarity threshold (set to 0.1 for our experiments). Once this process has been completed for all papers in P citing , we end up with a bipartite graph between sentences from P citing and P cited .</p><p>In this bipartite graph, sentences in P cited that  have a lot of incoming edges represent sentences that presented important contributions in the field. Similarly, sentences in P citing that have a lot of outgoing edges represent sentences that summa- rize a number of important contributions in the field. This suggests using the HITS algorithm, which, given a network, assigns hubs and author- ities scores to each node in the network in a mu- tually reinforcing way. Thus, nodes with high au- thority scores are those that are pointed to by a number of good hubs, and nodes with high hub scores are those that point to a number of good authorities. This can be formalized with the fol- lowing equation for the hub score of a node:</p><note type="other">φB φ C/QA φ D/J07−1005 φ C/N ER φ D/I08−1071 the 0.</note><note type="other">for 0.014 system 0.011 appropriately 0.00016 tagging 0.007 dakka 0.0009 that 0.012 trec 0.008 organized 0.00016 recognition 0.007 service 0.0009 we 0.011 factoid 0.008 foundation 0.00016 classes 0.007</note><formula xml:id="formula_2">h(v) = u∈successors(v) a(u)</formula><p>Where h(v) is the hub score for node v, successors(v) is the set of all nodes that v has an edge to, and a(u) is the authority score for node u. Similarly, the authority score for each node is computed as:</p><formula xml:id="formula_3">a(v) = u∈predecessors(v) h(u)</formula><p>Where predecessors(v) is the set of all nodes that have an edge to v. The hub and authority score for each node can be computed using the power method that starts with an initial value and itera- tively updates the scores for each node based on the above equations until the hub and authority scores for each node converge to within a toler- ance value (set to 1E-08 for our experiments).</p><p>In our bipartite lexical network, we expect sen- tences in P cited receiving high authority scores to be the ones reporting important contributions and sentences in P citing that receive high hub scores to be sentences summarizing important contribu- tions. <ref type="figure">Figure 1</ref> shows an example of a sentence with a high hub score from the topic of word sense disambiguation, along with some of the sentences that it points to. HITSUM computes the hub and authority score for each sentence in the lexical net- work and then uses the hub scores for sentences in P citing as their relevance score. Sentences from P cited are part of the lexical network, but are not used in the output summary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">TOPICSUM</head><p>TOPICSUM is a probabilistic content model pre- sented in <ref type="bibr" target="#b6">Haghighi and Vanderwende (2009)</ref> and is very similar to an earlier model called BayesSum proposed by <ref type="bibr" target="#b2">Daumé and Marcu (2006)</ref>. It is a hierarchical, LDA (Latent Dirichlet Alloca- tion) style model that is based on the following generative story: 2 words in any sentence in the corpus can come from one of three word distri- butions: a background word distribution φ B that flexibly models stop words, a content word dis- tribution φ C for each document set that models content relevant to the entire document set, and a document-specific word distribution φ D . The word distributions are learned using Gibbs sam- pling. Given n document sets each with k doc-  uments, we get n content word distributions and n * k document-specific distributions leading to a total of 1 + n + n * k word distributions.</p><p>To illustrate the kind of distributions TOPIC- SUM learns in our dataset, <ref type="figure" target="#fig_1">Figure 2</ref> shows the top words along with their probabilities from the background word distribution, two content distri- butions and two document-specific word distribu- tions. We see that the model effectively captures general content words for each topic. φ C/QA is the word distribution for the topic of question answer- ing, while φ D/J07−1005 is the document-specific word distribution for a specific paper in the docu- ment set for question answering 3 that focuses on clinical question answering. The word distribu- tion φ D/J07−1005 contains words that are relevant to the specific subtopic in the paper, while φ C/QA contains content words relevant to the general topic of question answering. Similar results can be seen in the word distributions for named entity recognition φ C/N ER and the document-specific word distribution for a specific paper in the topic φ D/I08−1071 4 that focuses on comparable entity mining.</p><p>These topics, learned using Gibbs sampling, can be used to select sentences for a summary in the following way. To summarize a document set, we greedily select sentences that minimize the KL- divergence of our summary to the document-set- specific topic. Thus, the score for each sentence s is KL(φ C ||P s ) where P s is the sentence word dis- tribution with add-one smoothing applied to both distributions. Using this objective, sentences that contain words from the content word distribution with high probability are more likely to be selected in the generated summary.</p><p>We implemented TOPICSUM in Python using Numpy and then optimized it using Scipy Weave. This code is available for use at https://github.com/rahuljha/ content-models.</p><p>The repository also contains Python code for HITSUM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>For evaluating our content models, we gener- ated 2,000-character-long summaries using each of the systems (Lexrank, C-Lexrank, HITSUM, and TOPICSUM) for each of the topics. The sum- maries are generated by ranking the input sen- tences using each content model and picking the top sentences till the budget of 2,000 characters is reached. Each of these summaries is then given a pyramid score ( <ref type="bibr" target="#b18">Nenkova and Passonneau, 2004</ref>) computed using the factoids assigned to each sen- tence.</p><p>For the pyramid evaluation, the factoids are or- ganized in a pyramid of order n. The top tier in this pyramid contains the highest weighted fac- toids, the next tier contains the second highest weighted factoids, and so on. The score assigned to a summary is the ratio of the sum of the weights of the factoids it contains to the sum of weights of an optimal summary with the same number of factoids. Pyramid evaluation allows us to capture how each content model performs in terms of se- lecting sentences with the most highly weighted factoids. Since the factoids have been extracted from human-written surveys and tutorials on each of the topics, the pyramid score gives us an idea of the survey-worthiness of the sentences selected by Question classification is a crucial component of modern question answering system. A what-type question is defined as the one whose question word is 'what', 'which', 'name' or 'list'. This metaclassifier beats all published numbers on standard question classification benchmarks <ref type="bibr">[4.4]</ref>. Due to its challenge, this paper focuses on what-type question classification. In this paper, we focus on fine-category classification. The promise of a machine learning approach is that the QA system builder can now focus on de- signing features and providing labeled data, rather than coding and maintaining complex heuristic rule bases. each content model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and Discussion</head><p>The results of pyramid evaluation are summarized in <ref type="table" target="#tab_4">Table 5</ref>. It shows the pyramid score obtained by each system on each of the topics as well as the av- erage score. The highest performing system on av- erage is HITSUM with an average performance of 76%. HITSUM does especially well for the topics of dependency parsing, question answering, and word sense disambiguation. The second best per- forming system is C-Lexrank, which is not sur- prising because it was developed specifically for the task of scientific paper summarization. How- ever, HITSUM outperforms C-Lexrank on several topics and by 4% on average. <ref type="figure" target="#fig_3">Figure 3</ref> shows part of the summary generated by HITSUM for the topic of question answering. The summary contains mostly informative sen- tences about different aspects of question answer- ing. One obvious drawback of this summary is that it's not very coherent and readable. How- ever, previous work has shown how network based content models can be combined with discourse models to generate informative yet readable sum- maries ( <ref type="bibr" target="#b9">Jha et al., 2015)</ref>. We looked at some of the network statistics of the lexical networks used by HITSUM. One of the things we noticed is that the lexical networks for topics where HITSUM per- forms well seem to have higher degree assorta- tivity compared to the topics for which it doesn't perform well. High degree assortativity in lexical networks means sentences with high degree tend to be linked to other sentences with high degree. This suggests that HITS performs well for topics where a set of important factoids are mentioned in many citing and source sentences. A larger evalua- tion dataset is needed for a more thorough analysis of how the network properties of these lexical net- works correlate with the performance of various content models.</p><p>TOPICSUM does well on the topics of named entity recognition and sentiment analysis, but does not do well on average. This can be attributed to the fact that it was developed as a content model for the domain of news summarization and does not translate well to our domain. All systems out- perform Lexrank, which achieves the lowest aver- age score. This result is also intuitive, because ev- ery other system in our evaluation uses additional information not used by Lexrank: C-Lexrank ex- ploits the community structure in the input set of sentences, HITSUM exploits the lexical informa- tion from cited sentences, and TOPICSUM exploits information about global word distribution across all topics.</p><p>The different systems we tried in our evaluation depend on using different lexical information and seem to perform well for different topics. This suggests that further gains can be made by com- bining these systems. For example, C-Lexrank and HITSUM can be combined by utilizing both the network formed by citing sentences and the network between the citing sentences and the cited sentences into a larger lexical network. TOPIC- SUM scores can be combined with these network- based system by using the TOPICSUM scores as a prior for each node, and then running either Pager- ank or HITS on top of it. We leave exploration of such hybrid systems to future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>The goal of content models in the context of sum- marization is to extract a representation from in- put text that can help in identifying important sen- tences that should be in the output summary. Our work is related to two main classes of content models: network-based methods and probabilis-tic methods. We summarize related work for each of these classes of content models, followed by a short summary of the related work in the domain of scientific summarization.</p><p>Network-based content models: Network- based content models ( <ref type="bibr" target="#b4">Erkan and Radev, 2004;</ref><ref type="bibr" target="#b15">Mihalcea and Tarau, 2004</ref>) work by converting the input sentences into a network. Each sentence is represented by a node in the network, and the edges between sentences are given weight based on the similarities of sentences. They then run Pagerank on this network, and sentences are selected based on their Pagerank score in the network. For computing Pagerank, the network can either be pruned by removing edges that have weights less than a certain threshold, or a weighted version of Pagerank can be run on the network. The method can also be modified for query-focused summarization <ref type="bibr" target="#b20">(Otterbacher et al., 2009</ref>). C-Lexrank ( <ref type="bibr" target="#b21">Qazvinian and Radev, 2008</ref>) modifies Lexrank by first running a clus- tering algorithm on the network to partition the network into different communities and then selecting sentences from each community by running Lexrank on the sub-network within each community. C-Lexrank was also used in the task of automated survey generation with encouraging results ( <ref type="bibr" target="#b16">Mohammad et al., 2009)</ref>.</p><p>Probabilistic content models: One of the first probabilistic content models seems to be BAYESSUM ( <ref type="bibr" target="#b2">Daumé and Marcu, 2006</ref>), designed for query-focused summarization. BAYESSUM models a set of document collections using a hi- erarchical LDA style model. Each word in a sen- tence can be generated using one of three language models: 1) a general English language model that captures English filler or background knowledge, 2) a document-specific language model, and 3) a query language model. These language models are inferred using expectation propagation, and then sentences are ranked based on their likelihood of being generated from the query language model. A similar model for general multidocument sum- marization called TOPICSUM was proposed by <ref type="bibr" target="#b6">Haghighi and Vanderwende (2009)</ref>, where the query language model is replaced by a document- collection-specific language model; thus sentences are selected based on how likely they are to con- tain information that summarizes the entire doc- ument collection instead of information pertain- ing to individual documents or background knowl- edge. <ref type="bibr" target="#b0">Barzilay and Lee (2004)</ref> present a Hidden Markov Model (HMM) based content model where the hidden states of the HMM represent the topics in the text. The transition probabili- ties are learned through Viterbi decoding. They show that the HMM model can be used for both re- ordering of sentences for coherence and discrimi- native scoring of sentences for extractive summa- rization. <ref type="bibr" target="#b5">Fung and Ngai (2006)</ref> present a simi- lar HMM-based model for multi-document sum- marization. <ref type="bibr" target="#b10">Jiang and Zhai (2005)</ref> proposed an HMM-based model for the problem of extract- ing coherent passages relevant to a query from a relevant document. They learn an HMM with two background states (B 1 and B 2 ) and a query- relevant state (R), each associated with a language model. The HMM starts in background state B 1 , switches to relevant state R and then switches to the next background state B 2 . The sentences that the HMM emits while in R constitute the query- relevant passage from the document.</p><p>Scientific summarization: Early work in scien- tific summarization used abstracts of scientific ar- ticles to produce summaries of specific scientific papers ( <ref type="bibr" target="#b13">Kupiec et al., 1995)</ref>. However, later work ( <ref type="bibr" target="#b3">Elkiss et al., 2008)</ref> showed that citation sentences are as important in understanding the main contri- butions of a paper.</p><p>Nanba and Okumura (1999) explored using ref- erence information to build a system for support- ing writing survey articles. Their system extracts citing sentences that describe a referred paper and identify the type of reference relationships. The type of references can be one of the three: 1) type B that base on other researcher's theory, 2) type C that compare with related works, or 3) type O representing relationships other than B or C. They posit that type C sentences are the most important for survey generation and can help show the simi- larities and differences among cited papers. <ref type="bibr" target="#b24">Teufel and Moens (2002)</ref> propose a method for summarizing scientific articles based on rhetorical status of sentences in scientific articles. They an- notate sentences in a corpus of 80 scientific arti- cles with rhetorical status, where the rhetorical sta- tus can be one of aim (specific research goal), tex- tual (section structure), own (neutral description of own work), background (generally accepted back- ground), contrast (comparison with other work), basis (agreement with or continuation of other work), and other (neutral description of other's work). They describe classifiers for tagging the rhetorical status of sentences automatically and present a method for using this to assign relevance score to sentences.</p><p>In other work, <ref type="bibr" target="#b11">Kan et al. (2002)</ref> use a corpus of 2000 annotated bibliographies for scientific papers as a first step towards a supervised summariza- tion system. They found that summaries in their corpus were mostly single-document abstractive summaries that were both indicative and informa- tive and were organized around a "theme," making them ideal for query-based summarization. <ref type="bibr" target="#b14">Mei and Zhai (2008)</ref> presented an impact-based sum- marization method for single-paper summariza- tion that assigns relevance scores to sentences in a paper based on their similarity to the set of cit- ing sentences that reference the paper.</p><p>More recently, Hoang and Kan (2010) present a method for automated related work generation. Their system takes as input a set of keywords ar- ranged in a hierarchical fashion that describes a target paper's topic. They hypothesize that sen- tences in a related work provide either background information or specific contributions. They use two different models to extract these two kinds of sentences using the input tree and combines them to create the final output summary. <ref type="bibr" target="#b25">Zhang et al. (2013)</ref> explore methods for biomedical sum- marization by identifying cliques in a network of semantic predications extracted from citations. These cliques are then clustered and labeled to identify different points of view represented in the summary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion and Future Work</head><p>We have presented a new factoid-annotated dataset for evaluating content models for scientific survey article generation by annotating sentences from seven topics in natural language processing. We also introduce a new HITS-based content model called HITSUM for survey article generation that exploits the lexical information from cited papers along with citing papers to rank input sentences for survey-worthiness.</p><p>We conduct pyramid evaluation using our factoid dataset to compare HITSUM with existing network-based methods (Lexrank, C-Lexrank) as well as methods based on Bayesian content modeling (TOPICSUM). On average, HITSUM outperforms C-Lexrank by 4% and TOPICSUM by 7%. Since the different con- tent models use different kinds of lexical informa- tion, further gains might be obtained by combining some of these models into a joint model. We plan to explore this in future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Top words from different word distributions learned by TOPICSUM on our input document set of 15 topics. φ B is the background word distribution that captures stop words. φ C/QA and φ C/N ER are the word distributions for the topics of question answering and named entity recognition respectively. φ D/J07−1005 is the document-specific word distribution for a single paper in question answering that focuses on clinical question answering. φ D/I08−1071 is the document-specific word distribution for a single paper in named entity recognition that focuses on named entity recognition in Wikipedia articles.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>3</head><label></label><figDesc>Dina Demner-Fushman and Jimmy Lin. 2007. Answer- ing Clinical Questions with Knowledge-Based and Statistical Techniques. Computational Linguistics. 4 Wisam Dakka and Silviu Cucerzan. 2008. Augmenting wikipedia with named entity tags. In Proceedings of IJCNLP.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Part of the summary generated by HITSUM for the topic of question answering.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Fractional distribution of factoids across 
various categories in citing sentences vs introduc-
tion sentences. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Pyramid scores obtained by different content models for each topic along with average scores 
for each model across all topics. For each topic as well as the average, the best performing method has 
been highlighted with a  *  . 

</table></figure>

			<note place="foot" n="1"> Other sections of papers might have such information, e.g. related work. Initial data analysis showed, however, that not all papers in our corpus had related work sections. Thus for consistency, we decided to use introduction sections. The perfect system for this task would be able to extract &quot;related work style&quot; text segments from an entire paper.</note>

			<note place="foot" n="2"> To avoid confusion in use of the term &quot;topic,&quot; in this paper we refer to topics in the LDA sense as &quot;word distributions.&quot; &quot;Topics&quot; in this paper refer to the natural language processing topics such as question answering, word sense disambiguation, etc.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Catching the drift: Probabilistic content models, with applications to generation and summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLTNAACL 2004: Main Proceedings</title>
		<editor>Daniel Marcu Susan Dumais and Salim Roukos</editor>
		<meeting><address><addrLine>Boston, Massachusetts, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-05-02" />
			<biblScope unit="page" from="113" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Finding community structure in very large networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Clauset</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristopher</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. E</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">66111</biblScope>
			<date type="published" when="2004-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Bayesian query-focused summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">,</forename><surname>Iii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics, ACL-44</title>
		<meeting>the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics, ACL-44<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="305" to="312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Blind men and elephants: What do citation summaries tell us about a research article</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Elkiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siwei</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Günesgünes¸</forename><surname>Günes¸erkan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>States</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><forename type="middle">R</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Society for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="51" to="62" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Lexrank: Graph-based centrality as salience in text summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><forename type="middle">R</forename><surname>Günesgünes¸günes¸erkan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<date type="published" when="2004" />
			<publisher>JAIR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">One story, one flow: Hidden markov story models for multilingual multidocument summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grace</forename><surname>Ngai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Speech Lang. Process</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2006-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Exploring content models for multi-document summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aria</forename><surname>Haghighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucy</forename><surname>Vanderwende</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, NAACL &apos;09</title>
		<meeting>Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, NAACL &apos;09<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="362" to="370" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Towards automated related work summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cong</forename><surname>Duy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min-Yen</forename><surname>Kan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics: Posters, COLING &apos;10</title>
		<meeting>the 23rd International Conference on Computational Linguistics: Posters, COLING &apos;10<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="427" to="435" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A system for summarizing scientific topics starting from keywords</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amjad</forename><surname>Abu-Jbara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><forename type="middle">R</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The Association for Computational Linguistics</title>
		<meeting>The Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>short paper</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Surveyor: A system for generating coherent survey articles for scientific topics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reed</forename><surname>Coke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><forename type="middle">R</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Ninth AAAI Conference</title>
		<meeting>the Twenty-Ninth AAAI Conference</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Accurately extracting coherent relevant passages using hidden Markov models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="289" to="290" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Using the Annotated Bibliography as a Resource for Indicative Summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min-Yen</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judith</forename><forename type="middle">L</forename><surname>Klavans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><forename type="middle">R</forename><surname>Mckeown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The International Conference on Language Resources and Evaluation (LREC)</title>
		<meeting><address><addrLine>Las Palmas, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Authoritative sources in a hyperlinked environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><forename type="middle">M</forename><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="604" to="632" />
			<date type="published" when="1999-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A trainable document summarizer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Kupiec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Pedersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francine</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR-95)</title>
		<meeting>the 18th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR-95)</meeting>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="68" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Generating impact-based summaries for scientific literature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaozhu</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th Annual Conference of the Association for Computational Linguistics (ACL-08)</title>
		<meeting>the 46th Annual Conference of the Association for Computational Linguistics (ACL-08)</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="816" to="824" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">TextRank: Bringing order into texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Tarau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-04)</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP-04)</meeting>
		<imprint>
			<date type="published" when="2004-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Using citations to generate surveys of scientific paradigms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saif</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Dorr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melissa</forename><surname>Egan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pradeep</forename><surname>Muthukrishan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vahed</forename><surname>Qazvinian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Zajic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, NAACL &apos;09</title>
		<meeting>Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, NAACL &apos;09<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="584" to="592" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Towards multi-paper summarization using reference information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hidetsugu</forename><surname>Nanba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manabu</forename><surname>Okumura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th International Joint Conference on Artificial Intelligence (IJCAI-99)</title>
		<meeting>the 16th International Joint Conference on Artificial Intelligence (IJCAI-99)</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="926" to="931" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Evaluating content selection in summarization: The pyramid method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Passonneau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the North American Chapter of the Association for Computational Linguistics-Human Language Technologies (HLTNAACL &apos;04)</title>
		<meeting>the North American Chapter of the Association for Computational Linguistics-Human Language Technologies (HLTNAACL &apos;04)</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Networks: An Introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Newman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Biased lexrank: Passage retrieval using random walks with question-based priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jahna</forename><surname>Otterbacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gunes</forename><surname>Erkan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><forename type="middle">R</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Process. Manage</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="42" to="54" />
			<date type="published" when="2009-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Scientific paper summarization using citation summary networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vahed</forename><surname>Qazvinian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><forename type="middle">R</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Computational Linguistics (COLING-08)</title>
		<meeting>the 22nd International Conference on Computational Linguistics (COLING-08)<address><addrLine>Manchester, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Generating extractive summaries of scientific paradigms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vahed Qazvinian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dragomir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Radev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Saif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Dorr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Zajic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesun</forename><surname>Whidby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Moon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Artif. Int. Res</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="165" to="201" />
			<date type="published" when="2013-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dragomir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Radev</surname></persName>
		</author>
		<title level="m">Pradeep Muthukrishnan, Vahed Qazvinian, and Amjad Abu-Jbara. 2013. The acl anthology network corpus. Language Resources and Evaluation</title>
		<imprint>
			<biblScope unit="page" from="1" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Summarizing scientific articles: experiments with relevance and rhetorical status</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Teufel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Moens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="409" to="445" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Clustering cliques for graph-based summarization of the biomedical research literature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcelo</forename><surname>Fiszman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongwook</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bartlomiej</forename><surname>Wilkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">C</forename><surname>Rindflesch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">182</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
