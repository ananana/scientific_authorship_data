<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:27+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Tackling the Story Ending Biases in The Story Cloze Test</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 15-20, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rishi</forename><surname>Sharma</surname></persName>
							<email>rishi.sharma@rochester.edu,</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Rochester</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">F</forename><surname>Allen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Rochester</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute for Human and Machine Cognition</orgName>
								<address>
									<addrLine>3 Verneek.ai 4 Elemental Cognition</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omid</forename><surname>Bakhshandeh</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nasrin</forename><surname>Mostafazadeh</surname></persName>
							<email>nasrinm@cs.rochester.edu</email>
						</author>
						<title level="a" type="main">Tackling the Story Ending Biases in The Story Cloze Test</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="752" to="757"/>
							<date type="published">July 15-20, 2018</date>
						</imprint>
					</monogr>
					<note>752</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The Story Cloze Test (SCT) is a recent framework for evaluating story comprehension and script learning. There have been a variety of models tackling the SCT so far. Although the original goal behind the SCT was to require systems to perform deep language understanding and commonsense reasoning for successful narrative understanding, some recent models could perform significantly better than the initial baselines by leverag-ing human-authorship biases discovered in the SCT dataset. In order to shed some light on this issue, we have performed various data analysis and analyzed a variety of top performing models presented for this task. Given the statistics we have ag-gregated, we have designed a new crowd-sourcing scheme that creates a new SCT dataset, which overcomes some of the biases. We benchmark a few models on the new dataset and show that the top-performing model on the original SCT dataset fails to keep up its performance. Our findings further signify the importance of benchmarking NLP systems on various evolving test sets.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Story comprehension has been one of the longest- running ambitions in artificial intelligence <ref type="bibr" target="#b4">(Dijk, 1980;</ref><ref type="bibr" target="#b2">Charniak, 1972)</ref>. One of the challenges in expanding the field had been the lack of a solid evaluation framework and datasets on which comprehension models can be trained and tested. <ref type="bibr" target="#b12">Mostafazadeh et al. (2016)</ref> introduced the Story Cloze Test (SCT) evaluation framework to address * This work was performed at <ref type="bibr">University of Rochester.</ref> this issue. This test evaluates a story compre- hension system where the system is given a four- sentence short story as the 'context' and two al- ternative endings and to the story, labeled 'right ending' and 'wrong ending.' Then, the system's task is to choose the right ending. In order to support this task, Mostafazadeh et al. also pro- vide the ROC Stories dataset, which is a collection of crowd-sourced complete five sentence stories through Amazon Mechanical Turk (MTurk). Each story follows a character through a fairly simple series of events to a conclusion.</p><p>Several shallow and neural models, includ- ing the state-of-the-art script learning approaches, were presented as baselines ( <ref type="bibr" target="#b12">Mostafazadeh et al., 2016)</ref> for tackling the task, where they show that all their models perform only slightly better than a random baseline suggesting that richer models are required for tackling this task. A variety of new systems were proposed <ref type="bibr" target="#b11">(Mihaylov and Frank, 2017;</ref><ref type="bibr" target="#b16">Schenk and Chiarcos, 2017;</ref><ref type="bibr" target="#b18">Schwartz et al., 2017b;</ref><ref type="bibr" target="#b15">Roemmele et al., 2017</ref>) as a part of the first shared task on SCT at LSDSem'17 work- shop ( <ref type="bibr" target="#b13">Mostafazadeh et al., 2017)</ref>. Surprisingly, one of the models made a staggering improve- ment of 15% to the accuracy, partially due to us- ing stylistic features isolated in the ending choices ( <ref type="bibr" target="#b18">Schwartz et al., 2017b</ref>), discarding the narrative context. Clearly, this success does not seem to re- flect the intent of the original task, where the sys- tems should leverage narrative understanding as opposed to the statistical biases in the data. In this paper, we study the effect of such biases between the ending choices and present a new scheme to reduce such stylistic artifacts.</p><p>The contribution of this paper is threefold: (1) we provide an extensive analysis of the SCT dataset to shed some light on the ending data char- acteristics (Section 3) (2) we develop a new strong classifier for tackling the SCT that uses a variety <ref type="bibr">Context</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Right Ending Wrong Ending</head><p>Ramona was very unhappy in her job. She asked for a raise, but was denied. The refusal prompted her to aggressively comb the want ads. She found an interesting new possibility and set up an interview.</p><p>She was offered the new job at a higher salary.</p><p>Ramona had no reason to want to change jobs any- more.</p><p>The teacher was walking with a stack of papers. Outside started to rain. When the teacher tried to walk down a few steps, she ended up falling. The papers flew out of her hands and landed on the ground.</p><p>A passer-by helped her up and helped her collect the papers.</p><p>The teacher got up and walked home leaving the papers behind. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>This paper mainly extends the work on cre- ating the Story Cloze Test set ( <ref type="bibr" target="#b12">Mostafazadeh et al., 2016)</ref>, hereinafter SCT-v1.0. The SCT-v1.0 dataset was created as follows: full five-sentence stories from the ROC Stories corpus were sam- pled, then, the initial four sentences were shown to a set of MTurk 2 crowd workers who were prompted to author 'right' and 'wrong' endings. <ref type="bibr" target="#b12">Mostafazadeh et al. (Mostafazadeh et al., 2016)</ref> give special care to make sure there were no boundary cases for 'right' and 'wrong' endings by implementing extra rounds of data filtering. The resulting SCT-v1.0 dataset had a validation (here- inafter, SCT-v1.0 Val) and a test set (SCT-v1.0 test), each with 1,871 cases.  Furthermore, we conducted an extensive n- gram analysis, using word tokens, characters, part- of-speech, and token-POS (similar to <ref type="bibr" target="#b18">Schwartz et al. (Schwartz et al., 2017b)</ref>) as features. We see char-grams such as "sn't" and "not" appear more commonly in the 'wrong endings', suggest- ing heavy negation. In 'right endings', pronouns are used more frequently versus proper nouns used in 'wrong endings'. Artifacts such as 'pizza' are common in 'wrong endings,' which could suggest that for a given topic, the authors may replace an object in a right ending with a wrong one and quickly think up a common item such as pizza to create a 'wrong' one. An extensive analysis of these features, including the n-gram analysis, can be found in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Model</head><p>Following the analysis above, we developed a Story Cloze model, hereinafter EndingReg, that only uses the ending features while disregarding the story context for choosing the right ending. We expanded each Story Cloze Test case's ending op- tions into a set of two single sentences. Then, for each sentence, we created the following features:</p><p>1. Number of tokens 2. VADER composite sentiment score 3. Yngve complexity score 4. Token-POS n-grams 5. POS n-grams 6. Four length character-grams All n-gram features needed to appear at least five times throughout the dataset. The features were collected for each five-sentence story and then fed into a logistic regression classifier. As an initial experiment, we trained this model using the SCT- v1.0 validation set and tested on the SCT-v1.0 test set. An L2 regularization penalty was used to en- force a Gaussian prior on the feature-space, where a grid search was conducted for hyper-parameter tuning. This model achieves an accuracy of 71.5% on the SCT-v1.0 dataset which is on par with the highest score achieved by any model using only the endings. <ref type="table">Table 3</ref> shows the accuracies ob- tained by models using only those particular fea- tures. We achieve minimal but sometimes impor- tant classification using token count, VADER, and Yngve in combination alone, better classification using POS or char-grams alone, and best classifi- cation using n-grams alone. By combining all of them we achieve the overall best results.  <ref type="table">Table 3</ref>: Classification results on SCT-v1.0 using each of the feature sets designated in the columns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Data Collection</head><p>Based on the findings above, a new test set for the SCT was deemed necessary. The premise of pre- dicting an ending to a short story, as opposed to predicting say a middle sentence, enables a more systematic evaluation where human can agree on the cases 100%. Hence, our goal was to come up with a data collection scheme that overcomes the data collection biases, while keeping the original evaluation format. As the data analysis revealed, the token count, sentiment, and the complexity are not as important features for classification as the ending n-grams are. We set the following goals for sourcing the new 'right' and 'wrong' endings. They both should:</p><p>1. Contain a similar number of tokens 2. Have similar distributions of token n-grams and char-grams 3. Occur as standalone events with the same likelihood to occur, with topical, sentimental, or emotion consistencies when applicable.</p><p>First, we crowdsourced 5,000 new five-sentence stories through Amazon Mechanical Turk. We prompted the users in the same manner described in <ref type="bibr" target="#b12">Mostafazadeh et al. (2016)</ref>. In order to source new 'wrong' endings, we tried two different meth- ods. In Method #1, we kept the original ending sourcing format of Mostafazadeh et al., but im- posed some further restrictions. This was done by taking the first four sentences of the newly col- lected stories and asking an MTurker to write a 'right' and 'wrong' ending for each. The new re- strictions were: 'Each sentence should stay within the same subject area of the story,' and 'The num- ber of words in the Right and Wrong sentences should not differ by more than 2 words,' and 'When possible, the Right and Wrong sentences should try to keep a similar tone/sentiment as one another.' The motivation behind this technique was to reduce the statistical differences by asking the user to be mindful of considerations.</p><p>In Method #2, we took the five sentences sto- ries and prompted a second set of MTurk workers to modify the fifth sentence in order to make a re- sulting five-sentence story non-sensible. Here, the prompt instructs the workers to make sure the new 'wrong ending' sentence makes sense standalone, that it does not differ in the number of words from the original sentence by more than three words, and that the changes cannot be as simple as e.g., putting the word 'not' in front of a description or a verb. As a result, the workers had much less flexi- bility for changing the underlying linguistic struc- tures which can help tackle the authorship style differences between the 'right' and 'wrong' end- ings.</p><p>The results in <ref type="table" target="#tab_4">Table 4</ref>, which show classifi- cation accuracy when using EndingReg on the two new data sources, show that Method #2 is a slightly better data sourcing scheme in reduc- ing the bias, since the EndingReg model's per- formance is slightly worse. The set was fur- ther filtered through human verification similar to <ref type="bibr" target="#b12">Mostafazadeh et al. (2016)</ref>. The filtering was done by splitting each SCT-v1.0's two alternative endings into two independent five-sentence stories and asking three different MTurk users to catego- rize the story as either: one where the story made complete sense, one where the story made sense until the last sentence and one where the story does not make sense for another reason. Stories were only selected if all the three MTurk users ver- ified that the story with the 'right ending' and the corresponding story with the 'wrong ending' were verified to be indeed right and wrong respectively. This ensured a higher quality of data and eliminat- ing boundary cases. This entire process resulted in creating the Story Cloze Test v1.5 (SCT-v1.5) dataset, consisting of 1,571 stories for each vali- dation and test sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method #1</head><p>Method #2 EndingReg 0.709 0.695 cogcomp 0.649 0.641  <ref type="table">Table 5</ref>: Standard deviation of the word and char- acter n-gram counts, as well as the part of speech (POS) counts, between the right and wrong end- ings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head><p>In order to test the decrease in n-gram bias, which was the most salient feature for the classification task using only the endings, we compare the vari- ance between the n-gram counts from SCT-v1.0 to SCT-v1.5. The results are presented in <ref type="table">Table  5</ref>, which indicates the drop in the standard devia- tions in our new dataset. <ref type="table" target="#tab_6">Table 6</ref> shows the clas- sification results of various models on SCT-v1.5. The drop in accuracy of the EndingReg model be- tween the SCT-v1.0 and SCT-v1.5 shows a signif- icant improvement on the statistical weight of the stylistic features generated by the model. Since the main features used are the token length and the various n-grams, this suggests that the new 'right endings' and 'wrong endings' have much more similar token n-gram, pos n-gram, pos- token n-gram and char-gram overlap. Further- more, the CogComp model's performance has sig- nificantly dropped on SCT-v1.5. Although this model seems to be using story comprehension fea- tures such as event sequencing, since the endings are included in the sequences, the biases within the endings have influenced the predictions and the weak performance of the model in SCT-v1.5 sug- gest that this model had picked up on the biases of SCT-v1.0 as opposed to really understanding the context. In particular, the posterior probabili- ties for each ending choice using their features are quite similar on the SCT-v1.5. These results place the classification accuracy of this top performing model on par with or worse than the models that did not use the ending features of the old SCT-v1.0 dataset ( <ref type="bibr" target="#b13">Mostafazadeh et al., 2017)</ref>, which suggest that the gap that once was held by models using the ending biases seems to be corrected for. Al-  though we did not get to test all the other models published on SCT-v1.0 directly, we predict similar trends.</p><formula xml:id="formula_0">SCT-v1.0 Val SCT-v1.0 Test SCT-v1.</formula><p>It is important to point out that the 64.4% per- formance attained by our EndingReg model is still high for a model which completely discards the context. This indicates that although we could correct for some of the stylistic biases, there are some other hidden patterns in the new endings that would not have been accounted for without hav- ing the EndingReg baseline. This showcases the importance of maintaining benchmarks that evolve and improve over time, where systems should not be optimized for particular narrow test sets. We propose the community to report accuracies on both SCT-v1.0 and SCT-v1.5, both of which still have a huge gap between the best system and the human performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this paper, we presented a comprehensive analysis of the stylistic features isolated in the endings of the original Story Cloze Test <ref type="bibr">(SCT-v1.0)</ref>. Using that analysis, along with a classifier we developed for testing new data col- lection schemes, we created a new SCT dataset, SCT-v1.5, which overcomes some of the biases. Based on the results presented in this paper, we believe that our SCT-v1.5 is a better benchmark for story comprehension. However, as shown in multiple AI tasks <ref type="bibr" target="#b5">(Ettinger et al., 2017;</ref><ref type="bibr" target="#b0">Antol et al., 2015;</ref><ref type="bibr" target="#b9">Jabri et al., 2016;</ref><ref type="bibr" target="#b14">Poliak et al., 2018)</ref>, no collected dataset is entirely without its inherent biases and often the biases in datasets go undis- covered. We believe that evaluation benchmarks should evolve and improve over time and we are planning to incrementally update the Story Cloze Test benchmark. All the new versions, along with a leader-board showcasing the state- of-the-art results, will be tracked via CodaLab https://competitions.codalab.org/ competitions/15333.</p><p>The success of our modified data collection method shows how extreme care must be given for sourcing new datasets. We suggest the next SCT challenges to be completely blind, where the participants cannot deliberately leverage any particular data biases.</p><p>Along with this pa- per, we are releasing the datasets and the de- veloped models to the community. All the an- nouncements, new supplementary material, and datasets can be accessed through http://cs. rochester.edu/nlp/rocstories/. We hope that this work ignites further interest in the community for making progress on story under- standing.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Example Story Cloze Test examples from the SCT-v1.0 corpus. 

of features inspired by all the top-performing sys-
tems on the task (Section 4) (3) we design a new 
crowd-sourcing scheme that yields a new SCT 
dataset; we benchmark various models on the new 
dataset (Section 5). The results show that the top-
performing SCT system on the the leaderboard 1 
(Chaturvedi et al., 2017) fails to keep up the per-
formance on our new dataset. We discuss the 
implications of this experiment to the greater re-
search community in terms of data collection and 
benchmarking practices in Section 6. All the code 
and datasets for this paper will be released to the 
public. We hope that the availability of the new 
evaluation set can further support the continued re-
search on story understanding. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 shows</head><label>1</label><figDesc></figDesc><table>two 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 : The mean value for the 'right endings' and the 'wrong endings' for the two sample T-tests conducted for each feature.</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 : Comparison of initial data sourcing meth- ods</head><label>4</label><figDesc></figDesc><table>n − gram char − gram P OS 
SCT-v1.0 
13.9 
12.4 
16.4 
SCT-v1.5 
7.0 
6.3 
7.5 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Classification accuracy for various mod-
els on the SCT-v1.0 and SCT-v1.5 datasets. 

</table></figure>

			<note place="foot" n="1"> As of 15th February 2018. 2 http://mturk.com shared task on SCT-v1.0 was conducted at the LSDSem&apos;17 workshop (Mostafazadeh et al., 2017), where most of the models performed with 6070% accuracy. One of the top-performing models, msap (Schwartz et al., 2017b,a), built a classifier using linguistic features that have been previously useful in authorship style detection, using only the ending sentences. They used stylistic features such as sentence length, word, and character level n-grams for each ending (fully discarding the context), achieving an accuracy of 72%. In conjunction with their work, Cai et al., (Cai et al., 2017) reported similar observations separately, exposing that features such as sentiment, negation, and length are different between the right and wrong endings. The best model on SCT-v1.0 to this date is cogcomp, which is a linear model that uses event sequences, sentiment trajectory, and topical consistency as features, and performs with an accuracy of 77.6%. This paper takes all their analysis further and introduces a model aggregating all the pinpointed features to shed more light into the stylistic biases isolated in SCT-v1.0 endings. 3 Stylistic Feature Analysis Despite all the efforts made in the original SCT paper, there was never an extensive analysis of the features isolated in the endings of the stories. We explored the differences among stylistic features such as word-token count, sentiment, and the sentence complexity between the endings, to determine a composite score for identifying sources of bias. For determining the sentiment, we used Stanford CoreNLP (Manning et al., 2014) and the VADER sentiment analyzer (Hutto and Gilbert, 2014). For measuring the syntactic complexity, we used Yngve and Frazier metrics (Yngve, 1960; Frazier, 1985). Table 2 compares these statistics between the right and wrong endings in the SCTv1.0 dataset. The feature distribution plots can be found in the supplementary material.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>We would like to thank Roy Schwartz for his valu-able feedback regarding some of the experiments. We also thank the amazing crowd workers, with-out the work of whom this work would have been impossible. This work was supported in part by grant W911NF15-1-0542 with the US Defense Advanced Research Projects Agency (DARPA) as a part of the Communicating with Computers (CwC) program.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">VQA: Visual Question Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislaw</forename><surname>Antol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aishwarya</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiasen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Pay attention to the ending: Strong neural baselines for the ROC story cloze task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifu</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note>Short Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Toward a model of children&apos;s story comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Story comprehension for predicting what happens next</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Snigdha</forename><surname>Chaturvedi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoruo</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Story comprehension: An introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Teun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Dijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Poetics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="1980" />
			<publisher>Special Issue Story Comprehension</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Towards linguistically generalizable nlp systems: A workshop and shared task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allyson</forename><surname>Ettinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sudha</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><forename type="middle">M</forename><surname>Bender</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<title level="m">Proceedings of the First Workshop on Building Linguistically Generalizable NLP Systems</title>
		<meeting>the First Workshop on Building Linguistically Generalizable NLP Systems</meeting>
		<imprint>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Natural language parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lyn</forename><surname>Frazier</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Vader: A parsimonious rule-based model for sentiment analysis of social media text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Hutto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">E</forename><surname>Gilbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eighth International Conference on Weblogs and Social Media</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Revisiting visual question answering baselines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allan</forename><surname>Jabri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Stanford corenlp natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL) System Demonstrations</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Simple story ending selection baselines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todor</forename><surname>Mihaylov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anette</forename><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics (LSDSem)</title>
		<meeting>the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics (LSDSem)<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A corpus and cloze evaluation for deeper understanding of commonsense stories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nasrin</forename><surname>Mostafazadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucy</forename><surname>Vanderwende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushmeet</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Allen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies NAACL HLT 2016</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies NAACL HLT 2016</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">839849</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Lsdsem 2017 shared task: The story cloze test</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nasrin</forename><surname>Mostafazadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Annie</forename><surname>Louis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">F</forename><surname>Allen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Linking Models of Lexical</title>
		<meeting>the 2nd Workshop on Linking Models of Lexical</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Sentential and Discourse-level Semantics</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Hypothesis Only Baselines in Natural Language Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Poliak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Naradowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aparajita</forename><surname>Haldar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachel</forename><surname>Rudinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint Conference on Lexical and Computational Semantics (StarSem)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">An RNN-based binary classifier for the story cloze test</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melissa</forename><surname>Roemmele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sosuke</forename><surname>Kobayashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naoya</forename><surname>Inoue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Gordon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics (LSDSem)</title>
		<meeting>the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics (LSDSem)<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Resourcelean modeling of coherence in commonsense stories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niko</forename><surname>Schenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Chiarcos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics (LSDSem)</title>
		<meeting>the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics (LSDSem)<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The effect of different writing tasks on linguistic style: A case study of the ROC story cloze task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Konstas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zilles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CoNLL</title>
		<meeting>of CoNLL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Story cloze task: Uw nlp system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Konstas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zilles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Linking Models of Lexical</title>
		<meeting>the 2nd Workshop on Linking Models of Lexical</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Sentential and Discourse-level Semantics</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">A model and an hypothesis for language structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Victor Yngve</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
