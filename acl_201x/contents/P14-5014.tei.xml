<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:57+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">KyotoEBMT: An Example-Based Dependency-to-Dependency Translation Framework</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>June 23-24, 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Richardson</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabien</forename><surname>Cromières</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Japan Science and Technology Agency</orgName>
								<address>
									<addrLine>Kawaguchi-shi</addrLine>
									<postCode>332-0012</postCode>
									<settlement>Saitama</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshiaki</forename><surname>Nakazawa</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Japan Science and Technology Agency</orgName>
								<address>
									<addrLine>Kawaguchi-shi</addrLine>
									<postCode>332-0012</postCode>
									<settlement>Saitama</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Graduate School of Informatics</orgName>
								<orgName type="institution">Kyoto University</orgName>
								<address>
									<postCode>606-8501</postCode>
									<settlement>Kyoto</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">KyotoEBMT: An Example-Based Dependency-to-Dependency Translation Framework</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
						<meeting>52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations <address><addrLine>Baltimore, Maryland USA</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="79" to="84"/>
							<date type="published">June 23-24, 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper introduces the Ky-otoEBMT Example-Based Machine Translation framework. Our system uses a tree-to-tree approach, employing syntactic dependency analysis for both source and target languages in an attempt to preserve non-local structure. The effectiveness of our system is maximized with online example matching and a flexible decoder. Evaluation demonstrates BLEU scores competitive with state-of-the-art SMT systems such as Moses. The current implementation is intended to be released as open-source in the near future.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Corpus-based approaches have become a ma- jor focus of Machine Translation research. We present here a fully-fledged Example- Based Machine Translation (EBMT) plat- form making use of both source-language and target-language dependency structure. This paradigm has been explored compar- atively less, as studies on Syntactic-based SMT/EBMT tend to focus on constituent trees rather than dependency trees, and on tree-to-string rather than tree-to-tree ap- proaches. Furthermore, we employ separate dependency parsers for each language rather than projecting the dependencies from one lan- guage to another, as in <ref type="bibr" target="#b16">(Quirk et. al, 2005</ref>).</p><p>The dependency structure information is used end-to-end: for improving the quality of the alignment of the translation examples, for constraining the translation rule extraction and for guiding the decoding. We believe that dependency structure, which considers more than just local context, is important in order to generate fluent and accurate translations of complex sentences across distant language pairs.</p><p>Our experiments focus on technical do- main translation for Japanese-Chinese and Japanese-English, however our implementa- tion is applicable to any domain and language pair for which there exist translation examples and dependency parsers.</p><p>A further unique characteristic of our sys- tem is that, again contrary to the majority of similar systems, it does not rely on precompu- tation of translation rules. Instead it matches each input sentence to the full database of translation examples before extracting trans- lation rules online. This has the merit of max- imizing the information available when creat- ing and combining translation rules, while re- taining the ability to produce excellent trans- lations for input sentences similar to an exist- ing translation example.</p><p>The system is mostly developed in C++ and incorporates a web-based translation interface for ease of use. The web interface (see <ref type="figure" target="#fig_0">Fig- ure 1</ref>) also displays information useful for error analysis such as the list of translation exam- ples used. Experiments are facilitated through the inclusion of a curses-based graphical in- terface for performing tuning and evaluation. The decoder supports multiple threads.</p><p>We are currently making preparations for the project to be released with an open- source license. The code will be available at http://nlp.ist.i.kyoto-u.ac.jp/kyotoebmt/. <ref type="figure" target="#fig_1">Figure 2</ref> shows the basic structure of the pro- posed translation pipeline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Overview</head><p>The training process begins with parsing and aligning parallel sentences from the train- ing corpus. Alignment uses a Bayesian sub- tree alignment model based on dependency trees. This contains a tree-based reorder- ing model and can capture non-local reorder- ings, which sequential word-based models of- ten cannot handle effectively. The alignments are then used to build an example database ('translation memory') containing 'examples' or 'treelets' that form the hypotheses to be combined during decoding.</p><p>Translation is performed by first parsing an input sentence then searching for treelets matching entries in the example database. The retrieved treelets are combined by a de- coder that optimizes a log linear model score. The example retrieval and decoding steps are explained in more detail in sections 3 and 4 respectively. The choice of features and the tuning of the log linear model is described in section 5. <ref type="figure">Figure 3</ref> shows the process of combining ex- amples matching the input tree to create an output sentence. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Example retrieval and translation hypothesis construction</head><p>An important characteristic of our system is that we do not extract and store translation rules in advance: the alignment of translation examples is performed offline. However, for a given input sentence i, the steps for finding examples partially matching i and extracting their translation hypotheses is an online pro- cess. This approach could be considered to be more faithful to the original EBMT approach advocated by <ref type="bibr" target="#b6">Nagao (1984)</ref>. It has already been proposed for phrase-based <ref type="bibr">(CallisonBurch et al., 2005</ref>), hierarchical <ref type="bibr" target="#b15">(Lopez, 2007)</ref>, and syntax-based (Cromières and Kurohashi, 2011) systems. It does not however, seem to be very commonly integrated in syntax-based MT. This approach has several benefits. The first is that we are not required to impose a limit on the size of translation hypotheses. Systems extracting rules in advance typically restrict the size and number of extracted rules for fear of becoming unmanageable. In particular, if an input sentence is the same or very similar to one of our translation examples, we will be able to retrieve a perfect translation. A second advantage is that we can make use of the full context of the example to assign features and scores to each translation hypothesis.</p><p>The main drawback of our approach is that it can be computationally more expensive to retrieve arbitrarily large matchings in the ex- .!/01)$"</p><formula xml:id="formula_0">&gt;)?@#6A*$$6 B@#?@#6A*$$6 C%!.?,$6D!#!&amp;!+$6 ,-." '()" *6 1" /6 06 *$!&lt;" !" E$6 &amp;''(6 2F54" 2F74" 2F54" 2F74"</formula><p>23"</p><p>?!?$*+"</p><formula xml:id="formula_1">2F84" 2F84"2F84" *+6 =0$6 2GBBA4" 2F54"</formula><p>2F74"</p><p>2F84"</p><p>Figure 3: The process of translation. The source sentence is parsed and matching subtrees from the example database are retrieved. From the examples, we extract translation hypotheses than can contain optional target words and several position for each non-terminals. For example the translation hypothesis containing "textbook" has three possible position for the non-terminal X3 (as a left-child before "a", as a left-child after "a" or as a right-child). The translation hypotheses are then combined during decoding. Choice of optional words and final Non-Terminal positions is also done during decoding.</p><p>ample database online than it is to match pre- computed rules. We use the techniques de- scribed in ( <ref type="bibr" target="#b2">Cromières and Kurohashi, 2011)</ref> to perform this step as efficiently as possible.</p><p>Once we have found an example translation (s, t) for which s partially matches i, we pro- ceed to extract a translation hypothesis from it. A translation hypothesis is defined as a generic translation rule for a part p of the in- put sentence that is represented as a target- language treelet, with non-terminals repre- senting the insertion positions for the transla- tions of other parts of the sentence. A trans- lation hypothesis is created from a translation example as follows:</p><p>1. We project the part of s that is matched into the target side t using the alignment of s and t. This is trivial if each word of s and t is aligned, but this is not typi- cally the case. Therefore our translation hypotheses will often have some target words/nodes marked as optionals: this means that we will decide if they should be added to the final translation only at the moment of combination.</p><p>2. We insert the non-terminals as child nodes of the projected subtree. This is simple if i, s and t have the same struc- ture and are perfectly aligned, but again this is not typically the case. A conse- quence is that we will sometimes have sev- eral possible insertion positions for each non-terminal. The choice of insertion po- sition is again made during combination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Decoding</head><p>After having extracted translation hypotheses for as many parts of the input tree as possible, we need to decide how to select and combine them. Our approach here is similar to what <ref type="figure">Figure 4</ref>: A translation hypothesis endoded as a lattice. This representation allows us to handle efficiently the ambiguities of our trans- lation rules. Note that each path in this lat- tice corresponds to different choices of inser- tion position for X2, morphological forms of "be", and the optional insertion of "at".</p><p>has been proposed for Corpus-Based Machine Translation. We first choose a number of fea- tures and create a linear model scoring each possible combination of hypotheses (see Sec- tion 5). We then attempt to find the combi- nation that maximizes this model score.</p><p>The combination of rules is constrained by the structure of the input dependency tree. If we only consider local features 1 , then a simple bottom-up dynamic programming approach can efficiently find the optimal combination with linear O(|H|) complexity 2 . However, non-local features (such as language models) will force us to prune the search space. This pruning is done efficiently through a varia- tion of cube-pruning <ref type="bibr" target="#b10">(Chiang, 2007</ref>). We use KenLM 3 (Heafield, 2011) for computing the target language model score. Decoding is made more efficient by using some of the more advanced features of KenLM such as state-reduction <ref type="bibr" target="#b14">((Li and Khudanpur, 2008)</ref>, ) and rest-cost estima- tions( <ref type="bibr" target="#b13">Heafield et al., 2012</ref>).</p><p>Compared with the original cube-pruning algorithm, our decoder is designed to handle an arbitrary number of non-terminals. In ad- dition, as we have seen in Section 3, the trans- lation hypotheses we initially extract from ex- amples are ambiguous in term of which target word is going to be used and which will be the final position of each non-terminal. In order to handle such ambiguities, we use a lattice-based internal representation that can encode them efficiently (see <ref type="figure">Figure 4)</ref>. This lattice represen- tation also allows the decoder to make choices between various morphological variations of a <ref type="bibr">1</ref> The score of a combination will be the sum of the local scores of each translation hypothesis.</p><p>2 H = set of translation hypotheses 3 http://kheafield.com/code/kenlm/ word (e.g. be/is/are).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Features and Tuning</head><p>During decoding we use a linear model to score each possible combination of hypotheses. This linear model is based on a linear combination of both local features (local to each translation hypothesis) and non-local features (such as a 5-gram language model score of the final trans- lation). The decoder considers in total a com- bination of 34 features, a selection of which are given below.</p><p>• Example penalty and example size</p><p>• Translation probability</p><p>• Language model score</p><p>• Optional words added/removed</p><p>The optimal weights for each feature are estimated using the Pairwise Ranking Op- timization (PRO) algorithm (Hopkins and May, 2011) and parameter optimization with MegaM 4 . We use the implementation of PRO that is provided with the Moses SMT system and the default settings of MegaM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head><p>In order to evaluate our system, we conducted translation experiments on four language pairs: Japanese-English (JA-EN), English- Japanese (EN-JA), Japanese-Chinese (JA- ZH) and Chinese-Japanese (ZH-JA).</p><p>For Japanese-English, we evaluated on the NTCIR-10 PatentMT task data (patents) ( <ref type="bibr" target="#b3">Goto et al., 2013</ref>) and compared our system with the official baseline scores. For Japanese- Chinese, we used parallel scientific paper ex- cerpts from the ASPEC 5 corpus and com- pared against the same baseline system as for Japanese-English. The corpora contain 3M parallel sentences for Japanese-English and 670K for Japanese-Chinese.</p><p>The two baseline systems are based on the open-source GIZA++/Moses pipeline. The baseline labeled "Moses" uses the classic phrase-based engine, while "Moses-Hiero" uses the Hierarchical Phrase-Based decoder. These Further, the expansion stroke, the sectional area of the inner tube 12, and the oil is supplied to the lower oil chamber S2 from the oil reservoir chamber R × stroke.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>JA-EN EN-JA JA-ZH ZH-JA</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Moses- Hiero</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>21.49</head><p>Also, the expansion stroke, the cross-sectional area of the inner tube 12 × stroke of oil supplied from the oil reservoir chamber R lower oil chamber S2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proposed</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>44.99</head><p>Further in this expansion stroke, the oil at an amount obtained by mul- tiplying cross sectional area of the inner tube 12 from the oil reservoir chamber R is resupplied to the lower oil chamber S2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reference</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>100.00</head><p>In this expansion stroke, oil in an amount obtained by multiplying the cross sectional area of the inner tube 12 by the stroke is resupplied from the upper oil reservoir chamber R to the lower oil chamber S2. correspond to the highest performing official baselines for the NTCIR-10 PatentMT task. As it appeared Moses was giving similar and slightly higher BLEU scores than Moses- Hiero for Japanese-English, we restricted eval- uation to the standard settings for Moses for our Japanese-Chinese experiments.</p><p>The following dependency parsers were used. The scores in parentheses are the ap- proximate parsing accuracies (micro-average), which were evaluated by hand on a random subset of sentences from the test data. The parsers were trained on domains different to those used in the experiments.</p><p>• English: NLParser 6 (92%) <ref type="bibr" target="#b0">(Charniak and Johnson, 2005)</ref> • Japanese: KNP (96%) ( <ref type="bibr" target="#b5">Kawahara and Kurohashi, 2006)</ref> • Chinese: SKP (88%) (Shen et al., 2012)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Results</head><p>The results shown are for evaluation on the test set after tuning. Tuning was conducted over 50 iterations on the development set using an n-best list of length 500. <ref type="table" target="#tab_1">Table 2</ref> shows an example sentence showing significant improvement over the baseline. In particular, non-local structure has been pre- served by the proposed system, such as the modification of 'oil' by the 'in an amount... by the stroke' phrase. Another example is the in- correct location of '× stroke' in the Moses out- put. The proposed system produces a much more fluent output than the hierarchical-based baseline Moses-Hiero.</p><p>The proposed system also outperforms the baseline for JA-ZH, however falls short for ZH-JA. We believe this is due to the low qual- ity of parsing for Chinese input.</p><p>The decoder requires on average 0.94 sec- onds per sentence when loading from precom- piled hypothesis files. As a comparison, Moses (default settings) takes 1.78 seconds per sen- tence, loading from a binarized and filtered phrase table.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>This paper introduces an example-based translation system exploiting both source and target dependency analysis and online exam- ple retrieving, allowing the availability of full translation examples at translation time.</p><p>We believe that the use of dependency pars- ing is important for accurate translation across distant language pairs, especially in settings such as ours with many long sentences. We have designed a complete translation frame-work around this idea, using dependency- parsed trees at each step from alignment to example retrieval to example combination.</p><p>The current performance (BLEU) of our system is similar to (or even slightly bet- ter than) state-of-the-art open-source SMT systems. As we have been able to obtain steady performance improvements during de- velopment, we are hopeful that this trend will continue and we will shortly obtain even bet- ter results. Future plans include enriching the feature set, adding a tree-based language model and considering forest input for multi- ple parses to provide robustness against pars- ing errors. When the code base is sufficiently stable, we intend to release the entire system as open-source, in the hope of providing a more syntactically-focused alternative to ex- isting open-source SMT engines.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: A screenshot of the web interface showing a Japanese-English translation. The interface provides the source and target side dependency tree, as well as the list of examples used with their alignments. The web interface facilitates easy and intuitive error analysis, and can be used as a tool for computeraided translation.</figDesc><graphic url="image-1.png" coords="2,72.00,63.81,218.26,188.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Translation pipeline. An example database is first trained from a parallel corpus. Translation is performed by the decoder, which combines initial hypotheses generated by the example retrieval module. Weights can be improved with batch tuning.</figDesc><graphic url="image-2.png" coords="2,310.16,62.57,213.17,127.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 : Example of JA-EN translation with better translation quality than baselines.</head><label>2</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="4"> http://www.umiacs.umd.edu/~hal/megam/ 5 http://orchid.kuee.kyoto-u.ac.jp/ASPEC/</note>

			<note place="foot" n="6"> Converted to dependency parses with in-house tool.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was partially supported by the Japan Science and Technology Agency. The first author is supported by a Japanese Gov-ernment (MEXT) research scholarship. We would like to thank the anonymous reviewers.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Coarse-to-Fine n-Best Parsing and MaxEnt Discriminative Reranking</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 43rd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Efficient retrieval of tree translation examples for syntax-based machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabien</forename><surname>Cromières</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Overview of the Patent Machine Translation Task at the NTCIR-10 Workshop</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isao</forename><surname>Goto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ka</forename><forename type="middle">Po</forename><surname>Chow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eiichiro</forename><surname>Sumita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Tsou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th NTCIR Workshop Meeting on Evaluation of Information Access Technologies (NTCIR-10)</title>
		<meeting>the 10th NTCIR Workshop Meeting on Evaluation of Information Access Technologies (NTCIR-10)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Tuning as Ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Hopkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A Fully-Lexicalized Probabilistic Model for Japanese Syntactic and Case Structure Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daisuke</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Human Language Technology Conference of the NAACL</title>
		<meeting>the Human Language Technology Conference of the NAACL</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">A framework of a mechanical translation between Japanese and English by analogy principle</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makoto</forename><surname>Nagao</surname></persName>
		</author>
		<editor>A. Elithorn and R. Banerji. Artificial and Human Intelligence</editor>
		<imprint>
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Alignment by bilingual generation and monolingual derivation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshiaki</forename><surname>Nakazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2012</title>
		<meeting>COLING 2012</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A Reranking Approach for Dependency Parsing with Variable-sized Subtree Features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daisuke</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 26th Pacific Asia Conference on Language Information and Computing</title>
		<meeting>26th Pacific Asia Conference on Language Information and Computing</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Scaling phrase-based statistical machine translation to larger corpora and longer phrases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Bannard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josh</forename><surname>Schroeder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 43rd Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="255" to="262" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Hierarchical phrase-based translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Linguistics</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">KenLM: faster and smaller language model queries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the EMNLP 2011 Sixth Workshop on Statistical Machine Translation</title>
		<meeting>the EMNLP 2011 Sixth Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Left language model state for syntactic machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tetsuo</forename><surname>Kiso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Workshop on Spoken Language Translation</title>
		<meeting>the International Workshop on Spoken Language Translation</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Language model rest costs and spaceefficient storage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A scalable decoder for parsing-based machine translation with equivalent language model state maintenance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Khudanpur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Workshop on Syntax and Structure in Statistical Translation</title>
		<meeting>the Second Workshop on Syntax and Structure in Statistical Translation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Hierarchical phrase-based translation with suffix arrays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lopez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLPCoNLL</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Dependency Treelet Translation: Syntactically Informed Phrasal SMT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Quirk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arul</forename><surname>Menezes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 43rd Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
