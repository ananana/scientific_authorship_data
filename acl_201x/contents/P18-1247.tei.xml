<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T13:04+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Neural Factor Graph Models for Cross-lingual Morphological Tagging</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 15-20, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaitanya</forename><surname>Malaviya</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Machine Learning Department</orgName>
								<orgName type="institution" key="instit1">Language Technologies Institute</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">R</forename><surname>Gormley</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Machine Learning Department</orgName>
								<orgName type="institution" key="instit1">Language Technologies Institute</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Machine Learning Department</orgName>
								<orgName type="institution" key="instit1">Language Technologies Institute</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Neural Factor Graph Models for Cross-lingual Morphological Tagging</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2653" to="2663"/>
							<date type="published">July 15-20, 2018. 2018</date>
						</imprint>
					</monogr>
					<note>2653</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Morphological analysis involves predicting the syntactic traits of a word (e.g. {POS: Noun, Case: Acc, Gender: Fem}). Previous work in morphological tagging improves performance for low-resource languages (LRLs) through cross-lingual training with a high-resource language (HRL) from the same family, but is limited by the strict-often false-assumption that tag sets exactly overlap between the HRL and LRL. In this paper we propose a method for cross-lingual morphological tagging that aims to improve information sharing between languages by relaxing this assumption. The proposed model uses factorial conditional random fields with neural network potentials, making it possible to (1) utilize the expressive power of neural network representations to smooth over superficial differences in the surface forms, (2) model pair-wise and transitive relationships between tags, and (3) accurately generate tag sets that are unseen or rare in the training data. Experiments on four languages from the Universal Dependencies Treebank (Nivre et al., 2017) demonstrate superior tagging accuracies over existing cross-lingual approaches. 1</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Morphological analysis <ref type="bibr" target="#b10">(Hajič and Hladká (1998)</ref>, <ref type="bibr" target="#b25">Oflazer and Kuruöz (1994)</ref>, inter alia) is the task of predicting fine-grained annotations about the syntactic properties of tokens in a language such as part-of-speech, case, or tense. For instance, in <ref type="figure" target="#fig_0">Figure 1</ref>, the given Portuguese sentence is la- beled with the respective morphological tags such as Gender and its label value Masculine.</p><p>The accuracy of morphological analyzers is paramount, because their results are often a first step in the NLP pipeline for tasks such as transla- tion ( <ref type="bibr" target="#b34">Vylomova et al., 2017;</ref><ref type="bibr" target="#b32">Tsarfaty et al., 2010)</ref> and parsing ( <ref type="bibr" target="#b33">Tsarfaty et al., 2013)</ref>, and errors in the upstream analysis may cascade to the down- stream tasks. One difficulty, however, in creating these taggers is that only a limited amount of anno- tated data is available for a majority of the world's languages to learn these morphological taggers. Fortunately, recent efforts in morphological an- notation follow a standard annotation schema for these morphological tags across languages, and now the Universal Dependencies Treebank ( <ref type="bibr" target="#b23">Nivre et al., 2017)</ref> has tags according to this schema in 60 languages. <ref type="bibr" target="#b2">Cotterell and Heigold (2017)</ref> have recently shown that combining this shared schema with cross-lingual training on a related high-resource language (HRL) gives improved performance on tagging accuracy for low-resource languages (LRLs). The output space of this model consists of tag sets such as {POS: Adj, Gender: Masc, Num- ber: Sing}, which are predicted for a token at each time step. However, this model relies heavily on the fact that the entire space of tag sets for the LRL must match those of the HRL, which is of- ten not the case, either due to linguistic divergence or small differences in the annotation schemes be- tween the two languages. <ref type="bibr">2</ref> For instance, in Fig- ure 1 "refrescante" is assigned a gender in the Por- tuguese UD treebank, but not in the <ref type="bibr">Spanish UD treebank.</ref> In this paper, we propose a method that in- stead of predicting full tag sets, makes predictions over single tags separately but ties together each decision by modeling variable dependencies be- tween tags over time steps (e.g. capturing the fact that nouns frequently occur after determiners) and pairwise dependencies between all tags at a sin- gle time step (e.g. capturing the fact that infini- tive verb forms don't have tense). The specific model is shown in <ref type="figure" target="#fig_1">Figure 2</ref>, consisting of a facto- rial conditional random field (FCRF; ) with neural network potentials calculated by long short-term memory (LSTM; <ref type="bibr" target="#b13">(Hochreiter and Schmidhuber, 1997)</ref>) at every variable node ( §3). Learning and inference in the model is made <ref type="bibr">2</ref> In particular, the latter is common because many UD re- sources were created by full or semi-automatic conversion from treebanks with less comprehensive annotation schemes than UD. Our model can generate label values for these tags too, which could possibly aid the enhancement of UD anno- tations, although we do not examine this directly in our work. tractable through belief propagation over the pos- sible tag combinations, allowing the model to con- sider an exponential label space in polynomial time <ref type="bibr">( §3.5)</ref>.</p><p>This model has several advantages:</p><p>• The model is able to generate tag sets un- seen in training data, and share information between similar tag sets, alleviating the main disadvantage of previous work cited above.</p><p>• Our model is empirically strong, as vali- dated in our main experimental results: it consistently outperforms previous work in cross-lingual low-resource scenarios in ex- periments.</p><p>• Our model is more interpretable, as we can probe the model parameters to understand which variable dependencies are more likely to occur in a language, as we demonstrate in our analysis.</p><p>In the following sections, we describe the model and these results in more detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Problem Formulation and Baselines</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Problem Formulation</head><p>Formally, we define the problem of morpholog- ical analysis as the task of mapping a length-T string of tokens x = x 1 , . . . , x T into the tar- get morphological tag sets for each token y = y 1 , . . . , y T . For the tth token, the target label y t = y t,1 , . . . , y t,m defines a set of tags (e.g. {Gender: Masc, Number: Sing, POS: Verb}). An annotation schema defines a set S of M possi- ble tag types and with the mth type (e.g. Gen- der) defining its set of possible labels Y m (e.g. {Masc, Fem, Neu}) such that y t,m ∈ Y m . We must note that not all tags or attributes need to be specified for a token; usually, a subset of S is specified for a token and the remaining tags can be treated as mapping to a NULL ∈ Y m value. Let Y = {(y 1 , . . . , y M ) : y 1 ∈ Y 1 , . . . , y M ∈ Y M } denote the set of all possible tag sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Baseline: Tag Set Prediction</head><p>Data-driven models for morphological analy- sis are constructed using training data</p><formula xml:id="formula_0">D = {(x (i) , y (i) )} N i=1</formula><p>consisting of N training exam- ples. The baseline model <ref type="bibr" target="#b2">(Cotterell and Heigold, 2017)</ref> we compare with regards the output space of the model as a subset˜Ysubset˜ subset˜Y ⊂ Y where˜Ywhere˜ where˜Y is the set of all tag sets seen in this training data. Specif- ically, they solve the task as a multi-class classi- fication problem where the classes are individual tag sets. In low-resource scenarios, this indicates that | ˜ Y| &lt;&lt; |Y| and even for those tag sets exist- ing iñ Y we may have seen very few training ex- amples. The conditional probability of a sequence of tag sets given the sentence is formulated as a 0th order CRF.</p><formula xml:id="formula_1">p(y|x) = T t=1 p(y t |x)<label>(1)</label></formula><p>Instead, we would like to be able to generate any combination of tags from the set Y, and share statistical strength among similar tag sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">A Relaxation: Tag-wise Prediction</head><p>As an alternative, we could consider a model that performs prediction for each tag's label y t,m inde- pendently.</p><formula xml:id="formula_2">p(y|x) = T t=1 M m=1 p(y t,m |x)<label>(2)</label></formula><p>This formulation has an advantage: the tag- predictions within a single time step are now in- dependent, it is now easy to generate any combi- nation of tags from Y. On the other hand, now it is difficult to model the interdependencies be- tween tags in the same tag set y i , a major dis- advantage over the previous model. In the next section, we describe our proposed neural factor graph model, which can model not only dependen- cies within tags for a single token, but also depen- dencies across time steps while still maintaining the flexibility to generate any combination of tags from Y.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Neural Factor Graph Model</head><p>Due to the correlations between the syntactic prop- erties that are represented by morphological tags, we can imagine that capturing the relationships between these tags through pairwise dependen- cies can inform the predictions of our model. These dependencies exist both among tags for the same token (intra-token pairwise dependencies), and across tokens in the sentence (inter-token tran- sition dependencies). For instance, knowing that a token's POS tag is a Noun, would strongly suggest that this token would have a NULL label for the tag Tense, with very few exceptions ( <ref type="bibr" target="#b24">Nordlinger and Sadler, 2004</ref>). In a language where nouns follow adjectives, a tag set prediction {POS: Adj, Gen- der: Fem} might inform the model that the next token is likely to be a noun and have the same gen- der. The baseline model can not explicitly model such interactions given their factorization in equa- tion 1.</p><p>To incorporate the dependencies discussed above, we define a factorial CRF ( , with pairwise links between cotemporal variables and transition links between the same types of tags. This model defines a distribution over the tag-set sequence y given the input sen- tence x as,</p><formula xml:id="formula_3">p(y|x) = 1 Z(x) T t=1 α∈C ψ α (y α , x, t) (3)</formula><p>where C is the set of factors in the factor graph (as shown in <ref type="figure" target="#fig_1">Figure 2</ref>), α is one such factor, and y α is the assignment to the subset of variables neigh- boring factor α. We define three types of potential functions: neural ψ N N , pairwise ψ P , and transi- tion ψ T , described in detail below. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Neural Factors</head><p>The flexibility of our formulation allows us to in- clude any form of custom-designed potentials in our model. Those for the neural factors have a fairly standard log-linear form,</p><formula xml:id="formula_4">ψ N N ,i (y t,m ) = exp k λ nn,k f nn,k (x, t)<label>(4)</label></formula><p>except that the features f nn,k are themselves given by a neural network. There is one such factor per variable. We obtain our neural factors using a biL- STM over the input sequence x, where the input word embedding for each token is obtained from a character-level biLSTM embedder. This compo- nent of our model is similar to the model proposed by <ref type="bibr" target="#b2">Cotterell and Heigold (2017)</ref>. Given an input token x t = c 1 ...c n , we compute an input embed- ding v t as,</p><formula xml:id="formula_5">v t = [cLSTM(c 1 ...c n ); cLSTM(c n ...c 1 )] (5)</formula><p>Here, cLSTM is a character-level LSTM function that returns the last hidden state. This input em- bedding v t is then used in the biLSTM tagger to compute an output representation e t . Finally, the scores f nn (x, t) are obtained as,</p><formula xml:id="formula_6">f nn (x, t) = W l e t + b l<label>(6)</label></formula><p>We use a language-specific linear layer with weights W l and bias b l .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Pairwise Factors</head><p>As discussed previously, the pairwise factors are crucial for modeling correlations between tags. The pairwise factor potential for a tag i and tag j at timestep t is given in equation 7. Here, the dimension of f p is (|Y i |, |Y j |). These scores are used to define the neural factors as,</p><formula xml:id="formula_7">ψ P i,j (y t,i , y t,j ) = exp k λ p,k f p,k (y t,i , y t,j )<label>(7)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Transition Factors</head><p>Previous work has experimented with the use of a linear chain CRF with factors from a neural net- work ( <ref type="bibr" target="#b14">Huang et al., 2015</ref>) for sequence tagging tasks. We hypothesize that modeling transition factors in a similar manner can allow the model to utilize information about neighboring tags and capture word order features of the language. The transition factor for tag i and timestep t is given below for variables y t,i and y t+1,i . The dimension of f T is (|Y i |, |Y i |).</p><formula xml:id="formula_8">ψT i,t (yt,i, yt+1,i) = exp k λ T,k f T,k (yt,i, yt+1,i)<label>(8)</label></formula><p>In our experiments, f p,k and f T,k are simple indi- cator features for the values of tag variables with no dependence on x.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Language-Specific Weights</head><p>As an enhancement to the information encoded in the transition and pairwise factors, we experi- ment with training general and language-specific parameters for the transition and the pairwise weights. We define the weight matrix λ gen to learn the general trends that hold across both languages, and the weights λ lang to learn the exceptions to these trends. In our model, we sum both these pa- rameter matrices before calculating the transition and pairwise factors. For instance, the transition weights λ T are calculated as λ T = λ T, gen +λ T, lang .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Loopy Belief Propagation</head><p>Since the graph from <ref type="figure" target="#fig_1">Figure 2</ref> is a loopy graph, performing exact inference can be expensive. Hence, we use loopy belief propagation ( <ref type="bibr" target="#b22">Murphy et al., 1999;</ref><ref type="bibr" target="#b15">Ihler et al., 2005</ref>) for computation of approximate variable and factor marginals. Loopy BP is an iterative message passing algorithm that sends messages between variables and factors in a factor graph. The message updates from variable v i , with neighboring factors N (i), to factor α is</p><formula xml:id="formula_9">µ i→α (v i ) = α∈N (i)\α µ α→i (v i )<label>(9)</label></formula><p>The message from factor α to variable v i is</p><formula xml:id="formula_10">µα→i(vi) = vα:vα[i]=v i ψα(vα) j∈N (α)\i µj→α(vα[i])<label>(10)</label></formula><p>where v α denote an assignment to the subset of variables adjacent to factor α, and v α [i] is the as- signment for variable v i . Message updates are performed asynchronously in our model. Our message passing schedule was similar to that of foward-backward: the forward pass sends all mes- sages from the first time step in the direction of the last. Messages to/from pairwise factors are in- cluded in this forward pass. The backward pass sends messages in the direction from the last time step back to the first. This process is repeated un- til convergence. We say that BP has converged when the maximum residual error ) over all messages is below some threshold. Upon convergence, we obtain the belief values of variables and factors as,</p><formula xml:id="formula_11">b i (v i ) = 1 κ i α∈N (i) µ α→i (v i )<label>(11)</label></formula><formula xml:id="formula_12">b α (v α ) = 1 κ α ψ α (v α ) i∈N (α) µ i→α (v α [i])<label>(12)</label></formula><p>where κ i and κ α are normalization constants en- suring that the beliefs for a variable i and factor α sum-to-one. In this way, we can use the beliefs as approximate marginal probabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Learning and Decoding</head><p>We perform end-to-end training of the neural fac- tor graph by following the (approximate) gradient of the log-likelihood N i=1 log p(y (i) |x (i) ). The true gradient requires access to the marginal prob- abilities for each factor, e.g. p(y α |x) where y α denotes the subset of variables in factor α. For example, if α is a transition factor for tag m at timestep t, then y α would be y t,m and y t+1,m . Following ( , we replace these marginals with the beliefs b α (y α ) from loopy be- lief propagation. <ref type="bibr">3</ref> Consider the log-likelihood of a single example (i) = log p(y (i) |x (i) ). The par- tial derivative with respect to parameter λ g,k for each type of factor g ∈ {N N, T, P } is the dif- ference of the observed features with the expected features under the model's (approximate) distribu- tion as represented by the beliefs:</p><formula xml:id="formula_13">∂ (i) ∂λ g,k = α∈Cg f g,k (y (i) α ) − yα b α (y α )f g,k (y α )</formula><p>where C g denotes all the factors of type g, and we have omitted any dependence on x (i) and t for brevity-t is accessible through the factor index α. For the neural network factors, the features are given by a biLSTM. We backpropagate through to the biLSTM parameters using the partial deriva- tive below,</p><formula xml:id="formula_14">∂ (i) ∂f N N,k (y (i) t,m , t) = λ N N,k − yt,m b t,m (y t,m )λ N N,k</formula><p>where b t,m (·) is the variable belief corresponding to variable y t,m .</p><p>To predict a sequence of tag setsˆysetsˆ setsˆy at test time, we use minimum Bayes risk (MBR) decoding <ref type="bibr" target="#b0">(Bickel and Doksum, 1977;</ref><ref type="bibr" target="#b8">Goodman, 1996)</ref> for Hamming loss over tags. For a variable y t,m rep- resenting tag m at timestep t, we takê takê y t,m = arg max l∈Ym b t,m (l).</p><p>where l ranges over the possible labels for tag m.   The sizes of the training and evaluation sets are specified in <ref type="table">Table 1</ref>. In order to simulate low- resource settings, we follow the experimental pro- cedure from <ref type="bibr" target="#b2">Cotterell and Heigold (2017)</ref>. We re- strict the number of sentences of the target lan- guage (tgt size) in the training set to 100 or 1000 sentences. We also augment the tag sets in our training data by adding a NULL label for all tags that are not seen for a token. It is expected that our model will learn which tags are unlikely to oc- cur given the variable dependencies in the factor graph. The dev set and test set are only in the tar- get language. From <ref type="table" target="#tab_1">Table 2</ref>, we can see there is also considerable variance in the number of unique tags and tag sets found in each of these language pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Language Pair HRL Train Dev Test</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Language</head><p>Model tgt size = 100 tgt size=1000 Accuracy F1-Micro F1-Macro Accuracy F1-Macro F1-Micro SV  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Baseline Tagger</head><p>As the baseline tagger model, we re-implement the SPECIFIC model from <ref type="bibr" target="#b2">Cotterell and Heigold (2017)</ref> that uses a language-specific softmax layer. Their model architecture uses a character biLSTM embedder to obtain a vector representation for each token, which is used as input in a word-level biLSTM. The output space of their model is all the tag sets seen in the training data. This work achieves strong performance on several languages from UD on the task of morphological tagging and is a strong baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Training Regimen</head><p>We followed the parameter settings from <ref type="bibr" target="#b2">Cotterell and Heigold (2017)</ref> for the baseline tagger and the neural component of the FCRF-LSTM model. For both models, we set the input embedding and linear layer dimension to 128. We used 2 hidden layers for the LSTM where the hidden layer di- mension was set to 256 and a dropout ( <ref type="bibr" target="#b29">Srivastava et al., 2014</ref>) of 0.2 was enforced during training. All our models were implemented in the PyTorch toolkit ( <ref type="bibr" target="#b26">Paszke et al., 2017)</ref>. The parameters of the character biLSTM and the word biLSTM were ini- tialized randomly. We trained the baseline models and the neural factor graph model with SGD and Adam respectively for 10 epochs each, in batches of 64 sentences. These optimizers gave the best performances for the respective models. For the FCRF, we initialized transition and pair- wise parameters with zero weights, which was im- portant to ensure stable training. We considered BP to have reached convergence when the maxi- mum residual error was below 0.05 or if the max- imum number of iterations was reached (set to 40 in our experiments). We found that in cross- lingual experiments, when tgt size = 100, the relatively large amount of data in the HRL was causing our model to overfit on the HRL and not generalize well to the LRL. As a solution to this, we upsampled the LRL data by a factor of 10 when tgt size = 100 for both the baseline and the pro- posed model.</p><p>Evaluation: Previous work on morphological analysis ( <ref type="bibr" target="#b2">Cotterell and Heigold, 2017;</ref><ref type="bibr" target="#b1">Buys and Botha, 2016)</ref> has reported scores on average token-level accuracy and F1 measure. The av- erage token level accuracy counts a tag set pre- diction as correct only it is an exact match with the gold tag set. On the other hand, F1 mea- sure is measured on a tag-by-tag basis, which al- lows it to give partial credit to partially correct tag sets. Based on the characteristics of each eval- uation measure, Accuracy will favor tag-set pre- diction models (like the baseline), and F1 mea- sure will favor tag-wise prediction models (like our proposed method). Given the nature of the task, it seems reasonable to prefer getting some of the tags correct (e.g. Noun+Masc+Sing becomes Noun+Fem+Sing), instead of missing all of them (e.g. Noun+Masc+Sing becomes Adj+Fem+Plur). F-score gives partial credit for getting some of the tags correct, while tagset-level accuracy will treat these two mistakes equally. Based on this, we believe that F-score is intuitively a better metric. However, we report both scores for completeness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Main Results</head><p>First, we report the results in the case of mono- lingual training in <ref type="table" target="#tab_3">Table 3</ref>. The first row for each language pair reports the results for our reimple-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Language</head><p>Model tgt size = 100 tgt size=1000 Accuracy F1-Micro F1-Macro Accuracy F1-Macro F1-Micro  <ref type="table">Table 4</ref>: Token-wise accuracy and F1 scores on cross-lingual experiments mentation of <ref type="bibr" target="#b2">Cotterell and Heigold (2017)</ref>, and the second for our full model. From these results, we can see that we obtain improvements on the F- measure over the baseline method in most experi- mental settings except BG with tgt size = 1000.</p><p>In a few more cases, the baseline model sometimes obtains higher accuracy scores for the reason de- scribed in 4.3.</p><p>In our cross-lingual experiments shown in Ta- ble 4, we also note F-measure improvements over the baseline model with the exception of DA/SV when tgt size = 1000. We observe that the improvements are on average stronger when tgt size = 100. This suggests that our model performs well with very little data due to its flex- ibility to generate any tag set, including those not observed in the training data. The strongest im- provements are observed for FI/HU. This is likely because the number of unique tags is the highest in this language pair and our method scales well with the number of tags due to its ability to make use of correlations between the tags in different tag sets.  To examine the utility of our transition and pair- wise factors, we also report results on ablation experiments by removing transition and pairwise factors completely from the model in <ref type="table" target="#tab_6">Table 5</ref>. Ablation experiments for each factor showed de- creases in scores relative to the model where both factors are present, but the decrease attributed to the pairwise factors is larger, in both the mono- lingual and cross-lingual cases. Removing both factors from our proposed model results in a fur- ther decrease in the scores. These differences were found to be more significant in the case when tgt size = 100.</p><p>Upon looking at the tag set predictions made by our model, we found instances where our model utilizes variable dependencies to predict correct labels. For instance, for a specific phrase in Portuguese (um estado), the baseline model predicted {POS: Det, Gender: Masc, Number: Sing} t , {POS: Noun, Gender: Fem (X), Number: Sing} t+1 , whereas our model was able to get the gender correct because of the transition factors in our model. Generic pairwise weights between Verbform and Tense from the RU/BG model the ability to interpret what the model has learned by looking at the trained parameter weights. We investigated both language-generic and language- specific patterns learned by our parameters:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">What is the Model Learning?</head><p>• Language-Generic: We found evidence for several syntactic properties learned by the model parameters. For instance, in <ref type="figure" target="#fig_4">Figure 4</ref>, we visualize the generic (λ T, gen ) transition weights of the POS tags in RU/BG. Several universal trends such as determiners and ad- jectives followed by nouns can be seen. In <ref type="figure">Figure 5</ref>, we also observed that infinitive has a strong correlation for NULL tense, which follows the universal phenomena that infini- tives don't have tense.   <ref type="figure" target="#fig_5">Figure 6</ref> and verified strong correlations be- tween the past tense and all gender labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>There exist several variations of the task of pre- diction of morphological information from an- notated data: paradigm completion ( <ref type="bibr" target="#b7">Durrett and DeNero, 2013;</ref><ref type="bibr" target="#b5">Cotterell et al., 2017b</ref>), morpho- logical reinflection ( <ref type="bibr" target="#b3">Cotterell et al., 2017a</ref>), seg- mentation ( <ref type="bibr" target="#b6">Creutz et al., 2005;</ref><ref type="bibr" target="#b4">Cotterell et al., 2016</ref>) and tagging. Work on morphological tag- ging has broadly focused on structured prediction models such as CRFs, and neural network models. Amongst structured prediction approaches, <ref type="bibr" target="#b20">Müller et al. (2013);</ref> proposed the use of a higher-order CRF that is approx- imated using coarse-to-fine decoding. <ref type="bibr">(Müller et al., 2015)</ref> proposed joint lemmatization and tag- ging using this framework. <ref type="bibr" target="#b9">(Hajič, 2000</ref>) was the first work that performed experiments on multilin- gual morphological tagging. They proposed an ex- ponential model and the use of a morphological dictionary. Buys and Botha (2016); <ref type="bibr" target="#b17">Kirov et al. (2017)</ref> proposed a model that used tag projection of type and token constraints from a resource-rich language to a low-resource language for tagging. Most recent work has focused on character- based neural models ( , that can handle rare words and are hence more use- ful to model morphology than word-based mod- els. These models first obtain a character-level representation of a token from a biLSTM or CNN, which is provided to a word-level biLSTM tagger. <ref type="bibr" target="#b11">Heigold et al. ( , 2016</ref> compared several neu- ral architectures to obtain these character-based representations and found the effect of the neu- ral network architecture to be minimal given the networks are carefully tuned. Cross-lingual trans- fer learning has previously boosted performance on tasks such as translation <ref type="bibr" target="#b16">(Johnson et al., 2016)</ref> and POS tagging <ref type="bibr" target="#b28">(Snyder et al., 2008;</ref><ref type="bibr" target="#b27">Plank et al., 2016)</ref>. <ref type="bibr" target="#b2">Cotterell and Heigold (2017)</ref> proposed a cross-lingual character-level neural morphological tagger. They experimented with different strate- gies to facilitate cross-lingual training: a language ID for each token, a language-specific softmax and a joint language identification and tagging model. We have used this work as a baseline model for comparing with our proposed method.</p><p>In contrast to earlier work on morphological tagging, we use a hybrid of neural and graphical model approaches. This combination has several advantages: we can make use of expressive fea- ture representations from neural models while en- suring that our model is interpretable. Our work is similar in spirit to <ref type="bibr" target="#b14">Huang et al. (2015)</ref> and <ref type="bibr" target="#b18">Ma and Hovy (2016)</ref>, who proposed models that use a CRF with features from neural models. For our graphical model component, we used a factorial CRF ( , which is a generaliza- tion of a linear chain CRF with additional pairwise factors between cotemporal variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion and Future Work</head><p>In this work, we proposed a novel framework for sequence tagging that combines neural networks and graphical models, and showed its effective- ness on the task of morphological tagging. We believe this framework can be extended to other sequence labeling tasks in NLP such as seman- tic role labeling. Due to the robustness of the model across languages, we believe it can also be scaled to perform morphological tagging for mul- tiple languages together.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Morphological tags for a UD sentence in Portuguese and a translation in Spanish</figDesc><graphic url="image-1.png" coords="1,317.20,222.54,198.43,149.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: FCRF-LSTM Model for morphological tagging</figDesc><graphic url="image-2.png" coords="2,74.84,62.81,212.60,194.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Factors in the Neural Factor Graph model (red: Pairwise, grey: Transition, green: Neural Network)</figDesc><graphic url="image-3.png" coords="3,362.55,399.71,107.71,139.37" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>DA</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Generic transition weights for POS from the RU/BG model</figDesc><graphic url="image-4.png" coords="7,345.54,562.69,141.73,138.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Language-specific pairwise weights for RU between Gender and Tense from the RU/BG model</figDesc><graphic url="image-6.png" coords="8,110.27,481.77,141.72,106.67" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Tag Set Sizes with tgt size=100 

4 Experimental Setup 

4.1 Dataset 

We used the Universal Dependencies Treebank 
UD v2.1 (Nivre et al., 2017) for our experiments. 
We picked four low-resource/high-resource 
language pairs, each from a different family: 
Danish/Swedish (DA/SV), Russian/Bulgarian 
(RU/BG), Finnish/Hungarian (FI/HU), Span-
ish/Portuguese (ES/PT). Picking languages from 
different families would ensure that we obtain 
results that are on average consistent across 
languages. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 : Token-wise accuracy and F1 scores on mono-lingual experiments</head><label>3</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 5 : Ablation Experiments (tgt size=1000)</head><label>5</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="1"> Our code and data is publicly available at www.github.com/chaitanyamalaviya/ NeuralFactorGraph.</note>

			<note place="foot" n="3"> Using this approximate gradient is akin to the surrogate likelihood training of (Wainwright, 2006).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors would like to thank David Mortensen, Soumya Wadhwa and Maria Ryskina for useful comments about this work. We would also like to thank the reviewers who gave valuable feedback to improve the paper. This project was supported in part by an Amazon Academic Research Award and Google Faculty Award.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Mathematical Statistics: Basic Ideas and Selected Topics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kjell</forename><forename type="middle">A</forename><surname>Bickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Doksum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1977" />
			<publisher>Holden-Day Inc</publisher>
			<pubPlace>Oakland, CA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Cross-lingual morphological tagging for low-resource languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Buys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">A</forename><surname>Botha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1954" to="1964" />
		</imprint>
	</monogr>
	<note>Long Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Crosslingual character-level neural morphological tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Heigold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="748" to="759" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Conll-sigmorphon 2017 shared task: Universal morphological reinflection in 52 languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christo</forename><surname>Kirov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Sylak-Glassman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Géraldine</forename><surname>Walther</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekaterina</forename><surname>Vylomova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandra</forename><surname>Kübler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Eisner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mans</forename><surname>Hulden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL SIGMORPHON 2017 Shared Task: Universal Morphological Reinflection. Association for Computational Linguistics</title>
		<meeting>the CoNLL SIGMORPHON 2017 Shared Task: Universal Morphological Reinflection. Association for Computational Linguistics<address><addrLine>Vancouver</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Morphological segmentation inside-out</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arun</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2325" to="2330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Paradigm completion for derivational morphology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekaterina</forename><surname>Vylomova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huda</forename><surname>Khayrallah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christo</forename><surname>Kirov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="714" to="720" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Morfessor and hutmegs: Unsupervised morpheme segmentation for highlyinflecting and compounding languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathias</forename><surname>Creutz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krista</forename><surname>Lagus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krister</forename><surname>Lindén</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sami</forename><surname>Virpioja</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Supervised learning of complete morphological paradigms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Durrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Denero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1185" to="1195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Efficient algorithms for parsing the DOP model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Morphological tagging: Data vs. dictionaries</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st North American chapter of the Association for Computational Linguistics conference. Association for Computational Linguistics</title>
		<meeting>the 1st North American chapter of the Association for Computational Linguistics conference. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="94" to="101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Tagging inflective languages: Prediction of morphological categories for a rich, structured tagset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Hajič</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbora</forename><surname>Hladká</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics</title>
		<meeting>the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="483" to="490" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Neural morphological tagging from characters for morphologically rich languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Heigold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guenter</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Van Genabith</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.06640</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">An extensive empirical evaluation of character-based morphological tagging for 14 languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Heigold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guenter</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Van Genabith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="505" to="513" />
		</imprint>
	</monogr>
	<note>Long Papers. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Bidirectional lstm-crf models for sequence tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1508.01991</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Loopy belief propagation: Convergence and effects of message errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Alexander T Ihler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename><surname>Fisher John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">S</forename><surname>Willsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="905" to="936" />
			<date type="published" when="2005-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Google&apos;s multilingual neural machine translation system: enabling zero-shot translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melvin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghui</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhil</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernanda</forename><surname>Thorat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Viégas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Wattenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Corrado</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.04558</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A rich morphological tagger for english: Exploring the cross-linguistic tradeoff between morphology and syntax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christo</forename><surname>Kirov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Sylak-Glassman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Knowles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter</title>
		<meeting>the 15th Conference of the European Chapter</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="112" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">End-to-end sequence labeling via bi-directional lstm-cnns-crf</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1064" to="1074" />
		</imprint>
	</monogr>
	<note>Long Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Joint lemmatization and morphological tagging with lemming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Fraser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2268" to="2274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Efficient higher-order crfs for morphological tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helmut</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="322" to="332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Robust morphological tagging with word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="526" to="536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Loopy belief propagation for approximate inference: An empirical study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kevin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yair</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifteenth conference on Uncertainty in artificial intelligence</title>
		<meeting>the Fifteenth conference on Uncertainty in artificial intelligence</meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="467" to="475" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Universal dependencies 2.1. LINDAT/CLARIN digital library at the Institute of Formal and Applied Linguistics ( ´ UFAL</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Faculty of Mathematics and Physics</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
		<respStmt>
			<orgName>Charles University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Nominal tense in crosslinguistic perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachel</forename><surname>Nordlinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Louisa</forename><surname>Sadler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="776" to="806" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Tagging and morphological disambiguation of turkish text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kemal</forename><surname>Oflazer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilker</forename><surname>Kuruöz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fourth conference on Applied natural language processing. Association for Computational Linguistics</title>
		<meeting>the fourth conference on Applied natural language processing. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="144" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Automatic differentiation in pytorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Multilingual part-of-speech tagging with bidirectional long short-term memory models and auxiliary loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Plank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="412" to="418" />
		</imprint>
	</monogr>
	<note>Short Papers)</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Unsupervised multilingual learning for pos tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Snyder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tahira</forename><surname>Naseem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1041" to="1050" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Improved dynamic schedules for belief propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Uncertainty in Artificial Intelligence (UAI)</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Dynamic conditional random fields: Factorized probabilistic models for labeling and segmenting sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khashayar</forename><surname>Rohanimanesh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="693" to="723" />
			<date type="published" when="2007-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Statistical parsing of morphologically rich languages (spmrl): what, how and whither</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reut</forename><surname>Tsarfaty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Djamé</forename><surname>Seddah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandra</forename><surname>Kübler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie</forename><surname>Candito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannick</forename><surname>Versley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ines</forename><surname>Rehbein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lamia</forename><surname>Tounsi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL HLT 2010 First Workshop on Statistical Parsing of Morphologically-Rich Languages. Association for Computational Linguistics</title>
		<meeting>the NAACL HLT 2010 First Workshop on Statistical Parsing of Morphologically-Rich Languages. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Parsing morphologically rich languages: Introduction to the special issue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reut</forename><surname>Tsarfaty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Djamé</forename><surname>Seddah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandra</forename><surname>Kübler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="15" to="22" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Word representation models for morphologically rich languages in neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekaterina</forename><surname>Vylomova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanli</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gholamreza</forename><surname>Haffari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Subword and Character Level Models in NLP</title>
		<meeting>the First Workshop on Subword and Character Level Models in NLP<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="103" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Estimating the&quot;wrong&quot;graphical model: Benefits in the computation-limited setting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wainwright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1829" to="1859" />
			<date type="published" when="2006-09" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
