<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:34+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Personalized Language Model for Query Auto-Completion</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 15-20, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Jaech</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mari</forename><surname>Ostendorf</surname></persName>
							<email>{ajaech, ostendor}@uw.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Personalized Language Model for Query Auto-Completion</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="700" to="705"/>
							<date type="published">July 15-20, 2018</date>
						</imprint>
					</monogr>
					<note>700</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Query auto-completion is a search engine feature whereby the system suggests completed queries as the user types. Recently, the use of a recurrent neural network language model was suggested as a method of generating query completions. We show how an adaptable language model can be used to generate personalized completions and how the model can use online updating to make predictions for users not seen during training. The personalized predictions are significantly better than a base-line that uses no user information.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Query auto-completion (QAC) is a feature used by search engines that provides a list of suggested queries for the user as they are typing. For in- stance, if the user types the prefix "mete" then the system might suggest "meters" or "meteorite" as completions. This feature can save the user time and reduce cognitive load <ref type="bibr" target="#b2">(Cai et al., 2016)</ref>.</p><p>Most approaches to QAC are extensions of the Most Popular Completion (MPC) algorithm <ref type="bibr">(BarYossef and Kraus, 2011</ref>). MPC suggests com- pletions based on the most popular queries in the training data that match the specified prefix. One way to improve MPC is to consider additional sig- nals such as temporal information <ref type="bibr" target="#b15">(Shokouhi and Radinsky, 2012;</ref><ref type="bibr" target="#b19">Whiting and Jose, 2014</ref>) or infor- mation gleaned from a users' past queries <ref type="bibr" target="#b14">(Shokouhi, 2013)</ref>. This paper deals with the latter of those two signals, i.e. personalization. Personal- ization relies on the fact that query likelihoods are drastically different among different people de- pending on their needs and interests.</p><p>Recently, <ref type="bibr" target="#b12">Park and Chiba (2017)</ref> suggested a significantly different approach to QAC. In their</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cold Start</head><p>Warm Start 1 bank of america bank of america 2 barnes and noble basketball 3 babiesrus baseball 4 baby names barnes and noble 5 bank one baltimore <ref type="table">Table 1</ref>: Top five completions for the prefix "ba" for a cold start model with no user knowledge and a warm model that has seen the queries espn, sports news, nascar, yankees, and nba.</p><p>work, completions are generated from a charac- ter LSTM language model instead of by ranking completions retrieved from a database, as in the MPC algorithm. This approach is able to com- plete queries whose prefixes were not seen during training and has significant memory savings over having to store a large query database. Building on this work, we consider the task of personalized QAC, advancing current methods by combining the obvious advantages of personaliza- tion with the effectiveness of a language model in handling rare and previously unseen prefixes. The model must learn how to extract information from a user's past queries and use it to adapt the gen- erative model for that person's future queries. To do this, we leverage recent advances in context- adaptive neural language modeling. In particular, we make use of the recently introduced FactorCell model that uses an embedding vector to additively transform the weights of the language model's re- current layer with a low-rank matrix <ref type="bibr" target="#b5">(Jaech and Ostendorf, 2017)</ref>. By allowing a greater fraction of the weights to change during personalization, the FactorCell model has advantages over the tra- ditional approach to adaptation of concatenating a context vector to the input of the LSTM <ref type="bibr" target="#b10">(Mikolov and Zweig, 2012)</ref>. <ref type="table">Table 1 provides an anecdotal example from the trained FactorCell model to demonstrate the  intended behavior. The table shows the top five  completions for the prefix "</ref>ba" in a cold start sce- nario and again after the user has completed five sports related queries. In the warm start scenario, the "baby names" and "babiesrus" completions no longer appear in the top five and have been re- placed with "basketball" and "baseball". The novel aspects of this work are the appli- cation of an adaptive language model to the task of QAC personalization and the demonstration of how RNN language models can be adapted to con- texts (users) not seen during training. An addi- tional contribution is showing that a richer adapta- tion framework gives added gains with added data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Model</head><p>Adaptation depends on learning an embedding for each user, which we discuss in Section 2.1, and then using that embedding to adjust the weights of the recurrent layer, discussed in Section 2.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Learning User Embeddings</head><p>During training, we learn an embedding for each of the users. We think of these embeddings as holding latent demographic factors for each user. Users who have less than 15 queries in the train- ing data (around half the users but less than 13% of the queries) are grouped together as a single entity, user 1 , leaving k users. The user embeddings ma- trix U k×m , where m is the user embedding size, is learned via back-propagation as part of the end-to- end model. The embedding for an individual user is the ith row of U and is denoted by u i .</p><p>It is important to be able to apply the model to users that are not seen during training. This is done by online updating of the user embeddings during evaluation. When a new person, user k+1 is seen, a new row is added to U and initialized to u 1 . Each person's user embedding is updated via back-propagation every time they select a query. When doing online updating of the user embed- dings, the rest of the model parameters (everything except U) are frozen.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Recurrent Layer Adaptation</head><p>We consider three model architectures which dif- fer only in the method for adapting the recurrent layer. First is the unadapted LM, analogous to the model from <ref type="bibr" target="#b12">Park and Chiba (2017)</ref>, which does no personalization. The second architecture was introduced by <ref type="bibr" target="#b10">Mikolov and Zweig (2012)</ref> and has been used multiple times for LM personalization <ref type="bibr" target="#b18">(Wen et al., 2013;</ref><ref type="bibr" target="#b4">Huang et al., 2014;</ref><ref type="bibr" target="#b8">Li et al., 2016)</ref>. It works by concatenating a user embed- ding to the character embedding at every step of the input to the recurrent layer. <ref type="bibr" target="#b5">Jaech and Ostendorf (2017)</ref> refer to this model as the ConcatCell and show that it is equivalent to adding a term Vu to adjust the bias of the recurrent layer. The hidden state of a ConcatCell with embedding size e and hidden state size h is given in Equation 1 where σ is the activation function, w t is the character embedding, h t−1 is the previous hidden state, and W ∈ R e+h×h and b ∈ R h are the recurrent layer weight matrix and bias vector.</p><formula xml:id="formula_0">h t = σ([w t , h t−1 ]W + b + Vu)<label>(1)</label></formula><p>Adapting just the bias vector is a significant lim- itation. The FactorCell model, <ref type="bibr" target="#b5">(Jaech and Ostendorf, 2017)</ref>, remedies this by letting the user embedding transform the weights of the recurrent layer via the use of a low-rank adaptation ma- trix. The FactorCell uses a weight matrix W = W + A that has been additively transformed by a personalized low-rank matrix A. Because the Fac- torCell weight matrix W is different for each user (See Equation 2), it allows for a much stronger adaptation than what is possible using the more standard ConcatCell model. 1</p><formula xml:id="formula_1">h t = σ([w t , h t−1 ]W + b)<label>(2)</label></formula><p>The low-rank adaptation matrix A is generated by taking the product between a user's m dimen- sional embedding and left and right bases tensors, Z L ∈ R m×e+h×r and Z R ∈ R r×h×m as so,</p><formula xml:id="formula_2">A = (u i × 1 Z L )(Z R × 3 u i )<label>(3)</label></formula><p>where × i denotes the mode-i tensor product. The above product selects a user specific adaptation matrix by taking a weighted combination of the m rank r matrices held between Z L and Z R . The rank, r, is a hyperparameter which controls the de- gree of personalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data</head><p>Our experiments make use of the AOL Query data collected over three months in 2006 ( <ref type="bibr" target="#b13">Pass et al., 2006</ref>). The first six of the ten files were used for training. This contains approximately 12 million queries from 173,000 users for an average of 70 queries per user (median 15). A set of 240,000 queries from those same users (2% of the data) was reserved for tuning and validation. From the remaining files, one million queries from 30,000 users are used to test the models on a disjoint set of users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Implementation Details</head><p>The vocabulary consists of 79 characters including special start and stop tokens. Models were trained for six epochs. The Adam optimizer is used dur- ing training with a learning rate of 10 −3 (Kingma and <ref type="bibr" target="#b6">Ba, 2014)</ref>. When updating the user embed- dings during evaluation, we found that it is easier to use an optimizer without momentum. We use Adadelta <ref type="bibr" target="#b20">(Zeiler, 2012)</ref> and tune the online learn- ing rate to give the best perplexity on a held-out set of 12,000 queries, having previously verified that perplexity is a good indicator of performance on the QAC task. <ref type="bibr">2</ref> The language model is a single-layer character- level LSTM with coupled input and forget gates and layer normalization ( <ref type="bibr" target="#b9">Melis et al., 2018;</ref><ref type="bibr">Ba et al., 2016</ref>). We do experiments on two model configurations: small and large. The small mod- els use an LSTM hidden state size of 300 and 20 dimensional user embeddings. The large models use a hidden state size of 600 and 40 dimensional user embeddings. Both sizes use 24 dimensional character embeddings. For the small sized mod- els, we experimented with different values of the FactorCell rank hyperparameter between 30 and 50 dimensions finding that bigger rank is better. The large sized models used a fixed value of 60 for the rank hyperparemeter. During training only and due to limited computational resources, queries are truncated to a length of 40 characters.</p><p>Prefixes are selected uniformly at random with the constraint that they contain at least two charac- ters in the prefix and that there is at least one char- acter in the completion. To generate completions using beam search, we use a beam width of 100 and a branching factor of 4. Results are reported using mean reciprocal rank (MRR), the standard method of evaluating QAC systems. It is the mean of the reciprocal rank of the true completion in the <ref type="bibr">2</ref>   <ref type="table">Table 2</ref>: MRR reported for seen and unseen pre- fixes for small (S) and big (B) models. top ten proposed completions. The reciprocal rank is zero if the true completion is not in the top ten. Neural models are compared against an MPC baseline. Following <ref type="bibr" target="#b12">Park and Chiba (2017)</ref>, we remove queries seen less than three times from the MPC training data. <ref type="table">Table 2</ref> compares the performance of the differ- ent models against the MPC baseline on a test set of one million queries from a user population that is disjoint with the training set. Results are pre- sented separately for prefixes that are seen or un- seen in the training data. Consistent with prior work, the neural models do better than the MPC baseline. The personalized models are both bet- ter than the unadapted one. The FactorCell model is the best overall in both the big and small sized experiments, but the gain is mainly for the seen prefixes. <ref type="figure" target="#fig_0">Figure 1</ref> shows the relative improvement in MRR over an unpersonalized model versus the number of queries seen per user. Both the Factor- Cell and the ConcatCell show continued improve- ment as more queries from each user are seen, and the FactorCell outperforms the ConcatCell by an increasing margin over time. In the long run, we expect that the system will have seen many queries from most users. Therefore, the right side of <ref type="figure" target="#fig_0">Fig- ure 1</ref>, where the relative gain of FactorCell is up to 2% better than that of the ConcatCell, is more indicative of the potential of these models for ac- tive users. Since the data was collected over a lim- ited time frame and half of all users have fifteen or fewer queries, the results in <ref type="table">Table 2</ref> do not reflect the full benefit of personalization. <ref type="figure" target="#fig_1">Figure 2</ref> shows the MRR for different prefix and query lengths. We find that longer prefixes help the model make longer completions and (more ob- viously) shorter completions have higher MRR. Comparing the personalized model against the unpersonalized baseline, we see that the biggest gains are for short queries and prefixes of length one or two.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head><p>We found that one reason why the FactorCell outperforms the ConcatCell is that it is able to pick up sooner on the repetitive search behaviors that some users have. This commonly happens for nav- igational queries where someone searches for the name of their favorite website once or more per day. At the extreme tail there are users who search for nothing but free online poker. Both models do well on these highly predictable users but the Fac- torCell is generally a bit quicker to adapt.</p><p>We conducted case studies to better understand what information is represented in the user em- beddings and what makes the FactorCell different from the ConcatCell. From a cold start user em- bedding we ran two queries and allowed the model to update the user embedding. Then, we ranked  <ref type="table">1 high school musical  horoscope  2  chris brown  high school musical  3  funnyjunk.com  homes for sale  4</ref> funbrain.com modular homes 5 chat room hair styles <ref type="table">Table 3</ref>: The five queries that have the great- est adapted vs. unadapted likelihood ratio after searching for "high school softball" and "math homework help". the most frequent 1,500 queries based on the ratio of their likelihood from before and after updating the user embeddings. <ref type="table">Tables 3 and 4</ref> show the queries with the high- est relative likelihood of the adapted vs. unadapted models after two related search queries: "high school softball" and "math homework help" for <ref type="table">Table 3</ref>, and "Prada handbags" and "Versace eye- wear" for <ref type="table">Table 4</ref>. In both cases, the Factor- Cell model examples are more semantically co- herent than the ConcatCell examples. In the first case, the FactorCell model identifies queries that a high school student might make, including enter- tainment sources and a celebrity entertainer pop- ular with that demographic. In the second case, the FactorCell model chooses retailers that carry woman's apparel and those that sell home goods. While these companies' brands are not as luxu- rious as Prada or Versace, most of the top luxury brand names do not appear in the top 1,500 queries and our model may not be capable of being that specific. There is no obvious semantic connec- tion between the highest likelihood ratio phrases for the ConcatCell; it seems to be focusing more on orthography than semantics (e.g. "home" in the first example).. Not shown are the queries which experienced the greatest decrease in like- lihood. For the "high school" case, these included searches for travel agencies and airline tickets- websites not targeted towards the high school age demographic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>While the standard implementation of MPC can not handle unseen prefixes, there are variants which do have that ability. <ref type="bibr" target="#b12">Park and Chiba (2017)</ref> find that the neural LM outperforms MPC even when MPC has been augmented with the approach from <ref type="bibr" target="#b11">Mitra and Craswell (2015)</ref> for handling rare  <ref type="table">1  neiman marcus  craigslist nyc  2  pottery barn  myspace layouts  3  jc penney  verizon wireless  4</ref> verizon wireless jensen ackles 5 bed bath and beyond webster dictionary <ref type="table">Table 4</ref>: The five queries that have the great- est adapted vs. unadapted likelihood ratio after searching for "prada handbags" and "versace eye- wear".</p><p>prefixes. There has also been work on personaliz- ing MPC <ref type="bibr" target="#b14">(Shokouhi, 2013;</ref><ref type="bibr" target="#b3">Cai et al., 2014</ref>). We did not compare against these specific models be- cause our goal was to show how personalization can improve the already-proven generative neural model approach. RNN's have also previously been used for the related task of next query suggestion ( <ref type="bibr" target="#b16">Sordoni et al., 2015</ref>).</p><p>Our results are not directly comparable to <ref type="bibr" target="#b12">Park and Chiba (2017)</ref> or <ref type="bibr" target="#b11">Mitra and Craswell (2015)</ref> due to differences in the partitioning of the data and the method for selecting random prefixes. Prior work partitions the data by time instead of by user. Splitting by users is necessary in order to properly test personalization over longer time ranges. <ref type="bibr" target="#b17">Wang et al. (2018)</ref> show how spelling correction can be integrated into an RNN language model query auto-completion system and how the com- pletions can be generated in real time using a GPU. Our method of updating the model during evaluation resembles work on dynamic evaluation for language modeling <ref type="bibr" target="#b7">(Krause et al., 2017</ref>), but differs in that only the user embeddings (latent de- mographic factors) are updated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>Our experiments show that the LSTM model can be improved using personalization. The method of adapting the recurrent layer clearly matters and we obtained an advantage by using the FactorCell model. The reason the FactorCell does better is in part attributable to having two to three times as many parameters in the recurrent layer as either the ConcatCell or the unadapted models. By de- sign, the adapted weight matrix W only needs to be computed at most once per query and is reused many thousands of times during beam search. As a result, for a given latency budget, the FactorCell model outperforms the <ref type="bibr" target="#b10">Mikolov and Zweig (2012)</ref> model for LSTM adaptation.</p><p>The cost for updating the user embeddings is similar to the cost of the forward pass and depends on the size of the user embedding, hidden state size, FactorCell rank, and query length. In most cases there will be time between queries for up- dates, but updates can be less frequent to reduce computational costs.</p><p>We also showed that language model person- alization can be effective even on users who are not seen during training. The benefits of person- alization are immediate and increase over time as the system continues to leverage the incoming data to build better user representations. The approach can easily be extended to include time as an addi- tional conditioning factor. We leave the question of whether the results can be improved by com- bining the language model with MPC for future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Relative improvement in MRR over the unpersonalized model versus queries seen using the large size models. Plot uses a moving average of width 9 to reduce noise.</figDesc><graphic url="image-1.png" coords="3,314.36,220.66,204.10,142.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: MRR by prefix and query lengths for the large FactorCell and unadapted models with the first 50 queries per user excluded.</figDesc><graphic url="image-2.png" coords="4,90.43,62.81,181.42,126.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>FactorCell ConcatCell</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>FactorCell ConcatCell</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>Code at http://github.com/ajaech/query completion</figDesc><table>Size 
Model 
Seen Unseen All 
MPC 
.292 
.000 .203 
Unadapted .292 
.256 .267 
(S) ConcatCell .296 
.263 .273 
FactorCell .300 
.264 .275 
Unadapted .324 
.286 .297 
(B) ConcatCell .330 
.298 .308 
FactorCell .335 
.298 .309 

</table></figure>

			<note place="foot" n="1"> In the case of an LSTM, W is extended to incorporate all of the gates.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><forename type="middle">Lei</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><forename type="middle">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.06450</idno>
		<imprint/>
	</monogr>
<note type="report_type">ton. 2016. Layer normalization. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Contextsensitive query auto-completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziv</forename><surname>Bar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Yossef</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naama</forename><surname>Kraus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="107" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A survey of query auto completion in information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends in Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="273" to="363" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Time-sensitive personalized query autocompletion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shangsong</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1599" to="1608" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Enriching cold start personalized language model using social network information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Yang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Ting</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shoude</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="611" to="617" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Low-rank RNN adaptation for context-aware language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Jaech</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mari</forename><surname>Ostendorf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.02603</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Dynamic evaluation of neural sequence models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emmanuel</forename><surname>Kahembwe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iain</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Renals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.07432</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">A persona-based neural conversation model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>ACL</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">On the state of the art of evaluation in neural language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gábor</forename><surname>Melis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>ICLR</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Context dependent recurrent neural network language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SLT</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="234" to="239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Query autocompletion for rare prefixes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhaskar</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1755" to="1758" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A neural language model for query auto-completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Park</forename><surname>Dae Hoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rikio</forename><surname>Chiba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1189" to="1192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A picture of search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Pass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdur</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cayley</forename><surname>Torgeson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">InfoScale</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">152</biblScope>
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning to personalize query auto-completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milad</forename><surname>Shokouhi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="103" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Timesensitive query auto-completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milad</forename><surname>Shokouhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kira</forename><surname>Radinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="601" to="610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A hierarchical recurrent encoderdecoder for generative context-aware query suggestion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hossein</forename><surname>Vahabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christina</forename><surname>Lioma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><forename type="middle">Grue</forename><surname>Simonsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianyun</forename><surname>Nie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="553" to="562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Realtime query completion via deep language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Po-Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Zico</forename><surname>Kolter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijai</forename><surname>Mohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inderjit</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>ICLR</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Recurrent neural network based language model personalization by social network crowdsourcing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Tsung-Hsien Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hung-Yi</forename><surname>Heidel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin-Shan</forename><surname>Tsao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2703" to="2707" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Recent and robust query auto-completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stewart</forename><surname>Whiting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joemon M Jose</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="971" to="982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">ADADELTA: an adaptive learning rate method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zeiler</surname></persName>
		</author>
		<idno>abs/1212.5701</idno>
		<imprint>
			<date type="published" when="2012" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
