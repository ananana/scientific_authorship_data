<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:32+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Improving Slot Filling in Spoken Language Understanding with Joint Pointer and Attention</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 15-20, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Bosch Research and Technology Center Sunnyvale</orgName>
								<address>
									<postCode>94085</postCode>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Feng</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Bosch Research and Technology Center Sunnyvale</orgName>
								<address>
									<postCode>94085</postCode>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Improving Slot Filling in Spoken Language Understanding with Joint Pointer and Attention</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="426" to="431"/>
							<date type="published">July 15-20, 2018</date>
						</imprint>
					</monogr>
					<note>426</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present a generative neural network model for slot filling based on a sequence-to-sequence (Seq2Seq) model together with a pointer network, in the situation where only sentence-level slot annotations are available in the spoken dialogue data. This model predicts slot values by jointly learning to copy a word which may be out-of-vocabulary (OOV) from an input utterance through a pointer network, or generate a word within the vocabulary through an attentional Seq2Seq model. Experimental results show the effectiveness of our slot filling model, especially at addressing the OOV problem. Additionally , we integrate the proposed model into a spoken language understanding system and achieve the state-of-the-art performance on the benchmark data.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Slot filling is a key component in spoken language understanding (SLU), which is usually treated as a sequence labeling problem and solved us- ing methods such as conditional random fields (CRFs) <ref type="bibr" target="#b10">(Raymond and Riccardi, 2007)</ref> or recur- rent neural networks (RNNs) ( <ref type="bibr" target="#b15">Yao et al., 2013;</ref><ref type="bibr" target="#b9">Mesnil et al., 2015)</ref>.</p><p>Although these models have achieved good re- sults, they are learned on the datasets with word- level annotations, e.g., with the BIO tagging schema as in ATIS ( <ref type="bibr" target="#b4">Hemphill et al., 1990</ref>). Man- ual annotations at word level require big effort and some corpora has only sentence-level annota- tions available, e.g., the utterance "... moderately priced restaurant" has a slot-value pair annotation of "pricerange=moderate". As such datasets lack explicit alignment between the annotations and the input words, some systems rely on handcrafted rules to find the alignments in order to automati- cally create word-level labels to learn the sequence model ( <ref type="bibr" target="#b17">Zhou and He, 2011;</ref><ref type="bibr" target="#b7">Henderson, 2015)</ref>, but finding such alignments is non-trivial. For exam- ple, it was shown in <ref type="bibr" target="#b7">(Henderson, 2015</ref>) that when applying the manually created word aliases to the speech recognition hypotheses, only around 73% of alignments can be found due to the noise, and a CRF model trained on such noisy data performs particularly worse than some other methods. In addition it is time-consuming to adapt the manual rules or aliases to new domains.</p><p>Some other work avoids this issue by regard- ing slot filling as a classification task <ref type="bibr" target="#b5">(Henderson et al., 2012;</ref><ref type="bibr" target="#b14">Williams, 2014;</ref><ref type="bibr" target="#b1">Barahona et al., 2016)</ref>, where an utterance is classified into one or more slot-value pairs. This, however, brings other challenges. One is that some types of slots may have a large or even unlimited number of possible values, so the classifiers may suffer from the data sparsity problem when the training data is limited. Another is the OOV problem caused by unknown slot values (e.g., restaurant name, street name), which is impossible to predefine and is very com- mon in real-world spoken dialogue applications.</p><p>To address these challenges, we present a neural generative model for slot filling on unaligned dia- log data, specifically for slot value prediction as it has more challenges caused by OOV. The model uses Seq2Seq learning to predict a sequence of slot values from an utterance. Inspired by the ability of pointer network (Ptr-Net) ( <ref type="bibr" target="#b12">Vinyals et al., 2015)</ref> at addressing OOV problems, we incorporate Ptr-Net into a standard Seq2Seq attentional model to han- dle OOV slots. It can predict slot values by either generating one from a fixed vocabulary or select- ing a word from the utterance. The final model is a weighted combination of the two operations.</p><p>To summarize, our main contributions are:</p><p>Figure 1: Our model for slot value prediction based on Seq2Seq learning with attention and Ptr-Net.</p><p>• We use a neural generative model for slot fill- ing on the data without word-level annota- tions which has received less attention.</p><p>• We adopt the pointer network to handle the OOV problem in slot value prediction, which achieves good performance without any manually-designed rules or features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background of Pointer Network</head><p>Ptr-Net is a variation of the standard Seq2Seq model with attention. At each decoding step, it selects a position from the input sequence based on the attention distribution instead of generating a token from the target vocabulary. Given the in- put X = {x 1 , ..., x T }, the output y t at time step t is predicted by:</p><formula xml:id="formula_0">P ptr (y t = w|y t−1 1 , X) = i:x i =w a t i (1)</formula><p>where a t i is the attention weight of position i at step t. The advantage of Ptr-Net is that it can make better predictions on unknown or rare words. It has been successfully applied to tasks such as ab- stractive summarization <ref type="bibr" target="#b11">(See et al., 2017)</ref>, ques- tion answering <ref type="bibr" target="#b3">(He et al., 2017)</ref>, reading com- prehension ( <ref type="bibr" target="#b13">Wang and Jiang, 2016)</ref>, and chunk- ing ( <ref type="bibr" target="#b16">Zhai et al., 2017</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model for Slot Value Prediction</head><p>Our model for slot value prediction is a hybrid of a Seq2Seq attentional model and a Ptr-Net, simi- lar as the one in <ref type="bibr" target="#b11">See et al. (2017)</ref>. The input is a sequence of words in an utterance, and the output is a sequence of slot values whose tokens may or may not appear in the input.</p><p>The hybrid model, illustrated in <ref type="figure">Figure 1</ref>, allows us to both generate a slot value from a fixed vo- cabulary and pick a value from the input via point- ing. The two components (Seq2Seq and Ptr-Net) share the same encoder-decoder architecture and attention scores. We adopt a single-layer bidirec- tional GRU ( ) for the encoder, and a single-layer unidirectional GRU for the decoder. The attention is calculated as in .</p><p>The slot vocabulary is set to contain only the values of enumerable slots, but not those of non-enumerable slots (e.g., values of "restaurant name") as we assume these are not known in ad- vance in the real scenarios.</p><p>We use the term "extended vocabulary" to de- note the union of the slot vocabulary and all words from the input utterances. The probability distri- bution over the extended vocabulary is calculated as:</p><formula xml:id="formula_1">P (w) = p t P gen + (1 − p t )P ptr (2)</formula><p>That is, the model makes the final predictions using a weighted combination of the predictions from two individual components. At the decod- ing step t, the Seq2Seq component produces the probability distribution P gen for the next slot value within the vocabulary, while Ptr-Net produces the probability distribution P ptr over the input posi- tions. p t ∈ [0, 1] is a parameter to balance the two components. It is learned at each time step based on the decoder input d t , decoder state s t and the context vector c t as follows:</p><formula xml:id="formula_2">p t = σ(w c c t + w s s t + w d d t + b)<label>(3)</label></formula><p>where σ is a sigmoid function. w c , w s and w d are all trainable weights.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we present our experimental re- sults on DSTC2 (Dialog State Tracking Chal- lenge) ( <ref type="bibr" target="#b6">Henderson et al., 2014</ref>), including the re- sults of slot value prediction solely and a complete SLU system. Our models are implemented using Keras 1 with TensorFlow as backend. In all the ex- periments, the dimension of hidden states is 128, dimension of word embeddings is 100, dropout rate is 0.5, and batch size is 32. Word embeddings are not pre-trained but learned from scratch during training. Teacher forcing is used during training, with Adam optimizer ( <ref type="bibr" target="#b8">Kingma and Ba, 2014</ref>). All training consists of 10 epochs with early stopping on the development set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data</head><p>DSTC2 consists of multi-turn dialogues between users and a dialog system, in the restaurant search domain. Each utterance is annotated with seman- tics including dialog-acts and slot-value pairs. For an utterance, both its transcription and 10-best hy- potheses are provided. We use the top hypothesis as input throughout our experiments. The corpus has been separated into training, development and testing, containing 11,677, 3,934 and 9,890 utter- ances respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">A Complete SLU System</head><p>For better evaluation and comparison, we inte- grated our model of slot value prediction into a complete SLU system, which uses a CNN clas- sifier to obtain dialog-acts and slot types respec- tively after slot value prediction. For dialog act prediction, the input to the CNN model is the ut- terance and the output is one or more dialog acts (some utterances can have more than one dialog acts). For slot type prediction, the input is each predicted slot value together with the utterance, and the output is one of the predefined slot types. Given the limited numbers of various dialog-acts and slot types for classification, a standard CNN model is expected to achieve good performance.</p><p>1 https://keras.io  Note that we can adopt other SLU frameworks as well (e.g., some joint frameworks), but given our focus in this work is to explore the hybrid Seq2Seq solutions for slot filling, we do not ex- plore much on the SLU architecture, nor do we use any extra information (e.g., dialogue context). Despite the simplicity of our SLU system, it out- performs the prior state-of-the-art. In the whole process, neither manually designed features nor domain-specific rules are employed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Baselines</head><p>We compare the overall SLU performance of our system against two existing baselines on DSTC2. One baseline <ref type="bibr" target="#b14">(Williams, 2014</ref>) uses binary SVM classifiers to predict the existence of each slot- value pair and dialog act. The other ( <ref type="bibr" target="#b1">Barahona et al., 2016</ref>) uses CNN and LSTM jointly for clas- sification.</p><p>For slot value prediction, since it is a sub-task of SLU and not reported in the prior work, we im- plemented another two models for it. One adopts CNN to classify an utterance into one or more slot values. The other uses the basic Seq2Seq atten- tional model (without Ptr-Net). Note that when learning this basic model, the target vocabulary is set to contain all the slot values in the training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Results of Slot Value Prediction</head><p>We first report the results on slot value predic- tion only. We compare the results of our proposed model and our own implemented baselines in Ta- ble 1, using precision, recall and F1.</p><p>We can see that the proposed hybrid model achieves the best F1 score. Although CNN has a high precision, it suffers from the low recall. By looking into the results for each slot type, it is ob-   served that CNN performs much poorer on non- enumerable types of slots such as "food" due to its high cardinality. While both our model and the basic Seq2Seq model have higher recall.</p><p>Since our assumption is that the proposed model can better handle the OOV problem, we analyze the OOV rate in the corpus to obtain more insight. By checking the percentage of slot values in the testing set that do not exist in the training, we find that the OOV problem in DSTC2 is not that severe, with a OOV ratio less than 0.1%. This could be a reason why our model does not obtain larger gain on the complete dataset. We therefore design more experiments in the next section to assess the model when the OOV problem is more severe.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">OOV Slot Prediction</head><p>We create specific datasets by re-sampling from the original corpus. In particular, let group A de- note all the training utterances that contain non- enumerable slots, and group B denote the rest of the training utterances. We randomly select 5%, 10%, 15%, and 20% of group A, plus the whole set of group B. In this way, we can create training data with less non-enumerable slot values thus re- sulting in a higher OOV ratio. The testing set is same as before. We compare the proposed model with the baselines on these four specific datasets with different OOV ratios <ref type="table" target="#tab_3">(Table 2)</ref>.</p><p>Input: danish food in the centre of town Output: danish centre | spanish centre | centre Input: i would like singaporean food Output: singaporean | korean | None Input: what about chiquito (portuguese) Output: chiquito | portuguese | None Input: an expensive restaurant serving cantonese food Output: cantonese | portuguese expensive | expensive <ref type="table">Table 5</ref>: Examples of predicted slot values. Out- put is from the proposed model, Seq2Seq w/ attn, and CNN respectively (split by "|"). Bold denotes gold standard and "None" denotes empty result.</p><p>As shown in each column, on all the specific datasets, our model achieves the best performance. The CNN model performs much poorer than be- fore in terms of the recall. We can see that by reducing the training size, the OOV ratio (indi- cated in the first row in the brackets) goes up, and the performance of all models decreases in gen- eral. While CNN and the basic Seq2Seq model de- cline 10.3% and 9.2% in F1 respectively using the smallest training set compared to using the com- plete one, our model is the most stable one with the least performance drop of 5.4%. The gain of our model over the other two becomes more sig- nificant with the larger OOV rate. This shows the capability of the Ptr-Net to correctly predict the OOV slots.</p><p>Overall, the results in Section 4.4 and 4.5 demonstrate the effectiveness of the proposed hy- brid model for slot value prediction, especially when the training set is small and the OOV ratio is large. <ref type="table" target="#tab_5">Table 3</ref> compares the results of the overall SLU task by our systems (incorporated with different slot value prediction models) and prior arts. All our systems outperform the prior work, and among them the one with the proposed hybrid model achieves the best F1 score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">SLU Results</head><p>We also conduct the similar OOV experiments as in Section 4.5 for SLU <ref type="table" target="#tab_6">(Table 4)</ref>. Similar trend is observed as discussed before. The performance of the proposed model with 20% training data al- ready reaches that of the best system reported in the literature with 100% training data. <ref type="table">Table 5</ref> gives some examples of slot values pre- dicted by the proposed model and baselines. We can see that for the less frequent slots, our model can still predict the values correctly, while without the Ptr-Net, the basic Seq2Seq model tends to gen- erate words not appearing in the input, and CNN outputs nothing in many cases, which aligns with our assumption. We analyze the cases where Ptr- Net does not perform well and find several major types of errors: 1) partial prediction (e.g., detect only "oriental" for "asian oriental food"; 2) the prediction contains repetition of correct values; 3) speech recognition error although the prediction is proper if we look at the hypothesis itself (the third example). There are also cases where all the mod- els fail to give a completely correct prediction, yet with different behaviors (the last example).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Case Study and Error Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We adopt an attentional Seq2Seq model with Ptr-Net to predict slot values on dialogue data when only sentence-level semantic annotations are available. By switching between copying and gen- erating words, this solution can bypass the need of word-level annotations and overcome the OOV is- sue which is very common in real-world spoken dialogue applications. It does not require any do- main specific rules or dictionaries, and therefore can be easily adapted to new domains. Our model has achieved the state-of-the-art performance for both slot value prediction and SLU on the bench- mark even with less training data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 : Results of slot value prediction.</head><label>1</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Results of slot value prediction with vary-
ing training size and OOV ratio. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><head>Table 3 : Overall SLU performance.</head><label>3</label><figDesc></figDesc><table>Training Size 
5% 10% 15% 20% 

CNN 

P 91.6 92.0 92.3 93.0 
R 67.5 70.4 71.7 72.7 
F 77.8 79.8 80.7 81.6 

Seq2Seq 
w/ attention 

P 82.8 87.2 86.4 87.9 
R 74.3 75.1 78.0 78.4 
F 78.3 80.7 82.0 82.9 

Our model 

P 84.9 86.3 88.4 88.0 
R 76.8 77.9 79.0 79.9 
F 80.6 81.9 83.4 83.8 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 :</head><label>4</label><figDesc>SLU results with varying training size.</figDesc><table></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank Yifan He for helpful dis-cussions and proofreading, and the anonymous re-viewers for their valuable feedback.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.0473</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Exploiting sentence and context representations in deep neural models for spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lina M Rojas</forename><surname>Barahona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Gasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Mrkši´mrkši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei-Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Ultes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Hsien</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2016</title>
		<meeting>COLING 2016</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="258" to="267" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning phrase representations using RNN encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1724" to="1734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Generating natural answers by incorporating copying and retrieving mechanisms in sequence-tosequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cao</forename><surname>Shizhu He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="199" to="208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The atis spoken language systems pilot corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">J</forename><surname>Hemphill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Godfrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>George R Doddington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the DARPA speech and natural language workshop</title>
		<meeting>the DARPA speech and natural language workshop</meeting>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="page" from="96" to="101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Discriminative spoken language understanding using word confusion networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Gaši´gaši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blaise</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pirros</forename><surname>Tsiakoulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Spoken Language Technology Workshop (SLT)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="176" to="181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The second dialog state tracking challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blaise</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason D</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGDIAL Conference</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="263" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Discriminative methods for statistical spoken dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Matthew S Henderson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
		<respStmt>
			<orgName>University of Cambridge</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Using recurrent neural networks for slot filling in spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grégoire</forename><surname>Mesnil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaisheng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Heck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gokhan</forename><surname>Tur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on Audio, Speech and Language Processing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="530" to="539" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>TASLP)</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Generative and discriminative algorithms for spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Raymond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Riccardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eighth Annual Conference of the International Speech Communication Association</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Get to the point: Summarization with pointergenerator networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abigail</forename><surname>See</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1073" to="1083" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Pointer networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meire</forename><surname>Fortunato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navdeep</forename><surname>Jaitly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2692" to="2700" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.07905</idno>
		<title level="m">Machine comprehension using match-LSTM and answer pointer</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Web-style ranking and slu combination for dialog state tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason D</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGDIAL Conference</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="282" to="291" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Recurrent neural networks for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaisheng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Zweig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mei-Yuh</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangyang</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Interspeech</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2524" to="2528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Neural models for sequence chunking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feifei</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saloni</forename><surname>Potdar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3365" to="3371" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning conditional random fields from unaligned data for natural language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Information Retrieval</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="283" to="288" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
