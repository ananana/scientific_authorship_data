<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:19+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Scalable Semantic Parsing with Partial Ontologies</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
							<email>eunsol@cs.washington.edu, tomkwiat@google.com, lsz@cs.washington.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science &amp; Engineering</orgName>
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science &amp; Engineering</orgName>
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science &amp; Engineering</orgName>
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Scalable Semantic Parsing with Partial Ontologies</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1311" to="1320"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We consider the problem of building scal-able semantic parsers for Freebase, and present a new approach for learning to do partial analyses that ground as much of the input text as possible without requiring that all content words be mapped to Freebase concepts. We study this problem on two newly introduced large-scale noun phrase datasets, and present a new semantic parsing model and semi-supervised learning approach for reasoning with partial ontological support. Experiments demonstrate strong performance on two tasks: referring expression resolution and entity attribute extraction. In both cases, the partial analyses allow us to improve precision over strong baselines, while parsing many phrases that would be ignored by existing techniques.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recently, significant progress has been made in learning semantic parsers for large knowledge bases (KBs) such as Freebase (FB) <ref type="bibr" target="#b3">(Cai and Yates, 2013;</ref><ref type="bibr" target="#b1">Berant et al., 2013;</ref><ref type="bibr" target="#b12">Kwiatkowski et al., 2013;</ref><ref type="bibr" target="#b15">Reddy et al., 2014)</ref>. Although these methods can build general purpose meaning representations, they are typically evaluated on question answering tasks and are designed to only parse questions that have complete ontological coverage, in the sense that there exists a logical form that can be executed against Freebase to get the correct answer. <ref type="bibr">1</ref> In this paper, we instead consider the problem of learning semantic parsers for open domain text containing † Now at Google, NY.</p><p>1 To ensure all questions are answerable, the data is man- ually filtered. For example, the WebQuestions dataset intro- duced by <ref type="bibr" target="#b1">Berant et al. (2013)</ref> contains only the 7% of the originally gathered questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Wikipedia</head><p>Haitian human rights activists Art museums and galleries in New York School buildings completed in 1897 Olympic gymnasts of Norway</p><p>Appos. the capital of quake-hit Sichuan Province a major coal producing province the relaxed seaside capital of Mozambique <ref type="figure">Figure 1</ref>: Example noun phrases from Wikipedia category labels and appositives in newswire text.</p><p>concepts that may or may not be representable us- ing the Freebase ontology.</p><p>Even very large knowledge bases have two types of incompleteness that provide challenges for se- mantic parsing algorithms. They (1) have partial ontologies that cannot represent the meaning of many English phrases and (2) are typically miss- ing many facts. For example, consider the phrases in <ref type="figure">Figure 1</ref>. They include subjective or otherwise unmodeled phrases such as "relaxed" and "quake- hit." Freebase, despite being large-scale, contains a limited set of concepts that cannot represent the meaning of these phrases. They also refer to enti- ties that may be missing key facts. For example, a recent study <ref type="bibr" target="#b20">(West et al., 2014)</ref> showed that over 70% of people in FB have no birth place, and 99% have no ethnicity. In our work, we introduce a new semantic parsing approach that explicitly models ontological incompleteness and is robust to miss- ing facts, with the goal of recovering as much of a sentence's meaning as the ontology supports. We argue that this will enable the application of se- mantic parsers to a range of new tasks, such as information extraction (IE), where phrases rarely have full ontological support and new facts must be added to the KB.</p><p>Because existing semantic parsing datasets have been filtered to limit incompleteness, we introduce two new corpora that pair complex noun phrases with one or more entities that they describe. The  Symphonic Poems by Jean Sibelius e :</p><p>{The Bard, Finlandia,Pohjola's Daughter, En Saga, Spring Song, Tapiola... } l0 :</p><p>λx.Symphonic(x) ∧ P oems(x) ∧ by(JeanSibelius, x) y :</p><p>λx.composition.form(x, Symphonicpoems) ∧ composer(JeanSibelius, x)</p><p>x : Defunct Korean football clubs e :</p><p>{ Goyang KB Kookmin Bank FC,Hallelujah FC, Kyungsung FC } l0 :</p><p>λx.def unct(x) ∧ korean(x) ∧ f ootball(x) ∧ clubs(x) y :</p><formula xml:id="formula_0">λx.OpenType[defunct](x) ∧ OpenRel(x, KOREA) ∧ football clubs(x)) (b) Appos</formula><p>x : a driving force behind the project e :</p><formula xml:id="formula_1">Germany l0 : λx.driving(x) ∧ f orce(x) ∧ behind(x, theproject) y : λx.OpenType[driving force](x) ∧ OpenRel[behind](x, OpenEntity[the project])</formula><p>x : an EU outpost in the Mediterranean e :</p><formula xml:id="formula_2">Malta l0 : λx.outpost(x) ∧ EU (x) ∧ in(x, theM editerranean) y : λx.OpenRel(x, EU) ∧ OpenType[outpost](x) ∧ contained by(x, MediterraneanSea)</formula><p>Figure 2: Examples of noun phrases x, from the Wikipedia category and apposition datasets, paired with the set of entities e they describe, their underspecified logical form l 0 , and their final logical form y.</p><p>first new dataset contains 365,000 Wikipedia cate- gory labels <ref type="figure">(Figure 1</ref>, top), each paired with the list of the associated Wikipedia entity pages. The sec- ond has 67,000 noun phrases paired with a single named entity, extracted from the appositive con- structions in KBP 2009 newswire text <ref type="figure">(Figure 1</ref>, bottom). <ref type="bibr">2</ref> This new data is both large scale, and unique in the focus on noun phrases. Noun phrases contain a number of challenging compositional phenomena, including implicit relations and noun- noun modifiers (e.g. see <ref type="bibr" target="#b6">Gerber and Chai (2010)</ref>).</p><p>To better model text with only partial ontologi- cal support, we present a new semantic parser that builds logical forms with concepts from a target ontology and open concepts that are introduced when there is no appropriate concept match in the target ontology. <ref type="figure">Figure 2</ref> shows examples of the meanings that we extract. Only the first of these examples can be fully represented using Free- base, all other examples require explicit modeling of open concepts. To build these logical forms, we follow recent work for Combinatory Categori- cal Grammar (CCG) semantic parsing with Free- base ( <ref type="bibr" target="#b12">Kwiatkowski et al., 2013</ref>), extended to model when open concepts should be used. We develop a two-stage learning algorithm: we first compute broad coverage lexical statistics over all of the data, which are then incorporated as features in a full parsing model. The parsing model is tuned on a hand-labeled data set with gold analyses.</p><p>Experiments demonstrate the benefits of the new approach. It significantly outperforms strong base- 2 All new data is available on the authors' websites. lines on both a referring expression resolution task, where much like in the QA setting we directly eval- uate if we recover the correct logical form for each input noun phrase, and on entity attribute extrac- tion, where individual facts are extracted from the groundable part of the logical form. We also see that modeling incompleteness significantly boosts precision; we are able to more effectively deter- mine which words should not be mapped to KB concepts. When run on all of the Wikipedia cat- egory data, we estimate that the learned model would discover 12 million new facts that could be added to Freebase with 72% precision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Overview</head><p>Semantic Parsing with Open Concepts Our goal is to learn to map noun phrase referring ex- pressions x to logical forms y that describe their meaning. In this work, y is built using both con- cepts from a knowledge base K and open concepts that lie outside of the scope of K. For example, in <ref type="figure">Figure 2</ref> the phrase "Defunct Korean football clubs" is modeled using a logical form y that con- tains the K concept football clubs(x) as well as the open concepts OpenType[defunct](x).</p><p>In this paper we describe a new method for learn- ing the mapping from x to y from corpora of refer- ring expression noun phrases, paired with a sets of entities e that these referring expressions describe. <ref type="figure">Figure 2</ref> shows examples of these data drawn from two sources.</p><p>Tasks We introduce two new datasets (Sec. 3) that pair referring noun phrases x with one or more entities e that they describe. These data support evaluation for two tasks: referring expression reso- lution and information extraction.</p><p>In referring expression resolution, the parser is given x and is used to predict the referring expres- sion logical form y that describes e. Since the majority of our data cannot be fully modeled with Freebase, we evaluate each y against a hand labeled gold standard instead of trying to extract e from K.</p><p>The entity attribute extraction task also involves mapping phrases x to logical forms y, with the goal of adding new facts to the knowledge base K. To do this, we assume each x is additionally paired with an set of entities e. We also define an entity attribute to be a literal in y that uses only concepts from K. Finally, we extract, for each entity in e, all of the attributes listed in y. For example, the first logical form y in <ref type="figure">Figure 2</ref> has two entity attributes: composer(JeanSibelius, x) and composition.form(x, Symphonic poems) which can be added to K for the entities {TheBard, Finlandia}.</p><p>Model and Learning Our approach extends the two-stage semantic parser introduced by <ref type="bibr" target="#b12">Kwiatkowski et al (2013)</ref>. We use CCG to build domain-independent logical forms l 0 and then in- troduce a new method for reasoning about how to map this intermediary representation onto both open concepts and K concepts <ref type="bibr">(Sec. 4)</ref>.</p><p>To learn this model, we assume access to data with two different types of annotations. The first contains noun phrase descriptions x and described entity sets e (as in <ref type="figure">Figure 2</ref>), which can be eas- ily gathered at scale with no manual data labeling effort. However, this data, in general, has signif- icant amount of knowledge base incompleteness; many described concepts and entity attributes will be missing from K (see Sec. 3 for more details). Therefore, to support effective learning, we will also use a small hand-labeled dataset containing x, e, a gold logical form y, an intermediary CCG logical form l 0 , and a mapping from words in x to constants in K and open concepts. Our full learning approach (Sec. 5) estimates a linear model on the small labeled dataset, with broad coverage features derived from the larger dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data</head><p>We gathered two new datasets that pair complex noun phrases with one or more Freebase entities.</p><p>The Wikipedia category dataset contains 365,504 Wikipedia category names paired with the list of entities in that category. <ref type="bibr">3</ref>  <ref type="table">Table 1</ref> shows the details of this dataset and examples are given in <ref type="figure">Figure 2</ref>. For each development and test data, we randomly select 500 categories consisted of 3-10 words and describing fewer than 100 entities.</p><p>The apposition dataset is a large set of com- plex noun phrases paired with named entities, ex- tracted from appositive constructions such as "Gus- tav Bayer, a former Olympic gymnast for Norway." For this example, we extract the entity "Gustav Bayer" and pair it with the noun phrase "a former Olympic gymnast for Norway." To identify apposi- tive constructions, we ran the Stanford dependency parser on the newswire section of the KBP 2009 source corpus, <ref type="bibr">4</ref> and selected noun phrases com- posed of 3 to 10 words, starting with an article, and paired with a named entity that is in Freebase.</p><p>This procedure of identifying complex entity de- scriptions allows for information extraction from a wide range of sources. However, it is also noisy and challenging. The dependency parser makes er- rors, for example "the next day against the United States, Spain" is falsely detected as an apposition. Furthermore, addressing context and co-reference is often necessary. For example, "Puerto Montt, a city south of the capital" or "the company's par- ent, Shenhua Group" requires reference resolution. We gathered 67 thousand appositions, which will be released to support future work, and randomly selected 300 for testing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Measuring Incompleteness</head><p>To study the amount of incompleteness in this data, we hand labeled logical forms for 500 Wikipedia categories in the development set. Examples of annotations are given in the rows labeled y in <ref type="figure">Figure 2</ref>. We use these to measure the schema and fact coverage of Freebase. Many of the entities in this dataset do not have the Freebase attributes described by the category phrases. When a concept is not in Freebase, we annotate it as OpenType or OpenRel, as shown in <ref type="figure">Figure 2</ref>  <ref type="table">Table 2</ref>: Appositive data statistics.</p><p>Each category may have multiple correct logical forms. For example, "Hotels" can be mapped to: hotel(x), accomodation.type(x, hotel), or building function(x, hotel). There are also genuine ambiguities in meaning. For example, "People from Bordeaux" can be interpreted as</p><formula xml:id="formula_3">people(x) ∧ place lived(x, Bordeaux) or people(x) ∧ place of birth(x, Bordeaux).</formula><p>We made a best effort attempt to gather as many correct logical forms as possible, finding on average 1.8 logical forms per noun phrase. There were 97 unique binary relations, and 247 unique unary attributes in the annotation.</p><p>Given these logical forms, we also measured factual coverage. For the 72.8% of phrases that can be completely represented using Freebase, we executed the logical forms and compared the result to the labeled entity set. In total, 56% of the queries returned no entities and those that did return results have on average 15% overlap with the Wikipedia entity set. We also measured how often attributes from the labeled logical forms were assigned to the Wikipedia entities in FB, finding that only 33.6% were present. Given this rate, we estimate that it is possible to add 12 million new facts into FB from the 7 million entity-category pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Mapping Text to Meaning</head><p>We adopt a two-stage semantic parsing ap- proach ( <ref type="bibr" target="#b12">Kwiatkowski et al., 2013)</ref>. We first use a CCG parser to define a set CCG(x) of possible logical forms l 0 . Then we will choose the logical form l 0 that closely matches the linguistic struc- ture of the input text x, according to a learned linear model, and use an ontological match step that defines a set of transformations ONT(l 0 , K) to map this meaning to a Freebase query y. <ref type="figure">Figure 2</ref> shows examples of x, l 0 and y. In this section we describe our approach with the more detailed ex- ample derivation in <ref type="figure" target="#fig_4">Figure 3</ref>. We also describe the parameterization of a linear model that scores each derivation.</p><p>CCG parsing We use a CCG <ref type="bibr" target="#b17">(Steedman, 1996</ref>) semantic parser ( <ref type="bibr" target="#b12">Kwiatkowski et al., 2013</ref>) to gen- erate an underspecified logical form l 0 . <ref type="figure" target="#fig_4">Figure 3a</ref> shows an example parse. The constants F ormer, M unicipalities, in, Brandenburgh in l 0 are not tied to the target knowledge base, causing the logi- cal form to be underspecified. They can be replaced with Freebase constants in the later ontology match- ing step.</p><p>Ontological Matching The ontological match step has structural match and constant match com- ponents. Structural match operators can collapse or expand sub-expressions in the logical forms to match equivalent typed concepts in the target knowledge base. We adopt existing structural match operators ( <ref type="bibr" target="#b12">Kwiatkowski et al., 2013)</ref> and refer readers to that work for details.</p><p>Constant match operators replace underspeci- fied constants in the underspecified logical form l 0 with concepts from the target knowledge base. There are four constant match operations used in <ref type="figure" target="#fig_4">Figure 3</ref>. The first two constant matches, shown be- low, match underspecified constants with constants of the same type from Freebase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>in → location.containedby</head><p>Brandenburgh → BRANDENBURGH However, because we are modeling the semantics of phrases that are not covered by the Freebase schema, we also require the following two constant matches:</p><formula xml:id="formula_4">F ormer(x) → OpenType municipalities(x) → OpenRel(x, Municipality)</formula><p>Here, the word 'former' has been associated with a placeholder typing predicate since Freebase has no way of expressing end dates of administrative divisions. There is also no Freebase type repre- senting the concept 'municipalities.' However, this word is associated with an entity in Freebase. Since there is no suitable linking predicate for the entity Municipality, we introduce a placeholder link- ing predicate OpenRel in the step from l 2 → l 3 . Our constant match operators can also introduce placeholder entities OpenEntity when there is no good match in Freebase.   We also allow the creation of typing predicates from matched entities through the introduction of linking predicates. For example, there is no native type associated with the word 'actor' in Freebase. Instead we create a typing predicate by matching the word to a Freebase entity Actor using Free- base API and allowing the introduction of linked predicates such as person.profession :</p><note type="other">) CCG parse builds an underspecified semantic representation of the sentence.</note><formula xml:id="formula_5">N/N N N \N/N P N P λf λx.f (x) ∧ f ormer(x) λx.municipalities(x) λf λxλy.f (y) ∧ in(y, x) Brandenburg &gt; &gt; N N \N λx.f ormer(x) ∧ municipalities(x) λf λy.f (y) ∧ in(y, Brandenburg) &lt; N l0 = λx.f ormer(x) ∧ municipalities(x) ∧ in(x, Brandenburg)<label>(</label></formula><formula xml:id="formula_6">actor(x) → person.profession(x, Actor)</formula><p>Scoring Full Parses Our goal in this paper is to learn a function from the phrase x to the correct analysis y. We score each parse using a linear model with features that signal attributes of the underspecified parse φ p and those that signal at- tributes of the ontological match φ ont . Since the model factors over the two stages of parser, we split the prediction problem similarly. First, we select the maximum scoring underspecified logical form:</p><formula xml:id="formula_7">l * = arg max l∈CCG(x) (θ p · φ p (l))</formula><p>and then we select the highest scoring Freebase analysis y * that can be built from l * :</p><formula xml:id="formula_8">y * = arg max r∈ONT(l * ,K) (θ ont · φ ont (r))</formula><p>We describe an approach to learning the parameter vectors θ p and θ ont below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Learning</head><p>We introduce a learning approach that first collates aggregate statistics from the 7 million Wikipedia entity-category pairs and existing facts in FB, and then uses a small labeled training set to tune the weights for features that incorporate these statistics.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Broad Coverage Lexical Statistics Each</head><p>Wikipedia category is associated with a number of entities, most of which exist in FB. We use these entities to extract relations and attributes in FB associated with that category. For example, in <ref type="figure" target="#fig_5">Figure 4</ref> the category 'Wars involving the Grand Duchy of Lithuania' is associated with the relation military conflict.combatants and the attribute type(x, military.conflict) multiple times, because they are present in many of the category's entities. For each of the sub-phrases in the category name we count these associations over the entire Wikipedia category set. We use these counts to calculate Pointwise Mutual Information (PMI) between words and Freebase attributes or relations. We choose PMI to avoid overcompensating common words, attributes, or relations. For example, the word 'Wars' is seen with the incorrect analysis type(x, time.event) more frequently than the correct analysis type(x, military.conflict). However, PMI penalizes the attribute type(x, time.event) for its popularity and the correct analysis is preferred. As PMI has a tendency to emphasize rare counts, we chose PMI squared, which takes the squared value of the co-occurence count (P M I 2 (a, b) = log count(a∧b) <ref type="bibr">2</ref> count(a) * count(b) ), as a feature. Structural KB Statistics Existing semantic parsers typically make use of type constraints to limit the space of possible logical forms. These strong type constraints are not fea- sible when the knowledge base is incom- plete. For example, in Freebase the relation military conflict.combatants expects an en- tity of type military conflict.combatant as its object. However, many countries that have been involved in wars are not assigned this type.</p><p>We instead calculate type overlap statistics for all Freebase entities, to find likely missing types. For example, including the fact that the object of military conflict.combatants is very often of type location.country.</p><p>Learning from Labeled Data We train each half of the prediction problem separately, as de- fined in Section 4, using the labeled training data introduced in Section 3. We use structured max- margin perceptrons to learn feature weights for both the underspecified parse and the ontological match step following ( <ref type="bibr" target="#b12">Kwiatkowski et al., 2013</ref>). The aggregate statistics collected from 7 million category-entity pairs produce very useful lexical features. We integrate these statistics into our linear model by summing their values for each derivation and treating them as a feature. All of the other fea- tures described in Section 6 are not word specific and are therefore far less sparse.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Features</head><p>We include a number of features that enable soft type checking on the output logical form, described first below, along with other features that measure different aspects of the analysis.</p><p>Coherency features For example, con- sider the phrase "The UK home city of the Queen," with Freebase logical form y = λx.home(QEII, x) ∧ in(x, UK) ∧ city(x). Each of the relations has expected types for their argument: the relation home expects a subject of type person and an object of type location. Each type in Freebase lives in a hierarchy, so the type city implies {location, administrative division, . . . }.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The next four features test agreement of these types on different parts of the output logical form.</head><p>Relation arguments trigger a feature if their type is in the set of types expected by the relation. QEII is a person so this feature is triggered for the relation-argument application in home <ref type="bibr">(QEII, x)</ref>.</p><p>Relation-relation pairs can share variable argu- ments. For example, the variable x is the object of home and the subject of in. Each relation expects a set of types of x. We have features to signal if: these sets are disjoint; one set subsumes the other; and the PMI between the highest level expected type (described in Section 5) if the sets are disjoint. In the example given here, the type location expected by in subsumes the type city expected by home so the second feature fires. We treat types such as city(x) as unary relations and include them in this feature set.</p><p>Type domain measures compatibility among do- mains in Freebase. Freebase is split into high-level domains and some of these are relevant, such as 'football' and 'sports'. We identify those by count- ing their co-occurrences. This becomes an indica- tor feature that signals their co-occurrence in y.</p><p>Named entity type features test if the entity e that we are extracting attributes for have Freebase type "person", "location" or "organization". If it does, we have a feature indicating if y defines a set of the same type. This features is not used in the referring expression task presented in Section 7 since we cannot assume access to the entities that are described.</p><p>CCG parse feature signals which lexical items were used in the CCG parse. Another feature fires if capitalized words map to named entities.</p><p>String similarity features signal exact string match, stemmed string match, and length weighted string edit distance between a phrase in the sen- tence and the name of the Freebase element it was matched on. We also use the Freebase search API to generate scores for phrase, entity pairs and in- clude the log of this score as a features.</p><p>Lexical PMI feature includes the lexical Point- wise Mutual Information described in Section 5.</p><p>Freebase constant features signal the use of linking predicates, as defined in Section 4, and the log frequency count of the Freebase attributes across all entities in the Wikipedia category set.</p><p>Other features indicate the use of OpenRel, OpenEntity, OpenType in y and count repetitions of Freebase concepts in y.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Experimental Setup</head><p>Knowledge base We use the Jan. 26, 2014 Free- base dump. After pruning binary predicates taking numeric values, it contains 9351 binary predicates, 2754 unary predicates, and 1.2 billion assertions.</p><p>Pruning and Feature Initialization We per- form beam search at each semantic parsing stage, using the Freebase search API to determine candi- date named entities (10 per phrase), binary predi- cates (300 per phrase), and unary predicates (500 per phrase). The ontology matching stage consid- ers the highest scored underspecified parse.</p><p>The features are initialized to prefer well-typed logical forms. Type checking features are initially set to -2 for mismatch. Features signalling incom- patible topic domains and repetition are initialized as -10. All other initial feature weights are set to 1.</p><p>Datasets and Annotation We evaluate on the Wikipedia category and appositive datasets intro- duced in Sec. 3. On the Wikipedia development data, we annotated 500 logical forms, underspeci- fied logical forms and constant mappings for ontol- ogy matching. The Wikipedia test data is composed of 500 unseen categories. We did not train on the appositive dataset, as it contains challenges such as co-reference and parsing errors as described in Sec. 3. Instead, we chose 300 randomly selected ex- amples for evaluation, and ran on the model trained on the Wikipedia development data.</p><p>Evaluation Metrics We report five-fold cross validation for development but ran the final model once on the test data, manually scoring the output.</p><p>For evaluation on the referring expression resolu- tion performance (as defined in Sec. 2), we include accuracy for the final logical form (Exact Match). We also evaluate precision and recall for predicting individual literals in this logical form on the devel- opment set. To control for missing facts, we did not evaluate the set of returned entities.</p><p>To evaluate entity attribute extraction perfor- mance (as defined in Sec. 2), we identified three classes of predictions. Extractions can be correct, benign, or false. Correct attributes are actually described in the phrase, benign extraction may not have been described but are still true, and false extractions are not true. For example, if   the phrase "the capital of the communist-ruled nation" is mapped to the pair of attributes capital of administrative division(x) , location(x), the first is correct and the second is benign. Other incorrect facts would be false.</p><p>On the development set, we report precision and recall against the union of the FB attributes in our annotations without adjusting for benign extrac- tions or the fact that the annotations are not com- plete. For the test sets, we computed precision (P) where benign extractions are considered to be wrong, as well as an adjusted precision metric (P*) where benign extractions are counted as correct. As we do not have full test set annotations, we cannot report recall. Finally, we report the average number of facts extracted per noun phrase (fact #).</p><p>Comparison Systems We compare performance to a number of ablated versions of the full system, where we have removed the open-constant ontology matching operators (NoOpenSchema), the PMI fea- tures (NoPMI), or the type checking features (No- Typing). For the referring expression resolution task, we excluded the named entity type feature, as this assumes typing information about the entity we are extracting attributes for.</p><p>We report results without the PMI features and the open schema matching operators (KCAZ13), which is a reimplementation of a recent Freebase QA model ( <ref type="bibr" target="#b12">Kwiatkowski et al., 2013</ref>). We also learn with gold named entity linking (Gold NE).</p><p>For the entity attribute extraction, we built a su- pervised learning baseline that combines the output of two discrete SVMs, one for predicting unary re- lations and one for binary relations. Each classifier   is trained using the annotated Wikipedia categories. This dataset contains hundreds of unary and bi- nary relations, which the IE baseline can predict. Each classifier is further anchored on a specific word, and includes n-gram and POS context fea- tures around that word, following features from Mintz et al <ref type="bibr">(2009)</ref>. To predict binary relations, we used named entities as anchors. For unary attributes we anchored on all possible nouns and adjectives. The final logical form includes the best relation predicted by each classifier. We use the Stanford CoreNLP 5 toolkit for tokenization, named entity recognition, and part-of-speech tagging. <ref type="table" target="#tab_3">Tables 3 and 4</ref> show performance on the referring expression resolution task. <ref type="table" target="#tab_6">Tables 5 and 6</ref> show performance on the extraction task. Reported pre- cision is lower on the labeled development set than on the test set, where predicted logical forms are manually evaluated. This reflects the fact that, de- spite our best attempts, the development set labels are incomplete, as discussed in Section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Results</head><p>Referring expression resolution The systems retrieve the full meaning with 28.4% accuracy on the Wikipedia test set, and 15.9% on the develop- ment set. The gold named entity input improves performance by modest amounts. This suggests that the errors stem from ontology mismatches, as we will describe in more detail later in the qualita- tive analysis. We also see that all of the ablations hurt performance, and that the KCAZ13 model per- forms extremely poorly. The independent classifier baseline performs well at the sub-clause level, but fails to form a full logical form of the referring expression. Partial grounding and broad-coverage data statistics are essential for this problem.</p><p>Entity attribute extraction In the two test sets, the approach achieves high benign precision lev- els (P*) of 72.6 and 61.4. However, the apposi- tives data is significantly more challenging, and the model misses many of the true facts that could be extracted. Many errors comes in the early stages of the pipeline, which can be attributed at least in part to both (1) the higher levels of noise in the input data (see Section 3), and (2) the fact that the CCG parser was developed on the Wikipedia category la- bels. While the IE baseline performs reasonably on the Wikipedia test data, its performance degrades significantly on appositions. As it is trained to pre- dict pre-determined relations, it does not generalize to different domains. For the development set, <ref type="table" target="#tab_6">Table 5</ref> also shows the precision-recall trade off for the set of Freebase attributes that appear in the top-n predicted logical forms. Precision drops quickly but recall can be improved significantly, showing that the model can produce many of the labeled facts.</p><p>Qualitative evaluation We sampled 100 errors from the Wikipedia test set for qualitative analy- sis. 10% came from entity linking. About 30% come from choosing a superset or subset of the desired meaning, for example by mapping "novel" to book. About 10% of the errors are from do- main ambiguity, such as mapping "stage actor" to film.film actor. 10% of the cases are from spu- rious string similarity, such as mapping "Hungarian expatriates" to nationality(x, Hungary). 15% of the failures were due to incorrect underspecified logical forms and, finally, about 10% of the errors were because the typing features encouraged com- pound nouns to be split into separate attributes. On the apposition dataset, 65% of errors stems from parsing, either in apposition detection or CCG pars- ing. Better modeling the complex attachment deci- sions for the noun phrases in the apposition dataset remains an area for future work.</p><p>One advantage of our approach, especially in comparison to classifier based models like the IE baseline, is the ability to predict previously unseen relations. Counting only the correctly predicted triples, we see that over 40% of the unique rela- tions we predict is not in the development set; our model learns to generalize based on the learned PMI features and other lexical cues.</p><p>Finally, our approach extracted 2.0 entity at- tributes per Wikipedia phrase and 0.9 per appo- sition on average. This matches our intuition that the apposition dataset contains many more words that cannot be modeled with concepts in Freebase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Related Work</head><p>Recent work has begun to study the problem of knowledge base incompleteness and reasoning with open concepts. <ref type="bibr" target="#b8">Joshi et al. (2014)</ref> describes an approach for mapping short search queries to a single Freebase relation, that benefits from model- ing schema incompleteness. Additionally, <ref type="bibr" target="#b9">Krishnamurthy et al. (2012;</ref>) present a semantic parser that builds partial meaning representations with Freebase for information extraction applica- tions. This is similar in spirit to the approach we present here, however they focus on a small, fixed, set of binary relations while we aim to represent as much of the text as possible using the entire Free- base ontology. <ref type="bibr" target="#b11">Krishnamurthy and Mitchell (2015)</ref> have also studied semantic parsing with open con- cepts via matrix factorization. They use Freebase entities but do not include Freebase concepts.</p><p>The problem of building complete sentence anal- yses using all of the Freebase ontology has re- cently received attention within the context of ques- tion answering systems <ref type="bibr" target="#b3">(Cai and Yates, 2013;</ref><ref type="bibr" target="#b12">Kwiatkowski et al., 2013;</ref><ref type="bibr" target="#b1">Berant et al., 2013;</ref><ref type="bibr" target="#b0">Berant and Liang, 2014;</ref><ref type="bibr" target="#b15">Reddy et al., 2014</ref>). Since they do not model KB incompleteness, these mod- els will not work well on data that cannot be fully modeled by Freebase. In section 7, we report re- sults using one of these systems to provide a refer- ence point for our approach. There has also been other work on Freebase question answering <ref type="bibr" target="#b22">(Yao and Van Durme, 2014;</ref><ref type="bibr" target="#b2">Bordes et al., 2014;</ref><ref type="bibr" target="#b19">Wang et al., 2014</ref>) that directly searches the facts in the KB to find answers without explicitly modeling compositional semantic structure. Therefore, these methods will suffer when facts are missing.</p><p>The syntactic and semantic structure of noun phrases has been extensively studied. For example, work on NomBank ( <ref type="bibr" target="#b13">Meyers et al., 2004;</ref><ref type="bibr" target="#b6">Gerber and Chai, 2010</ref>) focus on the challenge of modeling implicit arguments introduced by nominal predi- cates. In a manual study, we discovered that the 65% of our noun phrases contain implicit relations. We build on insights from <ref type="bibr" target="#b18">Vadas and Curran (2008)</ref>, who studied how to model the syntactic structure of noun phrases in CCGBank. While we are, to the best of our knowledge, the first to study compound noun phrases for semantic parsing to knowledge- bases, semantic parsers for noun phrase referring expressions have been built for visual <ref type="bibr">referring expression (FitzGerald et al., 2013)</ref>.</p><p>There has been little work on IE from compound noun phrases. Most existing IE algorithms extract a single relation, usually represented as a verb that holds between a pair of named entities, for exam- ple with supervised learning techniques <ref type="bibr" target="#b5">(Freitag, 1998)</ref> or via distant supervision ( <ref type="bibr" target="#b14">Mintz et al., 2009;</ref><ref type="bibr" target="#b16">Riedel et al., 2013;</ref><ref type="bibr" target="#b7">Hoffmann et al., 2011</ref>). We aim to go beyond relations between entity pairs, and to retrieve full semantics of noun phrases, extracting unary and binary relations for a single entity. A notable exception to this trend is the ReNoun sys- tem ( <ref type="bibr" target="#b21">Yahya et al., 2014</ref>) which models noun phrase structure for open information extraction. They report that 97% of the attributes in Freebase are commonly expressed as noun phrases. However, unlike our work, they considered open information extraction and did not ground the extractions in an external KB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">Conclusion</head><p>In this paper, we present a semantic parsing ap- proach with knowledge base incompleteness, ap- plied to the problem of information extraction from noun phrases. When run on all of the Wikipedia category data, the approach would extract up to 12 million new Freebase facts at 72% precision.</p><p>There is significant potential for improving the parsing models, as well as better optimizing the precision recall trade-off for the extracted facts. It would also be interesting to gather data with com- positional phenomena, such as negation and dis- junction, and study its impact on the performance of the semantic parser.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Derivation of the analysis for "Former municipalities in Brandenburgh". This analysis contains a placeholder type and a placeholder relation as described in Section 4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Labeled entities are associated with attributes and relations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Referring expression resolution perfor-
mance on the development set on gold references. 

Data 
System 
Exact Match Accuracy 

Wikipedia 
IE Baseline 
21.8% 
Our Approach 
28.4% 

Appos 
IE Baseline 
0.0% 
Our Approach 
4.7% 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Manual evaluation for referring expression 
resolution on the test sets. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Entity attribute extraction performance on 
the Wikipedia category development set. 

Data 
System 
P 
P* 
fact # 

Wikipedia 
IE Baseline 
56.7 58.7 
1.6 
Our Approach 61.2 72.6 
2.0 

Appos 
IE Baseline 
4.9 
13.9 
1.3 
Our Approach 33.2 61.4 
0.9 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Manual evaluation for entity attribute ex-
traction on the test sets. 

</table></figure>

			<note place="foot" n="3"> Compiled by the YAGO project, available at: www.mpiinf.mpg.de/departments/databases-and-informationsystems/research/yago-naga/yago/downloads/ 4 http://www.nist.gov/tac/2009/</note>

			<note place="foot" n="5"> http://nlp.stanford.edu/software/corenlp.html</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The research was supported in part by DARPA, un-der the DEFT program through the AFRL (FA8750-13-2-0019) and the CSSG (N11AP20020), as well as the NSF (IIS-1115966, IIS-1252835) and a gift from Google, Inc. The authors thank Xiao Ling for providing the apposition data, and Yoav Artzi, Nicholas FitzGerald, Mike Lewis, Sameer Singh and Mark Yatskar for discussion and comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Semantic parsing via paraphrasing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Semantic parsing on freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Empirical Methods in Natural Language Processing</title>
		<meeting>the Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Question answering with subgraph embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Large-scale semantic parsing via schema matching and lexicon extension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingqing</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandar</forename><surname>Yates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning distributions over logical forms for referring expression generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Toward general-purpose learning for information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dayne</forename><surname>Freitag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 36th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Beyond nombank: a study of implicit arguments for nominal predicates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Gerber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joyce Y</forename><surname>Chai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Knowledgebased weak supervision for information extraction of overlapping relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Congle</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the Association of Computational Linguistics</title>
		<meeting>the Conference of the Association of Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Knowledge graph and corpus driven segmentation and answer inference for telegraphic entityseeking queries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uma</forename><surname>Sawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumen</forename><surname>Chakrabarti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Weakly supervised training of semantic parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jayant</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Joint syntactic and semantic parsing with combinatory categorial grammar</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jayant</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><forename type="middle">M</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Learning a compositional semantics for freebase with an opne predicate vocabulary. Transactions of the Association for Computational Linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jayant</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Mitchell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Scaling semantic parsers with on-the-fly ontology matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Annotating noun argument structure for nombank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Meyers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruth</forename><surname>Reeves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catherine</forename><surname>Macleod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachel</forename><surname>Szekely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veronika</forename><surname>Zielinska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction without labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Mintz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bills</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rion</forename><surname>Snow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the Joint Conference of the Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Large-scale semantic parsing without questionanswer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siva</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Relation extraction with matrix factorization and universal schemas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><forename type="middle">M</forename><surname>Marlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint Human Language Technology Conference/Annual Meeting of the North American Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Surface Structure and Interpretation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Parsing noun phrase structure with ccg</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Vadas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">R</forename><surname>Curran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">An overview of microsoft deep qa system on stanford webquestions benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenghao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengquan</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaming</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuedong</forename><surname>Huang</surname></persName>
		</author>
		<idno>MSR-TR-2014-121</idno>
		<imprint>
			<date type="published" when="2014-09" />
		</imprint>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Knowledge base completion via search-based question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaohua</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of World Wide Web Conference</title>
		<meeting>World Wide Web Conference</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Renoun: Fact extraction for nominal attributes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Yahya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">Euijong</forename><surname>Whang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Halevy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Information extraction over structured data: Question answering with freebase</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuchen</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
