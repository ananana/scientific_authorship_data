<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:31+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Simple Negation Scope Resolution through Deep Parsing: A Semantic Solution to a Semantic Problem</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>June 23-25 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Woodley</forename><surname>Packard</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Linguistics</orgName>
								<orgName type="department" key="dep2">School of Computing</orgName>
								<orgName type="department" key="dep3">Department of Informatics</orgName>
								<orgName type="department" key="dep4">Department of Linguistics</orgName>
								<orgName type="institution" key="instit1">University of Washington</orgName>
								<orgName type="institution" key="instit2">Teesside University</orgName>
								<orgName type="institution" key="instit3">University of Oslo</orgName>
								<orgName type="institution" key="instit4">Potsdam University</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><forename type="middle">M</forename><surname>Bender</surname></persName>
							<email>ebender@uw.edu, sweaglesw@sweaglesw.org, j.read@tees.ac.uk, { oe | rdridan }@ifi.uio.no</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Linguistics</orgName>
								<orgName type="department" key="dep2">School of Computing</orgName>
								<orgName type="department" key="dep3">Department of Informatics</orgName>
								<orgName type="department" key="dep4">Department of Linguistics</orgName>
								<orgName type="institution" key="instit1">University of Washington</orgName>
								<orgName type="institution" key="instit2">Teesside University</orgName>
								<orgName type="institution" key="instit3">University of Oslo</orgName>
								<orgName type="institution" key="instit4">Potsdam University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Read</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Linguistics</orgName>
								<orgName type="department" key="dep2">School of Computing</orgName>
								<orgName type="department" key="dep3">Department of Informatics</orgName>
								<orgName type="department" key="dep4">Department of Linguistics</orgName>
								<orgName type="institution" key="instit1">University of Washington</orgName>
								<orgName type="institution" key="instit2">Teesside University</orgName>
								<orgName type="institution" key="instit3">University of Oslo</orgName>
								<orgName type="institution" key="instit4">Potsdam University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Oepen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Linguistics</orgName>
								<orgName type="department" key="dep2">School of Computing</orgName>
								<orgName type="department" key="dep3">Department of Informatics</orgName>
								<orgName type="department" key="dep4">Department of Linguistics</orgName>
								<orgName type="institution" key="instit1">University of Washington</orgName>
								<orgName type="institution" key="instit2">Teesside University</orgName>
								<orgName type="institution" key="instit3">University of Oslo</orgName>
								<orgName type="institution" key="instit4">Potsdam University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">♥</forename><forename type="middle">♦</forename></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Linguistics</orgName>
								<orgName type="department" key="dep2">School of Computing</orgName>
								<orgName type="department" key="dep3">Department of Informatics</orgName>
								<orgName type="department" key="dep4">Department of Linguistics</orgName>
								<orgName type="institution" key="instit1">University of Washington</orgName>
								<orgName type="institution" key="instit2">Teesside University</orgName>
								<orgName type="institution" key="instit3">University of Oslo</orgName>
								<orgName type="institution" key="instit4">Potsdam University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Dridan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Linguistics</orgName>
								<orgName type="department" key="dep2">School of Computing</orgName>
								<orgName type="department" key="dep3">Department of Informatics</orgName>
								<orgName type="department" key="dep4">Department of Linguistics</orgName>
								<orgName type="institution" key="instit1">University of Washington</orgName>
								<orgName type="institution" key="instit2">Teesside University</orgName>
								<orgName type="institution" key="instit3">University of Oslo</orgName>
								<orgName type="institution" key="instit4">Potsdam University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Simple Negation Scope Resolution through Deep Parsing: A Semantic Solution to a Semantic Problem</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="69" to="78"/>
							<date type="published">June 23-25 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In this work, we revisit Shared Task 1 from the 2012 *SEM Conference: the automated analysis of negation. Unlike the vast majority of participating systems in 2012, our approach works over explicit and formal representations of proposi-tional semantics, i.e. derives the notion of negation scope assumed in this task from the structure of logical-form meaning representations. We relate the task-specific interpretation of (negation) scope to the concept of (quantifier and operator) scope in mainstream underspecified semantics. With reference to an explicit encoding of semantic predicate-argument structure, we can operationalize the annotation decisions made for the 2012 *SEM task, and demonstrate how a comparatively simple system for negation scope resolution can be built from an off-the-shelf deep parsing system. In a system combination setting, our approach improves over the best published results on this task to date.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recently, there has been increased community in- terest in the theoretical and practical analysis of what Morante and Sporleder (2012) call modality and negation, i.e. linguistic expressions that mod- ulate the certainty or factuality of propositions. Automated analysis of such aspects of meaning is important for natural language processing tasks which need to consider the truth value of state- ments, such as for example text mining ( <ref type="bibr" target="#b15">Vincze et al., 2008</ref>) or sentiment analysis ( <ref type="bibr" target="#b8">Lapponi et al., 2012</ref>). Owing to its immediate utility in the cura- tion of scholarly results, the analysis of negation and so-called hedges in bio-medical research liter- ature has been the focus of several workshops, as well as the Shared Task at the 2011 Conference on Computational Language Learning (CoNLL). Task 1 at the First Joint Conference on <ref type="bibr">Lexical and Computational Semantics (*SEM 2012;</ref><ref type="bibr" target="#b9">Morante and Blanco, 2012</ref>) provided a fresh, prin- cipled annotation of negation and called for sys- tems to analyze negation-detecting cues (affixes, words, or phrases that express negation), resolv- ing their scopes (which parts of a sentence are ac- tually negated), and identifying the negated event or property. The task organizers designed and documented an annotation scheme <ref type="bibr" target="#b10">(Morante and Daelemans, 2012)</ref> and applied it to a little more than 100,000 tokens of running text by the nov- elist Sir Arthur Conan Doyle. While the task and annotations were framed from a semantic perspec- tive, only one participating system actually em- ployed explicit compositional semantics ( <ref type="bibr" target="#b1">Basile et al., 2012)</ref>, with results ranking in the middle of the 12 participating systems. Conversely, the best- performing systems approached the task through machine learning or heuristic processing over syn- tactic and linguistically relatively coarse-grained representations; see § 2 below.</p><p>Example (1), where marks the cue and {} the in-scope elements, illustrates the annotations, including how negation inside a noun phrase can scope over discontinuous parts of the sentence. <ref type="bibr">1</ref> (1) {The German} was sent for but professed to {know} nothing {of the matter}.</p><p>In this work, we return to the 2012 *SEM task from a deliberately semantics-centered point of view, focusing on the hardest of the three sub-problems: scope resolution. <ref type="bibr">2</ref> Where Morante and <ref type="bibr" target="#b10">Daelemans (2012)</ref> characterize negation as an "extra-propositional aspect of meaning" (p. 1563), <ref type="bibr">1</ref> Our running example is a truncated variant of an item from the Shared Task training data. The remainder of the original sentence does not form part of the scope of this cue. <ref type="bibr">2</ref> Resolving negation scope is a more difficult sub-problem at least in part because (unlike cue and event identification) it is concerned with much larger, non-local and often discontin- uous parts of each utterance. This intuition is confirmed by <ref type="bibr" target="#b14">Read et al. (2012)</ref>, who report results for each sub-problem using gold-standard inputs; in this setup, scope resolution showed by far the lowest performance levels.</p><p>we in fact see it as a core piece of composi- tionally constructed logical-form representations. Though the task-specific concept of scope of negation is not the same as the notion of quan- tifier and operator scope in mainstream under- specified semantics, we nonetheless find that re- viewing the 2012 *SEM Shared Task annotations with reference to an explicit encoding of seman- tic predicate-argument structure suggests a sim- ple and straightforward operationalization of their concept of negation scope. Our system imple- ments these findings through a notion of functor- argument 'crawling', using as our starting point the underspecified logical-form meaning represen- tations provided by a general-purpose deep parser.</p><p>Our contributions are three-fold: Theoretically, we correlate the structures at play in the Morante and Daelemans (2012) view on negation with formal semantic analyses; methodologically, we demonstrate how to approach the task in terms of underspecified, logical-form semantics; and prac- tically, our combined system retroactively 'wins' the 2012 *SEM Shared Task. In the following sections, we review related work ( § 2), detail our own setup ( § 3), and present and discuss our ex- perimental results ( § 4 and § 5, respectively).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Read et al. (2012) describe the best-performing submission to Task 1 of the 2012 *SEM Confer- ence. They investigated two approaches for scope resolution, both of which were based on syntac- tic constituents. Firstly, they created a set of 11 heuristics that describe the path from the preter- minal of a cue to the constituent whose projec- tion is predicted to match the scope. Secondly they trained an SVM ranker over candidate con- stituents, generated by following the path from a cue to the root of the tree and describing each candidate in terms of syntactic properties along the path and various surface features. Both ap- proaches attempted to handle discontinuous in- stances by applying two heuristics to the predicted scope: (a) removing preceding conjuncts from the scope when the cue is in a conjoined phrase and (b) removing sentential adverbs from the scope. The ranking approach showed a modest advan- tage over the heuristics (with F 1 equal to 77.9 and 76.7, respectively, when resolving the scope of gold-standard cues in evaluation data).  noted however that the annotated scopes did not align with the Shared Task-provided con- stituents for 14% of the instances in the training data, giving an F 1 upper-bound of around 86.0 for systems that depend on those constituents. <ref type="bibr" target="#b1">Basile et al. (2012)</ref> present the only submission to Task 1 of the 2012 *SEM Conference which employed compositional semantics. Their scope resolution pipeline consisted primarily of the C&amp;C parser and Boxer ( <ref type="bibr" target="#b4">Curran et al., 2007)</ref>, which pro- duce Discourse Representation Structures (DRSs). The DRSs represent negation explicitly, including representing other predications as being within the scope of negation. <ref type="bibr" target="#b1">Basile et al. (2012)</ref> describe some amount of tailoring of the Boxer lexicon to include more of the Shared Task scope cues among those that produce the negation operator in the DRSs, but otherwise the system appears to directly take the notion of scope of negation from the DRS and project it out to the string, with one caveat: As with the logical-forms representations we use, the DRS logical forms do not include function words as predicates in the semantics. Since the Shared Task gold standard annotations included such ar- guably semantically vacuous (see <ref type="bibr">Bender, 2013, p. 107)</ref> words in the scope, further heuristics are needed to repair the string-based annotations com- ing from the DRS-based system. Basile et al. re- sort to counting any words between in-scope to- kens which are not themselves cues as in-scope. This simple heuristic raises their F 1 for full scopes from 20.1 to 53.3 on system-predicted cues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">System Description</head><p>The new system described here is what we call the MRS Crawler. This system operates over the normalized semantic representations provided by the LinGO English Resource Grammar (ERG; <ref type="bibr" target="#b5">Flickinger, 2000</ref>). <ref type="bibr">3</ref> The ERG maps surface strings to meaning representations in the format of Mini- mal Recursion Semantics (MRS; <ref type="bibr" target="#b3">Copestake et al., 2005</ref>). MRS makes explicit predicate-argument relations, as well as partial information about scope (see below). We used the grammar together with one of its pre-packaged conditional Maxi- mum Entropy models for parse ranking, trained on a combination of encyclopedia articles and tourism brochures. Thus, the deep parsing front- end system to our MRS Crawler has not been h1, h4:_the_q0 : 3(ARG0 x6, RSTR h7, BODY h5 ), h8:_german_n_14 : 10(ARG0 x6 ), h9:_send_v_for15 : 19(ARG0 e10, ARG1 , ARG2 x6 ), h2:_but_c24 : 27(ARG0 e3, L-HNDL h9, R-HNDL h14 ), h14:_profess_v_to28 : 37(ARG0 e13, ARG1 x6, ARG2 h15 ), h16:_know_v_141 : 45(ARG0 e17, ARG1 x6, ARG2 x18 ), h20:_no_q46 : 53(ARG0 x18, RSTR h21, BODY h22 ), h19:thing46 : 53(ARG0 x18 ), h19:_of_p54 : 56(ARG0 e23, ARG1 x18, ARG2 x24 ), h25:_the_q57 : 60(ARG0 x24, RSTR h27, BODY h26 ), h28:_matter_n_of61 : 68(ARG0 x24, ARG1 ) { h27 =q h28, h21 =q h19, h15 =q h16, h7 =q h8, h1 =q h2 } <ref type="figure">Figure 1</ref>: MRS analysis of our running example (1). adapted to the task or its text type; it is applied in an 'off the shelf' setting. We combine our system with the outputs from the best-performing 2012 submission, the system of <ref type="bibr" target="#b14">Read et al. (2012)</ref>, firstly by relying on the latter for system negation cue detection, <ref type="bibr">4</ref> and secondly as a fall-back in sys- tem combination as described in § 3.4 below.</p><p>Scopal information in MRS analyses delivered by the ERG fixes the scope of operators-such as negation, modals, scopal adverbs (including sub- ordinating conjunctions like while), and clause- embedding verbs (e.g. believe)-based on their position in the constituent structure, while leaving the scope of quantifiers (e.g. a or every, but also other determiners) free. From these underspec- ified representations of possible scopal configu- rations, a scope resolution component can spell out the full range of fully-connected logical forms <ref type="bibr" target="#b7">(Koller and Thater, 2005</ref>), but it turns out that such enumeration is not relevant here: the notion of scope encoded in the Shared Task annotations is not concerned with the relative scope of quantifiers and negation, such as the two possible readings of (2) represented informally below: <ref type="bibr">5</ref> (2) Everyone didn't leave.</p><p>a. ∀(x)¬leave(x) ∼ Everyone stayed.</p><p>b. ¬∀(x)leave(x) ∼ At least some stayed.</p><p>However, as shown below, the information about fixed scopal elements in an underspecified MRS is sufficient to model the Shared Task annotations. <ref type="figure">Fig. 1</ref> shows the ERG semantic analysis for our running example. The heart of the MRS is a mul- tiset of elementary predications (EPs). Each ele-mentary prediction includes a predicate symbol, a label (or 'handle', prefixed to predicates with a colon in <ref type="figure">Fig. 1)</ref>, and one or more argument positions, whose values are semantic variables. Eventualities (e i ) in MRS denote states or activ- ities, while instance variables (x j ) typically corre- spond to (referential or abstract) entities. All EPs have the argument position ARG0, called the dis- tinguished variable <ref type="bibr" target="#b13">(Oepen and Lønning, 2006</ref>), and no variable is the ARG0 of more than one non- quantifier EP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">MRS Crawling</head><p>The arguments of one EP are linked to the argu- ments of others either directly (sharing the same variable as their value), or indirectly (through so- called 'handle constraints', where = q in <ref type="figure">Fig. 1</ref> de- notes equality modulo quantifier insertion). Thus a well-formed MRS forms a connected graph. In addition, the grammar links the EPs to the ele- ments of the surface string that give rise to them, via character offsets recorded in each EP (shown in angle brackets in <ref type="figure">Fig. 1</ref>). For the purposes of the present task, we take a negation cue as our en- try point into the MRS graph (as our initial active EP), and then move through the graph according to the following simple operations to add EPs to the active set:</p><p>Argument Crawling Add to the scope all EPs whose distinguished variable or label is an argu- ment of the active EP; for arguments of type h k , treat any = q constraints as label equality.</p><p>Label Crawling Add all EPs whose label is iden- tical to that of the active EP.</p><p>Functor Crawling Add all EPs that take the dis- tinguished variable or label of the active EP as an argument (directly or via = q constraints).</p><p>Our MRS crawling algorithm is sketched in <ref type="figure">Fig. 2</ref>. To illustrate how the rules work, we will trace their operation in the analysis of example <ref type="formula">(1)</ref>, i.e. traverse the EP graph in <ref type="figure">Fig. 1</ref>.</p><p>The negation cue is nothing, from character po- sition 46 to 53. This leads us to _no_q as our en- try point into the graph. Our algorithm states that for this type of cue (a quantifier) the first step is 1: Activate the cue EP 2: if the cue EP is a quantifier then 3:</p><p>Activate EPs reached by functor crawling from the distinguished variable (ARG0) of the cue EP 4: end if 5: repeat 6:</p><p>for each active EP X do 7:</p><p>Activate EPs reached by argument crawling or label crawling unless they are co-modifiers of the negation cue. a 8:</p><p>Activate EPs reached by functor crawling if they are modal verbs, or one of the following subordinating conjunctions reached by ARG1: whether, when, because, to, with, although, unless, until, or as.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>9:</head><p>end for 10: until a fixpoint is reached (no additional EPs were activated) 11: Deactivate zero-pronoun EPs (from imperative constructions) 12: Apply semantically empty word handling rules (iterate until a fixpoint is reached) 13: Apply punctuation heuristics <ref type="figure">Figure 2</ref>: Algorithm for scope detection by MRS crawling a Formally: If an EP shares its label with the negation cue, or is a quantifier whose restriction (RSTR) is =q equated with the label of the negation cue, it cannot be in-scope unless its ARG0 is an argument of the negation cue, or the ARG0 of the negation cue is one of its own arguments. See § 3.3 for elaboration.</p><p>functor crawling (see § 3.3 below), which brings _know_v_1 into the scope. We proceed with ar- gument crawling and label crawling, which pick up _the_q0 : 3 and _german_n_1 as the ARG1. Further, as the ARG2 of _know_v_1, we reach thing and through recursive invocation we acti- vate _of_p and, in yet another level of recursion, _the_q57 : 60 and _matter_n_of. At this point, crawling has no more links to follow. Thus, the MRS crawling operations 'paint' a subset of the MRS graph as in-scope for a given negation cue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Semantically Empty Word Handling</head><p>Our crawling rules operate on semantic represen- tations, but the annotations are with reference to the surface string. Accordingly, we need projec- tion rules to map from the 'painted' MRS to the string. We can use the character offsets recorded in each EP to project the scope to the string. How- ever, the string-based annotations also include words which the ERG treats as semantically vacu- ous. Thus in order to match the gold annotations, we define a set of heuristics for when to count vac- uous words as in scope. In (1), there are no se- mantically empty words in-scope, so we illustrate these heuristics with another example: (3) "I trust that {there is} nothing {of consequence which I have overlooked}?"</p><p>The MRS crawling operations discussed above paint the EPs corresponding to is, thing, of, conse- quence, I, and overlooked as in-scope (underlined in <ref type="formula">(3)</ref>). Conversely, the ERG treats the words that, there, which, and have as semantically empty. Of these, we need to add all except that to the scope.</p><p>Our vacuous word handling rules use the syntac- tic structure provided by the ERG as scaffolding to help link the scope information gleaned from con- tentful words to vacuous words. Each node in the syntax tree is initially colored either in-scope or out-of-scope in agreement with the decision made by the crawler about the lexical head of the corre- sponding subtree. A semantically empty word is determined to be in-scope if there is an in-scope syntax tree node in the right position relative to it, as governed by a short list of templates organized by the type of the semantically empty word (par- ticles, complementizers, non-referential pronouns, relative pronouns, and auxiliary verbs).</p><p>As an example, the rule for auxiliary verbs like have in our example (3) is that they are in scope when their verb phrase complement is in scope. Since overlooked is marked as in-scope by the crawler, the semantically empty have becomes in- scope as well. Sometimes the rules need to be iterated. For example, the main rule for relative pronouns is that they are in-scope when they fill a gap in an in-scope constituent; which fills a gap in the constituent have overlooked, but since have is the (syntactic) lexical head of that constituent, the verb phrase is not considered in-scope the first time the rules are tried.</p><p>Similar rules deal with that (complementizers are in-scope when the complement phrase is an ar- gument of an in-scope verb, which is not the case here) and there (non-referential pronouns are in- scope when they are the subject of an in-scope VP, which is true here).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Re-Reading the Annotation Guidelines</head><p>Our MRS crawling algorithm was defined by look- ing at the annotated data rather than the annota- tion guidelines for the Shared Task <ref type="bibr" target="#b11">(Morante et al., 2011</ref>). Nonetheless, our algorithm can be seen as a first pass formalization of the guidelines. In this section, we briefly sketch how our algorithm cor- responds to different aspects of the guidelines.</p><p>For negated verbs, the guidelines state that "If the negated verb is the main verb in the sen- tence, the entire sentence is in scope." <ref type="bibr">(Morante et al., 2011, 17)</ref>. In terms of our operations de- fined over semantic representations, this is ren- dered as follows: all arguments of the negated verb are selected by argument crawling, all in- tersective modifiers by label crawling, and func- tor crawling <ref type="figure">(Fig. 2, line 8</ref>) captures modal auxil- iaries and non-intersective modifiers. The guide- lines treat predicative adjectives under a separate heading from verbs, but describe the same desired annotations (scope over the whole clause; ibid., p. 20). Since these structures are analogous in the semantic representations, the same operations that handle negated verbs also handle negated predica- tive adjectives correctly.</p><p>For negated subjects and objects, the guidelines state that the negation scopes over "all the clause" and "the clause headed by the verb" <ref type="bibr">(Morante et al., 2011, 19)</ref>, respectively. The examples given in the annotation guidelines suggest that these are in fact meant to refer to the same thing. The negation cue for a negated nominal argument will appear as a quantifier EP in the MRS, triggering line 3 of our algorithm. This functor crawling step will get to the verb's EP, and from there, the process is the same as the last two cases.</p><p>In contrast to subjects and objects, negation of a clausal argument is not treated as negation of the verb (ibid., p. 18). Since in this case, the negation cue will not be a quantifier in the MRS, there will be no functor crawling to the verb's EP.</p><p>For negated modifiers, the situation is somewhat more complex, and this is a case where our crawl- ing algorithm, developed on the basis of the anno- tated data, does not align directly with the guide- lines as given. The guidelines state that negated at- tributive adjectives have scope over the entire NP (including the determiner) (ibid., p. 20) and anal- ogously negated adverbs have scope over the en- tire clause (ibid., p. 21). However, the annotations are not consistent, especially with respect to the treatment of negated adjectives: while the head noun and determiner (if present) are typically an- notated as in scope, other co-modifiers, especially long, post-nominal modifiers (including relative clauses) are not necessarily included: (4) "A dabbler in science, Mr. Holmes, a picker up of shells on the shores of {the} great un{known ocean}. (5) Our client looked down with a rueful face at {his} own un{conventional appearance}. (6) Here was {this} ir{reproachable Englishman} ready to swear in any court of law that the accused was in the house all the time. <ref type="formula">(7)</ref> {There is}, on the face of it, {something} un{natural about this strange and sudden friend- ship between the young Spaniard and Scott Eccles}.</p><p>Furthermore, the guidelines treat relative clauses as subordinate clauses and thus negation inside a relative clause is treated as bound to that clause only, and includes neither the head noun of the relative clause nor any of its other dependents in its scope. However, from the perspective of MRS, a negated relative clause is indistinguishable from any other negated modifier of a noun. This treat- ment of relative clauses (as well as the inconsis- tencies in other forms of co-modification) is the reason for the exception noted at line 7 of <ref type="figure">Fig. 2</ref>. By disallowing the addition of EPs to the scope if they share the label of the negation cue but are not one of its arguments, we block the head noun's EP (and any EPs only reachable from it) in cases of relative clauses where the head verb inside the rel- ative clause is negated. It also blocks co-modifiers like great, own, and the phrases headed by ready and about in (4)-(7). As illustrated in these exam- ples, this is correct some but not all of the time.</p><p>Having been unable to find a generalization cap- turing when comodifiers are annotated as in scope, we stuck with this approximation. For negation within clausal modifiers of verbs, the annotation guidelines have further informa- tion, but again, our existing algorithm has the cor- rect behavior: The guidelines state that a negation cue inside of the complement of a subordinating conjunction (e.g. if ) has scope only over the sub- ordinate clause (ibid., p. 18 and p. 26). The ERG treats all subordinating conjunctions as two-place predicates taking two scopal arguments. Thus, as with clausal complements of clause-embedding verbs, the embedding subordinating conjunction and any other arguments it might have are inac- cessible, since functor crawling is restricted to a handful of specific configurations.</p><p>As is usually the case with exercises in for- malization, our crawling algorithm generalizes be- yond what is given explicitly in the annotation guidelines. For example, all arguments that are treated as semantically nominal (including PP ar- guments where the preposition is semantically null) are treated in the same way as subjects and objects; similarly, all arguments which are seman- tically clausal (including certain PP arguments) are handled the same way as clausal complements. This is possible because we take advantage of the high degree of normalization that the ERG accom- plishes in mapping to the MRS representation.</p><p>There are also cases where we are more spe- cific. The guidelines do not handle coordination in detail, except to state that in coordinated clauses negation is restricted to the clause it appears in (ibid., p. 17-18) and to include a few examples of coordination under the heading 'ellipsis'. In the case of VP coordination, our existing algorithm does not need any further elaboration to pick up the subject of the coordinated VP but not the non- negated conjunct, as shown in discussion of (1) in § 3.1 above. In the case of coordination of negated NPs, recall that to reach the main portion of the negated scope we must first apply functor crawl- ing. The functor crawling procedure has a general mechanism to transparently continue crawling up through coordinated structures while blocking fu- ture crawling from traversing them again. <ref type="bibr">6</ref> On the other hand, there are some cases in the annotation guidelines which our algorithm does not yet handle. We have not yet provided any anal- ysis of the special cases for save and expect dis- cussed in <ref type="bibr">Morante et al., 2011, pp. 22-23</ref>, and also do not have a means of picking out the overt verb in gapping constructions (p. 24).</p><p>Finally, we note that even carefully worked out annotation guidelines such as these are never fol- lowed perfectly consistently by the human annota- tors who apply them. Because our crawling algo- rithm so closely models the guidelines, this puts our system in an interesting position to provide feedback to the Shared Task organizers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Fall-Back Configurations</head><p>The close match between our crawling algorithm and the annotation guidelines supported by the mapping to MRS provides for very high precision and recall when the analysis engine produces the desired MRS. <ref type="bibr">7</ref> However, the analysis engine does not always provide the desired analysis, largely because of idiosyncrasies of the genre (e.g. voca- tives appearing mid-sentence) that are either not handled by the grammar or not well modeled in the parse selection component. In addition, as noted above, there are a handful of negation cues we do not yet handle. Thus, we also tested fall-back con- figurations which use scope predictions based on MRS in some cases, and scope predictions from the system of <ref type="bibr" target="#b14">Read et al. (2012)</ref> in others.</p><p>Our first fall-back configuration (Crawler N in <ref type="table" target="#tab_1">Table 1</ref>) uses MRS-based predictions whenever there is a parse available and the cue is one that our system handles. Sometimes, the analysis picked by the ERG's statistical model is not the correct analysis for the given context. To com- bat such suboptimal parse selection performance, we investigated using the probability of the top ranked analysis (as determined by the parse selec- tion model and conditioned on the sentence) as a confidence metric. Our second fall-back configu- ration (Crawler P in <ref type="table" target="#tab_1">Table 1</ref>) uses MRS-based pre- dictions when there is a parse available whose con- ditional probability is at least 0.5. <ref type="bibr">8</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We evaluated the performance of our system using the Shared Task development and evaluation data (respectively CDD and CDE in <ref type="table" target="#tab_1">Table 1</ref>). Since we do not attempt to perform cue detection, we report performance using gold cues and also using the system cues predicted by <ref type="bibr" target="#b14">Read et al. (2012)</ref>. We used the official Shared Task evaluation script to compute all scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data Sets</head><p>The Shared Task data consists of chapters from the Adventures of Sherlock Holmes mystery nov- els and short stories. As such, the text is carefully edited turn-of-the-20th-century British English, 9   <ref type="formula">(2012)</ref>; Crawler refers to our current system in isolation, or falling back to the Ranker prediction either when the sentence is not covered by the parser <ref type="figure">(Crawler N )</ref>, or when the parse probability is predicted to be less than 0.5 (Crawler P ); finally, Oracle simulates best possible selection among the Ranker and Crawler predictions (and would be ill-defined on system cues).</p><p>annotated with token-level information about the cues and scopes in every negated sentence. The training set contains 848 negated sentences, the development set 144, and the evaluation set 235.</p><p>As there can be multiple usages of negation in one sentence, this corresponds to 984, 173, and 264 instances, respectively. Being rule-based, our system does not require any training data per se. However, the majority of our rule development and error analysis were per- formed against the designated training data. We used the designated development data for a single final round of error analysis and corrections. The system was declared frozen before running with the formal evaluation data. All numbers reported here reflect this frozen system. <ref type="bibr">10</ref>  <ref type="table" target="#tab_1">Table 1</ref> presents the results of our various config- urations in terms of both (a) whole scopes (i.e. a true positive is only generated when the predicted scope matches the gold scope exactly) and (b) in- scope tokens (i.e. a true positive for every token the system correctly predicts to be in scope). The table also details the performance upper-bound for system combination, in which an oracle selects the system prediction which scores the greater token- wise F 1 for each gold cue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head><p>The low recall levels for Crawler can be mostly that the archaic style in the 2012 *SEM Shared Task texts has a strong adverse effect on the parser. <ref type="bibr">10</ref> The code and data are available from http://www .delph-in.net/crawler/, for replicability ( <ref type="bibr" target="#b6">Fokkens et al., 2013).</ref> attributed to imperfect parser coverage. Crawler N , which falls back just for parse failure brings the recall back up, and results in F 1 levels closer to the system of <ref type="bibr" target="#b14">Read et al. (2012)</ref>, albeit still not quite advancing the state of the art (except over the development set). Our best results are from Crawler P , which outperforms all other configura- tions on the development and evaluation sets.</p><p>The Oracle results are interesting because they show that there is much more to be gained in com- bining our semantics-based system with the Read et al. (2012) syntactically-focused system. Further analysis of these results to draw out the patterns of complementary errors and strengths is a promising avenue for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Error Analysis</head><p>To shed more light on specific strengths and weak- nesses of our approach, we performed a manual er- ror analysis of scope predictions by Crawler, start- ing from gold cues so as to focus in-depth analy- sis on properties specific to scope resolution over MRSs. This analysis was performed on CDD, in order to not bar future work on this task. Of the 173 negation cue instances in CDD, Crawler by it- self makes 94 scope predictions that exactly match the gold standard. In comparison, the system of <ref type="bibr" target="#b14">Read et al. (2012)</ref> accomplishes 119 exact scope matches, of which 80 are shared with Crawler; in other words, there are 14 cue instances (or 8% of all cues) in which our approach can improve over the best-performing syntax-based submission to the original Shared Task.</p><p>We reviewed the 79 negation instances where Crawler made a wrong prediction in terms of ex- act scope match, categorizing the source of failure into five broad error types:</p><p>(1) Annotation Error In 11% of all instances, we consider the annotations erroneous or inconsistent. These judgments were made by two of the authors, who both were familiar with the annotation guide- lines and conventions observable in the data. For example, <ref type="bibr" target="#b11">Morante et al. (2011)</ref> unambiguously state that subordinating conjunctions shall not be in-scope <ref type="formula">(8)</ref>, whereas relative pronouns should be (9), and a negated predicative argument to the cop- ula must scope over the full clause (10):</p><p>(8) It was after nine this morning {when we} reached his house and {found} neither {you} nor {anyone else inside it}.</p><p>(9) "We can imagine that in the confusion of flight something precious, something which {he could} not {bear to part with}, had been left behind.</p><p>(10) He said little about the case, but from that little we gathered that he also was not dis{satisfied} at the course of events.</p><p>(2) Parser Failure Close to 30% of Crawler fail- ures reflect lacking coverage in the ERG parser, i.e. inputs for which the parser does not make available an analysis (within certain bounds on time and memory usage). 11 In this work, we have treated the ERG as an off-the-shelf system, but coverage could certainly be straightforwardly im- proved by adding analyses for phenomena partic- ular to turn-of-the-20th-century British English.</p><p>(3) MRS Inadequacy Another 33% of our false scope predictions are Crawler-external, viz. owing to erroneous input MRSs due to imperfect disam- biguation by the parser or other inadequacies in the parser output. Again, these judgments (assign- ing blame outside our own work) were double- checked by two authors, and we only counted MRS imperfections that actually involve the cue or in-scope elements. Here, we could anticipate improvements by training the parse ranker on in- domain data or otherwise adapting it to this task.</p><p>(4) Cue Selection In close to 9% of all cases, there is a valid MRS, but Crawler fails to pick out an initial EP that corresponds to the negation cue. This first type of genuine crawling failure often re- lates to cues expressed as affixation <ref type="formula">(11)</ref>  He said little about the case, but from that little we gathered that {he also was} not {dissatisfied at the course of events}.</p><p>(15) I tell you, sir, {I could}n't move a finger, nor {get my breath}, till it whisked away and was gone.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion and Comparison</head><p>The example in (1) nicely illustrates the strengths of the MRS Crawler and of the abstraction pro- vided by the deep linguistic analysis made pos- sible by the ERG. The negated verb in that sen- tence is know, and its first semantic argument is The German. This semantic dependency is di- rectly and explicitly represented in the MRS, but the phrase expressing the dependent is not adja- cent to the head in the string. Furthermore, even a system using syntactic structure to model scope would be faced with a more complicated task than our crawling rules: At the level of syntax the de- pendency is mediated by both verb phrase coordi- nation and the control verb profess, as well as by the semantically empty infinitival marker to.</p><p>The system we propose is very similar in spirit to that of <ref type="bibr" target="#b1">Basile et al. (2012)</ref>. Both systems map from logical forms with explicit representations of scope of negation out to string-based annotations in the format provided by the Shared Task gold standard. The main points of difference are in the robustness of the system and in the degree of tai- loring of both the rules for determining scope on the logical form level and the rules for handling se- mantically vacuous elements. The system descrip- tion in <ref type="bibr" target="#b1">Basile et al. (2012)</ref> suggests relatively little tailoring at either level: aside from adjustments to the Boxer lexicon to make more negation cues take the form of the negation operator in the DRS, the notion of scope is directly that given in the DRS. Similarly, their heuristic for picking up semanti- cally vacuous words is string-based and straight- forward. Our system, on the other hand, models the annotation guidelines more closely in the def- inition of the MRS crawling rules, and has more elaborated rules for handling semantically empty words. The Crawler alone is less robust than the Boxer-based system, returning no output for 29% of the cues in CDE. These factors all point to higher precision and lower recall for the Crawler compared to the Boxer-based system. At the to- ken level, that is what we see. Since full-scope re- call depends on token-level precision, the Crawler does better across the board at the full-scope level. A comparison of the results is shown in <ref type="table" target="#tab_3">Table 2</ref>.</p><p>A final key difference between our results and those of <ref type="bibr" target="#b1">Basile et al. (2012)</ref> is the cascading with a fall-back system. Presumably a similar system combination strategy could be pursued with the Boxer-based system in place of the Crawler.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Outlook</head><p>Our motivation in this work was to take the design of the 2012 *SEM Shared Task on negation analy- sis at face value-as an overtly semantic problem that takes a central role in our long-term pursuit of language understanding. Through both theoreti- cal and practical reflection on the nature of repre- sentations at play in this task, we believe we have demonstrated that explicit semantic structure will be a key driver of further progress in the analy- sis of negation. We were able to closely align two independently developed semantic analyses- the negation-specific annotations of <ref type="bibr" target="#b11">Morante et al. (2011)</ref>, on the one hand, and the broad-coverage, MRS meaning representations of the ERG, on the other hand. In our view, the conceptual correla- tion between these two semantic views on nega- tion analysis reinforces their credibility.</p><p>Unlike the rather complex top-performing sys- tems from the original 2012 competition, our MRS Crawler is defined by a small set of general rules that operate over general-purpose, explicit mean- ing representations. Thus, our approach scores high on transparency, adaptability, and replicabil- ity. In isolation, the Crawler provides premium precision but comparatively low recall. Its limi- tations, we conjecture, reflect primarily on ERG parsing challenges and inconsistencies in the tar- get data. In a sense, our approach pushes a larger proportion of the task into the parser, mean- ing (a) there should be good opportunities for parser adaptation to this somewhat idiosyncratic text type; (b) our results can serve to offer feed- back on ERG semantic analyses and parse rank- ing; and (c) there is a much smaller proportion of very task-specific engineering. When embed- ded in a confidence-thresholded cascading archi- tecture, our system advances the state of the art on this task, and oracle combination scores sug- gest there is much remaining room to better ex- ploit the complementarity of approaches in our study. In future work, we will seek to better un- derstand the division of labor between the systems involved through contrastive error analysis and possibly another oracle experiment, constructing gold-standard MRSs for part of the data. It would also be interesting to try a task-specific adaptation of the ERG parse ranking model, for example re- training on the pre-existing treebanks but giving preference to analyses that lead to correct Crawler results downstream.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc>Scope resolution performance of various configurations over each subset of the Shared Task data. Ranker refers to the system of Read et al.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head></head><label></label><figDesc>, as well 11 Overall parsing coverage on this data is about 86%, but of course all parser failures on sentences containing negation surface in our error analysis of Crawler in isolation.</figDesc><table>Scopes 
Tokens 
Method Prec Rec 
F1 
Prec Rec F1 

CDE 
Boxer 
76.1 41.0 53.3 69.2 82.3 75.2 
Crawler 87.8 43.4 58.1 78.8 66.7 72.2 
CrawlerP 87.6 62.7 73.1 82.6 88.5 85.4 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 2 : Comparison to Basile et al. (2012).</head><label>2</label><figDesc></figDesc><table>as to rare usages of cue expressions that predomi-
nantly occur with different categories, e.g. neither 
as a generalized quantifier (12): 

(11) Please arrange your thoughts and let me know, in 
their due sequence, exactly what those events are 
{which have sent you out} un{brushed} and un-
kempt, with dress boots and waistcoat buttoned 
awry, in search of advice and assistance. 

(12) You saw yourself {how} neither {of the inspec-
tors dreamed of questioning his statement}, extraor-
dinary as it was. 

(5) Crawler Deficiency Finally, a little more 
than 16% of incorrect predictions we attribute to 
our crawling rules proper, where we see many 
instances of under-coverage of MRS elements 
(13, 14) and a few cases of extending the scope too 
wide (15). In the examples below, erroneous scope 
predictions by Crawler are indicated through un-
derlining. Hardly any of the errors in this category, 
however, involve semantically vacuous tokens. 

(13) He in turn had friends among the indoor 
servants who unite in {their} fear and 
dis{like of their master}. 

(14) </table></figure>

			<note place="foot" n="3"> In our experiments, we use the 1212 release of the ERG, in combination with the ACE parser (http://sweaglesw .org/linguistics/ace/). The ERG and ACE are DELPHIN resources; see http://www.delph-in.net.</note>

			<note place="foot" n="4"> Read et al. (2012) predicted cues using a closed vocabulary assumption with a supervised classifier to disambiguate instances of cues. 5 In other words, a possible semantic interpretation of the (string-based) Shared Task annotation guidelines and data is in terms of a quantifier-free approach to meaning representation, or in terms of one where quantifier scope need not be made explicit (as once suggested by, among others, Alshawi, 1992). From this interpretation, it follows that the notion of scope assumed in the Shared Task does not encompass interactions of negation operators and quantifiers.</note>

			<note place="foot" n="6"> This allows ate to be reached in We ate bread but no fish., while preventing but and bread from being reached, which they otherwise would via argument crawling from ate.</note>

			<note place="foot" n="7"> And in fact, the task is somewhat noise-tolerant: some parse selection decisions are independent of each other, and a mistake in a part of the analysis far enough away from the negation cue does not harm performance. 8 This threshold was determined empirically on the development data. We also experimented with other confidence metrics-the probability ratio of the top-ranked and second parse or the entropy over the probability distribution of the top 10 parses-but found no substantive differences. 9 In contrast, the ERG was engineered for the analysis of contemporary American English, and an anecdotal analysis of parse failures and imperfect top-ranked parses suggests</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We are grateful to Dan Flickinger, the main devel-oper of the ERG, for many enlightening discus-sions and continuous assistance in working with the analyses available from the grammar. This work grew out of a discussion with colleagues of the Language Technology Group at the University of Oslo, notably Elisabeth Lien and Jan Tore Løn-ning, to whom we are indebted for stimulating co-operation. Furthermore, we have benefited from comments by participants of the 2013 DELPH-IN Summit, in particular Joshua Crowgey, Guy Emerson, Glenn Slayden, Sanghoun Song, and Rui Wang.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">The Core Language Engine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Alshawi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">UGroningen. Negation detection with Discourse Representation Structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Evang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Venhuizen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Joint Conference on Lexical and Computational Semantics</title>
		<meeting>the 1st Joint Conference on Lexical and Computational Semantics<address><addrLine>Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="301" to="309" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Linguistic fundamentals for natural language processing: 100 essentials from morphology and syntax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Bender</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Morgan &amp; Claypool Publishers</publisher>
			<pubPlace>San Rafael, CA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Minimal Recursion Semantics. An introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Copestake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Flickinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pollard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">A</forename><surname>Sag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Research on Language and Computation</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="281" to="332" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Linguistically motivated large-scale NLP with C&amp;C and Boxer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Curran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Meeting of the Association for Computational Linguistics Demo and Poster Sessions</title>
		<meeting>the 45th Meeting of the Association for Computational Linguistics Demo and Poster Sessions<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="33" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">On building a more efficient grammar by exploiting types</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Flickinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="15" to="28" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Offspring from reproduction problems. What replication failure teaches us</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fokkens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Van Erp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Postma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pedersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vossen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Freire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51th Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51th Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1691" to="1701" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Efficient solving and exploration of scope ambiguities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thater</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Meeting of the Association for Computational Linguistics: Interactive Poster and Demonstration Sessions</title>
		<meeting>the 43rd Meeting of the Association for Computational Linguistics: Interactive Poster and Demonstration Sessions<address><addrLine>Ann Arbor, MI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="9" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Representing and resolving negation for sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lapponi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Read</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Øvrelid</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 ICDM workshop on sentiment elicitation from natural text for information retrieval and extraction</title>
		<meeting>the 2012 ICDM workshop on sentiment elicitation from natural text for information retrieval and extraction<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">*SEM 2012 Shared Task. Resolving the scope and focus of negation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Morante</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Blanco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Joint Conference on Lexical and Computational Semantics</title>
		<meeting>the 1st Joint Conference on Lexical and Computational Semantics<address><addrLine>Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="265" to="274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">ConanDoyleneg. Annotation of negation in Conan Doyle stories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Morante</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Conference on Language Resources and Evaluation</title>
		<meeting>the 8th International Conference on Language Resources and Evaluation<address><addrLine>Istanbul, Turkey</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Annotation of negation cues and their scope guidelines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Morante</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schrauwen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
		<idno>v1.0</idno>
	</analytic>
	<monogr>
		<title level="m">Antwerp, Belgium: Computational Linguistics &amp; Psycholinguistics Research Center</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
		<respStmt>
			<orgName>Universiteit Antwerpen</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Tech. Rep. # CTRS-003</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Modality and negation. An introduction to the special issue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Morante</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sporleder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Linguistics</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="223" to="260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Discriminantbased MRS banking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Oepen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Lønning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Conference on Language Resources and Evaluation</title>
		<meeting>the 5th International Conference on Language Resources and Evaluation<address><addrLine>Genoa, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="1250" to="1255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">UiO1. Constituent-based discriminative ranking for negation resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Read</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Velldal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Øvrelid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Oepen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Joint Conference on Lexical and Computational Semantics</title>
		<meeting>the 1st Joint Conference on Lexical and Computational Semantics<address><addrLine>Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="310" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The BioScope corpus. Biomedical texts annotated for uncertainty, negation and their scopes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vincze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Szarvas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Farkas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Móra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Csirik</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">11</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>Suppl</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
