<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:08+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Character-Level Chinese Dependency Parsing</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>June 23-25 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meishan</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Research Center for Social Computing and Information Retrieval</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<country>China, Singapore</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
							<email>yue zhang@sutd.edu.sg</email>
							<affiliation key="aff0">
								<orgName type="department">Research Center for Social Computing and Information Retrieval</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<country>China, Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Research Center for Social Computing and Information Retrieval</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<country>China, Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Research Center for Social Computing and Information Retrieval</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<country>China, Singapore</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Character-Level Chinese Dependency Parsing</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1326" to="1336"/>
							<date type="published">June 23-25 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Recent work on Chinese analysis has led to large-scale annotations of the internal structures of words, enabling character-level analysis of Chinese syntactic structures. In this paper, we investigate the problem of character-level Chinese dependency parsing, building dependency trees over characters. Character-level information can benefit downstream applications by offering flexible granularities for word segmentation while improving word-level dependency parsing accuracies. We present novel adaptations of two major shift-reduce dependency parsing algorithms to character-level parsing. Experimental results on the Chinese Treebank demonstrate improved performances over word-based parsing methods.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>As a light-weight formalism offering syntactic information to downstream applications such as SMT, the dependency grammar has received in- creasing interest in the syntax parsing commu- nity ( <ref type="bibr" target="#b17">McDonald et al., 2005;</ref><ref type="bibr" target="#b18">Nivre and Nilsson, 2005;</ref><ref type="bibr" target="#b2">Carreras et al., 2006;</ref><ref type="bibr" target="#b8">Duan et al., 2007;</ref><ref type="bibr" target="#b13">Koo and Collins, 2010;</ref><ref type="bibr" target="#b22">Zhang and Clark, 2008;</ref><ref type="bibr" target="#b19">Nivre, 2008;</ref><ref type="bibr" target="#b1">Bohnet, 2010;</ref><ref type="bibr" target="#b25">Zhang and Nivre, 2011;</ref><ref type="bibr" target="#b5">Choi and McCallum, 2013)</ref>. Chinese dependency trees were conventionally defined over words ( <ref type="bibr" target="#b4">Chang et al., 2009;</ref>), requiring word segmen- tation and POS-tagging as pre-processing steps. Recent work on Chinese analysis has embarked on investigating the syntactic roles of characters, leading to large-scale annotations of word internal structures <ref type="bibr" target="#b16">(Li, 2011;</ref>. Such an- notations enable dependency parsing on the char- acter level, building dependency trees over Chi- nese characters. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>林业局</head><p>副局长 会 上 发言 forestry administration deputy director meeting in make a speech (a) a word-based dependency tree</p><formula xml:id="formula_0">林 业 局 副 局 长 会 上 发</formula><p>言 woods industry office deputy office manager meeting in make speech (b) a character-level dependency tree by <ref type="bibr" target="#b28">Zhao (2009)</ref> with real intra-word and pseudo inter-word dependencies</p><formula xml:id="formula_1">林 业 局 副 局 长 会 上 发</formula><p>言 woods industry office deputy office manager meeting in make speech (c) a character-level dependency tree investigated in this pa- per with both real intra-and inter-word dependencies <ref type="figure" target="#fig_0">Figure 1</ref>: An example character-level dependency tree. "林业局副局长在大会上发言 (The deputy director of forestry administration make a speech in the meeting)". a character-level dependency tree, where the leaf nodes are Chinese characters.</p><p>Character-level dependency parsing is interest- ing in at least two aspects. First, character-level trees circumvent the issue that no universal stan- dard exists for Chinese word segmentation. In the well-known Chinese word segmentation bakeoff tasks, for example, different segmentation stan- dards have been used by different data sets <ref type="bibr" target="#b9">(Emerson, 2005</ref>). On the other hand, most disagreement on segmentation standards boils down to disagree- ment on segmentation granularity. As demon- strated by <ref type="bibr" target="#b28">Zhao (2009)</ref>, one can extract both fine- grained and coarse-grained words from character- level dependency trees, and hence can adapt to flexible segmentation standards using this formal- ism. In <ref type="figure" target="#fig_0">Figure 1</ref>(c), for example, "副局长 (deputy director)" can be segmented as both "副 (deputy) | 局 长 (director)" and "副 局 长 (deputy direc- tor)", but not "副 (deputy) 局 (office) | 长 (man- ager)", by dependency coherence. Chinese lan- guage processing tasks, such as machine transla- tion, can benefit from flexible segmentation stan- dards ( <ref type="bibr" target="#b3">Chang et al., 2008)</ref>.</p><p>Second, word internal structures can also be useful for syntactic parsing.  have shown the usefulness of word structures in Chinese constituent parsing. Their results on the Chinese Treebank (CTB) showed that character- level constituent parsing can bring increased per- formances even with the pseudo word structures. They further showed that better performances can be achieved when manually annotated word struc- tures are used instead of pseudo structures.</p><p>In this paper, we make an investigation of character-level Chinese dependency parsing using 's annotations and based on a transition-based parsing framework ( <ref type="bibr" target="#b24">Zhang and Clark, 2011</ref>). There are two dominant transition- based dependency parsing systems, namely the arc-standard and the arc-eager parsers <ref type="bibr" target="#b19">(Nivre, 2008)</ref>. We study both algorithms for character- level dependency parsing in order to make a com- prehensive investigation. For direct comparison with word-based parsers, we incorporate the tra- ditional word segmentation, POS-tagging and de- pendency parsing stages in our joint parsing mod- els. We make changes to the original transition systems, and arrive at two novel transition-based character-level parsers.</p><p>We conduct experiments on three data sets, in- cluding CTB 5.0, CTB 6.0 and CTB 7.0. Exper- imental results show that the character-level de- pendency parsing models outperform the word- based methods on all the data sets. Moreover, manually annotated intra-word dependencies can give improved word-level dependency accuracies than pseudo intra-word dependencies. These re- sults confirm the usefulness of character-level syntax for Chinese analysis. The source codes are freely available at http://sourceforge. net/projects/zpar/, version 0.7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Character-Level Dependency Tree</head><p>Character-level dependencies were first proposed by <ref type="bibr" target="#b28">Zhao (2009)</ref>. They show that by annotat- ing character dependencies within words, one can adapt to different segmentation standards. The dependencies they study are restricted to intra- word characters, as illustrated in <ref type="figure" target="#fig_0">Figure 1</ref>(b). For inter-word dependencies, they use a pseudo right- headed representation.</p><p>In this study, we integrate inter-word syntactic dependencies and intra-word dependencies using large-scale annotations of word internal structures by , and study their interac- tions. We extract unlabeled dependencies from bracketed word structures according to <ref type="bibr">Zhang et al.'</ref>s head annotations. In <ref type="figure" target="#fig_0">Figure 1</ref>(c), the depen- dencies shown by dashed arcs are intra-word de- pendencies, which reflect the internal word struc- tures, while the dependencies with solid arcs are inter-word dependencies, which reflect the syntac- tic structures between words.</p><p>In this formulation, a character-level depen- dency tree satisfies the same constraints as the traditional word-based dependency tree for Chi- nese, including projectivity. We differentiate intra- word dependencies and inter-word dependencies by the arc type, so that our work can be com- pared with conventional word segmentation, POS- tagging and dependency parsing pipelines under a canonical segmentation standard.</p><p>The character-level dependency trees hold to a specific word segmentation standard, but are not limited to it. We can extract finer-grained words of different granulities from a coarse-grained word by taking projective subtrees of different sizes. For example, taking all the intra-word modifier nodes of "长 (manager)" in <ref type="figure" target="#fig_0">Figure 1</ref>(c) results in the word "副局长 (deputy director)", while taking the first modifier node of "长 (manager)" results in the word "局长 (director)". Note that "副局 (deputy office)" cannot be a word because it does not form a projective span without "长 (manager)".</p><p>Inner-word dependencies can also bring bene- fits to parsing word-level dependencies. The head character can be a less sparse feature compared to a word. As intra-word dependencies lead to fine-grained subwords, we can also use these sub- words for better parsing. In this work, we use the innermost left/right subwords as atomic fea- tures. To extract the subwords, we find the inner- most left/right modifiers of the head character, re- spectively, and then conjoin them with all their de- scendant characters to form the smallest left/right subwords. <ref type="figure" target="#fig_1">Figure 2</ref> shows an example, where the smallest left subword of "大法官 (chief lawyer)" is "法官 (lawyer)", and the smallest right subword of "合法化 (legalize)" is "合法 (legal)".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Character-Level Dependency Parsing</head><p>A transition-based framework with global learn- ing and beam search decoding ( <ref type="bibr" target="#b24">Zhang and Clark, 2011</ref>) has been applied to a number of natural lan- guage processing tasks, including word segmen- tation, POS-tagging and syntactic parsing <ref type="bibr" target="#b23">(Zhang and Clark, 2010;</ref><ref type="bibr" target="#b11">Huang and Sagae, 2010;</ref><ref type="bibr" target="#b0">Bohnet and Nivre, 2012;</ref>). It models a task incrementally from a start state to an end state, where each intermediate state during decod- ing can be regarded as a partial output. A num- ber of actions are defined so that the state ad- vances step by step. To learn the model param- eters, it usually uses the online perceptron algo- rithm with early-update under the inexact decod- ing condition <ref type="bibr" target="#b7">(Collins, 2002;</ref><ref type="bibr" target="#b6">Collins and Roark, 2004</ref>). Transition-based dependency parsing can be modeled under this framework, where the state consists of a stack and a queue, and the set of ac- tions can be either the arc-eager ( <ref type="bibr" target="#b22">Zhang and Clark, 2008)</ref> or the arc-standard ( <ref type="bibr" target="#b12">Huang et al., 2009</ref>) transition systems. When the internal structures of words are an- notated, character-level dependency parsing can be treated as a special case of word-level depen- dency parsing, with "words" being "characters". A big weakness of this approach is that full words and POS-tags cannot be used for feature engineer- ing. Both are crucial to well-established features for word segmentation, POS-tagging and syntactic parsing. In this section, we introduce novel exten- sions to the arc-standard and the arc-eager tran- sition systems, so that word-based and character- based features can be used simultaneously for character-level dependency parsing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The Arc-Standard Model</head><p>The arc-standard model has been applied to joint segmentation, POS-tagging and dependency pars- ing ( <ref type="bibr" target="#b10">Hatori et al., 2012</ref>), but with pseudo word structures. For unified processing of annotated word structures and fair comparison between character-level arc-eager and arc-standard sys- tems, we define a different arc-standard transition system, consistent with our character-level arc- eager system.</p><p>In the word-based arc-standard model, the tran- sition state includes a stack and a queue, where the stack contains a sequence of partially-parsed dependency trees, and the queue consists of un- processed input words. Four actions are defined for state transition, including arc-left (AL, which creates a left arc between the top element s 0 and the second top element s 1 on the stack), arc-right (AR, which creates a right arc between s 0 and s 1 ), pop-root (PR, which defines the root node of a de- pendency tree when there is only one element on the stack and no element in the queue), and the last shift (SH, which shifts the first element q 0 of the queue onto the stack).</p><p>For character-level dependency parsing, there are two types of dependencies: inter-word depen- dencies and intra-word dependencies. To parse them with both character and word features, we extend the original transition actions into two cat- egories, for inter-word dependencies and intra- word dependencies, respectively. The actions for inter-word dependencies include inter-word arc- left (AL w ), inter-word arc-right (AR w ), pop-root (PR) and inter-word shift (SH w ). Their definitions are the same as the word-based model, with one exception that the inter-word shift operation has a parameter denoting the POS-tag of the incoming word, so that POS disambiguation is performed by the SH w action.</p><p>The actions for intra-word dependencies in- clude intra-word arc-left (AL c ), intra-word arc- right (AR c ), pop-word (PW) and inter-word shift (SH c ). The definitions of AL c , AR c and SH c are the same as the word-based arc-standard model, while PW changes the top element on the stack into a full-word node, which can only take inter- word dependencies. One thing to note is that, due to variable word sizes in character-level parsing, the number of actions can vary between differ- ent sequences of actions corresponding to differ- ent analyses. We use the padding method ( <ref type="bibr" target="#b29">Zhu et al., 2013)</ref>, adding an IDLE action to finished transition action sequences, for better alignments between states in the beam.</p><p>In the character-level arc-standard transition</p><formula xml:id="formula_2">step action stack queue dependencies 0 - φ 林 业 · · · φ 1 SHw(NR) 林/NR 业 局 · · · φ 2 SHc 林/NR 业/NR 局 副 · · · φ 3 ALc 业/NR 局 副 · · · A1 = {林 业} 4 SHc 业/NR 局/NR 副 局 · · · A1 5 ALc 局/NR 副 局 · · · A2 = A1 {业 局} 6 PW 林业局/NR 副 局 · · · A2 7 SHw(NN) 林业局/NR 副/NN 局 长 · · · A2 · · · · · · · · · · · · · · · 12 PW 林业局/NR 副局长/NN 会 上 · · · Ai 13 ALw 副局长/NN 会 上 · · · Ai+1 = Ai {林业局/NR 副局长/NN} · · · · · · · · · · · · · · ·<label>(</label></formula><p>a) character-level dependency parsing using the arc-standard algorithm</p><formula xml:id="formula_3">step action stack deque queue dependencies 0 - φ 林 业 · · · 1 SHc(NR) φ 林/NR 业 局 · · · φ 2 ALc φ φ 业/NR 局 · · · A1 = {林 业} 3 SHc φ 业/NR 局 副 · · · A1 4 ALc φ φ 局/NR 副 · · · A2 = A1 {业 局} 5 SHc φ 局/NR 副 局 · · · A2 6 PW φ 林业局/NR 副 局 · · · A2 7 SHw 林业局/NR φ 副 局 · · · A2 · · · · · · · · · · · · · · · · · · 13 PW 林业局/NR 副局长/NN 会 上 · · · Ai 14 ALw φ 副局长/NN 会 上 · · · Ai+1 = Ai {林业局/NR 副局长/NN} · · · · · · · · · · · · · · · · · · (b)</formula><p>character-level dependency parsing using the arc-eager algorithm, t = 1 system, each word is initialized by the action SH w with a POS tag, before being incrementally mod- ified by a sequence of intra-word actions, and fi- nally being completed by the action PW. The inter- word actions can be applied when all the elements on the stack are full-word nodes, while the intra- word actions can be applied when at least the top element on the stack is a partial-word node. For the actions AL c and AR c to be valid, the top two elements on the stack are both partial-word nodes. For the action PW to be valid, only the top ele- ment on the stack is a partial-word node. <ref type="figure" target="#fig_2">Figure  3(a)</ref> gives an example action sequence.</p><p>There are three types of features. The first two types are traditionally established features for the dependency parsing and joint word segmentation and POS-tagging tasks. We use the features pro- posed by <ref type="bibr" target="#b10">Hatori et al. (2012)</ref>. The word-level dependency parsing features are added when the inter-word actions are applied, and the features for joint word segmentation and POS-tagging are added when the actions PW, SH w and SH c are ap- plied. Following the work of <ref type="bibr" target="#b10">Hatori et al. (2012)</ref>, we have a parameter α to adjust the weights for joint word segmentation and POS-tagging fea- tures. We apply word-based dependency pars- ing features to intra-word dependency parsing as well, by using subwords (the conjunction of char- acters spanning the head node) to replace words in word features. The third type of features is word- structure features. We extract the head charac- ter and the smallest subwords containing the head character from the intra-word dependencies (Sec- tion 2). <ref type="table">Table 1</ref> summarizes the features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">The Arc-Eager Model</head><p>Similar to the arc-standard case, the state of a word-based arc-eager model consists of a stack and a queue, where the stack contains a sequence of partial dependency trees, and the queue con- sists of unprocessed input words. Unlike the arc- standard model, which builds dependencies on the top two elements on the stack, the arc-eager model builds dependencies between the top element of the stack and the first element of the queue. Five actions are defined for state transformation: arc- left (AL, which creates a left arc between the top element of the stack s 0 and the first element in the queue q 0 , while popping s 0 off the stack), arc-right (AR, which creates a right arc between <ref type="table">Table 1</ref>: Feature templates encoding intra-word dependencies. L and R denote the two elements over which the dependencies are built; the sub- scripts lc1 and rc1 denote the left-most and right- most children, respectively; the subscripts lc2 and rc2 denote the second left-most and second right- most children, respectively; w denotes the word; t denotes the POS tag; c denotes the head charac- ter; lsw and rsw denote the smallest left and right subwords respectively, as shown in <ref type="figure" target="#fig_1">Figure 2</ref>. s 0 and q 0 , while shifting q 0 from the queue onto the stack), pop-root (PR, which defines the ROOT node of the dependency tree when there is only one element on the stack and no element in the queue), reduce (RD, which pops s 0 off the stack), and shift (SH, which shifts q 0 onto the stack).</p><p>There is no previous work that exploits the arc-eager algorithm for jointly performing POS- tagging and dependency parsing. Since the first element of the queue can be shifted onto the stack by either SH or AR, it is more difficult to assign a POS tag to each word by using a single action. In this work, we make a change to the configu- ration state, adding a deque between the stack and the queue to save partial words with intra-word de- pendencies. We divide the transition actions into two categories, one for inter-word dependencies (AR w , AL w , SH w , RD w and PR) and the other for intra-word dependencies (AR c , AL c , SH c , RD c and PW), requiring that the intra-word actions be operated between the deque and the queue, while the inter-word actions be operated between the stack and the deque.</p><p>For character-level arc-eager dependency pars- ing, the inter-word actions are the same as the word-based methods. The actions AL c and AR c are the same as AL w and AR w , except that they operate on characters, but the SH c operation has a parameter to denote the POS tag of a word. The PW action recognizes a full-word. We also have an IDLE action, for the same reason as the arc- standard model.</p><p>In the character-level arc-eager transition sys- tem, a word is formed in a similar way with that of character-level arc-standard algorithm. Each word is initialized by the action SH c with a POS tag, and then incrementally changed a sequence of intra-word actions, before being finalized by the action PW. All these actions operate between the queue and deque. For the action PW, only the first element in the deque (close to the queue) is a partial-word node. For the actions AR c and AL c to be valid, the first element in the deque must be a partial-word node. The action SH c have a POS tag when shifting the first character of a word,but does not have such a parameter when shifting the next characters of a word. For the action SH c with a POS tag to be valid, the first element in the deque must be a full-word node. Different from the arc- standard model, at any stage we can choose either the action SH c with a POS tag to initialize a new word on the deque, or the inter-word actions on the stack. In order to eliminate the ambiguity, we define a new parameter t to limit the max size of the deque. If the deque is full with t words, inter- word actions are performed; otherwise intra-word actions are performed. All the inter-word actions must be applied on full-word nodes between the stack an the deque. <ref type="figure" target="#fig_2">Figure 3(b)</ref> gives an example action sequence.</p><p>Similar to the arc-standard case, there are three types of features, with the first two types being traditionally established features for dependency parsing and joint word segmentation and POS- tagging. The dependency parsing features are taken from the work of <ref type="bibr" target="#b25">Zhang and Nivre (2011)</ref>, and the features for joint word segmentation and POS-tagging are taken from <ref type="bibr" target="#b23">Zhang and Clark (2010)</ref>  <ref type="bibr">1</ref> . The word-level dependency parsing fea- tures are triggered when the inter-word actions are applied, while the features of joint word segmenta- tion and POS-tagging are added when the actions SH c , AR c and PW are applied. Again we use a pa- rameter α to adjust the weights for joint word seg- mentation and POS-tagging features. The word- level features for dependency parsing are applied to intra-word dependency parsing as well, by us- ing subwords to replace words. The third type of features is word-structure features, which are the CTB50 CTB60 <ref type="table" target="#tab_1">CTB70   Training  #sent  18k  23k  31k  #word  494k  641k  718k   Development  #sent  350  2.1k  10k  #word  6.8k  60k  237k  #oov  553  3.3k  13k   Test  #sent</ref>   The standard measures of word-level precision, recall and F1 score are used to evaluate word seg- mentation, POS-tagging and dependency parsing, following <ref type="bibr" target="#b10">Hatori et al. (2012)</ref>. In addition, we use the same measures to evaluate intra-word depen- dencies, which indicate the performance of pre- dicting word structures. A word's structure is cor- rect only if all the intra-word dependencies are all correctly recognized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Baseline and Proposed Models</head><p>For the baseline, we have two different pipeline models. The first consists of a joint segmentation and POS-tagging model <ref type="bibr" target="#b23">(Zhang and Clark, 2010)</ref> and a word-based dependency parsing model us- ing the arc-standard algorithm ( <ref type="bibr" target="#b12">Huang et al., 2009)</ref>. We name this model STD (pipe). The second consists of the same joint segmentation and POS-tagging model and a word-based depen- dency parsing model using the arc-eager algorithm <ref type="bibr" target="#b25">(Zhang and Nivre, 2011)</ref>. We name this model EAG (pipe). For the pipeline models, we use a beam of size 16 for joint segmentation and POS- tagging, and a beam of size 64 for dependency parsing, according to previous work.</p><p>We study the following character-level depen- dency parsing models:</p><p>• STD (real, pseudo): the arc-standard model with annotated intra-word dependencies and pseudo inter-word dependencies;</p><p>• STD (pseudo, real): the arc-standard model with pseudo intra-word dependencies and real inter-word dependencies;</p><p>• STD (real, real): the arc-standard model with annotated intra-word dependencies and real inter-word dependencies;</p><p>• EAG (real, pseudo): the arc-eager model with annotated intra-word dependencies and pseudo inter-word dependencies;</p><p>• EAG (pseudo, real): the arc-eager model with pseudo intra-word dependencies and real inter-word dependencies;</p><p>• EAG (real, real): the arc-eager model with annotated intra-word dependencies and real inter-word dependencies.</p><p>The annotated intra-word dependencies refer to the dependencies extracted from annotated word structures, while the pseudo intra-word depen- dencies used in the above models are similar to those of <ref type="bibr" target="#b10">Hatori et al. (2012)</ref>. For a given word w = c 1 c 2 · · · c m , the intra-word depen- dency structure is c 1 c 2 · · · c m 3 . The real inter- word dependencies refer to the syntactic word- level dependencies by head-finding rules from CTB, while the pseudo inter-word dependencies refer to the word-level dependencies used by <ref type="bibr" target="#b28">Zhao (2009)</ref> </p><formula xml:id="formula_4">(w 1 w 2 · · · w n ).</formula><p>The character-level models with annotated intra-word dependencies and pseudo inter-word dependencies are compared with the pipelines on word segmentation and POS- tagging accuracies, and are compared with the character-level models with annotated intra-word dependencies and real inter-word dependencies on word segmentation, POS-tagging and word- structure predicating accuracies. All the proposed STD (real, real) SEG POS DEP WS   models use a beam of size 64 after considering both speeds and accuracies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Development Results</head><p>Our development tests are designed for two pur- poses: adjusting the parameters for the two pro- posed character-level models and testing the effec- tiveness of the novel word-structure features. Tun- ing is conducted by maximizing word-level depen- dency accuracies. All the tests are conducted on the CTB60 data set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Parameter Tuning</head><p>For the arc-standard model, there is only one pa- rameter α that needs tuning. It adjusts the weights of segmentation and POS-tagging features, be- cause the number of feature templates is much less for the two tasks than for parsing. We set the value of α to 1 · · · 5, respectively. <ref type="table" target="#tab_3">Table 3</ref> shows the accuracies on the CTB60 development set. Ac- cording to the results, we use α = 4 for our final character-level arc-standard model. For the arc-eager model, there are two parame- ters t and α. t denotes the deque size of the arc- eager model, while α shares the same meaning as the arc-standard model. We take two steps for pa- rameter tuning, first adjusting the more crucial pa- rameter t and then adjusting α on the best t. Both parameters are assigned the values of 1 to 5. Ta-  <ref type="table">Table 5</ref>: Feature ablation tests for the novel word- structure features, where "/wo" denotes the corre- sponding models without the novel intra-word de- pendency features.</p><p>ble 4 shows the results. According to results, we set t = 3 and α = 3 for the final character-level arc-eager model, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Effectiveness of Word-Structure Features</head><p>To test the effectiveness of our novel word- structure features, we conduct feature ablation ex- periments on the CTB60 development data set for the proposed arc-standard and arc-eager models, respectively. <ref type="table">Table 5</ref> shows the results. We can see that both the two models achieve better accu- racies on word-level dependencies with the novel word-structure features, while the features do not affect word-structure predication significantly. <ref type="table">Table 6</ref> shows the final results on the CTB50, CTB60 and CTB70 data sets, respectively. The results demonstrate that the character-level depen- dency parsing models are significantly better than the corresponding word-based pipeline models, for both the arc-standard and arc-eager systems. Similar to the findings of , we find that the annotated word structures can give better accuracies than pseudo word structures. An- other interesting finding is that, although the arc- eager algorithm achieves lower accuracies in the word-based pipeline models, it obtains compara- tive accuracies in the character-level models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Final Results</head><p>We also compare our results to those of <ref type="bibr" target="#b10">Hatori et al. (2012)</ref>, which is comparable to STD (pseudo, real) since similar arc-standard algorithms and features are used. The major difference is the set of transition actions. We rerun their system on the three datasets 4 . As shown in <ref type="table">Table 6</ref>, our arc-standard system with pseudo word structures  <ref type="table">Table 6</ref>: Main results, where the results marked with ‡ denote that the p-value is less than 0.001 compared with the pipeline word-based models using pairwise t-test.</p><p>brings consistent better accuracies than their work on all the three data sets.</p><p>Both the pipelines and character-level mod- els with pseudo inter-word dependencies perform word segmentation and POS-tagging jointly, with- out using real word-level syntactic information. A comparison between them (STD/EAG (pipe) vs. STD/EAG (real, pseudo)) reflects the effectiveness of annotated intra-word dependencies on segmen- tation and POS-tagging. We can see that both the arc-standard and arc-eager models with annotated intra-word dependencies can improve the segmen- tation accuracies by 0.3% and the POS-tagging ac- curacies by 0.5% on average on the three datasets. Similarly, a comparison between the character- level models with pseudo inter-word dependen- cies and the character-level models with real inter- word dependencies (STD/EAG (real, pseudo) vs. STD/EAG (real, real)) can reflect the effectiveness of annotated inter-word structures on morphology analysis. We can see that improved POS-tagging accuracies are achieved using the real inter-word dependencies when jointly performing inner-and inter-word dependencies. However, we find that the inter-word dependencies do not help the word- structure accuracies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Analysis</head><p>To better understand the character-level parsing models, we conduct error analysis in this section. All the experiments are conducted on the CTB60 test data sets. The new advantage of the character- level models is that one can parse the internal word structures of intra-word dependencies. Thus we are interested in their capabilities of predict- ing word structures. We study the word-structure accuracies in two aspects, including OOV, word length, POS tags and the parsing model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.1">OOV</head><p>The word-structure accuracy of OOV words re- flects a model's ability of handling unknown words. The overall recalls of OOV word structures are 67.98% by STD (real, real) and 69.01% by EAG (real, real), respectively. We find that most errors are caused by failures of word segmenta- tion. We further investigate the accuracies when words are correctly segmented, where the accura- cies of OOV word structures are 87.64% by STD (real, real) and 89.07% by EAG (real, real). The results demonstrate that the structures of Chinese words are not difficult to predict, and confirm the fact that Chinese word structures have some com- mon syntactic patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.2">Parsing Model</head><p>From the above analysis in terms of OOV, word lengths and POS tags, we can see that the EAG (real, real) model and the STD (real, real) mod- els behave similarly on word-structure accuracies. Here we study the two models more carefully, comparing their word accuracies sentence by sen- tence. <ref type="figure" target="#fig_3">Figure 4</ref> shows the results, where each point denotes a sentential comparison between STD (real, real) and EAG (real, real), the x-axis denotes the sentential word-structure accuracy of STD (real, real), and the y-axis denotes that of EAG (real, real). The points at the diagonal show the same accuracies by the two models, while oth- ers show that the two models perform differently on the corresponding sentences. We can see that most points are beyond the diagonal line, indicat- ing that the two parsing models can be comple- mentary in parsing intra-word dependencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Zhao (2009) was the first to study character-level dependencies; they argue that since no consistent word boundaries exist over Chinese word segmen- tation, dependency-based representations of word structures serve as a good alternative for Chinese word segmentation. Thus their main concern is to parse intra-word dependencies. In this work, we extend their formulation, making use of large- scale annotations of , so that the syntactic word-level dependencies can be parsed together with intra-word dependencies. <ref type="bibr" target="#b10">Hatori et al. (2012)</ref> proposed a joint model for Chinese word segmentation, POS-tagging and dependency parsing, studying the influence of joint model and character features for parsing, Their model is extended from the arc-standard transition-based model, and can be regarded as an alternative to the arc-standard model of our work when pseudo intra-word dependencies are used. Similar work is done by <ref type="bibr" target="#b14">Li and Zhou (2012)</ref>. Our proposed arc-standard model is more concise while obtaining better performance than <ref type="bibr" target="#b10">Hatori et al. (2012)</ref>'s work. With respect to word structures, real intra-word dependencies are often more com- plicated, while pseudo word structures cannot be used to correctly guide segmentation.</p><p>Zhao (2009), <ref type="bibr" target="#b10">Hatori et al. (2012)</ref> and our work all study character-level dependency pars- ing. While Zhao (2009) focus on word internal structures using pseudo inter-word dependencies, <ref type="bibr" target="#b10">Hatori et al. (2012)</ref> investigate a joint model using pseudo intra-word dependencies. We use manual dependencies for both inner-and inter-word struc- tures, studying their influences on each other.  was the first to perform Chi- nese syntactic parsing over characters. They ex- tended word-level constituent trees by annotated word structures, and proposed a transition-based approach to parse intra-word structures and word- level constituent structures jointly. For Hebrew, <ref type="bibr" target="#b20">Tsarfaty and Goldberg (2008)</ref> investigated joint segmentation and parsing over characters using a graph-based method. Our work is similar in ex- ploiting character-level syntax. We study the de- pendency grammar, another popular syntactic rep- resentation, and propose two novel transition sys- tems for character-level dependency parsing.</p><p>Nivre <ref type="formula" target="#formula_2">(2008)</ref> gave a systematic description of the arc-standard and arc-eager algorithms, cur- rently two popular transition-based parsing meth- ods for word-level dependency parsing. We extend both algorithms to character-level joint word seg- mentation, POS-tagging and dependency parsing. To our knowledge, we are the first to apply the arc- eager system to joint models and achieve compar- ative performances to the arc-standard model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>We studied the character-level Chinese depen- dency parsing, by making novel extensions to two commonly-used transition-based dependency parsing algorithms for word-based dependency parsing. With both pseudo and annotated word structures, our character-level models obtained better accuracies than previous work on seg- mentation, POS-tagging and word-level depen- dency parsing. We further analyzed some im- portant factors for intra-word dependencies, and found that two proposed character-level pars- ing models are complementary in parsing intra- word dependencies. We make the source code publicly available at http://sourceforge. net/projects/zpar/, version 0.7.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 (</head><label>1</label><figDesc>c) shows an example of * Corresponding author.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: An example to illustrate the innermost left/right subwords.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Character-level dependency parsing of the sentence in Figure 1(c).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Sentential word-structure accuracies of STD (real, real) and EAG (real, real).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Statistics of datasets. 

same as those of the character-level arc-standard 
model, shown in Table 1. 

4 Experiments 

4.1 Experimental Settings 

We use the Chinese Penn Treebank 5.0, 6.0 and 7.0 
to conduct the experiments, splitting the corpora 
into training, development and test sets according 
to previous work. Three different splitting meth-
ods are used, namely CTB50 by Zhang and Clark 
(2010), CTB60 by the official documentation of 
CTB 6.0, and CTB70 by Wang et al. (2011). The 
dataset statistics are shown in Table 2. We use 
the head rules of Zhang and Clark (2008) to con-
vert phrase structures into dependency structures. 
The intra-word dependencies are extracted from 
the annotations of Zhang et al. (2013) 2 . 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Development test results of the character-
level arc-standard model on CTB60. 

EAG (real, real) SEG POS DEP WS 

α = 1 

t = 1 96.00 91.66 74.63 95.49 
t = 2 95.93 91.75 76.60 95.37 
t = 3 95.93 91.74 76.94 95.36 
t = 4 95.91 91.71 76.82 95.33 
t = 5 95.95 91.73 76.84 95.40 

t = 3 

α = 1 95.93 91.74 76.94 95.36 
α = 2 96.11 91.99 77.17 95.56 
α = 3 96.16 92.01 77.48 95.62 
α = 4 96.11 91.93 77.40 95.53 
α = 5 96.00 91.84 77.10 95.43 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Development test results of the character-
level arc-eager model on CTB60. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Model CTB50 CTB60 CTB70 SEG POS DEP WS SEG POS DEP WS SEG POS DEP WS</head><label></label><figDesc></figDesc><table>The arc-standard models 
STD (pipe) 
97.53 93.28 79.72 
-
95.32 90.65 75.35 
-
95.23 89.92 73.93 
-
STD (real, pseudo) 97.78 93.74 
-
97.40 95.77  ‡ 91.24  ‡ 
-
95.08 95.59  ‡ 90.49  ‡ 
-
94.97 
STD (pseudo, real) 97.67 94.28  ‡ 81.63  ‡ 
-
95.63  ‡ 91.40  ‡ 76.75  ‡ 
-
95.53  ‡ 90.75  ‡ 75.63  ‡ 
-
STD (real, real) 
97.84 94.62  ‡ 82.14  ‡ 97.30 95.56  ‡ 91.39  ‡ 77.09  ‡ 94.80 95.51  ‡ 90.76  ‡ 75.70  ‡ 94.78 
Hatori+ '12 
97.75 94.33 81.56 
-
95.26 91.06 75.93 
-
95.27 90.53 74.73 
-

The arc-eager models 
EAG (pipe) 
97.53 93.28 79.59 
-
95.32 90.65 74.98 
-
95.23 89.92 73.46 
-
EAG (real, pseudo) 97.75 93.88 
-
97.45 95.63  ‡ 91.07  ‡ 
-
95.06 95.50  ‡ 90.36  ‡ 
-
95.00 
EAG (pseudo, real) 97.76 94.36  ‡ 81.70  ‡ 
-
95.63  ‡ 91.34  ‡ 76.87  ‡ 
-
95.39  ‡ 90.56  ‡ 75.56  ‡ 
-
EAG (real, real) 
97.84 94.36  ‡ 82.07  ‡ 97.49 95.71  ‡ 91.51  ‡ 76.99  ‡ 95.16 95.47  ‡ 90.72  ‡ 75.76  ‡ 94.94 

</table></figure>

			<note place="foot" n="1"> Since Hatori et al. (2012) also use Zhang and Clark (2010)&apos;s features, the arc-standard and arc-eager characterlevel dependency parsing models have the same features for joint word segmentation and POS-tagging.</note>

			<note place="foot" n="2"> https://github.com/zhangmeishan/ wordstructures; their annotation was conducted on CTB 5.0, while we made annotations of the remainder of the CTB 7.0 words. We also make the annotations publicly available at the same site.</note>

			<note place="foot" n="3"> We also tried similar structures with right arcs, which gave lower accuracies.</note>

			<note place="foot" n="4"> http://triplet.cc/. We use a different constituent-to-dependency conversion scheme in comparison with Hatori et al. (2012)&apos;s work.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the anonymous reviewers for their constructive comments, and gratefully acknowl-edge the support of the National Basic Re-search Program (973 Program) of China via Grant 2014CB340503, the National Natural Science Foundation of China (NSFC) via Grant 61133012 and 61370164, the Singapore Ministry of Educa-tion (MOE) AcRF Tier 2 grant T2MOE201301 and SRG ISTD 2012 038 from Singapore Univer-sity of Technology and Design.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A transitionbased system for joint part-of-speech tagging and labeled non-projective dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernd</forename><surname>Bohnet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the EMNLP-CONLL</title>
		<meeting>the EMNLP-CONLL<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-07" />
			<biblScope unit="page" from="1455" to="1465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Very high accuracy and fast dependency parsing is not a contradiction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernd</forename><surname>Bohnet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd COLING, number August</title>
		<meeting>the 23rd COLING, number August</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="89" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Projective dependency parsing with perceptron</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Carreras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth Conference on Computational Natural Language Learning (CoNLL-X)</title>
		<meeting>the Tenth Conference on Computational Natural Language Learning (CoNLL-X)<address><addrLine>New York City</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-06" />
			<biblScope unit="page" from="181" to="185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Optimizing chinese word segmentation for machine translation performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pi-Chuan</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL Workshop on Statistical Machine Translation</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Discriminative reordering with chinese grammatical relations features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pi-Chuan</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huihsin</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Workshop on Syntax and Structure in Statistical Translation</title>
		<meeting>the Third Workshop on Syntax and Structure in Statistical Translation</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Transition-based dependency parsing with selectional branching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jinho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2013-08" />
			<biblScope unit="page" from="1052" to="1062" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Incremental parsing with the perceptron algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Roark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL&apos;04), Main Volume</title>
		<meeting>the 42nd Meeting of the Association for Computational Linguistics (ACL&apos;04), Main Volume<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-07" />
			<biblScope unit="page" from="111" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th EMNLP</title>
		<meeting>the 7th EMNLP</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Probabilistic models for action-based chinese dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Xiangyu Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ECML/ECPPKDD</title>
		<meeting>ECML/ECPPKDD</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="559" to="566" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The second international chinese word segmentation bakeoff</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Emerson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second SIGHAN Workshop on Chinese Language Processing</title>
		<meeting>the Second SIGHAN Workshop on Chinese Language Processing</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="123" to="133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Incremental joint approach to word segmentation, pos tagging, and dependency parsing in chinese</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Hatori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takuya</forename><surname>Matsuzaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuke</forename><surname>Miyao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun&amp;apos;ichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th ACL</title>
		<meeting>the 50th ACL<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-07" />
			<biblScope unit="page" from="1045" to="1053" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Dynamic programming for linear-time incremental parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Sagae</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th ACL</title>
		<meeting>the 48th ACL<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-07" />
			<biblScope unit="page" from="1077" to="1086" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Bilingually-constrained (monolingual) shift-reduce parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenbin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2009 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1222" to="1231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Efficient thirdorder dependency parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the ACL</title>
		<meeting>the 48th Annual Meeting of the ACL</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Unified dependency parsing of chinese morphological and syntactic structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongguo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-07" />
			<biblScope unit="page" from="1445" to="1454" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Exploiting multiple treebanks for parsing with quasisynchronous grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenghua</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th ACL</title>
		<meeting>the 50th ACL<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-07" />
			<biblScope unit="page" from="675" to="684" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Parsing the internal structure of words: A new paradigm for chinese word segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongguo</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th ACL</title>
		<meeting>the 49th ACL<address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-06" />
			<biblScope unit="page" from="1405" to="1414" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Online large-margin training of dependency parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL, number June</title>
		<meeting>ACL, number June<address><addrLine>Morristown, NJ, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="91" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Pseudoprojective dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Nilsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Algorithms for deterministic incremental dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="513" to="553" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Word-based or morpheme-based? annotation strategies for modern hebrew clitics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reut</forename><surname>Tsarfaty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC. European Language Resources Association</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Improving chinese word segmentation and pos tagging with semi-supervised methods using large auto-analyzed data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshimasa</forename><surname>Jun&amp;apos;ichi Kazama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenliang</forename><surname>Tsuruoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 5th IJCNLP</title>
		<meeting>5th IJCNLP<address><addrLine>Chiang Mai, Thailand</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-11" />
			<biblScope unit="page" from="309" to="317" />
		</imprint>
	</monogr>
	<note>Yujie Zhang, and Kentaro Torisawa</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A tale of two parsers: Investigating and combining graphbased and transition-based dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP<address><addrLine>Honolulu, Hawaii</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-10" />
			<biblScope unit="page" from="562" to="571" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A fast decoder for joint word segmentation and POS-tagging using a single discriminative model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the EMNLP</title>
		<meeting>the EMNLP<address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-10" />
			<biblScope unit="page" from="843" to="852" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Syntactic processing using the generalized perceptron and beam search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="105" to="151" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Transition-based dependency parsing with rich non-local features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th ACL</title>
		<meeting>the 49th ACL<address><addrLine>Oregon, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-06" />
			<biblScope unit="page" from="188" to="193" />
		</imprint>
	</monogr>
	<note>Portland</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Chinese word segmentation and statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruiqiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keiji</forename><surname>Yasuda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eiichiro</forename><surname>Sumita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Chinese parsing exploiting characters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meishan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st ACL</title>
		<meeting>the 51st ACL<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-08" />
			<biblScope unit="page" from="125" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Character-level dependencies in chinese: Usefulness and learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the EACL</title>
		<meeting>the EACL<address><addrLine>Athens, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-03" />
			<biblScope unit="page" from="879" to="887" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Fast and accurate shiftreduce constituent parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhua</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenliang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingbo</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st ACL</title>
		<meeting>the 51st ACL<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-08" />
			<biblScope unit="page" from="434" to="443" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
