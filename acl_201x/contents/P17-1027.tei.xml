<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:42+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Full Non-Monotonic Transition System for Unrestricted Non-Projective Parsing</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Fernández-González</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Gómez-Rodríguez</surname></persName>
						</author>
						<title level="a" type="main">A Full Non-Monotonic Transition System for Unrestricted Non-Projective Parsing</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</title>
						<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="288" to="298"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-1027</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Restricted non-monotonicity has been shown beneficial for the projective arc-eager dependency parser in previous research , as posterior decisions can repair mistakes made in previous states due to the lack of information. In this paper, we propose a novel, fully non-monotonic transition system based on the non-projective Covington algorithm. As a non-monotonic system requires exploration of erroneous actions during the training process, we develop several non-monotonic variants of the recently defined dynamic oracle for the Covington parser, based on tight approximations of the loss. Experiments on data-sets from the CoNLL-X and CoNLL-XI shared tasks show that a non-monotonic dynamic oracle outperforms the mono-tonic version in the majority of languages.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Greedy transition-based dependency parsers are widely used in different NLP tasks due to their speed and efficiency. They parse a sentence from left to right by greedily choosing the highest- scoring transition to go from the current parser configuration or state to the next. The resulting se- quence of transitions incrementally builds a parse for the input sentence. The scoring of the trans- itions is provided by a statistical model, previously trained to approximate an oracle, a function that selects the needed transitions to parse a gold tree.</p><p>Unfortunately, the greedy nature that grants these parsers their efficiency also represents their main limitation.  show that greedy transition-based parsers lose ac- curacy to error propagation: a transition erro- neously chosen by the greedy parser can place it in an incorrect and unknown configuration, caus- ing more mistakes in the rest of the transition se- quence. Training with a dynamic oracle <ref type="bibr" target="#b4">(Goldberg and Nivre, 2012</ref>) improves robustness in these situations, but in a monotonic transition system, erroneous decisions made in the past are perman- ent, even when the availability of further informa- tion in later states might be useful to correct them. <ref type="bibr" target="#b9">Honnibal et al. (2013)</ref> show that allowing some degree of non-monotonicity, by using a limited set of non-monotonic actions that can repair past mistakes and replace previously-built arcs, can in- crease the accuracy of a transition-based parser. In particular, they present a modified arc-eager trans- ition system where the Left-Arc and Reduce trans- itions are non-monotonic: the former is used to repair invalid attachments made in previous states by replacing them with a leftward arc, and the latter allows the parser to link two words with a rightward arc that were previously left unattached due to an erroneous decision. Since the Right-Arc transition is still monotonic and leftward arcs can never be repaired because their dependent is re- moved from the stack by the arc-eager parser and rendered inaccessible, this approach can only re- pair certain kinds of mistakes: namely, it can fix erroneous rightward arcs by replacing them with a leftward arc, and connect a limited set of un- attached words with rightward arcs. In addition, they argue that non-monotonicity in the training oracle can be harmful for the final accuracy and, therefore, they suggest to apply it only as a fall- back component for a monotonic oracle, which is given priority over the non-monotonic one. Thus, this strategy will follow the path dictated by the monotonic oracle the majority of the time. <ref type="bibr" target="#b10">Honnibal and Johnson (2015)</ref> present an extension of this transition system with an Unshift transition al- lowing it some extra flexibility to correct past er- rors. However, the restriction that only rightward arcs can be deleted, and only by replacing them with leftward arcs, is still in place. Furthermore, both versions of the algorithm are limited to pro- jective trees.</p><p>In this paper, we propose a non-monotonic transition system based on the non-projective Cov- ington parser, together with a dynamic oracle to train it with erroneous examples that will need to be repaired. Unlike the system developed in <ref type="bibr" target="#b9">(Honnibal et al., 2013;</ref><ref type="bibr" target="#b10">Honnibal and Johnson, 2015)</ref>, we work with full non-monotonicity. This has a twofold meaning: (1) our approach can repair previous erroneous attachments regardless of their original direction, and it can replace them either with a rightward or leftward arc as both arc trans- itions are non-monotonic; 1 and (2) we use exclus- ively a non-monotonic oracle, without the inter- ferences of monotonic decisions. These modi- fications are feasible because the non-projective Covington transition system is less rigid than the arc-eager algorithm, as words are never deleted from the parser's data structures and can always be revisited, making it a better option to exploit the full potencial of non-monotonicity. To our knowledge, the presented system is the first non- monotonic parser that can produce non-projective dependency analyses. Another novel aspect is that our dynamic oracle is approximate, i.e., based on efficiently-computable approximations of the loss due to the complexity of calculating its ac- tual value in a non-monotonic and non-projective scenario. However, this is not a problem in prac- tice: experimental results show how our parser and oracle can use non-monotonic actions to repair erroneous attachments, outperforming the mono- tonic version developed by <ref type="bibr">Gómez-Rodríguez and Fernández-González (2015)</ref> in a large majority of the datasets tested.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Non-Projective Covington Transition System</head><p>The non-projective Covington parser was origin- ally defined by <ref type="bibr" target="#b2">Covington (2001)</ref>, and then recast by <ref type="bibr" target="#b15">Nivre (2008)</ref> under the transition-based parsing framework. <ref type="bibr">1</ref> The only restriction is that parsing must still proceed in left-to-right order. For this reason, a leftward arc cannot be repaired with a rightward arc, because this would imply going back in the sentence. The other three combinations (replacing leftward with leftward, rightward with leftward or rightward with rightward arcs) are possible.</p><p>The transition system that defines this parser is as follows: each parser configuration is of the form c = λ 1 , λ 2 , B, A, such that λ 1 and λ 2 are lists of partially processed words, B is another list (called the buffer) containing currently unpro- cessed words, and A is the set of dependencies that have been built so far. Suppose that our in- put is a string w 1 · · · w n , whose word occurrences will be identified with their indices 1 · · · n for sim- plicity. Then, the parser will start at an initial configuration c s (w 1 . . . w n ) = [], [], <ref type="bibr">[1 . . . n]</ref>, ∅∅, and execute transitions chosen from those in <ref type="figure">Fig- ure 1</ref> until a terminal configuration of the form {{λ 1 , λ 2 , [], A ∈ C} is reached. At that point, the sentence's parse tree is obtained from A. <ref type="bibr">2</ref> These transitions implement the same logic as the double nested loop traversing word pairs in the original formulation by <ref type="bibr" target="#b2">Covington (2001)</ref>. When the parser's configuration is λ 1 |i, λ 2 , j|B, A, we say that it is considering the focus words i and j, located at the end of the first list and at the begin- ning of the buffer. At that point, the parser must decide whether these two words should be linked with a leftward arc i ← j (Left-Arc transition), a rightward arc i → j (Right-Arc transition), or not linked at all (No-Arc transition). However, the two transitions that create arcs will be disal- lowed in configurations where this would cause a violation of the single-head constraint (a node can have at most one incoming arc) or the acyc- licity constraint (the dependency graph cannot have cycles). After applying any of these three transitions, i is moved to the second list to make i − 1 and j the focus words for the next step. As an alternative, we can instead choose to execute a Shift transition which lets the parser read a new input word, placing the focus on j and j + 1.</p><p>The resulting parser can generate any possible dependency tree for the input, including arbit- rary non-projective trees. While it runs in quad- ratic worst-case time, in theory worse than linear- time transition-based parsers (e.g. <ref type="bibr" target="#b14">(Nivre, 2003;</ref><ref type="bibr" target="#b7">Gómez-Rodríguez and Nivre, 2013)</ref>), it has been shown to outspeed linear algorithms in practice, thanks to feature extraction optimizations that can- not be implemented in other parsers <ref type="bibr" target="#b21">(Volokh and Neumann, 2012</ref>). In fact, one of the fastest de- pendency parsers ever reported uses this algorithm Shift:</p><formula xml:id="formula_0">λ1, λ2, j|B, A ⇒ λ1 · λ2|j, [], B, A No-Arc:</formula><p>λ1|i, λ2, B, A ⇒ λ1, i|λ2, B, A Left-Arc: λ1|i, λ2, j|B, A ⇒ λ1, i|λ2, j|B, A ∪ {j → i}} only if k | k → i ∈ A (single-head) and i → * j ∈ A (acyclicity).</p><p>Right-Arc: λ1|i, λ2, j|B, A ⇒ λ1, i|λ2, j|B, A ∪ {i → j}} only if k | k → j ∈ A (single-head) and j → * i ∈ A (acyclicity). <ref type="figure">Figure 1</ref>: Transitions of the monotonic Covington non-projective dependency parser. The notation i → * j ∈ A means that there is a (possibly empty) directed path from i to j in A.</p><p>(Volokh, 2013).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Monotonic Dynamic Oracle</head><p>A dynamic oracle is a function that maps a config- uration c and a gold tree t G to the set of transitions that can be applied in c and lead to some parse tree t minimizing the Hamming loss with respect to t G (the amount of nodes whose head is different in t and t G ). Following <ref type="bibr" target="#b5">Goldberg and Nivre (2013)</ref>, we say that an arc set A is reachable from con- figuration c, and we write c A, if there is some (possibly empty) path of transitions from c to some configuration c = λ 1 , λ 2 , B, A , with A ⊆ A . Then, we can define the loss of configuration c as</p><formula xml:id="formula_1">(c) = min t|ct L(t, t G ),</formula><p>and therefore, a correct dynamic oracle will return the set of transitions</p><formula xml:id="formula_2">o d (c, t G ) = {τ | (c) − (τ (c)) = 0},</formula><p>i.e., the set of transitions that do not increase con- figuration loss, and thus lead to the best parse (in terms of loss) reachable from c. Hence, imple- menting a dynamic oracle reduces to computing the loss (c) for each configuration c. <ref type="bibr" target="#b5">Goldberg and Nivre (2013)</ref> show a straightfor- ward method to calculate loss for parsers that are arc-decomposable, i.e., those where every arc set A that can be part of a well-formed parse verifies that if c (i → j) for every i → j ∈ A (i.e., each of the individual arcs of A is reachable from a given configuration c), then c A (i.e., the set A as a whole is reachable from c). If this holds, then the loss of a configuration c equals the num- ber of gold arcs that are not individually reachable from c, which is easy to compute in most parsers. <ref type="bibr">Gómez-Rodríguez and Fernández-González (2015)</ref> show that the non-projective Covington parser is not arc-decomposable because sets of individually reachable arcs may form cycles together with already-built arcs, preventing them from being jointly reachable due to the acyclicity constraint. In spite of this, they prove that a dynamic oracle for the Covington parser can be efficiently built by counting individually unreach- able arcs, and correcting for the presence of such cycles. Concretely, the loss is computed as:</p><formula xml:id="formula_3">(c) = |U(c, t G )| + n c (A ∪ I(c, t G ))</formula><p>where</p><formula xml:id="formula_4">I(c, t G ) = {x → y ∈ t G | c (x → y)}</formula><p>is the set of individually reachable arcs of t G from configuration c; U(c, t G ) is the set of indi- vidually unreachable arcs of t G from c, com- puted as t G \I(c, t G ); and n c (G) denotes the num- ber of cycles in a graph G.</p><p>Therefore, to calculate the loss of a configur- ation c, we only need to compute the two terms |U(c, t G )| and n c (A ∪ I(c, t G )). To calculate the first term, given a configuration c with focus words i and j (i.e., c = λ 1 |i, λ 2 , j|B, A), an arc x → y will be in U(c, t G ) if it is not in A, and at least one of the following holds:</p><p>• j &gt; max(x, y), (i.e., we have read too far in the string and can no longer get max(x, y) as right focus word), • j = max(x, y) ∧ i &lt; min(x, y), (i.e., we have max(x, y) as the right focus word but the left focus word has already moved left past min(x, y), and we cannot go back), • there is some z = 0, z = x such that z → y ∈ A, (i.e., we cannot create x → y because it would violate the single-head constraint), • x and y are on the same weakly connected component of A (i.e., we cannot create x → y due to the acyclicity constraint). The second term of the loss, n c (A ∪ I(c, t G )), can be computed by first obtaining I(c, t G ) as t G \ U(c, t G ). Since the graph I(c, t G ) has in- degree 1, the algorithm by <ref type="bibr" target="#b18">Tarjan (1972)</ref> can then be used to find and count the cycles in O(n) time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Computation of the loss of a config- uration in the monotonic oracle.</head><p>1: function LOSS(c = λ1|i, λ2, j|B, A, tG) 2:</p><formula xml:id="formula_5">U ← ∅ Variable U is for U(c, tG) 3: for each x → y ∈ (tG \ A) do 4: left ← min(x, y) 5: right ← max(x, y) 6: if j &gt; right ∨ 7: (j = right ∧ i &lt; left) ∨ 8: (∃z &gt; 0, z = x : z → y ∈ A) ∨ 9:</formula><p>WEAKLYCONNECTED(A, x, y) then 10:</p><p>U ← u ∪ {x → y} 11:</p><p>I ← tG \ U Variable I is for I(c, tG) 12:</p><p>return |U | + COUNTCYCLES(A ∪ I )</p><p>Algorithm 1 shows the resulting loss calcula- tion algorithm, where COUNTCYCLES is a func- tion that counts the number of cycles in the given graph and WEAKLYCONNECTED returns whether two given nodes are weakly connected in A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Non-Monotonic Transition System for the Covington Non-Projective Parser</head><p>We now define a non-monotonic variant of the Covington non-projective parser. To do so, we al- low the Right-Arc and Left-Arc transitions to cre- ate arcs between any pair of nodes without restric- tion. If the node attached as dependent already had a previous head, the existing attachment is dis- carded in favor of the new one. This allows the parser to correct erroneous attachments made in the past by assigning new heads, while still enfor- cing the single-head constraint, as only the most recent head assigned to each node is kept.</p><p>To enforce acyclicity, one possibility would be to keep the logic of the monotonic algorithm, forbidding the creation of arcs that would cre- ate cycles. However, this greatly complicates the definition of the set of individually unreachable arcs, which is needed to compute the loss bounds that will be used by the dynamic oracle. This is because a gold arc x → y may superficially seem unreachable due to forming a cycle together with arcs in A, but it might in fact be reachable if there is some transition sequence that first breaks the cycle using non-monotonic transitions to remove arcs from A, to then create x → y. We do not know of a way to characterize the conditions un- der which such a transition sequence exists, and thus cannot estimate the loss efficiently.</p><p>Instead, we enforce the acyclicity constraint in a similar way to the single-head constraint: Right-Arc and Left-Arc transitions are always al- lowed, even if the prospective arc would create a cycle in A. However, if the creation of a new arc x → y generates a cycle in A, we immediately re- move the arc of the form z → x from A (which trivially exists, and is unique due to the single- head constraint). This not only enforces the acyc- licity constraint while keeping the computation of U(c, t G ) simple and efficient, but also produces a straightforward, coherent algorithm (arc trans- itions are always allowed, and both constraints are enforced by deleting a previous arc) and allows us to exploit non-monotonicity to the maximum (we can not only recover from assigning a node the wrong head, but also from situations where pre- vious errors together with the acyclicity constraint prevent us from building a gold arc, keeping with the principle that later decisions override earlier ones).</p><p>In <ref type="figure">Figure 2</ref>, we can see the resulting non- monotonic transition system for the non-projective Covington algorithm, where, unlike the monotonic version, all transitions are allowed at each con- figuration, and the single-head and acyclicity con- straints are kept in A by removing offending arcs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Non-Monotonic Approximate Dynamic Oracle</head><p>To successfully train a non-monotonic system, we need a dynamic oracle with error exploration, so that the parser will be put in erroneous states and need to apply non-monotonic transitions in or- der to repair them. To achieve that, we modify the dynamic oracle defined by <ref type="bibr">Gómez-Rodríguez and Fernández-González (2015)</ref> so that it can deal with non-monotonicity. Our modification is an ap- proximate dynamic oracle: due to the extra flexib- ility added to the algorithm by non-monotonicity, we do not know of an efficient way of obtaining an exact calculation of the loss of a given configura- tion. Instead, we use upper or lower bounds on the loss, which we empirically show to be very tight (less that 1% relative error with respect to the real loss) and are sufficient for the algorithm to provide better accuracy than the exact monotonic oracle. First of all, we adapt the computation of the set of individually unreachable arcs U(c, t G ) to the new algorithm. In particular, if c has focus words i and j (i.e., c = λ 1 |i, λ 2 , j|B, A), then an arc x → y is in U(c, t G ) if it is not in A, and at least one of the following holds:</p><p>• j &gt; max(x, y), (i.e., we have read too far in the string and can no longer get max(x, y) as</p><note type="other">Shift: λ1, λ2, j|B, A ⇒ λ1 · λ2|j, [], B, A No-Arc:</note><p>λ1|i, λ2, B, A ⇒ λ1, i|λ2, B, A Left-Arc: λ1|i, λ2, j|B, A ⇒ λ1, i|λ2, j|B, (A ∪ {j → i}) <ref type="figure">Figure 2</ref>: Transitions of the non-monotonic Covington non-projective dependency parser. The notation i → * j ∈ A means that there is a (possibly empty) directed path from i to j in A.</p><formula xml:id="formula_6">\{x → i ∈ A} \ {k → j ∈ A | i → * k ∈ A}} Right-Arc: λ1|i, λ2, j|B, A ⇒ λ1, i|λ2, j|B, A ∪ {i → j} \{x → j ∈ A} \ {k → i ∈ A | j → * k ∈ A}}</formula><p>right focus word), • j = max(x, y) ∧ i &lt; min(x, y) (i.e., <ref type="bibr">we</ref> have max(x, y) as the right focus word but the left focus word has already moved left past min(x, y), and we cannot move it back). Note that, since the head of a node can change during the parsing process and arcs that produce cycles in A can be built, the two last conditions present in the monotonic scenario for comput- ing U(c, t G ) are not needed when we use non- monotonicity and, as a consequence, the set of individually reachable arcs I(c, t G ) is larger: due to the greater flexibility provided by non- monotonicity, we can reach arcs that would be un- reachable for the monotonic version.</p><p>Since arcs that are in this new U(c, t G ) are unreachable even by the non-monotonic parser, |U(c, t G )| is trivially a lower bound of the loss (c). It is worth noting that there always exists at least one transition sequence that builds every arc in I(c, t G ) at some point (although not all of them necessarily appear in the final tree, due to non-monotonicity). This can be easily shown based on the fact that the non-monotonic parser does not forbid transitions at any configuration. Thanks to this, we can can generate one such se- quence by just applying the original Covington (2001) criteria (choose an arc transition whenever the focus words are linked in I(c, t G ), and oth- erwise Shift or No-Arc depending on whether the left focus word is the first word in the sentence or not), although this sequence is not necessar- ily optimal in terms of loss. In such a transition sequence, the gold arcs that are missed are (1) those in U(c, t G ), and (2) those that are removed by the cycle-breaking in Left-Arc and Right-Arc transitions. In practice configurations where (2) is needed are uncommon, so this lower bound is a very close approximation of the real loss, as will be seen empirically below.</p><p>This reasoning also helps us calculate an up- per bound of the loss: in a transition sequence as described, if we only build the arcs in I(c, t G ) and none else, the amount of arcs removed by breaking cycles (2) cannot be larger than the num- ber of cycles in A ∪ I(c, t G ). This means that |U(c, t G )|+n c <ref type="figure">(A∪I(c, t G )</ref>) is an upper bound of the loss (c). Note that, contrary to the monotonic case, this expression does not always give us the exact loss, for several reasons: firstly, A ∪ I(c, t G ) can have non-disjoint cycles (a node may have different heads in A and I since attachments are not permanent, contrary to the monotonic ver- sion) and thus removing a single arc may break more than one cycle; secondly, the removed arc can be a non-gold arc of A and therefore not in- cur loss; and thirdly, there may exist alternative transition sequences where a cycle in A ∪ I(c, t G ) is broken early by non-monotonic configurations that change the head of a wrongly-attached node in A to a different (and also wrong) head, 3 remov- ing the cycle before the cycle-breaking mechanism needs to come into play without incurring in extra errors. Characterizing the situations where such an alternative exists is the main difficulty for an exact calculation of the loss. However, it is possible to obtain a closer upper bound to the real loss if we consider the following: for each cycle in A ∪ I(c, t G ) that will be broken by the transition sequence described above, we can determine exactly which is the arc removed by cycle-breaking (if x → y is the arc that will close the cycle according to the Covington arc-building order, then the affected arc is the one of the form z → x). The cycle can only cause the loss of a gold arc if that arc z → x is gold, which can be trivially checked. Hence, if we call cycles where that holds problematic cycles, then the expression   <ref type="table">Table 1</ref>: Average value of the different bounds and the loss, and of the relative differences from each bound to the loss, on CoNLL-XI (first block) and CoNLL-X (second block) datasets during 100,000 transitions. For each language, we show in boldface the average value and relative difference of the bound that is closer to the loss.</p><formula xml:id="formula_7">|U(c, t G )| + n pc (A ∪ I(c, t G ))</formula><p>, where "pc" stands for problematic cycles, is a closer upper bound to the loss (c) and the following holds:</p><formula xml:id="formula_8">|U(c, t G )| ≤ (c) ≤ |U(c, t G )|+n pc (A∪I(c, t G )) ≤ |U(c, t G )| + n c (A ∪ I(c, t G ))</formula><p>As mentioned before, unlike the monotonic ap- proach, a node can have a different head in A than in I(c, t G ) and, as a consequence, the result- ing graph A ∪ I(c, t G ) has maximum in-degree 2 rather than 1, and there can be overlapping cycles. Therefore, the computation of the non-monotonic terms n c (A ∪ I(c, t G )) and n pc (A ∪ I(c, t G )) re- quires an algorithm such as the one by <ref type="bibr" target="#b11">Johnson (1975)</ref> to find all elementary cycles in a directed graph. This runs in O((n + e)(c + 1)), where n is the number of vertices, e is the number of edges and c is the number of elementary cycles in the graph. This implies that the calculation of the two non-monotonic upper bounds is less efficient than the linear loss computation in the monotonic scenario. However, a non-monotonic algorithm that uses the lower bound as loss expression is the fastest option (even faster than the monotonic ap- proach) as the oracle does not need to compute cycles at all, speeding up the training process.</p><p>Algorithm 2 shows the non-monotonic vari- ant of Algorithm 1, where COUNTRELEVANT- CYCLES is a function that counts the number of cycles or problematic cycles in the given graph, Algorithm 2 Computation of the approximate loss of a non-monotonic configuration.</p><p>1: function LOSS(c = λ1|i, λ2, j|B, A, tG) 2:</p><formula xml:id="formula_9">U ← ∅ Variable U is for U(c, tG) 3: for each x → y ∈ (tG \ A) do 4: left ← min(x, y) 5: right ← max(x, y) 6: if j &gt; right ∨ 7: (j = right ∧ i &lt; left) then 8: U ← u ∪ {x → y} 9:</formula><p>I ← tG \ U Variable I is for I(c, tG) 10:</p><p>return |U | + COUNTRELEVANTCYCLES(A ∪ I ) depending on the upper bound implemented, and will return 0 in case we use the lower bound.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation of the Loss Bounds</head><p>To determine how close the lower bound |U(c, t G )| and the upper bounds |U(c, t G )| + n pc (A∪I(c, t G )) and |U(c, t G )|+n c (A∪I(c, t G )) are to the actual loss in practical scenarios, we use exhaustive search to calculate the real loss of a given configuration, to then compare it with the bounds. This is feasible because the lower and up- per bounds allow us to prune the search space: if an upper and a lower bound coincide for a con- figuration we already know the loss and need not keep searching, and if we can branch to two con- figurations such that the lower bound of one is greater or equal than an upper bound of the other, we can discard the former as it will never lead to smaller loss than the latter. Therefore, this ex-</p><formula xml:id="formula_10">Unigrams L0w; L0p; L0wp; L0l; L 0h w; L 0h p; L 0h l; L 0l w; L 0l p; L 0l l; L 0r w; L 0r p; L 0r l; L 0h2 w; L 0h2 p; L 0h2 l; L 0l w;</formula><p>L 0l p; L 0l l; L0rw; L0rp; L0rl; L0wd; L0pd; L0wvr; L0pvr; L0wv l ; L0pv l ; L0ws l ; L0ps l ; L0wsr; L0psr; L1w; L1p; L1wp; R0w; R0p; R0wp; R 0h w; R 0h p;R 0h l; R 0h2 w; R 0h2 p; R 0l w; R 0l p; R 0l l; R 0l w; R 0l p; R 0l l; R0wd; R0pd; R0wv l ; R0pv l ; R0ws l ; R0ps l ; R1w; R1p; R1wp; R2w; R2p; R2wp; CLw; CLp; CLwp; CRw; CRp; CRwp; Pairs L0wp+R0wp; L0wp+R0w; L0w+R0wp; L0wp+R0p; L0p+R0wp; L0w+R0w; L0p+R0p; R0p+R1p; L0w+R0wd; L0p+R0pd; Triples R0p+R1p+R2p; L0p+R0p+R1p; L 0h p+L0p+R0p; L0p+L 0l p+R0p; L0p+L 0r p+R0p; L0p+R0p+R 0l p; L0p+L 0l p+L 0l p; L0p+L 0r p+L0rp; L0p+L 0h p+L 0h2 p; R0p+R 0l p+R 0l p; <ref type="table">Table 2</ref>: Feature templates. L 0 and R 0 denote the left and right focus words; L 1 , L 2 , . . . are the words to the left of L 0 and R 1 , R 2 , . . . those to the right of R 0 . X ih means the head of X i , X ih2 the grandparent, X il and X il the farthest and closest left dependents, and X ir and X ir the farthest and closest right dependents, respectively. CL and CR are the first and last words between L 0 and R 0 whose head is not in the interval [L 0 , R 0 ]. Finally, w stands for word form; p for PoS tag; l for de- pendency label; d is the distance between L 0 and R 0 ; v l , v r are the left/right valencies (number of left/right dependents); and s l , s r the left/right label sets (dependency labels of left/right dependents).</p><p>haustive search with pruning guarantees to find the exact loss. Due to the time complexity of this process, we undertake the analysis of only the first 100,000 transitions on each dataset of the nineteen lan- guages available from CoNLL-X and CoNLL-XI shared tasks ( <ref type="bibr" target="#b0">Buchholz and Marsi, 2006;</ref>. In <ref type="table">Table 1</ref>, we present the average values for the lower bound, both upper bounds and the loss, as well as the relative differences from each bound to the real loss. After those experiments, we conclude that the lower and the closer upper bounds are a tight approximation of the loss, with both bounds incurring relative er- rors below 0.8% in all datasets. If we compare them, the real loss is closer to the upper bound |U(c, t G )| + n pc <ref type="figure">(A ∪ I(c, t G )</ref>) in the majority of datasets (12 out of 18 languages, excluding Ja- panese where both bounds were exactly equal to the real loss in the whole sample of configura- tions). This means that the term n pc <ref type="figure">(A ∪ I(c, t G )</ref>) provides a close approximation of the gold arcs missed by the presence of cycles in A. Regard- ing the upper bound |U(c, t G )| + n c <ref type="figure">(A ∪ I(c, t G )</ref>), it presents a more variable relative error, ranging from 0.1% to 4.0%.</p><p>Thus, although we do not know an algorithm to obtain the exact loss which is fast enough to be practical, any of the three studied loss bounds can be used to obtain a feasible approximate dynamic oracle with full non-monotonicity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head><p>To prove the usefulness of our approach, we im- plement the static, dynamic monotonic and non- monotonic oracles for the non-projective Coving- ton algorithm and compare their accuracies on nine datasets 4 from the CoNLL-X shared task ( <ref type="bibr" target="#b0">Buchholz and Marsi, 2006</ref>) and all datasets from the CoNLL-XI shared task ( . For the non-monotonic algorithm, we test the three different loss expressions defined in the previous section. We train an averaged perceptron model for 15 iterations and use the same feature tem- plates for all languages 5 which are listed in detail in <ref type="table">Table 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Results</head><p>The accuracies obtained by the non-projective Covington parser with the three available oracles are presented in <ref type="table">Table 3</ref>, in terms of Unlabeled (UAS) and Labeled Attachment Score (LAS). For the non-monotonic dynamic oracle, three variants are shown, one for each loss expression implemen- ted. As we can see, the novel non-monotonic or- acle improves over the accuracy of the monotonic version on 14 out of 19 languages (0.32 in UAS on average) with the best loss calculation being |U(c, t G )| + n c <ref type="figure">(A ∪ I(c, t G )</ref>), where 6 of these improvements are statistically significant at the .05 level <ref type="bibr" target="#b22">(Yeh, 2000</ref>). The other two loss calculation methods also achieve good results, outperforming the monotonic algorithm on 12 out of 19 datasets tested.</p><p>The loss expression |U(c, t G )| + n c (A ∪ I(c, t G )) obtains greater accuracy on average than the other two loss expressions, including the more adjusted upper bound that is provably closer to the real loss. This could be explained by the fact that dynamic dynamic <ref type="table">non-monotonic  static  monotonic  lower  pc upper  upper  Language  UAS  LAS  UAS  LAS  UAS  LAS  UAS  LAS  UAS</ref>    identifying problematic cycles is a difficult task to learn for the parser, and for this reason a more straightforward approach, which tries to avoid all kinds of cycles (regardless of whether they will cost gold arcs or not), can perform better. This also leads us to hypothesize that, even if it were feas- ible to build an oracle with the exact loss, it would not provide practical improvements over these ap- proximate oracles; as it appears difficult for a stat- istical model to learn the situations where repla- cing a wrong arc with another indirectly helps due to breaking prospective cycles.</p><p>It is also worth mentioning that the non- monotonic dynamic oracle with the best loss ex- pression accomplishes an average improvement over the static version (1.26 UAS) greater than that obtained by the monotonic oracle (0.98 UAS), res- ulting in 13 statistically significant improvements achieved by the non-monotonic variant over the static oracle in comparison to the 12 obtained by the monotonic system. Finally, note that, despite this remarkable performance, the non-monotonic version (regardless of the loss expression imple- mented) has an inexplicable drop in accuracy in Basque in comparison to the other two oracles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Comparison</head><p>In order to provide a broader contextualization of our approach, <ref type="table" target="#tab_4">Table 4</ref> presents a comparison of the average accuracy and parsing speed ob- tained by some well-known transition-based sys- tems with dynamic oracles. Concretely, we in- clude in this comparison both monotonic <ref type="bibr" target="#b4">(Goldberg and Nivre, 2012</ref>) and non-monotonic <ref type="bibr" target="#b9">(Honnibal et al., 2013</ref>) versions of the arc-eager parser, as well as the original monotonic Covington sys- tem <ref type="bibr">(Gómez-Rodríguez and Fernández-González, 2015)</ref>. The three of them were ran with our own implementation so the comparison is homo- geneous. We also report the published accuracy of the non-projective Attardi algorithm ( <ref type="bibr">GómezRodríguez et al., 2014</ref>) on the nineteen datasets used in our experiments. From <ref type="table" target="#tab_4">Table 4</ref> we can see that our approach achieves the best average UAS score, but is slightly slower at parsing time than the monotonic Covington algorithm. This can be explained by the fact that the non-monotonic parser has to take into consideration the whole set of transitions at each configuration (since all are allowed), while the monotonic parser only needs to evaluate a limited set of transitions in some con-  All al- gorithms are tested under our own implementa- tion, except for the system developed by <ref type="bibr">GómezRodríguez et al. (2014)</ref> (marked with *) where we report the published results.</p><p>figurations, speeding up the parsing process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Error Analysis</head><p>We also carry out some error analysis to provide some insights about how non-monotonicity is im- proving accuracy with respect to the original Cov- ington parser. In particular, we notice that non- monotonicity tends to be more beneficial on pro- jective than on non-projective arcs. In addi- tion, the non-monotonic algorithm presents a not- able performance on long arcs (which are more prone to error propagation): average precision on arcs with length greater than 7 goes from 58.41% in the monotonic version to 63.19% in the non-monotonic parser, which may mean that non-monotonicity is alleviating the effect of er- ror propagation. Finally, we study the effective- ness of non-monotonic arcs (i.e., those that break a previously-created arc), obtaining that, on aver- age across all datasets tested, 36.86% of the arc transitions taken were non-monotonic, replacing an existing arc with a new one. Out of these trans- itions, 60.31% created a gold arc, and only 5.99% were harmful (i.e., they replaced a previously-built gold arc with an incorrect arc), with the remain- ing cases creating non-gold arcs without introdu- cing extra errors (replacing a non-gold arc with another). These results back up the usefulness of non-monotonicity in transition-based parsing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We presented a novel, fully non-monotonic vari- ant of the well-known non-projective Covington parser, trained with a dynamic oracle. Due to the unpredictability of a non-monotonic scenario, the real loss of each configuration cannot be com- puted. To overcome this, we proposed three differ- ent loss expressions that closely bound the loss and enable us to implement a practical non-monotonic dynamic oracle.</p><p>On average, our non-monotonic algorithm ob- tains better performance than the monotonic ver- sion, regardless of which of the variants of the loss calculation is used. In particular, one of the loss expressions developed proved very promising by providing the best average accuracy, in spite of being the farthest approximation from the ac- tual loss. On the other hand, the proposed lower bound makes the non-monotonic oracle the fastest one among all dynamic oracles developed for the non-projective Covington algorithm.</p><p>To our knowledge, this is the first im- plementation of non-monotonicity for a non- projective parsing algorithm, and the first approx- imate dynamic oracle that uses close, efficiently- computable approximations of the loss, showing this to be a feasible alternative when it is not prac- tical to compute the actual loss.</p><p>While we used a perceptron classifier for our ex- periments, our oracle could also be used in neural- network implementations of greedy transition- based parsing <ref type="bibr" target="#b1">(Chen and Manning, 2014;</ref><ref type="bibr" target="#b3">Dyer et al., 2015)</ref>, providing an interesting avenue for future work. We believe that gains from both tech- niques should be complementary, as they apply to orthogonal components of the parsing system (the scoring model vs. the transition system), although we might see a "diminishing returns"effect.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>average</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>3 :</head><label>3</label><figDesc>Parsing accuracy (UAS and LAS, including punctuation) of the Covington non-projective parser with static, and dynamic monotonic and non-monotonic oracles on CoNLL-XI (first block) and CoNLL- X (second block) datasets. For the dynamic non-monotonic oracle, we show the performance with the three loss expressions, where lower stands for the lower bound |U(c, t G )|, pc upper for the upper bound |U(c, t G )| + n pc (A ∪ I(c, t G )), and upper for the upper bound |U(c, t G )| + n c (A ∪ I(c, t G )). For each language, we run five experiments with the same setup but different seeds and report the averaged accuracy. Best results for each language are shown in boldface. Statistically significant improvements (α = .05) of both dynamic oracles are marked with * if they are only over the static oracle, and with † if they are over the opposite dynamic oracle too.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table</head><label></label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>295</head><label>295</label><figDesc></figDesc><table>Average value 
Algorithm 
UAS 
LAS 
sent./s. 
G&amp;N 2012 
84.32 77.68 833.33 
G-R et al. 2014* 
83.78 78.64 
-
G-R&amp;F-G 2015 
84.46 77.92 335.63 
H et al. 2013 
84.28 77.68 847.33 
This work 
84.74 78.24 236.74 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Comparison of the average Unlabeled 
and Labeled Attachment Scores (including punc-
tuation) achieved by some widely-used transition-
based algorithms with dynamic oracles on nine 
CoNLL-X datasets and all CoNLL-XI datatsets, 
as well as their average parsing speed (sen-
tences per second across all datasets) measured 
on a 2.30GHz Intel Xeon processor. The first 
block corresponds to monotonic parsers, while the 
second gathers non-monotonic parsers. </table></figure>

			<note place="foot" n="2"> In general A is a forest, but it can be converted to a tree by linking headless nodes as dependents of an artificial root node at position 0. When we refer to parser outputs as trees, we assume that this transformation is being implicitly made.</note>

			<note place="foot" n="3"> Note that, in this scenario, the new head must also be wrong because otherwise the newly created arc would be an arc of I(c, tG) (and therefore, would not be breaking a cycle in A ∪ I(c, tG)). However, replacing a wrong attachment with another wrong attachment need not increase loss.</note>

			<note place="foot" n="4"> We excluded the languages from CoNLL-X that also appeared in CoNLL-XI, i.e., if a language was present in both shared tasks, we used the latest version. 5 No feature optimization is performed since our priority in this paper is not to compete with state-of-the-art systems, but to prove, under uniform experimental settings, that our approach outperforms the baseline system.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and in-novation programme (grant agreement No 714150-FASTPARSE). The second author has re-ceived funding from the TELEPARES-UDC pro-ject (FFI2014-51978-C2-2-R) from MINECO.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">CoNLL-X shared task on multilingual dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabine</forename><surname>Buchholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erwin</forename><surname>Marsi</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/W06-2920" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL)</title>
		<meeting>the 10th Conference on Computational Natural Language Learning (CoNLL)</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="149" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A fast and accurate dependency parser using neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/D14-1082" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="750" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A fundamental algorithm for dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Covington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th Annual ACM Southeast Conference</title>
		<meeting>the 39th Annual ACM Southeast Conference<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="95" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Transitionbased dependency parsing with stack long shortterm memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Austin</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P15-1033" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="334" to="343" />
		</imprint>
	</monogr>
	<note>Long Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A dynamic oracle for arc-eager dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/C12-1059" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2012. Association for Computational Linguistics</title>
		<meeting>COLING 2012. Association for Computational Linguistics<address><addrLine>Mumbai, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="959" to="976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Training deterministic parsers with non-deterministic oracles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="403" to="414" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An efficient dynamic oracle for unrestricted non-projective parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Gómez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Rodríguez</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Fernándezgonzález</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/P/P15/P15-2042.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2015-07-26" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="256" to="261" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Divisible transition systems and multiplanar dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Gómez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Rodríguez</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="799" to="845" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A polynomial-time dynamic oracle for non-projective dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Gómez-Rodríguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Sartorio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgio</forename><surname>Satta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="917" to="927" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A non-monotonic arc-eager transition system for dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Honnibal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/W/W13/W13-3518.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth Conference on Computational Natural Language Learning</title>
		<meeting>the Seventeenth Conference on Computational Natural Language Learning<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-08-08" />
			<biblScope unit="page" from="163" to="172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">An improved non-monotonic transition system for dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Honnibal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/D15-1162" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1373" to="1378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Finding all the elementary circuits of a directed graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Donald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Johnson</surname></persName>
		</author>
		<idno type="doi">10.1137/0204007</idno>
		<ptr target="tps://doi.org/10.1137/0204007" />
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="77" to="84" />
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Characterizing the errors of data-driven dependency parsing models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the</title>
		<meeting>the</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<title level="m">Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)</title>
		<imprint>
			<biblScope unit="page">122</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">An efficient algorithm for projective dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Workshop on Parsing Technologies (IWPT 03). ACL/SIGPARSE</title>
		<meeting>the 8th International Workshop on Parsing Technologies (IWPT 03). ACL/SIGPARSE</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="149" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Algorithms for Deterministic Incremental Dependency Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="513" to="553" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title/>
		<idno type="doi">10.1162/coli.07-056-R1-07-027</idno>
		<ptr target="https://doi.org/10.1162/coli.07-056-R1-07-027" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The CoNLL 2007 shared task on dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandra</forename><surname>Kübler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Nilsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deniz</forename><surname>Yuret</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL</title>
		<meeting>the CoNLL Shared Task Session of EMNLP-CoNLL</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="915" to="932" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Depth-first search and linear graph algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Robert Endre Tarjan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J</title>
		<imprint>
			<date type="published" when="1972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title/>
		<ptr target="http://dblp.uni-trier.de/db/journals/siamcomp/siamcomp1.html" />
	</analytic>
	<monogr>
		<title level="j">Comput</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="146" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Performance-Oriented Dependency Parsing. Doctoral dissertation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Volokh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<pubPlace>Saarbrücken, Germany</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Saarland University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Dependency parsing with efficient feature extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Volokh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Günter</forename><surname>Neumann</surname></persName>
		</author>
		<idno type="doi">10.1007/978-3-642-33347-7</idno>
		<ptr target="https://doi.org/10.1007/978-3-642-33347-7" />
	</analytic>
	<monogr>
		<title level="j">Lecture Notes in Computer Science</title>
		<editor>Birte Glimm and Antonio Krüger</editor>
		<imprint>
			<biblScope unit="volume">7526</biblScope>
			<biblScope unit="page" from="253" to="256" />
			<date type="published" when="2012" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">More accurate tests for the statistical significance of result differences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Yeh</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/C/C00/C00-2137.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th International Conference on Computational Linguistics (COLING)</title>
		<meeting>the 18th International Conference on Computational Linguistics (COLING)</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="947" to="953" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
