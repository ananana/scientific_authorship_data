<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:52+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Novel Measure for Coherence in Statistical Topic Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>August 7-12, 2016. 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fred</forename><surname>Morstatter</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Arizona State University Tempe</orgName>
								<address>
									<settlement>Arizona</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Arizona State University Tempe</orgName>
								<address>
									<settlement>Arizona</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Novel Measure for Coherence in Statistical Topic Models</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="543" to="548"/>
							<date type="published">August 7-12, 2016. 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Big data presents new challenges for understanding large text corpora. Topic mod-eling algorithms help understand the underlying patterns, or &quot;topics&quot;, in data. Re-searchersauthor often read these topics in order to gain an understanding of the underlying corpus. It is important to evaluate the interpretability of these automatically generated topics. Methods have previously been designed to use crowdsourcing platforms to measure interpretability. In this paper, we demonstrate the necessity of a key concept, coherence, when assessing the topics and propose an effective method for its measurement. We show that the proposed measure of coherence captures a different aspect of the topics than existing measures. We further study the automation of these topic measures for scalabil-ity and reproducibility, showing that these measures can be automated.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Big data poses new challenges in analyzing text corpora. Topic modeling algorithms have recently grown to popularity for their ability to help dis- cover the underlying topics in a corpus. Topic words are the words selected to represent a topic. They have been shown to be useful in the ar- eas of machine learning, text analysis <ref type="bibr" target="#b5">(Grimmer and Stewart, 2013)</ref>, and social media analy- sis <ref type="bibr" target="#b16">(O'Connor et al., 2010</ref>), among others. Topic models can be used as predictive models to clas- sify new documents in the context of the train- ing corpus. They are evaluated by measuring their predictive performance on a held-out set of docu- ments. Topic models can also be inspected man- ually by a human to understand the themes of the underlying corpus. A widely adopted way is suggested by <ref type="bibr" target="#b3">(Chang et al., 2009)</ref>: it measures the quality of a topic by inspecting how far topic words are from some random words. The idea is that the quality of a topic can be measured by how far topic words are from some random words. In other words, if human evaluators can consistently separate random words from topic words, these topics are good, otherwise, they are not good. An advantage of this measure is that it can be easily implemented to deploy on a crowd-sourcing plat- form like Amazon's Mechanical Turk.</p><p>Assuming that random words represent random topics, we can name the above method "between- topic" measure. In this paper, we hypothesize that this measure considers just one important as- pect in assessing the quality of statistical topics. Specifically, we investigate the topic interpretabil- ity by examining the "coherence" of a topic gener- ated by topic modeling algorithms, i.e., how close topic words are within a topic. Thus, this mea- sure is a "within-topic" measure. Two immedi- ate challenging questions are: (1) without know- ing ground truth of topic coherence, how can we design an equally effective method like "between- topic" measure for crowd-sourcing evaluation? and (2) how different is this "within-topic" coher- ence measure from the existing "between-topic" measure? We elaborate how we answer these two challenges by starting with some related work, showing how the "between-topic" measure faces difficulty in measuring coherence, and presenting our proposal of a coherence measure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Topic modeling is pervasive, and has been widely accepted across many communities such as ma- chine learning and social sciences ( <ref type="bibr" target="#b18">Ramage et al., 2009;</ref><ref type="bibr" target="#b19">Schmidt, 2012;</ref><ref type="bibr" target="#b22">Yang et al., 2011</ref>). One of the reasons for the wide appreciation of these al- gorithms is their ability to find underlying topics in enormous sets of data <ref type="bibr" target="#b1">(Blei, 2012)</ref>. More re- cently topic modeling has been widely applied to social media data ( <ref type="bibr" target="#b9">Kireyev et al., 2009;</ref><ref type="bibr" target="#b8">Joseph et al., 2012;</ref>), e.g. <ref type="bibr" target="#b23">(Yin et al., 2011;</ref><ref type="bibr" target="#b6">Hong et al., 2012;</ref><ref type="bibr" target="#b17">Pozdnoukhov and Kaiser, 2011</ref>) focus on identifying topics in geographical Twitter datasets. In ( <ref type="bibr" target="#b10">Kumar et al., 2013;</ref><ref type="bibr" target="#b14">Mimno et al., 2011)</ref>, the authors had to employ subject- matter experts to assess topic quality. These man- ual topic labels can be supplemented with auto- matic labeling algorithms ( <ref type="bibr" target="#b12">Maiya et al., 2013)</ref>. While these works attempt to ensure topic qual- ity by employing domain experts, these are highly domain-specific cases. The measures we discuss going forward are more general, and can be ap- plied to topic models trained with text data.</p><p>The most important point of comparison be- tween our work and others lies in the Model Pre- cision measure proposed in ( <ref type="bibr" target="#b3">Chang et al., 2009)</ref>. The insight of this measure is that a good topic is one whose top few words are distant, or highly separate, from randomly-selected words. Their task works by showing several human participants, or Turker, the top 5 words from a topic and one randomly-chosen, low-ranking "intruded" word. The humans are then asked to select the word that they think was intruded. The measure then esti- mates the topic's quality by calculating the number of times the humans correctly guessed the intruded word. While Word Intrusion provides insight into a topic's interpretability, the key assumption is that topic goodness comes only from the top words be- ing separate from a randomly-selected word. This measure does not offer any insight about the co- herence of the top words. We propose a new mea- sure which complements Word Intrusion by mea- suring distance within a topic.</p><p>( <ref type="bibr" target="#b11">Lau et al., 2014</ref>) built a machine learning algo- rithm to automatically detect the intruded word in a topic. Methods for evaluating topic models were proposed in ( <ref type="bibr" target="#b21">Wallach et al., 2009</ref>). We investigate the applicability of this measure in our work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model Precision Quandary</head><p>Model Precision works by asking the user to choose the word that does not fit within the rest of the set. We are measuring the top words in the topic by comparing them to an outlier. While this method has merit, it does not help us understand the coherence within the top words for the topic.</p><p>A diagram illustrating this phenomenon is shown in <ref type="figure">Figure 1</ref>. In <ref type="figure">Figure 1</ref>(a), we see a co- herent topic. This topic is coherent because all 5 of the top words are close together, while the intruded word is far away. In <ref type="figure">Figure 1</ref>(b) we see a topic that is less coherent because the fifth word lies at a distance from the first four. In both cases, Model Precision gives us the intruder word in the topic, as seen in <ref type="figure">Figures 1(c)</ref>, and 1(d). While this is the de- sired performance of Model Precision, it leaves us with no understanding of the coherence of the top words of the topic. Results are masked by the out- lier, and do not give information about the intra- cluster distance, or coherence of the topic.</p><p>In light of this, we look for a way to separate topics not just by their distance from an outlier, but also by the distance within the top words in the topic. The next section of this paper investigates a method which can measure not just the intruder word, but also the coherence of the top words in the topic. In this way we separate topics such as those shown in <ref type="figure">Figure 1</ref> based on the coherence of their top words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Word Intrusion Choose Two</head><p>In this section we propose a new experiment that measures the interpretability of the top words of a topic. This experiment sets up the task as be- fore: we select the top five words from a topic, and inject one low-probability word. The key dif- ference is that we ask the Turker to select two in- truded words among the six.</p><p>The intuition behind this experiment is that the Turkers' first choice will be the intruded word, just as in Model Precision. However, their second choice is what makes the topic's quality clear. In a coherent topic the Turkers won't be able to distin- guish a second word as all of the words will seem similar. A graphical representation of this phe- nomenon is shown in <ref type="figure">Figure 1</ref>(e). In the case of an incoherent, a strong "second-place" contender will emerge as the Turkers identify a 2nd intruder word, as in <ref type="figure">Figure 1</ref>(f).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Setup</head><p>To perform this experiment, we inject one low- probability word for each topic, and we ask the Turkers to select two words that do not fit within the group. We show the six words to the Turker in random order with the following prompt: You will be shown six words. Four words belong to- gether, and two of them do not. Choose two words that do not belong in the group.</p><p>Coherent topics will cause the Turkers' re- sponses regarding the second intruded word to be unpredictable. Thus, our measure of the good- ness of the topic should be the predictability of the Turkers' second choice. We propose a new measure called "Model Precision Choose Two" to measure this. Model Precision Choose Two (MPCT) measures this spread as the peakedness of the probability distribution. We define M P CT m k for topic k on model m as: The intuition behind choosing entropy is that it will measure the unpredictability in the Turker selections. That is, if the Turkers are confused about which second word to choose, then their answers will be scattered amongst the remaining five words. As a result, the entropy will be high. Conversely, if the second word is obvious, the Turkers will begin to congregate around that sec- ond choice, meaning that their answers will be fo- cused. As a result, the entropy will be low. Be- cause entropy is able to measure the confusion of the Turkers responses about the second word, we use it directly in the design of our measure.</p><formula xml:id="formula_0">M P CT m k = H(p turk (w m k,1 ), ..., p turk (w m k,5 )),<label>(1)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Data</head><p>The data used in this study consists of articles from English Wikipedia. We sample 10,000 articles uniformly at random from across the dataset. We selected articles containing more than 50 words. In preprocessing we stripped case, removed punc- tuation, stopwords, and words consisting entirely of numbers. This process yields a corpus con- taining 10,000 documents, 4,200,174 tokens, and  <ref type="bibr" target="#b13">(McCallum, 2002)</ref>. This yields 4 models and 185 total topics. The model generated by each value of K is denoted by m in the equations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Experimental Results</head><p>The results of this experiment, aggregated by model, are shown in <ref type="figure" target="#fig_2">Figure 2</ref>. We see that as the value of K increases, the median score for MPCT stays roughly the same. We compute the Spear- man's ρ correlation coefficient <ref type="bibr" target="#b20">(Spearman, 1904)</ref> between the M P and M P CT measures, and find that the measures have ρ = 0.09. This lack of cor- relation indicates that this measure is assessing a different dimension of the topics.</p><p>To help explain these results, we provide some examples of topics that received different MPCT scores with a perfect separateness (MP) score in <ref type="table" target="#tab_0">Table 1</ref>. We see that although all of the topics have perfect scores along this dimension, their co- hesiveness score varies. This is due to the Turkers' agreement about the second intruded word.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Automating Model Precision Choose Two</head><p>The crowdsourced experiments carried out in this paper provide a complementary understanding of how humans understand the topics that are gener- ated using statistical topic models. One drawback of these methods lies in the difficulty of repro- ducing these experiments. This difficulty comes from two sources: 1) the monetary cost of employ- ing the Turkers to solve the HITs, and 2) the time cost to build the surveys and to collect the results. To overcome these issues, we propose automated methods that can estimate the topics' performance along these different dimensions. These measures can be used by future researchers to automatically gauge their topics.</p><p>We test several automated measures for their ability to predict the outcome of the crowdsourced measures. To test these measures, we calculate the Spearman's ρ between the automated measure of the topic and the crowdsourced measure. The au- tomated measures we propose are as follows:</p><p>1. Topic Size: LDA assigns a topic label to each token in the dataset. Topic size measures the number of tokens assigned to the topic by the LDA model, where more tokens indicates a larger topic. This has been tested in <ref type="bibr" target="#b14">(Mimno et al., 2011</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Topic Entropy:</head><p>The entropy of the entire probability distribution for the topic. High entropy indicates a flat distribution of proba- bilities, while low entropy indicates a peaked distribution around the first few words.</p><p>3. Mimno Co-Occurrence: Measures the fre- quency of the top words co-occurring within the same document. Proposed in <ref type="bibr" target="#b14">(Mimno et al., 2011)</ref>, and measured as: where w is the vector of the top 20 words in the topic, and D(·) returns the number of times the words co-occur in any document in the corpus.</p><formula xml:id="formula_1">M CO(w) = |w| j=2 j−1 k=1 log D(w j , w k ) + 1 D(w k ) ,<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">No. Word Senses:</head><p>The total number of word senses, according to WordNet, of the top five words in the topic. This varies slightly from the measure proposed in ( <ref type="bibr" target="#b3">Chang et al., 2009)</ref>, where the authors also consider the intruded word. Because the intruded word is generally far away, we exclude it from our calculation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Avg. Pairwise Jiang-Conrath Distance:</head><p>The Jiang-Conrath (Jiang and Conrath, 1997) distance (JCD) is a measure of semantic sim- ilarity, or coherence, that considers the low- est common subsumer according to Word- Net. Here we compute the average JCD of all 5 2 = 10 pairs of the top five words of the topic. This approach was introduced by <ref type="bibr" target="#b3">(Chang et al., 2009</ref>), however we modify it slightly to only consider the top five words in the topic.</p><p>6. Mean-Link JCD: Using the JCD measure as before, we compute the average distance from the intruded word to each of the top 5 words from the topic.</p><p>7. Normalized Pointwise Mutual Informa- tion (NPMI): NPMI measures the associa- tion between the top words in a topic. It is normalized to yield a score of 1 in the case of perfect association. This measure was first introduced by <ref type="bibr" target="#b2">(Bouma, 2009)</ref>. We use the calculation adapted for the problem of estimating a topic's performance introduced in ( <ref type="bibr" target="#b11">Lau et al., 2014</ref>).</p><p>We calculate the correlation between all au- tomated methods and MPCT, shown in <ref type="table" target="#tab_1">Table 2</ref>. MPCT is best predicted using the Avg. Pairwise JCD measure. The implications of this result are important: MPCT is best predicted by JCD, a mea- sure that approximates the coherence of topics. Furthermore the correlations are negative, indicat- ing that a low average distance (and thus, a high semantic similarity) indicates a high performance along this automated measure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>In this work we define a new measure for the per- formance of statistical topic models. We show that this measure gauges a different aspect of the top- ics than the traditional model precision measure. Finally, we identify automated measures that can approximate the crowdsourced measures for both interpretability and coherence. This measure can be used by future researchers to complement their analysis of statistical topics. The results from our experiments indicate that Word Intrusion Choose Two is different from Word Intrusion, with almost no correlation between the two measures.</p><p>Furthermore, we propose automatic measures that can replace the crowdsourced measures. This is important as it allows for both scalability and reproducibility, as experiments using crowdsourc- ing are costly in terms of both time and money. We find that measures based on the interpretabil- ity of topics can best approximate the Model Precision Choose Two measure, indicating that this measure favors topics whose top words are more semantically similar, furthering our claim that this measure is assessing the coherence of the topic. Code and data to reproduce Model Preci- sion Choose Two can be found at http://bit. ly/mpchoose2.</p><p>While model precision choose two offers a new way to understand topics, there may be others that could help to reveal other dimensions of topic quality. Future work is to find other measures for the semantic properties of topic modeling algo- rithms. Furthermore, the automated measures we discover to approximate the crowdsourced ones may be incorporated into a topic modeling algo- rithm that can better produce interpretable topics.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Figure 1: Comparison between Model Precision, and Model Precision Choose Two for a toy topic. Circles represent the top words and triangles represent intruded words. Model Precision Choose Two can distinguish the less-coherent topic.</figDesc><graphic url="image-1.png" coords="3,348.59,272.23,131.86,68.47" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>where H(·) is the Shannon entropy (Cover and Thomas, 2006), w m k is the vector of the top words in topic k generated by model m, and p turk (w m k,i ) is the probability that a Turker selects w m k,i . This measures the strength of the second-place candi- date, with higher values indicating a smoother, more even distribution, and lower values indicat- ing Turkers gravitation towards a second word.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Model Precision Choose Two across the four models used in this work. Higher scores are better. We see that as K increases, the median score does not improve noticeably.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 : Example topics showing the variance of M P CT when M P = 1.0.</head><label>1</label><figDesc></figDesc><table>MPCT Top Five Words 
Intruded Word 

0.202 
canada, canadian, north, ontario, http 
shipping 
0.373 
language, century, word, english, greek drew 
0.407 
river, highway, road, north, route 
berea 
0.569 
born, children, family, life, father 
boatsman 
0.795 
design, engine, model, power, system 
resynthesized 
0.946 
railway, station, road, line, route 
anagarika 
1.000 
film, series, show, television, films 
bubblegrunge 

196,219 types. 
The topic modeling algorithm used is latent 
Dirichlet allocation (LDA) (Blei et al., 2003). To 
build the models used in the experiments, we 
run LDA on the Wikipedia corpus using values 
of K = {10, 25, 50, 100} with the Mallet pack-
age </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Performance of automated measures in 
approximating the crowdsourced experiments. All 
values are Spearman's ρ correlation coefficients 
with the crowdsourced measure. 

Automated Measure MPCT 

1. Topic Size 
-0.572 
2. Topic Entropy 
-0.539 
3. Mimno 
-0.438 
4. No. Word Senses 
-0.456 
5. Avg. Pairwise JCD 
-0.844 
6. Mean-Link JCD 
-0.434 
7. NPMI 
-0.582 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work is sponsored, in part, by Office of Naval Research (ONR) grant N000141410095.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Latent Dirichlet Allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Topic modeling and digital humanities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Digital Humanities</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="8" to="11" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Normalized (pointwise) mutual information in collocation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerlof</forename><surname>Bouma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of GSCL</title>
		<meeting>GSCL</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="31" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Reading tea leaves: How humans interpret topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><forename type="middle">L</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Gerrish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="288" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Elements of Information Theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Thomas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>Wiley InterScience</publisher>
			<pubPlace>Hoboken, New Jersey</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Text as data: The promise and pitfalls of automatic content analysis methods for political texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Grimmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brandon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stewart</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Political Analysis</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Discovering geographical topics in the twitter stream</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangjie</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amr</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siva</forename><surname>Gurumurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Tsioutsiouliklis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st international conference on World Wide Web, WWW &apos;12</title>
		<meeting>the 21st international conference on World Wide Web, WWW &apos;12<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="769" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Semantic similarity based on corpus statistics and lexical taxonomy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David W</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Conrath</surname></persName>
		</author>
		<idno>cmp-lg/9709008</idno>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Beyond &quot;local&quot;, &quot;categories&quot; and &quot;friends&quot;: clustering foursquare users with latent &quot;topics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun</forename><forename type="middle">How</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><forename type="middle">M</forename><surname>Carley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 ACM Conference on Ubiquitous Computing, UbiComp &apos;12</title>
		<meeting>the 2012 ACM Conference on Ubiquitous Computing, UbiComp &apos;12<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="919" to="926" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Applications of Topics Models to Analysis of DisasterRelated Twitter Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kireyev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Palen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop on Applications for Topic Models: Text and Beyond</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Whom Should I Follow?: Identifying Relevant Users During Crises</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shamanth</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fred</forename><surname>Morstatter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reza</forename><surname>Zafarani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM Conference on Hypertext and Social Media, HT &apos;13</title>
		<meeting>the 24th ACM Conference on Hypertext and Social Media, HT &apos;13<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="139" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Machine reading tea leaves: Automatically evaluating topic coherence and topic model quality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jey Han</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Exploratory analysis of highly heterogeneous document collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Arun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">P</forename><surname>Maiya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert M</forename><surname>Loaizalemos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rolfe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 19th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1375" to="1383" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Mallet: A machine learning for language toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<ptr target="http://mallet.cs.umass.edu" />
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Optimizing semantic coherence in topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mimno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanna</forename><forename type="middle">M</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edmund</forename><surname>Talley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miriam</forename><surname>Leenders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;11</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;11<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="262" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Is the Sample Good Enough? Comparing Data from Twitters Streaming API with Twitters Firehose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fred</forename><surname>Morstatter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Pfeffer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><forename type="middle">M</forename><surname>Carley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICWSM</title>
		<meeting>ICWSM</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Tweetmotif: Exploratory search and topic summarization for twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O&amp;apos;</forename><surname>Brendan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Krieger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICWSM</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Space-time dynamics of topics in streaming text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><surname>Pozdnoukhov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Kaiser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 3rd ACM SIGSPATIAL Int&apos;l Workshop on Location-Based Social Networks, LBSN &apos;11</title>
		<meeting>of the 3rd ACM SIGSPATIAL Int&apos;l Workshop on Location-Based Social Networks, LBSN &apos;11<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Topic modeling for the social sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Ramage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Rosen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel A</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcfarland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS 2009 Workshop on Applications for Topic Models: Text and Beyond</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Words alone: Dismantling topic models in the humanities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Benjamin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schmidt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Digital Humanities</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="49" to="65" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">The proof and measurement of association between two things. The American journal of psychology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Spearman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1904" />
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="72" to="101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Evaluation methods for topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iain</forename><surname>Hanna M Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mimno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1105" to="1112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Topic modeling on historical newspapers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-I</forename><surname>Tze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Torget</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mihalcea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th ACL-HLT Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities</title>
		<meeting>the 5th ACL-HLT Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="96" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Geographical topic discovery and comparison</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangliang</forename><surname>Zhijun Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th international conference on World wide web, WWW &apos;11</title>
		<meeting>the 20th international conference on World wide web, WWW &apos;11<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="247" to="256" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
