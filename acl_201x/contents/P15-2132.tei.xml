<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:07+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Compact Lexicon Selection with Spectral Methods</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Bum</forename><surname>Kim</surname></persName>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Stratos</surname></persName>
							<email>stratos@cs.columbia.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">Columbia University</orgName>
								<address>
									<settlement>New York</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohu</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Corporation</orgName>
								<address>
									<settlement>Redmond</settlement>
									<region>WA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Compact Lexicon Selection with Spectral Methods</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="806" to="811"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In this paper, we introduce the task of selecting compact lexicon from large, noisy gazetteers. This scenario arises often in practice, in particular spoken language understanding (SLU). We propose a simple and effective solution based on matrix decomposition techniques: canonical correlation analysis (CCA) and rank-revealing QR (RRQR) factorization. CCA is first used to derive low-dimensional gazetteer embeddings from domain-specific search logs. Then RRQR is used to find a subset of these embeddings whose span approximates the entire lexicon space. Experiments on slot tagging show that our method yields a small set of lexicon entities with average relative error reduction of &gt; 50% over randomly selected lexicon.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Discriminative models trained with large quanti- ties of arbitrary features are a dominant paradigm in spoken language understanding (SLU) ( <ref type="bibr" target="#b3">Celikyilmaz et al., 2013;</ref><ref type="bibr" target="#b14">Liu and Sarikaya, 2014;</ref><ref type="bibr" target="#b0">Anastasakos et al., 2014;</ref><ref type="bibr" target="#b17">Xu and Sarikaya, 2014;</ref><ref type="bibr" target="#b4">Celikyilmaz et al., 2015;</ref><ref type="bibr" target="#b9">Kim et al., 2015a;</ref><ref type="bibr" target="#b11">Kim et al., 2015c;</ref><ref type="bibr" target="#b10">Kim et al., 2015b</ref>). An impor- tant category of these features comes from entity dictionaries or gazetteers-lists of phrases whose labels are given. For instance, they can be lists of movies, music titles, actors, restaurants, and cities. These features enable SLU models to ro- bustly handle unseen entities at test time.</p><p>However, these lists are often massive and very noisy. This is because they are typically obtained automatically by mining the web for recent en- tries (such as newly launched movie names). Ide- ally, we would like an SLU model to have access to this vast source of information at deployment. But this is difficult in practice because an SLU model needs to be light-weight to support fast user interaction. It becomes more challenging when we consider multiple domains, languages, and lo- cales.</p><p>In this paper, we introduce the task of selecting a small, representative subset of noisy gazetteers that will nevertheless improve model performance nearly as much as the original lexicon. This will allow an SLU model to take full advantage of gazetteer resources at test time without being over- whelmed by their scale.</p><p>Our selection method is two steps. First, we gather relevant information for each gazetteer ele- ment using domain-specific search logs. Then we perform CCA using this information to derive low- dimensional gazetteer embeddings <ref type="bibr" target="#b7">(Hotelling, 1936)</ref>. Second, we use a subset selection method based on RRQR to locate gazetteer embeddings whose span approximates the the entire lexicon space ( <ref type="bibr" target="#b1">Boutsidis et al., 2009;</ref><ref type="bibr" target="#b8">Kim and Snyder, 2013)</ref>. We show in slot tagging experiments that the gazetteer elements selected by our method not only preserve the performance of using full lexi- con but even improve it in some cases. Compared to random selection, our method achieves average relative error reduction of &gt; 50%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Motivation</head><p>We motivate our task by describing the process of lexicon construction. Entity dictionaries are usually automatically mined from the web us- ing resources that provide typed entities. On a regular basis, these dictionaries are automati- cally updated and accumulated based on local data feeds and knowledge graphs. Local data feeds are generated from various origins (e.g., yellow pages, Yelp). Knowledge graphs such as www. freebase.com are resources that define a se- mantic space of entities (e.g., movie names, per-sons, places and organizations) and their relations.</p><p>Because of the need to keep dictionaries up- dated to handle newly emerging entities, lexicon construction is designed to aim for high recall at the expense of precision. Consequently, the result- ing gazetteers are noisy. For example, a movie dic- tionary may contain hundreds of thousands movie names, but many of them are false positives.</p><p>While this large base of entities is useful as a whole, it is challenging to take advantage of at test time. This is because we normally cannot afford to consume so much memory when we deploy an SLU model in practice. In the next section, we will describe a way to filter these entities while retaining their overall benefit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Row subset selection problem</head><p>We frame gazetteer element selection as the row subset selection problem. In this framework, we organize n gazetteer elements as matrix A ∈ R n×d whose rows A i ∈ R d are some representations of the gazetteer members. Given m ≤ n, let S(A, m) := {B ∈ R m×d : B i = A π(i) } be a set of matrices whose rows are a subset of the rows of A. Note that |S(A, m)| = n m . Our goal is to</p><formula xml:id="formula_0">select 1 B * = arg min B∈S(A,m) A − AB + B F</formula><p>That is, we want B to satisfy range(B ) ≈ range(A ). We can solve for B * exactly with exhaustive search in O(n m ), but this brute-force approach is clearly not scalable. Instead, we turn to the O(nd 2 ) algorithm of Boutsidis et al. <ref type="formula">(2009)</ref> which we review below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">RRQR factorization</head><p>A key ingredient in the algorithm of <ref type="bibr" target="#b1">Boutsidis et al. (2009)</ref> is the use of RRQR factorization. Recall that a (thin) QR factorization of A expresses A = QR where Q ∈ R n×d has orthonormal columns and R ∈ R d×d is an upper triangular matrix. A limitation of QR factorization is that it does not assign a score to each of the d components. This is in contrast to singular value decomposition (SVD) which assigns a score (singular value) indicating the importance of these components. <ref type="bibr">1</ref> The Frobenius norm ||M ||F is defined as the entry-wise</p><formula xml:id="formula_1">L2 norm: i,j m 2 ij . B + is the Moore-Penrose pseudo- inverse of B Input: d-dimensional gazetteer representations A ∈ R n×d , number of gazetteer elements to select m ≤ n Output: m rows of A, call B ∈ R m×d , such that A − AB + B F is small</formula><p>• Perform SVD on A and let U ∈ R d×m be a ma- trix whose columns are the left singular vectors cor- responding to the largest m singular values.</p><p>• Associate a probability pi with the i-th row of A as follows:</p><p>pi := min 1, m log m ||Ui|| 2 m</p><p>• Discard the i-th row of A with probability 1 − pi.</p><p>If kept, the row is multiplied by 1/ √ pi. Let these O(m log m) rows form the columns of a new matrix ¯ A ∈ R d×O(m log m) .</p><p>• Perform RRQR on ¯ A to obtain ¯ AΠ = QR.</p><p>• Return the m rows of the original A corresponding to the top m columns of ¯ AΠ. RRQR factorization is a less well-known vari- ant of QR that addresses this limitation. Let σ i (M ) denote the i-th largest singular value of matrix M . Given A, RRQR jointly finds a permutation matrix Π ∈ {0, 1} d×d , orthonor- mal Q ∈ R n×d , and upper triangular R = [R 11 R 12 ; 0 R 22 ] ∈ R d×d such that</p><formula xml:id="formula_2">AΠ = Q R 11 R 12 R 22 satisfying σ k (R 11 ) = O(σ k (A)) and σ 1 (R 22 ) = Ω(σ k+1 (A)) for k = 1 . . . d.</formula><p>Because of this rank- ing property, RRQR "reveals" the numerical rank of A. Furthermore, the columns of AΠ are sorted in the order of decreasing importance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Gazetteer selection algorithm</head><p>The algorithm is a two-stage procedure. In the first step, we randomly sample O(m log m) rows of A with carefully chosen probabilities and scale them to form columns of matrix ¯ A ∈ R d×O(m log m) . In the second step, we perform RRQR factoriza- tion on ¯ A and collect the gazetteer elements cor- responding to the top components given by the RRQR permutation. The algorithm is shown in <ref type="figure" target="#fig_0">Figure 1</ref>. The first stage involves random sam- pling and scaling of rows, but it is shown that ¯ A has O(m log m) columns with constant probabil- ity. This algorithm has the following optimality guarantee:</p><p>Theorem 3.1 ( <ref type="bibr" target="#b1">Boutsidis et al. (2009)</ref>). LetˆBLetˆ LetˆB ∈ R m×d be the matrix returned by the algorithm in <ref type="figure" target="#fig_0">Figure 1</ref>. Then with probability at least 0.7,</p><formula xml:id="formula_3">A − A ˆ B + ˆ B F ≤ O(m log m)× miñ miñ A∈R n×d : rank( ˜ A)=m A − ˜ A F</formula><p>In other words, the selected rows are not arbi- trarily worse than the best rank-m approximation of A (given by SVD) with high probability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Gazetteer embeddings via CCA</head><p>In order to perform the selection algorithm in <ref type="figure" target="#fig_0">Fig- ure 1</ref>, we need a d-dimensional representation for each of n gazetteer elements. We use CCA for its simplicity and generality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Canonical Correlation Analysis (CCA)</head><p>CCA is a general statistical technique that char- acterizes the linear relationship between a pair of multi-dimensional variables. CCA seeks to find k dimensions (k is a parameter to be specified) in which these variables are maximally correlated.</p><p>Let x 1 . . . x n ∈ R d and y 1 . . . y n ∈ R d be n samples of the two variables. For simplicity, as- sume that these variables have zero mean. Then CCA computes the following for i = 1 . . . k:</p><p>arg max</p><formula xml:id="formula_4">u i ∈R d , v i ∈R d : u i u i =0 ∀i &lt;i v i v i =0 ∀i &lt;i n l=1 (u i x l )(v i y l ) n l=1 (u i x l ) 2 n l=1 (v i y l ) 2</formula><p>In other words, each (u i , v i ) is a pair of projec- tion vectors such that the correlation between the projected variables u i x l and v i y l is maximized, under the constraint that this projection is uncor- related with the previous i − 1 projections. This is a non-convex problem due to the inter- action between u i and v i . However, a method based on singular value decomposition (SVD) pro- vides an efficient and exact solution to this prob- lem <ref type="bibr" target="#b7">(Hotelling, 1936)</ref>. The resulting solution u 1 . . . u k ∈ R d and v 1 . . . v k ∈ R d can be used to project the variables from the original d-and d -dimensional spaces to a k-dimensional space:</p><formula xml:id="formula_5">x ∈ R d −→ ¯ x ∈ R k : ¯ x i = u i x y ∈ R d −→ ¯ y ∈ R k : ¯ y i = v i y</formula><p>The new k-dimensional representation of each variable now contains information about the other variable. The value of k is usually selected to be much smaller than d or d , so the representation is typically also low-dimensional.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Inducing gazetteer embeddings</head><p>We now describe how to use CCA to induce vec- tor representations for gazetteer elements. Using the same notation, let n be the number of elements in the entire gazetteers. Let x 1 . . . x n be the orig- inal representations of the element samples and y 1 . . . y n be the original representations of the as- sociated features in the element. We employ the following definition for the orig- inal representations. Let d be the number of dis- tinct element types and d be the number of distinct feature types.</p><p>• x l ∈ R d is a zero vector in which the entry corresponding to the element type of the l-th instance is set to 1.</p><p>• y l ∈ R d is a zero vector in which the en- tries corresponding to features generated by the element are set to 1.</p><p>In our case, we want to induce gazetteer (ele- ment) embeddings that correlate with the relevant features about gazetteers. For this purpose, we use three types of features: context features, search click log features, and knowledge graph features.</p><p>Context features: For each gazetteer element g of domain l, we take sentences from search logs on domain l containing g and extract five words each to the left and the right of the element g in the sentences. For instance, if g = "The Matrix" is a gazetteer element of domain l = "Movie", we collect sentences from movie-specific search logs involving the phrase "The Matrix". Such domain-specific search logs are collected using a pre-trained domain classifier.</p><p>Search click log features: Large-scale search engines such as Bing and Google process mil- lions of queries on a daily basis. Together with the search queries, user clicked URLs are also logged anonymously. These click logs have been used for extracting semantic information for var- ious NLP tasks ( <ref type="bibr" target="#b9">Kim et al., 2015a;</ref><ref type="bibr" target="#b16">Tseng et al., 2009;</ref><ref type="bibr" target="#b5">Hakkani-Tür et al., 2011</ref>). We used the clicked URLs as features to determine the likeli- hood of an entity being a member of a dictionary. These features are useful because common URLs are shared across different names such as movie, business and music. <ref type="table">Table 1</ref> shows the top five most frequently clicked URLs for movies "Furi- ous 7" and "The age of adaline".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Furious 7</head><p>The One issue with using only click logs is that some entities may not be covered in the query logs since logs are extracted from a limited time frame (e.g. six months). Even the big search engines employ a moving time window for processing and stor- ing search logs. Consequently, click logs are not necessarily good evidence. For example, "apollo thirteen" is a movie name appearing in the movie training data, but it does not appear in search logs. One way to solve the issue of missing logs for en- tities is to search bing.com at real time. Given that the search engine is updated on a daily ba- sis, real-time search can make sure we capture the newest entities. We run live search for all entities no matter if they appear in search logs or not. Each URL returned from the live search is considered to have an additional click.</p><p>Knowledge graph features: The graph in www.freebase.com contains a large set of tu- ples in a resource description framework (RDF) defined by W3C. A tuple typically consists of two entities: a subject and an object linked by some relation.</p><p>An interesting part of this resource is the entity type defined in the graph for each entity. In the knowledge graph, the "type" relation represents the entity type. <ref type="table" target="#tab_2">Table 2</ref> shows some examples of entities and their relations in the knowledge graph. From the graph, we learn that "Romeo &amp; Juliet" could be a film name or a music album since it has two types: "film.film" and "music.album".  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>To test the effectiveness of the proposed gazetteer selection method, we conduct slot tagging experi- ments across a test suite of three domains: Movies, Music and Places, which are very sensitive do- mains to gazetteer features. The task of slot tag- ging is to find the correct sequence of tags of words given a user utterance. For example, in Places domain, a user could say "search for home depot in kingsport" and the phrase "home depot" and "kingsport" are tagged with Place Name and Location respectively. The data statistics are shown in <ref type="table">Table 3</ref>. One domain can have var- ious kinds of gazetteers. For example, Places do- main has business name, restaurant name, school name and etc. Candidate dictionaries are mined from the web and search logs automatically using basic pattern matching approaches (e.g. entities sharing the same or similar context in queries or documents) and consequently contain significant amount of noise. As the table indicates, the num- ber of elements in total across all the gazetteers (#total gazet elements) in each domain are too large for models to consume. In all our experiments, we trained conditional random fields (CRFs) ( <ref type="bibr" target="#b12">Lafferty et al., 2001</ref>) with the following features: (1) n-gram features up to n = 3, (2) regular expression features, and (3) Brown clusters ( <ref type="bibr" target="#b2">Brown et al., 1992</ref>) induced from search logs. With these features, we compare the following methods to demonstrate the importance of adding appropriate gazetteers:</p><p>• NoG: train without gazetteer features.</p><p>• AllG: train with all gazetteers.</p><p>• RandG: train with randomly selected gazetteers.</p><p>• RRQRG: train with gazetteers selected from RRQR.</p><p>• RankAllG: train with all ranked gazetteers. <ref type="table" target="#tab_2">Movies  25  21  14,188,527  43,784  12,179  Music  7  13  62,231,869  31,853  8,615  Places  32  31  34,227,612  22,345  6,143   Table 3: Data statistics</ref> Here gazetteer features are activated when a phrase contains an entity in a dictionary. For RandG, we first sample a category of gazetteers uniformly and then choose a lexicon from gazetteers in that category. The results when we use selected gazetteer randomly in whole cate- gories are very low and did not include them here. For selecting gazetteer methods (NoG, RnadG and RRQRG), we select 500,000 elements in total.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Domains #labels #kinds of gazets #total gazet elements #training queries #test queries</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Results across Domains</head><p>First, we evaluate all models across three do- mains. Note that the both training and test data are collected from the United States. The results are shown in <ref type="table" target="#tab_4">Table 4</ref>. Not surprisingly, using all gazetteer features (AllG) boosts the F1 score from 85.14 % to 88.30%, confirming the power of gazetteer features. However, with a random selection of gazetteers, the model does not per- form well, only achieving 79.99% F1-score. In- terestingly, we see that across all domains our method (RRQRG) fares better than both RandG and NoG, almost reaching the AllG performance with gazetteer size dramatically reduced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results across Locales</head><p>In the size of test data is about 5k for each locale. The results are shown in <ref type="table" target="#tab_7">Table 5</ref>. Interestingly, the RRQR even outperforms the AllG. This is because some noisy entities are filtered.</p><p>Finally, we show that the proposed method is useful even in all gazetteer scenario (AllG). Us- ing RRQR, we can order entities according to their importance and transform a gazetteer fea- ture into a few ones by binning the entities with their rankings. For example, instead of having one single big business names gazetteer, we can divide them into lexicon with first 1000 entities, 10000 entities and so on. Results using ranked gazetteers are shown in <ref type="table" target="#tab_8">Table 6</ref>. We see that the Ranked gazetteers approach (RankAllG) has con- sistent gains across domains over AllG.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We proposed the task of selecting compact lexi- cons from large and noisy gazetteers. This sce- nario arises often in practice. We introduced a sim- ple and effective solution based on matrix decom- position techniques: CCA is used to derive low- dimensional gazetteer embeddings and RRQR is used to find a subset of these embeddings. Experi- ments on slot tagging show that our method yields relative error reduction of &gt; 50% on average over the random selection method.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Gazetteer selection based on the algorithm of Boutsidis et al. (2009).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 : Entities &amp; relation in the knowledge graph.</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Comparison of models evaluated on three do-

mains. The numbers are F1-scores. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 5 : Comparison of models across different locales.</head><label>5</label><figDesc></figDesc><table>Places Music Movies AVG. 
AllG 
92.11 
84.24 
88.56 
88.30 
RankAllG 92.78 
86.30 
89.1 
89.40 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Comparison of models with or without ranked 

gazetteers. These are evaluated on three domains collected 
in the United States. 

</table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Task specific continuous word representations for mono and multi-lingual spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tasos</forename><surname>Anastasakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Bum</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anoop</forename><surname>Deoras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3246" to="3250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An improved approximation algorithm for the column subset selection problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Boutsidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petros</forename><surname>Mahoney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Drineas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the twentieth Annual ACM-SIAM Symposium on Discrete Algorithms</title>
		<meeting>the twentieth Annual ACM-SIAM Symposium on Discrete Algorithms</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="968" to="977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Class-based n-gram models of natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Peter F Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">L</forename><surname>Desouza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent J Della</forename><surname>Mercer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenifer C</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="467" to="479" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Semi-supervised semantic tagging of conversational understanding using markov topic regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asli</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dilek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gökhan</forename><surname>Hakkani-Tür</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Tür</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sarikaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (1)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="914" to="923" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Enriching word embeddings using knowledge graph for semantic tagging in conversational dialog systems. AAAI-Association for the Advancement of Artificial Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asli</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panupong</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Employing web search query click logs for multi-domain spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tür</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gokhan</forename><surname>Tur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Heck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asli</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashley</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dustin</forename><surname>Hillard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rukmini</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Parthasarathy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Automatic Speech Recognition and Understanding Workshop, December</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning weighted entity lists from web click logs for spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dustin</forename><surname>Hillard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asli</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dilek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gökhan</forename><surname>Hakkanitür</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tür</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="705" to="708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Relations between two sets of variates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harold</forename><surname>Hotelling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3/4</biblScope>
			<biblScope unit="page" from="321" to="377" />
			<date type="published" when="1936" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Optimal data set selection: An application to graphemeto-phoneme conversion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Bum</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Snyder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1196" to="1205" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Weakly supervised slot tagging with partially labeled sequences from web search click logs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Bum</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeong</forename><surname>Minwoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Startos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="84" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Pre-training of hidden-unit crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Bum</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Stratos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">New transfer learning techniques for disparate label sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Bum</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Stratos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minwoo</forename><surname>Jeong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando Cn</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="282" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Extracting structured information from user queries with semi-supervised conditional random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye-Yi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Acero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 32nd international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A discriminative model based entity dictionary weighting approach for spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Spoken Language Technology Workshop (SLT)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="195" to="199" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Shrinkage based features for slot tagging with conditional random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Asli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anoop</forename><surname>Deoras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minwoo</forename><surname>Jeong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of ISCA-International Speech Communication Association</title>
		<meeting>eeding of ISCA-International Speech Communication Association</meeting>
		<imprint>
			<date type="published" when="2014-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Mining search engine clickthrough log for matching n-gram features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huihsin</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Longbin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziming</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Belle</forename><surname>Tseng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2009 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="524" to="533" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Targeted feature dropout for robust slot filling in natural language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Puyang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA-International Speech Communication Association</title>
		<imprint>
			<date type="published" when="2014-09" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
