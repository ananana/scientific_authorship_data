<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:39+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Joint Modeling of Content and Discourse Relations in Dialogues</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kechen</forename><surname>Qin</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Kim</surname></persName>
						</author>
						<title level="a" type="main">Joint Modeling of Content and Discourse Relations in Dialogues</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</title>
						<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="974" to="984"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-1090</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present a joint modeling approach to identify salient discussion points in spoken meetings as well as to label the discourse relations between speaker turns. A variation of our model is also discussed when discourse relations are treated as latent variables. Experimental results on two popular meeting corpora show that our joint model can outperform state-of-the-art approaches for both phrase-based content selection and discourse relation prediction tasks. We also evaluate our model on predicting the consistency among team members&apos; understanding of their group decisions. Classifiers trained with features constructed from our model achieve significant better predictive performance than the state-of-the-art.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>We present a joint modeling approach to iden- tify salient discussion points in spoken meet- ings as well as to label the discourse rela- tions between speaker turns. A variation of our model is also discussed when discourse relations are treated as latent variables. Ex- perimental results on two popular meeting cor- pora show that our joint model can outperform state-of-the-art approaches for both phrase- based content selection and discourse rela- tion prediction tasks. We also evaluate our model on predicting the consistency among team members' understanding of their group decisions. Classifiers trained with features constructed from our model achieve signif- icant better predictive performance than the state-of-the-art.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Goal-oriented dialogues, such as meetings, nego- tiations, or customer service transcripts, play an important role in our daily life. Automatically ex- tracting the critical points and important outcomes from dialogues would facilitate generating sum- maries for complicated conversations, understand- ing the decision-making process of meetings, or analyzing the effectiveness of collaborations.</p><p>We are interested in a specific type of dia- logues -spoken meetings, which is a common way for collaboration and idea sharing. Previ- ous work <ref type="bibr" target="#b16">(Kirschner et al., 2012</ref>) has shown that discourse structure can be used to capture the main discussion points and arguments put forward during problem-solving and decision-making pro- cesses in meetings. Indeed, content of different speaker turns do not occur in isolation, and should be interpreted within the context of discourse. Meanwhile, content can also reflect the purpose of speaker turns, thus facilitate with discourse rela- tion understanding. Take the meeting snippet from D: Three different types of batteries. Um can either use a hand dynamo, or the kinetic type ones, you know that they use in watches, or else uh a solar powered one.</p><p>B: Um the bat uh the battery for a a watch wouldn't require a lot of power, would be my one query. Is a kinetic one going to be able to supply enough power? Here we highlight salient phrases (in italics) that are relevant to the major topic discussed, i.e., "which type of battery to use for the remote control". Arrows indicate discourse struc- ture between speaker turns. We also show some of the discourse relations for illustration.</p><formula xml:id="formula_0">D</formula><p>AMI corpus ) in <ref type="figure">Figure 1</ref> as an example. This discussion is annotated with dis- course structure based on the Twente Argumenta- tion Schema (TAS) by <ref type="bibr" target="#b33">Rienks et al. (2005)</ref>, which focuses on argumentative discourse information. As can be seen, meeting participants evaluate dif- ferent options by showing doubt (UNCERTAIN), bringing up alternative solution (OPTION), or giv- ing feedback. The discourse information helps with the identification of the key discussion point, i.e., "which type of battery to use", by revealing the discussion flow. To date, most efforts to leverage discourse in- formation to detect salient content from dialogues have focused on encoding gold-standard discourse relations as features for use in classifier train- ing ( <ref type="bibr" target="#b28">Murray et al., 2006;</ref><ref type="bibr" target="#b7">Galley, 2006;</ref><ref type="bibr" target="#b23">McKeown et al., 2007;</ref><ref type="bibr" target="#b1">Bui et al., 2009</ref>). However, automatic discourse parsing in dialogues is still a challenging problem <ref type="bibr" target="#b31">(Perret et al., 2016)</ref>. Moreover, acquiring human annotation on discourse relations is a time- consuming and expensive process, and does not scale for large datasets.</p><p>In this paper, we propose a joint modeling ap- proach to select salient phrases reflecting key dis- cussion points as well as label the discourse re- lations between speaker turns in spoken meet- ings. We hypothesize that leveraging the inter- action between content and discourse has the po- tential to yield better prediction performance on both phrase-based content selection and discourse relation prediction. Specifically, we utilize argu- mentative discourse relations as defined in Twente Argument Schema (TAS) ( <ref type="bibr" target="#b33">Rienks et al., 2005</ref>), where discussions are organized into tree struc- tures with discourse relations labeled between nodes (as shown in <ref type="figure">Figure 1</ref>). Algorithms for joint learning and joint inference are proposed for our model. We also present a variation of our model to treat discourse relations as latent variables when true labels are not available for learning. We en- vision that the extracted salient phrases by our model can be used as input to abstractive meeting summarization systems ( <ref type="bibr" target="#b38">Wang and Cardie, 2013;</ref><ref type="bibr" target="#b24">Mehdad et al., 2014)</ref>. Combined with the pre- dicted discourse structure, a visualization tool can be exploited to display conversation flow to sup- port intelligent meeting assistant systems.</p><p>To the best of our knowledge, our work is the first to jointly model content and discourse relations in meetings. We test our model with two meeting corpora -the AMI corpus ) and the ICSI corpus ( <ref type="bibr" target="#b12">Janin et al., 2003)</ref>. Experimental results show that our model yields an accuracy of 63.2 on phrase selec- tion, which is significantly better than a classifier based on Support Vector Machines (SVM). Our discourse prediction component also obtains bet- ter accuracy than a state-of-the-art neural network- based approach (59.2 vs. 54.2). Moreover, our model trained with latent discourse outperforms SVMs on both AMI and ICSI corpora for phrase selection. We further evaluate the usage of se- lected phrases as extractive meeting summaries. Results evaluated by ROUGE ( <ref type="bibr" target="#b18">Lin and Hovy, 2003</ref>) demonstrate that our system summaries ob- tain a ROUGE-SU4 F1 score of 21.3 on AMI corpus, which outperforms non-trivial extractive summarization baselines and a keyword selection algorithm proposed in <ref type="bibr" target="#b20">Liu et al. (2009)</ref>.</p><p>Moreover, since both content and discourse structure are critical for building shared under- standing among participants <ref type="bibr" target="#b26">(Mulder et al., 2002;</ref><ref type="bibr" target="#b25">Mercer, 2004)</ref>, we further investigate whether our learned model can be utilized to predict the con- sistency among team members' understanding of their group decisions. This task is first defined as consistency of understanding (COU) prediction by <ref type="bibr" target="#b15">Kim and Shah (2016)</ref>, who have labeled a por- tion of AMI discussions with consistency or in- consistency labels. We construct features from our model predictions to capture different discourse patterns and word entrainment scores for discus- sion with different COU level. Results on AMI discussions show that SVM classifiers trained with our features significantly outperform the state-of- the-art results <ref type="bibr" target="#b15">(Kim and Shah, 2016</ref>) (F1: 63.1 vs. 50.5) and non-trivial baselines.</p><p>The rest of the paper is structured as follows: we first summarize related work in Section 2. The joint model is presented in Section 3. Datasets and experimental setup are described in Section 4, which is followed by experimental results (Sec- tion 5). We then study the usage of our model for predicting consistency of understanding in groups in Section 6. We finally conclude in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Our model is inspired by research work that lever- ages discourse structure for identifying salient content in conversations, which is still largely reliant on features derived from gold-standard discourse labels ( <ref type="bibr" target="#b23">McKeown et al., 2007;</ref><ref type="bibr" target="#b27">Murray et al., 2010;</ref><ref type="bibr" target="#b0">Bokaei et al., 2016</ref>). For in- stance, adjacency pairs, which are paired utter- ances with question-answer or offer-accept rela- tions, are found to frequently appear in meeting summaries together and thus are utilized to extract summary-worthy utterances by <ref type="bibr" target="#b7">Galley (2006)</ref>. There is much less work that jointly predicts the importance of content along with the discourse structure in dialogus. <ref type="bibr" target="#b30">Oya and Carenini (2014)</ref> employs Dynamic Conditional Random Field to recognize sentences in email threads for use in summary as well as their dialogue acts. Only local discourse structures from adjacent utterances are considered. Our model is built on tree structures, which captures more global information.</p><p>Our work is also in line with keyphrase identifi- cation or phrase-based summarization for conver- sations. Due to the noisy nature of dialogues, re- cent work focuses on identifying summary-worthy phrases from meetings ( <ref type="bibr" target="#b6">Fernández et al., 2008;</ref><ref type="bibr" target="#b32">Riedhammer et al., 2010</ref>) or email threads <ref type="bibr" target="#b22">(Loza et al., 2014</ref>). For instance, <ref type="bibr" target="#b37">Wang and Cardie (2012)</ref> treat the problem as an information extrac- tion task, where summary-worthy content repre- sented as indicator and argument pairs is identi- fied by an unsupervised latent variable model. Our work also targets at detecting salient phrases from meetings, but focuses on the joint modeling of crit- ical discussion points and discourse relations held between them.</p><p>For the area of discourse analysis in dialogues, a significant amount of work has been done in pre- dicting local discourse structures, such as recog- nizing dialogue acts or social acts of adjacent ut- terances from phone conversations ( <ref type="bibr" target="#b36">Stolcke et al., 2000;</ref><ref type="bibr" target="#b14">Kalchbrenner and Blunsom, 2013;</ref><ref type="bibr" target="#b13">Ji et al., 2016)</ref>, spoken meetings ( <ref type="bibr" target="#b5">Dielmann and Renals, 2008)</ref>, or emails ( <ref type="bibr" target="#b4">Cohen et al., 2004</ref>). Although discourse information from non-adjacent turns has been studied in the context of online discussion fo- rums ( <ref type="bibr" target="#b8">Ghosh et al., 2014</ref>) and meetings <ref type="bibr">(HakkaniTur, 2009</ref>), none of them models the effect of dis- course structure on content selection, which is a gap that this work fills in.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The Joint Model of Content and Discourse Relations</head><p>In this section, we first present our joint model in Section 3.1. The algorithms for learning and in- ference are described in Sections 3.2 and 3.3, fol- lowed by feature description (Section 3.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Model Description</head><p>Our proposed model learns to jointly perform phrase-based content selection and discourse re- lation prediction by making use of the interac- tion between the two sources of information. As- sume that a meeting discussion is denoted as x, where x consists of a sequence of discourse units</p><formula xml:id="formula_1">x = {x 1 , x 2 , · · · , x n }.</formula><p>Each discourse unit can be a complete speaker turn or a part of it. As demon- strated in <ref type="figure">Figure 1</ref>, a tree-structured discourse dia- gram is constructed for each discussion with each discourse unit x i as a node of the tree. In this work, we consider the argumentative discourse structure by Twente Argument Schema (TAS) ( <ref type="bibr" target="#b33">Rienks et al., 2005</ref>). For each node x i , it is attached to another node x i (i &lt; i) in the discussion, and a discourse relation d i is hold on the link x i , x i (d i is empty if x i is the root). Let t denote the set of links x i , x i in x. Following previous work on dis- course analysis in meetings ( <ref type="bibr" target="#b33">Rienks et al., 2005;</ref><ref type="bibr" target="#b10">Hakkani-Tur, 2009</ref>), we assume that the attach- ment structure between discourse units are given during both training and testing. A set of candidate phrases are extracted from each discourse unit x i , from which salient phrases that contain gist information will be identified. We obtain constituent and dependency parses for ut- terances using Stanford parser <ref type="bibr" target="#b17">(Klein and Manning, 2003</ref>). We restrict eligible candidate to be a noun phrase (NP), verb phrase (VP), prepositional phrase (PP), or adjective phrase (ADJP) with at most 5 words, and its head word cannot be a stop word. <ref type="bibr">1</ref> If a candidate is a parent of another can- didate in the constituent parse tree, we will only keep the parent. We further merge a verb and a candidate noun phrase into one candidate if the later is the direct object or subject of the verb. For example, from utterance "let's use a rubber case as well as rubber buttons", we can identify can- didates "use a rubber case" and "rubber buttons". For x i , the set of candidate phrases are denoted as</p><formula xml:id="formula_2">c i = {c i,1 , c i,2 , · · · , c i,m i },</formula><p>where m i is the num- ber of candidates. c i,j takes a value of 1 if the cor- responding candidate is selected as salient phrase; otherwise, c i,j is equal to 0. All candidate phrases in discussion x are represented as c.</p><p>We then define a log-linear model with feature parameters w for the candidate phrases c and dis- course relations d in x as:</p><formula xml:id="formula_3">p(c, d|x, w) ∝ exp[w · Φ(c, d, x)] ∝ exp[w · n i=1,&lt;xi,x i &gt;∈t φ(c i , d i , d i , x)] ∝ exp[ n i=1,&lt;xi,x i &gt;∈t (w c · mi j=1 φ c (c i,j , x) + w d · φ d (d i , d i , x) + w cd · mi j=1 φ cd (c i,j , d i , x))] (1)</formula><p>Here Φ(·) and φ(·) denote feature vectors. We utilize three types of feature functions: (1) content-only features φ c (·), which capture the im- portance of phrases, (2) discourse-only features φ d (·), which characterize the (potentially higher- order) discourse relations, and (3) joint features of content and discourse φ cd (·), which model the in- teraction between the two. w c , w d , and w cd are corresponding feature parameters. Detailed fea- ture descriptions can be found in Section 3.4. Discourse Relations as Latent Variables. As we mentioned in the introduction, acquiring labeled training data for discourse relations is a time- consuming process since it would require human annotators to inspect the full discussions. There- fore, we further propose a variation of our model where it treats the discourse relations as latent variables, so that p(c|x, w) = d p(c, d|x, w). Its learning algorithm is slightly different as de- scribed in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Joint Learning for Parameter Estimation</head><p>For learning the model parameters w, we em- ploy an algorithm based on SampleRank <ref type="bibr" target="#b34">(Rohanimanesh et al., 2011</ref>), which is a stochastic struc- ture learning method. In general, the learning al- gorithm constructs a sequence of configurations for sample labels as a Markov chain Monte Carlo (MCMC) chain based on a task-specific loss func- tion, where stochastic gradients are distributed across the chain.</p><p>The full learning procedure is described in Al- gorithm 1. To start with, the feature weights w is initialized with each value randomly drawn from [−1, 1]. Multiple epochs are run through all sam- ples. For each sample, we randomly initialize the assignment of candidate phrases labels c and dis- course relations d. Then an MCMC chain is con- structed with a series of configurations σ = (c, d): at each step, it first samples a discourse structure d based on the proposal distribution q(d |d, x), and then samples phrase labels conditional on the new discourse relations and previous phrase labels based on q(c |c, d , x). Local search is used for both proposal distributions. <ref type="bibr">2</ref> The new configu- ration is accepted if it improves on the score by ω(σ ). The parameters w are updated accordingly.</p><p>For the scorer ω, we use a weighted combina- tion of F1 scores of phrase selection (F 1 c ) and</p><formula xml:id="formula_4">discourse relation prediction (F 1 d ): ω(σ) = α · F 1 c + (1 − α) · F 1 d . We fix α to 0.1.</formula><p>When discourse relations are treated as latent, we initialize discourse relations for each sample with a label in {1, 2, . . . , K} if there are K rela- tions indicated, and we only use F 1 c as the scorer.</p><p>Input : X = {x}: discussions in the training set, η: learning rate, : number of epochs, δ: number of sampling rounds, ω(·): scoring function, Φ(·): feature functions Output: feature weights 1</p><formula xml:id="formula_5">|W| w∈W w Initialize w; W ← {w}; for e = 1 to do for x in X do // Initialize configuration for x Initialize c and d; σ = (c, d); for s = 1 to δ do // New configuration via local search d ∼ q d (·|x, d); c ∼ q d (·|x, c, d ); σ = (c , d ); σ + = arg max˜σ∈{σmax˜ max˜σ∈{σ,σ } ω(˜ σ); σ − = arg miñ σ∈{σ,σ } ω(˜ σ); ˆ = Φ(σ + ) − Φ(σ − ); ∆ω = ω(σ + ) − ω(σ − ); // Update parameters if w · ˆ &lt; ∆ω &amp; ∆ω = 0 then w ← w + η · ˆ ; Add w in W; end // Accept or reject new configuration if σ + == σ then σ = σ end end end end</formula><p>Algorithm 1: SampleRank-based joint learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Joint Inference for Prediction</head><p>Given a new sample x and learned parameters w, we predict phrase labels and discourse relations as arg max c,d p(c, d|x, w).</p><p>Dynamic programming can be employed to carry out joint inference, however, it would be time-consuming since our objective func- tion has a large search space for both content and discourse labels. Hence we propose an alternating optimizing algorithm to search for c and d iteratively. Concretely, for each it- eration, we first optimize on d by maximiz- <ref type="bibr" target="#b35">Smith and Eisner, 2008</ref>) is used to find the best d.</p><formula xml:id="formula_6">ing n i=1,&lt;x i ,x i &gt;∈t (w d · φ d (d i , d i , x) + w cd · m i j=1 φ cd (c i,j , d i , x)). Message-passing (</formula><p>In the second step, we search for c that max-</p><formula xml:id="formula_7">imizes n i=1,&lt;x i ,x i &gt;∈t (w c · m i j=1 φ c (c i,j , x) + w cd · m i j=1 φ cd (c i,j , d i , x)</formula><p>). We believe that can- didate phrases based on the same concepts should have the same predicted label. Therefore, can- didates of the same phrase type and sharing the same head word are grouped into one cluster. We then cast our task as an integer linear programming problem. <ref type="bibr">3</ref> We optimize our objective function un- der constraints: (1) c i,j = c i ,j if c i,j and c i ,j are in the same cluster, and (2) c i,j ∈ {0, 1}, ∀i, j.</p><p>The inference process is the same for models trained with latent discourse relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Features</head><p>We use features that characterize content, dis- course relations, and the combination of both. Content Features. For modeling the salience of content, we calculate the minimum, maximum, and average of TF-IDF scores of words and number of content words in each phrase based on the intuition that important phrases tend to have more content words with high TF-IDF scores <ref type="bibr" target="#b6">(Fernández et al., 2008</ref>). We also consider whether the head word of the phrase has been mentioned in preceding turn, which implies the focus of a discus- sion.</p><p>The size of the cluster each phrase belongs to is also included. Number of POS tags and phrase types are counted to characterize the syntactic structure. Previous work ( <ref type="bibr" target="#b37">Wang and Cardie, 2012</ref>) has found that a discussion usually ends with decision-relevant information. We thus identify the absolute and relative positions of the turn con- taining the candidate phrase in the discussion. Finally, we record whether the candidate phrase is uttered by the main speaker, who speakers the most words in the discussion. Discourse Features. For each discourse unit, we collect the dialogue act types of the cur- rent unit and its parent node in discourse tree, whether there is any adjacency pair held be- tween the two nodes <ref type="bibr" target="#b10">(Hakkani-Tur, 2009)</ref>, and the Jaccard similarity between them. We record whether two turns are uttered by the same speaker, for example, ELABORATION is commonly observed between the turns from the same participant. We also calculate the number of candidate phrases based on the obser- vation that OPTION and SPECIALIZATION tend to contain more informative words than POSI- TIVE feedback. Length of the discourse unit is also relevant. Therefore, we compute the time span and number of words. To incorporate global structure features, we encode the depth of the node in the discourse tree and the <ref type="bibr">3</ref> We use lpsolve: http://lpsolve. sourceforge.net/5.5/. number of its siblings. Finally, we in- clude an order-2 discourse relation feature that encodes the relation between current discourse unit and its parent, and the relation be- tween the parent and its grandparent if it exists. Joint Features. For modeling the interaction be-</p><note type="other">tween content and discourse, the discourse rela- tion is added to each content feature to compose a joint feature. For example, if candidate c in discus- sion x has a content feature φ [avg−T F IDF ] (c, x) with a value of 0.5, and its discourse relation d is POSITIVE, then the joint feature takes the form of φ [avg−T F IDF,P ositive] (c, d, x) = 0.5.</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Datasets and Experimental Setup</head><p>Meeting Corpora. We evaluate our joint model on two meeting corpora with rich annotations: the AMI meeting corpus ) and the ICSI meeting corpus ( <ref type="bibr" target="#b12">Janin et al., 2003)</ref>. AMI corpus consists of 139 scenario-driven meetings, and ICSI corpus contains 75 naturally occurring meetings. Both of the corpora are annotated with dialogue acts, adjacency pairs, and topic segmen- tation. We treat each topic segment as one dis- cussion, and remove discussions with less than 10 turns or labeled as "opening" and "chitchat". 694 discussions from AMI and 1139 discussions from ICSI are extracted, and these two datasets are henceforth referred as AMI-FULL and ICSI-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FULL.</head><p>Acquiring Gold-Standard Labels. Both corpora contain human constructed abstractive summaries and extractive summaries on meeting level. Short abstracts, usually in one sentence, are constructed by meeting participants -participant summaries, and external annotators -abstractive summaries. Dialogue acts that contribute to important output of the meeting, e.g. decisions, are identified and used as extractive summaries, and some of them are also linked to the corresponding abstracts.</p><p>Since the corpora do not contain phrase-level importance annotation, we induce gold-standard labels for candidate phrases based on the follow- ing rule. A candidate phrase is considered as a positive sample if its head word is contained in any abstractive summary or participant summary. On average, 71.9 candidate phrases are identified per discussion for AMI-FULL with 31.3% labeled as positive, and 73.4 for ICSI-FULL with 24.0% of them as positive samples.</p><p>Furthermore, a subset of discussions in AMI-FULL are annotated with discourse structure and relations based on Twente Argumentation Schema (TAS) by <ref type="bibr" target="#b33">Rienks et al. (2005)</ref>  <ref type="bibr">4</ref> . A tree-structured argument diagram (as shown in <ref type="figure">Figure 1</ref>) is cre- ated for each discussion or a part of the discussion. The nodes of the tree contain partial or complete speaker turns, and discourse relation types are la- beled on the links between the nodes. In total, we have 129 discussions annotated with discourse la- bels. This dataset is called AMI-SUB hereafter. Experimental Setup. 5-fold cross validation is used for all experiments. All real-valued features are uniformly normalized to <ref type="bibr">[0,</ref><ref type="bibr">1]</ref>. For the joint learning algorithm, we use 10 epochs and carry out 50 sampling for MCMC for each training sample. The learning rate is set to 0.01. We run the learn- ing algorithm for 20 times, and use the average of the learned weights as the final parameter values. For models trained with latent discourse relations, we fix the number of relations to 9. Baselines and Comparisons. For both phrase- based content selection and discourse relation pre- diction tasks, we consider a baseline that always predicts the majority label (Majority). Previous work has shown that Support Vector Machines (SVMs)-based classifiers achieve state-of-the-art performance for keyphrase selection in meet- ings <ref type="bibr" target="#b6">(Fernández et al., 2008;</ref><ref type="bibr" target="#b38">Wang and Cardie, 2013)</ref> and discourse parsing for formal text <ref type="bibr" target="#b11">(Hernault et al., 2010</ref>). Therefore, we compare with linear SVM-based classifiers, trained with the same feature set of content features or discourse features. We fix the trade-off parameter to 1.0 for all SVM-based experiments. For discourse re- lation prediction, we use one-vs-rest strategy to build multiple binary classifiers. <ref type="bibr">5</ref> We also com- pare with a state-of-the-art discourse parser ( <ref type="bibr" target="#b13">Ji et al., 2016)</ref>, which employs neural language model to predict discourse relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Phrase Selection and Discourse Labeling</head><p>Here we present the experimental results on phrase-based content selection and discourse re- lation prediction. We experiment with two vari- ations of our joint model: one is trained on gold- standard discourse relations, the other is trained by <ref type="bibr">4</ref> There  treating discourse relations as latent models as de- scribed in Section 3.1. Remember that we have gold-standard argument diagrams on the AMI- SUB dataset, we can thus conduct experiments by assuming the True Attachment Structure is given for latent versions. When argument diagrams are not available, we build a tree among the turns in each discussion as follows. Two turns are attached if there is any adjacency pair between them. If one turn is attached to more than one previous turns, the closest one is considered. For the rest of the turns, they are attached to the preceding turn. This construction is applied on AMI-FULL and ICSI- FULL.</p><p>We also investigate whether joint learning and joint inference can produce better prediction per-</p><formula xml:id="formula_8">AMI-FULL ICSI-FULL Acc F1 Acc F1 Comparisons Baseline (Majority)</formula><p>61.8 38.2 75.3 43.0 SVM (with content features in § 3.4) 58.6 56.7 66.2 53.1 Our Models (Latent Discourse) Joint-Learn + Joint-Inference 63.4 * 63.0 * 73.5 * 61.4 * Joint-Learn + Separate-Inference 57.7 57.5 70.0 * 62.7 * formance. We consider joint learning with sepa- rate inference, where only content features or dis- course features are used for prediction (Separate- Inference). We further study learning separate classifiers for content selection and discourse re- lations without joint features (Separate-Learn).</p><p>We first show the phrase selection and discourse relation prediction results on AMI-SUB in Ta- bles 1 and 2. As shown in <ref type="table">Table 1</ref>, our models, trained with gold-standard discourse relations or latent ones with true attachment structure, yield significant better accuracy and F1 scores than SVM-based classifiers trained with the same fea- ture sets for phrase selection (paired t-test, p &lt; 0.05). Our joint learning model with separate inference also outperforms neural network-based discourse parsing model ( <ref type="bibr" target="#b13">Ji et al., 2016</ref>) in <ref type="table" target="#tab_1">Table 2</ref>.</p><p>Moreover, <ref type="table" target="#tab_1">Tables 1 and 2</ref> demonstrate that joint learning usually produces superior performance for both tasks than separate learning. Combined with joint inference, our model obtains the best ac- curacy and F1 on phrase selection. This indicates that leveraging the interplay between content and discourse boost the prediction performance. Sim- ilar results are achieved on AMI-FULL and ICSI- FULL in <ref type="table" target="#tab_2">Table 3</ref>, where latent discourse relations without true attachment structure are employed for training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Phrase-Based Extractive Summarization</head><p>We further evaluate whether the prediction of the content selection component can be used for sum- marizing the key points on discussion level. For each discussion, salient phrases identified by our model are concatenated in sequence for use as the summary. We consider two types of gold-standard summaries. One is utterance-level extractive sum- mary, which consists of human labeled summary- worthy utterances. The other is abstractive sum-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Extractive Summaries as Gold-Standard</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ROUGE-1 ROUGE-SU4 Len Prec Rec F1</head><p>Prec Rec F1 Longest DA 30.9 64.4 15.0 23.1 58.6 9.3 15.3 Centroid DA 17.5 73.9 13.4 20.8 62.5 6.9 11.3 SVM 49.8 47.1 24.1 27.5 22.7 10.7 11.8 <ref type="bibr" target="#b20">Liu et al. (2009)</ref>  mary, where we collect human abstract with at least one link from summary-worthy utterances. We calculate scores based on ROUGE ( <ref type="bibr" target="#b18">Lin and Hovy, 2003)</ref>, which is a popular tool for eval- uating text summarization ( <ref type="bibr" target="#b9">Gillick et al., 2009;</ref><ref type="bibr" target="#b19">Liu and Liu, 2010)</ref>. ROUGE-1 (unigrams) and ROUGE-SU4 (skip-bigrams with at most 4 words in between) are used. Following previous work on meeting summarization ( <ref type="bibr" target="#b32">Riedhammer et al., 2010;</ref><ref type="bibr" target="#b38">Wang and Cardie, 2013)</ref>, we consider two dialogue act-level summarization baselines: (1) LONGEST DA in each discussion is selected as the summary, and (2) CENTROID DA, the one with the highest TF-IDF similarity with all DAs in the dis- cussion. We also compare with an unsupervised keyword extraction approach by <ref type="bibr" target="#b20">Liu et al. (2009)</ref>, where word importance is estimated by its TF-IDF score, POS tag, and the salience of its correspond- ing sentence. With the same candidate phrases as in our model, we extend <ref type="bibr" target="#b20">Liu et al. (2009)</ref> by scoring each phrase based on its average score of the words. Top phrases, with the same number of phrases output by our model, are included into the summaries. Finally, we compare with summaries consisting of salient phrases predicted by an SVM classifier trained with our content features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="62.4">40.4 39.2 36.2 15.5 15.2 13.5 Our Model 66.6 45.4 44.7 41.1 * 24.1 * 23.4 * 20.9 * Our Model-latent 85.9 42.9 49.3 42.4 * 21.6 25.7 * 21.3 * Abstractive Summaries as Gold-Standard</head><note type="other">ROUGE1 ROUGE-SU4 Len Prec Rec F1 Prec Rec F1 Longest DA 30.9 14.8 5.5 7.4 4.8 1.4 1.9 Centroid DA 17.5 24.9 5.6 8.5 11.6 1.4 2.2 SVM 49.8 13.3 9.7 9.5 4.4 2.4 2.4 Liu et al. (2009) 62.4 10.3 16.7 11.3 2.7 4.5 2.8 Our Model 66.6 12.6 18.9 13.1 * 3.8 5.5 * 3.7 * Our Model-latent 85.9 11.4 20.0 12.4 * 3.3 6.1 * 3.5 *</note><p>From the results in <ref type="table" target="#tab_3">Table 4</ref>, we can see that phrase-based extractive summarization methods can yield better ROUGE scores for recall and F1 than baselines that extract the whole sen- tences. Meanwhile, our system significantly out-Meeting Clip: D: can we uh power a light in this? can we get a strong enough battery to power a light? A: um i think we could because the lcd panel requires power, and the lcd is a form of a light so that. . . D: . . .it's gonna have to have something high-tech about it and that's gonna take battery power. . . D: illuminate the buttons. yeah it glows. D: well m i'm thinking along the lines of you're you're in the dark watching a dvd and you um you find the thing in the dark and you go like this . . . oh where's the volume button in the dark, and uh y you just touch it . . . and it lights up or something. Abstract by Human: What sort of battery to use. The industrial designer pre- sented options for materials, components, and batteries and discussed the restrictions involved in using certain materi- als. Longest DA: well m i'm thinking along the lines of you're you're in the dark watching a dvd and you um you find the thing in the dark and you go like this. Centroid DA: can we uh power a light in this? Our Method: -power a light, a strong enough battery, -requires power, a form, -a really good battery, battery power, -illuminate the buttons, glows, -watching a dvd, the volume button, lights up or something performs the SVM-based classifiers when evalu- ated on ROUGE recall and F1, while achieving comparable precision. Compared to <ref type="bibr" target="#b20">Liu et al. (2009)</ref>, our system also yields better results on all metrics.</p><p>Sample summaries by our model along with two baselines are displayed in <ref type="figure" target="#fig_1">Figure 2</ref>. Utterance- level extract-based baselines unavoidably contain disfluency and unnecessary details. Our phrase- based extractive summary is able to capture the key points from both the argumentation process and important outcomes of the conversation. This implies that our model output can be used as input for an abstractive summarization system. It can also facilitate the visualization of decision-making processes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Further Analysis and Discussions</head><p>Features Analysis. We first discuss salient fea- tures with top weights learned by our joint model. For content features, main speaker tends to utter more salient content. Higher TF-IDF scores also indicate important phrases. If a phrase is men- tioned in previous turn and repeated in the current turn, it is likely to be a key point. For discourse features, structure features matter the most. For instance, jointly modeling the discourse relation of the parent node along with the current node can lead to better inference. An example is that giv- ing more details on the proposal (ELABORATION) tends to lead to POSITIVE feedback. Moreover, REQUEST usually appears close to the root of the argument diagram tree, while POSITIVE feedback is usually observed on leaves. Adjacency pairs also play an important role for discourse predic- tion. For joint features, features that compos- ite "phrase mentioned in previous turn" and rela- tion POSITIVE feedback or REQUEST yield higher weight, which are indicators for both key phrases and discourse relations. We also find that main speaker information composite with ELABORA- TION and UNCERTAIN are associated with high weights. Error Analysis and Potential Directions. Taking a closer look at our prediction results, one major source of incorrect prediction for phrase selection is based on the fact that similar concepts might be expressed in different ways, and our model pre- dicts inconsistently for different variations. For example, participants use both "thick" and "two centimeters" to talk about the desired shape of a remote control. However, our model does not group them into the same cluster and later makes different predictions. For future work, semantic similarity with context information can be lever- aged to produce better clustering results. Fur- thermore, identifying discourse relations in dia- logues is still a challenging task. For instance, "I wouldn't choose a plastic case" should be labeled as OPTION EXCLUSION, if the previous turns talk about different options. Otherwise, it can be la- beled as NEGATIVE. Therefore, models that better handle semantics and context need to be consid- ered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Predicting Consistency of Understanding</head><p>As discussed in previous work <ref type="bibr" target="#b26">(Mulder et al., 2002;</ref><ref type="bibr" target="#b25">Mercer, 2004</ref>), both content and discourse structure are critical for building shared under- standing among discussants. In this section, we test whether our joint model can be utilized to pre- dict the consistency among team members' under-standing of their group decisions, which is defined as consistency of understanding (COU) in <ref type="bibr" target="#b15">Kim and Shah (2016)</ref>. <ref type="bibr" target="#b15">Kim and Shah (2016)</ref> establish gold-standard COU labels on a portion of AMI discussions, by comparing participant summaries to determine whether participants report the same decisions. If all decision points are consistent, the associated topic discussion is labeled as consistent; other- wise, the discussion is identified as inconsistent. Their annotation covers the AMI-SUB dataset. Therefore, we run the prediction experiments on AMI-SUB by using the same annotation. Out of total 129 discussions in AMI-SUB, 86 discussions are labeled as consistent and 43 are inconsistent.</p><p>We construct three types of features by us- ing our model's predicted labels. Firstly, we learn two versions of our model based on the "consistent" discussions and the "inconsistent" ones in the training set, with learned parame- ters w con and w incon . For a discussion in the test set, these two models output two probabili- ties p con = max c,d P (c, d|x, w con ) and p incon = max c,d P (c, d|x, w incon ). We use p con − p incon as a feature.</p><p>Furthermore, we consider discourse relations of length one and two from the discourse struc- ture tree. Intuitively, some discourse relations, e.g., <ref type="bibr">ELABORATION</ref> followed by multiple POSI- TIVE feedback, imply consistent understanding.</p><p>The third feature is based on word entrainment, which has been shown to correlate with task suc- cess for groups ( <ref type="bibr" target="#b29">Nenkova et al., 2008)</ref>. Using the formula in <ref type="bibr" target="#b29">Nenkova et al. (2008)</ref>, we com- pute the average word entrainment between the main speaker who utters the most words and all the other participants. The content words in the salient phrases predicted by our model is consid- ered for entrainment computation.</p><p>Results. Leave-one-out is used for experiments. For training, our features are constructed from gold-standard phrase and discourse labels. Pre- dicted labels by our model is used for constructing features during testing. SVM-based classifier is used for experimenting with different sets of fea- tures output by our model. A majority class base- line is constructed as well. We also consider an SVM classifier trained with ngram features (uni- grams and bigrams). Finally, we compare with the state-of-the-art method in <ref type="bibr" target="#b15">Kim and Shah (2016)</ref>, where discourse-relevant features and head ges-  <ref type="table">(Majority)</ref> 66.7 40.0 Ngrams (SVM) 51.2 50.6 <ref type="bibr" target="#b15">Kim and Shah (2016)</ref> 60.5 50.5 Features from Our Model Consistency Probability (Prob) 52.7 52.   <ref type="bibr" target="#b15">and Shah (2016)</ref> are highlighted with * (p &lt; 0.05, paired t-test). For reference, we also show the pre- diction performance based on gold-standard discourse relations and phrase selection labels.</p><p>ture features are utilized in Hidden Markov Mod- els to predict the consistency label.</p><p>The results are displayed in <ref type="table" target="#tab_5">Table 5</ref>. All SVMs trained with our features surpass the ngrams-based baseline. Especially, the discourse features, word entrainment feature, and the combination of the three, all significantly outperform the state-of-the- art system by <ref type="bibr" target="#b15">Kim and Shah (2016)</ref>. <ref type="bibr">6</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We presented a joint model for performing phrase- level content selection and discourse relation pre- diction in spoken meetings. Experimental results on AMI and ICSI meeting corpora showed that our model can outperform state-of-the-art methods for both tasks. Further evaluation on the task of pre- dicting consistency-of-understanding in meetings demonstrated that classifiers trained with features constructed from our model output produced supe- rior performance compared to the state-of-the-art model. This provides an evidence of our model be- ing successfully applied in other prediction tasks in spoken meetings.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Figure 1: A sample clip from AMI meeting corpus. B, C, and D denotes different speakers. Here we highlight salient phrases (in italics) that are relevant to the major topic discussed, i.e., "which type of battery to use for the remote control". Arrows indicate discourse structure between speaker turns. We also show some of the discourse relations for illustration.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Sample summaries output by different systems for a meeting clip from AMI corpus (less relevant utterances in between are removed). Salient phrases by our system output are displayed for each turn of the clip, with duplicated phrases removed for brevity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Discourse relation prediction performance on 

AMI-SUB. Our models that significantly outperform 
SVM-based model and Ji et al. (2016) are highlighted 
with  *  (p &lt; 0.05, paired t-test). Best result for each 
column is in bold. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Phrase-based content selection performance 

on AMI-FULL and ICSI-FULL. We display results 
of our models trained with latent discourse relations. 
Results that are significantly better than SVM-based 
model are highlighted with  *  (p &lt; 0.05, paired t-test). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>ROUGE scores for phrase-based extractive 

summarization evaluated against human-constructed 
utterance-level extractive summaries and abstractive 
summaries. Our models that statistically significantly 
outperform SVM and Liu et al. (2009) are highlighted 
with  *  (p &lt; 0.05, paired t-test). Best ROUGE score for 
each column is in bold. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Consistency of Understanding (COU) predic-

tion results on AMI-SUB. Results that statistically sig-
nificantly outperform ngrams-based baseline and Kim 
</table></figure>

			<note place="foot" n="1"> Other methods for mining candidate phrases, such as frequency-based method (Liu et al., 2015), will be studied for future work.</note>

			<note place="foot" n="2"> For future work, we can explore other proposal distributions that utilize the conditional distribution of salient phrases given sampled discourse relations.</note>

			<note place="foot" n="6"> We also experiment with other popular classifiers, e.g. logistic regression or decision tree, and similar trend is respected.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported in part by National Sci-ence Foundation Grant IIS-1566382 and a GPU gift from Nvidia. We thank three anonymous re-viewers for their valuable suggestions on various aspects of this work.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Extractive Summarization of Multi-party Meetings Through Discourse Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Hadi Bokaei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hossein</forename><surname>Sameti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">01</biblScope>
			<biblScope unit="page" from="41" to="72" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Extracting Decisions from Multi-party Dialogue Using Directed Graphical Models and Semantic Similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Trung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Bui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Frampton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanley</forename><surname>Dowding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Peters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGDIAL 2009 Conference: The 10th</title>
		<meeting>the SIGDIAL 2009 Conference: The 10th</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<title level="m">Annual Meeting of the Special Interest Group on Discourse and Dialogue. Association for Computational Linguistics</title>
		<meeting><address><addrLine>Stroudsburg, PA, USA, SIGDIAL &apos;09</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="235" to="243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The AMI Meeting Corpus: A Pre-announcement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Carletta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Ashby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastien</forename><surname>Bourban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Flynn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mael</forename><surname>Guillemot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Hain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaroslav</forename><surname>Kadlec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasilis</forename><surname>Karaiskos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wessel</forename><surname>Kraaij</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melissa</forename><surname>Kronenthal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lathoud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lincoln</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agnes</forename><surname>Lisowska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iain</forename><surname>Mccowan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second International Conference on Machine Learning for Multimodal Interaction</title>
		<meeting>the Second International Conference on Machine Learning for Multimodal Interaction<address><addrLine>Wilfried Post, Dennis Reidsma, and Pierre Wellner; Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="28" to="39" />
		</imprint>
	</monogr>
	<note>MLMI&apos;05</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning to Classify Email into &quot;Speech Acts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vitor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><forename type="middle">M</forename><surname>Carvalho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics</title>
		<editor>Dekang Lin and Dekai Wu</editor>
		<meeting>the 2004 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="309" to="316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Recognition of Dialogue Acts in Multiparty Meetings Using a Switching DBN</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alfred</forename><surname>Dielmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Renals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on audio, speech, and language processing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1303" to="1314" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Identifying Relevant Phrases to Summarize Decisions in Spoken Meetings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Fernández</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Frampton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Dowding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="78" to="81" />
		</imprint>
	</monogr>
	<note>Anish Adukuzhiyil, Patrick Ehlen, and Stanley Peters</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A Skip-chain Conditional Random Field for Ranking Meeting Utterances by Importance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2006 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Stroudsburg, PA, USA, EMNLP &apos;06</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="364" to="372" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Analyzing Argumentative Discourse Units in Online Interactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Debanjan</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Smaranda</forename><surname>Muresan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nina</forename><surname>Wacholder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Aakhus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Mitsui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Argumentation Mining</title>
		<meeting>the First Workshop on Argumentation Mining</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="39" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A Global Optimization Framework for Meeting Summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Gillick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Korbinian</forename><surname>Riedhammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoit</forename><surname>Favre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acoustics, Speech and Signal Processing</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="4769" to="4772" />
		</imprint>
	</monogr>
	<note>IEEE International Conference on. IEEE</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Towards Automatic Argument Diagramming of Multiparity Meetings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acoustics, Speech and Signal Processing</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="4753" to="4756" />
		</imprint>
	</monogr>
	<note>IEEE International Conference on. IEEE</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">HILDA: A Discourse Parser Using Support Vector Machine Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Hernault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helmut</forename><surname>Prendinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">A</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitsuru</forename><surname>Ishizuka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dialogue &amp; Discourse</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="33" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Proceedings.(ICASSP&apos;03)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Janin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Don</forename><surname>Baron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jane</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Ellis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Gelbart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nelson</forename><surname>Morgan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Peskin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thilo</forename><surname>Pfau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elizabeth</forename><surname>Shriberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Stolcke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The ICSI Meeting Corpus. In Acoustics, Speech, and Signal Processing</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="I" to="I" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A Latent Variable Recurrent Neural Network for Discourse-Driven Language Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gholamreza</forename><surname>Haffari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="332" to="342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Recurrent Convolutional Neural Networks for Discourse Compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Continuous Vector Space Models and their Compositionality. Association for Computational Linguistics</title>
		<meeting>the Workshop on Continuous Vector Space Models and their Compositionality. Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="119" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Improving Team&apos;s Consistency of Understanding in Meetings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julie</forename><forename type="middle">A</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Human-Machine Systems</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="625" to="637" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Visualizing Argumentation: Software Tools for Collaborative and Educational Sense-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Paul A Kirschner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chad</forename><forename type="middle">S</forename><surname>Buckingham-Shum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Carr</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Accurate Unlexicalized Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 41st Annual Meeting on Association for Computational Linguistics<address><addrLine>Stroudsburg, PA, USA, ACL &apos;03</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="423" to="430" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Automatic Evaluation of Summaries Using N-gram Cooccurrence Statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology</title>
		<meeting>the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="71" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Using Spoken Utterance Compression for Meeting Summarization: A Pilot Study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Spoken Language Technology Workshop (SLT)</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="37" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Unsupervised Approaches for Automatic Keyword Extraction Using Meeting Transcripts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feifan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deana</forename><surname>Pennell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics<address><addrLine>Boulder, Colorado</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="620" to="628" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Mining quality phrases from massive text corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jialu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingbo</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the 2015 ACM SIGMOD International Conference on Management of Data</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1729" to="1744" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Building a Dataset for Summarization and Keyword Extraction from Emails</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vanessa</forename><surname>Loza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shibamouli</forename><surname>Lahiri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Po-Hsiang</forename><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2441" to="2446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Using Question-answer Pairs in Extractive Summarization of Email Conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><surname>Mckeown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lokesh</forename><surname>Shrestha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Owen</forename><surname>Rambow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Intelligent Text Processing and Computational Linguistics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="542" to="550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Abstractive Summarization of Spoken and Written Conversations Based on Phrasal Queries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yashar</forename><surname>Mehdad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Carenini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">T</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1220" to="1230" />
		</imprint>
	</monogr>
	<note>Long Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Sociocultural Discourse Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Mercer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of applied linguistics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="137" to="168" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Assessing Group Learning and Shared Understanding in Technology-mediated Interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ingrid</forename><surname>Mulder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janine</forename><surname>Swaak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Kessels</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Educational Technology &amp; Society</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="35" to="47" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Generating and Validating Abstracts of Meeting Conversations: A User Study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Carenini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Natural Language Generation Conference. Association for Computational Linguistics</title>
		<meeting>the 6th International Natural Language Generation Conference. Association for Computational Linguistics<address><addrLine>Stroudsburg, PA, USA, INLG &apos;10</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="105" to="113" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Incorporating Speaker and Discourse Features into Speech Summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Renals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Carletta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johanna</forename><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics. Association for Computational Linguistics</title>
		<meeting>the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="367" to="374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">High Frequency Word Entrainment in Spoken Dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agustin</forename><surname>Gravano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hirschberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th annual meeting of the association for computational linguistics on human language technologies: Short papers. Association for Computational Linguistics</title>
		<meeting>the 46th annual meeting of the association for computational linguistics on human language technologies: Short papers. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="169" to="172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Extractive Summarization and Dialogue Act Modeling on Email Threads: An Integrated Probabilistic Approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatsuro</forename><surname>Oya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Carenini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">15th Annual Meeting of the Special Interest Group on Discourse and Dialogue</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page">133</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Integer Linear Programming for Discourse Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jérémy</forename><surname>Perret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stergos</forename><surname>Afantenos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Asher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Morey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="99" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Long Story Short-Global Unsupervised Models for Keyphrase Based Meeting Summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Korbinian</forename><surname>Riedhammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Benoit Favre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hakkani-Tür</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Speech Commun</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="801" to="815" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Argument Diagramming of Meeting Conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rutger</forename><surname>Rienks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Heylen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Van Der Weijden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MMMP 2005, part of the 7th International Conference on Multimodal Interfaces</title>
		<editor>A. Vinciarelli and J-M. Odobez</editor>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>International Workshop on Multimodal Multiparty Meeting Processing. ICMI</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Samplerank: Training Factor Graphs with Atomic Gradients</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khashayar</forename><surname>Rohanimanesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kedar</forename><surname>Bellare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aron</forename><surname>Culotta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael L</forename><surname>Wick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Machine Learning (ICML11)</title>
		<meeting>the 28th International Conference on Machine Learning (ICML11)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="777" to="784" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Dependency Parsing by Belief Propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="145" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Dialogue Act Modeling for Automatic Tagging and Recognition of Conversational Speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Stolcke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Ries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Coccaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elizabeth</forename><surname>Shriberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachel</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carol</forename><surname>Van Ess-Dykema</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie</forename><surname>Meteer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="339" to="373" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Focused Meeting Summarization via Unsupervised Relation Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue</title>
		<meeting>the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue<address><addrLine>Seoul, South Korea</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">DomainIndependent Abstract Generation for Focused Meeting Summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st</title>
		<meeting>the 51st</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
				<title level="m">Annual Meeting of the Association for Computational Linguistics</title>
		<meeting><address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1395" to="1405" />
		</imprint>
	</monogr>
	<note>Long Papers). Association for Computational Linguistics</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
