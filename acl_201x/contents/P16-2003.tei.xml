<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:48+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning Multiview Embeddings of Twitter Users</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrian</forename><surname>Benton</surname></persName>
							<email>adrian@cs.jhu.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raman</forename><surname>Arora</surname></persName>
							<email>arora@cs.jhu.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dredze</surname></persName>
							<email>mdredze@cs.jhu.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Bloomberg LP</orgName>
								<address>
									<postCode>10022</postCode>
									<settlement>New York</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Human Language Technology Center of Excellence Center for Language and Speech Processing</orgName>
								<orgName type="institution">Johns Hopkins University Baltimore</orgName>
								<address>
									<postCode>21218</postCode>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Learning Multiview Embeddings of Twitter Users</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="14" to="19"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Low-dimensional vector representations are widely used as stand-ins for the text of words, sentences, and entire documents. These em-beddings are used to identify similar words or make predictions about documents. In this work, we consider embeddings for social media users and demonstrate that these can be used to identify users who behave similarly or to predict attributes of users. In order to capture information from all aspects of a user&apos;s online life, we take a multiview approach, applying a weighted variant of Generalized Canonical Correlation Analysis (GCCA) to a collection of over 100,000 Twitter users. We demonstrate the utility of these multiview em-beddings on three downstream tasks: user engagement , friend selection, and demographic attribute prediction.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Dense, low-dimensional vector representations (em- beddings) have a long history in NLP, and recent work on neural models have provided new and popular al- gorithms for training representations for word types <ref type="bibr" target="#b14">(Mikolov et al., 2013;</ref><ref type="bibr" target="#b6">Faruqui and Dyer, 2014)</ref>, sen- tences ( <ref type="bibr" target="#b7">Kiros et al., 2015)</ref>, and entire documents ( <ref type="bibr" target="#b9">Le and Mikolov, 2014</ref>). These embeddings often have nice properties, such as capturing some aspects of syntax or semantics and outperforming their sparse counterparts at downstream tasks.</p><p>While there are many approaches to generating em- beddings of text, it is not clear how to learn embeddings for social media users. There are several different types of data (views) we can use to build user representations: the text of messages they post, neighbors in their local network, articles they link to, images they upload, etc. We propose unsupervised learning of representations of users with a variant of Generalized Canonical Correla- tion Analysis (GCCA) <ref type="bibr" target="#b4">(Carroll, 1968;</ref><ref type="bibr" target="#b20">Van De Velden and Bijmolt, 2006;</ref><ref type="bibr" target="#b3">Arora and Livescu, 2014;</ref><ref type="bibr" target="#b17">Rastogi et al., 2015</ref>), a multiview technique that learns a single, low-dimensional vector for each user best capturing in- formation from each of their views. We believe this is more appropriate for learning user embeddings than concatenating views into a single vector, since views may correspond to different modalities (image vs. text data) or have very different distributional properties. Treating all features as equal in this concatenated vec- tor is not appropriate.</p><p>We offer two main contributions: (1) an application of GCCA to learning vector representations of social media users that best accounts for all aspects of a user's online life, and (2) an evaluation of these vector repre- sentations for a set of Twitter users at three different tasks: user engagement, friend, and demographic at- tribute prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Twitter User Data</head><p>We begin with a description of our dataset, which is necessary for understanding the data available to our multiview model. We uniformly sampled 200,000 users from a stream of publicly available tweets from the 1% Twitter stream from April 2015. To include typical, English speaking users we removed users with verified accounts, more than 10,000 followers, or non- English profiles <ref type="bibr">1</ref> . For each user we collected their 1,000 most recent tweets, and then filtered out non- English tweets. Users without English tweets in Jan- uary or February 2015 were omitted, yielding a total of 102,328 users. Although limiting tweets to only these two months restricted the number of tweets we were able to work with, it also ensured that our data are drawn from a narrow time window, controlling for differences in user activity over time. This allows us to learn distinctions between users, and not temporal distinctions of content. We will use this set of users to learn representations for the remainder of this paper.</p><p>Next, we expand the information available about these users by collecting information about their so- cial networks. Specifically, for each user mentioned in a tweet by one of the 102,328 users, we collect up to the 200 most recent English tweets for these users from January and February 2015. Similarly, we col- lected the 5,000 most recently added friends and fol- lowers of each of the 102,328 users. We then sampled 10 friends and 10 followers for each user and collected up to the 200 most recent English tweets for these users from January and February 2015. Limits on the num- ber of users and tweets per user were imposed so that we could operate within Twitter's API limits. This data supports several of our prediction tasks, as well as the four sources for each user: their tweets, tweets of men- tioned users, friends and followers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">User Views</head><p>Our user dataset provides several sources of informa- tion on which we can build user views: text posted by the user (ego) and people that are mentioned, friended or followed by the user and their posted text.</p><p>For each text source we can aggregate the many tweets into a single document, e.g. all tweets written by accounts mentioned by a user. We represent this document as a bag-of-words (BOW) in a vector space model with a vocabulary of the 20,000 most frequent word types after stopword removal. We will consider both count and TF-IDF weighted vectors.</p><p>A common problem with these high dimensional representations is that they suffer from the curse of dimensionality. A natural solution is to apply a di- mensionality reduction technique to find a compact representation that captures as much information as possible from the original input. Here, we consider principal components analysis (PCA), a ubiquitous linear dimensionality reduction technique, as well as word2vec ( <ref type="bibr" target="#b14">Mikolov et al., 2013)</ref>, a technique to learn nonlinear word representations.</p><p>We consider the following views for each user. BOW: We take the bag-of-words (both count and TF- IDF weighted) representation of all tweets made by users in that view (ego, mention, friend, or follower) following the above pre-processing. BOW-PCA: We run PCA and extract the top princi- pal components for each of the above views. We also consider all possible combinations of views obtained by concatenating views before applying PCA, and con- catenating PCA-projected views. By considering all possible concatenation of views, we ensure that this method has access to the same information as multi- view methods. Both the raw BOW and BOW-PCA rep- resentations have been explored in previous work for demographic prediction <ref type="bibr" target="#b21">(Volkova et al., 2014;</ref><ref type="bibr" target="#b1">Al Zamal et al., 2012</ref>) and recommendation systems <ref type="bibr" target="#b0">(Abel et al., 2011;</ref><ref type="bibr" target="#b24">Zangerle et al., 2013)</ref>. Word2Vec: BOW-PCA is limited to linear representa- tions of BOW features. Modern neural network based approaches to learning word embeddings, including word2vec continuous bag of words and skipgram mod- els, can learn nonlinear representations that also cap- ture local context around each word ( <ref type="bibr" target="#b14">Mikolov et al., 2013)</ref>. We represent each view as the simple average of the word embeddings for all tokens within that view (e.g., all words written by the ego user). Word em- beddings are learned on a sample of 87,755,398 tweets and profiles uniformly sampled from the 1% Twitter stream in April 2015 along with all the tweets/profiles collected for our set of users -a total of over a billion tokens. We use the word2vec tool, select either skip- gram or continuous bag-of-words embeddings on dev data for each prediction task, and train for 50 epochs. We use the default settings for all other parameters. NetSim: An alternative to text based representations is to use the social network of users as a representation. We encode a user's social network as a vector by treat- ing the users as a vocabulary, where users with simi- lar social networks have similar vector representations (NetSim). An n-dimensional vector then encodes the user's social network as a bag-of-words over this user vocabulary. In other words, a user is represented by a summation of the one-hot encodings of each neigh- boring user in their social network. In this representa- tion, the number of friends two users have in common is equal to the dot product between their social network vectors. We define the social network may be as one's followers, friends, or the union of both. The motiva- tion behind this representation is that users who have similar networks may behave in similar ways. Such network features are commonly used to construct user representations as well as to make user recommenda- tions ( <ref type="bibr" target="#b12">Lu et al., 2012;</ref><ref type="bibr" target="#b8">Kywe et al., 2012)</ref>. NetSim-PCA: The PCA-projected representations for each NetSim vector. This may be important for computing similarity, since users are now represented as dense vectors capturing linear correlations in the friends/followers a user has. NetSim-PCA is to NetSim as BOW-PCA is to BOW-we apply PCA directly to the user's social network as opposed to the BOW represen- tations of users in that network.</p><p>Each of these views can be treated independently as a user representation. However, different downstream tasks may favor different views. For example, the friend network is useful at recommending new friends, whereas the ego tweet view may be better at predict- ing what content a user will post in the future. Pick- ing a single view may ignore valuable information as views may contain complementary information, so us- ing multiple views improves on a single view. One ap- proach is to concatenate multiple views together, but this further increases the size of the user embeddings. In the next section, we propose an alternate approach for learning a single embedding from multiple views.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Learning Multiview User Embeddings</head><p>We use Generalized Canonical Correlation Analysis (GCCA) <ref type="bibr" target="#b4">(Carroll, 1968)</ref> to learn a single embedding from multiple views. GCCA finds G,U i that minimize:</p><formula xml:id="formula_0">arg min G,Ui i G − X i U i 2 F s.t. G G = I<label>(1)</label></formula><p>where X i ∈ R n×di corresponds to the data matrix for the ith view, U i ∈ R di×k maps from the latent space to observed view i, and G ∈ R n×k contains all user representations (Van De Velden and <ref type="bibr" target="#b20">Bijmolt, 2006</ref>).</p><p>Since each view may be more or less helpful for a downstream task, we do not want to treat each view equally in learning a single embedding. Instead, we weigh each view differently in the objective:</p><formula xml:id="formula_1">arg min G,Ui i w i G − X i U i 2 F s.t. G G = I, w i ≥ 0 (2)</formula><p>where w i explicitly expresses the importance of the ith view in determining the joint embedding. The columns of G are the eigenvectors of i w i X i (X i X i ) −1 X i , and the solution for</p><formula xml:id="formula_2">U i = (X i X i ) −1 X i G.</formula><p>In our ex- periments, we use the approach of <ref type="bibr" target="#b17">Rastogi et al. (2015)</ref> to learn G and U i , since it is more memory-efficient than decomposing the sum of projection matrices.</p><p>GCCA embeddings were learned over combinations of the views in §3. When available, we also consider GCCA-net, where in addition to the four text views, we also include the follower and friend network views used by NetSim-PCA. For computational efficiency, each of these views was first reduced in dimensionality by pro- jecting its BOW TF-IDF-weighted representation to a 1000-dimensional vector through PCA. <ref type="bibr">2</ref> We add an identity matrix scaled by a small amount of regulariza- tion, 10 −8 , to the per-view covariance matrices before inverting, for numerical stability, and use the formula- tion of GCCA reported in Van De Velden and Bijmolt (2006), which ignores rows with missing data (some users had no data in the mention tweet view and some users accounts were private). We tune the weighting of each view i, w i ∈ {0.0, 0.25, 1.0}, discriminatively for each task, although the GCCA objective is unsuper- vised once the w i are fixed.</p><p>We also consider a minor modification of GCCA, where G is scaled by the square-root of the singular val- ues of i w i X i X i , GCCA-sv. This is inspired by pre- vious work showing that scaling each feature of multi- view embeddings by the singular values of the data ma- trix can improve performance at downstream tasks such as image or caption retrieval ( <ref type="bibr" target="#b15">Mroueh et al., 2015)</ref>. Note that if we only consider a single view, X 1 , with weight w 1 = 1, then the solution to GCCA-sv is iden- tical to the PCA solution for data matrix X 1 , without mean-centering.</p><p>When we compare representations in the fol- lowing tasks, we sweep over embedding width in {10, 20, 50, 100, 200, 300, 400, 500, 1000} for all methods. This applies to GCCA, BOW-PCA, NetSim- PCA, and Word2Vec. We also consider concatena- tions of vectors for every possible subset of views: singletons, pairs, triples, and all views. We tried ap- plying PCA directly to the concatenation of all 1000- dimensional BOW-PCA views, but this did not perform competitively in our experiments. <ref type="bibr">2</ref> We excluded count vectors from the GCCA experiments for computational efficiency since they performed similarly to TF-IDF representations in initial experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Setup</head><p>We selected three user prediction tasks to demonstrate the effectiveness of the multi-view embeddings: user engagement prediction, friend recommendation and demographic characteristics inference. Our focus is to show the performance of multiview embeddings com- pared to other representations, not on building the best system for a given task. User Engagement Prediction The goal of user en- gagement prediction is to determine which topics a user will likely tweet about, using hashtag as a proxy. This task is similar to hashtag recommendation for a tweet based on its contents ( <ref type="bibr" target="#b8">Kywe et al., 2012;</ref><ref type="bibr" target="#b19">She and Chen, 2014;</ref><ref type="bibr" target="#b24">Zangerle et al., 2013</ref>). Purohit et al. (2011) pre- sented a supervised task to predict if a hashtag would appear in a tweet using features from the user's net- work, previous tweets, and the tweet's content.</p><p>We selected the 400 most frequently used hashtags in messages authored by our users and which first ap- peared in March 2015, randomly and evenly dividing them into dev and test sets. We held out the first 10 users who tweeted each hashtag as exemplars of users that would use the hashtag in the future. We ranked all other users by the cosine distance of their embedding to the average embedding of these 10 users. Since em- beddings are learned on data pre-March 2015, the hash- tags cannot impact the learned representations. Perfor- mance is measured using precision and recall at k, as well as mean reciprocal rank (MRR), where a user is marked as correct if they used the hashtag. Note that this task is different than that reported in Purohit et al. (2011), since we are making recommendations at the level of users, not tweets. Friend Recommendation The goal of friend rec- ommendation/link prediction is to recommend/predict other accounts for a user to follow <ref type="bibr" target="#b11">(Liben-Nowell and Kleinberg, 2007)</ref>.</p><p>We selected the 500 most popular accounts -which we call celebrities -followed by our users, randomly, and evenly divided them into dev and test sets. We randomly select 10 users who follow each celebrity and rank all other users by cosine distance to the av- erage of these 10 representations. The tweets of se- lected celebrities are removed during embedding train- ing so as not to influence the learned representations. We use the same evaluation as user engagement pre- diction, where a user is marked as correct if they follow the given celebrity.</p><p>For both user engagement prediction and friend rec- ommendation we z-score normalize each feature, sub- tracting off the mean and scaling each feature indepen- dently to have unit variance, before computing cosine similarity. We select the approach and whether to z- score normalize based on the development set perfor- mance. Demographic Characteristics Inference Our final task is to infer the demographic characteristics of a user <ref type="bibr" target="#b1">(Al Zamal et al., 2012;</ref><ref type="bibr" target="#b5">Chen et al., 2015</ref>  We use the dataset from <ref type="bibr" target="#b21">Volkova et al. (2014;</ref><ref type="bibr" target="#b22">Volkova (2015)</ref> which annotates 383 users for age (old/young), 383 for gender (male/female), and 396 po- litical affiliation (republican/democrat), with balanced classes. Predicting each characteristic is a binary su- pervised prediction task. Each set is partitioned into 10 folds, with two folds held out for test, and the other eight for tuning via cross-fold validation. The pro- vided dataset contained tweets from each user, men- tioned users, friends and follower networks. It did not contain the actual social networks for these users, so we did not evaluate NetSim, NetSim-PCA, or GCCA-net at these prediction tasks.</p><p>Each feature was z-score normalized before being passed to a linear-kernel SVM where we swept over 10 −4 , . . . , 10 4 for the penalty on the error term, C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head><p>User Engagement Prediction <ref type="table">Table 1</ref> shows results for user engagement prediction and <ref type="figure" target="#fig_0">Figure 1</ref> the preci- sion and recall curves as a function of number of rec- ommendations. GCCA outperforms other methods for precision and recall at 1000, and does close to the best in terms of MRR. Including network views (GCCA- GCCA BOW-PCA    net and GCCA-sv) improves the performance further. The best performing GCCA setting placed weight 1 on the ego tweet view, mention view, and friend view, while BOW-PCA concatenated these views, suggesting that these were the three most important views but that GCCA was able to learn a better representation. <ref type="figure" target="#fig_1">Figure  2</ref> compares performance of different view subsets for GCCA and BOW-PCA, showing that GCCA uses infor- mation from multiple views more effectively for pre- dicting user engagement.</p><p>Friend Recommendation <ref type="table" target="#tab_2">Table 2</ref> shows results for friend prediction and <ref type="figure" target="#fig_3">Figure 3</ref>   NetSim-PCA, although GCCA-sv is able to meet the performance of NetSim-PCA. The best GCCA placed non-zero weight on the friend tweets view, and GCCA- net only places weight on the friend network view; the other views were not informative. BOW-PCA and Word2Vec only used the friend tweet view. This sug- gests that the friend view is the most important for this task, and multiview techniques cannot exploit ad- ditional views to improve performance. GCCA-sv per- forms identically to GCCA-net, since it only placed weight on the friend network view, learning identical embeddings to GCCA-net. Demographic Characteristics Prediction <ref type="table" target="#tab_3">Table 3</ref> shows the average cross-fold validation and test ac- curacy on the demographic prediction task. GCCA + BOW and BOW-PCA + BOW are the concatenation of BOW features with GCCA and BOW-PCA, respec- tively. The wide variation in performance is due to the small size of the datasets, thus it's hard to draw many conclusions other than that GCCA seems to per- form well compared to other linear methods. Word2Vec surpasses other representations in two out of three datasets.</p><p>It is difficult to compare the performance of the methods we evaluate here to that reported in previous work, <ref type="bibr" target="#b1">(Al Zamal et al., 2012)</ref>. This is because they re- port cross-fold validation accuracy (not test), they con- sider a wider range of hand-engineered features, differ- ent subsets of networks, radial basis function kernels for SVM, and find that accuracy varies wildly across different feature sets. They report cross-fold validation accuracy ranging from 0.619 to 0.805 for predicting age, 0.560 to 0.802 for gender, and 0.725 to 0.932 for politics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We have proposed several representations of Twitter users, as well as a multiview approach that combines these views into a single embedding. Our multiview embeddings achieve promising results on three differ- ent prediction tasks, making use of both what a user writes as well as the social network. We found that each task relied on different information, which our method successfully combined into a single representation.</p><p>We plan to consider other means for learning user representations, including comparing nonlinear dimen- sionality reduction techniques such as kernel PCA ( <ref type="bibr" target="#b18">Schölkopf et al., 1997)</ref> and deep canonical correlation analysis ( <ref type="bibr" target="#b2">Andrew et al., 2013;</ref>. Re- cent work on learning user representations with mul- titask deep learning techniques ( <ref type="bibr" target="#b10">Li et al., 2015)</ref>, sug- gests that learning a nonlinear mapping from observed views to the latent space can learn high quality user representations. One issue with GCCA is scalabil- ity: solving for G relies on an SVD of a large ma- trix that must be loaded into memory. Online variants of GCCA would allow this method to scale to larger training sets and incrementally update representations. The PCA-reduced views for all 102,328 Twitter users can be found here: http://www.dredze.com/ datasets/multiview_embeddings/.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The best-performing approaches on user engagement prediction as a function of k (number of recommendations). The ordering of methods is consistent across k.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Macro recall@1000 on user engagement prediction for different combinations of text views. Each bar shows the best-performing model swept over dimensionality. E: ego, M: mention, Fr: friend, Fol: followertweet views. Model Dim P@1000 R@1000 MRR BOW 20000 0.133/0.153 0.043/0.048 0.000/0.001 BOW-PCA 20 0.311/0.314 0.101/0.102 0.001/0.001 NetSim NA 0.406/0.420 0.131/0.132 0.002/0.002 NetSim-PCA 500 0.445/0.439 0.149/0.147 0.002/0.002 Word2Vec 200 0.260/0.249 0.084/0.080 0.001/0.001 GCCA 50 0.269/0.276 0.089/0.091 0.001/0.001 GCCA-sv 500 0.445/0.439 0.149/0.147 0.002/0.002 GCCA-net 20 0.376/0.364 0.123/0.120 0.001/0.001 NetSize NA 0.033/0.035 0.009/0.010 0.000/0.000 Random NA 0.034/0.036 0.010/0.010 0.000/0.000</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Performance on friend recommendation varying k.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>) .</head><label>.</label><figDesc></figDesc><table>Model 

Dim 
P@1000 
R@1000 
MRR 
BOW 
20000 
0.009/0.005 
0.241/0.157 
0.006/0.006 
BOW-PCA 
500 
0.011/0.008 
0.312/0.29 
0.007/0.009 
NetSim 
NA 
0.006/0.006 
0.159/0.201 
0.004/0.004 
NetSim-PCA 
300 
0.010/0.008 
0.293/0.299 
0.006/0.006 
Word2Vec 
100 
0.009/0.007 
0.254/0.217 
0.005/0.004 
GCCA 
100 
0.012/0.009 
0.357/0.325 
0.011/0.008 
GCCA-sv 
500 
0.012/0.010 
0.359/0.334 
0.010/0.011 
GCCA-net 
200 
0.013/0.009 
0.360/0.346 
0.011/0.011 
NetSize 
NA 
0.001/0.001 
0.012/0.012 
0.000/0.000 
Random 
NA 
0.000/0.000 
0.002/0.008 
0.000/0.000 

Table 1: Macro performance at user engagement prediction 
on dev/test. Ranking of model performance was consistent 
across metrics. Precision is low since few users tweet a given 
hashtag. Values bolded by best test performance per metric. 
Baselines (bottom): NetSize: a ranking of users by the size of 
their local network; Random randomly ranks users. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Macro performance for friend recommendation. 
Performance of NetSim-PCA and GCCA-sv are identical 
since the view weighting for GCCA-sv only selected solely 
the friend view. Thus, these methods learned identical user 
embeddings. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Average CV/test accuracy for inferring demo-
graphic characteristics. 

</table></figure>

			<note place="foot" n="1"> Identified with langid (Lui and Baldwin, 2012).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This research was supported in part by NSF BIGDATA grant IIS-1546482 and a gift from Bloomberg LP.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Analyzing user modeling on twitter for personalized news recommendations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Abel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geert-Jan</forename><surname>Houben</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">User Modeling, Adaption and Personalization-19th International Conference</title>
		<meeting><address><addrLine>Girona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-07-11" />
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Homophily and latent attribute inference: Inferring latent attributes of twitter users from neighbors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Al</forename><surname>Faiyaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wendy</forename><surname>Zamal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ruths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Internation Conference on Weblogs and Social Media (ICWSM)</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Deep canonical correlation analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Galen</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raman</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Bilmes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Livescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1247" to="1255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multi-view learning with supervision for transformed bottleneck features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raman</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Livescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2499" to="2503" />
		</imprint>
	</monogr>
	<note>IEEE International Conference on</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Generalization of canonical correlation analysis to three or more sets of variables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J Douglas</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carroll</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Convention of the American Psychological Association</title>
		<imprint>
			<date type="published" when="1968" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="227" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A comparative study of demographic attribute inference in twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Agichtein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fusheng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Weblogs and Social Media (ICWSM)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Improving vector space word representations using multilingual correlation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Conference of the European Chapter</title>
		<meeting>the 14th Conference of the European Chapter<address><addrLine>Gothenburg, Sweden</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014-04" />
			<biblScope unit="page" from="462" to="471" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Raquel Urtasun, and Sanja Fidler</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
		<idno>abs/1506.06726</idno>
	</analytic>
	<monogr>
		<title level="m">Skip-thought vectors. CoRR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">On recommending hashtags in twitter networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tuan-Anh</forename><surname>Su Mon Kywe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ee-Peng</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feida</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Social Informatics-4th International Conference</title>
		<meeting><address><addrLine>Lausanne, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-12-05" />
			<biblScope unit="page" from="337" to="350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Distributed representations of sentences and documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Internation Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1510.05198</idno>
		<title level="m">Learning multi-faceted representations of individuals from heterogeneous evidence using neural networks</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The link-prediction problem for social networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Liben</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-</forename><surname>Nowell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American society for information science and technology</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1019" to="1031" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Twitter user modeling and tweets recommendation based on wikipedia concept graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunliang</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wai</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingxiao</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI Workshop on Intelligent Techniques for Web Personalization and Recommender Systems</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">2012. langid. py: An off-the-shelf language identification tool</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Lui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL): system demonstrations</title>
		<imprint>
			<biblScope unit="page" from="25" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Asymmetrically weighted cca and hierarchical kernel sentence embedding for multimodal retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youssef</forename><surname>Mroueh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Etienne</forename><surname>Marcheret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vaibhava</forename><surname>Goel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06267</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Understanding user-community engagement by multi-faceted features: A case study on twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hemant</forename><surname>Purohit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiye</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amruta</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinivasan</forename><surname>Parthasarathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Sheth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW Workshop on Social Media Engagement (SoME)</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multiview lsa: Representation learning via generalized cca</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushpendre</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raman</forename><surname>Arora</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">North American Association for Computational Linguistics (NAACL)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Kernel principal component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klausrobert</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Neural Networks-ICANN &apos;97, 7th International Conference</title>
		<meeting><address><addrLine>Lausanne, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997-10-08" />
			<biblScope unit="page" from="583" to="588" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Tomoha: Topic model-based hashtag recommendation on twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jieying</forename><surname>She</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International World Wide Web Conferences Steering Committee</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="371" to="372" />
		</imprint>
	</monogr>
	<note>International conference on World wide web (WWW)</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Generalized canonical correlation analysis of matrices with missing rows: a simulation study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Van De Velden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Tammo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bijmolt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="323" to="331" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Inferring user political preferences from streaming communications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svitlana</forename><surname>Volkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Glen</forename><surname>Coppersmith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="186" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Predicting Demographics and Affect in Social Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svitlana</forename><surname>Volkova</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015-10" />
		</imprint>
		<respStmt>
			<orgName>Johns Hopkins University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">On deep multi-view representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiran</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raman</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Livescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Bilmes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Machine Learning (ICML-15)</title>
		<meeting>the 32nd International Conference on Machine Learning (ICML-15)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1083" to="1092" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">On the impact of text similarity functions on hashtag recommendations in microblogging environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eva</forename><surname>Zangerle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Gassler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Günther</forename><surname>Specht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social Network Analysis and Mining</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="889" to="898" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
