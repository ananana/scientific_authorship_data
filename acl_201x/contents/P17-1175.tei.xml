<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:02+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Doubly-Attentive Decoder for Multi-modal Neural Machine Translation</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iacer</forename><surname>Calixto</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Campbell</surname></persName>
						</author>
						<title level="a" type="main">Doubly-Attentive Decoder for Multi-modal Neural Machine Translation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</title>
						<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1913" to="1924"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-1175</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We introduce a Multi-modal Neural Machine Translation model in which a doubly-attentive decoder naturally incorporates spatial visual features obtained using pre-trained convolutional neural networks , bridging the gap between image description and translation. Our decoder learns to attend to source-language words and parts of an image independently by means of two separate attention mechanisms as it generates words in the target language. We find that our model can efficiently exploit not just back-translated in-domain multi-modal data but also large general-domain text-only MT corpora. We also report state-of-the-art results on the Multi30k data set.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Neural Machine Translation (NMT) has been suc- cessfully tackled as a sequence to sequence learn- ing problem <ref type="bibr" target="#b22">(Kalchbrenner and Blunsom, 2013;</ref><ref type="bibr" target="#b9">Cho et al., 2014b;</ref><ref type="bibr" target="#b41">Sutskever et al., 2014</ref>) where each training example consists of one source and one target variable-length sequences, with no prior information on the alignment between the two.</p><p>In the context of NMT, <ref type="bibr" target="#b0">Bahdanau et al. (2015)</ref> first proposed to use an attention mechanism in the decoder, which is trained to attend to the rel- evant source-language words as it generates each word of the target sentence. Similarly, <ref type="bibr" target="#b45">Xu et al. (2015)</ref> proposed an attention-based model for the task of image description generation (IDG) where a model learns to attend to specific parts of an im- age representation (the source) as it generates its description (the target) in natural language.</p><p>We are inspired by recent successes in applying attention-based models to NMT and IDG. In this work, we propose an end-to-end attention-based multi-modal neural machine translation (MNMT) model which effectively incorporates two inde- pendent attention mechanisms, one over source- language words and the other over different areas of an image.</p><p>Our main contributions are:</p><p>• We propose a novel attention-based MNMT model which incorporates spatial visual fea- tures in a separate visual attention mecha- nism;</p><p>• We use a medium-sized, back-translated multi-modal in-domain data set and large general-domain text-only MT corpora to pre- train our models and show that our MNMT model can efficiently exploit both;</p><p>• We show that images bring useful informa- tion into an NMT model, e.g. in situations in which sentences describe objects illustrated in the image.</p><p>To the best of our knowledge, previous MNMT models in the literature that utilised spatial vi- sual features did not significantly improve over a comparable model that used global visual fea- tures or even only textual features <ref type="bibr" target="#b3">(Caglayan et al., 2016a;</ref><ref type="bibr" target="#b5">Calixto et al., 2016;</ref><ref type="bibr" target="#b20">Huang et al., 2016;</ref><ref type="bibr">Libovick´ybovick´y et al., 2016;</ref>. In this work, we wish to address this issue and propose an MNMT model that uses, in addition to an atten- tion mechanism over the source-language words, an additional visual attention mechanism to incor- porate spatial visual features, and still improves on simpler text-only and multi-modal attention-based NMT models.</p><p>The remainder of this paper is structured as follows. We first briefly revisit the attention- based NMT framework ( §2) and expand it into an MNMT framework ( §3). In §4, we introduce the datasets we use to train and evaluate our models, in §5 we discuss our experimental setup and anal- yse and discuss our results. Finally, in §6 we dis- cuss relevant related work and in §7 we draw con- clusions and provide avenues for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background and Notation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Attention-based NMT</head><p>In this section, we describe the attention-based NMT model introduced by <ref type="bibr" target="#b0">Bahdanau et al. (2015)</ref>. Given a source sequence X = (x 1 , x 2 , · · · , x N ) and its translation Y = (y 1 , y 2 , · · · , y M ), an NMT model aims to build a single neural network that translates X into Y by directly learning to model p(Y | X). The entire network consists of one en- coder and one decoder with one attention mech- anism, typically implemented as two Recurrent Neural Networks (RNN) and one multilayer per- ceptron, respectively. Each x i is a row index in a source lookup or word embedding matrix E x ∈ R |Vx|×dx , as well as each y j being an in- dex in a target lookup or word embedding matrix E y ∈ R |Vy|×dy , V x and V y are source and target vocabularies, and d x and d y are source and target word embeddings dimensionalities, respectively.</p><p>The encoder is a bi-directional RNN with GRU ( <ref type="bibr" target="#b8">Cho et al., 2014a)</ref>, where a forward RNN − → Φ enc reads X word by word, from left to right, and generates a sequence of forward annota- tion vectors (</p><formula xml:id="formula_0">− → h 1 , − → h 2 , · · · , − → h N ) at each encoder time step i ∈ [1, N ].</formula><p>Similarly, a backward RNN ← − Φ enc reads X from right to left, word by word, and generates a sequence of backward annota- tion vectors (</p><formula xml:id="formula_1">← − h N , ← − h N −1 , · · · , ← − h 1 ).</formula><p>The final annotation vector is the concatenation of for- ward and backward vectors</p><formula xml:id="formula_2">h i = − → h i ; ← − h i , and C = (h 1 , h 2 , · · · , h N )</formula><p>is the set of source anno- tation vectors.</p><p>These annotation vectors are in turn used by the decoder, which is essentially a neural language model (LM) ( <ref type="bibr" target="#b1">Bengio et al., 2003</ref>) conditioned on the previously emitted words and the source sen- tence via an attention mechanism. A multilayer perceptron is used to initialise the decoder's hid- den state s 0 at time step t = 0, where the input to this network is the concatenation of the last for- ward and backward vectors − → h N ; ← − h 1 . At each time step t of the decoder, a time- dependent source context vector c t is computed based on the annotation vectors C and the decoder previous hidden state s t−1 . This is part of the for- mulation of the conditional GRU and is described further in §2.2. In other words, the encoder is a bi-directional RNN with GRU and the decoder is an RNN with a conditional GRU.</p><p>Given a hidden state s t , the probabilities for the next target word are computed using one pro- jection layer followed by a softmax layer as il- lustrated in eq. <ref type="formula">(1)</ref>, where the matrices L o , L s , L w and L c are transformation matrices and c t is a time-dependent source context vector generated by the conditional GRU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Conditional GRU</head><p>The conditional GRU 1 , illustrated in <ref type="figure">Figure 1</ref>, has three main components computed at each time step t of the decoder:</p><p>• REC 1 computes a hidden state proposal s t based on the previous hidden state s t−1 and the previously emitted wordˆywordˆ wordˆy t−1 ;</p><p>• ATT src 2 is an attention mechanism over the hidden states of the source-language RNN and computes c t using all source annotation vectors C and the hidden state proposal s t ; • REC 2 computes the final hidden state s t us- ing the hidden state proposal s t and the time- dependent source context vector c t .</p><p>First, a single-layer feed-forward network is used to compute an expected alignment e src t,i be- tween each source annotation vector h i and the target wordˆywordˆ wordˆy t to be emitted at the current time step t, as shown in Equations (2) and (3):</p><formula xml:id="formula_3">e src t,i = (v src a ) T tanh(U src a s t + W src a h i ),<label>(2)</label></formula><formula xml:id="formula_4">α src t,i = exp (e src t,i ) N j=1 exp (e src t,j ) ,<label>(3)</label></formula><p>where α src t,i is the normalised alignment matrix be- tween each source annotation vector h i and the wordˆywordˆ wordˆy t to be emitted at time step t, and v src a , U src a and W src a are model parameters. Finally, a time-dependent source context vector c t is computed as a weighted sum over the source annotation vectors, where each vector is weighted by the attention weight α src t,i , as in eq. (4):</p><formula xml:id="formula_5">c t = N i=1 α src t,i h i .<label>(4)</label></formula><formula xml:id="formula_6">p(y t = k | y &lt;t , c t ) ∝ exp(L o tanh(L s s t + L w E y [ˆ y t−1 ] + L c c t )).</formula><p>(1) <ref type="figure">Figure 1</ref>: An illustration of the conditional GRU: the steps taken to compute the current hidden state s t from the previous state s t−1 , the previously emitted wordˆywordˆ wordˆy t−1 , and the source annotation vec- tors C, including the candidate hidden state s t and the source-language attention vector c t .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Multi-modal NMT</head><p>Our MNMT model can be seen as an expansion of the attention-based NMT framework described in §2.1 with the addition of a visual component to incorporate spatial visual features.</p><p>We use publicly available pre-trained CNNs for image feature extraction. Specifically, we extract spatial image features for all images in our dataset using the 50-layer Residual network (ResNet-50) of . These spatial features are the activations of the res4f layer, which can be seen as encoding an image in a 14×14 grid, where each of the entries in the grid is represented by a 1024D feature vector that only encodes infor- mation about that specific region of the image. We vectorise this 3-tensor into a 196×1024 matrix</p><formula xml:id="formula_7">A = (a 1 , a 2 , · · · , a L ), a l ∈ R 1024</formula><p>where each of the L = 196 rows consists of a 1024D feature vec- tor and each column, i.e. feature vector, represents one grid in the image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">NMT SRC+IMG : decoder with two independent attention mechanisms</head><p>Model NMT SRC+IMG integrates two separate atten- tion mechanisms over the source-language words and visual features in a single decoder RNN. Our doubly-attentive decoder RNN is conditioned on the previous hidden state of the decoder and the previously emitted word, as well as the source sen- tence and the image via two independent attention mechanisms, as illustrated in <ref type="figure">Figure 2</ref>. We implement this idea expanding the con- ditional GRU described in §2.2 onto a doubly- conditional GRU. To that end, in addition to the source-language attention, we introduce a new at- tention mechanism ATT img to the original condi- tional GRU proposal. This visual attention com- putes a time-dependent image context vector i t given a hidden state proposal s t and the image an- notation vectors A = (a 1 , a 2 , · · · , a L ) using the "soft" attention ( <ref type="bibr" target="#b45">Xu et al., 2015)</ref>.</p><p>This attention mechanism is very similar to the source-language attention with the addition of a gating scalar, explained further below. First, a single-layer feed-forward network is used to com- pute an expected alignment e img t,l between each im- age annotation vector a l and the target word to be emitted at the current time step t, as in eqs. <ref type="formula">(5)</ref> and <ref type="formula" target="#formula_8">(6)</ref>:</p><formula xml:id="formula_8">e img t,l = (v img a ) T tanh(U img a s t + W img a a l ), (5) α img t,l = exp (e img t,l ) L j=1 exp (e img t,j ) ,<label>(6)</label></formula><p>where α img t,l is the normalised alignment matrix between all the image patches a l and the target word to be emitted at time step t, and v  <ref type="formula" target="#formula_3">(2)</ref> and <ref type="formula" target="#formula_4">(3)</ref>, that compute the expected source alignment e src t,i and the weight matrices α src t,i , and eqs. <ref type="formula">(5)</ref> and <ref type="formula" target="#formula_8">(6)</ref> that compute the expected image alignment e img t,l and the weight matrices α img t,l , both compute similar statistics over the source and im- age annotations, respectively.</p><p>In eq. <ref type="formula" target="#formula_9">(7)</ref> we compute β t ∈ [0, 1], a gating scalar used to weight the expected importance of the im- age context vector in relation to the next target word at time step t:</p><formula xml:id="formula_9">β t = σ(W β s t−1 + b β ),<label>(7)</label></formula><p>where W β , b β are model parameters. It is in turn used to compute the time-dependent image con- text vector i t for the current decoder time step t, as in eq. <ref type="formula" target="#formula_10">(8)</ref>:</p><formula xml:id="formula_10">i t = β t L l=1 α img t,l a l .<label>(8)</label></formula><p>Figure 2: A doubly-attentive decoder learns to at- tend to image patches and source-language words independently when generating translations.</p><p>The only difference between Equations (4) (source context vector) and (8) (image context vector) is that the latter uses a gating scalar, whereas the former does not. We use β follow- ing <ref type="bibr" target="#b45">Xu et al. (2015)</ref> who empirically found it to improve the variability of the image descriptions generated with their model. Finally, we use the time-dependent image con- text vector i t as an additional input to a modified version of REC 2 ( §2.2), which now computes the final hidden state s t using the hidden state pro- posal s t , and the time-dependent source and image context vectors c t and i t , as in eq. <ref type="formula" target="#formula_11">(9)</ref>:</p><formula xml:id="formula_11">z t = σ(W src z c t + W img z i t + U z s j ), r t = σ(W src r c t + W img r i t + U r s j ), s t = tanh(W src c t + W img i t + r t (U s t )), s t = (1 − z t ) s t + z t s t .<label>(9)</label></formula><p>In Equation (10), the probabilities for the next target word are computed using the new multi- modal hidden state s t , the previously emitted wordˆy wordˆ wordˆy t−1 , and the two context vectors c t and i t , where L o , L s , L w , L cs and L ci are projection matrices and trained with the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Data</head><p>The Flickr30k data set contains 30k images and 5 descriptions in English for each image <ref type="bibr" target="#b46">(Young et al., 2014)</ref>. In this work, we use the Multi30k dataset ( , which consists of two multilingual expansions of the original Flickr30k: one with translated data and another one with comparable data, henceforth referred to as M30k T and M30k C , respectively.</p><p>For each of the 30k images in the Flickr30k, the M30k T has one of the English descriptions manually translated into German by a professional translator. Training, validation and test sets con- tain 29k, 1,014 and 1k images respectively, each accompanied by a sentence pair (the original En- glish sentence and its translation into German). For each of the 30k images in the Flickr30k, the M30k C has five descriptions in German col- lected independently from the English descrip- tions. Training, validation and test sets contain 29k, 1,014 and 1k images respectively, each ac- companied by five sentences in English and five sentences in German.</p><p>We use the entire M30k T training set for train- ing our MNMT models, its validation set for model selection with BLEU ( <ref type="bibr" target="#b33">Papineni et al., 2002</ref>), and its test set for evaluation. In addi- tion, since the amount of training data available is small, we build a back-translation model using the text-only NMT model described in §2.1 trained on the Multi30k T data set (German→English and English→German), without images. We use this model to back-translate the 145k German (En- glish) descriptions in the Multi30k C into En- glish (German) and include the triples (synthetic English description, German description, image) when translating into German, and the triples (syn- thetic German description, English description, image) when translating into English, as addi- tional training data ( <ref type="bibr" target="#b35">Sennrich et al., 2016a</ref>).</p><p>We also use the WMT 2015 text-only paral- lel corpora available for the English-German lan- guage pair, consisting of about 4.3M sentence pairs ( <ref type="bibr" target="#b2">Bojar et al., 2015)</ref>. These include the Eu-</p><formula xml:id="formula_12">p(y t = k | y &lt;t , C, A) ∝ exp(L o tanh(L s s t + L w E y [ˆ y t−1 ] + L cs c t + L ci i t )).<label>(10)</label></formula><p>roparl v7 ( <ref type="bibr" target="#b24">Koehn, 2005)</ref>, News Commentary and Common Crawl corpora, which are concatenated and used for pre-training.</p><p>We use the scripts in the Moses SMT Toolkit ( <ref type="bibr" target="#b25">Koehn et al., 2007</ref></p><note type="other">) to normalise and tokenize English and German descriptions, and we also convert space-separated tokens into sub- words (Sennrich et al., 2016b). All models use a common vocabulary of 83, 093 English and 91, 141 German subword tokens. If sentences in English or German are longer than 80 tokens, they are discarded. We train models to translate from English into German, as well as for German into English, and report evaluation of cased, tokenized sentences with punctuation.</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental setup</head><p>Our encoder is a bidirectional RNN with GRU, one 1024D single-layer forward and one 1024D single-layer backward RNN. Source and target word embeddings are 620D each and trained jointly with the model. Word embeddings and other non-recurrent matrices are initialised by sampling from a Gaussian N (0, 0.01 2 ), recurrent matrices are random orthogonal and bias vectors are all initialised to zero. Visual features are obtained by feeding images to the pre-trained ResNet-50 and using the activa- tions of the res4f layer ( ). We apply dropout with a probability of 0.5 in the en- coder bidirectional RNN, the image features, the decoder RNN and before emitting a target word. We follow <ref type="bibr" target="#b16">Gal and Ghahramani (2016)</ref> and apply dropout to the encoder bidirectional and the de- coder RNN using one same mask in all time steps.</p><p>All models are trained using stochastic gradi- ent descent with ADADELTA (Zeiler, 2012) with minibatches of size 80 (text-only NMT) or 40 (MNMT), where each training instance consists of one English sentence, one German sentence and one image (MNMT). We apply early stopping for model selection based on BLEU4, so that if a model does not improve on BLEU4 in the valida- tion set for more than 20 epochs, training is halted.</p><p>The translation quality of our models is eval- uated quantitatively in terms of BLEU4 <ref type="bibr" target="#b33">(Papineni et al., 2002</ref>), METEOR <ref type="bibr" target="#b11">(Denkowski and Lavie, 2014</ref>), TER ( <ref type="bibr" target="#b39">Snover et al., 2006</ref>), and chrF3 <ref type="bibr" target="#b34">(Popovi´cPopovi´c, 2015)</ref>. <ref type="bibr">3</ref> We report statistical sig- nificance with approximate randomisation for the first three metrics with <ref type="bibr">MultEval (Clark et al., 2011</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Baselines</head><p>We train a text-only phrase-based SMT (PBSMT) system and a text-only NMT model for compar- ison (English→German and German→English). Our PBSMT baseline is built with Moses and uses a 5-gram LM with modified Kneser-Ney smoothing <ref type="bibr" target="#b23">(Kneser and Ney, 1995)</ref>. It is trained on the English→German (German→English) de- scriptions of the M30k T , whereas its LM is trained on the German (English) descriptions only. We use minimum error rate training to tune the model with BLEU <ref type="bibr" target="#b32">(Och, 2003)</ref>. The text-only NMT baseline is the one described in §2.1 and is trained on the M30k T 's English-German descriptions, again in both language directions.</p><p>When translating into German, we also com- pare our model against two publicly available re- sults obtained with multi-modal attention-based NMT models. The first model is <ref type="bibr" target="#b20">Huang et al. (2016)</ref>'s best model trained on the same data, and the second is their best model using additional ob- ject detections, respectively models m1 (image at head) and m3 in the authors' paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results</head><p>In <ref type="table" target="#tab_0">Table 1</ref>, we show results for the two text- only baselines NMT and PBSMT, the multi- modal models of <ref type="bibr" target="#b20">Huang et al. (2016)</ref>, and our MNMT models trained on the M30k T and pre- trained on the in-domain back-translated M30k C and the general-domain text-only English-German MT corpora from WMT 2015. All models are trained to translate from English into German.</p><p>Training on M30k T One main finding is that our model consistently outperforms the compa- rable model of <ref type="bibr" target="#b20">Huang et al. (2016)</ref> when trans- lating into German, with improvements of +1.4 BLEU and +2.7 METEOR. In fact, even when their model has access to more data our model still improves by +0.9 METEOR.</p><p>Moreover, we can also conclude from  <ref type="table" target="#tab_0">Table 1</ref>: BLEU4, METEOR, chrF3, character-level precision and recall (higher is better) and TER scores (lower is better) on the translated Multi30k (M30k T ) test set. Best text-only baselines results are under- lined and best overall results appear in bold. We show <ref type="bibr" target="#b20">Huang et al. (2016)</ref>'s improvements over the best text-only baseline in parentheses. Results are significantly better than the NMT baseline ( † ) and the SMT baseline ( ‡ ) with p &lt; 0.01 (no pre-training) or p &lt; 0.05 (when pre-training either on the back-translated M30k C or WMT'15 corpora).</p><formula xml:id="formula_13">NMT SRC+IMG vs. best PBSMT ↑ 6.4 ↑ 2.7 ↓ 5.4 ↑ 2.3 ↑ 3.3 / ↑ 2.2 NMT SRC+IMG vs. NMT ↑ 1.2 ↑ 0.1 ↓ 0.4 ↑ 0.4 ↓ 0.1 / ↑ 0.5</formula><p>metrics, i.e. METEOR and chrF3, whereas NMT is better at precision-oriented ones, i.e. BLEU4. This is somehow expected, since the attention mechanism in NMT ( <ref type="bibr" target="#b0">Bahdanau et al., 2015)</ref> does not explicitly take attention weights from previous time steps into account, an thus lacks the notion of source coverage as in SMT ( <ref type="bibr" target="#b27">Koehn et al., 2003;</ref><ref type="bibr" target="#b42">Tu et al., 2016</ref>). We note that these ideas are com- plementary and incorporating coverage into model NMT SRC+IMG could lead to more improvements, especially in recall-oriented metrics. Nonetheless, our doubly-attentive model shows consistent gains in both precision-and recall-oriented metrics in comparison to the text-only NMT baseline, i.e. it is significantly better according to BLEU4, ME- TEOR and TER (p &lt; 0.01), and it also improves chrF3 by +2.1. In comparison to the PBSMT baseline, our proposed model still significantly improves according to both BLEU4 and TER (p &lt; 0.01), also increasing METEOR by +0.7 but with an associated p-value of p = 0.071, therefore not significant for p &lt; 0.05. Although chrF3 is the only metric in which the PBSMT model scores best, the difference between our model and the lat- ter is only 0.1, meaning that they are practically equivalent. We note that model NMT SRC+IMG con- sistently increases character recall in comparison to the text-only NMT baseline. Although it can happen at the expense of character precision, gains in recall are always much higher than any eventual loss in precision, leading to consistent improve- ments in chrF3.</p><p>In <ref type="table">Table 2</ref>, we observe that when translating into English and training on the original M30k T , model NMT SRC+IMG outperforms both baselines by a large margin, according to all four met- rics evaluated. We also note that both model NMT SRC+IMG 's character-level precision and re-  <ref type="table">Table 2</ref>: BLEU4, METEOR, chrF3 (higher is bet- ter), and TER scores (lower is better) on the trans- lated Multi30k (M30k T ) test set. Best text-only baselines results are underlined and best overall results appear in bold. Results are significantly better than the NMT baseline ( † ) and the SMT baseline ( ‡ ) with p &lt; 0.01.</p><p>call are higher than those of the two baselines, in contrast to results obtained when translating from English into German. This suggests that model NMT SRC+IMG might better integrate the image fea- tures when translating into an "easier" language, i.e. a language with less morphology, although ex- periments involving more language pairs are nec- essary to confirm whether this is indeed the case.</p><p>Pre-training We now discuss results for mod- els pre-trained using different data sets. We first pre-trained the two text-only baselines PBSMT and NMT, and our MNMT model on the back- translated M30k C , a medium-sized in-domain im- age description data set (145k training instances), in both directions. We also pre-trained the same models on the English-German parallel sentences of much larger MT data sets, i.e. the concatenation of the Europarl ( <ref type="bibr" target="#b24">Koehn, 2005)</ref>, Common Crawl and News Commentary corpora, used in WMT 2015 (∼4.3M parallel sentences). Model PB- SMT (concat.) used the concatenation of the pre- training and training data for training, and model PBSMT (LM) used the general-domain German sentences as additional data to train the LM. From <ref type="table" target="#tab_0">Tables 1 and 2</ref>, it is clear that model NMT SRC+IMG can learn from both in-domain, multi-modal pre- training data sets as well as text-only, general do- main ones.</p><p>Pre-training on M30k C When pre-training on the back-translated M30k C and translating into German, the recall-oriented chrF3 shows a dif- ference of 1.4 points between PBSMT and our model, mostly due to character recall; nonethe- less, our model still improved by the same mar- gin on the text-only NMT baseline. Our model still outperforms the PBSMT baseline according to BLEU4 and TER, and the text-only NMT base- line according to all metrics (p &lt; .05).</p><p>When translating into English, model NMT SRC+IMG still consistently scores higher according to all metrics evaluated, although the differences between its translations and those obtained with the NMT baseline are no longer statistically significant (p &lt; 0.01).</p><p>Pre-training on WMT 2015 corpora We also pre-trained our English-German models on the WMT 2015 corpora, which took 10 days, i.e. ∼6-7 epochs. Results show that model NMT SRC+IMG improves significantly over the NMT baseline according to BLEU4, and is con- sistently better than the PBSMT baseline accord- ing to all four metrics. 4 This is a strong indica- tion that model NMT SRC+IMG can exploit the ad- ditional pre-training data efficiently, both general- and in-domain. While the PBSMT model is still competitive when using additional in-domain data-according to METEOR and chrF3-the same cannot be said when using general-domain pre-training corpora. From our experiments, NMT models in general, and especially model NMT SRC+IMG , thrive when training and test do- mains are mixed, which is a very common real- world scenario.</p><p>Textual and visual attention In <ref type="figure" target="#fig_2">Figure 3</ref>, we visualise the visual and textual attention weights for an entry of the M30k T test set. In the visual attention, the β gate (written in parentheses after each word) caused the image features to be used mostly to generate the words Mann (man) and Hut (hat), two highly visual terms in the sentence. We observe that in general visually grounded terms, e.g. Mann and Hut, usually have a high associated β value, whereas other less visual terms like mit (with) or auf (at) do not. That causes the model to use the image features when it is describing a vi- sual concept in the sentence, which is an interest-  ing feature of our model. Interestingly, our model is very selective when choosing to use image fea- tures: it only assigned β &gt; 0.5 for 20% of the out- putted target words, and β &gt; 0.8 to only 8%. A manual inspection of translations shows that these words are mostly concrete nouns with a strong vi- sual appeal.</p><p>Lastly, using two independent attention mech- anisms is a good compromise between model compactness and flexibility. While the attention- based NMT model baseline has ∼200M parame- ters, model NMT SRC+IMG has ∼213M, thus using just ∼6.6% more parameters than the latter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related work</head><p>Multi-modal MT was just recently addressed by the MT community by means of a shared task ( . However, there has been a considerable amount of work on natu- ral language generation from non-textual inputs. In the context of NMT, Zoph and Knight (2016) introduced a multi-source attention-based NMT model trained to translate a pair of sentences in two different source languages into a target lan- guage, and reported considerable improvements over a single-source baseline. <ref type="bibr" target="#b12">Dong et al. (2015)</ref> proposed a multi-task learning approach where a model is trained to translate from one source lan- guage into multiple target languages. <ref type="bibr" target="#b15">Firat et al. (2016)</ref> put forward a multi-way model trained to translate between many different source and tar- get languages. Instead of one attention mecha- nism per language pair as in <ref type="bibr" target="#b12">Dong et al. (2015)</ref>, which would lead to a quadratic number of atten- tion mechanisms in relation to language pairs, they use a shared attention mechanism where each tar- get language has one attention shared by all source languages. <ref type="bibr" target="#b29">Luong et al. (2016)</ref> proposed a multi- task approach where they train a model using two tasks and a shared decoder: the main task is to translate from German into English and the sec-ondary task is to generate English image descrip- tions. They show improvements in the main trans- lation task when also training for the secondary image description task. Although not an NMT model, <ref type="bibr" target="#b19">Hitschler et al. (2016)</ref> recently used image features to re-rank translations of image descrip- tions generated by an SMT model and reported significant improvements.</p><p>Although no purely neural multi-modal model to date significantly improves on both text-only NMT and SMT models ( , dif- ferent research groups have proposed to include global and spatial visual features in re-ranking n-best lists generated by an SMT system or di- rectly in an NMT framework with some suc- cess <ref type="bibr" target="#b3">(Caglayan et al., 2016a;</ref><ref type="bibr" target="#b5">Calixto et al., 2016;</ref><ref type="bibr" target="#b20">Huang et al., 2016;</ref><ref type="bibr">Libovick´yLibovick´y et al., 2016;</ref><ref type="bibr" target="#b37">Shah et al., 2016)</ref>. To the best of our knowledge, the best published results of a purely MNMT model are those of <ref type="bibr" target="#b20">Huang et al. (2016)</ref>, who proposed to use global visual features extracted with the VGG19 network ( <ref type="bibr" target="#b38">Simonyan and Zisserman, 2015)</ref> for an entire image, and also for regions of the im- age obtained using the RCNN of <ref type="bibr" target="#b17">Girshick et al. (2014)</ref>. Their best model improves over a strong text-only NMT baseline and is comparable to re- sults obtained with an SMT model trained on the same data. For that reason, their models are used as baselines in our experiments whenever possible.</p><p>Our work differs from previous work in that, first, we propose attention-based MNMT mod- els. This is an important difference since the use of attention in NMT has become standard and is the current state-of-the-art ( <ref type="bibr" target="#b21">Jean et al., 2015;</ref><ref type="bibr" target="#b30">Luong et al., 2015;</ref><ref type="bibr" target="#b15">Firat et al., 2016;</ref><ref type="bibr" target="#b36">Sennrich et al., 2016b</ref>). Second, we propose a doubly- attentive model where we effectively fuse two mono-modal attention mechanisms into one multi- modal decoder, training the entire model jointly and end-to-end. Additionally, we are interested in how to merge textual and visual representa- tions into multi-modal representations when gen- erating words in the target language, which differs substantially from text-only translation tasks even when these translate from many source languages and/or into many target languages ( <ref type="bibr" target="#b12">Dong et al., 2015;</ref><ref type="bibr" target="#b15">Firat et al., 2016;</ref><ref type="bibr" target="#b48">Zoph and Knight, 2016)</ref>. To the best of our knowledge, we are among the first <ref type="bibr">6</ref> to integrate multi-modal inputs in NMT via <ref type="bibr">6</ref> As pointed out by an anonymous reviewer, <ref type="bibr" target="#b4">Caglayan et al. (2016b)</ref> have also experimented with attention-based independent attention mechanisms.</p><p>Applications Initial experiments with model NMT SRC+IMG have been reported in <ref type="bibr" target="#b5">Calixto et al. (2016)</ref>. Additionally, NMT SRC+IMG has been ap- plied to the machine translation of user-generated product listings from an e-commerce website, while also making use of the product images to improve translations ( <ref type="bibr" target="#b7">Calixto et al., 2017b</ref>,a).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions and Future Work</head><p>We have introduced a novel attention-based, multi-modal NMT model to incorporate spatial visual information into NMT. We have reported state-of-the-art results on the M30k T test set, im- proving on previous multi-modal attention-based models. We have also showed that our model can be efficiently pre-trained on both medium- sized back-translated in-domain multi-modal data as well as also large general-domain text-only MT corpora, finding that it is able to exploit the addi- tional data regardless of the domain. Our model also compares favourably to both NMT and PB- SMT baselines evaluated on the same training data. In the future, we will incorporate coverage into our model and study how to apply it to other Natural Language Processing tasks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>img a , U img a and W img a are model parameters. Note that Equa- tions</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Visualisation of image-and source-target word alignments for the M30k T test set.</figDesc><graphic url="image-4.png" coords="8,288.80,62.81,226.77,181.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Mao et al. (2014) introduced a multi-modal RNN that integrates text and visual features and ap- plied it to the tasks of image description genera- tion and image-sentence ranking. In their work, the authors incorporate global image features in a separate multi-modal layer that merges the RNN textual representations and the global image fea- tures. Vinyals et al. (2015) proposed an influ- ential neural IDG model based on the sequence- to-sequence framework, which is trained end-to- end. Elliott et al. (2015) put forward a model to generate multilingual descriptions of images by learning and transferring features between two in- dependent, non-attentive neural image description models. 5 Venugopalan et al. (2015) introduced a model trained end-to-end to generate textual de- scriptions of open-domain videos from the video frames based on the sequence-to-sequence frame- work. Finally, Xu et al. (2015) introduced the first attention-based IDG model where an attentive de- coder learns to attend to different parts of an image as it generates its description in natural language.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 that PBSMT performs better at recall-oriented</head><label>1</label><figDesc></figDesc><table>English→German 

Model 
Training 
BLEU4↑ 
METEOR↑ TER↓ 
chrF3↑ (prec. / recall) 
data 

NMT 
M30k T 
33.7 
52.3 
46.7 
65.2 (67.7 / 65.0) 
PBSMT 
M30k T 
32.9 
54.3  † 
45.1  † 
67.4 (66.5 / 67.5) 
Huang et al. (2016) M30k T 
35.1 (↑ 1.4) 52.2 (↓ 2.1) 
-
-
-
+ RCNN 
36.5 (↑ 2.8) 54.1 (↓ 0.2) 
-
-
-

NMT SRC+IMG 
M30k T 
36.5  † ‡ 
55.0  † 
43.7  † ‡ 
67.3 (66.8 / 67.4) 

Improvements 

NMT SRC+IMG vs. NMT 
↑ 2.8 
↑ 2.7 
↓ 3.0 
↑ 2.1 ↓ 0.9 / ↑ 2.4 
NMT SRC+IMG vs. PBSMT 
↑ 3.6 
↑ 0.7 
↓ 1.4 
↓ 0.1 ↑ 0.3 / ↓ 0.1 
NMT SRC+IMG vs. Huang 
↑ 1.4 
↑ 2.8 
-
-
-
NMT SRC+IMG vs. Huang (+RCNN) ↑ 0.0 
↑ 0.9 
-
-
-

Pre-training data set: back-translated M30k C (in-domain) 

PBSMT (LM) 
M30k T 
34.0 ↑ 0.0 
55.0  † ↑ 0.0 
44.7 ↑ 0.0 68.0 (66.8 / 68.1) 
NMT 
M30k T 
35.5  ‡ ↑ 0.0 53.4 ↑ 0.0 
43.3  ‡ ↑ 0.0 65.2 (67.7 / 65.0) 
NMT SRC+IMG 
M30k T 
37.1  † ‡ 
54.5  † ‡ 
42.8  † ‡ 
66.6 (67.2 / 66.5) 

NMT SRC+IMG vs. best PBSMT 
↑ 3.1 
↓ 0.5 
↓ 1.9 
↓ 1.4 ↑ 0.4 / ↓ 1.6 
NMT SRC+IMG vs. NMT 
↑ 1.6 
↑ 1.1 
↓ 0.5 
↑ 1.4 ↓ 0.5 / ↑ 1.5 

Pre-training data set: WMT'15 English-German corpora (general domain) 

PBSMT (concat) 
M30k T 
32.6 
53.9 
46.1 
67.3 (66.3 / 67.4) 
PBSMT (LM) 
M30k T 
32.5 
54.1 
46.0 
67.3 (66.0 / 67.4) 
NMT 
M30k T 
37.8  † ↑ 0.0 56.7  † ↑ 0.0 
41.0  † ↑ 0.0 69.2 (69.7 / 69.1) 
NMT SRC+IMG 
M30k T 
39.0  † ‡ 
56.8  † ‡ 
40.6  † ‡ 
69.6 (69.6 / 69.6) 

</table></figure>

			<note place="foot" n="1"> https://github.com/nyu-dl/ dl4mt-tutorial/blob/master/docs/cgru.pdf. 2 ATTsrc is named ATT in the original technical report.</note>

			<note place="foot" n="3"> We specifically compute character 6-gram F3, and additionally character precision and recall for comparison.</note>

			<note place="foot" n="4"> In order for PBSMT models to remain competitive, we believe more advanced data selection techniques are needed, which are out of the scope of this work.</note>

			<note place="foot" n="5"> Although their model has not been devised with translation as its primary goal, theirs is one of the baselines of the first shared task in multi-modal MT in WMT 2016 (Specia et al., 2016).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This project has received funding from Science Foundation Ireland in the ADAPT Centre for Dig-ital Content Technology (www.adaptcentre.ie) at Dublin City University funded under the SFI Re-search Centres Programme (Grant 13/RC/2106) co-funded under the European Regional Develop-ment Fund and the European Union Horizon 2020 research and innovation programme under grant agreement 645452 (QT21). The authors would like to thank Chris Hokamp, Peyman Passban, and Dasha Bogdanova for insightful discussions at early stages of this work, Andy Way for proof-reading and providing many good suggestions of improvements, as well as our anonymous review-ers for their valuable comments and feedback.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reproducibility</head><p>Code and pre-trained models for this pa-per are available at https://github. com/iacercalixto/nmt_doubly_ attentive.</p><p>multi-modal NMT.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Neural Machine Translation by Jointly Learning to Align and Translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations, ICLR 2015</title>
		<meeting><address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A Neural Probabilistic Language Model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Réjean</forename><surname>Ducharme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Janvin</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=944919.944966" />
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1137" to="1155" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajen</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Huck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Hokamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varvara</forename><surname>Logacheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carolina</forename><surname>Scarton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Turchi</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/W15-3001" />
		<title level="m">Proceedings of the Tenth Workshop on Statistical Machine Translation</title>
		<meeting>the Tenth Workshop on Statistical Machine Translation<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="46" />
		</imprint>
	</monogr>
	<note>Findings of the 2015 workshop on statistical machine translation</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Does multimodality help human and machine for translation and image captioning?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozan</forename><surname>Caglayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walid</forename><surname>Aransa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaxing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Masana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mercedes</forename><surname>García-Martínez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lo¨ıclo¨ıc</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joost</forename><surname>Van De Weijer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Conference on Machine Translation</title>
		<meeting>the First Conference on Machine Translation<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="627" to="633" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Multimodal Attention for Neural Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozan</forename><surname>Caglayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lo¨ıclo¨ıc</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<idno>CoRR abs/1609.03976</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">DCU-UvA Multimodal MT System Report</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iacer</forename><surname>Calixto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Desmond</forename><surname>Elliott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stella</forename><surname>Frank</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/W/W16/W16-2359" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Conference on Machine Translation</title>
		<meeting>the First Conference on Machine Translation<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="634" to="638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Human Evaluation of Multi-modal Neural Machine Translation: A Case-Study on E-Commerce Listing Titles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iacer</forename><surname>Calixto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeny</forename><surname>Matusov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheila</forename><surname>Castilho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Way</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/W17-2004" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Workshop on Vision and Language</title>
		<meeting>the Sixth Workshop on Vision and Language<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="31" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Using Images to Improve Machine-Translating ECommerce Product Listings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iacer</forename><surname>Calixto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeny</forename><surname>Matusov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pintu</forename><surname>Lohar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheila</forename><surname>Castilho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Way</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/E17-2101" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter</title>
		<meeting>the 15th Conference of the European Chapter<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="637" to="643" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">On the properties of neural machine translation: Encoder-decoder approaches. Syntax, Semantics and Structure in Statistical Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page">103</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning phrase representations using rnn encoderdecoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1724" to="1734" />
		</imprint>
	</monogr>
	<note>Holger Schwenk, and Yoshua Bengio</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Better Hypothesis Testing for Statistical Machine Translation: Controlling for Optimizer Instability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">H</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: Short Papers</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: Short Papers<address><addrLine>Portland, Oregon</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="176" to="181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Meteor Universal: Language Specific Translation Evaluation for Any Target Language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Denkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the EACL 2014 Workshop on Statistical Machine Translation</title>
		<meeting>the EACL 2014 Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Multi-Task Learning for Multiple Language Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daxiang</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dianhai</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P15-1166" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1723" to="1732" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Multi-Language Image Description with Neural Sequence Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Desmond</forename><surname>Elliott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stella</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eva</forename><surname>Hasler</surname></persName>
		</author>
		<idno>CoRR abs/1510.04709</idno>
		<ptr target="http://arxiv.org/abs/1510.04709" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Multi30K: Multilingual English-German Image Descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Desmond</forename><surname>Elliott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stella</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khalil</forename><surname>Sima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/W/W16/W16-3210.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th Workshop on Vision and Language, VL@ACL 2016. Berlin, Germany</title>
		<meeting>the 5th Workshop on Vision and Language, VL@ACL 2016. Berlin, Germany</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Multi-Way, Multilingual Neural Machine Translation with a Shared Attention Mechanism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Orhan</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/N16-1101" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="866" to="875" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A Theoretically Grounded Application of Dropout in Recurrent Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/6241-a-theoretically-grounded-application-of-dropout-in-recurrent-neural-networks.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems, NIPS</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1019" to="1027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
		<idno type="doi">10.1109/CVPR.2014.81</idno>
		<ptr target="https://doi.org/10.1109/CVPR.2014.81" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the 2014 IEEE Conference on Computer Vision and Pattern Recognition<address><addrLine>Washington, DC, USA, CVPR</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="580" to="587" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.03385</idno>
		<title level="m">Deep residual learning for image recognition</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Multimodal Pivots for Image Caption Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Hitschler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shigehiko</forename><surname>Schamoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Riezler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2399" to="2409" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Attention-based Multimodal Neural Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Po-Yao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederick</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sz-Rung</forename><surname>Shiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Conference on Machine Translation</title>
		<meeting>the First Conference on Machine Translation<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="639" to="645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">On Using Very Large Target Vocabulary for Neural Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sébastien</forename><surname>Jean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Memisevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P15-1001" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Recurrent Continuous Translation Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Seattle, US</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1700" to="1709" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Improved backing-off for m-gram language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reinhard</forename><surname>Kneser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<meeting>the IEEE International Conference on Acoustics, Speech and Signal Processing<address><addrLine>Michigan</addrLine></address></meeting>
		<imprint>
			<publisher>Detroit</publisher>
			<date type="published" when="1995" />
			<biblScope unit="volume">I</biblScope>
			<biblScope unit="page" from="181" to="184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Europarl: A Parallel Corpus for Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<ptr target="http://mt-archive.info/MTS-2005-Koehn.pdf" />
	</analytic>
	<monogr>
		<title level="m">Conference Proceedings: the tenth Machine Translation Summit. AAMT, AAMT</title>
		<meeting><address><addrLine>Phuket, Thailand</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Moses: Open Source Toolkit for Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brooke</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wade</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Herbst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions</title>
		<meeting>the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<title level="m">ACL &apos;07</title>
		<meeting><address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="177" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Statistical Phrase-based Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz</forename><forename type="middle">Josef</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
		<idno type="doi">10.3115/1073445.1073462</idno>
		<ptr target="https://doi.org/10.3115/1073445.1073462" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology</title>
		<meeting>the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology<address><addrLine>Edmonton, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="48" to="54" />
		</imprint>
	</monogr>
	<note>NAACL &apos;03</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Ondřej Bojar, and Pavel Pecina. 2016. CUNI System for WMT16 Automatic Post-Editing and Multimodal Translation Tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jindřich</forename><surname>Libovick´ylibovick´y</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jindřich</forename><surname>Helcl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marek</forename><surname>Tlust´ytlust´y</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Conference on Machine Translation</title>
		<meeting>the First Conference on Machine Translation<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="646" to="654" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Multi-Task Sequence to Sequence Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)<address><addrLine>San Juan, Puerto Rico</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Effective Approaches to Attentionbased Neural Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1412" to="1421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junhua</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1410.1090" />
		<title level="m">Explain Images with Multimodal Recurrent Neural Networks</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Minimum Error Rate Training in Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz Josef</forename><surname>Och</surname></persName>
		</author>
		<idno type="doi">10.3115/1075096.1075117</idno>
		<ptr target="https://doi.org/10.3115/1075096.1075117" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 41st Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="160" to="167" />
		</imprint>
	</monogr>
	<note>Sapporo, Japan, ACL &apos;03</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">BLEU: A Method for Automatic Evaluation of Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="doi">10.3115/1073083.1073135</idno>
		<ptr target="https://doi.org/10.3115/1073083.1073135" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting on Association for Computational Linguistics. Philadelphia, Pennsylvania, ACL &apos;02</title>
		<meeting>the 40th Annual Meeting on Association for Computational Linguistics. Philadelphia, Pennsylvania, ACL &apos;02</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">chrf: character n-gram fscore for automatic mt evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maja</forename><surname>Popovi´cpopovi´c</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/W15-3049" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth Workshop on Statistical Machine Translation</title>
		<meeting>the Tenth Workshop on Statistical Machine Translation<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="392" to="395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Improving Neural Machine Translation the Association for Computational Linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Long Papers</publisher>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="86" to="96" />
			<pubPlace>Berlin, Germany</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Neural Machine Translation of Rare Words with Subword Units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1715" to="1725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">SHEF-Multimodal: Grounding Machine Translation on Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kashif</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josiah</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Conference on Machine Translation</title>
		<meeting>the First Conference on Machine Translation<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="660" to="665" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)<address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A study of translation edit rate with targeted human annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Snover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Dorr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linnea</forename><surname>Micciulla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Makhoul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Association for Machine Translation in the Americas</title>
		<meeting>Association for Machine Translation in the Americas<address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="223" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A Shared Task on Multimodal Machine Translation and Crosslingual Image Description</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stella</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khalil</forename><surname>Sima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Desmond</forename><surname>Elliott</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/W/W16/W16-2346.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Conference on Machine Translation, WMT 2016, colocated with ACL 2016</title>
		<meeting>the First Conference on Machine Translation, WMT 2016, colocated with ACL 2016<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="543" to="553" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Sequence to Sequence Learning with Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<meeting><address><addrLine>Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Modeling Coverage for Neural Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P16-1008" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="76" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Sequence to sequence-video to text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhashini</forename><surname>Venugopalan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
		<idno type="doi">10.1109/ICCV.2015.515</idno>
		<ptr target="https://doi.org/10.1109/ICCV.2015.515" />
	</analytic>
	<monogr>
		<title level="m">2015 IEEE International Conference on Computer Vision, ICCV 2015</title>
		<meeting><address><addrLine>Santiago, Chile</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4534" to="4542" />
		</imprint>
	</monogr>
	<note>Trevor Darrell, and Kate Saenko</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Show and tell: A neural image caption generator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2015</title>
		<meeting><address><addrLine>Boston, Massachusetts</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3156" to="3164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Show, attend and tell: Neural image caption generation with visual attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhudinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Machine Learning (ICML-15). JMLR Workshop and Conference Proceedings</title>
		<meeting>the 32nd International Conference on Machine Learning (ICML-15). JMLR Workshop and Conference Proceedings<address><addrLine>Lille, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2048" to="2057" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions. Transactions of the Association for</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alice</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micah</forename><surname>Hodosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hockenmaier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="67" to="78" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">ADADELTA: An Adaptive Learning Rate Method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zeiler</surname></persName>
		</author>
		<idno>CoRR abs/1212.5701</idno>
		<ptr target="http://arxiv.org/abs/1212.5701" />
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Multi-Source Neural Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/N16-1004" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="30" to="34" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
