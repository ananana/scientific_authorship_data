<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:47+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Prediction of Prospective User Engagement with Intelligent Assistants</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>August 7-12, 2016. 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shumpei</forename><surname>Sano</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Yahoo Japan Corporation</orgName>
								<address>
									<addrLine>9-7-1 Akasaka, Minato-ku</addrLine>
									<postCode>107-6211</postCode>
									<settlement>Tokyo</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nobuhiro</forename><surname>Kaji</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Yahoo Japan Corporation</orgName>
								<address>
									<addrLine>9-7-1 Akasaka, Minato-ku</addrLine>
									<postCode>107-6211</postCode>
									<settlement>Tokyo</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manabu</forename><surname>Sassano</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Yahoo Japan Corporation</orgName>
								<address>
									<addrLine>9-7-1 Akasaka, Minato-ku</addrLine>
									<postCode>107-6211</postCode>
									<settlement>Tokyo</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Prediction of Prospective User Engagement with Intelligent Assistants</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1203" to="1212"/>
							<date type="published">August 7-12, 2016. 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Intelligent assistants on mobile devices, such as Siri, have recently gained considerable attention as novel applications of dialogue technologies. A tremendous amount of real users of intelligent assistants provide us with an opportunity to explore a novel task of predicting whether users will continually use their intelligent assistants in the future. We developed prediction models of prospective user engagement by using large-scale user logs obtained from a commercial intelligent assistant. Experiments demonstrated that our models can predict prospective user engagement reasonably well, and outper-forms a strong baseline that makes prediction based past utterance frequency.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Intelligent assistants on mobile devices, such as Siri, <ref type="bibr">1</ref> have recently gained considerable atten- tion as novel applications of dialogue technologies ( <ref type="bibr" target="#b3">Jiang et al., 2015)</ref>. They receive instructions from users via voice control to execute a wide range of tasks (e.g., searching the Web, setting alarms, making phone calls, and so on). Some are able to even chat or play games with users ( <ref type="bibr" target="#b7">Kobayashi et al., 2015)</ref>.</p><p>Intelligent assistants possess a unique character- istic as an object of dialogue study. Popular intel- ligent assistants have thousands or even millions of real users, thanks to the prevalence of mobile devices. Some of those users continually use in- telligent assistants for a long period of time, while others stop using them after a few trials. Such user behaviors are rarely observed in conventional ex- perimental environments, where dialogue systems 1 http://www.apple.com/ios/siri have only a small number of experimental partici- pants who almost always continue to use the sys- tems for the whole duration of the experiment.</p><p>This paper explores a novel task of predicting whether a user will continue to use intelligent as- sistants in the future (This task is referred to as prospective user engagement prediction and its definition is given in Section 3). We attempt to de- velop such a prediction model, which would con- tribute to enhancing intelligent assistants in many ways. For example, if users who are likely to stop using systems can be identified, intelligent assis- tants can take actions to gain or maintain their in- terest (e.g., by sending push notifications).</p><p>This task is related to, but is significantly differ- ent from, user engagement detection, which has been extensively explored in prior dialogue stud- ies ( <ref type="bibr">Wang and Hirschberg, 2011;</ref><ref type="bibr" target="#b2">Forbes-Riley et al., 2012;</ref><ref type="bibr" target="#b1">Forbes-Riley and Litman, 2013;</ref><ref type="bibr">Oertel and Salvi, 2013)</ref>. The prior studies attempt to pre- dict how strongly users are currently engaged in dialogues with systems. On the other hand, the goal of this study is to predict how strongly users will be engaged with intelligent assistants in the future. The largest difference lies in whether the prediction target is user engagement at present or in the future. Also, our definition of engagement is slightly different from the prior ones. In this study, engagement is considered as a sentiment as to whether users like intelligent assistants and feel like they want to use them continually.</p><p>To develop and evaluate models of prospective user engagement prediction, we exploit large-scale user logs obtained from a commercial intelligent assistant. Since monitoring users' long-term be- haviors is considered crucial for precise prediction of their prospective engagement, we tailor various features by extracting usage patterns from a long history of user dialogues. The resulting features are contrastive to those previously used for user engagement detection, in which features are basi- cally extracted from a single user utterance.</p><p>Experimental results demonstrated that our models are able to predict prospective user en- gagement reasonably well and are overwhelm- ingly better than a strong baseline that makes pre- dictions based on past utterance frequency. We also discuss the trade-off between prediction ac- curacy and instancy. Specifically, we investigate how the prediction performance improves as we wait for more user dialogues to be collected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Yahoo! Voice Assist</head><p>This section summarizes Yahoo! Voice As- sist 2 (hereafter Voice Assist), a commercial intel- ligent assistant that is investigated in this study. Although our investigation exclusively focused on this system, we will discuss how our findings can be generalized to other intelligent assistants in Section 5.5 <ref type="table" target="#tab_0">Table 1</ref> illustrates example dialogues of Voice Assist users. <ref type="bibr">3</ref> As illustrated, Voice Assist offers a variety of functions to mobile users. They are largely categorized into two types: device operation Voice Assist allows users to op- erate mobile devices through dialogue. This includes setting alarms, making phone calls, searching the Web, launching an app, and so on (e.g., V1, V3, V4, and V5).</p><p>chat Voice Assist can give greetings to, have con- versations with, and play games with users (e.g., V2 and V6). In contrast to device oper- ations for accomplishing certain tasks, these functions are offered for fun or for facilitating smooth communication.</p><p>Voice Assist currently supports 66 functions (in- cluding setting alarms, the word chain game, etc.) and they can further be classified into fine-grained types, although a detailed description of them is beyond the scope of this paper. Voice Assist users can register personal pro- file such as their home address and birthday, with which the system makes personalized responses. For example, the home address are used to esti- mate users' location when launching weather fore-U1 Wake me up at 8 o'clock tomorrow. V1 OK. Set the alarm to 8 am.</p><p>(show the timer configuration) U2 Good morning. V2 Good morning. Thank you for talking to me. U3 Check today's weather. V3 Tokyo's weather will be fine today.</p><p>(launch weather forecast app) U4 From Tokyo to Kyoto. V4 A rapid express is available at 9:30.</p><p>(launch transit app to show timetable) U5 What time will it arrive? V5 It will arrive at Kyoto at 11:50.</p><p>(show the timetable again) U6 Let's play the word chain game. V6 OK. Apple... cast apps (i.e., response V3), while knowing birth- days allows Voice Assist to send greeting mes- sages to users on their birthdays.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Prospective User Engagement Prediction</head><p>This section specifies the task of prospective user engagement prediction. We first explain the user log data used in our experiments. We then describe two kinds of task settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">User log data</head><p>We conducted an empirical study in which we ex- amined Voice Assist user logs. We randomly sam- pled 348,295 users who used the system at least once from March 2015 to June 2015 (16 weeks) and extracted all their dialogue histories during that period. The log data included 7,472,915 ut- terances in total.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Task definition</head><p>We propose two types of prospective user engage- ment prediction tasks. In both tasks, we collect user dialogues from the first eight weeks of the user logs (referred to as observation period. We will discuss on length of observation period in Section 5.4), and then use those past dialogues to predict whether users are engaged with the intelli- gent assistant in the last eight weeks of the log data (referred to as prediction period). <ref type="bibr">4</ref> We specifically explored two prediction tasks as follows.</p><p>Dropout prediction The first task is to predict whether a given user will not at all use the system in the prediction period. This task is referred to as dropout prediction and is formulated as a binary classification problem. The model of dropout pre- diction would allow intelligent assistants to take proactive actions against users who are likely to stop using the system. There are 71,330 dropout users, who does not at all use the system in the prediction period, among 275,630 in our data set.</p><p>Engagement level prediction The second task aims at predicting how frequently the system will be used in the prediction period by a given user. Because there are outliers, or heavy users, who use the system extremely frequently (one user used the system as many as 1,099 times in the eight weeks), we do not attempt to directly predict the number of utterances or sessions. Instead, we define engage- ment levels as detailed below, and aim at predict- ing those values. The engagement levels are defined as follows. First, users are sorted in the ascending order of  the number of sessions they made in the prediction period. We then split users into four equally-sized groups. The engagement levels of users in the four groups are defined as 1, 2, 3, and 4, respectively ( <ref type="table" target="#tab_4">Table 3</ref>). Note that a larger value of the engage- ment level means that the users are more engaged with the intelligent assistants. This task is referred to as engagement level prediction and is formu- lated as a regression problem. The engagement level prediction has different applications from the dropout prediction. For ex- ample, it would allow us to detect in advance that a user's engagement level will change from four to three in the near future. It is beyond the scope of dropout prediction task to foresee such a change.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Features</head><p>The dropout prediction is performed using lin- ear support vector machine (SVM) <ref type="bibr" target="#b0">(Fan et al., 2008)</ref>, while the engagement level prediction is performed using support vector regression (SVR) ( <ref type="bibr">Smola and Schölkopf, 2004</ref>) on the same feature set. Here, we divide the features into four cate- gories by their function: utterance frequency fea- tures, response frequency features, time interval features, and user profile features. <ref type="table" target="#tab_5">Table 4</ref> lists these features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Utterance frequency features</head><p>Here, we describe the features related to utterance frequency. These features attempt to capture our #Features Name <ref type="table" target="#tab_0">Definition  1</ref> Utterance The number of utterances 7</p><p>UtterancewWeeks The number of utterances in recent w weeks 1</p><p>LongUtterance The number of lengthy utterances 1</p><p>UrgedUtterance The number of utterances made in response to push notifications 1 Restatement The number of restatement utterances 100</p><p>UtteranceTopici The number of utterances including words in the i-th cluster 1</p><p>Session The number of sessions 7</p><p>SessionwWeeks</p><p>The number of sessions in recent w weeks 7</p><p>SessionByDay</p><p>The number of sessions during each day of the week 66</p><p>Response(t)</p><p>The number of responses with response type t 66</p><p>FirstResponse(t) Response(t) computed by using only the first responses in sessions 1</p><p>LongResponse</p><p>The number of lengthy responses 1</p><p>ErrorMessage</p><p>The number of error messages 1</p><p>MaxInterval Max days between adjacent utterances 1 MinInterval Min days between adjacent utterances 1 AvgInterval Average days between adjacent utterances 1 InactivePeriod Days from the last utterance date 66</p><p>InactivePeriod(t) InactivePeriod computed for each type of the last response 1</p><p>Nickname</p><p>Whether or not a user has provided nickname information 1</p><p>Birthday</p><p>Whether or not a user has provided birthday information 6 Age User's age category intuition that users who frequently use intelligent assistants are likely to be engaged with them.</p><p>Utterance The number of utterances in the obser- vation period. For scaling purposes, the value of this feature is set to log 10 (x+1), where x is the number of utterances. The same scaling is performed on all features but user profile features.</p><p>UtterancewWeeks The number of utterances in the last w (1 ≤ w &lt; 8) weeks of the obser- vation period.</p><p>LongUtterance The number of lengthy utter- ances (more than 20 characters long). <ref type="bibr" target="#b3">Jiang et al. (2015)</ref> pointed out that long utterances are prone to cause ASR errors. Since ASR errors are a factor that decreases user engagement, users who are prone to make long utterances are likely to be disengaged.</p><p>UrgedUtterance The number of utterances made in response to push notifications sent from the system. We expect that engaged users tend to react to push notifications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Restatement</head><p>The number of restatements made by users. <ref type="bibr" target="#b3">Jiang et al. (2015)</ref> found that users tend to repeat previous utterances in case of ASR errors. An utterance is regarded as a re- statement of the previous one if their normal- ized edit distance (Li and Liu, 2007) is below 0.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>UtteranceTopici</head><p>The number of utterances in- cluding a keyword belonging to i-th word cluster.</p><p>To induce the word clusters, 100-dimensional word embeddings are first learned from the log data using WORD2VEC ( <ref type="bibr">Mikolov et al., 2013</ref>) 5 , and then K-means clustering (K=100) is performed <ref type="bibr">(MacQueen, 1967</ref>). All options of WORD2VEC are set to the default values. These features aim at capturing topics on utterances or speech acts. <ref type="table">Table 5</ref> illustrates example words in the clusters. For example, utterances including words in the cluster ID 36 and 63 are con- sidered to be greeting acts and sports-related conversations, respectively.</p><p>Cluster ID Example words 14 (Weather) pollen, typhoon, temperature 23 (Curse) die, stupid, shit, shurrup, dorf 36 (Greeting) thanks, good morning, hello 48 (Sentiment) funny, cute, good, awesome 63 (Sports) World cup, Nishikori, Yankees <ref type="table">Table 5</ref>: Example words in the clusters. Clus- ter names (presented in parentheses) are manually provided by the authors to help readers understand the word clusters.</p><p>Session The number of sessions in the observa- tion period.</p><p>SessionwWeeks The number of sessions in the last w (1 ≤ w &lt; 8) weeks of the observa- tion period.</p><p>SessionByDay The number of sessions in each day of week. There are seven different fea- tures of this type.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Response frequency features</head><p>Here, we describe the features of the response fre- quency.</p><p>Response(t) The number of system responses with response type t.</p><p>FirstResponse(t) Response(t) features that are computed by using only the first responses in sessions. Our hypothesis is that first re- sponses in sessions crucially affect user en- gagement.</p><p>LongResponse The number of lengthy responses (more than 50 characters long). Because longer responses require a longer reading time, they are prone to irritate users and con- sequently decrease user engagement.</p><p>ErrorMessage The number of error messages. Voice Assist returns error messages (Sorry, I don't know.) when it fails to find appropriate responses to the user's utterances. We con- sider that these error messages decrease user engagement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Time interval features</head><p>Here, we describe the features related to the ses- sion interval times.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MaxInterval</head><p>The maximum interval (in days) be- tween adjacent sessions in the observation period.</p><p>MinInterval The minimum interval (in days) be- tween adjacent sessions in the observation period.</p><p>AvgInterval The average interval (in days) be- tween adjacent sessions in the observation period.</p><p>InactivePeriod The time span (in days) from the last utterance to the end of the observation pe- riod.</p><p>InactivePeriod(t) InactivePeriod computed sep- arately for each type t of the last response.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">User profile features</head><p>Here, we describe the features of the user's profile information. Since it is not mandotory for users to register their profiles, we expect that those who have provided profile information are likely to be engaged with the system.</p><p>Nickname A binary feature representing whether or not the user has provided their nickname.</p><p>Birthday A binary feature representing whether or not the user has provided their birthday.</p><p>Age Six binary features representing the user's age. They respectively indicate whether the user is less than twenty years, in their 20's, 30's, 40's, or 50's, or is more than 60 years old. Note that these features are available only if the user has provided their birthday.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>In this section, we describe our experimental re- sults and discuss them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental settings</head><p>We randomly divided the log data into training, de- velopment, and test sets with the ratio of 8:1:1. Note that we confirmed that the users in differ- ent data sets do not overlap with each other. We trained the model with the training set and opti- mized hyperparameters with the development set. The test set was used for a final blind test to eval- uate the learnt model. We used the LIBLINEAR tool <ref type="bibr" target="#b0">(Fan et al., 2008</ref>) to train the SVM for the dropout prediction and    <ref type="table">Table 7</ref>: Precisions and Recalls in the dropout pre- diction task.</p><p>the SVR for the engagement level prediction task.</p><p>We optimized the C parameter on the development set. In the dropout prediction task, we used the -w option to weigh the C parameter of each class with the inverse ratio of the number of users in that class. We also used the -B option to introduce the bias term. Next, we describe the evaluation metrics. We used accuracy and F 1 -measure in the dropout pre- diction task. Mean squared error (MSE) and Spearman rank correlation coefficient were used in the engagement level prediction task. These eval- uation metrics are commonly used in classification and regression tasks.</p><p>We compare the proposed models with base- line method. Because we have no previous work on both tasks, we defined baseline method of our own. The baseline method was trained in the same framework as the proposed methods except that they used only Session feature. We chose Ses- sion for baseline because frequency of use features such as Session were shown predictive to similar tasks ( <ref type="bibr" target="#b6">Kloft et al., 2014;</ref><ref type="bibr">Sadeque et al., 2015</ref>) to prospective user engagement. <ref type="table" target="#tab_7">Table 6</ref> illustrates the result of dropout prediction task. The first row compares the proposed method with the baseline. We can see that the proposed <ref type="figure">Figure 1</ref>: Accuracies per the number of sessions in the observation period of the proposed method and the baseline. The rightmost points represent the accuracy of the users whose number of sessions in the observation period are equal to or more than 40.  model outperforms the baseline. This indicates the effectiveness of our feature set. The second row illustrates the performances of the proposed method when only one feature type is used. This result suggests that the utterance frequency and time interval features are especially useful, while the combination of all types of features performs the best. We conducted McNemar test <ref type="bibr">(McNemar, 1947)</ref> to investigate the significance of these im- provements, and confirmed that all improvements are statistically significant (p &lt; 0.01). <ref type="table">Table 7</ref> shows the precisions and the recalls of dropout prediction task. As shown in <ref type="table">Table 7</ref>, the precision of the proposed method performs the best while the recall is worst. We consider that the performance of the precision is more important for our model because taking proactive actions against users who are likely to stop using the system is one of the assumed applications. Taking proactive ac- tions (e.g., push notifications) against users contin- ually using the system might irritate them and de- crease their user engagement. Therefore, the rate of the users who actually intend to stop using the system in the users predicted as dropout affects the effectiveness of these proactive actions. The result that the precision of the proposed method is 0.553 and that of the baseline is 0.350 is, in other words, using the proposed model improves the effective- ness by 20% absolute in taking these actions. <ref type="figure">Figure 1</ref> shows the accuracies per the number of sessions in the observation period of the proposed method and the baseline. The proposed method consistently outperforms the baseline throughout the number of sessions in the observation period. In particular, the proposed method predicts well the dropout of users whose number of sessions is around five compared to the baseline. These re- sults again indicate the effectiveness of the combi- nation of our feature set. <ref type="table" target="#tab_9">Table 8</ref> shows the result of engagement level prediction task. We again observe similar trends to the dropout prediction task. The proposed method outperforms the baseline. The utterance frequency and time interval features are the most effective, while the combination of all four feature types achieves the best performance in both evaluation metrics. <ref type="figure" target="#fig_1">Figure 2</ref> visualizes the correlation between the oracle engagement levels and the ones predicted by the baseline (left) and by the proposed method (right). We can intuitively reconfirm that the pro- posed method is able to predict the engagement levels reasonably well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MSE Spearman</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Investigation of feature weights</head><p>We investigate weights of the features learned by the SVR for figuring out what features contribute to the precise prediction of prospective user en- gagement. <ref type="table" target="#tab_10">Table 9</ref> exemplifies features that received large weights for the four feature types. We observe that most features with large positive or negative weights are from the utterance frequency and time interval features. Those include Session, Utter- ance, and InactivePeriod. It is interesting to see that UrgedUtterance, which is based on an utter- ance type specific to mobile users, also receives a large positive weight.</p><p>Further detailed analysis revealed that the pro- posed model captures some linguistic proper- ties that correlate with the prospective user en- gagement. For example, UtteranceTopic36 and UtteranceTopic23 recieve positive and negative weights, respectively. This follows our intuition since those clusters correspond to greeting and curse words (c.f. <ref type="table">Table 5</ref>). We also observe Re- sponse(WORD CHAIN), Response(QUIZ) (word association quiz), and Response(TRIVIA) (show- ing some trivia) receive positive weights. This means that playing games or showing some trivia attract users. It is interesting to see that this re- sult is consistent with findings in ( <ref type="bibr" target="#b7">Kobayashi et al., 2015)</ref>. It also follows our intuition that the weight of ErrorMessage feature is negative.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Discussion on length of observation period</head><p>Next, we investigate how the length of the obser- vation period affects the prediction performance.</p><p>We varied the length of the observation periods from one to eight weeks, and evaluated the results <ref type="figure" target="#fig_2">(Figure 3</ref>). <ref type="figure" target="#fig_2">Figure 3</ref> demonstrates that the model perfor-  mance generally improves as the observation pe- riod becomes longer in both tasks. When we in- crease the length of the observation period from one week to eight weeks, the accuracy increases by 7.9% in the dropout prediction and Spearman's ρ increases by 4.1 point in the engagement level prediction. The most significant improvements are achieved when we increase the length from one week to two weeks in the three metrics except the F-measure. This suggests that it is generally effective to collect user dialogues of two weeks long, rather than as long as eight weeks or more. This approach would allow to make predictions promptly without waiting for user dialogues to be collected for a long time, while harming accuracy (or other evaluation metrics) as little as possible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Application to other intelligent assistants</head><p>Here, we discuss how well our approach applies to intelligent assistants other than Voice Assist.</p><p>The results of this study are considered to apply to other intelligent assistants so long as user logs like the ones in <ref type="table" target="#tab_1">Table 2</ref> are available. The concern is that some attributes in <ref type="table" target="#tab_1">Table 2</ref> may not be avail- able in other systems. In the following, we inves- tigate two attributes, response types and profiles, that are specific to Voice Assist.</p><p>We consider that response types like ours are available in user logs of many other intelligent assistants as well. Because our response types mostly correspond to commands issued when op- erating mobile devices, response types analogous to ours can be obtained by simply logging the commands. Alternatively, it would be possible to employ taggers like ( <ref type="bibr" target="#b3">Jiang et al., 2015</ref>) to auto- matically type system responses.</p><p>As for profiles, it is likely that similar informa- tion is also available in many other intelligent as- sistants because profile registration is a common function in many IT services including intelligent assistants. For example, Cortana offers greetings and other activities on special days registered by users. <ref type="bibr">6</ref> Even if user profiles were not at all avail- able, we consider that it would not seriously spoil the significance of this study, because our exper- iments revealed that user profiles are among the least predictive features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Many dialogue studies have explored the issue of detecting user engagement as well as related affects such as interest and uncertainty ( <ref type="bibr">Wang and Hirschberg, 2011;</ref><ref type="bibr" target="#b2">Forbes-Riley et al., 2012;</ref><ref type="bibr" target="#b1">Forbes-Riley and Litman, 2013;</ref><ref type="bibr">Oertel and Salvi, 2013)</ref>. As discussed in Section 1, these stud- ies typically use a single user utterance to predict whether the user is currently engaged in dialogues with systems. We introduced a new perspective on this line of research by exploring models of predicting prospective user engagement in a large- scale empirical study. <ref type="bibr" target="#b7">Kobayashi et al. (2015)</ref> investigated how games played with intelligent assistants affect prospec- tive user engagement. Although their research interest was prospective user engagement like ours, they exclusively studied the effect of playing game, and left other factors unexplored. In addi- tion, they did not develop any prediction models.</p><p>Recently, user satisfaction for intelligent assis- tants gain attention( <ref type="bibr" target="#b3">Jiang et al., 2015;</ref><ref type="bibr" target="#b4">Kiseleva et al., 2016a;</ref><ref type="bibr" target="#b5">Kiseleva et al., 2016b</ref>). <ref type="bibr" target="#b3">Jiang et al. (2015)</ref> proposed an automatic method of as- sessing user satisfaction with intelligent assistants. Kiseleva et al. extended the study of Jiang et al. for prediction (2016a) and detailed understand- ing (2016b) of user satisfaction with intelligent as- sistants. Although both satisfaction and engage- ment are affective states worth considering by in- telligent assistants, their research goals were quite different from ours. In their studies, user sat- isfaction was measured as to whether intelligent assistants can accomplish predefined tasks (e.g., checking the exchange rate between US dollars and Australian dollars). This virtually assesses task-level response accuracy, which is a different notion from user engagement.</p><p>Nevertheless, we consider that their studies are closely related to ours and indeed helpful for im- proving the proposed model. Since user satisfac- tion is considered to greatly affect prospective user engagement, it might be a good idea to use au- tomatically evaluated satisfaction levels as addi- tional features. The proposed model currently uses ErrorMessage feature as an alternative that can be implemented with ease.</p><p>Several studies have investigated the chances of predicting continuous participation in SNSs such as MOOC and health care forum <ref type="bibr">(Rosé and Siemens, 2014;</ref><ref type="bibr" target="#b6">Kloft et al., 2014;</ref><ref type="bibr">Ramesh et al., 2014;</ref><ref type="bibr">Sadeque et al., 2015)</ref>. Unlike those studies, this study exclusively investigates a specific type of dialogue system, namely intelligent assistants, and aims at uncovering usage and/or response pat- terns that strongly affect prospective user engage- ment. Consequently, many of the proposed fea- tures are specially designed to analyze intelligent assistant users rather than SNS participants.</p><p>Our work also relates to the evaluation of di- alogue systems. <ref type="bibr">Walker et al. (1997)</ref> presented the offline evaluation framework for spoken dialog system (PARADISE). They integrate various eval- uation metrics such as dialogue success and dia- logue costs into one performance measure func- tion. Although our goal is to predict prospective user engagement and different from theirs, some measures (e.g., the number of utterances) are use- ful to predict prospective user engagement with in- telligent assistants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>This paper explored two tasks of predicting prospective user engagement with intelligent as- sistants: dropout prediction and engagement level prediction. The experiments successfully demonstrated that reasonable performance can be archived in both tasks. Also, we examined how the length of the observation period affects pre- diction performance, and investigated the trade-off between prediction accuracy and instancy. The fu- ture work includes using those prediction models in a real service to take targeted actions to users who are likely to stop using intelligent assistants.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Accuracy</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Correlation between the oracle engagement levels and the ones predicted by the baseline method (left) and by the proposed method (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Results of dropout prediction (left) and engagement level prediction (right) across different observation periods (in weeks).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc>Example dialogues of Voice Assist users. U and V indicate the user and Voice Assist, respec- tively. The notes in parentheses represent actions that Voice Assist takes after the responses.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 illustrates</head><label>2</label><figDesc></figDesc><table>examples of user logs. We 
used the following seven attributes: user ID, nick-
name, birthday, time stamp, user utterance, sys-
tem response, and response type. Because it is not 
mandatory to register the personal profiles (includ-
ing nicknames, birthdays, etc.), they are some-
times missing, as indicated by N/A in the table. 
The response type represents the 66 functions sup-
ported by Voice Assist. The time stamps were 
used to segment utterances into sessions, as rep-</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>User log examples. The dashed line represents the session boundary. 

resented by dashed lines in the table. We follow 
(Jiang et al., 2015) to define sessions as utterance 
sequences in which the interval of two adjacent ut-
terances does not exceed 30 minutes. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>User distribution over the four engage-
ment levels. The second column represents inter-
vals of the number of sessions corresponding to 
the four levels. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>List of features. The utterance frequency features, response frequency features, and time interval 
features are all scaled. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Classification accuracies and F-measures 
in the dropout prediction task. 

Precision Recall 
Baseline 
0.350 
0.774 
Proposed 
0.553 
0.714 
Utterance frequency 
0.458 
0.785 
Response frequency 
0.346 
0.831 
Time interval 
0.507 
0.789 
User profile 
0.273 
0.793 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head>Table 8 :</head><label>8</label><figDesc></figDesc><table>MSE and Spearman's ρ in the engage-
ment level prediction task. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="false"><head>Table 9 : Feature weights learned by the SVR.</head><label>9</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="2"> http://v-assist.yahoo.co.jp (in Japanese) 3 Because Voice Assist supports only Japanese, all utterances are made in Japanese. In this paper, we present English translations rather than the original Japanese to facilitate nonJapanese readers&apos; understanding.</note>

			<note place="foot" n="4"> We removed users from the log data if the number of sessions was only once in the observation period, because such data lack a sufficient amount of dialogue histories for making a reliable prediction.</note>

			<note place="foot" n="5"> https://code.google.com/archive/p/ word2vec</note>

			<note place="foot" n="6"> http://m.windowscentral.com/articles (an article posted on Dec. 5, 2015)</note>
		</body>
		<back>
			<div type="annex">
			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Liblinear: A library for large linear classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Wei</forename><surname>Rong-En Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho-Jui</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangrui</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Jen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1871" to="1874" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">When does disengagement correlate with performance in spoken dialog computer tutoring?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Riley</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><surname>Litman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Artificial Intelligence in Education</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="39" to="58" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Intrinsic and extrinsic evaluation of an automatic user disengagement detector for an uncertainty-adaptive spoken dialogue system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Forbes-Riley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><surname>Litman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heather</forename><surname>Friedberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joanna</forename><surname>Drummond</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="91" to="102" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Automatic online evaluation of intelligent assistants</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiepu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><forename type="middle">Hassan</forename><surname>Awadallah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rosie</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Umut</forename><surname>Ozertem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Imed</forename><surname>Zitouni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ranjitha</forename><forename type="middle">Gurunath</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omar</forename><forename type="middle">Zia</forename><surname>Khan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on World Wide Web</title>
		<meeting>the 24th International Conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="506" to="516" />
		</imprint>
	</monogr>
	<note>International World Wide Web Conferences Steering Committee</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Predicting user satisfaction with intelligent assistants</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Kiseleva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyle</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiepu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><forename type="middle">Hassan</forename><surname>Awadallah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Imed</forename><surname>Zitouni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">C</forename><surname>Crook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tasos</forename><surname>Anastasakos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="495" to="505" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Understanding user satisfaction with intelligent assistants</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Kiseleva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyle</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiepu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><forename type="middle">Hassan</forename><surname>Awadallah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">C</forename><surname>Crook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Imed</forename><surname>Zitouni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tasos</forename><surname>Anastasakos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 ACM SIGIR Conference on Human Information Interaction and Retrieval</title>
		<meeting>the 2016 ACM SIGIR Conference on Human Information Interaction and Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="121" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Predicting MOOC dropout over weeks using machine learning methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Kloft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Stiehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niels</forename><surname>Pinkwart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="60" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Effects of game on user engagement with spoken dialogue system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hayato</forename><surname>Kobayashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaori</forename><surname>Tanio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manabu</forename><surname>Sassano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue</title>
		<meeting>the 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="422" to="426" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
