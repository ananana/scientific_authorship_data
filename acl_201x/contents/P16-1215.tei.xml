<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:19+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Composing Distributed Representations of Relational Patterns</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sho</forename><surname>Takase</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Graduate School of Information Sciences</orgName>
								<orgName type="institution">Tohoku University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naoaki</forename><surname>Okazaki</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Graduate School of Information Sciences</orgName>
								<orgName type="institution">Tohoku University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kentaro</forename><surname>Inui</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Graduate School of Information Sciences</orgName>
								<orgName type="institution">Tohoku University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Composing Distributed Representations of Relational Patterns</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="2276" to="2286"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Learning distributed representations for relation instances is a central technique in downstream NLP applications. In order to address semantic modeling of rela-tional patterns, this paper constructs a new dataset that provides multiple similarity ratings for every pair of relational patterns on the existing dataset (Zeichner et al., 2012). In addition, we conduct a comparative study of different encoders including additive composition, RNN, LSTM, and GRU for composing distributed representations of relational patterns. We also present Gated Additive Composition, which is an enhancement of additive composition with the gating mechanism. Experiments show that the new dataset does not only enable detailed analyses of the different encoders, but also provides a gauge to predict successes of distributed representations of relational patterns in the relation classification task.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Knowledge about entities and their relations (re- lation instances) are crucial for a wide spectrum of NLP applications, e.g., information retrieval, question answering, and recognizing textual en- tailment. Learning distributed representations for relation instances is a central technique in down- stream applications as a number of recent studies demonstrated the usefulness of distributed repre- sentations for words ( <ref type="bibr" target="#b20">Mikolov et al., 2013;</ref><ref type="bibr" target="#b24">Pennington et al., 2014</ref>) and sentences <ref type="bibr" target="#b32">(Sutskever et al., 2014;</ref><ref type="bibr" target="#b16">Kiros et al., 2015)</ref>.</p><p>In particular, semantic modeling of relations and their textual realizations (relational patterns hereafter) is extremely important because a rela- Figure 1: Overview of this study.</p><p>tion (e.g., causality) can be mentioned by various expressions (e.g., "X cause Y", "X lead to Y", "Y is associated with X"). To make matters worse, rela- tional patterns are highly productive: we can pro- duce a emphasized causality pattern "X increase the severe risk of Y" from "X increase the risk of Y" by inserting severe to the pattern. To model the meanings of relational patterns, the previous studies built a co-occurrence matrix between relational patterns (e.g., "X increase the risk of Y") and entity pairs (e.g., "X: smoking, Y: cancer") ( <ref type="bibr" target="#b19">Lin and Pantel, 2001;</ref><ref type="bibr" target="#b23">Nakashole et al., 2012</ref>). Based on the distributional hypothe- sis <ref type="bibr" target="#b11">(Harris, 1954)</ref>, we can compute a semantic vec- tor of a relational pattern from the co-occurrence matrix, and measure the similarity of two rela- tional patterns as the cosine similarity of the vec- tors. Nowadays, several studies adopt distributed representations computed by neural networks for semantic modeling of relational patterns <ref type="bibr" target="#b39">(Yih et al., 2014;</ref><ref type="bibr" target="#b34">Takase et al., 2016)</ref>.</p><p>Notwithstanding, the previous studies paid lit- tle attention to explicitly evaluate semantic mod- eling of relational patterns. In this paper, we con- struct a new dataset that contains a pair of rela- tional patterns with five similarity ratings judged by human annotators. The new dataset shows a high inter-annotator agreement, following the an- notation guideline of <ref type="bibr" target="#b21">Mitchell and Lapata (2010)</ref>. The dataset is publicly available on the Web site <ref type="bibr">1</ref> .</p><p>In addition, we conduct a comparative study of different encoders for composing distributed representations of relational patterns. During the comparative study, we present Gated Additive Composition, which is an enhancement of addi- tive composition with the gating mechanism. We utilize the Skip-gram objective for training the pa- rameters of the encoders on a large unlabeled cor- pus. Experiments show that the new dataset does not only enable detailed analyses of the different encoders, but also provides a gauge to predict suc- cesses of distributed representations of relational patterns in another task (relation classification). <ref type="figure">Figure 1</ref> illustrates the overview of this study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data Construction</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Target relation instances</head><p>We build a new dataset upon the work of <ref type="bibr" target="#b40">Zeichner et al. (2012)</ref>, which consists of relational patterns with semantic inference labels annotated. The dataset includes 5,555 pairs 2 extracted by Re- verb <ref type="bibr" target="#b7">(Fader et al., 2011</ref>), 2,447 pairs with infer- ence relation and 3,108 pairs (the rest) without one.</p><p>Initially, we considered using this high-quality dataset as it is for semantic modeling of relational patterns. However, we found that inference rela- tions exhibit quite different properties from those of semantic similarity. Take a relational pattern pair "X be the part of Y" and "X be an essential part of Y" filled with "X = the small intestine, Y = the digestive system" as an instance. The pattern "X be the part of Y" does not entail "X be an essen- tial part of Y" because the meaning of the former does not include 'essential'. Nevertheless, both statements are similar, representing the same rela- tion (PART-OF). Another uncomfortable pair is "X fall down Y" and "X go up Y" filled with "X = the dude, Y = the stairs". The dataset indicates that the former entails the latter probably because falling down from the stairs requires going up there, but they present the opposite meaning. For this rea- son, we decided to re-annotate semantic similarity 1 http://github.com/takase/relPatSim 2 More precisely, the dataset includes 1,012 meaningless pairs in addition to 5,555 pairs. A pair of relational patterns was annotated as meaningless if the annotators were unable to understand the meaning of the patterns easily. We ignore the meaningless pairs in this study. judgments on every pair of relational patterns on the dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Annotation guideline</head><p>We use instance-based judgment in a similar man- ner to that of <ref type="bibr" target="#b40">Zeichner et al. (2012)</ref> to secure a high inter-annotator agreement. In instance- based judgment, an annotator judges a pair of relational patterns whose variable slots are filled with the same entity pair. In other words, he or she does not make a judgment for a pair of relational patterns with variables, "X prevent Y" and "X reduce the risk of Y", but two instantiated statements "Cephalexin prevent the bacteria" and "Cephalexin reduce the risk of the bacteria" ("X = Cephalexin, Y = the bacteria"). We use the entity pairs provided in <ref type="bibr" target="#b40">Zeichner et al. (2012)</ref>.</p><p>We asked annotators to make a judgment for a pair of relation instances by choosing a rating from 1 (dissimilar) to 7 (very similar). We provided the following instructions for judgment, which is compatible with <ref type="bibr" target="#b21">Mitchell and Lapata (2010)</ref>: (1) rate 6 or 7 if the meanings of two statements are the same or mostly the same (e.g., "Palmer team with Jack Nicklaus" and "Palmer join with Jack Nicklaus"); (2) rate 1 or 2 if two statements are dissimilar or unrelated (e.g., "the kids grow up with him" and "the kids forget about him"); (3) rate 3, 4, or 5 if two statements have some rela- tionships (e.g., "Many of you know about the site" and "Many of you get more information about the site", where the two statements differ but also rea- sonably resemble to some extent).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Annotation procedure</head><p>We use a crowdsourcing service CrowdFlower 3 to collect similarity judgments from the crowds. CrowdFlower has the mechanism to assess the re- liability of annotators using Gold Standard Data (Gold, hereafter), which consists of pairs of re- lational patterns with similarity scores assigned. Gold examples are regularly inserted throughout the judgment job to enable measurement of the performance of each worker <ref type="bibr">4</ref> . Two authors of this paper annotated 100 pairs extracted randomly from 5,555 pairs, and prepared 80 Gold examples showing high agreement. Ratings of the Gold ex- amples were used merely for quality assessment of the workers. In other words, we discarded the similarity ratings of the Gold examples, and used those judged by the workers.</p><p>To build a high quality dataset, we use judg- ments from workers whose confidence values (re- liability scores) computed by CrowdFlower are greater than 75%. Additionally, we force every pair to have at least five judgments from the work- ers. Consequently, 60 workers participated in this job. In the final version of this dataset, each pair has five similarity ratings judged by the five most reliable workers who were involved in the pair. <ref type="figure" target="#fig_0">Figure 2</ref> presents the number of judgments for each similarity rating. Workers seldom rated 7 for a pair of relational patterns, probably because most pairs have at least one difference in content words. The mean of the standard deviations of similarity ratings of all pairs is 1.16. Moreover, we computed Spearman's ρ between similarity judg- ments from each worker and the mean of five judg- ments in the dataset. The mean of Spearman's ρ of workers involved in the dataset is 0.728. These statistics show a high inter-annotator agreement of the dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Encoder for Relational Patterns</head><p>The new dataset built in the previous section raises two new questions -What is the reasonable method (encoder) for computing the distributed representations of relational patterns? Is this dataset useful to predict successes of distributed representations of relational patterns in real ap- plications? In order to answer these questions, this section explores various methods for learning dis- tributed representations of relational patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Baseline methods without supervision</head><p>A na¨ıvena¨ıve approach would be to regard a rela- tional pattern as a single unit (word) and to train word/pattern embeddings as usual. In fact, <ref type="bibr" target="#b20">Mikolov et al. (2013)</ref> implemented this approach as a preprocessing step, mining phrasal expres- sions with strong collocations from a training cor- pus. However, this approach might be affected by data sparseness, which lowers the quality of dis- tributed representations.</p><p>Another simple but effective approach is ad- ditive composition <ref type="bibr" target="#b21">(Mitchell and Lapata, 2010)</ref>, where the distributed representation of a relational pattern is computed by the mean of embeddings of constituent words. Presuming that a relational pat- tern consists of a sequence of T words w 1 , ..., w T , then we let x t ∈ R d the embedding of the word w t . This approach computes 1 T ∑ T t=1 x t as the em- bedding of the relational pattern. <ref type="bibr" target="#b22">Muraoka et al. (2014)</ref> reported that the additive composition is a strong baseline among various methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Recurrent Neural Network</head><p>Recently, a number of studies model seman- tic compositions of phrases and sentences by using (a variant of) Recurrent Neural Network (RNN) ( <ref type="bibr" target="#b32">Sutskever et al., 2014;</ref><ref type="bibr" target="#b35">Tang et al., 2015)</ref>. For a given embedding x t at position t, the vanilla RNN <ref type="bibr" target="#b6">(Elman, 1990</ref>) computes the hidden state h t ∈ R d by the following recursive equation 5 ,</p><formula xml:id="formula_0">h t = g(W x x t + W h h t−1 ).<label>(1)</label></formula><p>Here, W x and</p><formula xml:id="formula_1">W h are d × d matrices (parameters), g(.)</formula><p>is the elementwise activation function (tanh).</p><p>We set h 0 = 0 at t = 1. In essence, RNN com- putes the hidden state h t based on the one at the previous position (h t−1 ) and the word embedding x t . Applying Equation 1 from t = 1 to T , we use h T as the distributed representation of the re- lational pattern.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">RNN variants</head><p>We also employ Long Short-Term Memory (LSTM) <ref type="bibr" target="#b15">(Hochreiter and Schmidhuber, 1997</ref> Gated Additive Composition (GAC) <ref type="figure">Figure 3</ref>: Overview of GAC trained with Skip- gram model. GAC computes the distributed rep- resentation of a relational pattern using the input gate and forget gate, and learns parameters by pre- dicting surrounding words (Skip-gram model).</p><p>tasks including sentence similarity, paraphrase de- tection, and sentiment analysis ( <ref type="bibr" target="#b16">Kiros et al., 2015)</ref>. LSTM and GRU are similar in that the both ar- chitectures have gates (input, forget, and output for LSTM; reset and update for GRU) to rem- edy the gradient vanishing or explosion problem in training RNNs. Although some researchers re- ported that GRU is superior to LSTM <ref type="bibr" target="#b3">(Chung et al., 2014</ref>), we have no consensus about the supe- riority. Besides, we are not sure whether LSTM or GRU is really necessary for relational patterns, which ususlly consist of a few words. Thus, we compare RNN, LSTM, and GRU empirically with the same training data and the same training pro- cedure. Similarly to RNN, we use the hidden state h T of LSTM 6 or GRU as the distributed represen- tation of a relation pattern.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Gated Additive Composition (GAC)</head><p>In addition to the gradient problem, LSTM or GRU may be suitable for relational patterns, hav- ing the mechanism of adaptive control of gates for input words and hidden states. Consider the rela- tional pattern "X have access to Y", whose mean- ing is mostly identical to that of "X access Y". Because 'have' in the pattern is a light verb, it may be harmful to incorporate the semantic vector of 'have' into the distributed representation of the pattern. The same may be true for the functional word 'to' in the pattern. However, the additive composition nor RNN does not have a mechanism to ignore the semantic vectors of these words. It is interesting to explore a method somewhere be- tween additive composition and LSTM/GRU: ad- ditive composition with the gating mechanism.</p><p>For this reason, we present an another variant of RNN in this study. Inspired by the input and forget gates in LSTM, we compute the input gate i t ∈ R d and forget gate f t ∈ R d at position t. We use them to control the amount to propagate to the hidden state h t from the current word x t and the previous state h t−1 .</p><formula xml:id="formula_2">i t = σ(W ix x t + W ih h t−1 )<label>(2)</label></formula><formula xml:id="formula_3">f t = σ(W f x x t + W f h h t−1 )<label>(3)</label></formula><formula xml:id="formula_4">h t = g(f t ⊙ h t−1 + i t ⊙ x t )<label>(4)</label></formula><p>Here,</p><formula xml:id="formula_5">W ix , W ih , W f x , W f h are d × d matri- ces. Equation 4</formula><p>is interpreted as a weighted ad- ditive composition between the vector of the cur- rent word x t and the vector of the previous hid- den state h t−1 . The elementwise weights are con- trolled by the input gate i t and forget gate f t ; we expect that input gates are closed (close to zero) and forget gates are opened (close to one) when the current word is a control verb or function word. We name this architecture gated additive compo- sition (GAC).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Parameter estimation: Skip-gram model</head><p>To train the parameters of the encoders (RNN, LSTM, GRU, and GAC) on an unlabeled text cor- pus, we adapt the Skip-gram model ( <ref type="bibr" target="#b20">Mikolov et al., 2013</ref>). Formally, we designate an occurrence of a relational pattern p as a subsequence of L words w s , ..., w s+L−1 in a corpus. We define δ words appearing before and after pattern p as the context words, and let C p = (s − δ, ..., s − 1, s + L, ..., s + L + δ) denote the indices of the context words. We define the log-likelihood of the relational pattern l p , following the objec- tive function of Skip-gram with negative sampling (SGNS) ( <ref type="bibr" target="#b18">Levy and Goldberg, 2014)</ref>.</p><formula xml:id="formula_6">l p = ∑ τ ∈Cp ( log σ(h ⊤ p ˜ x τ ) + K ∑ k=1 log σ(−h ⊤ p ˜ x ˘ τ ) )<label>(5)</label></formula><p>In this formula: K denotes the number of nega- tive samples; h p ∈ R d is the vector for the rela- tional pattern p computed by each encoder such as RNN; ˜ x τ ∈ R d is the context vector for the word w τ 7 ; x ˘ τ ′ ∈ R d is the context vector for the word <ref type="bibr">7</ref> The Skip-gram model has two kinds of vectors xt and˜xt and˜ and˜xt assigned for a word wt. Equation 2 of the original pa- per ( <ref type="bibr" target="#b20">Mikolov et al., 2013</ref>) denotes xt (word vector) as v (input vector) and˜xtand˜ and˜xt (context vector) as v ′ (output vector). The word2vec implementation does not write context (out- put) vectors but only word (input) vectors to a model file. Therefore, we modified the source code to save context vec- tors, and use them in Equation 5. This modification ensures the consistency of the entire model.</p><note type="other">that were sampled from the unigram distribution 8 at every iteration of ∑ k . At every occurrence of a relational pattern in the corpus, we use Stochastic Gradient Descent (SGD) and backpropagation through time (BPTT) for training the parameters (matrices) in encoders. More specifically, we initialize the word vectors x t and context vectors˜xvectors˜ vectors˜x t with pre-trained values, and compute gradients for Equation 5 to update the pa- rameters in encoders. In this way, each encoder is trained to compose a vector of a relational pat- tern so that it can predict the surrounding context</note><p>words. An advantage of this parameter estimation is that the distributed representations of words and relational patterns stay in the same vector space. <ref type="figure">Figure 3</ref> visualizes the training process for GAC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In Section 4.1, we investigate the performance of the distributed representations computed by differ- ent encoders on the pattern similarity task. Section 4.2 examines the contribution of the distributed representations on SemEval 2010 Task 8, and dis- cusses the usefulness of the new dataset to predict successes of the relation classification task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Relational pattern similarity</head><p>For every pair in the dataset built in Section 2, we compose the vectors of the two relational patterns using an encoder described in Section 3, and com- pute the cosine similarity of the two vectors. Re- peating this process for all pairs in the dataset, we measure Spearman's ρ between the similarity val- ues computed by the encoder and similarity ratings assigned by humans.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Training procedure</head><p>We used ukWaC 9 as the training corpus for the encoders. This corpus includes the text of 2 bil- lion words from Web pages crawled in the .uk domain. Part-of-speech tags and lemmas are an- notated by TreeTagger <ref type="bibr">10</ref> . We used lowercased lemmas throughout the experiments. We apply word2vec to this corpus to pre-train word vec- tors x t and context vectors˜xvectors˜ vectors˜x t . All encoders use word vectors x t to compose vectors of relational patterns; and the Skip-gram model uses context <ref type="bibr">8</ref> We use the probability distribution of words raised to the 3/4 power ( <ref type="bibr" target="#b20">Mikolov et al., 2013</ref>  We used <ref type="bibr">Reverb (Fader et al., 2011</ref>) to the ukWaC corpus to extract relational pattern can- didates. To remove unuseful relational patterns, we applied filtering rules that are compatible with those used in the publicly available extraction re- sult <ref type="bibr">11</ref> . Additionally, we discarded relational pat- terns appearing in the evaluation dataset through- out the experiments to assess the performance un- der which an encoder composes vectors of unseen relational patterns. This preprocessing yielded 127, 677 relational patterns.</p><p>All encoders were implemented on Chainer 12 , a flexible framework of neural networks. The hyper- parameters of the Skip-gram model are identical to those in <ref type="bibr" target="#b20">Mikolov et al. (2013)</ref>: the width of context window δ = 5, the number of negative samples K = 5, the subsampling of 10 −5 . For each encoder that requires training, we tried 0.025, 0.0025, and 0.00025 as an initial learning rate, and selected the best value for the encoder. In contrast to the presentation of Section 3, we compose a pat- tern vector in backward order (from the last to the first) because preliminary experiments showed a slight improvement with this treatment. <ref type="figure" target="#fig_1">Figure 4</ref> shows Spearman's rank correlations of different encoders when the number of dimensions of vectors is 100-500. The figure shows that GAC achieves the best performance on all dimensions. <ref type="figure" target="#fig_1">Figure 4</ref> includes the performance of the na¨ıvena¨ıve approach, "NoComp", which regards a relational pattern as a single unit (word). In this approach, we allocated a vector h p for each relational pat- tern p in Equation 5 instead of the vector compo- sition, and trained the vectors of relational patterns using the Skip-gram model. The performance was poor for two reasons: we were unable to compute similarity values for 1,744 pairs because relational patterns in these pairs do not appear in ukWaC; and relational patterns could not obtain sufficient statistics because of data sparseness. <ref type="table">Table 1</ref> reports Spearman's rank correlations computed for each pattern length. Here, the length of a relational-pattern pair is defined by the maxi- mum of the lengths of two patterns in the pair. In length of 1, all methods achieve the same corre- lation score because they use the same word vec- tor x t . The table shows that additive composition (Add) performs well for shorter relational patterns (lengths of 2 and 3) but poorly for longer ones (lengths of 4 and 5+). GAC also exhibits the sim- ilar tendency to Add, but it outperforms Add for shorter patterns (lengths of 2 and 3) probably be- cause of the adaptive control of input and forget gates. In contrast, RNN and its variants (RNN, GRU, and LSTM) enjoy the advantage on longer patterns (lengths of 4 and 5+).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Results and discussions</head><p>To examine the roles of input and forget gates of GAC, we visualize the moments when input/forget gates are wide open or closed. More precisely, we extract the input word and scanned words when |i t | 2 or |f t | 2 is small (close to zero) or large (close to one) on the relational-pattern dataset. We re- state that we compose a pattern vector in backward order (from the last to the first): GAC scans 'of', 'author', and 'be' in this order for composing the vector of the relational pattern 'be author of'.  vector of the content word and to ignore the se- mantic vector of the preposition. In contrast, input gates close and forget gates open when the current word is 'be' or 'a' and scanned words form a noun phrase (e.g., "charter member of"), a complement (e.g., "eligible to participate in"), or a passive voice (e.g., "require(d) to submit"). This behavior is also reasonable because GAC emphasizes infor- mative words more than functional words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Relation classification</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Experimental settings</head><p>To examine the usefulness of the dataset and dis- tributed representations for a different application, we address the task of relation classification on the SemEval 2010 Task 8 dataset ( <ref type="bibr" target="#b14">Hendrickx et al., 2010)</ref>. In other words, we explore whether high-quality distributed representations of rela- tional patterns are effective to identify a relation type of an entity pair. The dataset consists of 10, 717 relation in- stances (8, 000 training and 2, 717 test instances) with their relation types annotated. The dataset <ref type="table">Table 3</ref>: F1 scores on the SemEval 2010 dataset. defines 9 directed relations (e.g.,CAUSE-EFFECT) and 1 undirected relation OTHER. Given a pair of entity mentions, the task is to identify a rela- tion type in 19 candidate labels (2 × 9 directed + 1 undirected relations). For example, given the pair of entity mentions e 1 = 'burst' and e 2 = 'pressure' in the sentence "The burst has been caused by water hammer pressure", a system is expected to predict CAUSE-EFFECT(e 2 , e 1 ). We used Support Vector Machines (SVM) with a Radial Basis Function (RBF) kernel imple- mented in libsvm <ref type="bibr">13</ref> . Basic features are: part- of-speech tags (predicted by TreeTagger), surface forms, lemmas of words appearing between an en- tity pair, and lemmas of the words in the entity pair. Additionally, we incorporate distributed rep- resentations of a relational pattern, entities, and a word before and after the entity pair (number of dimensions d = 500). In this task, we regard words appearing between an entity pair as a re-lational pattern. We compare the vector represen- tations of relational patterns computed by the five encoders presented in Section 4.1: additive com- position, RNN, GRU, LSTM, and GAC. Hyper- parameters related to SVM were tuned by 5-fold cross validation on the training data. <ref type="table">Table 3</ref> presents the macro-averaged F1 scores on the SemEval 2010 Task 8 dataset. The first group of the table provides basic features and enhance- ments with the distributed representations. We can observe a significant improvement even from the distributed representation of NoComp (77.3 to 79.9). Moreover, the distributed representation that exhibited the high performance on the pattern similarity task was also successful on this task; GAC, which yielded the highest performance on the pattern similarity task, also achieved the best performance (82.0) of all encoders on this task.</p><note type="other">Method Feature set F1 SVM BoW, POS 77.3 SVM + NoComp embeddings, BoW, POS 79.9 SVM + LSTM embeddings, BoW, POS 81.1 SVM + Add embeddings, BoW, POS 81.1 SVM + GRU embeddings, BoW, POS 81.4 SVM + RNN embeddings, BoW, POS 81.7 SVM + GAC embeddings, BoW, POS 82.0 + dependency, WordNet, NE 83.7 Ranking loss + GAC w/ fine-tuning embeddings, BoW, POS + dependency, WordNet, NE 84.2 SVM (Rink and Harabagiu, 2010) BoW, POS, dependency, Google n-gram, etc. 82.2 MV-RNN (Socher et al., 2012) embeddings, parse trees 79.1 + WordNet, POS, NE 82.4 FCM (Gormley et al., 2015) w/o fine-tuning embeddings, dependency 79.4 + WordNet 82.0 w/ fine-tuning embeddings, dependency 82.2 + NE 83.4 RelEmb (Hashimoto et al., 2015) embeddings 82.8 + dependency, WordNet, NE 83.5 CR-CNN (dos Santos et al., 2015) w/ Other embeddings, word position embeddings 82.7 w/o Other embeddings, word position embeddings 84.1 depLCNN (Xu et al., 2015) embeddings, dependency 81.9 + WordNet 83.7 depLCNN + NS embeddings, dependency 84.0 + WordNet 85.6</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Results and discussions</head><p>It is noteworthy that the improvements brought by the different encoders on this task roughly cor-respond to the performance on the pattern similar- ity task. This fact implies two potential impacts. First, the distributed representations of relational patterns are useful and easily transferable to other tasks such as knowledge base population. Second, the pattern similarity dataset provides a gauge to predict successes of distributed representations in another task.</p><p>We could further improve the performance of SVM + GAC by incorporating external resources in the similar manner as the previous studies did. Concretely, SVM + GAC achieved 83.7 F1 score by adding features for WordNet, named en- tities (NE), and dependency paths explained in <ref type="bibr" target="#b13">Hashimoto et al. (2015)</ref>. Moreover, we could ob- tain 84.2 F1 score, using the ranking based loss function (dos <ref type="bibr" target="#b4">Santos et al., 2015</ref>) and fine-tuning of the distributed representations initially trained by GAC. Currently, this is the second best score among the performance values reported in the pre- vious studies on this task (the second group of Ta- ble 3). If we could use the negative sampling tech- nique proposed by <ref type="bibr" target="#b38">Xu et al. (2015)</ref>, we might im- prove the performance further 14 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Mitchell and Lapata (2010) was a pioneering work in semantic modeling of short phrases. They con- structed the dataset that contains two-word phrase pairs with semantic similarity judged by human annotators. <ref type="bibr" target="#b17">Korkontzelos et al. (2013)</ref> provided a semantic similarity dataset with pairs of two words and a single word. <ref type="bibr" target="#b37">Wieting et al. (2015)</ref> annotated a part of PPDB ( <ref type="bibr" target="#b8">Ganitkevitch et al., 2013</ref>) to eval- uate semantic modeling of paraphrases. Although the target unit of semantic modeling is different from that for these previous studies, we follow the annotation guideline and instruction of <ref type="bibr" target="#b21">Mitchell and Lapata (2010)</ref> to build the new dataset.</p><p>The task addressed in this paper is also re- lated to the Semantic Textual Similarity (STS) task <ref type="bibr" target="#b0">(Agirre et al., 2012</ref>). STS is the task to mea- sure the degree of semantic similarity between two sentences. Even though a relational pattern ap- pears as a part of a sentence, it may be difficult to transfer findings from one to another: for exam- ple, the encoders of RNN and its variants explored in this study may exhibit different characteristics, influenced by the length and complexity of input text expressions.</p><p>In addition to data construction, this paper ad- dresses semantic modeling of relational patterns. <ref type="bibr" target="#b23">Nakashole et al. (2012)</ref> approached the similar task by constructing a taxonomy of relational pat- terns. They represented a vector of a relational pat- tern as the distribution of entity pairs co-occurring with the relational pattern. <ref type="bibr" target="#b10">Grycner et al. (2015)</ref> extended <ref type="bibr" target="#b23">Nakashole et al. (2012)</ref> to generalize di- mensions of the vector space (entity pairs) by in- corporating hyponymy relation between entities. They also used external resources to recognize the transitivity of pattern pairs and applied transitivi- ties to find patterns in entailment relation. These studies did not consider semantic composition of relational patterns. Thus, they might suffer from the data sparseness problem, as shown by No- Comp in <ref type="figure" target="#fig_1">Figure 4</ref>.  <ref type="bibr" target="#b12">Hashimoto et al., 2014</ref>), etc. As described in Section 3, we applied RNN, GRU, and LSTM to compute distributed representations of relational patterns because recent papers have demonstrated their superiority in semantic compo- sition ( <ref type="bibr" target="#b32">Sutskever et al., 2014;</ref><ref type="bibr" target="#b35">Tang et al., 2015)</ref>. In this paper, we presented a comparative study of different encoders for semantic modeling of rela- tional patterns.</p><p>To investigate usefulness of the distributed rep- resentations and the new dataset, we adopted the relation classification task <ref type="bibr">(SemEval 2010 Task 8)</ref> as a real application. On the SemEval 2010 Task 8, several studies considered semantic composi- tion. <ref type="bibr" target="#b9">Gormley et al. (2015)</ref> proposed Feature-rich Compositional Embedding Model (FCM) that can combine binary features (e.g., positional indica- tors) with word embeddings via outer products. dos <ref type="bibr" target="#b4">Santos et al. (2015)</ref> addressed the task using Convolutional Neural Network (CNN). <ref type="bibr" target="#b38">Xu et al. (2015)</ref> achieved a higher performance than dos <ref type="bibr" target="#b4">Santos et al. (2015)</ref> by application of CNN on de- pendency paths.</p><p>In addition to the relation classification task, we briefly describe other applications. To popu- late a knowledge base, <ref type="bibr" target="#b25">Riedel et al. (2013)</ref> jointly learned latent feature vectors of entities, relational patterns, and relation types in the knowledge base. <ref type="bibr" target="#b36">Toutanova et al. (2015)</ref> adapted CNN to capture the compositional structure of a relational pattern during the joint learning. For open domain ques- tion answering, <ref type="bibr" target="#b39">Yih et al. (2014)</ref> proposed the method to map an interrogative sentence on an en- tity and a relation type contained in a knowledge base by using CNN.</p><p>Although these reports described good perfor- mance on the respective tasks, we are unsure of the generality of distributed representations trained for a specific task such as the relation classifica- tion. In contrast, this paper demonstrated the con- tribution of distributed representations trained in a generic manner (with the Skip-gram objective) to the task of relation classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we addressed the semantic model- ing of relational patterns. We introduced the new dataset in which humans rated multiple similar- ity scores for every pair of relational patterns on the dataset of semantic inference <ref type="bibr" target="#b40">(Zeichner et al., 2012</ref>). Additionally, we explored different en- coders for composing distributed representations of relational patterns. The experimental results shows that Gated Additive Composition (GAC), which is a combination of additive composition and the gating mechanism, is effective to compose distributed representations of relational patterns. Furthermore, we demonstrated that the presented dataset is useful to predict successes of the dis- tributed representations in the relation classifica- tion task.</p><p>We expect that several further studies will use the new dataset not only for distributed represen- tations of relational patterns but also for other NLP tasks (e.g., paraphrasing). Analyzing the internal mechanism of LSTM, GRU, and GAC, we plan to explore an alternative architecture of neural net- works that is optimal for relational patterns.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Number of judgments for each similarity rating. The total number of judgments is 27, 775 (5, 555 pairs × 5 workers).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Performance of each method on the relational pattern similarity task with variation in the number of dimensions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Numerous studies have been aimed at encod- ing distributed representations of phrases and sen- tences from word embeddings by using: Recur- sive Neural Network (Socher et al., 2011), Matrix Vector Recursive Neural Network (Socher et al., 2012), Recursive Neural Network with different weight matrices corresponding to syntactic cate- gories (Socher et al., 2013) or word types (Takase et al., 2016), RNN (Sutskever et al., 2011), LSTM (Sutskever et al., 2014), GRU (Cho et al., 2014), PAS-CLBLM (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><head>Table 2 displays</head><label>2</label><figDesc>the top three examples iden- tified using the procedure. The table shows two groups of tendencies. Input gates open and forget gates close when scanned words are only a prepo- sition and the current word is a content word. In these situations, GAC tries to read the semantic</figDesc><table>w t 
w t+1 w t+2 ... 
large i t reimburse for 
(input 
payable 
in 
open) 
liable 
to 
small i t a 
charter member of 
(input 
a 
valuable member of 
close) 
be 
an avid reader of 
large f t be 
eligible to participate in 
(forget 
be 
require to submit 
open) 
be 
request to submit 
small f t coauthor 
of 
(forget 
capital 
of 
close) 
center 
of 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Prominent moments for input/forget 
gates. 

</table></figure>

			<note place="foot" n="3"> http://www.crowdflower.com/ 4 We allow ±1 differences in rating when we measure the performance of the workers.</note>

			<note place="foot" n="5"> We do not use a bias term in this study. We set the number of dimensions of hidden states identical to that of word embeddings (d) so that we can adapt the objective function of the Skip-gram model for training (Section 3.5).</note>

			<note place="foot" n="6"> We omitted peephole connections and bias terms.</note>

			<note place="foot" n="11"> http://reverb.cs.washington.edu/ 12 http://chainer.org/</note>

			<note place="foot" n="13"> https://www.csie.ntu.edu.tw/ ˜ cjlin/ libsvm/</note>

			<note place="foot" n="14"> In fact, we made substantial efforts to introduce the negative sampling technique. However, Xu et al. (2015) omits the detail of the technique probably because of the severe page limit of short papers. For this reason, we could not reproduce their method in this study.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the reviewers and Jun Suzuki for valu-able comments. This work was partially sup-ported by Grant-in-Aid for JSPS Fellows Grant no. 26.5820, JSPS KAKENHI Grant number 15H05318, and JST, CREST.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Semeval-2012 task 6: A pilot on semantic textual similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aitor</forename><surname>Gonzalez-Agirre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The First Joint Conference on Lexical and Computational Semantics (*SEM 2012)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="385" to="393" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Long short-term memory neural networks for chinese word segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinchi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxi</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1197" to="1206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1724" to="1734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Empirical evaluation of gated recurrent neural networks on sequence modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyoung</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Gülçehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Classifying relations by ranking with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Cicero Dos Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (ACLIJCNLP 2015)</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (ACLIJCNLP 2015)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="626" to="634" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Transitionbased dependency parsing with stack long shortterm memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Austin</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (ACLIJCNLP 2015)</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (ACLIJCNLP 2015)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="334" to="343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Finding structure in time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jeffrey L Elman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive science</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="211" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Identifying relations for open information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1535" to="1545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Ppdb: The paraphrase database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juri</forename><surname>Ganitkevitch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT 2013)</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT 2013)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="758" to="764" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Improved relation extraction with feature-rich compositional embedding models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">R</forename><surname>Gormley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP 2015)</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP 2015)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1774" to="1784" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Relly: Inferring hypernym relationships between relational phrases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Grycner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jay</forename><surname>Pujara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Foulds</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lise</forename><surname>Getoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP 2015)</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP 2015)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="971" to="981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zellig</forename><surname>Harris</surname></persName>
		</author>
		<title level="m">Distributional structure. Word</title>
		<imprint>
			<date type="published" when="1954" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="146" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Jointly learning word representations and composition functions using predicate-argument structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuma</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makoto</forename><surname>Miwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshimasa</forename><surname>Tsuruoka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1544" to="1555" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Task-oriented learning of word embeddings for semantic relation classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuma</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makoto</forename><surname>Miwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshimasa</forename><surname>Tsuruoka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th Conference on Computational Natural Language Learning</title>
		<meeting>the 19th Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="268" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Semeval-2010 task 8: Multi-way classification of semantic relations between pairs of nominals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iris</forename><surname>Hendrickx</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Su</forename><forename type="middle">Nam</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zornitsa</forename><surname>Kozareva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diarmuid´odiarmuid´</forename><forename type="middle">Diarmuid´o</forename><surname>Séaghdha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Padó</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Pennacchiotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenza</forename><surname>Romano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><surname>Szpakowicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Workshop on Semantic Evaluation</title>
		<meeting>the 5th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="33" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Raquel Urtasun, and Sanja Fidler</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 28 (NIPS 2015)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3276" to="3284" />
		</imprint>
	</monogr>
	<note>Skip-thought vectors</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Semeval-2013 task 5: Evaluating phrasal semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torsten</forename><surname>Ioannis Korkontzelos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><forename type="middle">Massimo</forename><surname>Zesch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Zanzotto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Biemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Second Joint Conference on Lexical and Computational Semantics (*SEM 2013)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="39" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Neural word embedding as implicit matrix factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 27 (NIPS 2014)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2177" to="2185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Dirt-discovery of inference rules from text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Pantel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD 01)</title>
		<meeting>the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD 01)</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="323" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 26 (NIPS 2013)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Composition in distributional models of semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1388" to="1439" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Finding the best model among representative compositional models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masayasu</forename><surname>Muraoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sonse</forename><surname>Shimaoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazeto</forename><surname>Yamamoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yotaro</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naoaki</forename><surname>Okazaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kentaro</forename><surname>Inui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th Pacific Asia Conference on Language, Information, and Computation (PACLIC 28)</title>
		<meeting>the 28th Pacific Asia Conference on Language, Information, and Computation (PACLIC 28)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="65" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Patty: A taxonomy of relational patterns with semantic types</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ndapandula</forename><surname>Nakashole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Suchanek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1135" to="1145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Relation extraction with matrix factorization and universal schemas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><forename type="middle">M</forename><surname>Marlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT 2013)</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT 2013)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="74" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Utd: Classifying semantic relations by combining lexical and semantic resources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Rink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanda</forename><surname>Harabagiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Workshop on Semantic Evaluation</title>
		<meeting>the 5th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="256" to="259" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Parsing natural scenes and natural language with recursive neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cliff Chiung-Yu</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Machine learning (ICML 2011)</title>
		<meeting>the 28th International Conference on Machine learning (ICML 2011)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="129" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Semantic compositionality through recursive matrix-vector spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brody</forename><surname>Huval</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1201" to="1211" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Parsing with compositional vector grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ng</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st</title>
		<meeting>the 51st</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<title level="m">Annual Meeting of the Association for Computational Linguistics (ACL 2013)</title>
		<imprint>
			<biblScope unit="page" from="455" to="465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Generating text with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Martens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Machine Learning</title>
		<meeting>the 28th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1017" to="1024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 27 (NIPS 2014)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Improved semantic representations from tree-structured long short-term memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai Sheng</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (ACL-IJCNLP 2015)</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (ACL-IJCNLP 2015)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1556" to="1566" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Modeling semantic compositionality of relational patterns. Engineering Applications of Artificial Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naoaki</forename><surname>Sho Takase</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kentaro</forename><surname>Okazaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Inui</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="256" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Document modeling with gated recurrent neural network for sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP 2015)</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP 2015)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1422" to="1432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Representing text for joint embedding of text and knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Pantel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoifung</forename><surname>Poon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pallavi</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Gamon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP 2015)</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP 2015)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1499" to="1509" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">From paraphrase database to compositional paraphrase model and back</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Wieting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Livescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions of the Association for Computational Linguistics (TACL 2015)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="345" to="358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Semantic relation classification via convolutional neural networks with simple negative sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yansong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songfang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="536" to="540" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Semantic parsing for single-relation question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Meek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL 2014)</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics (ACL 2014)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="643" to="648" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Crowdsourcing inference-rule evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naomi</forename><surname>Zeichner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL 2012)</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics (ACL 2012)</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="156" to="160" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
