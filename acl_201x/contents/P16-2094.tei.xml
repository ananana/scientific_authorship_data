<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:24+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Weakly Supervised Part-of-speech Tagging Using Eye-tracking Data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Barrett</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Centre for Language Technology</orgName>
								<orgName type="institution">University of Copenhagen Njalsgade 140</orgName>
								<address>
									<postCode>2300</postCode>
									<settlement>Copenhagen S</settlement>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><surname>Bingel</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Centre for Language Technology</orgName>
								<orgName type="institution">University of Copenhagen Njalsgade 140</orgName>
								<address>
									<postCode>2300</postCode>
									<settlement>Copenhagen S</settlement>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Keller</surname></persName>
							<email>keller@inf.ed.ac.uk</email>
							<affiliation key="aff1">
								<orgName type="department">School of Informatics</orgName>
								<orgName type="institution">University of Edinburgh</orgName>
								<address>
									<addrLine>10 Crichton Street</addrLine>
									<postCode>EH8 9AB</postCode>
									<settlement>Edinburgh</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>SÃ¸gaard</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Centre for Language Technology</orgName>
								<orgName type="institution">University of Copenhagen Njalsgade 140</orgName>
								<address>
									<postCode>2300</postCode>
									<settlement>Copenhagen S</settlement>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Weakly Supervised Part-of-speech Tagging Using Eye-tracking Data</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="579" to="584"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>For many of the world&apos;s languages, there are no or very few linguistically annotated resources. On the other hand, raw text, and often also dictionaries, can be harvested from the web for many of these languages, and part-of-speech taggers can be trained with these resources. At the same time, previous research shows that eye-tracking data, which can be obtained without explicit annotation, contains clues to part-of-speech information. In this work, we bring these two ideas together and show that given raw text, a dictionary, and eye-tracking data obtained from naive participants reading text, we can train a weakly supervised PoS tagger using a second-order HMM with maximum entropy emissions. The best model use type-level aggregates of eye-tracking data and significantly outperforms a baseline that does not have access to eye-tracking data.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>According to Ethnologue, there are around 7,000 languages in the world. <ref type="bibr">1</ref> For most of these lan- guages, no or very little linguistically annotated resources are available. This is why over the past decade or so, NLP researchers have focused on developing unsupervised algorithms that learn from raw text, which for many languages is widely available on the web. An example is part-of- speech (PoS) tagging, in which unsupervised ap- proaches have been increasingly successful (see <ref type="bibr" target="#b3">Christodoulopoulos et al. (2010)</ref> for an overview). The performance of unsupervised PoS taggers can be improved further if dictionary information is available, making it possible to constrain the PoS 1 http://www.ethnologue.com/world tagging process. Again, dictionary information can be harvested readily from the web for many languages ( <ref type="bibr" target="#b7">Li et al., 2012)</ref>.</p><p>In this paper, we show that PoS tagging perfor- mance can be improved further by using a weakly supervised model which exploits eye-tracking data in addition to raw text and dictionary informa- tion. Eye-tracking data can be obtained by get- ting native speakers of the target language to read text while their gaze behavior is recorded. Read- ing is substantially faster than manual annota- tion, and competent readers are available for lan- guages where trained annotators are hard to find or non-existent. While high quality eye-tracking equipment is still expensive, $100 eye-trackers such as the EyeTribe are already on the market, and cheap eye-tracking equipment is likely to be widely available in the near future, including eye- tracking by smartphone or webcam ( <ref type="bibr" target="#b10">Skovsgaard et al., 2013;</ref><ref type="bibr" target="#b11">Xu et al., 2015)</ref>.</p><p>Gaze patterns during reading are strongly in- fluenced by the parts of speech of the words be- ing read. Psycholinguistic experiments show that readers are less likely to fixate on closed-class words that are predictable from context. Read- ers also fixate longer on rare words, on words that are semantically ambiguous, and on words that are morphologically complex <ref type="bibr" target="#b9">(Rayner, 1998</ref>). These findings indicate that eye-tracking data should be useful for classifying words by part of speech, and indeed  show that word-type-level aggregate statistics collected from eye-tracking corpora can be used as features for supervised PoS tagging, leading to substantial gains in accuracy across domains. This leads us to hypothesize that gaze data should also improve weakly supervised PoS tagging.</p><p>In this paper, we test this hypothesis by ex- perimenting with a PoS tagging model that uses raw text, dictionary information, and eye-tracking data, but requires no explicit annotation. We start with a state-of-the-art unsupervised PoS tagging model, the second-order hidden Markov model with maximum entropy emissions of <ref type="bibr" target="#b7">Li et al. (2012)</ref>, which uses only textual features. We aug- ment this model with a wide range of features de- rived from an eye-tracking corpus at training time (type-level gaze features). We also experiment with token-level gaze features; the use of these features implies that eye-tracking is available both at training time and at test time. We find that eye- tracking features lead to a significant increase in PoS tagging accuracy, and that type-level aggre- gates work better than token-level features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The Dundee Treebank</head><p>The Dundee Treebank ( ) is a Universal Dependency annotation layer that has recently been added to the world's largest eye- tracking corpus, the Dundee Corpus ( <ref type="bibr" target="#b6">Kennedy et al., 2003</ref>). The English portion of the corpus con- tains 51,502 tokens and 9,776 types in 2,368 sen- tences. The Dundee Corpus is a well-known and widely used resource in psycholinguistic research.</p><p>The corpus enables researchers to study the read- ing of contextualized, running text obtained un- der relatively naturalistic conditions. The eye- movements in the Dundee Corpus were recorded with a high-end eye-tracker, sampling at 1000 Hz. The corpus contains the eye-movements of ten na- tive English speakers as they read the same twenty newspaper articles from The Independent. The 3 Type-constrained second-order HMM PoS tagging</p><p>We build on the type-constrained second-order hidden Markov model with maximum entropy emissions (SHMM-ME) proposed by <ref type="bibr" target="#b7">Li et al. (2012)</ref>. This model is an extension of the first-order max-ent HMM introduced by <ref type="bibr">BergKirkpatrick et al. (2010</ref> n regressions from w n long regressions from w Total regression-from duration CONTEXT w+1 fixation probability w+1 fixation duration w+2 fixation probability w+2 fixation duration w-2 fixation probability w-2 fixation probability NOGAZEB. Word length BNC log frequency w-1 BNC log frequency BNC forward transitional log probability BNC backward transitional log probability NOGAZED. Word length Dundee log frequency w-1 Dundee log frequency Dundee forward transitional log probability Dundee backward transitional log probability  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>Features Based on the eye-movement data in the Dundee Corpus, we compute token-level val- ues for 22 features pertaining to gaze and comple-  <ref type="table">Table 2</ref>: Tagging accuracy on the development set (token-level) for all individual feature groups, for the best combination of groups and for the best gaze-only combination of groups. ment them with another nine non-gaze features. Word length and word frequency are known to correlate and interact with gaze features. We use frequency counts from both a large corpus (the British National Corpus, BNC) and the Dundee Corpus itself. From these corpora, we also ob- tain forward and backward transitional probabil- ities, i.e., the conditional probabilities of a word given the previous or next word.</p><p>All gaze features are averaged over the ten read- ers and normalized linearly to a scale between 0 and 1. We divide the set of 31 features, which we list in <ref type="table" target="#tab_1">Table 1</ref>, into the following seven groups in order to examine for their individual contribution:</p><p>1. EARLY measures of processing such as first- pass fixation duration. Fixations on previous words are included in this group due to pre- view benefits. Early measures capture lexical access and early syntactic processing.</p><p>2. LATE measures of processing such as number of regressions to a word and re-fixation prob- ability. These measures reflect late syntactic processing and disambiguation in general.</p><p>3. BASIC word-level features, e.g., mean fixa- tion duration and fixation probability. These metrics do not belong explicitly to early or late processing measures.  can have syntactic relevance, e.g., in garden path sentences.</p><p>5. CONTEXT features of the surrounding to- kens. This group contains features relating to the fixations of the words in near proximity of the token. The eye can only recognize words a few characters to the left, and seven to eight characters to the right of the fixation <ref type="bibr" target="#b9">(Rayner, 1998)</ref>. Therefore it is useful to know the fix- ation pattern around the token.</p><p>6. NOGAZEBNC includes word length and word frequency obtained from the British Na- tional Corpus, as well as forward and back- ward transitional probabilities. These were computed using the KenLM language model- ing toolkit <ref type="bibr" target="#b5">(Heafield, 2011</ref>) with Kneser-Ney smoothing for unseen bigrams.  </p><note type="other">groups Accuracy â All groups 81.00 âNOGAZEBNC 80.80 â0.20 âNOGAZEDUN 80.28 â0.52* âBASIC 80.20 â0.08 âEARLY 79.78 â0.42* âLATE 79.53 â0.25 âREGFROM 79.24 â0.29* âCONTEXT (Baseline)</note><p>79.77 +0.53* <ref type="table">Table 4</ref>: Results of an ablation study over fea- ture groups on the test set on token-level features.</p><p>Significant differences with previous model are marked by * (p &lt; 0.05, McNemar's test).</p><p>vided it into a training set containing 46,879 to- kens/1,896 sentences, a development set contain- ing 5,868 tokens/230 sentences, and a test set of 5,832 tokens/241 sentences.</p><p>To tune the number of EM iterations required for the SHMM-ME model, we ran several exper- iments on the development set using 1 through 50 iterations. The result is fairly consistent for both the baseline (the original model of <ref type="bibr" target="#b7">Li et al. (2012)</ref>) and the full model (which includes all fea- ture groups in <ref type="table" target="#tab_1">Table 1</ref>). Tagging accuracy as a function of number of iterations is graphed in <ref type="figure" target="#fig_1">Fig- ure 2</ref>. The best number of iterations on the full model is five, which we will use for the remaining experiments.</p><p>We perform a grid search over all combinations of the seven feature groups, using five EM iter- ations for training, evaluating the resulting mod- els on token-level features of the development set. We observe that the best single feature group is NOGAZEDUN, the best single group of gaze fea- tures is BASIC, the best gaze-only group combi- nation is BASIC-LATE and the best group combi- nation is obtained by including all seven feature groups. Using all feature groups outperforms any individual feature group on development data. The performance of all the individual groups and of the best group combinations can be seen in <ref type="table">Table 2</ref>.</p><p>We run experiments on the test set and report re- sults using the best single group (NOGAZEDUN), the best single gaze group (BASIC), the best gaze- only group combination (BASIC-LATE) and the best group combination (all features).</p><p>Following , we con- trast the token-level gaze features with features ag-gregated at the type level. Type-level aggregation was used by  for super- vised PoS tagging: A lexicon of word types was created and the features values were averaged over all occurrences of each type in the training data.</p><p>As our baseline, we train and evaluate the origi- nal model proposed by <ref type="bibr" target="#b7">Li et al. (2012)</ref> on the train- test split described above, and compare it to the models that make use of eye-tracking measures.</p><p>To get an estimate of the effect of the textual features of Li et al., we train a model without these features, labeled NOTEXTFEATS. We also aug- ment this model with the best combination of fea- ture groups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>The main results are presented in Ta- ble 3. We first of all observe that both type- and token-level gaze features lead to significant improvements over <ref type="bibr" target="#b7">Li et al. (2012)</ref>, but type- level features perform better than token-level. We observe that the best individual feature group, NOGAZEDUN, performs better than the best in- dividual gaze feature group, BASIC and the best gaze-only feature group, BASIC+LATE. This is true on both type and token-level. Using the best combination of feature groups (All features) works best for both type-and token-level features. Also when excluding the textual feature model gaze helps and type-level features also work bet- ter than token-level here.</p><p>A feature ablation study (see <ref type="table">Table 4</ref>) supports the hierarchical ordering of the features based on the development set results (see <ref type="table" target="#tab_1">Table 1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>The proposed approach continues the work of  by augmenting an unsu- pervised baseline PoS tagging model instead of a supervised model. Our work also explores the po- tentials of token-level features. <ref type="bibr" target="#b12">Zelenina (2014)</ref> is the only work we are aware of that uses gaze features for unsupervised PoS tagging. <ref type="bibr" target="#b12">Zelenina (2014)</ref> employs gaze features to re-rank the output of a standard unsupervised tagger. She reports a small improvement with gaze features when evalu- ating on the Universal PoS tagset, but finds no im- provement when using the Penn Treebank tagset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>The best individual feature group is NOGAZE- DUN, indicating that just using word length and word frequency, as well as transitional probabili- ties, leads to a significant improvement in tagging accuracy. However, performance increases further when we add gaze features, which supports our claim that gaze data is useful for weakly supervis- ing PoS induction.</p><p>Type-level features work noticeably better than token-level features, suggesting that access to eye- tracking data at test time is not necessary. On the contrary, our results support the more resource- efficient set-up of just having eye-tracking data available at training time. We assume that this finding is due to the fact that eye-movement data is typically quite noisy; averaging over all tokens of a type reduces the noise more than just averag- ing over the ten participants that read each token. Thus token-level aggregation leads to more reli- able feature values.</p><p>Our finding that the best model includes all groups of gaze features, and that the best gaze- only group combination works better than the best individual gaze group suggest that different eye- tracking features contain complementary informa- tion. A broad selection of eye-movement features is necessary for reliably identifying PoS classes.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Second-order HMM. In addition to the transitional probabilities of the antecedent state z iâ1 in first-order HMMs, second-order models incorporate transitional probabilities from the second-order antecedent state z iâ2 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Tagging accuracy on development data (token-level) as a function of number of iterations on baseline and full model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>the</head><label></label><figDesc>Universal PoS tags (Petrov et al., 2011). Fig- ure 1 shows a graphical representation of a second- order hidden Markov model. Li et al. explore two aspects of type-constrained HMMs for unsupervised PoS tagging: the use of a second-order Markov model, and the use of textual features modeled by maximum entropy emissions. They find that both aspects improve tagging accu- racy and report the following results for English using Universal PoS tags on the Penn Treebank: first-order HMM 85.4, first-order HMM with max- ent emissions 86.1, second-order HMM 85.0, and second-order HMM with max-ent emissions 87.1. Li et al. employ a set of basic textual features for the max-ent versions, which encode word identity, presence of a hyphen, a capital letter, or a digit, and word suffixes of two to three letters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Feature</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 : Features in feature selection groups.</head><label>1</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Tagging accuracy for the baseline, for 
models with no text features and for our gaze-
enriched models using type and token gaze fea-
tures. Significant improvements over the baseline 
marked by * (p &lt; 10 â3 , McNemar's test). 

</table></figure>

			<note place="foot" n="2"> https://code.google.com/archive/p/ wikily-supervised-pos-tagger/</note>

			<note place="foot" n="3"> defined as saccades going further back than w iâ2</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>We presented the first study of weakly super-vised part-of-speech tagging with eye-tracking data, using a type-constrained second-order hid-den Markov model with max-ent emissions. We performed experiments adding a broad selection of eye-tracking features at training time (type-level features) and at test time (token-level fea-tures). We found significant improvements over the baseline in both cases, but type averaging worked better than token-level features. Our re-sults indicate that using traces of human cognitive processing, such as the eye-movements made dur-ing reading, can be used to augment NLP models. This could enable us to bootstrap better PoS tag-gers for domains and languages for which man-ually annotated corpora are not available, in par-ticular once eye-trackers become widely available through smartphones or webcams ( <ref type="bibr" target="#b10">Skovsgaard et al., 2013;</ref><ref type="bibr" target="#b11">Xu et al., 2015</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research was partially funded by the ERC Starting Grant LOWLANDS No. 313695, as well as by Trygfonden.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Reading behavior predicts syntactic categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>SÃ¸gaard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="345" to="349" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The dundee treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Zeljko AgiÂ´cagiÂ´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>SÃ¸gaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 14th International Workshop on Treebanks and Linguistic Theories (TLT 14)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="242" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Painless unsupervised learning with features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Bouchard-Cote</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Denero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="582" to="590" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Two decades of unsupervised POS induction: How far have we come?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Christodoulopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Goldwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="575" to="584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Surprisal-based comparison between a symbolic and a connectionist model of sentence processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><forename type="middle">L</forename><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st annual Conference of the Cognitive Science Society</title>
		<meeting>the 31st annual Conference of the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1139" to="1144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">KenLM: faster and smaller language model queries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the EMNLP 2011 Sixth Workshop on Statistical Machine Translation</title>
		<meeting>the EMNLP 2011 Sixth Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="187" to="197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The dundee corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">JoÃ«l</forename><surname>Pynte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th European conference on eye movement</title>
		<meeting>the 12th European conference on eye movement</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Wikily supervised part-of-speech tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">JoÃ£o</forename><surname>GraÃ§a</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Taskar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1389" to="1398" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">A universal part-of-speech tagset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<idno>CoRR abs/1104.2086</idno>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Eye movements in reading and information processing: 20 years of research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Rayner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological bulletin</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="372" to="422" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Gaze tracking through smartphones</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henrik</forename><surname>Skovsgaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Paulin Hansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emilie</forename><surname>MÃ¸llenbach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Gaze Interaction in the Post-WIMP World CHI 2013 One-day Workshop</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename><surname>Ehinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Finkelstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1504.06755</idno>
		<title level="m">TurkerGaze: Crowdsourcing saliency with webcam based eye tracking</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Part of speech induction with gaze features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Zelenina</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<pubPlace>United Kingdom</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Edinburgh</orgName>
		</respStmt>
	</monogr>
	<note>Master&apos;s thesis</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
