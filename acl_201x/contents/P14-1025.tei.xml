<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:01+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning Word Sense Distributions, Detecting Unattested Senses and Identifying Novel Senses Using Topic Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>June 23-25 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jey</forename><forename type="middle">Han</forename><surname>Lau</surname></persName>
							<email>jeyhan.lau@gmail.com, paulcook@unimelb.edu.au, diana@dianamccarthy.co.uk, spandanagella@gmail.com, tb@ldwin.net</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Dept of Philosophy</orgName>
								<orgName type="department" key="dep2">Dept of Computing and Information Systems</orgName>
								<orgName type="institution" key="instit1">King&apos;s College London</orgName>
								<orgName type="institution" key="instit2">The University of Melbourne</orgName>
								<orgName type="institution" key="instit3">University of Cambridge</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Cook</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Dept of Philosophy</orgName>
								<orgName type="department" key="dep2">Dept of Computing and Information Systems</orgName>
								<orgName type="institution" key="instit1">King&apos;s College London</orgName>
								<orgName type="institution" key="instit2">The University of Melbourne</orgName>
								<orgName type="institution" key="instit3">University of Cambridge</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Mccarthy</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Dept of Philosophy</orgName>
								<orgName type="department" key="dep2">Dept of Computing and Information Systems</orgName>
								<orgName type="institution" key="instit1">King&apos;s College London</orgName>
								<orgName type="institution" key="instit2">The University of Melbourne</orgName>
								<orgName type="institution" key="instit3">University of Cambridge</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spandana</forename><surname>Gella</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Dept of Philosophy</orgName>
								<orgName type="department" key="dep2">Dept of Computing and Information Systems</orgName>
								<orgName type="institution" key="instit1">King&apos;s College London</orgName>
								<orgName type="institution" key="instit2">The University of Melbourne</orgName>
								<orgName type="institution" key="instit3">University of Cambridge</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Dept of Philosophy</orgName>
								<orgName type="department" key="dep2">Dept of Computing and Information Systems</orgName>
								<orgName type="institution" key="instit1">King&apos;s College London</orgName>
								<orgName type="institution" key="instit2">The University of Melbourne</orgName>
								<orgName type="institution" key="instit3">University of Cambridge</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Learning Word Sense Distributions, Detecting Unattested Senses and Identifying Novel Senses Using Topic Models</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="259" to="270"/>
							<date type="published">June 23-25 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Unsupervised word sense disambiguation (WSD) methods are an attractive approach to all-words WSD due to their non-reliance on expensive annotated data. Unsuper-vised estimates of sense frequency have been shown to be very useful for WSD due to the skewed nature of word sense distributions. This paper presents a fully unsu-pervised topic modelling-based approach to sense frequency estimation, which is highly portable to different corpora and sense inventories, in being applicable to any part of speech, and not requiring a hierarchical sense inventory, parsing or parallel text. We demonstrate the effectiveness of the method over the tasks of predominant sense learning and sense distribution acquisition, and also the novel tasks of detecting senses which aren&apos;t attested in the corpus, and identifying novel senses in the corpus which aren&apos;t captured in the sense inventory.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The automatic determination of word sense infor- mation has been a long-term pursuit of the NLP community ( <ref type="bibr">Agirre and Edmonds, 2006;</ref><ref type="bibr" target="#b48">Navigli, 2009)</ref>. Word sense distributions tend to be Zip- fian, and as such, a simple but surprisingly high- accuracy back-off heuristic for word sense dis- ambiguation (WSD) is to tag each instance of a given word with its predominant sense ( <ref type="bibr" target="#b40">McCarthy et al., 2007)</ref>. Such an approach requires knowl- edge of predominant senses; however, word sense distributions -and predominant senses too - vary from corpus to corpus. Therefore, meth- ods for automatically learning predominant senses and sense distributions for specific corpora are re- quired ( <ref type="bibr" target="#b28">Koeling et al., 2005;</ref><ref type="bibr" target="#b29">Lapata and Brew, 2004)</ref>.</p><p>In this paper, we propose a method which uses topic models to estimate word sense distributions. This method is in principle applicable to all parts of speech, and moreover does not require a parser, a hierarchical sense representation or parallel text. Topic models have been used for WSD in a num- ber of studies <ref type="bibr" target="#b34">Li et al., 2010;</ref><ref type="bibr" target="#b30">Lau et al., 2012;</ref><ref type="bibr" target="#b52">Preiss and Stevenson, 2013;</ref><ref type="bibr" target="#b10">Cai et al., 2007;</ref><ref type="bibr" target="#b27">Knopp et al., 2013</ref>), but our work extends significantly on this earlier work in focusing on the acquisition of prior word sense distributions <ref type="bibr">(and predominant senses)</ref>.</p><p>Because of domain differences and the skewed nature of word sense distributions, it is often the case that some senses in a sense inventory will not be attested in a given corpus. A system ca- pable of automatically finding such senses could reduce ambiguity, particularly in domain adapta- tion settings, while retaining rare but nevertheless viable senses. We further propose a method for ap- plying our sense distribution acquisition system to the task of finding unattested senses -i.e., senses that are in the sense inventory but not attested in a given corpus. In contrast to the previous work of <ref type="bibr" target="#b38">McCarthy et al. (2004a)</ref> on this topic which uses the sense ranking score from <ref type="bibr" target="#b39">McCarthy et al. (2004b)</ref> to remove low-frequency senses from WordNet, we focus on finding senses that are unat- tested in the corpus on the premise that, given ac- curate disambiguation, rare senses in a corpus con- tribute to correct interpretation.</p><p>Corpus instances of a word can also correspond to senses that are not present in a given sense in- ventory. This can be due to, for example, words taking on new meanings over time (e.g. the rela-tively recent senses of tablet and swipe related to touchscreen computers) or domain-specific terms not being included in a more general-purpose sense inventory. A system for automatically iden- tifying such novel senses -i.e. senses that are attested in the corpus but not in the sense inven- tory -would be a very valuable lexicographi- cal tool for keeping sense inventories up-to-date ( . We further propose an appli- cation of our proposed method to the identification of such novel senses. In contrast to <ref type="bibr" target="#b39">McCarthy et al. (2004b)</ref>, the use of topic models makes this possi- ble, using topics as a proxy for sense <ref type="bibr" target="#b9">(Brody and Lapata, 2009;</ref><ref type="bibr" target="#b56">Yao and Durme, 2011;</ref><ref type="bibr" target="#b30">Lau et al., 2012)</ref>. Earlier work on identifying novel senses focused on individual tokens <ref type="bibr" target="#b16">(Erk, 2006</ref>), whereas our approach goes further in identifying groups of tokens exhibiting the same novel sense.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background and Related Work</head><p>There has been a considerable amount of research on representing word senses and disambiguating usages of words in context (WSD) as, in order to produce computational systems that understand and produce natural language, it is essential to have a means of representing and disambiguat- ing word sense. WSD algorithms require word sense information to disambiguate token instances of a given ambiguous word, e.g. in the form of sense definitions <ref type="bibr" target="#b33">(Lesk, 1986)</ref>, semantic relation- ships ( <ref type="bibr" target="#b46">Navigli and Velardi, 2005</ref>) or annotated data ( <ref type="bibr" target="#b57">Zhong and Ng, 2010)</ref>. One extremely use- ful piece of information is the word sense prior or expected word sense frequency distribution. This is important because word sense distributions are typically skewed <ref type="bibr" target="#b26">(Kilgarriff, 2004)</ref>, and sys- tems do far better when they take bias into ac- count ( <ref type="bibr" target="#b1">Agirre and Martinez, 2004</ref>).</p><p>Typically, word frequency distributions are esti- mated with respect to a sense-tagged corpus such as SemCor ( <ref type="bibr" target="#b41">Miller et al., 1993</ref>), a 220,000 word corpus tagged with <ref type="bibr">WordNet (Fellbaum, 1998)</ref> senses. Due to the expense of hand tagging, and sense distributions being sensitive to domain and genre, there has been some work on trying to estimate sense frequency information automati- cally ( <ref type="bibr" target="#b39">McCarthy et al., 2004b;</ref><ref type="bibr" target="#b12">Chan and Ng, 2005;</ref><ref type="bibr" target="#b43">Mohammad and Hirst, 2006;</ref><ref type="bibr" target="#b13">Chan and Ng, 2006</ref>). Much of this work has been focused on ranking word senses to find the predominant sense in a given corpus <ref type="bibr" target="#b39">(McCarthy et al., 2004b;</ref><ref type="bibr" target="#b43">Mohammad and Hirst, 2006</ref>), which is a very powerful heuris- tic approach to WSD. Most WSD systems rely upon this heuristic for back-off in the absence of strong contextual evidence ( <ref type="bibr" target="#b40">McCarthy et al., 2007)</ref>. <ref type="bibr" target="#b39">McCarthy et al. (2004b)</ref> proposed a method which relies on distributionally similar words (nearest neighbours) associated with the target word in an automatically acquired thesaurus <ref type="bibr" target="#b35">(Lin, 1998)</ref>. The distributional similarity scores of the nearest neighbours are associated with the respective tar- get word senses using a WordNet similarity mea- sure, such as those proposed by <ref type="bibr" target="#b23">Jiang and Conrath (1997)</ref> and <ref type="bibr" target="#b5">Banerjee and Pedersen (2002)</ref>. The word senses are ranked based on these similar- ity scores, and the most frequent sense is selected for the corpus that the distributional similarity the- saurus was trained over.</p><p>As well as sense ranking for predominant sense acquisition, automatic estimates of sense fre- quency distribution can be very useful for WSD for training data sampling purposes ( <ref type="bibr" target="#b1">Agirre and Martinez, 2004</ref>), entropy estimation ( <ref type="bibr" target="#b24">Jin et al., 2009)</ref>, and prior probability estimates, all of which can be integrated within a WSD system <ref type="bibr" target="#b12">(Chan and Ng, 2005;</ref><ref type="bibr" target="#b13">Chan and Ng, 2006;</ref><ref type="bibr" target="#b29">Lapata and Brew, 2004</ref>). Various approaches have been adopted, such as normalizing sense ranking scores to ob- tain a probability distribution ( <ref type="bibr" target="#b24">Jin et al., 2009)</ref>, us- ing subcategorisation information as an indication of verb sense ( <ref type="bibr" target="#b29">Lapata and Brew, 2004</ref>) or alter- natively using parallel text <ref type="bibr" target="#b12">(Chan and Ng, 2005;</ref><ref type="bibr" target="#b13">Chan and Ng, 2006;</ref><ref type="bibr" target="#b1">Agirre and Martinez, 2004</ref>).</p><p>The work of Boyd-  is highly related in that it extends the method of <ref type="bibr" target="#b39">McCarthy et al. (2004b)</ref> to provide a generative model which assumes the words in a given document are generated according to the topic distribution ap- propriate for that document. They then predict the most likely sense for each word in the document based on the topic distribution and the words in context ("corroborators"), each of which, in turn, depends on the document's topic distribution. Us- ing this approach, they get comparable results to McCarthy et al. when context is ignored (i.e. us- ing a model with one topic), and at most a 1% im- provement on SemCor when they use more topics in order to take context into account. Since the results do not improve on McCarthy et al. as re- gards sense distribution acquisition irrespective of context, we will compare our model with that pro- posed by McCarthy et al.</p><p>Recent work on finding novel senses has tended to focus on comparing diachronic corpora ( <ref type="bibr" target="#b54">Sagi et al., 2009;</ref><ref type="bibr" target="#b14">Cook and Stevenson, 2010;</ref><ref type="bibr" target="#b20">Gulordava and Baroni, 2011</ref>) and has also considered topic models ( <ref type="bibr" target="#b30">Lau et al., 2012)</ref>. In a similar vein, <ref type="bibr" target="#b51">Peirsman et al. (2010)</ref> considered the identifica- tion of words having a sense particular to one language variety with respect to another (specif- ically Belgian and Netherlandic Dutch). In con- trast to these studies, we propose a model for com- paring a corpus with a sense inventory. <ref type="bibr" target="#b11">Carpuat et al. (2013)</ref> exploit parallel corpora to identify words in domain-specific monolingual corpora with previously-unseen translations; the method we propose does not require parallel data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head><p>Our methodology is based on the WSI system described in <ref type="bibr" target="#b30">Lau et al. (2012)</ref>, 1 which has been shown ( <ref type="bibr" target="#b30">Lau et al., 2012;</ref><ref type="bibr" target="#b31">Lau et al., 2013a;</ref><ref type="bibr" target="#b32">Lau et al., 2013b</ref>) to achieve state-of-the-art results over the WSI tasks from <ref type="bibr">SemEval-2007 (Agirre and</ref><ref type="bibr" target="#b2">Soroa, 2007)</ref>, <ref type="bibr">SemEval-2010</ref><ref type="bibr" target="#b37">(Manandhar et al., 2010</ref> and <ref type="bibr">SemEval-2013 (Navigli and</ref><ref type="bibr" target="#b44">Vannella, 2013;</ref><ref type="bibr" target="#b25">Jurgens and Klapaftis, 2013</ref>  <ref type="formula" target="#formula_1">(2006)</ref>), a non-parametric variant of a Latent Dirichlet Allocation topic model ( <ref type="bibr" target="#b6">Blei et al., 2003)</ref> where the model automatically opti- mises the number of topics in a fully-unsupervised fashion over the training data.</p><p>To learn the senses of a target lemma, we train a single topic model per target lemma. The sys- tem reads in a collection of usages of that lemma, and automatically induces topics (= senses) in the form of a multinomial distribution over words, and per-usage topic assignments (= probabilistic sense assignments) in the form of a multinomial distri- bution over topics. Following <ref type="bibr" target="#b30">Lau et al. (2012)</ref>, we assign one topic to each usage by selecting the topic that has the highest cumulative probability density, based on the topic allocations of all words in the context window for that usage. <ref type="bibr">2</ref> Note that in their original work, <ref type="bibr" target="#b30">Lau et al. (2012)</ref> experimented with the use of features extracted from a depen- dency parser. Due to the computational overhead associated with these features, and the fact that the empirical impact of the features was found to be marginal, we make no use of parser-based features in this paper. <ref type="bibr">3</ref> The induced topics take the form of word multi- nomials, and are often represented by the top-N words in descending order of conditional probabil- ity. We interpret each topic as a sense of the target lemma. <ref type="bibr">4</ref> To illustrate this, we give the example of topics induced by the HDP model for network in <ref type="table">Table 1</ref>.</p><p>We refer to this method as HDP-WSI hence- forth. <ref type="bibr">5</ref> In predominant sense acquisition, the task is to learn, for each target lemma, the most frequently occurring word sense in a particular domain or corpus, relative to a predefined sense inventory. The WSI system provides us with a topic alloca- tion per usage of a given word, from which we can derive a distribution of topics over usages and a predominant topic. In order to map this onto the predominant sense, we need to have some way of aligning a topic with a sense. We design our topic- sense alignment methodology with portability in mind -it should be applicable to any sense in- ventory. As such, our alignment methodology as- sumes only that we have access to a conventional sense gloss or definition for each sense, and does not rely on ontological/structural knowledge (e.g. the WordNet hierarchy).</p><p>To compute the similarity between a sense and a topic, we first convert the words in the gloss/definition into a multinomial distribution over words, based on simple maximum likeli- hood estimation. <ref type="bibr">6</ref> We then calculate the Jensen- Shannon divergence between the multinomial dis- tribution (over words) of the gloss and that of the topic, and convert the divergence value into a sim- ilarity score by subtracting it from 1. Formally, the similarity sense s i and topic t j is:</p><formula xml:id="formula_0">sim(s i , t j ) = 1 − JS(ST )<label>(1)</label></formula><p>where S and T are the multinomial distributions Topic Num Top-10 Terms 1 network support @card@ information research service group development community member 2 service @card@ road company transport rail area government network public 3 network social model system family structure analysis form relationship neural 4 network @card@ computer system service user access internet datum server 5 system network management software support corp company service application product 6 @card@ radio news television show bbc programme call think film 7 police drug criminal terrorist intelligence network vodafone iraq attack cell 8 network atm manager performance craigavon group conference working modelling assistant 9 root panos comenius etd unipalm lse brazil telephone xxx discuss <ref type="table">Table 1</ref>: An example to illustrate the topics induced for network by the HDP model. The top-10 highest probability terms are displayed to represent each topic (@card@ denotes a tokenised cardinal number).</p><p>over words for sense s i and topic t j , respectively, and JS(XY ) is the Jensen-Shannon divergence for distribution X and Y . To learn the predominant sense, we compute the prevalence score of each sense and take the sense with the highest prevalence score as the predom- inant sense. The prevalence score for a sense is computed by summing the product of its similar- ity scores with each topic (i.e. sim(s i , t j )) and the prior probability of the topic in question (based on maximum likelihood estimation). Formally, the prevalence score of sense s i is given as follows:</p><formula xml:id="formula_1">prevalence(s i ) = T j (sim(s i , t j ) × P (t j ))<label>(2)</label></formula><formula xml:id="formula_2">= T j sim(s i , t j ) × f (t j ) T k f (t k )</formula><p>where f (t j ) is the frequency of topic t j (i.e. the number of usages assigned to topic t j ), and T is the number of topics. The intuition behind the approach is that the predominant sense should be the sense that has rel- atively high similarity (in terms of lexical overlap) with high-probability topic(s).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">WordNet Experiments</head><p>We first test the proposed method over the tasks of predominant sense learning and sense distribu- tion induction, using the WordNet-tagged dataset of <ref type="bibr" target="#b28">Koeling et al. (2005)</ref>, which is made up of 3 collections of documents: a domain-neutral corpus (BNC), and two domain-specific corpora (SPORTS and FINANCE). For each domain, annotators were asked to sense-annotate a ran- dom selection of sentences for each of 40 target nouns, based on WordNet v1.7. The predominant sense and distribution across senses for each target lemma was obtained by aggregating over the sense annotations. The authors evaluated their method in terms of WSD accuracy over a given corpus, based on assigning all instances of a target word with the predominant sense learned from that corpus. For the remainder of the paper, we denote their system as MKWC.</p><p>To compare our system (HDP-WSI) with MKWC, we apply it to the three datasets of <ref type="bibr" target="#b28">Koeling et al. (2005)</ref>. For each dataset, we use HDP to induce topics for each target lemma, compute the similarity between the topics and the WordNet senses (Equation <ref type="formula" target="#formula_0">(1)</ref>), and rank the senses based on the prevalence scores (Equation <ref type="formula" target="#formula_1">(2)</ref>). In addi- tion to the WSD accuracy based on the predomi- nant sense inferred from a particular corpus, we additionally compute: (1) Acc UB , the upper bound for the first sense-based WSD accuracy (using the gold standard predominant sense for disambigua- tion); 7 and (2) ERR, the error rate reduction be- tween the accuracy for a given system (Acc) and the upper bound (Acc UB ), calculated as follows:</p><formula xml:id="formula_3">ERR = 1 − Acc UB − Acc Acc UB</formula><p>Looking at the results in <ref type="table" target="#tab_2">Table 2</ref>, we see lit- tle difference in the results for the two methods, with MKWC performing better over two of the datasets (BNC and SPORTS) and HDP-WSI per- forming better over the third (FINANCE), but all differences are small. Based on the McNemar's Test with Yates correction for continuity, MKWC is significantly better over BNC and HDP-WSI is significantly better over FINANCE (p &lt; 0.0001 in both cases), but the difference over SPORTS is not statistically significance (p &gt; 0.1). Note that there is still much room for improvement with   both systems, as we see in the gap between the up- per bound (based on perfect determination of the first sense) and the respective system accuracies. Given that both systems compute a continuous- valued prevalence score for each sense of a tar- get lemma, a distribution of senses can be ob- tained by normalising the prevalence scores across all senses. The predominant sense learning task of <ref type="bibr" target="#b40">McCarthy et al. (2007)</ref> evaluates the ability of a method to identify only the head of this dis- tribution, but it is also important to evaluate the full sense distribution ( <ref type="bibr" target="#b24">Jin et al., 2009)</ref>. To this end, we introduce a second evaluation metric: the Jensen-Shannon (JS) divergence between the inferred sense distribution and the gold-standard sense distribution, noting that smaller values are better in this case, and that it is now theoretically possible to obtain a JS divergence of 0 in the case of a perfect estimate of the sense distribution. Re- sults are presented in <ref type="table" target="#tab_3">Table 3.</ref> HDP-WSI consistently achieves lower JS diver- gence, indicating that the distribution of senses that it finds is closer to the gold standard distri- bution. Testing for statistical significance over the paired JS divergence values for each lemma using the Wilcoxon signed-rank test, the result for FI- NANCE is significant (p &lt; 0.05) but the results for the other two datasets are not (p &gt; 0.1 in each case).   <ref type="table">Table 5</ref>: Sense distribution evaluation of HDP- WSI on the Macmillan-annotated datasets as com- pared to corpus-and dictionary-based first sense methods, evaluated using JS divergence (lower values indicate better performance; the best sys- tem in each row is indicated in boldface).</p><note type="other">Dataset FSCORPUS MKWC HDP-WSI AccUB Acc ERR Acc ERR BNC 0.</note><p>To summarise, the results for MKWC and HDP- WSI are fairly even for predominant sense learn- ing (each outperforms the other at a level of statis- tical significance over one dataset), but HDP-WSI is better at inducing the overall sense distribution.</p><p>It is important to bear in mind that MKWC in these experiments makes use of full-text parsing in calculating the distributional similarity thesaurus, and the WordNet graph structure in calculating the similarity between associated words and different senses. Our method, on the other hand, uses no parsing, and only the synset definitions (and not the graph structure) of WordNet. 8 The non-reliance on parsing is significant in terms of portability to text sources which are less amenable to parsing (such as Twitter: <ref type="figure">(Baldwin et al., 2013)</ref>), and the non-reliance on the graph structure of WordNet is significant in terms of portability to conventional "flat" sense inventories. While comparable results on a different dataset have been achieved with a proximity thesaurus ( <ref type="bibr" target="#b40">McCarthy et al., 2007)</ref> com- pared to a dependency one, 9 it is not stated how wide a window is needed for the proximity the- saurus. This could be a significant issue with Twit- ter data, where context tends to be limited. In the next section, we demonstrate the robustness of the method in experimenting with two new datasets, based on Twitter and a web corpus, and the Macmil- lan English Dictionary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Macmillan Experiments</head><p>In our second set of experiments, we move to a new dataset (Gella et al., to appear) based on text from ukWaC ( <ref type="bibr" target="#b18">Ferraresi et al., 2008)</ref> and Twit- ter, and annotated using the Macmillan English Dic- tionary 10 (henceforth "Macmillan"). For the pur- poses of this research, the choice of Macmillan is significant in that it is a conventional dictionary with sense definitions and examples, but no link- ing between senses. 11 In terms of the original re- search which gave rise to the sense-tagged dataset, Macmillan was chosen over WordNet for reasons in- cluding: (1) the well-documented difficulties of sense tagging with fine-grained WordNet senses ( <ref type="bibr" target="#b50">Palmer et al., 2004;</ref><ref type="bibr" target="#b47">Navigli et al., 2007)</ref>; (2) the regular update cycle of Macmillan (meaning it con- tains many recently-emerged senses); and (3) the finding in a preliminary sense-tagging task that it better captured Twitter usages than WordNet (and also OntoNotes: <ref type="bibr" target="#b21">Hovy et al. (2006)</ref>).</p><p>The dataset is made up of 20 target nouns which were selected to span the high-to mid-frequency range in both Twitter and the ukWaC corpus, and have at least 3 Macmillan senses. The average sense ambiguity of the 20 target nouns in Macmillan is 5.6 (but 12.3 in WordNet). 100 usages of each target noun were sampled from each of Twitter (from a crawl over the time period Jan 3-Feb 28, 2013 us- ing the Twitter Streaming API) and ukWaC, after language identification using langid.py <ref type="bibr" target="#b36">(Lui and Baldwin, 2012)</ref> and POS tagging (based on the CMU ARK Twitter POS tagger v2.0 ( <ref type="bibr" target="#b49">Owoputi et al., 2012</ref>) for Twitter, and the POS tags provided with the corpus for ukWaC). Amazon Mechani- cal Turk (AMT) was then used to 5-way sense-tag each usage relative to Macmillan, including allow- ing the annotators the option to label a usage as "Other" in instances where the usage was not cap- tured by any of the Macmillan senses. After qual- ity control over the annotators/annotations (see <ref type="bibr">Gella et al.</ref> (to appear) for details), and aggregation of the annotations into a single sense per usage (possibly "Other"), there were 2000 sense-tagged ukWaC sentences and Twitter messages over the 20 target nouns. We refer to these two datasets as UKWAC and TWITTER henceforth.</p><p>To apply our method to the two datasets, we use HDP-WSI to train a model for each target noun, based on the combined set of usages of that lemma in each of the two background corpora, namely the original Twitter crawl that gave rise to the TWIT- TER dataset, and all of ukWaC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Learning Sense Distributions</head><p>As in Section 4, we evaluate in terms of WSD accuracy <ref type="table" target="#tab_5">(Table 4)</ref> and JS divergence over the gold-standard sense distribution <ref type="table">(Table 5</ref>). We also present the results for: (a) a supervised base- line ("FS CORPUS "), based on the most frequent sense in the corpus; and (b) an unsupervised base- line ("FS DICT "), based on the first-listed sense in <ref type="bibr">Macmillan.</ref> In each case, the sense distribution is based on allocating all probability mass for a given word to the single sense identified by the respec- tive method.</p><p>We first notice that, despite the coarser-grained senses of Macmillan as compared to WordNet, the upper bound WSD accuracy using Macmillan is comparable to that of the WordNet-based datasets over the balanced BNC, and quite a bit lower than that of the two domain corpora of <ref type="bibr" target="#b28">Koeling et al. (2005)</ref>. This suggests that both datasets are di- verse in domain and content.</p><p>In terms of WSD accuracy, the results over UKWAC (ERR = 0.895) are substantially higher than those for BNC, while those over TWITTER (ERR = 0.716) are comparable. The accuracy is significantly higher than the dictionary-based first sense baseline (FS DICT ) over both datasets (McNe- mar's test; p &lt; 0.0001), and the ERR is also con- siderably higher than for the two domain datasets in Section 4 (FINANCE and SPORTS). One cause of difficulty in sense-modelling TWITTER is large numbers of missing senses, with 12.3% of usages in TWITTER and 6.6% in UKWAC hav- ing no corresponding Macmillan sense. <ref type="bibr">12</ref> This chal- lenges the assumption built into the sense preva- lence calculation that all topics will align to a pre- existing sense, a point we return to in Section 5.2.  <ref type="table">Table 6</ref>: Evaluation of our method for identify- ing unattested senses, averaged over 10 runs of 10- fold cross validation</p><p>The JS divergence results for both datasets are well below (= better than) the results for all three WordNet-based datasets, and also superior to both the supervised and unsupervised first-sense base- lines. Part of the reason for this improvement is simply that the average polysemy in Macmillan (5.6 senses per target lemma) is slightly less than in WordNet (6.7 senses per target lemma), 13 making the task slightly easier in the Macmillan case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Identification of Unattested Senses</head><p>We observed in Section 5.1 that there are rela- tively frequent occurrences of usages (e.g. 12.3% for TWITTER) which aren't captured by Macmil- lan. Conversely, there are also senses in Macmillan which aren't attested in the annotated sample of usages. Specifically, of the 112 senses defined for the 20 target lemmas, 25 (= 22.3%) of the senses are not attested in the 2000 usages in either cor- pora. Given that our methodology computes a prevalence score for each sense, it can equally be applied to the detection of these unattested senses, and it is this task that we address in this section: the identification of senses that are defined in the sense inventory but not attested in a given corpus.</p><p>Intuitively, an unused sense should have low similarity with the HDP induced topics. As such, we introduce sense-to-topic affinity, a measure that estimates how likely a sense is not attested in the corpus:</p><formula xml:id="formula_4">st-affinity(s i ) = T j sim(s i , t j ) S k T l sim(s k , t l ) (3)</formula><p>where sim(s i , t j ) is carried over from Equa- tion (1), and T and S represent the number of top- ics and senses, respectively.</p><p>We treat the task of identification of unused senses as a binary classification problem, where the goal is to find a sense-to-topic affinity thresh- old below which a sense will be considered to be unused. We pool together all the senses and run 10-fold cross validation to learn the threshold for identifying unused senses, 14 evaluated using sense-level precision (P ), recall (R) and F-score (F ) at detecting unattested senses. We repeat the experiment 10 times (partitioning the items ran- domly into folds) and collect the mean precision, recall and F-scores across the 10 runs. We found encouraging results for the task, as detailed in Ta- ble 6. For the threshold, the average value with standard deviation is 0.092 ± 0.044 over UKWAC and 0.125±0.052 over TWITTER, indicating rela- tive stability in the value of the threshold both in- ternally within a dataset, and also across datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Identification of Novel Senses</head><p>In both TWITTER and UKWAC, we observed fre- quent occurrences of usages of our target nouns which didn't map onto a pre-existing Macmillan sense. A natural question to ask is whether our method can be used to predict word senses that are missing from our sense inventory, and identify us- ages associated with each such missing sense. We will term these "novel senses", and define "novel sense identification" to be the task of identifying new senses that are not recorded in the inventory but are seen in the corpus.</p><p>An immediate complication in evaluating novel sense identification is that we are attempting to identify senses which explicitly aren't in our sense inventory. This contrasts with the identification of unattested senses, e.g., where we were attempting to identify which of the known senses wasn't ob- served in the corpus. Also, while we have annota- tions of "Other" usages in TWITTER and UKWAC, there is no real expectation that all such usages will correspond to the same sense: in practice, they are attributable to a myriad of effects such as incorporation in a non-compositional multiword expression, and errors in POS tagging (i.e. the us- age not being nominal). As such, we can't use the "Other" annotations to evaluate novel sense iden- tification. The evaluation of systems for this task is a known challenge, which we address similarly to <ref type="bibr" target="#b16">Erk (2006)</ref> by artificially synthesising novel senses through removal of senses from the sense inventory. In this way, even if we remove multi- ple senses for a given word, we still have access to information about which usages correspond to   <ref type="table">Table 8</ref>: Classification of usages with novel sense for target lemmas with a removed sense.</p><p>which novel sense. An additional advantage of this procedure is that it allows us to control an im- portant property of novel senses: their frequency of occurrence.</p><p>In the experiments that follow, we randomly select senses for removal from three frequency bands: low, medium and high frequency senses. Frequency is defined by relative occurrence in the annotated usages: low = 0.0-0.2; medium = 0.2- 0.4; and high = 0.4-0.6. Note that we do not con- sider high-frequency senses with frequency higher than 0.6, as it is rare for a medium-to high- frequency word to take on a novel sense which is then the predominant sense in a given corpus. Note also that not all target lemmas will have a novel sense through synthesis, as they may have no senses that fall within the indicated bounds of relative occurrence (e.g. if &gt; 60% of usages are a single sense). For example, only 6 of our 20 target nouns have senses which are candidates for high- frequency novel senses.</p><p>As before, we treat the novel sense identifica- tion task as a classification problem, although with a significantly different formulation: we are no longer attempting to identify pre-existing senses, as novel senses are by definition not included in the sense inventory. Instead, we are seeking to identify clusters of usages which are instances of a novel sense, e.g. for presentation to a lexicogra- pher as part of a dictionary update process <ref type="bibr" target="#b53">(Rundell and Kilgarriff, 2011;</ref>. That is, for each usage, we want to classify whether it is an instance of a given novel sense.</p><p>A usage that corresponds to a novel sense should have a topic that does not align well with any of the pre-existing senses in the sense inven- tory. Based on this intuition, we introduce topic- to-sense affinity to estimate the similarity of a topic to the set of senses, as follows:</p><formula xml:id="formula_5">ts-affinity(t j ) = S i sim(s i , t j ) T l S k sim(s k , t l ) (4)</formula><p>where, once again, sim(s i , t j ) is defined as in Equation <ref type="formula" target="#formula_0">(1)</ref>, and T and S represent the number of topics and senses, respectively.</p><p>Using topic-to-sense affinity as the sole fea- ture, we pool together all instances and optimise the affinity feature to classify instances that have novel senses. Evaluation is done by computing the mean precision, recall and F-score across 10 sepa- rate runs; results are summarised in <ref type="table" target="#tab_8">Table 7</ref>. Note that we evaluate only over UKWAC in this section, for ease of presentation.</p><p>The results show that instances with high- frequency novel senses are more easily identifi- able than instances with medium/low-frequency novel senses. This is unsurprising given that high- frequency senses have a higher probability of gen- erating related topics (sense-related words are ob- served more frequently in the corpus), and as such are more easily identifiable.</p><p>We are interested in understanding whether pooling all instances -instances from target lem- mas that have a sense artificially removed and those that do not -impacted the results (re- call that not all target lemmas have a removed sense). To that end, we chose to include only instances from lemmas with a removed sense, and repeated the experiment for the medium-and high-frequency novel sense condition (for the low- frequency condition, all target lemmas have a novel sense). In other words, we are assuming knowledge of which words have novel sense, and the task is to identify specifically what the novel sense is, as represented by novel usages. Results are presented in <ref type="table">Table 8</ref>.  <ref type="table">Table 9</ref>: Wilcoxon Rank Sum p-value results for testing target lemmas with removed sense vs. target lemmas without removed sense using novelty.</p><p>From the results, we see that the F-scores im- proved notably. This reveals that an additional step is necessary to determine whether a target lemma has a potential novel sense before feeding its in- stances to learn which of them contains the usage of the novel sense.</p><p>In the last experiment, we propose a new mea- sure to tackle this: the identification of target lem- mas that have a novel sense. We introduce novelty, a measure of the likelihood of a target lemma w having a novel sense:</p><formula xml:id="formula_6">novelty(w) = min t j max s i sim(s i , t j ) f (t j )<label>(5)</label></formula><p>where f (t j ) is the frequency of topic t j in the corpus. The intuition behind novelty is that a target lemma with a novel sense should have a (somewhat-)frequent topic that has low associa- tion with any sense. That we use the frequency rather than the probability of the topic here is de- liberate, as topics with a higher raw number of oc- currences (whether as a low-probability topic for a high-frequency word, or a high-probability topic for a low-frequency word) are indicative of a novel word sense. For each of our three datasets (with low-, medium-and high-frequency novel senses, respec- tively), we compute the novelty of the target lem- mas and the p-value of a one-tailed Wilcoxon rank sum test to test if the two groups of lemmas (i.e. lemmas with a novel sense vs. lemmas without a novel sense) are statistically different. <ref type="bibr">15</ref> Results are presented in <ref type="table">Table 9</ref>. We see that the nov- elty measure can readily identify target lemmas with high-and medium-frequency novel senses (p &lt; 0.05), but the results are less promising for the low-frequency novel senses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>Our methodologies for the two proposed tasks of identifying unused and novel senses are simple extensions to demonstrate the flexibility and ro- bustness of our methodology. Future work could pursue a more sophisticated methodology, using non-linear combinations of sim(s i , t j ) for com- puting the affinity measures or multiple features in a supervised context. We contend, however, that these extensions are ultimately a preliminary demonstration to the flexibility and robustness of our methodology.</p><p>A natural next step for this research would be to couple sense distribution estimation and the detec- tion of unattested senses with evidence from the context, using topics or other information about the local context (e.g. <ref type="bibr" target="#b3">Agirre and Soroa (2009)</ref>) to carry out unsupervised WSD of individual token occurrences of a given word.</p><p>In summary, we have proposed a topic modelling-based method for estimating word sense distributions, based on Hierarchical Dirich- let Processes and the earlier work of <ref type="bibr" target="#b30">Lau et al. (2012)</ref> on word sense induction, in probabilisti- cally mapping the automatically-learned topics to senses in a sense inventory. We evaluated the abil- ity of the method to learn predominant senses and induce word sense distributions, based on a broad range of datasets and two separate sense invento- ries. In doing so, we established that our method is comparable to the approach of <ref type="bibr" target="#b40">McCarthy et al. (2007)</ref> at predominant sense learning, and supe- rior at inducing word sense distributions. We fur- ther demonstrated the applicability of the method to the novel tasks of detecting word senses which are unattested in a corpus, and identifying novel senses which are found in a corpus but not cap- tured in a word sense inventory.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>). The system is built around a Hierarchical Dirichlet Process (HDP: Teh et al.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 : WSD accuracy for MKWC and HDP-</head><label>2</label><figDesc></figDesc><table>WSI 
on the WordNet-annotated datasets, as compared 
to the upper-bound based on actual first sense in 
the corpus (higher values indicate better perfor-
mance; the best system in each row [other than the 
FS CORPUS upper bound] is indicated in boldface). 

Dataset 
MKWC HDP-WSI 
BNC 
0.226 
0.214 
FINANCE 
0.426 
0.375 
SPORTS 
0.420 
0.363 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Sense distribution evaluation of MKWC 
and HDP-WSI on the WordNet-annotated datasets, 
evaluated using JS divergence (lower values indi-
cate better performance; the best system in each 
row is indicated in boldface). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 : WSD accuracy for HDP-WSI on the</head><label>4</label><figDesc></figDesc><table>Macmillan-annotated datasets, as compared to the 
upper-bound based on actual first sense in the cor-
pus (higher values indicate better performance; the 
best system in each row [other than the FS CORPUS 
upper bound] is indicated in boldface). 

Dataset 
FSCORPUS FSDICT HDP-WSI 

UKWAC 

0.210 
0.393 
0.156 
TWITTER 
0.259 
0.472 
0.171 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="true"><head>Table 7 : Classification of usages with novel sense for all target lemmas.</head><label>7</label><figDesc></figDesc><table>No. Lemmas with 
Relative Freq 
Threshold 
P 
R 
F 
a Removed Sense of Removed Sense Mean±stdev 
9 
0.2-0.4 
0.093±0.023 0.50 0.66 0.52 
6 
0.4-0.6 
0.099±0.018 0.73 0.90 0.80 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head>No . of Lemmas with No. of Lemmas without</head><label>No</label><figDesc></figDesc><table>Relative Freq 
Wilcoxon Rank Sum 
a Removed Sense 
a Removed Sense 
of Removed Sense 
p-value 
10 
0 
0.0-0.2 
0.4543 
9 
11 
0.2-0.4 
0.0391 
6 
14 
0.4-0.6 
0.0247 

</table></figure>

			<note place="foot" n="1"> Based on the implementation available at: https:// github.com/jhlau/hdp-wsi 2 This includes all words in the usage sentence except stopwords, which were filtered in the preprocessing step.</note>

			<note place="foot" n="3"> For hyper-parameters α and γ, we used 0.1 for both. We did not tune the parameters, and opted to use the default parameters introduced in Teh et al. (2006). 4 To avoid confusion, we will refer to the HDP-induced topics as topics, and reserve the term sense to denote senses in a sense inventory. 5 The code used to learn predominant sense and run all experiments described in this paper is available at: https: //github.com/jhlau/predom_sense. 6 Words are tokenised using OpenNLP and lemmatised with Morpha (Minnen et al., 2001). We additionally remove the target lemma, stopwords and words that are less than 3 characters in length.</note>

			<note place="foot" n="7"> The upper bound for a WSD approach which tags all token occurrences of a given word with the same sense, as a first step towards context-sensitive unsupervised WSD.</note>

			<note place="foot" n="8"> McCarthy et al. (2004b) obtained good results with definition overlap, but their implementation uses the relation structure alongside the definitions (Banerjee and Pedersen, 2002). Iida et al. (2008) demonstrate that further extensions using distributional data are required when applying the method to resources without hierarchical relations. 9 The thesauri used in the reimplementation of MKWC in this paper were obtained from http://webdocs.cs. ualberta.ca/ ˜ lindek/downloads.htm.</note>

			<note place="foot" n="10"> http://www.macmillandictionary.com/ 11 Strictly speaking, there is limited linking in the form of sets of synonyms in Macmillan, but we choose to not use this information in our research.</note>

			<note place="foot" n="12"> The relative occurrence of unlisted/unclear senses in the datasets of Koeling et al. (2005) is comparable to UKWAC.</note>

			<note place="foot" n="13"> Note that the set of lemmas differs between the respective datasets, so this isn&apos;t an accurate reflection of the relative granularity of the two dictionaries.</note>

			<note place="foot" n="14"> We used a fixed step and increment at steps of 0.001, up to the max value of st-affinity when optimising the threshold.</note>

			<note place="foot" n="15"> Note that the number of words with low-frequency novel senses here is restricted to 10 (cf. 20 in Table 7) to ensure we have both positive and negative lemmas in the dataset.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We wish to thank the anonymous reviewers for their valuable comments. This research was sup-ported in part by funding from the Australian Re-search Council.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Word Sense Disambiguation: Algorithms and Applications</title>
		<editor>Eneko Agirre and Philip Edmonds</editor>
		<imprint>
			<date type="published" when="2006" />
			<publisher>Springer</publisher>
			<pubPlace>Dordrecht, Netherlands</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Unsupervised WSD based on automatically retrieved examples: The importance of bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Martinez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2004</title>
		<meeting>EMNLP 2004<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="25" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">SemEval-2007 task 02: Evaluating word sense induction and discrimination systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aitor</forename><surname>Soroa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th International Workshop on Semantic Evaluations</title>
		<meeting>the 4th International Workshop on Semantic Evaluations<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="7" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Personalizing PageRank for word sense disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aitor</forename><surname>Soroa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Conference of the EACL (EACL 2009)</title>
		<meeting>the 12th Conference of the EACL (EACL 2009)<address><addrLine>Athens, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="33" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">How noisy social media text, how diffrnt social media sources?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Lui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mackinlay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Joint Conference on Natural Language Processing (IJCNLP 2013)</title>
		<meeting>the 6th International Joint Conference on Natural Language Processing (IJCNLP 2013)<address><addrLine>Nagoya, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="356" to="364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">An adapted Lesk algorithm for word sense disambiguation using WordNet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satanjeev</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ted</forename><surname>Pedersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Conference on Intelligent Text Processing and Computational Linguistics (CICLing-2002)</title>
		<meeting>the 3rd International Conference on Intelligent Text Processing and Computational Linguistics (CICLing-2002)<address><addrLine>Mexico City, Mexico</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="136" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Latent Dirichlet allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Putop: Turning predominant senses into a topic model for word sense disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Graber</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Fourth International Workshop on Semantic Evaluations (SemEval-2007)</title>
		<meeting>of the Fourth International Workshop on Semantic Evaluations (SemEval-2007)<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="277" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A topic model for word sense disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojin</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)</title>
		<meeting>of the 2007 Joint Conference on Empirical Methods in Natural Language essing and Computational Natural Language Learning (EMNLP-CoNLL)<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1024" to="1033" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Bayesian word sense induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Brody</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Conference of the EACL (EACL 2009)</title>
		<meeting>the 12th Conference of the EACL (EACL 2009)<address><addrLine>Athens, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="103" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">NUS-ML: Improving word sense disambiguation using topic features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Fu Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wee</forename><surname>Sun Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee</forename><forename type="middle">Whye</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Fourth International Workshop on Semantic Evaluations (SemEval-2007)</title>
		<meeting>of the Fourth International Workshop on Semantic Evaluations (SemEval-2007)<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="249" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">SenseSpotting: Never let your parallel data tie you to an old domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marine</forename><surname>Carpuat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katharine</forename><surname>Henry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ann</forename><surname>Irvine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jagadeesh</forename><surname>Jagarlamudi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachel</forename><surname>Rudinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 51st Annual Meeting of the Association for Computational Linguistics (ACL 2013)</title>
		<meeting>of the 51st Annual Meeting of the Association for Computational Linguistics (ACL 2013)<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1435" to="1445" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Word sense disambiguation with distribution estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee</forename><surname>Seng Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee Tou</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 19th International Joint Conference on Artificial Intelligence (IJCAI 2005)</title>
		<meeting>of the 19th International Joint Conference on Artificial Intelligence (IJCAI 2005)<address><addrLine>Edinburgh, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="1010" to="1015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Estimating class priors in domain adaptation for word sense disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee</forename><surname>Seng Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee Tou</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="89" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Automatically identifying changes in the semantic orientation of words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suzanne</forename><surname>Stevenson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Conference on Language Resources and Evaluation (LREC 2010)</title>
		<meeting>the 7th International Conference on Language Resources and Evaluation (LREC 2010)<address><addrLine>Valletta, Malta</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="28" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A lexicographic appraisal of an automatic approach for detecting new word senses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Rundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of eLex 2013</title>
		<meeting>eLex 2013<address><addrLine>Tallinn, Estonia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="49" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Unknown word sense detection as outlier detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katrin</forename><surname>Erk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Main Conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics</title>
		<meeting>of the Main Conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics<address><addrLine>New York City, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="128" to="135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">WordNet: An Electronic Lexical Database</title>
		<editor>Christiane Fellbaum</editor>
		<imprint>
			<date type="published" when="1998" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Introducing and evaluating ukWaC, a very large web-derived corpus of English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriano</forename><surname>Ferraresi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eros</forename><surname>Zanchetta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvia</forename><surname>Bernardini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 4th Web as Corpus Workshop: Can we beat Google</title>
		<meeting>of the 4th Web as Corpus Workshop: Can we beat Google<address><addrLine>Marrakech, Morocco</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="47" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">One sense per tweeter ... and other lexical semantic tales of Twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spandana</forename><surname>Gella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Conference of the EACL (EACL 2014)</title>
		<meeting>the 14th Conference of the EACL (EACL 2014)<address><addrLine>Gothenburg, Sweden</addrLine></address></meeting>
		<imprint/>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A distributional similarity approach to the detection of semantic change in the Google Books Ngram corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Gulordava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the GEMS 2011 Workshop on GEometrical Models of Natural Language Semantics</title>
		<meeting>the GEMS 2011 Workshop on GEometrical Models of Natural Language Semantics<address><addrLine>Edinburgh, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="67" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">OntoNotes: The 90% solution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lance</forename><surname>Ramshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Weischedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Main Conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics</title>
		<meeting>the Main Conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics<address><addrLine>New York City, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="57" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Gloss-based semantic similarity metrics for predominant sense acquisition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryu</forename><surname>Iida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Koeling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Third International Joint Conference on Natural Language Processing</title>
		<meeting>of the Third International Joint Conference on Natural Language essing</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="561" to="568" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Semantic similarity based on corpus statistics and lexical taxonomy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jay</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Conrath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings on International Conference on Research in Computational Linguistics</title>
		<meeting>on International Conference on Research in Computational Linguistics<address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="19" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Estimating and exploiting the entropy of sense distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Peng Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Koeling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Carroll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the North American Chapter of the Association for Computational Linguistics-Human Language Technologies 2009 (NAACL HLT 2009): Short Papers</title>
		<meeting>the North American Chapter of the Association for Computational Linguistics-Human Language Technologies 2009 (NAACL HLT 2009): Short Papers<address><addrLine>Boulder, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="233" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Semeval2013 task 13: Word sense induction for graded and non-graded senses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Jurgens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Klapaftis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval 2013)</title>
		<meeting>the 7th International Workshop on Semantic Evaluation (SemEval 2013)<address><addrLine>Atlanta, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="290" to="299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">How dominant is the commonest sense of a word?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Kilgarriff</surname></persName>
		</author>
		<idno>ITRI-04-10</idno>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
		<respStmt>
			<orgName>Information Technology Research Institute, University of Brighton</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Topic modeling for word sense induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Knopp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johanna</forename><surname>Völker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><forename type="middle">Paolo</forename><surname>Ponzetto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Conference of the German Society for Computational Linguistics and Language Technology</title>
		<meeting>of the International Conference of the German Society for Computational Linguistics and Language Technology<address><addrLine>Darmstadt; Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="97" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Domain-specific sense distributions and predominant sense acquisition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Koeling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Carroll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2005 Conference on Empirical Methods in Natural Language Processing (EMNLP 2005)</title>
		<meeting>the 2005 Conference on Empirical Methods in Natural Language Processing (EMNLP 2005)<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="419" to="426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Verb class disambiguation using informative priors. Computational Linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brew</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="45" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Word sense induction for novel sense detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jey Han</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Conference of the EACL (EACL 2012)</title>
		<meeting>the 13th Conference of the EACL (EACL 2012)<address><addrLine>Avignon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="591" to="601" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">unimelb: Topic modelling-based word sense induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jey Han</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Workshop on Semantic Evaluation</title>
		<meeting>the 7th International Workshop on Semantic Evaluation<address><addrLine>Atlanta, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="307" to="311" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">unimelb: Topic modelling-based word sense induction for web snippet clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jey Han</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Workshop on Semantic Evaluation</title>
		<meeting>the 7th International Workshop on Semantic Evaluation<address><addrLine>Atlanta, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="217" to="221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Automatic sense disambiguation using machine readable dictionaries: How to tell a pine cone from an ice cream cone</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Lesk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1986 SIGDOC Conference</title>
		<meeting>the 1986 SIGDOC Conference<address><addrLine>Ontario, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1986" />
			<biblScope unit="page" from="24" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Topic models for word sense disambiguation and token-based idiom detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linlin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caroline</forename><surname>Sporleder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 48th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>of the 48th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1138" to="1147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Automatic retrieval and clustering of similar words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th Annual Meeting of the ACL and 17th International Conference on Computational Linguistics (COLING/ACL98)</title>
		<meeting>the 36th Annual Meeting of the ACL and 17th International Conference on Computational Linguistics (COLING/ACL98)<address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="768" to="774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">langid.py: An off-the-shelf language identification tool</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Lui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL 2012) Demo Session</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics (ACL 2012) Demo Session<address><addrLine>Jeju, Republic of Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="25" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">SemEval-2010 Task 14: Word sense induction &amp; disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suresh</forename><surname>Manandhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Klapaftis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitriy</forename><surname>Dligach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Pradhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Workshop on Semantic Evaluation</title>
		<meeting>the 5th International Workshop on Semantic Evaluation<address><addrLine>Uppsala</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="63" to="68" />
		</imprint>
	</monogr>
	<note>Sweden</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Automatic identification of infrequent word senses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Koeling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julie</forename><surname>Weeds</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Carroll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 20th International Conference of Computational Linguistics, COLING2004</title>
		<meeting>of the 20th International Conference of Computational Linguistics, COLING2004<address><addrLine>Geneva, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="1220" to="1226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Finding predominant senses in untagged text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Koeling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julie</forename><surname>Weeds</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Carroll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL 2004)</title>
		<meeting>the 42nd Annual Meeting of the Association for Computational Linguistics (ACL 2004)<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="280" to="287" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Unsupervised acquisition of predominant word senses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Koeling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julie</forename><surname>Weeds</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Carroll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">33</biblScope>
			<biblScope unit="page" from="553" to="590" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A semantic concordance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudia</forename><surname>Leacock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Randee</forename><surname>Tengi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">T</forename><surname>Bunker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the ARPA Workshop on Human Language Technology</title>
		<meeting>of the ARPA Workshop on Human Language Technology</meeting>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="303" to="308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Applied morphological processing of English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guido</forename><surname>Minnen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Carroll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Darren</forename><surname>Pearce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="207" to="223" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Determining word sense dominance using a thesaurus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saif</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graeme</forename><surname>Hirst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EACL-2006</title>
		<meeting>of EACL-2006<address><addrLine>Trento, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="121" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniele</forename><surname>Vannella</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Word sense induction and disambiguation within an end-user application</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Workshop on Semantic Evaluation</title>
		<meeting>the 7th International Workshop on Semantic Evaluation<address><addrLine>Atlanta, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="193" to="201" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Structural semantic interconnections: a knowledge-based approach to word sense disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paola</forename><surname>Velardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1075" to="1088" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">SemEval-2007 task 07: Coarsegrained English all-words task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><forename type="middle">C</forename><surname>Litkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Orin</forename><surname>Hargraves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th International Workshop on Semantic Evaluations</title>
		<meeting>the 4th International Workshop on Semantic Evaluations<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="30" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Word sense disambiguation: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">41</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Partof-speech tagging for Twitter: Word clusters and other advances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olutobi</forename><surname>Owoputi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O&amp;apos;</forename><surname>Brendan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schneider</surname></persName>
		</author>
		<idno>CMU-ML-12- 107</idno>
	</analytic>
	<monogr>
		<title level="j">Machine Learning Department</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Different sense granularities for different applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Babko-Malaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoa</forename><forename type="middle">Trang</forename><surname>Dang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the HLT-NAACL 2004 Workshop: 2nd Workshop on Scalable Natural Language Understanding</title>
		<meeting>the HLT-NAACL 2004 Workshop: 2nd Workshop on Scalable Natural Language Understanding<address><addrLine>Boston, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="49" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">The automatic identification of lexical variation between language varieties</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yves</forename><surname>Peirsman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Geeraerts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Speelman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="469" to="491" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Unsupervised domain tuning to improve word sense disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judita</forename><surname>Preiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Stevenson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Atlanta, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="680" to="684" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Automating the creation of dictionaries: where will it all end?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Rundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Kilgarriff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">honour of Sylviane Granger</title>
		<editor>Fanny Meunier, Sylvie De Cock, Gaëtanelle Gilquin, and Magali Paquot</editor>
		<meeting><address><addrLine>Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="257" to="282" />
		</imprint>
	</monogr>
	<note>A Taste for Corpora</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Semantic density analysis: Comparing word meaning across time and space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eyal</forename><surname>Sagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Kaufmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brady</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the EACL 2009 Workshop on GEMS: GEometrical Models of Natural Language Semantics</title>
		<meeting>the EACL 2009 Workshop on GEMS: GEometrical Models of Natural Language Semantics<address><addrLine>Athens, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="104" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Hierarchical Dirichlet processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee Whye</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">J</forename><surname>Beal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="1566" to="1581" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Nonparametric Bayesian word sense induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuchen</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of TextGraphs-6: Graph-based Methods for Natural Language Processing</title>
		<meeting>TextGraphs-6: Graph-based Methods for Natural Language Processing<address><addrLine>Portland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="10" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">It makes sense: A wide-coverage word sense disambiguation system for free text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee Tou</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the ACL 2010 System Demonstrations</title>
		<meeting>of the ACL 2010 System Demonstrations<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="78" to="83" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
