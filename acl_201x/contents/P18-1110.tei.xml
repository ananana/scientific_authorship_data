<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:07+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Extending a Parser to Distant Domains Using a Few Dozen Partially Annotated Examples</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 15-20, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vidur</forename><surname>Joshi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Allen Institute for AI</orgName>
								<address>
									<settlement>Seattle</settlement>
									<region>WA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Peters</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Allen Institute for AI</orgName>
								<address>
									<settlement>Seattle</settlement>
									<region>WA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Hopkins</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Allen Institute for AI</orgName>
								<address>
									<settlement>Seattle</settlement>
									<region>WA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Extending a Parser to Distant Domains Using a Few Dozen Partially Annotated Examples</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1190" to="1199"/>
							<date type="published">July 15-20, 2018. 2018</date>
						</imprint>
					</monogr>
					<note>1190</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We revisit domain adaptation for parsers in the neural era. First we show that recent advances in word representations greatly diminish the need for domain adaptation when the target domain is syntactically similar to the source domain. As evidence, we train a parser on the Wall Street Journal alone that achieves over 90% F 1 on the Brown corpus. For more syntactically distant domains, we provide a simple way to adapt a parser using only dozens of partial annotations. For instance, we increase the percentage of error-free geometry-domain parses in a held-out set from 45% to 73% using approximately five dozen training examples. In the process, we demonstrate a new state-of-the-art single model result on the Wall Street Journal test set of 94.3%. This is an absolute increase of 1.7% over the previous state-of-the-art of 92.6%.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Statistical parsers are often criticized for their per- formance outside of the domain they were trained on. The most straightforward remedy would be more training data in the target domain, but build- ing treebanks <ref type="bibr" target="#b21">(Marcus et al., 1993</ref>) is expensive.</p><p>In this paper, we revisit this issue in light of re- cent developments in neural natural language pro- cessing. Our paper rests on two observations:</p><p>1. It is trivial to train on partial annotations using a span-focused model. <ref type="bibr" target="#b41">Stern et al. (2017a)</ref> demonstrated that a parser with min- imal dependence between the decisions that produce a parse can achieve state-of-the-art performance. We modify their parser, hence-  forth MSP, so that it trains directly on individ- ual labeled spans instead of parse trees. This results in a parser that can be trained, with no adjustments to the training regime, from par- tial sentence bracketings.</p><p>2. The use of contextualized word represen- tations ( <ref type="bibr" target="#b33">Peters et al., 2017;</ref><ref type="bibr" target="#b22">McCann et al., 2017)</ref> greatly reduces the amount of data needed to train linguistic models. Contex- tualized word representations, which encode tokens conditioned on their context in a sen- tence, have been shown to give significant boosts across a variety of NLP tasks, and also to reduce the amount of data needed by an or- der of magnitude in some tasks.</p><p>Taken together, this suggests a way to rapidly ex- tend a newswire-trained parser to new domains. Specifically, we will show it is possible to achieve large out-of-domain performance improvements using only dozens of partially annotated sentences, like those shown in <ref type="figure" target="#fig_1">Figure 1</ref>. The resulting parser also does not suffer any degradation on the newswire domain.</p><p>Along the way, we provide several other notable contributions:</p><p>• We raise the state-of-the-art single-model F 1 - score for constituency parsing from 92.6% to 94.3% on the Wall Street Journal (WSJ) test set. A trained model is publicly available. 1</p><p>• We show that, even without domain-specific training data, our parser has much less out-of- domain degradation than previous parsers on "newswire-adjacent" domains like the Brown corpus.</p><p>• We provide a version of MSP which pre- dicts its own POS tags (rather than requiring a third-party tagger).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The Reconciled Span Parser (RSP)</head><p>When we allow annotators to selectively anno- tate important phenomena, we make the process faster and simpler <ref type="bibr" target="#b27">(Mielens et al., 2015)</ref>. Unfor- tunately, this produces a disconnect between the model (which typically asserts the probability of a full parse tree) and the annotation task (which as- serts the correctness of some subcomponent, like a constituent span or a dependency arc). There is a body of research <ref type="bibr" target="#b13">(Hwa, 1999;</ref><ref type="bibr" target="#b18">Li et al., 2016</ref>) that discusses how to bridge this gap by modifying the training data, training algorithm, or the train- ing objective. Alternatively, we could just better align the model with the annotation task. Specifically, we could train a parser whose base model predicts ex- actly what we ask the annotator to annotate, e.g. whether a particular span is a constituent. This makes it trivial to train with partial or full anno- tations, because the training data reduces to a col- lection of span labels in either case.</p><p>Luckily, recent state-of-the-art results that model NLP tasks as independently classified spans ( <ref type="bibr" target="#b41">Stern et al., 2017a</ref>) suggest this strategy is cur- rently viable. In this section, we present the Rec- onciled Span Parser (RSP), a modified version of the Minimal Span Parser (MSP) of <ref type="bibr" target="#b41">Stern et al. (2017a)</ref>. RSP differs from MSP in the following ways:</p><p>• It is trained on a span classification task.</p><p>MSP trains on a maximum margin objec- tive; that is, the loss function penalizes the 1 http://allennlp.org/models violation of a margin between the scores of the gold parse and the next highest scoring parse decoded. This couples its training pro- cedure with its decoding procedure, result- ing in two versions, a top-down parser and a chart parser. To allow our model to be trained on partial annotations, we change the train- ing task to be the span classification task de- scribed below.</p><p>• It uses contextualized word representa- tions instead of predicted part-of-speech tags. Our model uses contextualized word representations as described in <ref type="bibr" target="#b32">Peters et al. (2018)</ref>. It does not take part-of-speech-tags as input, eliminating the dependence of the parser on a newswire-trained POS-tagger.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Overview</head><p>We will view a parse tree as a labeling of all the spans of a sentence such that:</p><p>• Every constituent span is labeled with the se- quence of non-terminals assigned to it in the parse tree. • Every non-constituent is labeled with the empty sequence.</p><p>Given a sentence represented by a sequence of to- kens x of length n, define spans(x) = {(i, j) | 0 ≤ i &lt; j ≤ n}. Define a parse for sentence x as a function π : spans(x) → L where L is the set of all sequences of non-terminal tags, including the empty sequence. We model the probability of a parse as the inde- pendent product of its span labels:</p><formula xml:id="formula_0">P r(π|x) = s∈spans(x) P r(π(s) | x, s) ⇒ log P r(π|x) = s∈spans(x) log P r(π(s) | x, s)</formula><p>Hence, we will train a base model σ(l | x, s) to estimate the log probability of label l for span s (given sentence x), and we will score the overall parse with:  Note that this probability model accords mass to mis-structured trees (e.g. overlapping spans like (2, 5) and (3, 7) cannot both be constituents of a well-formed tree). We solve the following Integer Linear Program (ILP) 2 to find the highest scoring parse that admits a well-formed tree:</p><formula xml:id="formula_1">score(π|x) = s∈spans(x) σ(π(s) | x, s)</formula><formula xml:id="formula_2">max δ (i,j)∈spans(x) v + (i,j) δ (i,j) + v − (i,j) (1 − δ (i,j) )</formula><p>subject to:</p><formula xml:id="formula_3">i &lt; k &lt; j &lt; m =⇒ δ (i,j) + δ (k,m) ≤ 1 (i, j) ∈ spans(x) =⇒ δ (i,j) ∈ {0, 1}</formula><p>where:</p><formula xml:id="formula_4">v + (i,j) = max l s.t. l =∅ σ(l | x, (i, j)) v − (i,j) = σ(∅ | x, (i, j))</formula><p>2 There are a number of ways to reconcile the span con- flicts, including an adaptation of the standard dynamic pro- gramming chart parsing algorithm to work with spans of an unbinarized tree. However it turns out that the classification model rarely produces span conflicts, so all methods we tried performed equivalently well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Classification Model</head><p>For our span classification model σ(l | x, s), we use the model from ( <ref type="bibr" target="#b41">Stern et al., 2017a</ref>), which leverages a method for encoding spans from ( <ref type="bibr" target="#b46">Wang and Chang, 2016;</ref><ref type="bibr" target="#b6">Cross and Huang, 2016)</ref>. First, it creates a sentence encoding by running a two-layer bidirectional LSTM over the sentence to obtain forward and backward encodings for each position i, denoted by f i and b i respec- tively. Then, spans are encoded by the difference in LSTM states immediately before and after the span; that is, span (i, j) is encoded as the con- catenation of the vector differences f j − f i−1 and b i − b j+1 . A one-layer feedforward network maps each span representation to a distribution over la- bels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Classification Model Parameters and Initializations</head><p>We preserve the settings used in Stern et al. (2017a) where possible. As a result, the size of the hidden dimensions of the LSTM and the feed- forward network is 250. The dropout ratio for the LSTM is set to 0.4 . Unlike the model it is based on, our model uses word embeddings of length 1124. These result from concatenating a 100 di- mension learned word embedding, with a 1024 di-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parser</head><p>Rec Prec F 1 RNNG ( <ref type="bibr" target="#b8">Dyer et al., 2016)</ref> - - 91.7 MSP ( <ref type="bibr" target="#b41">Stern et al., 2017a</ref>  mension learned linear combination of the internal states of a bidirectional language model run on the input sentence as described in <ref type="bibr" target="#b32">Peters et al. (2018)</ref>. We refer to them below as ELMo (Embeddings from Language Models). For the learned em- beddings, words with n occurrences in the train- ing data are replaced by UNK with probability </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Analysis of RSP</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Performance on Newswire</head><p>On WSJTEST 3 , RSP outperforms (see <ref type="table">Table 1</ref>) all previous single models trained on WSJTRAIN by a significant margin, raising the state-of-the-art re- sult from 92.6% to 94.3%. Additionally, our pre- dicted part-of-speech tags achieve 97.72% 4 accu- racy on WSJTEST.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Beyond Newswire</head><p>The Brown Corpus</p><p>The Brown corpus <ref type="bibr" target="#b21">(Marcus et al., 1993</ref>) is a standard benchmark used to assess WSJ-trained parsers outside of the newswire domain. When ( <ref type="bibr" target="#b16">Kummerfeld et al., 2012</ref>) parsed the various Brown verticals with the (then state-of-the-art) Charniak parser <ref type="bibr" target="#b4">(Charniak, 2000;</ref><ref type="bibr" target="#b5">Charniak and Johnson, 2005;</ref><ref type="bibr" target="#b24">McClosky et al., 2006a</ref>), it achieved F 1 scores between 83% and 86%, even though its F 1 score on WSJTEST was 92.1%.</p><p>In <ref type="table" target="#tab_3">Table 3</ref>, we discover that RSP does not suf- fer nearly as much degradation, with an average F 1 -score of 90.3%. To determine whether this in- creased portability is because of the parser archi- tecture or the use of ELMo vectors, we also run MSP on the Brown verticals. We used the Stan- ford tagger <ref type="bibr">5 (Toutanova et al., 2003</ref>) to tag WSJ- TRAIN and the Brown verticals so that MSP could be given these at train and test time. We learned that most of the improvement can be attributed to the ELMo word representations. In fact, even if we use MSP with gold POS tags, the average per- formance is 3.4% below RSP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question Bank and Genia</head><p>Despite being a standard benchmark for parsing domain adaptation, the Brown corpus has con- siderable commonality with newswire text. It is primarily composed of well-formed sentences with similar syntactic phenomena. Perhaps the main challenge with the Brown corpus is a dif- ference in vocabulary, rather than a difference in syntax, which may explain the success of RSP, which leverages contextualized embeddings learned from a large corpus.</p><p>If we try to run RSP on a more syntactically di- vergent corpus like QuestionBank <ref type="bibr">6</ref>     Surprisingly, with only 50 annotated questions (see <ref type="table" target="#tab_4">Table 4</ref>), performance on QBANKDEV jumps 5 points, from 89.9% to 94.9%. This is only 1.5% below training with all of WSJTRAIN and QBANKTRAIN. The resulting system improves slightly on WSJTEST getting 94.38%.</p><p>On the more difficult GENIA corpus of biomed- ical abstracts ( <ref type="bibr" target="#b44">Tateisi et al., 2005</ref>), we see a simi- lar, if somewhat less dramatic, trend. See <ref type="table" target="#tab_5">Table 5</ref>. With 50 annotated sentences, performance on GE- NIADEV jumps from 79.5% to 86.2%, outper- forming all but one parser from David McClosky's thesis <ref type="bibr" target="#b23">(McClosky, 2010)</ref> -the one that trains on all 14k sentences from GENIATRAIN and self-trains using 270k sentences from PubMed. That parser achieves 87.6%, which we outperform with just 500 sentences from GENIATRAIN.</p><p>These results suggest that it is currently feasi- ble to extend a parser to a syntactically distant do- main (for which no gold parses exist) with a cou- ple hours of effort. We explore this possibility in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Rapid Parser Extension</head><p>To create a parser for their geometry question an- swering system, ( <ref type="bibr" target="#b39">Seo et al., 2015</ref>) did the follow- ing:</p><p>• Designed regular expressions to identify mathematical expressions.</p><p>• Replaced the identified expressions with dummy words.</p><p>• Parsed the resulting sentences.  • Substituted the regex-analyzed expressions for the dummy words in the parses.</p><p>It is clear why this was necessary. Still, beyond just the inconvenience of build- ing additional infrastructure, there are downsides to the "regex-and-replace" strategy:</p><p>1. It assumes that each expression always maps to the same constituent label. Con- sider "2x = 3y". This is a verb phrase in the sentence "In the above figure, x is prime and 2x = 3y." However, it is a noun phrase in the sentence "The equation 2x = 3y has 2 solutions." If we replace both instances with the same dummy word, the parser will almost certainly become confused in one of the two instances.</p><p>2. It assumes that each expression is always a constituent. Suppose that we replace the expression "AB &lt; 30" with a dummy word. This means we cannot properly parse a sen- tence like "When angle AB &lt; 30, the lines are parallel," because the constituent "angle AB" no longer exists in the resulting sen- tence.</p><p>3. It does not handle other syntactic varia- tion. As we will see in the next section, the geometry domain has a propensity for using right-attaching participial adjective phrases, like "labeled x" in the phrase "the segment labeled x." Encouraging a parser to recognize this syntactic construct is out-of-scope for the "regex-and-replace" strategy.</p><p>Instead, we propose directly extending the parser by providing a few domain-specific examples like those in <ref type="figure" target="#fig_1">Figure 1</ref>. Because RSP's model directly predicts span constituency, we can simply mark up a sentence with the "tricky" domain-specific constituents that the model will not already have learned from WSJTRAIN. For instance, we mark up NOUN-LABEL constructs like "chord BD", and equations like "AD = 4". From these marked-up sentences, we can ex- tract training instances declaring the constituency of certain spans (like "to chord BD" in the third example) and the implied non-constituency of cer- tain spans (like "perpendicular to chord" in the third example). We also allow annotators to ex- plicitly declare the non-constituency of a span via an alternative markup (not shown).</p><p>We do not require annotators to provide span labels (although they can if desired). If a training instance merely declares a span to be a constituent (but does not provide a particular label), then the loss function only records loss when that span is classified as a non-constituent (i.e. any label is ok).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Geometry Questions</head><p>We took the publicly available training data from <ref type="bibr" target="#b39">(Seo et al., 2015)</ref>, split the data into sentences, and then annotated each sentence as in <ref type="figure" target="#fig_1">Figure 1</ref>. Next, we randomly split these sentences into GEO- TRAIN and GEODEV 7 . After removing duplicate sentences spanning both sets, we ended up with 63 annotated sentences in GEOTRAIN and 62 in GEODEV. In GEOTRAIN, we made an average of 2.8 constituent declarations and 0.3 (explicit) non- constituent declarations per sentence.</p><p>After preparing the data, we started with RSP trained on WSJTRAIN, and fine-tuned it on mini- batches containing 50 randomly selected WSJ- TRAIN sentences, plus all of GEOTRAIN. The re- sults are in   <ref type="table">Table 7</ref>: RSP performance on BIOCHEMDEV.</p><p>• Given [ a circle with [ the tangent shown ] ] .</p><p>• Find the hypotenuse of [ the triangle labeled t ] .</p><p>•  gets 87% of the 185 annotations on GEODEV cor- rect, compared with 71.9% before fine-tuning 8 . Moreover, the fraction of sentences with no er- rors increases from 45.2% to 72.6%. With only a few dozen partially-annotated training exam- ples, not only do we see a large increase in do- main performance, but there is also no degradation in the parser's performance on newswire. Some GEODEV parses have enormous qualitative differ- ences, like the example shown in <ref type="figure" target="#fig_7">Figure 3</ref>. For the GEODEV sentences on which we get errors after retraining, the errors fall predomi- nantly into three categories. First, approximately 44% have some mishandled math syntax, like failing to recognize "dimensions 16 by 8" as a constituent, or providing a flat structuring of the equation "BAC = 1/4 * ACB" (instead of recog- nizing "1/4 * ACB" as a subconstituent). Sec- ond, approximately 19% have PP-attachment er- rors. Third, another 19% fail to correctly analyze right-attaching participial adjectives like "labeled x" in the noun phrase "the segment labeled x" or "indicated" in the noun phrase "the center indi- cated." This phenomenon is unusually frequent in geometry but was insufficiently marked-up in our training examples. For instance, while we have a training instance "Find [ the measure of [ the angle designated by x ] ]," it does not explicitly highlight the constituency of "designated by x". This suggests that in practice, this domain adap- tation method could benefit from an iterative cy- cle in which a user assesses the parser's errors on their target domain, creates some partial annota- tions that address these issues, retrains the parser, and then repeats the process until satisfied. As a proof-of-concept, we invented 3 additional sen- tences with right-attaching participial adjectives (shown in <ref type="figure" target="#fig_10">Figure 4</ref>), added them to GEOTRAIN, and then retrained. Indeed, the handling of par- ticipial adjectives in GEODEV improved, increas- ing the overall percentage of correctly identified constituents to 88.6% and the percentage of error- free sentences to 75.8%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Biomedicine and Chemistry</head><p>We ran a similar experiment using biomedical and chemistry text, taken from the unannotated data provided by <ref type="bibr" target="#b30">(Nivre et al., 2007)</ref>. We par- tially annotated 134 sentences and randomly split them into BIOCHEMTRAIN (72 sentences) and BIOCHEMDEV (62 sentences) <ref type="bibr">9</ref> . In BIOCHEM- TRAIN, we made an average of 4.2 constituent declarations per sentence. We made no non- constituent declarations.</p><p>Again, we started with RSP trained on WSJ- TRAIN, and fine-tuned it on minibatches contain- ing annotations from 50 randomly selected WSJ-TRAIN sentences, plus all of BIOCHEMTRAIN. <ref type="table">Table 7</ref> shows the improvement in the percent- age of correctly-identified annotated constituents and the percentage of test sentences for which the parse agrees with every annotation. As with the geometry domain, we get significant improve- ments using only dozens of partially annotated training sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>The two major themes of this paper, domain adap- tation and learning from partial annotation, each have a long tradition in natural language process- ing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Domain Adaptation</head><p>Domain adaptation has been recognized as a ma- jor NLP problem for over a decade <ref type="bibr" target="#b1">(Ben-David et al., 2006;</ref><ref type="bibr" target="#b7">Daumé, 2007;</ref><ref type="bibr" target="#b9">Finkel and Manning, 2009</ref>). In particular, domain adaptation for parsers <ref type="bibr" target="#b34">(Plank, 2011;</ref><ref type="bibr" target="#b19">Ma and Xia, 2013</ref>) has received considerable attention. Much of this work <ref type="bibr" target="#b25">(McClosky et al., 2006b;</ref><ref type="bibr" target="#b35">Reichart and Rappoport, 2007;</ref><ref type="bibr" target="#b37">Sagae and Tsujii, 2007;</ref><ref type="bibr" target="#b15">Kawahara and Uchimoto, 2008;</ref><ref type="bibr" target="#b36">Sagae, 2010;</ref><ref type="bibr" target="#b0">Baucom et al., 2013;</ref><ref type="bibr" target="#b47">Yu et al., 2015)</ref> has focused on how to best use co-training <ref type="bibr" target="#b3">(Blum and Mitchell, 1998)</ref> or self-training to augment a small domain corpus, or how to best combine models to perform well on a particular domain.</p><p>In this work, we focus on the direct impact that just a few dozen partially annotated out-of-domain examples can have, when using a particular neural model with contextualized word representations. Co-training, self-training, and model combination are orthogonal to our approach. Our work is a spir- itual successor to ( <ref type="bibr" target="#b12">Garrette and Baldridge, 2013)</ref>, which shows how to train a part-of-speech tagger with a minimal amount of annotation effort.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Learning from Partial Annotation</head><p>Most literature on training parsers from partial an- notations ( <ref type="bibr" target="#b38">Sassano and Kurohashi, 2010;</ref><ref type="bibr" target="#b40">Spreyer et al., 2010;</ref><ref type="bibr" target="#b10">Flannery et al., 2011;</ref><ref type="bibr" target="#b11">Flannery and Mori, 2015;</ref><ref type="bibr" target="#b27">Mielens et al., 2015</ref>) focuses on de- pendency parsing. ( <ref type="bibr" target="#b18">Li et al., 2016</ref>) provides a good overview. Here we highlight three important high- level strategies.</p><p>The first is "complete-then-train" <ref type="bibr">(Mirroshandel and Nasr, 2011;</ref><ref type="bibr" target="#b20">Majidi and Crane, 2013)</ref>, which "completes" every partially annotated de- pendency parse by finding the most likely parse (according to an already trained parser model) that respects the constraints of the partial annotations. These "completed" parses are then used to train a new parser.</p><p>The second strategy <ref type="bibr" target="#b29">(Nivre et al., 2014;</ref><ref type="bibr" target="#b18">Li et al., 2016</ref>) is similar to "complete-then-train," but inte- grates parse completion into the training process. At each iteration, new "complete" parses are cre- ated using the parser model from the most recent training iteration.</p><p>The third strategy ( <ref type="bibr" target="#b17">Li et al., 2014</ref><ref type="bibr" target="#b18">Li et al., , 2016</ref>) trans- forms each partial annotation into a forest of parses that encodes all fully-specified parses per- mitted by the partial annotation. Then, the training objective is modified to support optimization over these forests.</p><p>Our work differs from these in two respects. First, since we are training a constituency parser, our partial annotations are constituent bracketings rather than dependency arcs. Second, and more importantly, we can use the partial annotations for training without modifying either the training al- gorithm or the training data.</p><p>While the bulk of the literature on training from partial annotations focuses on dependency pars- ing, the earliest papers ( <ref type="bibr" target="#b31">Pereira and Schabes, 1992;</ref><ref type="bibr" target="#b13">Hwa, 1999</ref>) focus on constituency parsing. These leverage an adapted version of the inside-outside algorithm for estimating the parameters of a prob- abilistic context-free grammar (PCFG). Our work is not tied to PCFG parsing, nor does it require a specialized training algorithm when going from full annotations to partial annotations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>Recent developments in neural natural language processing have made it very easy to build cus- tom parsers. Not only do contextualized word rep- resentations help parsers learn the syntax of new domains with very few examples, but they also work extremely well with parsing models that cor- respond directly with a granular and intuitive an- notation task (like identifying whether a span is a constituent). This allows you to train with either full or partial annotations without any change to the training process.</p><p>This work provides a convenient path forward for the researcher who requires a parser for their domain, but laments that "parsers don't work out- side of newswire." With a couple hours of effort (and a layman's understanding of syntactic build- ing blocks), they can get significant performance improvements. We envision an iterative use case in which a user assesses a parser's errors on their target domain, creates some partial annotations to teach the parser how to fix these errors, then re- trains the parser, repeating the process until they are satisfied.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Given [ the circle [ at the right ] with [ designated center, designated perpendicu- lar, and radius 5 ] ] . In [ the figure above ] , [ [ AD = 4 ] , [ AB = 3 ] and [ CD = 9 ] ] . [ Diameter AC ] is perpendicular [ to chord BD ] [ at E ] .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example of partial annotations. Annotators indicate that a span is a constituent by enclosing it in square brackets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>For instance, span (2, 4) in Fig- ure 2b is labeled with the sequence S, VP, as shown in Figure 2a.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>(a) Spans classified by the parsing procedure. Note that leaves have their part-of-speech tags predicted in addition to their se- quence of non-terminals.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The correspondence between labeled spans and a parse tree. This diagram is adapted from figure 1 in (Stern et al., 2017a).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>1+ n 10 1+n . This does not affect the ELMo component of the word embeddings. As a result, even com- mon words are replaced with probability at least 1 10 , making the model rely on the ELMo embed- dings instead of the learned embeddings. To make the model self-contained, it does not take part-of- speech tags as input. Using a linear layer over the last hidden layer of the classification model, part- of-speech tags are predicted for spans containing single words.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The top-level split for the development sentence "In the rhombus PQRS, PR = 24 and QS = 10." before and after retraining RSP on 63 partially annotated geometry statements.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 3 (</head><label>3</label><figDesc>top) shows how RSP (trained only on WSJTRAIN) parses the sentence "In the rhombus PQRS, PR = 24 and QS = 10." The result is completely wrong, and useless to a downstream application.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>Examine [ the following diagram with [ the square highlighted ] ] .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Three partial annotations targeting right-attaching participial adjectives.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 : Feature ablation on WSJDEV.</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Parsing performance on Brown verticals. MSP refers to the Minimal Span Parser (Stern et al., 
2017a). Charniak refers to the Charniak parser with reranking and self-training (Charniak, 2000; Char-
niak and Johnson, 2005; McClosky et al., 2006a). MSP + Stanford POS tags refers to MSP trained and 
tested using part-of-speech tags predicted by the Stanford tagger (Toutanova et al., 2003). 

Training Data 
Rec. Prec. 
F 1 
WSJ QBANK 
40k 
0 
91.07 88.77 89.91 
0 
2k 
94.44 96.23 95.32 
40k 
2k 
95.84 97.02 96.43 
40k 
50 
93.85 95.91 94.87 
40k 
100 
95.08 96.06 95.57 
40k 
400 
94.94 97.05 95.99 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><head>Table 4 : Performance of RSP on QBANKDEV.</head><label>4</label><figDesc></figDesc><table>Training Data Rec 
Prec 
F 1 
WSJ GENIA 
40k 
0 
72.51 88.84 79.85 
0k 
14k 
88.04 92.30 90.12 
40k 
14k 
88.24 92.33 90.24 
40k 
50 
82.30 90.55 86.23 
40k 
100 
83.94 89.97 86.85 
40k 
500 
85.52 91.01 88.18 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><head>Table 5 : Performance of RSP on GENIADEV.</head><label>5</label><figDesc></figDesc><table>For the experiments summarized in table 4 and 
table 5 involving 40k sentences from WSJTRAIN, 
we started with RSP trained on WSJTRAIN, and 
fine-tuned it on minibatches containing an equal 
number of target domain and WSJTRAIN sen-
tences. 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>table 6 . After fine-tuning, the model</head><label>6</label><figDesc></figDesc><table>Training Data 
GEODEV 
WSJTEST 
correct constituents % error-free % 
F 1 
WSJTRAIN 
71.9 
45.2 
94.28 
WSJTRAIN + GEOTRAIN 
87.0 
72.6 
94.30 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="true"><head>Table 6 : RSP performance on GEODEV.</head><label>6</label><figDesc></figDesc><table>Training Data 
BIOCHEMDEV 
WSJTEST 
correct constituents % error-free % 
F 1 
WSJTRAIN 
70.1 
27.0 
94.28 
WSJTRAIN + BIOCHEMTRAIN 
79.5 
46.7 
94.23 

</table></figure>

			<note place="foot" n="3"> For all our experiments on the WSJ component of the Penn Treebank (Marcus et al., 1993), we use the standard split which is sections 2-21 for training, henceforth WSJTRAIN, section 22 for development, henceforth WSJDEV, and 23 for testing, henceforth WSJTEST. 4 The split we used is not standard for part-of-speech tagging. As a result, we do not compare to part-of-speech taggers.</note>

			<note place="foot" n="5"> We used the english-left3words-distsim.tagger model from the 2017-06-09 release of the Stanford POS tagger since it achieved the best accuracy on the Brown corpus. 6 For all our experiments on QuestionBank, we use the following split: sentences 1-1000 and 2001-3000 for training, henceforth QBANKTRAIN, 1001-1500 and 3001-3500 for development, henceforth QBANKDEV, and 1501-2000 and 2501-4000 for testing, henceforth QBANKTEST. This split is described at https://nlp.stanford.edu/data/QuestionBankStanford.shtml.</note>

			<note place="foot" n="7"> GEOTRAIN and GEODEV are available at https://github.com/vidurj/parser-adaptation/tree/master/data.</note>

			<note place="foot" n="8"> This improvement has a p-value of 10 −4 under the onesided, two-sample difference between proportions test.</note>

			<note place="foot" n="9"> BIOCHEMTRAIN and BIOCHEMDEV are available at https://github.com/vidurj/parser-adaptation/tree/master/data.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Domain adaptation for parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Baucom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Levi</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandra</forename><surname>Kübler</surname></persName>
		</author>
		<editor>RANLP</editor>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Analysis of representations for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shai</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Domain adaptation with structural correspondence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><forename type="middle">T</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Combining labeled and unlabeled data with co-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avrim</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the eleventh annual conference on Computational learning theory</title>
		<meeting>the eleventh annual conference on Computational learning theory</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="92" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A maximum-entropy-inspired parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ANLP</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Coarseto-fine n-best parsing and maxent discriminative reranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 43rd Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="173" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Span-based constituency parsing with a structure-label system and provably optimal dynamic oracles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Cross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Frustratingly easy domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<idno>CoRR abs/0907.1815</idno>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Recurrent neural network grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adhiguna</forename><surname>Kuncoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<idno>CoRR abs/1602.07776</idno>
		<ptr target="http://arxiv.org/abs/1602.07776" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Hierarchical bayesian domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><forename type="middle">Rose</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLTNAACL</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Training dependency parsers from partially annotated corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Flannery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuke</forename><surname>Miyao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinsuke</forename><surname>Mori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCNLP</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Combining active learning and partial annotation for domain adaptation of a japanese dependency parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Flannery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinsuke</forename><surname>Mori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IWPT</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning a part-of-speech tagger from two hours of annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Garrette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Baldridge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="138" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Supervised grammar induction using training data with limited constituent information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Hwa</surname></persName>
		</author>
		<idno>cs.CL/9905001</idno>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Questionbank: Creating a corpus of parseannotated questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Judge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aoife</forename><surname>Cahill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Van Genabith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics</title>
		<meeting>the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="497" to="504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning reliability of parses for domain adaptation of dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daisuke</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiyotaka</forename><surname>Uchimoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCNLP</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Parser showdown at the wall street corral: An empirical investigation of error types in parser output</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">K</forename><surname>Kummerfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">Leo</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wright</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">R</forename><surname>Curran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-CoNLL</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Soft cross-lingual syntax projection for dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenghua</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenliang</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Training dependency parsers with partial annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenghua</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayuan</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<idno>CoRR abs/1609.09247</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Dependency parser adaptation with subtrees from auto-parsed target domain data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Committee-based active learning for dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saeed</forename><surname>Majidi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><forename type="middle">R</forename><surname>Crane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TPDL</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Building a large annotated corpus of english: The penn treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><forename type="middle">Ann</forename><surname>Mitchell P Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatrice</forename><surname>Marcinkiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Santorini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="313" to="330" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learned in translation: Contextualized word vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Any domain parsing: automatic domain adaptation for natural language parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Effective self-training for parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Reranking and self-training for parser adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Automatic domain adaptation for parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Parse imputation for dependency annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Mielens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Baldridge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Active learning for dependency parsing using partially annotated sentences</title>
	</analytic>
	<monogr>
		<title level="m">IWPT</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note>Seyed Abolghasem Mirroshandel and Alexis Nasr</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Constrained arc-eager dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><forename type="middle">T</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="249" to="527" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The conll 2007 shared task on dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandra</forename><surname>Kübler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Nilsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deniz</forename><surname>Yuret</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<publisher>EMNLP-CoNLL</publisher>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Insideoutside reestimation from partially bracketed corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yves</forename><surname>Schabes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<title level="m">Deep contextualized word representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Semi-supervised sequence tagging with bidirectional language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Waleed</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chandra</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Russell</forename><surname>Power</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Domain adaptation for parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Plank</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Citeseer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Self-training for enhancement and domain adaptation of statistical parsers trained on small datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Rappoport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Self-training without reranking for parser domain adaptation and its impact on semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Sagae</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Dependency parsing and domain adaptation with lr models and parser ensembles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Sagae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun&amp;apos;ichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-CoNLL</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Using smaller constituents rather than sentences in active learning for japanese dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manabu</forename><surname>Sassano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Solving geometry problems: Combining text and diagram interpretation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min Joon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clint</forename><surname>Malcolm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Training parsers on partial trees: A cross-language comparison</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathrin</forename><surname>Spreyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lilja</forename><surname>Ovrelid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Kuhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">A minimal span-based neural constituency parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><surname>Stern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<idno>CoRR abs/1705.03919</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Effective inference for generative neural parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><surname>Stern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Fried</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017</title>
		<meeting>the 2017</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
				<ptr target="https://aclanthology.info/papers/D17-1178/d17-1178" />
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods in Natural Language Processing</title>
		<meeting><address><addrLine>Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2017</biblScope>
			<biblScope unit="page" from="1695" to="1700" />
		</imprint>
	</monogr>
	<note>EMNLP</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Syntax annotation for the genia corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuka</forename><surname>Tateisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akane</forename><surname>Yakushiji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoko</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun&amp;apos;ichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Companion Volume to the Proceedings of Conference including Posters/Demos</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>and tutorial abstracts</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Feature-rich partof-speech tagging with a cyclic dependency network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/N/N03/N03-1033.pdf" />
	</analytic>
	<monogr>
		<title level="m">Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics, HLT-NAACL 2003</title>
		<meeting><address><addrLine>Edmonton, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-05-27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Graph-based dependency parsing with bidirectional lstm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baobao</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2306" to="2315" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Domain adaptation for dependency parsing via selftraining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juntao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohab</forename><surname>Elkaref</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernd</forename><surname>Bohnet</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>In IWPT</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
