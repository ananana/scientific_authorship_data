<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:50+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Compositional Representation of Morphologically-Rich Input for Neural Machine Translation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 15-20, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duygu</forename><surname>Ataman</surname></persName>
							<email>ataman@fbk.eu</email>
							<affiliation key="aff0">
								<orgName type="department">Trento</orgName>
								<orgName type="institution" key="instit1">FBK</orgName>
								<orgName type="institution" key="instit2">Italy University of Trento</orgName>
								<address>
									<country>Italy, Italy, Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
							<email>federico@fbk.eu</email>
							<affiliation key="aff0">
								<orgName type="department">Trento</orgName>
								<orgName type="institution" key="instit1">FBK</orgName>
								<orgName type="institution" key="instit2">Italy University of Trento</orgName>
								<address>
									<country>Italy, Italy, Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Compositional Representation of Morphologically-Rich Input for Neural Machine Translation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="305" to="311"/>
							<date type="published">July 15-20, 2018</date>
						</imprint>
					</monogr>
					<note>305</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Neural machine translation (NMT) models are typically trained with fixed-size input and output vocabularies, which creates an important bottleneck on their accuracy and generalization capability. As a solution , various studies proposed segmenting words into sub-word units and performing translation at the sub-lexical level. However , statistical word segmentation methods have recently shown to be prone to morphological errors, which can lead to inaccurate translations. In this paper, we propose to overcome this problem by replacing the source-language embedding layer of NMT with a bi-directional recurrent neural network that generates compo-sitional representations of the input at any desired level of granularity. We test our approach in a low-resource setting with five languages from different morphological typologies, and under different composition assumptions. By training NMT to compose word representations from character trigrams, our approach consistently outperforms (from 1.71 to 2.48 BLEU points) NMT learning embeddings of statistically generated sub-word units.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>An important problem in neural machine trans- lation (NMT) is translating infrequent or unseen words. The reasons are twofold: the necessity of observing many examples of a word until its in- put representation (embedding) becomes reliable, and the computational requirement of limiting the input and output vocabularies to few tens of thou- sands of words. These requirements eventually lead to coverage issues when dealing with low- resource and/or morphologically-rich languages, due to their high lexical sparseness. To cope with this well-known problem, several approaches have been proposed redefining the model vocabu- lary in terms of interior orthographic units com- pounding the words, ranging from character n- grams ( <ref type="bibr" target="#b15">Ling et al., 2015b;</ref><ref type="bibr" target="#b7">Costa-jussà and Fonollosa, 2016;</ref><ref type="bibr" target="#b13">Lee et al., 2017;</ref><ref type="bibr" target="#b16">Luong and Manning, 2016)</ref> to statistically-learned sub-word units <ref type="bibr" target="#b23">(Sennrich et al., 2016;</ref><ref type="bibr">Wu et al., 2016;</ref><ref type="bibr" target="#b1">Ataman et al., 2017)</ref>. While the former provide an ideal open vocabulary solution, they mostly failed to achieve competitive results. This might be related to the semantic ambiguity caused by solely relying on input representations based on character n-grams which are generally learned by disregarding any morphological information. In fact, the second approach is now prominent and has established a pre-processing step for constructing a vocabulary of sub-word units before training the NMT model. However, several studies have shown that seg- menting words into sub-word units without pre- serving morpheme boundaries can lead to loss of semantic and syntactic information and, thus, in- accurate translations <ref type="bibr" target="#b18">(Niehues et al., 2016;</ref><ref type="bibr" target="#b1">Ataman et al., 2017;</ref><ref type="bibr" target="#b20">Pinnis et al., 2017;</ref><ref type="bibr" target="#b11">Huck et al., 2017;</ref><ref type="bibr" target="#b24">Tamchyna et al., 2017)</ref>.</p><p>In this paper, we propose to improve the quality of input (source language) representations of rare words in NMT by augmenting its embedding layer with a bi-directional recurrent neural network (bi- RNN), which can learn compositional input repre- sentations at different levels of granularity. Com- positional word embeddings have recently been applied in language modeling and obtained suc- cessful results <ref type="bibr" target="#b26">(Vania and Lopez, 2017)</ref>. The ap- parent advantage of our approach is that by feed- ing NMT with simple character n-grams, our bi- RNN can potentially learn the morphology neces- sary to create word-level representations of the in-put language directly at training time, thus, avoid- ing the burden of a separate and sub-optimal word segmentation step. We compare our approach against conventional embedding-based represen- tations learned from statistical word segmenta- tion in a public evaluation benchmark, which pro- vides low-resource training conditions by pair- ing English with five morphologically-rich lan- guages: Arabic, Czech, German, Italian and Turk- ish, where each language represents a distinct morphological typology and language family. The experimental results show that our compositional input representations lead to significantly and con- sistently better translation quality in all language directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Neural Machine Translation</head><p>In this paper, we use the NMT model of . The model essentially estimates the conditional probability of translating a source se- quence x = (x 1 , x 2 , . . . x m ) into a target sequence y = (y 1 , y 2 , . . . y l ), using the decomposition</p><formula xml:id="formula_0">p(y|x) = l i=1 p(y j |y i−1 , .., y 0 , x m−1 , .., x 1 ) (1)</formula><p>The model is trained by maximizing the log- likelihood of a parallel training set via stochastic gradient descent <ref type="bibr" target="#b3">(Bottou, 2010)</ref> and the backprop- agation through time <ref type="bibr">(Werbos, 1990)</ref> algorithms.</p><p>The inputs of the network are one-hot vectors, which are binary vectors with a single bit set to 1 to identify a specific word in the vocabulary. Each one-hot vector is then mapped to an embed- ding, a distributed representation of the word in a lower dimension but a more dense continuous space. From this input, a representation of the whole input sequence is learned using a bi-RNN, the encoder, which maps x into m dense sentence vectors corresponding to its hidden states. Next, another RNN, the decoder, predicts each target to- ken y i by sampling from a distribution computed from the previous target token y i−1 , the previous decoder hidden state, and the context vector. The latter is a linear combination of the encoder hidden states, whose weights are dynamically computed by a feed-forward neural network called attention model ( ). The probability of generating each target word y j is normalized via a softmax function.</p><p>Both the source and target vocabulary sizes play an important role in terms of defining the complex- ity of the model. In a standard architecture, like ours, the source and target embedding matrices ac- tually account for the vast majority of the network parameters. The vocabulary size also plays an important role when translating from and to low- resource and morphologically-rich languages, due to the sparseness of the lexical distribution. There- fore, a conventional approach has now become to compose both the source and target vocabular- ies of sub-word units generated through statistical segmentation methods <ref type="bibr" target="#b23">(Sennrich et al., 2016;</ref><ref type="bibr">Wu et al., 2016;</ref><ref type="bibr" target="#b1">Ataman et al., 2017)</ref>, and perform- ing NMT by directly learning embeddings of sub- word units. A popular one of these is the Byte-Pair Encoding (BPE) method <ref type="bibr" target="#b9">(Gage, 1994;</ref><ref type="bibr" target="#b23">Sennrich et al., 2016)</ref>, which finds the optimal description of a corpus vocabulary by iteratively merging the most frequent character sequences. A more recent approach is the Linguistically-Motivated Vocabu- lary Reduction (LMVR) method <ref type="bibr" target="#b1">(Ataman et al., 2017)</ref>, which similarly generates a new vocabu- lary by segmenting words into sub-lexical units based on their likeliness of being morphemes and their morphological categories. A drawback of these methods is that, as pre-processing steps to NMT, they are not optimized for the translation task. Moreover, they can suffer from morphologi- cal errors at different levels, which can lead to loss of semantic or syntactic information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Learning Compositional Input</head><p>Representations via bi-RNNs</p><p>In this paper, we propose to perform NMT from input representations learned by composing smaller symbols, such as character n-grams ( <ref type="bibr" target="#b14">Ling et al., 2015a)</ref>, that can easily fit in the model vo- cabulary. This composition is essentially a func- tion which can establish a mapping between com- binations of ortographic units and lexical meaning, that is learned using the bilingual context so that it can produce representations that are optimized for machine translation.</p><p>In our model <ref type="figure">(Figure 1</ref>), the one-hot vectors, af- ter being fed into the embedding layer, are pro- cessed by an additional composition layer, which computes the final input representations passed to the encoder to generate translations. For learn- ing the composition function, we employ a bi- RNN. Hence, by encoding each interior unit in- side the word, we hope to capture important cues about their functional role, i.e. semantic or syn- <ref type="figure">Figure 1</ref>: Translation of the Italian sentence tor- nai a casa (I came home) with a word-level repre- sentation composed from character trigrams. tactic contribution to the word. We implement the network using gated recurrent units (GRUs) ( ), which have shown compara- ble performance to long-short-term-memory units <ref type="bibr" target="#b10">(Hochreiter and Schmidhuber, 1997</ref>), whereas they provide much faster computation. As a min- imal set of input symbols required to cope with contextual ambiguities, we opt to use intersecting sequences of character trigrams, as recently sug- gested by <ref type="bibr" target="#b26">Vania and Lopez (2017)</ref>.</p><p>Given a bi-RNN with a forward (f ) and back- ward (b) layer, the input representation w of a to- ken of t characters is computed from the hidden states h f t and h 0 b , i.e. the final outputs of the for- ward and backward RNNs, as follows:</p><formula xml:id="formula_1">w = W f h t f + W b h 0 b + b<label>(2)</label></formula><p>where W f and W b are weight matrices asso- ciated to each RNN and b is a bias vector ( <ref type="bibr" target="#b14">Ling et al., 2015a</ref>). These parameters are jointly learned together with the internal parameters of the GRUs and the input token embedding matrix while train- ing the NMT model. For an input of m tokens, our implementation increases the computational com- plexity of the network by O(Kt max m), where K is the bi-RNN cost and t max is the maximum num- ber of symbols per word. However, since compu- tation of each input representation is independent, a parallelised implementation could cut the over- head down to O(Kt max ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We test our approach along with statistical word segmentation based open vocabulary NMT meth- ods in an evaluation benchmark simulating a low- resource translation setting pairing English (En) with five languages from different language fam- ilies and morphological typologies: Arabic (Ar), Czech (Cs), German (De), Italian (It) and Turk- ish (TR). The characteristics of each language are given in <ref type="table">Table 1</ref>, whereas  The simple NMT model constitutes the baseline in our study and performs translation directly at the level of sub-word units, which can be of four different types: characters, character trigrams, BPE sub-word units, and LMVR sub-word units.</p><p>The compositional model, on the other hand, per- forms NMT with input representations composed from sub-lexical vocabulary units. In our study, we evaluate representations composed from char- acter trigrams, BPE, and LMVR units. In order to choose the segmentation method to apply on the English side (the output of NMT decoder), we compare BPE and LMVR sub-word units by car- rying out an evaluation on the official data sets of Morpho Challenge 2010 2 ( <ref type="bibr" target="#b12">Kurimo et al., 2010)</ref>. The results of this evaluation, as given in <ref type="table" target="#tab_3">Table  3</ref>, suggest that LMVR seems to provide a seg- mentation that is more consistent with morpheme boundaries, which motivates us to use sub-word tokens generated by LMVR for the target side. This choice aids us in evaluating the morpholog- ical knowledge contained in input representations in terms of the translation accuracy in NMT.</p><p>The compositional bi-RNN layer is imple- mented in <ref type="bibr" target="#b25">Theano (Team et al., 2016)</ref> and inte- grated into the Nematus NMT toolkit ( <ref type="bibr">Sennrich et al., 2017)</ref>. In our experiments, we use a compo- sitional bi-RNN with 256 hidden units, an NMT model with a one-layer bi-directional GRU en- coder and one-layer GRU decoder of 512 hidden units, and an embedding dimension of 256 for both models. We use a highly restricted dictio- nary size of 30,000 for both source and target lan- guages, and train the segmentation models (BPE and LMVR) to generate sub-word vocabularies of the same size. We train the NMT models using the <ref type="bibr">Adagrad (Duchi et al., 2011</ref>) optimizer with a mini-batch size of 50, a learning rate of 0.01, and a dropout rate of 0.1 (in all layers and embeddings). In order to prevent over-fitting, we stop training if the perplexity on the validation does not decrease for 5 epochs, and use the best model to translate the test set. The model outputs are evaluated using the (case-sensitive) BLEU ( <ref type="bibr" target="#b19">Papineni et al., 2002</ref>) metric and the <ref type="bibr">Multeval (Clark et al., 2011</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>The performance of NMT models in translating each language using different vocabulary units and encoder input representations can be seen in <ref type="table" target="#tab_5">Ta- ble 4</ref>. With the simple model, LMVR based units achieve the best accuracy in translating all lan- guages, with improvements over BPE by 0.85 to 1.09 BLEU points in languages with high morpho- logical complexity (Arabic, Czech and Turkish) and 0.32 to 0.53 BLEU points in languages with low to medium complexity (Italian and German). This confirms our previous results in <ref type="bibr" target="#b0">(Ataman and Federico, 2018)</ref>. Moreover, simple models using character trigrams as vocabulary units reach much higher translation accuracy compared to models using characters, indicating their superior perfor- mance in handling contextual ambiguity. In the Italian to English translation direction, the per- formance of simple models using character tri- grams and BPE sub-word units as input represen- tations are almost comparable, showing that char- acter trigrams can even be sufficient as the stand- alone vocabulary units in languages with low lex- ical sparseness. These findings suggest that each type of sub-word unit used in the simple model is specifically convenient for a given morphological typology. Using our compositional model improves the quality of input representations for each type of vocabulary unit, nevertheless, the best perfor- mance is obtained by using character trigrams as input symbols and words as input representa- tions. The higher quality of these input repre- sentations compared to those obtained from sub- word units generated with LMVR suggest that our compositional model can learn morphology better than LMVR, which was found to provide compa- rable performance to morphological analyzers in Turkish to English NMT ( <ref type="bibr" target="#b1">Ataman et al., 2017)</ref>. Moreover, sample outputs from both models show that the compositional model is also able to bet- ter capture syntactic information of input sen- tences. <ref type="figure">Figure 5</ref> illustrates two example transla- tions from Italian and Turkish. In Italian, the sim- ple model fails to understand the common sub- ject of different verbs in the sentence due to the repetition of the same inflective suffix after seg- mentation. In Turkish, the genitive case "yer- lerin foto˘ graflarının" (the photographs of places) and the complex predicate "birles¸tirilmesiylebirles¸tirilmesiyle mey- dana geldi" (is composed of ) are both incorrectly  Input e comunque, em@@ ig@@ riamo , circol@@ iamo e mescol@@ iamo cos`cos`ı tanto che <ref type="table">(Simple Model)</ref> non esistepì u l' isolamento necessario affinché avvenga un' evoluzione .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NMT Output</head><p>and anyway , we repair, and we mix so much that <ref type="table">(Simple Model)</ref> there 's no longer the isolation that we need to happen to make an evolution . Input e comunque, emigriamo, circoliamo e mescoliamo cos`cos`ı tanto che (Compositional Model) non esistepì u l' isolamento necessario affinché avvenga un' evoluzione.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NMT Output</head><p>and anyway , we migrate , circle and mix so much that</p><formula xml:id="formula_2">(Compositional Model)</formula><p>there 's no longer the isolation necessary to become evolutionary . Reference and by the way , we immigrate and circulate and intermix so much that you can 't any longer have the isolation that is necessary for evolution to take place .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input</head><p>ama aslında bu resim tamamen , farklı yerlerin foto˘ graf@@ larının <ref type="table">(Simple Model)</ref> birles¸tir@@birles¸tir@@ il@@ mesiyle meydana geldi . NMT Output but in fact , this picture came up with a completely (Simple Model) different place of photographs . Input ama aslında bu resim tamamen , farklı yerlerin foto˘ graflarının <ref type="table">(Compositional Model)</ref> birles¸tirilmesiylebirles¸tirilmesiyle meydana geldi . NMT Output but in fact , this picture came from collecting pictures of (Compositional Model) different places . Reference but this image is actually entirely composed of photographs from different locations . <ref type="table">Table 5</ref>: Example translations with different approaches in Italian (above) and Turkish (below).</p><p>translated by the simple model. On the other hand, the compositional model is able to cap- ture the correct sentence semantics and syntax in either case. These findings suggest that main- taining translation at the lexical level apparently aids the attention mechanism and provides more semantically and syntactically consistent transla- tions. The overall improvements obtained with this model over the best performing simple model are 1.99 BLEU points in Arabic, 2.32 BLEU points in Czech, 1.91 BLEU points in German, 2.48 BLEU points in Italian and 1.71 BLEU points in Turkish to English translation directions. As ev- ident from the significant and consistent improve- ments across all languages, our approach provides a more promising and generic solution to the data sparseness problem in NMT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we addressed the problem of trans- lating infrequent words in NMT and proposed to solve it by replacing the conventional sub-word embeddings with input representations composi- tionally learned from character n-grams using a bi- RNN. Our approach showed significant and con- sistent improvements over a variety of languages, making it a competitive solution for NMT of low- resource and morphologically-rich languages. In the future, we plan to optimize our implementa- tion and to test its scalability on larger data sets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 2 presents</head><label>2</label><figDesc>the sta- tistical properties of the training data. We train our NMT models using the TED Talks corpora (Cet- tolo et al., 2012) and test them on the official data sets of IWSLT 1 (Mauro et al., 2017).</figDesc><table>Language Morphological Morphological 
Typology 
Complexity 
Turkish 
Agglutinative 
High 
Arabic 
Templatic 
High 
Czech 
Fusional, 
High 
Agglutinative 
German 
Fusional 
Medium 
Italian 
Fusional 
Low 

Table 1: The languages evaluated in our study and 
their morphological characteristics. 

Language 
# tokens 
# types 
Pair 
Src 
Tgt 
Src 
Tgt 
Tr -En 
2,7M 2,0M 171K 53K 
Ar -En 
3,9M 4,9M 220K 120K 
Cs -En 
2,0M 2,3M 118K 50K 
De -En 
4,0M 4,3M 144K 69K 
It -En 
3,5M 3,8M 95K 
63K 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Sizes of the training sets and vocabularies 
in the TED Talks benchmark. Development and 
test sets are on average 50K to 100K tokens. (M: 
Million, K: Thousand.) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head></head><label></label><figDesc>) sig- nificance test.</figDesc><table>Method Precision Recall F 1 Score 
BPE 
52.87 
24.44 
33.43 
LMVR 
70.22 
55.66 
62.10 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc>The performance of different segmenta- tion models trained on the English portion of our benchmark in the Morpho Challenge shared task.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Experiment results. Best scores for each translation direction are in bold font. All improvements 
over the baseline (simple model with BPE) are statistically significant (p-value &lt; 0.05). 

</table></figure>

			<note place="foot" n="1"> The International Workshop on Spoken Language Translation with shared tasks organized between 2003-2017.</note>

			<note place="foot" n="2"> Shared Task on Unsupervised Morphological Analysis, http://morpho.aalto.fi/events/morphochallenge.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors would like to thank NVIDIA for their computational support that aided this research.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">An Evaluation of Two Vocabulary Reduction Methods for Neural Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duygu</forename><surname>Ataman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Conference of The Association for Machine Translation in the Americas</title>
		<meeting>the 13th Conference of The Association for Machine Translation in the Americas</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="97" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Linguistically Motivated Vocabulary Reduction for Neural Machine Translation from Turkish to English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duygu</forename><surname>Ataman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Turchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Prague Bulletin of Mathematical Linguistics</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="331" to="342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Neural Machine Translation by Jointly Learning to Align and Translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXivpreprintarXiv:1409.0473</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Large-Scale Machine Learning with Stochastic Gradient Descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 19th International Conference on Computational Statistics (COMPSTAT)</title>
		<meeting>19th International Conference on Computational Statistics (COMPSTAT)</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="177" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Wit3: Web Inventory of Transcribed and Translated Talks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mauro</forename><surname>Cettolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Girardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference of the European Association for Machine Translation (EAMT)</title>
		<meeting>the 16th Conference of the European Association for Machine Translation (EAMT)</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="261" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">On the properties of neural machine translation: Encoder-decoder approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 8th Workshop on Syntax, Semantics and Structure in Statistical Translation (SSST)</title>
		<meeting>8th Workshop on Syntax, Semantics and Structure in Statistical Translation (SSST)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="103" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Better Hypothesis Testing for Statistical Machine Translation: Controlling for Optimizer Instability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">H</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="176" to="181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Character-based neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Marta R Costa-Jussà</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>José</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fonollosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="357" to="361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Adaptive Subgradient Methods for Online Learning and Stochastic Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2121" to="2159" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A New Algorithm for Data Compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Gage</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The C Users Journal</title>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="23" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural computation</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1997" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Target-Side Word Segmentation Strategies for Neural Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Huck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Riess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Fraser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Conference on Machine Translation (WMT)</title>
		<meeting>the 2nd Conference on Machine Translation (WMT)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="56" to="67" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Morpho challenge competition 2005-2010: evaluations and results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikko</forename><surname>Kurimo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sami</forename><surname>Virpioja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ville</forename><surname>Turunen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krista</forename><surname>Lagus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th Meeting of the ACL Special Interest Group on Computational Morphology and Phonology</title>
		<meeting>the 11th Meeting of the ACL Special Interest Group on Computational Morphology and Phonology</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="87" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Fully character-Level Neural Machine Translation without Explicit Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions of the Association for Computational Linguistics (TACL)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="365" to="378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Finding function in form: Compositional character models for open vocabulary word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">W</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabel</forename><surname>Trancoso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramon</forename><surname>Fermandez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Amir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luis</forename><surname>Marujo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiago</forename><surname>Luis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1520" to="1530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Character-based Neural Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabel</forename><surname>Trancoso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">W</forename><surname>Black</surname></persName>
		</author>
		<idno type="arXiv">arXivpreprintarXiv:1511.04586</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1054" to="1063" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Overview of the iwslt 2017 evaluation campaign</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cettolo</forename><surname>Mauro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Marcello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bentivogli</forename><surname>Luisa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niehues</forename><surname>Jan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stüker</forename><surname>Sebastian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sudoh</forename><surname>Katsuitho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshino</forename><surname>Koichiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federmann</forename><surname>Christian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In International Workshop on Spoken Language Translation</title>
		<imprint>
			<biblScope unit="page" from="2" to="14" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Pre-translation for Neural Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Niehues</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunah</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thanh-Le</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Waibel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 26th International Conference on Computational Linguistics (COLING)</title>
		<meeting>The 26th International Conference on Computational Linguistics (COLING)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1828" to="1836" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">BLEU: a Method for Automatic Evaluation of Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 40th Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Neural Machine Translation for Morphologically Rich Languages with Improved Subword Units and Synthetic Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rihards</forename><surname>M¯ Arcis Pinnis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daiga</forename><surname>Krišlauks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toms</forename><surname>Deksne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Miks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Text, Speech, and Dialogue (TSD)</title>
		<meeting>the International Conference on Text, Speech, and Dialogue (TSD)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="237" to="245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Orhan</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<imprint>
			<pubPlace>Julian Hitschler, Marcin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Nematus: a toolkit for Neural Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Junczys-Dowmunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Läubli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Valerio Miceli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jozef</forename><surname>Barone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mokry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Annual Meeting of the European Chapter of the Association for Computational Linguistics (EACL)</title>
		<meeting>the 15th Annual Meeting of the European Chapter of the Association for Computational Linguistics (EACL)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="65" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Neural Machine Translation of Rare Words with Subword Units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1715" to="1725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Modeling Target-Side Inflection in Neural Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleš</forename><surname>Tamchyna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marion</forename><surname>Weller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Di</forename><surname>Marco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Fraser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Conference on Machine Translation (WMT)</title>
		<meeting>the 2nd Conference on Machine Translation (WMT)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="32" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Theano: A python framework for fast computation of mathematical expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rami</forename><surname>The Theano Development Team</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amjad</forename><surname>Alain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Almahairi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Angermueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frédéric</forename><surname>Ballas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Bastien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anatoly</forename><surname>Bayer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Belikov</surname></persName>
		</author>
		<idno type="arXiv">arXivpreprintarXiv:1605.02688</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">From characters to words to in between: Do we capture morphology?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clara</forename><surname>Vania</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lopez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2016" to="2027" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
