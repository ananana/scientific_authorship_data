<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:43+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Hybrid Approach to Skeleton-based Translation</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>June 23-25 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Xiao</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Northeastern University</orgName>
								<address>
									<postCode>110819</postCode>
									<settlement>Shenyang</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">China ‡ Hangzhou YaTuo Company</orgName>
								<address>
									<addrLine>358 Wener Rd</addrLine>
									<postCode>310012</postCode>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingbo</forename><surname>Zhu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Northeastern University</orgName>
								<address>
									<postCode>110819</postCode>
									<settlement>Shenyang</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">China ‡ Hangzhou YaTuo Company</orgName>
								<address>
									<addrLine>358 Wener Rd</addrLine>
									<postCode>310012</postCode>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunliang</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Northeastern University</orgName>
								<address>
									<postCode>110819</postCode>
									<settlement>Shenyang</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">China ‡ Hangzhou YaTuo Company</orgName>
								<address>
									<addrLine>358 Wener Rd</addrLine>
									<postCode>310012</postCode>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Hybrid Approach to Skeleton-based Translation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="563" to="568"/>
							<date type="published">June 23-25 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In this paper we explicitly consider sentence skeleton information for Machine Translation (MT). The basic idea is that we translate the key elements of the input sentence using a skeleton translation model , and then cover the remain segments using a full translation model. We apply our approach to a state-of-the-art phrase-based system and demonstrate very promising BLEU improvements and TER reductions on the NIST Chinese-English MT evaluation data.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Current Statistical Machine Translation (SMT) ap- proaches model the translation problem as a pro- cess of generating a derivation of atomic transla- tion units, assuming that every unit is drawn out of the same model. The simplest of these is the phrase-based approach <ref type="bibr" target="#b13">(Och et al., 1999;</ref><ref type="bibr" target="#b7">Koehn et al., 2003)</ref> which employs a global model to process any sub-strings of the input sentence. In this way, all we need is to increasingly translate a sequence of source words each time until the entire sentence is covered. Despite good result- s in many tasks, such a method ignores the roles of each source word and is somewhat differen- t from the way used by translators. For exam- ple, an important-first strategy is generally adopt- ed in human translation -we translate the key ele- ments/structures (or skeleton) of the sentence first, and then translate the remaining parts. This es- pecially makes sense for some languages, such as Chinese, where complex structures are usually in- volved.</p><p>Note that the source-language structural infor- mation has been intensively investigated in recent studies of syntactic translation models. Some of them developed syntax-based models on complete syntactic trees with Treebank annotations ( <ref type="bibr" target="#b8">Liu et al., 2006;</ref><ref type="bibr" target="#b5">Huang et al., 2006;</ref>, and others used source-language syntax as soft constraints <ref type="bibr" target="#b10">(Marton and Resnik, 2008;</ref><ref type="bibr" target="#b0">Chiang, 2010)</ref>. However, these approaches suffer from the same problem as the phrase-based counterpart and use the single global model to handle differ- ent translation units, no matter they are from the skeleton of the input tree/sentence or other not-so- important sub-structures.</p><p>In this paper we instead explicitly model the translation problem with sentence skeleton infor- mation. In particular,</p><p>• We develop a skeleton-based model which divides translation into two sub-models: a skeleton translation model (i.e., translating the key elements) and a full translation model (i.e., translating the remaining source words and generating the complete translation).</p><p>• We develop a skeletal language model to de- scribe the possibility of translation skeleton and handle some of the long-distance word dependencies.</p><p>• We apply the proposed model to Chinese- English phrase-based MT and demonstrate promising BLEU improvements and TER re- ductions on the NIST evaluation data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">A Skeleton-based Approach to MT</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Skeleton Identification</head><p>The first issue that arises is how to identify the skeleton for a given source sentence. Many ways are available. E.g., we can start with a full syntac- tic tree and transform it into a simpler form (e.g., removing a sub-tree). Here we choose a simple and straightforward method: a skeleton is obtained by dropping all unimportant words in the origi- nal sentence, while preserving the grammaticali- ty. See the following for an example skeleton of a Chinese sentence.</p><p>Original Sentence (subscripts represent indices):</p><formula xml:id="formula_0">z [1] per ë [2]</formula><p>ton °Yz <ref type="bibr">[3]</ref> seawater desalination ?n <ref type="bibr">[4]</ref> treatment <ref type="bibr">[5]</ref> of ¤ <ref type="bibr">[6]</ref> the cost 3 <ref type="bibr">[7]</ref> 5 <ref type="bibr">[8]</ref> 5 <ref type="bibr">[9]</ref> yuan <ref type="bibr">[10]</ref> of Ä: <ref type="bibr">[11]</ref> from þ <ref type="bibr">[12]</ref> ?˜Ú <ref type="bibr">[13]</ref> has been further eü <ref type="bibr">[14]</ref> reduced " <ref type="bibr">[15]</ref> . (The cost of seawater desalination treatment has been further reduced from 5 yuan per ton.)</p><p>Sentence Skeleton (subscripts represent indices):</p><formula xml:id="formula_1">¤ [6] the cost</formula><p>?˜Ú <ref type="bibr">[13]</ref> has been further eü <ref type="bibr">[14]</ref> reduced " <ref type="bibr">[15]</ref> . (The cost has been further reduced.)</p><p>Obviously the skeleton used in this work can be viewed as a simplified sentence. Thus the prob- lem is in principle the same as sentence simpli- fication/compression. The motivations of defin- ing the problem in this way are two-fold. First, as the skeleton is a well-formed (but simple) sen- tence, all current MT approaches are applicable to the skeleton translation problem. Second, ob- taining simplified sentences by word deletion is a well-studied issue <ref type="bibr" target="#b6">(Knight and Marcu, 2000;</ref><ref type="bibr" target="#b1">Clarke and Lapata, 2006;</ref><ref type="bibr" target="#b4">Galley and McKeown, 2007;</ref><ref type="bibr" target="#b2">Cohn and Lapata, 2008;</ref><ref type="bibr" target="#b19">Yamangil and Shieber, 2010;</ref><ref type="bibr" target="#b20">Yoshikawa et al., 2012</ref>). Many good sentence simpliciation/compression methods are available to our work. Due to the lack of space, we do not go deep into this problem. In Section 3.1 we describe the corpus and system employed for automatic generation of sentence skeletons.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Base Model</head><p>Next we describe our approach to integrating skeleton information into MT models. We start with an assumption that the 1-best skeleton is pro- vided by the skeleton identification system. Then we define skeleton-based translation as a task of searching for the best target stringˆtstringˆ stringˆt given the source string and its skeleton τ :</p><formula xml:id="formula_2">ˆ t = arg max t P(t|τ, s)<label>(1)</label></formula><p>As is standard in SMT, we further assume that 1) the translation process can be decomposed in- to a derivation of phrase-pairs (for phrase-based models) or translation rules (for syntax-based models); 2) and a linear function g(·) is used to assign a model score to each derivation. Let d s,τ,t (or d for short) denote a translation derivation. The above problem can be redefined in a Viterbi fash- ion -we find the derivationˆdderivationˆ derivationˆd with the highest mod- el score given s and τ :</p><formula xml:id="formula_3">ˆ d = arg max d g(d)<label>(2)</label></formula><p>In this way, the MT output can be regarded as the target-string encoded inˆdinˆ inˆd.</p><p>To compute g(d), we use a linear combination of a skeleton translation model g skel (d) and a full translation model g f ull (d):</p><formula xml:id="formula_4">g(d) = g skel (d) + g f ull (d)<label>(3)</label></formula><p>where the skeleton translation model handles the translation of the sentence skeleton, while the full translation model is the baseline model and han- dles the original problem of translating the whole sentence. The motivation here is straightforward: we use an additional score g skel (d) to model the problem of skeleton translation and interpolate it with the baseline model. See <ref type="figure" target="#fig_3">Figure 1</ref> for an exam- ple of applying the above model to phrase-based MT. In the figure, each source phrase is translated into a target phrase, which is represented by linked rectangles. The skeleton translation model focus- es on the translation of the sentence skeleton, i.e., the solid (red) rectangles; while the full transla- tion model computes the model score for all those phrase-pairs, i.e., all solid and dashed rectangles.</p><p>Another note on the model. Eq. (3) provides a very flexible way for model selection. While we will restrict ourself to phrase-based translation in the following description and experiments, we can choose different models/features for g skel (d) and g f ull (d). E.g., one may introduce syntactic fea- tures into g skel (d) due to their good ability in cap- turing structural information; and employ a stan- dard phrase-based model for g f ull (d) in which not all segments of the sentence need to respect syn- tactic constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Model Score Computation</head><p>In this work both the skeleton translation model g skel (d) and full translation model g f ull (d) resem- ble the usual forms used in phrase-based MT, i.e., the model score is computed by a linear combina- tion of a group of phrase-based features and lan- guage models. In phrase-based MT, the transla- tion problem is modeled by a derivation of phrase- pairs. Given a translation model m, a language model lm and a vector of feature weights w, the model score of a derivation d is computed by zë °Yz ?n ¤ 3 5 Ä: þ ?˜Ú eü " Skeleton:</p><p>Full:</p><formula xml:id="formula_5">g(dτ ; w τ , m, lm τ ) = w τ m · fm(p1) + w τ lm · lm τ ("the cost") g(d; w, m, lm) = wm · fm(p1) + w lm · lm("the cost")</formula><p>zë °Yz ?n ¤ 3 5 Ä: þ ?˜Ú eü " the cost of seawater desalination treatment phrases 2 &amp; 3 p1 p2 p3</p><p>Skeleton:</p><p>Full: Skeleton:</p><formula xml:id="formula_6">g(dτ ; w τ , m, lm τ ) = w τ m · fm(p1) + w τ lm · lm τ ("the cost X") g(d; w, m, lm) = wm · fm(p1 • p2 • p3) + w lm · lm("</formula><p>Full: Skeleton:</p><formula xml:id="formula_7">g(dτ ; w τ , m, lm τ ) = w τ m · fm(p1 • p4 • p5)+ w τ lm · lm τ ("</formula><p>Full: To ease modeling, we only consider skeleton- consistent derivations in this work. A deriva- tion d is skeleton-consistent if no phrases in d cross skeleton boundaries (e.g., a phrase where t- wo of the source words are in the skeleton and one is outside). Obviously, from any skeleton- consistent derivation d we can extract a skeleton derivation d τ which covers the sentence skeleton exactly. For example, in <ref type="figure" target="#fig_3">Figure 1</ref>, the deriva- tion of phrase-pairs {p 1 , p 2 , ..., p 9 } is skeleton- consistent, and the skeleton derivation is formed by {p 1 , p 4 , p 5 , p 9 }.</p><formula xml:id="formula_8">g(dτ ; w τ , m, lm τ ) = w τ m · fm(p1 • p4 • p5 • p9)+ w τ lm · lm τ ("</formula><p>Then, we can simply define g skel (d) and g f ull (d) as the model scores of d τ and d:</p><formula xml:id="formula_9">g skel (d) g(d τ ; w τ , m, lm τ ) (5) g f ull (d) g(d; w, m, lm)<label>(6)</label></formula><p>This model makes the skeleton translation and full translation much simpler because they per- form in the same way of string translation in phrase-based MT. Both g skel (d) and g f ull (d) share the same translation model m which can easily learned from the bilingual data <ref type="bibr">1</ref> . On the other hand, it has different feature weight vectors for in- dividual models (i.e., w and w τ ).</p><p>For language modeling, lm is the standard n- gram language model adopted in the baseline sys- tem. lm τ is a skeletal language for estimating the well-formedness of the translation skeleton. Here a translation skeleton is a target string where all segments of non-skeleton translation are general- ized to a symbol X. E.g., in <ref type="figure" target="#fig_3">Figure 1</ref>, the trans-lation skeleton is 'the cost X has been further re- duced X .', where two Xs represent non-skeleton segments in the translation. In such a way of string representation, the skeletal language model can be implemented as a standard n-gram language mod- el, that is, a string probability is calculated by a product of a sequence of n-gram probabilities (in- volving normal words and X). To learn the skele- tal language model, we replace non-skeleton parts of the target sentences in the bilingual corpus to Xs using the source sentence skeletons and word alignments. The skeletal language model is then trained on these generalized strings in a standard way of n-gram language modeling.</p><p>By substituting Eq. <ref type="formula">(4)</ref> into Eqs. <ref type="formula">(5)</ref> and <ref type="formula" target="#formula_9">(6)</ref>, and then Eqs. <ref type="formula" target="#formula_4">(3)</ref> and <ref type="formula" target="#formula_3">(2)</ref>, we have the final model used in this work: <ref type="figure" target="#fig_3">Figure 1</ref> shows the translation process and as- sociated model scores for the example sentence. Note that this method does not require any new translation models for implementation. Given a baseline phrase-based system, all we need is to learn the feature weights w and w τ on the devel- opment set (with source-language skeleton anno- tation) and the skeletal language model lm τ on the target-language side of the bilingual corpus. To implement Eq. <ref type="formula" target="#formula_10">(7)</ref>, we can perform standard decoding while "doubly weighting" the phrases which cover a skeletal section of the sentence, and combining the two language models and the trans- lation model in a linear fashion.</p><formula xml:id="formula_10">ˆ d = arg max d w m · f m (d) + w lm · lm(d) + w τ m · f m (d τ ) + w τ lm · lm τ (d τ )<label>(7)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental Setup</head><p>We experimented with our approach on Chinese- English translation using the NiuTrans open- source MT toolkit ( <ref type="bibr" target="#b18">Xiao et al., 2012</ref>). Our bilin- gual corpus consists of 2.7M sentence pairs. Al- l these sentences were aligned in word level us- ing the GIZA++ system and the "grow-diag-final- and" heuristics. A 5-gram language model was trained on the Xinhua portion of the English Gi- gaword corpus in addition to the target-side of the bilingual data. This language model was used in both the baseline and our improved system- s. For our skeletal language model, we trained a 5-gram language model on the target-side of the bilingual data by generalizing non-skeleton seg- ments to Xs. We used the newswire portion of the NIST MT06 evaluation data as our developmen- t set, and used the evaluation data of MT04 and MT05 as our test sets. We chose the default fea- ture set of the NiuTrans.Phrase engine for building the baseline, including phrase translation proba- bilities, lexical weights, a 5-gram language mod- el, word and phrase bonuses, a ME-based lexical- ized reordering model. All feature weights were learned using minimum error rate training <ref type="bibr" target="#b14">(Och, 2003)</ref>.</p><p>Our skeleton identification system was built using the t3 toolkit 2 which implements a state- of-the-art sentence simplification system. We used the NEU Chinese sentence simplification (NEUCSS) corpus as our training data ( <ref type="bibr" target="#b22">Zhang et al., 2013)</ref>. It contains the annotation of sen- tence skeleton on the Chinese-language side of the Penn Parallel Chinese-English Treebank (LD- C2003E07). We trained our system using the Parts 1-8 of the NEUCSS corpus and obtained a 65.2% relational F1 score and 63.1% compression rate in held-out test (Part 10). For comparison, we also manually annotated the MT development and test data with skeleton information according to the annotation standard provided within NEUCSS. <ref type="table">Table 1</ref> shows the case-insensitive IBM-version BLEU and TER scores of different systems. We see, first of all, that the MT system benefits from our approach in most cases. In both the manual and automatic identification of sentence skeleton (rows 2 and 4), there is a significant improvemen- t on the "All" data set. However, using different skeleton identification results for training and in- ference (row 3) does not show big improvements due to the data inconsistency problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results</head><p>Another interesting question is whether the skeletal language model really contributes to the improvements. To investigate it, we removed the skeletal language model from our skeleton-based translation system (with automatic skeleton iden- tification on both the development and test sets). Seen from row −lm τ of <ref type="table">Table 1</ref>, the removal of the skeletal language model results in a significan- t drop in both BLEU and TER performance. It indicates that this language model is very benefi- cial to our system. For comparison, we removed Entry MT06 (Dev) MT04 <ref type="table">MT05  All  system  dev-skel test-skel BLEU TER BLEU TER BLEU TER BLEU TER  baseline - -</ref>  . SBMT means our skeleton-based MT system. −lm τ (or −m τ ) means that we remove the skeletal language model (or translation model) from our proposed approach. s-space means that we restrict the baseline system to the search space of skeleton-consistent derivations. s-feat. means that we introduce an indicator feature for skeleton-consistent derivations into the baseline system.</p><p>the skeleton-based translation model from our sys- tem as well. Row −m τ of <ref type="table">Table 1</ref> shows that the skeleton-based translation model can contribute to the overall improvement but there is no big differ- ences between baseline and −m τ . Apart from showing the effects of the skeleton- based model, we also studied the behavior of the MT system under the different settings of search space. Row s-space of <ref type="table">Table 1</ref> shows the BLEU and TER results of restricting the baseline sys- tem to the space of skeleton-consistent derivation- s, i.e., we remove both the skeleton-based trans- lation model and language model from the SBMT system. We see that the limited search space is a little harmful to the baseline system. Further, we regarded skeleton-consistent derivations as an in- dicator feature and introduced it into the baseline system. Seen from row s-feat., this feature does not show promising improvements. These results indicate that the real improvements are due to the skeleton-based model/features used in this work, rather than the "well-formed" derivations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related Work</head><p>Skeleton is a concept that has been used in several sub-areas in MT for years. For example, in confu- sion network-based system combination it refer- s to the backbone hypothesis for building confu- sion networks ( <ref type="bibr" target="#b16">Rosti et al., 2007;</ref><ref type="bibr" target="#b17">Rosti et al., 2008)</ref>; <ref type="bibr" target="#b9">Liu et al. (2011)</ref> regard skeleton as a short- ened sentence after removing some of the function words for better word deletion. In contrast, we de- fine sentence skeleton as the key segments of a sentence and develop a new MT approach based on this information.</p><p>There are some previous studies on the use of sentence skeleton or related information in MT ( <ref type="bibr">Mellebeek et al., 2006a;</ref><ref type="bibr">Mellebeek et al., 2006b;</ref>). In spite of their good ideas of using skeleton skeleton information, they did not model the skeleton-based translation prob- lem in modern SMT pipelines. Our work is a fur- ther step towards the use of sentence skeleton in MT. More importantly, we develop a complete ap- proach to this issue and show its effectiveness in a state-of-the-art MT system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>We have presented a simple but effective approach to integrating the sentence skeleton information into a phrase-based system. The experimental re- sults show that the proposed approach achieves very promising BLEU improvements and TER re- ductions on the NIST evaluation data. In our fu- ture work we plan to investigate methods of inte- grating both syntactic models (for skeleton trans- lation) and phrasal models (for full translation) in our system. We also plan to study sophisticated reordering models for skeleton translation, rather than reusing the baseline reordering model which is learned on the full sentences.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>the cost of seawater desalination treatment") zë °Yz ?n ¤ 3 5 Ä: þ ?˜Ú eü " the cost of seawater desalination treatment has been further reduced phrases 4 &amp; 5 p1 p2 p3 p4 p5</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>the cost X has been further reduced") g(d; w, m, lm) = wm · fm(p1 • p2 • ... • p5) + w lm · lm("the cost of seawater ... further reduced") zë °Yz ?n ¤ 3 5 Ä: þ ?˜Ú eü " the cost of seawater desalination treatment has been further reduced from 5 yuan per ton .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example derivation and model scores for a sentence in LDC2006E38. The solid (red) rectangles represent the sentence skeleton, and the dashed (blue) rectangles represent the non-skeleton segments. X represents a slot in the translation skeleton. • represents composition of phrase-pairs.</figDesc></figure>

			<note place="foot" n="1"> In g skel (d), we compute the reordering model score on the skeleton though it is learned from the full sentences. In this way the reordering problems in skeleton translation and full translation are distinguished and handled separately.</note>

			<note place="foot" n="2"> http://staffwww.dcs.shef.ac.uk/people/T.Cohn/t3/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was supported in part by the Nation-al Science Foundation of China (Grants 61272376 and 61300097), and the China Postdoctoral Sci-ence Foundation (Grant 2013M530131). The au-thors would like to thank the anonymous reviewers for their pertinent and insightful comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning to Translate with Source and Target Syntax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL 2010</title>
		<meeting>of ACL 2010</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1443" to="1452" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Models for Sentence Compression: A Comparison across Domains, Training Requirements and Evaluation Measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL/COLING 2006</title>
		<meeting>of ACL/COLING 2006</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="377" to="384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Sentence Compression Beyond Word Deletion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of COLING</title>
		<meeting>of COLING</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="137" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning Non-Isomorphic Tree Mappings for Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL 2003</title>
		<meeting>of ACL 2003</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="205" to="208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Lexicalized Markov Grammars for Sentence Compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><surname>Mckeown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of HLT:NAACL 2007</title>
		<meeting>of HLT:NAACL 2007</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="180" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Statistical syntax-directed translation with extended domain of locality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of AMTA</title>
		<meeting>of AMTA</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="66" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Statisticalbased summarization-step one: sentence compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of AAAI</title>
		<meeting>of AAAI</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="703" to="710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Statistical Phrase-Based Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz</forename><forename type="middle">J</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL 2003</title>
		<meeting>of NAACL 2003</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="48" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Tree-toString Alignment Template for Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shouxun</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL/COLING 2006</title>
		<meeting>of ACL/COLING 2006</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="609" to="616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Statistic Machine Translation Boosted with Spurious Word Deletion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shujie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Ho</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Machine Translation Summit XIII</title>
		<meeting>of Machine Translation Summit XIII</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="72" to="79" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Soft Syntactic Constraints for Hierarchical Phrased-Based Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuval</forename><surname>Marton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL:HLT 2008</title>
		<meeting>of ACL:HLT 2008</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1003" to="1011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Multi-Engine Machine Translation by Recursive Sentence Decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Mellebeek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karolina</forename><surname>Owczarzak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Van Genabith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Way</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of AMTA</title>
		<meeting>of AMTA</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="110" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A Syntactic Skeleton for Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Mellebeek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karolina</forename><surname>Owczarzak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Declan</forename><surname>Groves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Van Genabith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Way</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EAMT</title>
		<meeting>of EAMT</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="195" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Improved Alignment Models for Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz</forename><forename type="middle">J</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Tillmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP/VLC 1999</title>
		<meeting>of EMNLP/VLC 1999</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="20" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Minimum error rate training in statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz</forename><forename type="middle">J</forename><surname>Och</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL 2003</title>
		<meeting>of ACL 2003</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="160" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Wrapper Syntax for Example-Based Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karolina</forename><surname>Owczarzak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Mellebeek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Declan</forename><surname>Groves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Van Genabith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Way</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of AMTA2006</title>
		<meeting>of AMTA2006</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="148" to="155" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Improved Word-Level System Combination for Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Antti-Veikko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyros</forename><surname>Rosti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Matsoukas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="312" to="319" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Incremental hypothesis alignment for building confusion networks with application to machine translation system combination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Antti-Veikko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Rosti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyros</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Matsoukas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Third Workshop on Statistical Machine Translation</title>
		<meeting>of Third Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="183" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">NiuTrans: An Open Source Toolkit for Phrase-based and Syntax-based Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingbo</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL 2012, system demonstrations</title>
		<meeting>of ACL 2012, system demonstrations</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="19" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Bayesian Synchronous Tree-Substitution Grammar Induction and Its Application to Sentence Compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elif</forename><surname>Yamangil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stuart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shieber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL 2010</title>
		<meeting>of ACL 2010</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="937" to="947" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Sentence Compression with Semantic Role Constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katsumasa</forename><surname>Yoshikawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryu</forename><surname>Iida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsutomu</forename><surname>Hirao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manabu</forename><surname>Okumura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL 2012</title>
		<meeting>of ACL 2012</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="349" to="353" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A Tree Sequence Alignment-based Tree-to-Tree Translation Model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongfei</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aiti</forename><surname>Aw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haizhou</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chew</forename><surname>Lim Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL:HLT 2008</title>
		<meeting>of ACL:HLT 2008</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="559" to="567" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Chinese Sentence Compression: Corpus and Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunliang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghan</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lixin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingbo</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Chinese Computational Linguistics and Natural Language Processing Based on Naturally Annotated Big Data</title>
		<meeting>of Chinese Computational Linguistics and Natural Language essing Based on Naturally Annotated Big Data</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="257" to="267" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
