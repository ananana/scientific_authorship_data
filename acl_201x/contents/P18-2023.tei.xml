<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:57+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Analogical Reasoning on Chinese Morphological and Semantic Relations</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 15-20, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shen</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Chinese Information Processing</orgName>
								<orgName type="institution">Beijing Normal University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">UltraPower-BNU Joint Laboratory for Artificial Intelligence</orgName>
								<orgName type="institution">Beijing Normal University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Zhao</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Information</orgName>
								<orgName type="institution">Renmin University of China</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renfen</forename><surname>Hu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Chinese Information Processing</orgName>
								<orgName type="institution">Beijing Normal University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">UltraPower-BNU Joint Laboratory for Artificial Intelligence</orgName>
								<orgName type="institution">Beijing Normal University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wensi</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Chinese Information Processing</orgName>
								<orgName type="institution">Beijing Normal University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">UltraPower-BNU Joint Laboratory for Artificial Intelligence</orgName>
								<orgName type="institution">Beijing Normal University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Liu</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Information</orgName>
								<orgName type="institution">Renmin University of China</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">♣</forename><forename type="middle">Xiaoyong</forename><surname>Du</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Information</orgName>
								<orgName type="institution">Renmin University of China</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Analogical Reasoning on Chinese Morphological and Semantic Relations</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="138" to="143"/>
							<date type="published">July 15-20, 2018</date>
						</imprint>
					</monogr>
					<note>138</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Analogical reasoning is effective in capturing linguistic regularities. This paper proposes an analogical reasoning task on Chinese. After delving into Chinese lexical knowledge, we sketch 68 implicit morphological relations and 28 explicit semantic relations. A big and balanced dataset CA8 is then built for this task, including 17813 questions. Furthermore, we systematically explore the influences of vector representations, context features, and corpora on analogical reasoning. With the experiments, CA8 is proved to be a reliable benchmark for evaluating Chinese word embeddings.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recently, the boom of word embedding draws our attention to analogical reasoning on linguistic reg- ularities. Given the word representations, anal- ogy questions can be automatically solved via vec- tor computation, e.g. "apples -apple + car ≈ cars" for morphological regularities and "king - man + woman ≈ queen" for semantic regularities <ref type="bibr" target="#b10">(Mikolov et al., 2013)</ref>. Analogical reasoning has become a reliable evaluation method for word em- beddings. In addition, It can be used in inducing morphological transformations <ref type="bibr" target="#b12">(Soricut and Och, 2015)</ref>, detecting semantic relations <ref type="bibr" target="#b4">(Herdagdelen and Baroni, 2009)</ref>, and translating unknown words <ref type="bibr" target="#b5">(Langlais and Patry, 2007)</ref>.</p><p>It is well known that linguistic regularities vary a lot among different languages. For example, Chinese is a typical analytic language which lacks inflection. <ref type="figure" target="#fig_0">Figure 1</ref> shows that function words and reduplication are used to denote grammatical and semantic information. In addition, many semantic † Corresponding author. relations are closely related with social and cul- tural factors, e.g. in Chinese "sh¯ ı-xi¯ an" (god of poetry) refers to the poet Li-bai and "sh¯ ı-shèng" (saint of poetry) refers to the poet Du-fu.</p><p>However, few attempts have been made in Chinese analogical reasoning. The only Chi- nese analogy dataset is translated from part of an English dataset ( <ref type="bibr" target="#b1">Chen et al., 2015</ref>) (denote as CA_translated). Although it has been widely used in evaluation of word embeddings <ref type="bibr" target="#b15">(Yang and Sun, 2015;</ref><ref type="bibr" target="#b16">Yin et al., 2016;</ref><ref type="bibr" target="#b13">Su and Lee, 2017)</ref>, it could not serve as a reliable benchmark since it includes only 134 unique Chinese words in three semantic relations (capital, state, and family), and morpho- logical knowledge is not even considered.</p><p>Therefore, we would like to investigate linguis- tic regularities beneath Chinese. By modeling them as an analogical reasoning task, we could further examine the effects of vector offset meth- ods in detecting Chinese morphological and se- mantic relations. As far as we know, this is the first study focusing on Chinese analogical reasoning. Moreover, we release a standard benchmark for evaluation of Chinese word embedding, together with 36 open-source pre-trained embeddings at GitHub 1 , which could serve as a solid basis for Chinese NLP tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Morphological Relations</head><p>Morphology concerns the internal structure of words. There is a common belief that Chinese is a morphologically impoverished language since a morpheme mostly corresponds to an orthographic character, and it lacks apparent distinctions be- tween roots and affixes. However, <ref type="bibr" target="#b11">Packard (2000)</ref> suggests that Chinese has a different morpholog- ical system because it selects different "settings" on parameters shared by all languages. We will clarify this special system by mapping its morpho- logical analogies into two processes: reduplication and semi-affixation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Reduplication</head><p>Reduplication means a morpheme is repeated to form a new word, which is semantically and/or syntactically distinct from the original morpheme, e.g. the word "ti¯ an-ti¯ an"(day day) in <ref type="figure" target="#fig_0">Figure 1</ref>(b) means "everyday". By analyzing all the word cat- egories in Chinese, we find that nouns, verbs, ad- jectives, adverbs, and measure words have redupli- cation abilities. Given distinct morphemes A and B, we summarize 6 repetition patterns in <ref type="figure" target="#fig_1">Figure 2</ref>. Each pattern may have one or more morpho- logical functions. Taking Pattern 1 (A→AA) as an example, noun morphemes could form kinship terms or yield every/each meaning. For verbs, it signals doing something a little bit or things hap- pen briefly. AA reduplication could also intensify an adjective or transform it to an adverb.</p><p>• bà(dad) → bà-bà(dad)</p><p>• ti¯ an(day) → ti¯ an-ti¯ an(everyday)</p><p>• shu¯ o(say) → shu¯ o-shuo(say a little)</p><p>• kàn(look) → kàn-kàn(have a brief look)</p><p>• dà(big) → dà-dà(very big; greatly)</p><p>• sh¯ en(deep) → sh¯ en-sh¯ en(deeply) 1 https://github.com/Embedding/Chinese-Word-Vectors</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Semi-affixation</head><p>Affixation is a morphological process whereby a bound morpheme (an affix) is attached to roots or stems to form new language units. Chinese is a typical isolating language that has few affixes. <ref type="bibr" target="#b9">Liu et al. (2001)</ref> points out that although affixes are rare in Chinese, there are some components be- having like affixes and can also be used as inde- pendent lexemes. They are called semi-affixes.</p><p>To model the semi-affixation process, we un- cover 21 semi-prefixes and 41 semi-suffixes. These semi-suffixes can be used to denote changes of meaning or part of speech. For example, the semi-prefix "dì-" could be added to numerals to form ordinal numbers, and the semi-suffix "-zi" is able to nominalize an adjective:</p><formula xml:id="formula_0">• y¯ ı(one) → dì-y¯ ı(first) èr(two) → dì-èr(second) • pàng(fat) → pàng-zi(a fat man) shòu(thin) → shòu-zi(a thin man)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Semantic Relations</head><p>To investigate semantic knowledge reasoning, we present 28 semantic relations in four aspects: ge- ography, history, nature, and people. Among them we inherit a few relations from English datasets, e.g. country-capital and family members, while the rest of them are proposed originally on the ba- sis of our observation of Chinese lexical knowl- edge. For example, a Chinese province may have its own abbreviation, capital city, and representa- tive drama, which could form rich semantic analo- gies:</p><p>• ¯ an-hu¯ ı vs zhè-ji¯ ang (province) • wˇanwˇan vs zhè (abbreviation)</p><p>• hé-féi vs háng-zh¯ ou (capital)</p><p>• huáng-méi-xì vs yuè-jù (drama)</p><p>We also address novel relations that could be used for other languages, e.g. scientists and their findings, companies and their founders.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Task of Chinese Analogical Reasoning</head><p>Analogical reasoning task is to retrieve the answer of the question "a is to b as c is to ?". Based on the relations discussed above, we firstly collect word pairs for each relation. Since there are no explicit word boundaries in Chinese, we take dic- tionaries and word segmentation specifications as references to confirm the inclusion of each word   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>In Chinese analogical reasoning task, we aim at in- vestigating to what extent word vectors capture the linguistic relations, and how it is affected by three important factors: vector representations (sparse and dense), context features (character, word, and ngram), and training corpora (size and domain). <ref type="table" target="#tab_2">Table 2</ref> shows the hyper-parameters used in this work. All the text data used in our experiments (as shown in <ref type="table" target="#tab_4">Table 3</ref>) are preprocessed via the follow- ing steps:</p><p>• Remove the html and xml tags from the texts and set the encoding as utf-8. Digits and punctuations are remained.</p><p>• Convert traditional Chinese characters into simplified characters with Open Chinese Convert (OpenCC) 2 .</p><p>• Conduct Chinese word segmentation with HanLP(v_1.5.3) 3 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Vector Representations</head><p>Existing vector representations fall into two types, dense vectors and sparse vectors. SGNS (skip- gram model with negative sampling) ( <ref type="bibr" target="#b10">Mikolov et al., 2013)</ref> and PPMI (Positive Pointwise Mutual Information) ( <ref type="bibr" target="#b6">Levy and Goldberg, 2014a</ref>) are re- spectively typical methods for learning dense and sparse word vectors. <ref type="table" target="#tab_5">Table 4</ref> lists the performance of them on CA_translated and CA8 datasets under different configurations. We can observe that on CA8 dataset, SGNS representations perform better in analogical rea- soning of morphological relations and PPMI rep- resentations show great advantages in semantic relations. This result is consistent with per- formance of English dense and sparse vectors on MSR (morphology-only), SemEval (semantic- only), and Google (mixed) analogy datasets ( <ref type="bibr" target="#b7">Levy and Goldberg, 2014b;</ref><ref type="bibr" target="#b8">Levy et al., 2015</ref>   probably because the reasoning on morphological relations relies more on common words in con- text, and the training procedure of SGNS favors frequent word pairs. Meanwhile, PPMI model is more sensitive to infrequent and specific word pairs, which are beneficial to semantic relations.</p><p>The above observation shows that CA8 is a re- liable benchmark for studying the effects of dense and sparse vectors. Compared with CA_translated and existing English analogy datasets, it offers both morphological and semantic questions which are also balanced across different types 4 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Context Features</head><p>To investigate the influence of context features on analogical reasoning, we consider not only word features, but also ngram features inspired by sta- tistical language models, and character (Hanzi) features based on the close relationship between Chinese words and their composing characters <ref type="bibr">5</ref> . Specifically, we use word bigrams for ngram fea- tures, character unigrams and bigrams for charac- ter features.</p><p>Ngrams and Chinese characters are effective features in training word representations ( <ref type="bibr" target="#b17">Zhao et al., 2017;</ref><ref type="bibr" target="#b1">Chen et al., 2015;</ref><ref type="bibr" target="#b0">Bojanowski et al., 2016)</ref>. However, <ref type="table" target="#tab_5">Table 4</ref> shows that there is only a slight increase on CA_translated dataset with ngram features, and the accuracies in most cases decrease after integrating character features. In contrast, on CA8 dataset, the introduction of ngram and character features brings significant and consistent improvements on almost all the cat- egories. Furthermore, character features are espe- cially advantageous for reasoning of morphologi- cal relations. SGNS model integrating with char- acter features even doubles the accuracy in mor- phological questions.</p><p>Besides, the representations achieve surpris- ingly high accuracies in some categories of CA_translated, which means that there is little room for further improvement. However it is much harder for representation methods to achieve high accuracies on CA8. The best configuration only achieves 68.0%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Corpora</head><p>We compare word representations learned upon corpora of different sizes and domains. As shown in  bination" which is built by combining the first five corpora together. <ref type="table" target="#tab_7">Table 5</ref> shows that accuracies increase with the growth in corpus size, e.g. Baidubaike (an online Chinese encyclopedia) has a clear advantage over Wikipedia. Also, the domain of a corpus plays an important role in the experiments. We can ob- serve that vectors trained on news data are benefi- cial to geography relations, especially on People's Daily which has a focus on political news. An- other example is Zhihu QA, an online question- answering corpus which contains more informal data than others. It is helpful to reduplication rela- tions since many reduplication words appear fre- quently in spoken language. With the largest size and varied domains, "Combination" corpus per- forms much better than others in both morpholog- ical and semantic relations.</p><p>Based on the above experiments, we find that vector representations, context features, and cor- pora all have important influences on Chinese ana- logical reasoning. Also, CA8 is proved to be a re- liable benchmark for evaluation of Chinese word embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we investigate the linguistic regular- ities beneath Chinese, and propose a Chinese ana- logical reasoning task based on 68 morphological relations and 28 semantic relations. In the experi- ments, we apply vector offset method to this task, and examine the effects of vector representations, context features, and corpora. This study offers an interesting perspective combining linguistic anal- ysis and representation models. The benchmark and embedding sets we release could also serve as a solid basis for Chinese NLP tasks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Examples of Chinese lexical knowledge: (a) function words (in orange boxes) are used to indicate the comparative and superlative degrees; (b) reduplication yields the meaning of "every".</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Reduplication patterns of A and A-B.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Comparisons of CA_translated and CA8 benchmarks. More details about the relations in CA8 
can be seen in GitHub. 

Window 
(dynamic) 
Iteration Dimension 
Sub-
sampling 

Low-frequency 
threshold 

Context distribution 
smoothing 

Negative 
(SGNS/PPMI) 

Vector 
offset 
5 
5 
300 
1e-5 
50 
0.75 
5/1 
3COSMUL 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Hyper-parameter details. Levy and Goldberg (2014b) unifies SGNS and PPMI in a framework, 
which share the same hyper-parameter settings. We exploit 3COSMUL to solve the analogical questions 
suggested by Levy and Goldberg (2014a). 

pair. To avoid the imbalance problem addressed in 
English benchmarks (Gladkova et al., 2016), we 
set a limit of 50 word pairs at most for each rela-
tion. In this step, 1852 unique Chinese word pairs 
are retrieved. We then build CA8, a big, balanced 
dataset for Chinese analogical reasoning including 
17813 questions. Compared with CA_translated 
(Chen et al., 2015), CA8 incorporates both mor-
phological and semantic questions, and it brings 
in much more words, relation types and questions. 
Table 1 shows details of the two datasets. They are 
both used for evaluation in Experiments section. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>). It is</head><label></label><figDesc></figDesc><table>Corpus 
Size 
#tokens 
|V | 
Description 

Wikipedia 
1.3G 
223M 
2129K 
Wikipedia data obtained from 
https://dumps.wikimedia.org/ 

Baidubaike 
4.1G 
745M 
5422K 
Chinese wikipedia data from 
https://baike.baidu.com/ 

People's Daily News 
3.9G 
668M 
1664K 
News data from People's Daily (1946-2017) 
http://data.people.com.cn/ 

Sogou news 
3.7G 
649M 
1226K 
News data provided by Sogou Labs 
http://www.sogou.com/labs/ 

Zhihu QA 
2.1G 
384M 
1117K 
Chinese QA data from https://www.zhihu.com/, 
including 32137 questions and 3239114 answers 
Combination 
14.8G 2668M 8175K We build this corpus by combining the above corpora 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Detailed information of the corpora. #tokens denotes the number of tokens in corpus. |V | 
denotes the vocabulary size. 

CA_translated 
CA8 
Cap. Sta. Fam. 
A 
AB 
Pre. Suf. Mor. Geo. His. Nat. Peo. Sem. 

SGNS 

word 
.706 .966 .603 .117 .162 .181 .389 .222 .414 .345 .236 .223 .327 
word+ngram .715 .977 .640 .143 .184 .197 .429 .250 .449 .308 .276 .310 .368 
word+char .676 .966 .548 .358 .540 .326 .612 .455 .468 .226 .296 .305 .368 

PPMI 

word 
.925 .920 .548 .103 .139 .138 .464 .226 .627 .501 .300 .515 .522 
word+ngram .943 .960 .658 .102 .129 .168 .456 .230 .680 .535 .371 .626 .586 
word+char .913 .886 .614 .106 .190 .173 .505 .260 .638 .502 .288 .515 .524 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 :</head><label>4</label><figDesc>Performance of word representations learned under different configurations. Baidubaike is used as the training corpus. The top 1 results are in bold.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 3 ,</head><label>3</label><figDesc></figDesc><table>six corpora are used in the experi-
ments: Chinese Wikipedia, Baidubaike, People's 
Daily News, Sogou News, Zhihu QA, and "Com-</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Performance of word representations learned upon different training corpora by SGNS with 
context feature of word. The top 2 results are in bold. 

</table></figure>

			<note place="foot" n="2"> https://github.com/BYVoid/OpenCC 3 https://github.com/hankcs/HanLP</note>

			<note place="foot" n="4"> CA_translated and SemEval datasets contain only semantic questions, MSR dataset contains only morphological questions, and in Google dataset the capital:country relation constitutes 56.72% of all semantic questions. 5 The SGNS with word and character features are implemented by fasttext toolkit, the rest are implemented by ngram2vec toolkit.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Enriching word vectors with subword information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.04606</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Joint learning of character and word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinxiong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan-Bo</forename><surname>Luan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1236" to="1242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Analogical translation of unknown words in a statistical machine translation framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Etienne</forename><surname>Denoual</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Machine Translation Summit XI</title>
		<meeting>Machine Translation Summit XI<address><addrLine>Copenhagen</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Analogy-based detection of morphological and semantic relations with word embeddings: what works and what doesn&apos;t</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Gladkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandr</forename><surname>Drozd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Matsuoka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL Student Research Workshop</title>
		<meeting>the NAACL Student Research Workshop</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="8" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Bagpack: A general framework to represent semantic relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amac</forename><surname>Herdagdelen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Geometrical Models of Natural Language Semantics. Association for Computational Linguistics</title>
		<meeting>the Workshop on Geometrical Models of Natural Language Semantics. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="33" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Translating unknown words by analogical learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Langlais</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Patry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-CoNLL</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="877" to="886" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Linguistic regularities in sparse and explicit word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the eighteenth conference on computational natural language learning</title>
		<meeting>the eighteenth conference on computational natural language learning</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="171" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Neural word embedding as implicit matrix factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2177" to="2185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Improving distributional similarity with lessons learned from word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="211" to="225" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Practical grammar of modern Chinese</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuehua</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Gu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>The Commercial Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Linguistic regularities in continuous space word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">hlt-Naacl</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="746" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">The morphology of Chinese: A linguistic and cognitive approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jerome L Packard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Unsupervised morphology induction using word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz Josef</forename><surname>Och</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1627" to="1637" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning chinese word representations from glyphs of characters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tzu-Ray</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hung-Yi</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="264" to="273" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A uniform approach to analogies, synonyms, antonyms, and associations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Peter D Turney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Computational Linguistics</title>
		<meeting>the 22nd International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="905" to="912" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Improved learning of chinese word embeddings with semantic knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liner</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Chinese Computational Linguistics and Natural Language Processing Based on Naturally Annotated Big Data</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="15" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Multi-granularity chinese word embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rongchao</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="981" to="986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Ngram2vec: Learning improved word representations from ngram co-occurrence statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bofang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyong</forename><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="244" to="253" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
