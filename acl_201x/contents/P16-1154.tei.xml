<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T13:01+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Incorporating Copying Mechanism in Sequence-to-Sequence Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>August 7-12, 2016. 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiatao</forename><surname>Gu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Electronic Engineering</orgName>
								<orgName type="laboratory">Huawei Noah&apos;s Ark Lab</orgName>
								<orgName type="institution">The University of Hong Kong</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Electronic Engineering</orgName>
								<orgName type="laboratory">Huawei Noah&apos;s Ark Lab</orgName>
								<orgName type="institution">The University of Hong Kong</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Electronic Engineering</orgName>
								<orgName type="laboratory">Huawei Noah&apos;s Ark Lab</orgName>
								<orgName type="institution">The University of Hong Kong</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><forename type="middle">O K</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Electronic Engineering</orgName>
								<orgName type="laboratory">Huawei Noah&apos;s Ark Lab</orgName>
								<orgName type="institution">The University of Hong Kong</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">†</forename></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Electronic Engineering</orgName>
								<orgName type="laboratory">Huawei Noah&apos;s Ark Lab</orgName>
								<orgName type="institution">The University of Hong Kong</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Incorporating Copying Mechanism in Sequence-to-Sequence Learning</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1631" to="1640"/>
							<date type="published">August 7-12, 2016. 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We address an important problem in sequence-to-sequence (Seq2Seq) learning referred to as copying, in which certain segments in the input sequence are selectively replicated in the output sequence. A similar phenomenon is observable in human language communication. For example, humans tend to repeat entity names or even long phrases in conversation. The challenge with regard to copying in Seq2Seq is that new machinery is needed to decide when to perform the operation. In this paper, we incorporate copying into neural network-based Seq2Seq learning and propose a new model called COPYNET with encoder-decoder structure. COPYNET can nicely integrate the regular way of word generation in the decoder with the new copying mechanism which can choose sub-sequences in the input sequence and put them at proper places in the output sequence. Our empirical study on both synthetic data sets and real world data sets demonstrates the efficacy of COPYNET. For example, COPYNET can outperform regular RNN-based model with remarkable margins on text summarization tasks.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recently, neural network-based sequence-to- sequence learning (Seq2Seq) has achieved re- markable success in various natural language pro- cessing (NLP) tasks, including but not limited to Machine Translation ( ), Syntactic Parsing ( <ref type="bibr" target="#b22">Vinyals et al., 2015b</ref>), Text Summarization ( <ref type="bibr">Rush et al., 2015)</ref> and Dialogue Systems ( ).</p><p>Seq2Seq is essentially an encoder-decoder model, in which the encoder first transform the input se- quence to a certain representation which can then transform the representation into the output se- quence. Adding the attention mechanism ) to Seq2Seq, first proposed for automatic alignment in machine translation, has led to significant improvement on the perfor- mance of various tasks <ref type="bibr" target="#b15">(Shang et al., 2015;</ref><ref type="bibr">Rush et al., 2015)</ref>. Different from the canonical encoder- decoder architecture, the attention-based Seq2Seq model revisits the input sequence in its raw form (array of word representations) and dynamically fetches the relevant piece of information based mostly on the feedback from the generation of the output sequence.</p><p>In this paper, we explore another mechanism important to the human language communication, called the "copying mechanism". Basically, it refers to the mechanism that locates a certain seg- ment of the input sentence and puts the segment into the output sequence. For example, in the following two dialogue turns we observe differ- ent patterns in which some subsequences (colored blue) in the response (R) are copied from the input utterance (I):</p><p>I: Hello Jack, my name is Chandralekha.</p><p>R: Nice to meet you, Chandralekha.</p><p>I: This new guy doesn't perform exactly as we expected.</p><p>R: What do you mean by "doesn't perform exactly as we expected"?</p><p>Both the canonical encoder-decoder and its variants with attention mechanism rely heavily on the representation of "meaning", which might not be sufficiently inaccurate in cases in which the system needs to refer to sub-sequences of in- put like entity names or dates. In contrast, the copying mechanism is closer to the rote memo- rization in language processing of human being, deserving a different modeling strategy in neural network-based models. We argue that it will ben- efit many Seq2Seq tasks to have an elegant unified model that can accommodate both understanding and rote memorization. Towards this goal, we pro- pose COPYNET, which is not only capable of the regular generation of words but also the operation of copying appropriate segments of the input se- quence. Despite the seemingly "hard" operation of copying, COPYNET can be trained in an end-to- end fashion. Our empirical study on both synthetic datasets and real world datasets demonstrates the efficacy of COPYNET.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background: Neural Models for</head><p>Sequence-to-sequence Learning Seq2Seq Learning can be expressed in a prob- abilistic view as maximizing the likelihood (or some other evaluation metrics <ref type="bibr" target="#b16">(Shen et al., 2015)</ref>) of observing the output (target) sequence given an input (source) sequence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">RNN Encoder-Decoder</head><p>RNN-based Encoder-Decoder is successfully ap- plied to real world Seq2Seq tasks, first by  and <ref type="bibr" target="#b19">Sutskever et al. (2014)</ref>, and then by <ref type="bibr" target="#b21">Vinyals et al., 2015a</ref>).</p><p>In the Encoder-Decoder framework, the source se- quence X = [x 1 , ..., x T S ] is converted into a fixed length vector c by the encoder RNN, i.e.</p><formula xml:id="formula_0">h t = f (x t , h t−1 ); c = φ({h 1 , ..., h T S }) (1)</formula><p>where {h t } are the RNN states, c is the so-called context vector, f is the dynamics function, and φ summarizes the hidden states, e.g. choosing the last state h T S . In practice it is found that gated RNN alternatives such as LSTM <ref type="bibr" target="#b8">(Hochreiter and Schmidhuber, 1997</ref>) or GRU ( ) of- ten perform much better than vanilla ones. The decoder RNN is to unfold the context vec- tor c into the target sequence, through the follow- ing dynamics and prediction model:</p><formula xml:id="formula_1">s t = f (y t−1 , s t−1 , c) p(y t |y &lt;t , X) = g(y t−1 , s t , c)<label>(2)</label></formula><p>where s t is the RNN state at time t, y t is the pre- dicted target symbol at t (through function g(·)) with y &lt;t denoting the history {y 1 , ..., y t−1 }. The prediction model is typically a classifier over the vocabulary with, say, 30,000 words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">The Attention Mechanism</head><p>The attention mechanism was first introduced to Seq2Seq ( ) to release the burden of summarizing the entire source into a fixed-length vector as context. Instead, the atten- tion uses a dynamically changing context c t in the decoding process. A natural option (or rather "soft attention") is to represent c t as the weighted sum of the source hidden states, i.e.</p><formula xml:id="formula_2">c t = T S τ =1 α tτ h τ ; α tτ = e η(s t−1 ,hτ ) τ e η(s t−1 ,h τ ) (3)</formula><p>where η is the function that shows the correspon- dence strength for attention, approximated usually with a multi-layer neural network (DNN). Note that in ( ) the source sen- tence is encoded with a Bi-directional RNN, mak- ing each hidden state h τ aware of the contextual information from both ends.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">COPYNET</head><p>From a cognitive perspective, the copying mech- anism is related to rote memorization, requiring less understanding but ensuring high literal fi- delity. From a modeling perspective, the copying operations are more rigid and symbolic, making it more difficult than soft attention mechanism to integrate into a fully differentiable neural model. In this section, we present COPYNET, a differen- tiable Seq2Seq model with "copying mechanism", which can be trained in an end-to-end fashion with just gradient descent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Model Overview</head><p>As illustrated in <ref type="figure" target="#fig_0">Figure 1</ref>, COPYNET is still an encoder-decoder (in a slightly generalized sense). The source sequence is transformed by Encoder into representation, which is then read by Decoder to generate the target sequence.</p><p>Encoder: Same as in ( ), a bi-directional RNN is used to transform the source sequence into a series of hidden states with equal length, with each hidden state h t corresponding to word x t . This new representation of the source, {h 1 , ..., h T S }, is considered to be a short-term memory (referred to as M in the remainder of the paper), which will later be accessed in multiple ways in generating the target sequence (decoding). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Softmax</head><p>Prob("Jebara") = Prob("Jebara", g) + Prob("Jebara", c) … ... Decoder: An RNN that reads M and predicts the target sequence. It is similar with the canoni- cal RNN-decoder in ( ), with however the following important differences</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(b) Generate-Mode &amp; Copy-Mode</head><p>• Prediction: COPYNET predicts words based on a mixed probabilistic model of two modes, namely the generate-mode and the copy- mode, where the latter picks words from the source sequence (see Section 3.2);</p><p>• State Update: the predicted word at time t−1 is used in updating the state at t, but COPY- NET uses not only its word-embedding but also its corresponding location-specific hid- den state in M (if any) (see Section 3.3 for more details);</p><p>• Reading M: in addition to the attentive read to M, COPYNET also has"selective read" to M, which leads to a powerful hybrid of content-based addressing and location-based addressing (see both Sections 3.3 and 3.4 for more discussion).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Prediction with Copying and Generation</head><p>We assume a vocabulary V = {v 1 , ..., v N }, and use UNK for any out-of-vocabulary (OOV) word. In addition, we have another set of words X , for all the unique words in source sequence X = {x 1 , ..., x T S }. Since X may contain words not in V, copying sub-sequence in X enables COPY- NET to output some OOV words. In a nutshell, the instance-specific vocabulary for source X is V ∪ UNK ∪ X .</p><p>Given the decoder RNN state s t at time t to- gether with M, the probability of generating any target word y t , is given by the "mixture" of proba- bilities as follows</p><formula xml:id="formula_3">p(y t |s t , y t−1 , c t , M) = p(y t , g|s t , y t−1 , c t , M) + p(y t , c|s t , y t−1 , c t , M) (4)</formula><p>where g stands for the generate-mode, and c the copy mode. The probability of the two modes are given respectively by</p><formula xml:id="formula_4">p(y t , g|·)=        1 Z e ψg(yt) , y t ∈ V 0, y t ∈ X ∩ ¯ V 1 Z e ψg(UNK) y t ∈ V ∪ X (5) p(y t , c|·)= 1 Z j:x j =yt e ψc(x j ) , y t ∈ X 0 otherwise (6)</formula><p>where ψ g (·) and ψ c (·) are score functions for generate-mode and copy-mode, respectively, and Z is the normalization term shared by the two modes, Z = v∈V∪{UNK} e ψg(v) + x∈X e ψc(x) . Due to the shared normalization term, the two modes are basically competing through a softmax function (see <ref type="figure" target="#fig_0">Figure 1</ref> for an illustration with ex- ample), rendering Eq.(4) different from the canon- ical definition of the mixture model <ref type="bibr" target="#b13">(McLachlan and Basford, 1988)</ref>. This is also pictorially illus- trated in <ref type="figure" target="#fig_2">Figure 2</ref>. The score of each mode is cal- culated:</p><formula xml:id="formula_5">unk í µí± í µí± í µí± ∩ í µí± ' ( exp í µí¼ -í µí±£ / | í µí±£ / = í µí±¦ 4 ' (</formula><p>∑ exp í µí¼ 6 í µí±¥ 8 | í µí±¥ 8 = í µí±¦  Generate-Mode: The same scoring function as in the generic RNN encoder-decoder ( ) is used, i.e.</p><formula xml:id="formula_6">ψ g (y t = v i ) = v i W o s t , v i ∈ V ∪ UNK (7)</formula><p>where W o ∈ R (N +1)×ds and v i is the one-hot in- dicator vector for v i .</p><p>Copy-Mode: The score for "copying" the word x j is calculated as</p><formula xml:id="formula_7">ψ c (y t = x j ) = σ h j W c s t , x j ∈ X (8)</formula><p>where W c ∈ R d h ×ds , and σ is a non-linear ac- tivation function, considering that the non-linear transformation in Eq. <ref type="formula">( 8)</ref> can help project s t and h j in the same semantic space. Empirically, we also found that using the tanh non-linearity worked better than linear transformation, and we used that for the following experiments. When calculating the copy-mode score, we use the hidden states {h 1 , ..., h T S } to "represent" each of the word in the source sequence {x 1 , ..., x T S } since the bi- directional RNN encodes not only the content, but also the location information into the hidden states in M. The location informaton is important for copying (see Section 3.4 for related discussion).</p><p>Note that we sum the probabilities of all x j equal to y t in Eq. <ref type="formula">(6)</ref> considering that there may be mul- tiple source symbols for decoding y t . Naturally we let p(y t , c|·) = 0 if y t does not appear in the source sequence, and set p(y t , g|·) = 0 when y t only appears in the source.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">State Update</head><p>COPYNET updates each decoding state s t with the previous state s t−1 , the previous symbol y t−1 and the context vector c t following Eq. (2) for the generic attention-based Seq2Seq model. However, there is some minor changes in the y t−1 −→s t path for the copying mechanism. More specifically, y t−1 will be represented as [e(y t−1 ); ζ(y t−1 )] , where e(y t−1 ) is the word embedding associated with y t−1 , while ζ(y t−1 ) is the weighted sum of hidden states in M corresponding to y t</p><formula xml:id="formula_8">ζ(y t−1 ) = T S τ =1 ρ tτ h τ ρ tτ = 1 K p(x τ , c|s t−1 , M), x τ = y t−1 0 otherwise (9)</formula><p>where K is the normalization term which equals τ :x τ =y t−1 p(x τ , c|s t−1 , M), considering there may exist multiple positions with y t−1 in the source sequence. In practice, ρ tτ is often con- centrated on one location among multiple appear- ances, indicating the prediction is closely bounded to the location of words.</p><p>In a sense ζ(y t−1 ) performs a type of read to M similar to the attentive read (resulting c t ) with however higher precision. In the remainder of this paper, ζ(y t−1 ) will be referred to as selective read. ζ(y t−1 ) is specifically designed for the copy mode: with its pinpointing precision to the cor- responding y t−1 , it naturally bears the location of y t−1 in the source sequence encoded in the hidden state. As will be discussed more in Section 3.4, this particular design potentially helps copy-mode in covering a consecutive sub-sequence of words. If y t−1 is not in the source, we let ζ(y t−1 ) = 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Hybrid Addressing of M</head><p>We hypothesize that COPYNET uses a hybrid strategy for fetching the content in M, which com- bines both content-based and location-based ad- dressing. Both addressing strategies are coordi- nated by the decoder RNN in managing the atten- tive read and selective read, as well as determining when to enter/quit the copy-mode. Both the semantics of a word and its location in X will be encoded into the hidden states in M by a properly trained encoder RNN. Judging from our experiments, the attentive read of COPYNET is driven more by the semantics and language model, therefore capable of traveling more freely on M, even across a long distance. On the other hand, once COPYNET enters the copy-mode, the selec- tive read of M is often guided by the location in- formation. As the result, the selective read often takes rigid move and tends to cover consecutive words, including UNKs. Unlike the explicit de- sign for hybrid addressing in Neural Turing Ma- chine ( <ref type="bibr" target="#b5">Graves et al., 2014;</ref><ref type="bibr" target="#b10">Kurach et al., 2015)</ref>, COPYNET is more subtle: it provides the archi-tecture that can facilitate some particular location- based addressing and lets the model figure out the details from the training data for specific tasks.</p><p>Location-based Addressing: With the location information in {h i }, the information flow</p><formula xml:id="formula_9">ζ(y t−1 ) update −−−→ s t predict −−−→ y t sel. read −−−−→ ζ(y t )</formula><p>provides a simple way of "moving one step to the right" on X. More specifically, assuming the se- lective read ζ(y t−1 ) concentrates on the th word in X, the state-update operation ζ(y t−1 ) update −−−→s t acts as "location ← location+1", making s t favor the (+1) th word in X in the prediction Handling Out-of-Vocabulary Words Although it is hard to verify the exact addressing strategy as above directly, there is strong evidence from our empirical study. Most saliently, a properly trained COPYNET can copy a fairly long segment full of OOV words, despite the lack of semantic infor- mation in its M representation. This provides a natural way to extend the effective vocabulary to include all the words in the source. Although this change is small, it seems quite significant empiri- cally in alleviating the OOV problem. Indeed, for many NLP applications (e.g., text summarization or spoken dialogue system), much of the OOV words on the target side, for example the proper nouns, are essentially the replicates of those on the source side.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Learning</head><p>Although the copying mechanism uses the "hard" operation to copy from the source and choose to paste them or generate symbols from the vocab- ulary, COPYNET is fully differentiable and can be optimized in an end-to-end fashion using back- propagation. Given the batches of the source and target sequence {X} N and {Y } N , the objectives are to minimize the negative log-likelihood:</p><formula xml:id="formula_10">L = − 1 N N k=1 T t=1 log p(y (k) t |y (k) &lt;t , X (k) ) ,<label>(10)</label></formula><p>where we use superscripts to index the instances. Since the probabilistic model for observing any target word is a mixture of generate-mode and copy-mode, there is no need for any additional labels for modes. The network can learn to co- ordinate the two modes from data. More specif- ically, if one particular word y (k) t can be found in the source sequence, the copy-mode will con- tribute to the mixture model, and the gradient will more or less encourage the copy-mode; otherwise, the copy-mode is discouraged due to the compe- tition from the shared normalization term Z. In practice, in most cases one mode dominates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>We report our empirical study of COPYNET on the following three tasks with different characteristics 1. A synthetic dataset on with simple patterns; 2. A real-world task on text summarization; 3. A dataset for simple single-turn dialogues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Synthetic Dataset</head><p>Dataset: We first randomly generate transforma- tion rules with 5∼20 symbols and variables x &amp; y, e.g.</p><formula xml:id="formula_11">a b x c d y e f −→ g h x m,</formula><p>with {a b c d e f g h m} being regular symbols from a vocabulary of size 1,000. As shown in the table below, each rule can further produce a num- ber of instances by replacing the variables with randomly generated subsequences (1∼15 sym- bols) from the same vocabulary. We create five types of rules, including "x → ∅". The task is to learn to do the Seq2Seq transformation from the training instances. This dataset is designed to study the behavior of COPYNET on handling sim- ple and rigid patterns. Since the strings to repeat are random, they can also be viewed as some ex- treme cases of rote memorization.</p><p>Rule-type Examples (e.g. x = i h k, y = j c)</p><formula xml:id="formula_12">x → ∅ a b c d x e f → c d g x → x a b c d x e f → c d x g x → x x a b c d x e f → x d x g x y → x a b y d x e f → x d i g x y → x y a b y d x e f → x d y g</formula><p>Experimental Setting: We select 200 artificial rules from the dataset, and for each rule 200 in- stances are generated, which will be split into training (50%) and testing (50%). We compare the accuracy of COPYNET and the RNN Encoder- Decoder with (i.e. RNNsearch) or without atten- tion (denoted as Enc-Dec). For a fair compari- son, we use bi-directional GRU for encoder and another GRU for decoder for all Seq2Seq models, with hidden layer size = 300 and word embedding dimension = 150. We use bin size = 10 in beam search for testing. The prediction is considered  correct only when the generated sequence is ex- actly the same as the given one. It is clear from <ref type="table" target="#tab_2">Table 1</ref> that COPYNET signifi- cantly outperforms the other two on all rule-types except "x → ∅", indicating that COPYNET can ef- fectively learn the patterns with variables and ac- curately replicate rather long subsequence of sym- bols at the proper places.This is hard to Enc-Dec due to the difficulty of representing a long se- quence with very high fidelity. This difficulty can be alleviated with the attention mechanism. How- ever attention alone seems inadequate for handling the case where strict replication is needed.</p><note type="other">Rule-type x x x xy xy → ∅ → x → xx → x → xy Enc-Dec 100 3.3 1.5 2.9 0.0 RNNSearch 99.0 69.4 22.</note><p>A closer look (see <ref type="figure">Figure 3</ref> for example) re- veals that the decoder is dominated by copy-mode when moving into the subsequence to replicate, and switch to generate-mode after leaving this area, showing COPYNET can achieve a rather pre- cise coordination of the two modes. Input:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pattern</head><p>The Target Sequence</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Predict:</head><p>Figure 3: Example output of COPYNET on the synthetic dataset. The heatmap represents the ac- tivations of the copy-mode over the input sequence (left) during the decoding process (bottom).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Text Summarization</head><p>Automatic text summarization aims to find a con- densed representation which can capture the core meaning of the original document. It has been recently formulated as a Seq2Seq learning prob- lem in ( <ref type="bibr">Rush et al., 2015;</ref><ref type="bibr" target="#b9">Hu et al., 2015)</ref>, which essentially gives abstractive summarization since the summary is generated based on a represen- tation of the document. In contrast, extractive summarization extracts sentences or phrases from the original text to fuse them into the summaries, therefore making better use of the overall struc- ture of the original document. In a sense, COPY- NET for summarization lies somewhere between two categories, since part of output summary is ac- tually extracted from the document (via the copy- ing mechanism), which are fused together possi- bly with the words from the generate-mode.   It is clear from <ref type="table" target="#tab_6">Table 3</ref> that COPYNET beats the competitor models with big margin. <ref type="bibr" target="#b9">Hu et al. (2015)</ref> reports that the performance of a word-based model is inferior to a character-based</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input(1): 今天上午 9 点半 ， 复旦 投毒案 将 在 上海 二中院 公开审理 。 被害 学生 黄洋 的 亲属 已 从 四川 抵达 上海 ， 其父 称待 刑事 部分 结束 后 ， 再 提 民事 赔偿 ， 黄洋 92 岁 的 奶奶 依然</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>不知情 。 今年 4 月 ， 在 复旦 上海医学院 读 研究生 的 黄洋 疑遭 室友 林森 浩 投毒 ， 不幸身亡 。 新民 网</head><p>Today 9:30, the Fudan poisoning case will be will on public trial at the Shanghai Second Intermediate Court. The relatives of the murdered student Huang Yang has arrived at Shanghai from Sichuan. His father said that they will start the lawsuit for civil compensation after the criminal section. HuangYang 92-year-old grandmother is still unaware of his death. In April, a graduate student at Fudan University Shanghai Medical College, Huang Yang is allegedly poisoned and killed by his roommate Lin Senhao. Reported by Xinmin </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input(6): 镁离子电池相比锂电池能量密度提升了近一倍，这意味着使用了镁电池的电动车，纯电续航也将有质的提升。但目前由于电解质等技术壁垒，要大规模量产并取代锂电池还为时过早。</head><p>The energy density of Magnesium ion batteries almost doubles that of lithium battery, which means that for the electric vehicles using of magnesium batteries will last longer even at pure electric power. But currently due to the technical barriers to the electrolyte, it is still too early for the mass production of it and replacing lithium batteries.. ______________________________________________________________</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Golden: 锂电池或将被淘汰 能量密度更高的镁电池亦大势所趋</head><p>Lithium batteries will be phased out, magnesium battery with energy density higher will be the future trend 发现 机遇 保持 创业 激情 。 1. master the skills; 2 Learn to finance ; 3. understand the law; 4. Be confident; 5. test+ trial; 6. understand the need of customers; 7 forecast + measure + ensure; 8. mentally prepared to fight all kinds of small bugs ; 9 discover opportunities and keep the passion of start-up.    are those words with copy-mode probability higher than the generate-mode. We also provide literal English translation for the document, the golden, and COPYNET, while omitting that for RNN context since the language is broken. one. One possible explanation is that a word- based model, even with a much larger vocabulary (50,000 words in <ref type="bibr" target="#b9">Hu et al. (2015)</ref>), still has a large proportion of OOVs due to the large number of en- tity names in the summary data and the mistakes in word segmentation. COPYNET, with its ability to handle the OOV words with the copying mech- anism, performs however slightly better with the word-based variant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Case Study</head><p>As shown in <ref type="figure" target="#fig_9">Figure 4</ref>, we make the following interesting observations about the summary from COPYNET: 1) most words are from copy-mode, but the summary is usually still fluent; 2) COPY- NET tends to cover consecutive words in the orig- inal document, but it often puts together seg- ments far away from each other, indicating a so- phisticated coordination of content-based address- ing and location-based addressing; 3) COPYNET handles OOV words really well: it can gener- ate acceptable summary for document with many OOVs, and even the summary itself often con- tains many OOV words. In contrast, the canonical RNN-based approaches often fail in such cases.</p><p>It is quite intriguing that COPYNET can often find important parts of the document, a behav- ior with the characteristics of extractive summa- rization, while it often generate words to "con- nect" those words, showing its aspect of abstrac- tive summarization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Single-turn Dialogue</head><p>In this experiment we follow the work on neural dialogue model proposed in <ref type="bibr" target="#b15">(Shang et al., 2015;</ref><ref type="bibr" target="#b17">Sordoni et al., 2015)</ref>, and test COPYNET on single-turn dialogue. Basically, the neural model learns to generate a response to user's input, from the given (input, response) pairs as training instances.</p><p>Dataset: We build a simple dialogue dataset based on the following three instructions:</p><p>1. Dialogue instances are collected from Baidu Tieba 3 with some coverage of conversations of real life e.g., greeting and sports, etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Patterns with slots like</head><p>hi, my name is x → hi, x are mined from the set, with possibly multi- ple responding patterns to one input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Similar with the synthetic dataset, we enlarge</head><p>the dataset by filling the slots with suitable subsequence (e.g. name entities, dates, etc.)</p><p>To make the dataset close to the real conversations, we also maintain a certain proportion of instances with the response that 1) do not contain entities or 2) contain entities not in the input.</p><p>Experimental Setting: We create two datasets: DS-I and DS-II with slot filling on 173 collected patterns. The main difference between the two datasets is that the filled substrings for training and testing in DS-II have no overlaps, while in DS-I they are sampled from the same pool. For each dataset we use 6,500 instances for training and 1,500 for testing. We compare COPYNET with canonical RNNSearch, both character-based, with the same model configuration in Section 5.  We compare COPYNET and RNNSearch on DS-I and DS-II in terms of top-1 and top-10 ac- curacy (shown in <ref type="table" target="#tab_8">Table 4</ref>), estimating respectively the chance of the top-1 or one of top-10 (from beam search) matching the golden. Since there are often many good responses to an input, top- 10 accuracy appears to be closer to the real world setting.</p><p>As shown in <ref type="table" target="#tab_8">Table 4</ref>, COPYNET significantly outperforms RNNsearch, especially on DS-II. It suggests that introducing the copying mechanism helps the dialogue system master the patterns in dialogue and correctly identify the correct parts of input, often proper nouns, to replicate in the re- sponse. Since the filled substrings have no over- laps in DS-II, the performance of RNNSearch drops significantly as it cannot handle words un- seen in training data. In contrast, the performance of COPYNET only drops slightly as it has learned to fill the slots with the copying mechanism and relies less on the representation of the words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Case Study</head><p>As indicated by the examples in <ref type="figure">Figure 5</ref>, COPY- NET accurately replicates the critical segments from the input with the copy-mode, and generates <ref type="figure">Figure 5</ref>: Examples from the testing set of DS-II shown as the input text and golden, with the outputs of RNNSearch and CopyNet. Words in red rectangles are unseen in the training set. The highlighted words (with different colors) are those words with copy-mode probability higher than the generate-mode. Green cirles (meaning correct) and red cross (meaning incorrect) are given based on human judgment on whether the response is appropriate. the rest of the answers smoothly by the generate- mode. Note that in (2) and (3), the decoding se- quence is not exactly the same with the standard one, yet still correct regarding to their meanings. In contrast, although RNNSearch usually gener- ates answers in the right formats, it fails to catch the critical entities in all three cases because of the difficulty brought by the unseen words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Our work is partially inspired by the recent work of Pointer Networks ( <ref type="bibr" target="#b21">Vinyals et al., 2015a</ref>), in which a pointer mechanism (quite similar with the proposed copying mechanism) is used to predict the output sequence directly from the input. In ad- dition to the difference with ours in application, ( <ref type="bibr" target="#b21">Vinyals et al., 2015a</ref>) cannot predict outside of the set of input sequence, while COPYNET can naturally combine generating and copying.</p><p>COPYNET is also related to the effort to solve the OOV problem in neural machine translation. <ref type="bibr" target="#b12">Luong et al. (2015)</ref> introduced a heuristics to post- process the translated sentence using annotations on the source sentence. In contrast COPYNET ad- dresses the OOV problem in a more systemic way with an end-to-end model. However, as COPY- NET copies the exact source words as the output, it cannot be directly applied to machine translation. However, such copying mechanism can be natu- rally extended to any types of references except for the input sequence, which will help in appli- cations with heterogeneous source and target se- quences such as machine translation.</p><p>The copying mechanism can also be viewed as carrying information over to the next stage without any nonlinear transformation. Similar ideas are proposed for training very deep neural networks in ( <ref type="bibr" target="#b18">Srivastava et al., 2015;</ref>) for clas- sification tasks, where shortcuts are built between layers for the direct carrying of information.</p><p>Recently, we noticed some parallel efforts to- wards modeling mechanisms similar to or related to copying. <ref type="bibr" target="#b3">Cheng and Lapata (2016)</ref> devised a neural summarization model with the ability to ex- tract words/sentences from the source. <ref type="bibr" target="#b6">Gulcehre et al. (2016)</ref> proposed a pointing method to han- dle the OOV words for summarization and MT. In contrast, COPYNET is more general, and not lim- ited to a specific task or OOV words. Moreover, the softmaxCOPYNET is more flexible than gating in the related work in handling the mixture of two modes, due to its ability to adequately model the content of copied segment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion and Future Work</head><p>We proposed COPYNET to incorporate copy- ing into the sequence-to-sequence learning frame- work. For future work, we will extend this idea to the task where the source and target are in hetero- geneous types, for example, machine translation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The overall diagram of COPYNET. For simplicity, we omit some links for prediction (see Sections 3.2 for more details).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>∑</head><label></label><figDesc>exp í µí¼ 6 í µí±¥ 8 + 9 : exp í µí¼ -í µí±£ / | í µí±¥ 8 = í µí±¦ 4 , í µí±£ / = í µí±¦ 4 ' ( exp [í µí¼ -unk ] *Z is the normalization term.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The illustration of the decoding probability p(y t |·) as a 4-class classifier.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>s t predict −−−→ y t in copy-mode. This again leads to the selective readˆhreadˆ readˆh t sel. read −−−−→ζ(y t ) for the state up- date of the next round.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>______________________________________________________________ Golden: 林森 浩 投毒案 今日 开审 92 岁 奶奶 尚不知 情 the case of Lin Senhao poisoning is on trial today, his 92-year-old grandmother is still unaware of this RNN context: 复旦投毒案： 黄洋疑遭室友投毒凶手已从四川飞往上海，父亲命案另有4人被通知家属不治？ CopyNet: 复旦 投毒案 今 在 沪 上 公开审理 the Fudan poisoning case is on public trial today in Shanghai Input(2): 华谊 兄弟 （ 300027 ） 在 昨日 收盘 后 发布公告 称 ， 公司 拟 以 自有 资金 3.978 亿元 收购 浙江 永乐 影视 股份 有限公司 若干 股东 持有 的 永乐 影视 51 % 的 股权 。 对于 此项 收购 ， 华谊 兄弟 董秘 胡明 昨日 表示 ： " 和 永乐 影视 的 合并 是 对 华谊 兄弟 电视剧 业务 的 一个 加强 。 Huayi Brothers (300027) announced that the company intends to buy with its own fund 397.8 million 51% of Zhejiang Yongle Film LTD's stake owned by a number of shareholders of Yongle Film LTD. For this acquisition, the secretary of the board, Hu Ming, said yesterday: "the merging with Yongle Film is to strengthen Huayi Brothers on TV business". ______________________________________________________________ Golden: 华谊 兄弟 拟 收购 永乐 影视 ５ １ ％ 股权 Huayi Brothers intends to acquire 51% stake of Zhejiang Yongle Film RNN context: 华谊兄弟收购永乐影视51%股权：与永乐影视合并为"和唐"影视合并的"UNK"和"UNK"的区别？ CopyNet: 华谊 兄弟 拟 3.978 亿 收购 永乐 影视 董秘 称 加强 电视剧 业务 Huayi Brothers is intended to 397.8 million acquisition of Yongle Film secretaries called to strengthen the TV business Input(3): 工厂 ， 大门 紧锁 ， 约 20 名 工人 散 坐在 树荫下 。 " 我们 就是 普通工人 ， 在 这里 等 工资 。 " 其中 一人 说道 。 7 月 4 日 上午 ， 记者 抵达 深圳 龙华区 清 湖 路上 的 深圳 愿景 光电子 有限公司 。 正如 传言 一般 ， 愿景 光电子 倒闭 了 ， 大 股东 邢毅 不知 所踪 。 The door of factory is locked. About 20 workers are scattered to sit under the shade. "We are ordinary workers, waiting for our salary" one of them said. In the morning of July 4th, reporters arrived at Yuanjing Photoelectron Corporation located at Qinghu Road, Longhua District, Shenzhen. Just as the rumor, Yuanjing Photoelectron Corporation is closed down and the big shareholder Xing Yi is missing. ______________________________________________________________ Golden: 深圳 亿元 级 LED 企业倒闭 烈日 下 工人 苦 等 老板 Hundred-million CNY worth LED enterprise is closed down and workers wait for the boss under the scorching sun RNN context: 深圳"&lt;UNK&gt;"：深圳&lt;UNK&gt;&lt;UNK&gt;，&lt;UNK&gt;，&lt;UNK&gt;，&lt;UNK&gt; CopyNet: 愿景 光电子 倒闭 20 名 工人 散 坐在 树荫下 Yuanjing Photoelectron Corporation is closed down, 20 workers are scattered to sit under the shade Input(4): 截至 2012 年 10 月底 ， 全国 累计 报告 艾滋病 病毒感染者 和 病人 492191 例 。 卫生部 称 ， 性传播 已 成为 艾滋病 的 主要 传播 途径 。 至 2011 年 9 月 ， 艾滋病 感染者 和 病人数 累 计 报告 数排 在 前 6 位 的 省份 依次 为 云南 、 广西 、 河南 、 四川 、 新疆 和 广东 ， 占 全国 的 75.8 % 。。 At the end of October 2012, the national total of reported HIV infected people and AIDS patients is 492,191 cases. The Health Ministry saids exual transmission has become the main route of transmission of AIDS. To September 2011, the six provinces with the most reported HIV infected people and AIDS patients were Yunnan, Guangxi, Henan,Sichuan, Xinjiang and Guangdong, accounting for 75.8% of the country. ______________________________________________________________ Golden: 卫生部 ： 性传播 成 艾滋病 主要 传播 途径 Ministry of Health: Sexually transmission became the main route of transmission of AIDS RNN context: 全国累计报告艾滋病患者和病人&lt;UNK&gt;例艾滋病患者占全国&lt;UNK&gt;%，性传播成艾滋病高发人群 ？ CopyNet: 卫生部 ： 性传播 已 成为 艾滋病 主要 传播 途径 Ministry of Health: Sexually transmission has become the main route of transmission of AIDS Input(5): 中国 反垄断 调查 风暴 继续 席卷 汽车行业 ， 继 德国 车企 奥迪 和 美国 车企 克莱斯勒 " 沦陷 " 之后 ， 又 有 12 家 日本 汽车 企业 卷入漩涡 。 记者 从 业内人士 获悉 ， 丰田 旗下 的 雷克萨斯 近期 曾 被 发改委 约 谈 。 Chinese antitrust investigation continues to sweep the automotive industry. After Germany Audi car and the US Chrysler "fell", there are 12 Japanese car companies involved in the whirlpool. Reporters learned from the insiders that Toyota's Lexus has been asked to report to the Development and Reform Commission recently. ______________________________________________________________ Golden: 发改委 公布 汽车 反垄断 进程 ： 丰田 雷克萨斯 近期 被 约 谈 the investigation by Development and Reform Commission: Toyota's Lexus has been asked to report RNN context: 丰田雷克萨斯遭发改委约谈：曾被约谈丰田旗下的雷克萨斯遭发改委约谈负人被约谈 CopyNet: 中国 反垄断 继续 席卷 汽车行业 12 家 日本 汽车 企业 被 发改委 约 谈 Chinese antitrust investigation continues to sweep the automotive industry. 12 Japanese car companies are asked to report to he Development and Reform Commission</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>RNN context:</head><label></label><figDesc>&lt;UNK&gt;、&lt;UNK&gt;、&lt;UNK&gt;、&lt;UNK&gt;、&lt;UNK&gt;、&lt;UNK&gt;、&lt;UNK&gt;、&lt;UNK&gt;、&lt;UNK&gt;、&lt;UNK&gt;、&lt;UNK&gt;、&lt;UNK&gt;电 池 了 CopyNet: 镁离子电池问世：大规模量产取代锂电池 Magnesium ion battery is developed : mass production of it will replace lithium batteries Input(7): 1 . 掌握 技巧 融会贯通 ； 2 . 学会 融资 ； 3 . 懂 法律 ； 4 . 保持 自信 ； 5 . 测试 + 尝试 ； 6 . 了解 客户 的 需求 ； 7 . 预测 + 衡量 + 确保 ； 8 . 做好 与 各种 小 bug 做 斗争 的 心态 ； 9 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>______________________________________________________________ Golden: 初次 创业者 必知 的 10 个 技巧 The 10 tips for the first time start-ups RNN context: 6个方法让你创业的6个&lt;UNK&gt;与&lt;UNK&gt;，你怎么看懂你的创业故事吗？（6家） CopyNet: 创业 成功 的 9 个 技巧 The 9 tips for success in start-up Input(8): 9 月 3 日 ， 总部 位于 日内瓦 的 世界 经济 论坛 发布 了 《 2014 -2015 年 全球 竞争力 报告 》 ， 瑞士 连续 六年 位居 榜首 ， 成为 全球 最具 竞争力 的 国家 ， 新加坡 和 美国 分列 第二 位 和 第三位 。 中国 排名第 28 位 ， 在 金砖 国家 中 排名 最高 。 On September 3, the Geneva based World Economic Forum released " The Global Competitiveness Report 2014-2015". Switzerland topped the list for six consecutive years , becoming the world's most competitive country. Singapore and the United States are in the second and third place respectively. China is in the 28th place, ranking highest among the BRIC countries.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>______________________________________________________________ Golden: 全球 竞争力 排行榜 中国 居 28 位居 金砖 国家 首位 The Global competitiveness ranking list, China is in the 28th place, the highest among BRIC countries.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>RNN context: 2014 -</head><label>2014</label><figDesc>2015年全球竞争力报告：瑞士连续6年居榜首中国居28位(首/3---访榜首)中国排名第28位 CopyNet: 2014 -2015 年 全球 竞争力 报告 ： 瑞士 居首 中国 第 28 2014--2015 Global Competitiveness Report: Switzerland topped and China the 28th</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Examples of COPYNET on LCSTS compared with RNN context. Word segmentation is applied on the input, where OOV words are underlined. The highlighted words (with different colors) are those words with copy-mode probability higher than the generate-mode. We also provide literal English translation for the document, the golden, and COPYNET, while omitting that for RNN context since the language is broken.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>2 h 3 h 4 h 5 s 1 s 2 s 3 s 4 h 6 h 7 h 8</head><label></label><figDesc></figDesc><table>hello 

, 
my 
name 
is 
Tony Jebara 
. 

Attentive Read 

hi 
, 
Tony Jebara 

&lt;eos&gt; 
hi 
, 
Tony 

h 1 
h "Tony" 

DNN 

Embedding 
for "Tony" 

Selective Read 
for "Tony" 

(a) Attention-based Encoder-Decoder (RNNSearch) 

(c) State Update 

s 4 

Source 
Vocabulary 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 1 : The test accuracy (%) on synthetic data.</head><label>1</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><head>Table 2 : Some statistics of the LCSTS dataset.</head><label>2</label><figDesc></figDesc><table>Experimental Setting: We try COPYNET that is 
based on character (+C) and word (+W). For the 
word-based variant the word-segmentation is ob-
tained with jieba 2 . We set the vocabulary size to 
3,000 (+C) and 10,000 (+W) respectively, which 
are much smaller than those for models in (Hu 
et al., 2015). For both variants we set the em-
bedding dimension to 350 and the size of hidden 
layers to 500. Following (Hu et al., 2015), we 
evaluate the test performance with the commonly 
used ROUGE-1, ROUGE-2 and ROUGE-L (Lin, 
2004), and compare it against the two models in 
(Hu et al., 2015), which are essentially canonical 
Encoder-Decoder and its variant with attention. 

Models 
ROUGE scores on LCSTS (%) 
R-1 
R-2 
R-L 

RNN 
+C 
21.5 
8.9 
18.6 
(Hu et al., 2015) +W 17.7 
8.5 
15.8 
RNN context 
+C 
29.9 
17.4 
27.2 
(Hu et al., 2015) +W 26.8 
16.1 
24.1 

COPYNET 
+C 
34.4 
21.6 
31.3 
+W 35.0 
22.3 
32.0 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Testing performance of LCSTS, where 
"RNN" is canonical Enc-Dec, and "RNN context" 
its attentive variant. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>The decoding accuracy on the two testing 
sets. Decoding is admitted success only when the 
answer is found exactly in the Top-K outputs. 

</table></figure>

			<note place="foot" n="1"> www.sina.com 2 https://pypi.python.org/pypi/jieba</note>

			<note place="foot" n="3"> http://tieba.baidu.com</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work is supported in part by the China Na-tional 973 Project 2014CB340301.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">你喜欢喝雪碧还是喜欢可乐？ /Would you like to drink Sprite or Coke? Golden: 都不喜欢，谢谢! /Not at all, thanks! RNNSearch: 我喜欢喝蜂蜜! /I like to drink honey! CopyNet: 我喜欢喝可乐! /I like to drink coke! Input(4): 我大青岛四季宜人 /Our great Qingdao has a good weather! Golden: 壮我大青岛～～～ /Our Qingdao is great~~~ RNNSearch: 壮我大哈尔滨～～～ /Our Harbin is great~~~ CopyNet: 壮我大青岛～～～ /Our Qingdao is great~~~ Input(5): 女儿会游蝶泳 /Daughter can swim butterfly? Golden: 我连游泳都不会T^T /I cannot swim at all T^T RNNSearch: 我连游泳都不会T^T /I cannot swim at all T^T CopyNet: 我连游泳都不会T^T /I cannot swim at all T^T</title>
	</analytic>
	<monogr>
		<title level="m">我出生在上海。 /I was born in Shanghai Golden: 真巧，我也来自上海，老乡啊! /What a coincidence, I also come from Shanghai, we are fellow townsman! RNNSearch: 真巧，我也来自海南，老乡啊! /What a coincidence, I also come from Hainan, we are fellow townsman! CopyNet: 真巧，我也来自上海，老乡啊! /What a coincidence, I also come from Shanghai, we are fellow townsman! Input</title>
		<imprint/>
	</monogr>
	<note>今天去爬黄山吗？ /Shall we climbing Huangshan? Golden: 去爬泰山吧，黄山没意思! /Climb Taishan. Huangshan is boring! RNNSearch: 去爬长白山吧，衡山没意思! /Climb Changbaishan, Hengshan is boring! CopyNet: 去爬嵩山吧，黄山没意思! /Climb Songshan. Input(6): 苏有朋是谁? /Who is Su You Peng? Golden: 苏有朋是一个男明星。 /Su You Peng is a male star</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<title level="m">CopyNet: 苏有是一个男明星。 /Su You is a male star RNNSearch: 吴亦凡是一个男明星。 /Wu Yifan is a male star</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>References Dzmitry Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.0473</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianpeng</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.07252</idno>
		<title level="m">Neural summarization by extracting sentences and words</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.1078</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Wayne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivo</forename><surname>Danihelka</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1410.5401</idno>
		<title level="m">Neural turing machines</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungjin</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.08148</idno>
		<title level="m">Pointing the unknown words</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.03385</idno>
		<title level="m">Deep residual learning for image recognition</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baotian</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingcai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangze</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.05865</idno>
		<title level="m">Lcsts: a large scale chinese short text summarization dataset</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karol</forename><surname>Kurach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Andrychowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06392</idno>
		<title level="m">Neural random-access machines</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Rouge: A package for automatic evaluation of summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text Summarization Branches Out: Proceedings of the ACL-04 Workshop</title>
		<editor>Stan Szpakowicz Marie-Francine Moens</editor>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-07" />
			<biblScope unit="page" from="74" to="81" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Addressing the rare word problem in neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015-07" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="11" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Mixture models. inference and applications to clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Geoffrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaye</forename><forename type="middle">E</forename><surname>Mclachlan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Basford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics: Textbooks and Monographs</title>
		<imprint>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="1988" />
			<publisher>Dekker</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Alexander M Rush</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1509.00685</idno>
		<title level="m">Sumit Chopra, and Jason Weston. 2015. A neural attention model for abstractive sentence summarization</title>
		<imprint/>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifeng</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02364</idno>
		<title level="m">Neural responding machine for short-text conversation</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Minimum risk training for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiqi</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongjun</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<idno>abs/1512.02433</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">A neural network approach to context-sensitive generation of conversational responses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.06714</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rupesh Kumar</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Greff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.00387</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">Highway networks. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.05869</idno>
		<title level="m">A neural conversational model</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Pointer networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meire</forename><surname>Fortunato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navdeep</forename><surname>Jaitly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2674" to="2682" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Grammar as a foreign language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2755" to="2763" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
