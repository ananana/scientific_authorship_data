<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:41+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">RETURNN as a Generic Flexible Neural Toolkit with Application to Translation and Speech Recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 15-20, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Zeyer</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Human Language Technology and Pattern Recognition Group</orgName>
								<orgName type="institution">RWTH Aachen University</orgName>
								<address>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">AppTek</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamer</forename><surname>Alkhouli</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Human Language Technology and Pattern Recognition Group</orgName>
								<orgName type="institution">RWTH Aachen University</orgName>
								<address>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">AppTek</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Human Language Technology and Pattern Recognition Group</orgName>
								<orgName type="institution">RWTH Aachen University</orgName>
								<address>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">AppTek</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">RETURNN as a Generic Flexible Neural Toolkit with Application to Translation and Speech Recognition</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics-System Demonstrations</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics-System Demonstrations <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="128" to="133"/>
							<date type="published">July 15-20, 2018. 2018</date>
						</imprint>
					</monogr>
					<note>128</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We compare the fast training and decoding speed of RETURNN of attention models for translation, due to fast CUDA LSTM kernels, and a fast pure Tensor-Flow beam search decoder. We show that a layer-wise pretraining scheme for recurrent attention models gives over 1% BLEU improvement absolute and it allows to train deeper recurrent encoder networks. Promising preliminary results on max. expected BLEU training are presented. We obtain state-of-the-art models trained on the WMT 2017 German↔English translation task. We also present end-to-end model results for speech recognition on the Switchboard task. The flexibility of RETURNN allows a fast research feedback loop to experiment with alternative architectures, and its generality allows to use it on a wide range of applications.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>RETURNN, the RWTH extensible training frame- work for universal recurrent neural networks, was introduced in ( <ref type="bibr" target="#b5">Doetsch et al., 2017</ref>  <ref type="bibr">(TensorFlow Development Team, 2015</ref>) for its com- putation. Since it was introduced, it got ex- tended by comprehensive TensorFlow support. A generic recurrent layer allows for a wide range of encoder-decoder-attention or other recurrent struc- tures. An automatic optimization logic can opti- mize the computation graph depending on train- ing, scheduled sampling, sequence training, or beam search decoding. The automatic optimiza- tion together with our fast native CUDA imple- mented LSTM kernels allows for very fast train- 1 https://github.com/rwth-i6/returnn ing and decoding. We will show in speed compar- isons with Sockeye ( <ref type="bibr" target="#b10">Hieber et al., 2017</ref>) that we are at least as fast or usually faster in both train- ing and decoding. Additionally, we show in ex- periments that we can train very competitive mod- els for machine translation and speech recogni- tion. This flexibility together with the speed is the biggest strength of RETURNN.</p><p>Our focus will be on recurrent attention mod- els. We introduce a layer-wise pretraining scheme for attention models and show its significant ef- fect on deep recurrent encoder models. We show promising preliminary results on expected maxi- mum BLEU training. The configuration files of all the experiments are publicly available 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>Multiple frameworks exist for training attention models, most of which are focused on machine translation.</p><p>• Sockeye ( <ref type="bibr" target="#b10">Hieber et al., 2017</ref>  <ref type="bibr">, 2016)</ref> which is going to be discontinued in devel- opment. We show that RETURNN is much faster in both training and decoding as can be concluded from our speed comparison to Sockeye and the comparisons performed by the Sockeye authors ( <ref type="bibr" target="#b10">Hieber et al., 2017</ref>).</p><p>• Marian ( <ref type="bibr" target="#b12">Junczys-Dowmunt et al., 2016</ref>) is implemented directly in C++ for perfor- mance reasons. Again by our speed compar- isons and the comparisons performed by the Sockeye authors ( <ref type="bibr" target="#b10">Hieber et al., 2017)</ref>, one can conclude that RETURNN is very com- petitive in terms of speed, but is much more flexible.</p><p>• NeuralMonkey ( <ref type="bibr">Helcl and Libovick`Libovick`y, 2017)</ref> is based on <ref type="bibr">TensorFlow (TensorFlow Development Team, 2015)</ref>. This framework is not as flexible as RETURNN. Also here we can conclude just as before that RETURNN is much faster in both training and decoding. • Tensor2Tensor ( <ref type="bibr" target="#b26">Vaswani et al., 2018</ref>) is based on TensorFlow <ref type="bibr">(TensorFlow Development Team, 2015)</ref>. It comes with the reference implementation of the Transformer model ( <ref type="bibr" target="#b27">Vaswani et al., 2017)</ref>, however, it lacks sup- port for recurrent decoder models and overall is way less flexible than RETURNN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Speed comparison</head><p>Various improved and fast CUDA LSTM kernels are available for the TensorFlow backend in RE- TURNN. A comparison of the speed of its own LSTM kernel vs. other TensorFlow LSTM kernels can be found on the website 3 . In addition, an au- tomatic optimization path which moves out com- putation of the recurrent loop as much as possible improves the performance. We want to compare different toolkits in train- ing and decoding for a recurrent attention model in terms of speed on a GPU. Here, we try to maximize the batch size such that it still fits into the GPU memory of our reference GPU card, the Nvidia GTX 1080 Ti with 11 GB of memory. We keep the maximum sequence length in a batch the same, which is 60 words. We always use Adam ( <ref type="bibr" target="#b13">Kingma and Ba, 2014</ref>) for training. In <ref type="table">Table 1</ref>, we see that RETURNN is the fastest, and also is most efficient in its memory consumption (implied by the larger batches  <ref type="table">Table 1</ref>: Training speed and memory consumption on WMT 2017 German→English. Train time is for seeing the full train dataset once. Batch size is in words, such that it almost maximizes the GPU memory consumption. The BLEU score is for the converged models, reported for newstest2015 (dev) and newstest2017. The encoder has one bidirectional LSTM layer and either 3 or 5 uni- directional LSTM layers. more pessimistic, i.e. the decrease is slower and it sees the data more often until convergence. This greatly increases the total training time but in our experience also improves the model. For decoding, we extend RETURNN with a fast pure TensorFlow beam search decoder, which sup- ports batch decoding and can run on the GPU. A speed and memory consumption comparison is shown in <ref type="table">Table 2</ref>. We see that RETURNN is the fastest. We report results for the batch size that yields the best speed. The slow speed of Sockeye is due to frequent cross-device communication.  <ref type="table">Table 2</ref>: Decoding speed and memory consump- tion on WMT 2017 German→English. Time is for decoding the whole dataset, reported for new- stest2015 (dev) and newstest2017, with beam size 12. Batch size is the number of sequences, such that it optimizes the decoding speed. This does not mean that it uses the whole GPU memory. These are the same models as in <ref type="table">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Performance comparison</head><p>We want to study what possible performance we can get with each framework on a specific task. We restrict this comparison here to recurrent at- tention models.</p><p>The first task is the WMT 2017 German to En- glish translation task. We use the same 20K byte- pair encoding subword units in all toolkits <ref type="bibr">(Sen-nrich et al., 2015</ref>). We also use Adam ( <ref type="bibr" target="#b13">Kingma and Ba, 2014</ref>) in all cases. The learning rate scheduling is also similar. In RETURNN, we use a 6 layer bidirectional encoder, trained with pre- training and label smoothing. It has bidirectional LSTMs in every layer of the encoder, unlike Sock- eye, which only has the first layer bidirectional. We use a variant of attention weight / fertility feed- back ( <ref type="bibr" target="#b25">Tu et al., 2016)</ref>, which is inverse in our case, to use a multiplication instead of a division, for better numerical stability. Our model was derived from the model presented by <ref type="bibr" target="#b17">Peter et al., 2017)</ref> and ( <ref type="bibr" target="#b1">Bahdanau et al., 2014</ref>).</p><p>We report the best performing Sockeye model we trained, which has 1 bidirectional and 3 unidi- rectional encoder layers, 1 pre-attention target re- current layer, and 1 post-attention decoder layer. We trained with a max sequence length of 75, and used the 'coverage' RNN attention type. For Sockeye, the final model is an average of the 4 best runs according to the development perplex- ity. The results are collected in <ref type="table">Table 3</ref>. We obtain the best results with Sockeye using a Transformer network model ( <ref type="bibr" target="#b27">Vaswani et al., 2017</ref> <ref type="table">Table 3</ref>: Comparison on German→English.</p><note type="other">), where we achieve 32.0% BLEU on newstest2017. So far, RETURNN does not support this architecture; see Section 7 for details. toolkit BLEU [%] 2015 2017 RETURNN 31.2 31.3 Sockeye 29.7 30.2</note><p>We compare RETURNN to other toolkits on the WMT 2017 English→German translation task in <ref type="table">Table 4</ref>. We observe that our toolkit outper- forms all other toolkits. The best result obtained by other toolkits is using Marian (25.5% BLEU). In comparison, RETURNN achieves 26.1%. We also compare RETURNN to the best performing single systems of WMT 2017. In comparison to the fine-tuned evaluation systems that also include back-translated data, our model performs worse by only 0.3 to 0.9 BLEU. We did not run experiments with back-translated data, which can potentially boost the performance by several BLEU points.</p><p>We also have preliminary results with recur- rent attention models for speech recognition on the Switchboard task, which we trained on the 300h trainset. We report on both the Switch- board (SWB) and the CallHome (CH) part of Hub5'00 and Hub5'01. We also compare to a con- ventional frame-wise trained hybrid deep bidirec- <ref type="table">Table 4</ref>: Performance comparison on WMT 2017 English→German. The baseline systems (upper half) are trained on the parallel data of the WMT Enlgish→German 2017 task. We downloaded the hypotheses from here. <ref type="bibr">4</ref> The WMT 2017 system hypotheses (lower half) are generated using sys- tems having additional back-translation (bt) data. These hypotheses are downloaded from here. <ref type="bibr">5</ref> tional LSTM with 6 layers ( <ref type="bibr" target="#b30">Zeyer et al., 2017b)</ref>, and a generalized full-sum sequence trained hy- brid deep bidirectional LSTM with 5 layers (Zeyer et al., 2017a). The frame-wise trained hybrid model also uses focal loss ( <ref type="bibr">Lin et al., 2017)</ref>. All the hybrid models use a phonetic lexicon and an external 4-gram language model which was trained on the transcripts of both the Switchboard and the Fisher corpus. The attention model does not use any external language model nor a pho- netic lexicon. Its output labels are byte-pair en- coded subword units ( <ref type="bibr" target="#b21">Sennrich et al., 2015)</ref>. It has a 6 layer bidirectional encoder, which also applies max-pooling in the time dimension, i.e. it reduces the input sequence by factor 8. Pretraining as ex- plained in Section 6 was applied. To our knowl- edge, this is the best reported result for an end-to- end system on Switchboard 300h without using a language model or the lexicon. For comparison, we also selected comparable results from the lit- erature. From these, the Baidu DeepSpeech CTC model is modeled on characters and does not use the lexicon but it does use a language model. The results are collected in <ref type="table">Table 5</ref>. </p><note type="other">System BLEU [%] newstest2017 RETURNN 26.1 OpenNMT-py 21.8 OpenNMT-lua 22.6 Marian 25.6 Nematus 23.5 Sockeye 25.3 WMT 2017 Single Systems + bt data LMU 26.4 + reranking 27.0 Systran 26.5 Edinburgh 26.5</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Maximum expected BLEU training</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Pretraining</head><p>RETURNN supports very generic and flexible pretraining which iteratively starts with a small model and adds new layers in the process. A similar pretraining scheme for deep bidirectional LSTMs acoustic speech models was presented ear- lier ( <ref type="bibr" target="#b30">Zeyer et al., 2017b</ref>). Here, we only study a layer-wise construction of the deep bidirectional LSTM encoder network of an encoder-decoder- attention model for translation on the WMT 2017 German→English task. Experimental results are presented in <ref type="table">Table 6</ref>. The observations very clearly match our expectations, that we can both greatly improve the overall performance, and we are able to train deeper models. A minor benefit is faster training speed of the initial pretrain epochs. In preliminary recurrent attention experiments for speech recognition, pretraining seems very es- sential to get good performance.</p><p>Also, we use in all cases a learning rate schedul- ing scheme, which lowers the learning rate if the cross validation score does not improve enough. Without pretraining and a 2 layer encoder in the same setting as above, with a fixed learning rate, we get 28.4% BLEU, where-as with learning rate scheduling, we get 29.3% BLEU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">RETURNN features</head><p>Besides the fast speed, and the many features such as pretraining, scheduled sampling ( <ref type="bibr" target="#b2">Bengio et al., 2015)</ref>, label smoothing ( <ref type="bibr" target="#b22">Szegedy et al., 2016)</ref>, and the ability to train state-of-the-art models, one of the greatest strengths of RETURNN is its flexibil- ity. The definition of the recurrent dependencies and the whole model architecture are provided in a very explicit way via a config file. Thus, e.g. try- ing out a new kind of attention scheme, adding a new latent variable to the search space, or drasti- cally changing the whole architecture, is all sup- ported already and does not need any more im- plementation in RETURNN. All that can be ex- pressed by the neural network definition in the config. A (simplified) example of a network defi- nition is given in Listing 1.</p><p>Each layer in this definition does some com- putation, specified via the class attribute, and gets its input from other layers via the from at- tribute, or from the input data, in case of layer src. The output layer defines a whole subnet- work, which can make use of recurrent dependen- cies via a prev: prefix. Depending on whether training or decoding is done, the choice layer class would return the true labels or the predicted labels. In case of scheduled sampling or max BLEU training, we can also use the predicted label during training. Depending on this configuration, during compilation of the computation graph, RE- TURNN figures out that certain calculations can be moved out of the recurrent loop. This automatic optimization also adds to the speedup. This flexi- bility and ease of trying out new architectures and models allow for a very efficient development / re- search feedback loop. Fast, consistent and robust feedback greatly helps the productivity and qual- ity. This is very different to other toolkits which only support a predefined set of architectures.</p><p>To summarize the features of RETURNN:</p><p>• flexibility (see above),</p><p>• generality, wide range of models and appli-network = { # recurrent bidirectional encoder: "src": {"class": "linear", "n_out": 620}, # embedding "enc0_fw": {"class": "rec", "unit": "nativelstm2", "n_out": 1000, "direction": 1, "from": ["src"]}, "enc0_bw": {"class": "rec", "unit": "nativelstm2", "n_out": 1000, "direction": -1, "from": ["src"]}, # ... more encoder LSTM layers "encoder": {"class": "copy", "from": ["enc5_fw", "enc5_bw"]}, "enc_ctx": {"class": "linear", "from": ["encoder"], "n_out": 1000}, # recurrent decoder: "output": {"class": "rec", "from": [], "unit": { "output": {"class": "choice", "from": ["output_prob"]}, "trg": {"class": "linear", "from": ["output"], "n_out": 620, "initial_output": 0}, "weight_feedback": {"class": "linear", "from": ["prev:accum_a"], "n_out": 1000}, "s_tr": {"class": "linear", "from": ["s"], "n_out": 1000}, "e_in": {"class": "combine", "kind": "add", "from": ["base:enc_ctx", "weight_feedback", "s_tr"]}, "e_tanh": {"class": "activation", "activation": "tanh", "from": ["e_in"]}, "e": {"class": "linear", "from": ["e_tanh"], "n_out": 1}, "a": {"class": "softmax_over_spatial", "from": ["e"]}, "accum_a": {"class": "combine", "kind": "add", "from": ["prev:accum_a", "a"]}, "att": {"class": "generic_attention", "weights": "a", "base": "base:encoder"}, "s": {"class": "rnn_cell", "unit": "LSTMBlock", "from": ["prev:trg", "prev:att"], "n_out": 1000}, "readout": {"class": "linear", "activation": "relu", "from": ["s", "prev:trg", "att"], "n_out": 1000}, "output_prob": {"class": "softmax", "from": ["readout"], "dropout": 0.3, "loss": "ce", "loss_opts": {"label_smoothing": 0.1}} }}, "decision": {"class": "decide", "from": ["output"], "loss": "bleu"} } Listing 1: RETURNN config example for an attention model cations, such as hybrid acoustic speech mod- els, language models and attention models for translation and speech recognition, • fast CUDA LSTM kernels, • attention models, generic recurrent layer, fast beam search decoder, • sequence training (min WER, max BLEU), • label smoothing, scheduled sampling, • TensorFlow backend and the old Theano backend, which has a separate fast atten- tion implementation ( , fast CUDA MDLSTM kernels <ref type="bibr" target="#b28">(Voigtlaender et al., 2016)</ref>, as well as fast sequence training ( <ref type="bibr" target="#b31">Zeyer et al., 2017c</ref>). One feature which is currently work-in-progress is the support for self-attention in the recurrent layer. The reason this needs some more work is because we currently only support access to the previous time step (prev:) but not to the whole past, which is needed for self-attention. That is why we did not present any <ref type="bibr">Transformer (Vaswani et al., 2017</ref>) comparisons yet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>We have demonstrated many promising features of RETURNN and presented state-of-the-art systems in translation and speech recognition. We argue that it is a convenient testbed for research and ap- plications. We introduced pretraining for recurrent attention models and showed its advantages while not having any disadvantages. Maximum expected BLEU training seems to be promising.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>). The source code is fully open 1 . It can use Theano (Theano Development Team, 2016) or TensorFlow</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head></head><label></label><figDesc>minimization, following (Prabhavalkar et al., 2017; Edunov et al., 2017). The results are still preliminary but promising. We do the approxima- tion by beam search with beam size 4. For a 4 layer encoder network model, with forced align- ment cross entropy training, we get 30.3% BLEU, and when we use maximum expected BLEU train- ing, we get 31.1% BLEU.</figDesc><table>We implement expected risk minimization, i.e. 
expected BLEU maximization or expected WER model 
training 
WER [%] 
Hub5'00 
Hub5'01 
Σ SWB CH 
hybrid 1 frame-wise 
11.2 
hybrid 2 LF-MMI 15.8 10.8 
CTC 3 
CTC 
25.9 20.0 31.8 

hybrid frame-wise 14.4 9.8 19.0 14.7 
full-sum 15.9 10.1 21.8 14.5 
attention frame-wise 20.3 13.5 27.1 19.9 
Table 5: Performance comparison on Switch-
board, trained on 300h. hybrid 1 is the IBM 2017 
ResNet model (Saon et al., 2017). hybrid 2 trained 
with Lattice-free MMI (Hadian et al., 2018). 
CTC 3 is the Baidu 2014 DeepSpeech model (Han-
nun et al., 2014). Our attention model does not use 
any language model. 

</table></figure>

			<note place="foot" n="2"> https://github.com/rwth-i6/returnn-experiments/tree/ master/2018-attention</note>

			<note place="foot" n="4"> https://github.com/awslabs/sockeye/ tree/arxiv_1217/arxiv/output/rnn 5 http://matrix.statmt.org/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research has re-ceived funding from the European Research Council (ERC) (under the European Union's Horizon 2020 research and innovation pro-gramme, grant agreement No 694537, project "SEQCLAS") and the Deutsche Forschungsge-meinschaft (DFG; grant agreement NE 572/8-1, project "CoreTec"). Tamer Alkhouli was partly funded by the 2016 Google PhD fellowship for North America, Europe and the Middle East. The work reflects only the authors' views and none of the funding parties is responsible for any use that may be made of the information it contains.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The RWTH Aachen machine translation systems for IWSLT 2017</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parnia</forename><surname>Bahar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Rosendahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Rossenbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IWSLT</title>
		<meeting><address><addrLine>Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="29" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.0473</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Scheduled sampling for sequence prediction with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navdeep</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1171" to="1179" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Mxnet: A flexible and efficient machine learning library for heterogeneous distributed systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naiyan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianjun</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.01274</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Bidirectional decoder networks for attentionbased end-to-end offline handwriting recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Doetsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Zeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICFHR</title>
		<meeting><address><addrLine>Shenzhen, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="361" to="366" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">RETURNN: the RWTH extensible training framework for universal recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Doetsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Zeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Voigtlaender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilia</forename><surname>Kulikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralf</forename><surname>Schlüter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICASSP</title>
		<imprint>
			<biblScope unit="page" from="5345" to="5349" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Classical structured prediction losses for sequence to sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc&amp;apos;aurelio</forename><surname>Ranzato</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.04956</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Towards discriminativelytrained HMM-based end-to-end model for automatic speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hossein</forename><surname>Hadian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hossein</forename><surname>Sameti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Povey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Khudanpur</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Submitted to ICASSP</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">DeepSpeech: Scaling up end-to-end speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Awni</forename><surname>Hannun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Case</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jared</forename><surname>Casper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Catanzaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Diamos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erich</forename><surname>Elsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Prenger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shubho</forename><surname>Sengupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Coates</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.5567</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Neural monkey: An open-source tool for sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jindřich</forename><surname>Helcl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jindřich</forename><surname>Libovick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Prague Bulletin of Mathematical Linguistics</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="17" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Libovick`y</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Sockeye: A toolkit for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hieber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Domhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Denkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Vilar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Artem</forename><surname>Sokolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ann</forename><surname>Clifton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.05690</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Ierusalimschy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luiz</forename><surname>Henrique De Figueiredo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Waldemar</forename><surname>Celes</surname></persName>
		</author>
		<title level="m">Lua 5.1 Reference Manual. Lua.Org</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Is neural machine translation ready for deployment? a case study on 30 translation directions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Junczys-Dowmunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomasz</forename><surname>Dwojak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.01108</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Toward a full-scale neural machine translation in production: the booking. com use case</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nishikant</forename><surname>Dhanuka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Talaat</forename><surname>Khalil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fedor</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Khalilov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.05820</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nishikant</forename><surname>Dhanuka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Khalilov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.07911</idno>
		<title level="m">Machine translation at booking. com: Journey and lessons learned</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Kaiming He, and Piotr Dollár. 2017. Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.02002</idno>
		<imprint/>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The RWTH Aachen university english-german and german-english machine translation system for WMT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan-Thorsten</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Guta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamer</forename><surname>Alkhouli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parnia</forename><surname>Bahar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Rosendahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Rossenbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Graça</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ney</forename><surname>Hermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EMNLP</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Minimum word error rate training for attention-based sequence-to-sequence models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohit</forename><surname>Prabhavalkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghui</forename><surname>Sainath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chung-Cheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anjuli</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kannan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.01818</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
	<note>PyTorch Development Team. 2018. PyTorch. Software available from pytorch.org</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">English conversational telephone speech recognition by humans and machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Saon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gakuto</forename><surname>Kurata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Sercu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kartik</forename><surname>Audhkhasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitrios</forename><surname>Dimitriadis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhuvana</forename><surname>Ramabhadran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Picheny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lynn-Li</forename><surname>Lim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.02136</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Orhan</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Hitschler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Junczys-Dowmunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Läubli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Valerio Miceli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jozef</forename><surname>Barone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mokry</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.04357</idno>
		<title level="m">Nematus: a toolkit for neural machine translation. EACL Demo</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1508.07909</idno>
		<title level="m">Neural machine translation of rare words with subword units</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zbigniew</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2818" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">TensorFlow: Large-scale machine learning on heterogeneous systems</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>TensorFlow Development Team. Software available from tensorflow.org</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Theano: A Python framework for fast computation of mathematical expressions</title>
		<idno>abs/1605.02688</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Theano Development Team. arXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Modeling coverage for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francois</forename><surname>Chollet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Gouws</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.07416</idno>
		<title level="m">Tensor2tensor for neural machine translation</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6000" to="6010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Handwriting recognition with large multidimensional long short-term memory recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Voigtlaender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Doetsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICFHR</title>
		<meeting><address><addrLine>Shenzhen, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="228" to="233" />
		</imprint>
	</monogr>
	<note>IAPR Best Student Paper Award</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">CTC in the context of generalized fullsum HMM training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Zeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugen</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralf</forename><surname>Schlüter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Interspeech</title>
		<meeting><address><addrLine>Stockholm, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="944" to="948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A comprehensive study of deep bidirectional LSTM RNNs for acoustic modeling in speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Zeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Doetsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Voigtlaender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralf</forename><surname>Schlüter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP</title>
		<meeting><address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2462" to="2466" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Faster sequence training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Zeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilia</forename><surname>Kulikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralf</forename><surname>Schlüter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP</title>
		<meeting><address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5285" to="5289" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
