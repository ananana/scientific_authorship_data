<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T13:02+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Marian: Fast Neural Machine Translation in C++</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 15-20, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Junczys-Dowmunt</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Adam Mickiewicz University in Pozna´nPozna´n ‡ University of Edinburgh ¶ Unbabel</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roman</forename><surname>Grundkiewicz</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Adam Mickiewicz University in Pozna´nPozna´n ‡ University of Edinburgh ¶ Unbabel</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomasz</forename><surname>Dwojak</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Adam Mickiewicz University in Pozna´nPozna´n ‡ University of Edinburgh ¶ Unbabel</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Adam Mickiewicz University in Pozna´nPozna´n ‡ University of Edinburgh ¶ Unbabel</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Adam Mickiewicz University in Pozna´nPozna´n ‡ University of Edinburgh ¶ Unbabel</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Neckermann</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Adam Mickiewicz University in Pozna´nPozna´n ‡ University of Edinburgh ¶ Unbabel</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Seide</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Adam Mickiewicz University in Pozna´nPozna´n ‡ University of Edinburgh ¶ Unbabel</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Germann</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Adam Mickiewicz University in Pozna´nPozna´n ‡ University of Edinburgh ¶ Unbabel</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alham</forename><surname>Fikri</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Adam Mickiewicz University in Pozna´nPozna´n ‡ University of Edinburgh ¶ Unbabel</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aji</forename></persName>
							<affiliation key="aff0">
								<orgName type="institution">Adam Mickiewicz University in Pozna´nPozna´n ‡ University of Edinburgh ¶ Unbabel</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolay</forename><surname>Bogoychev</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Adam Mickiewicz University in Pozna´nPozna´n ‡ University of Edinburgh ¶ Unbabel</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">André</forename><forename type="middle">F T</forename><surname>Martins</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Adam Mickiewicz University in Pozna´nPozna´n ‡ University of Edinburgh ¶ Unbabel</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Adam Mickiewicz University in Pozna´nPozna´n ‡ University of Edinburgh ¶ Unbabel</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Microsoft</forename><surname>Translator</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Adam Mickiewicz University in Pozna´nPozna´n ‡ University of Edinburgh ¶ Unbabel</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Marian: Fast Neural Machine Translation in C++</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics-System Demonstrations</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics-System Demonstrations <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="116" to="121"/>
							<date type="published">July 15-20, 2018</date>
						</imprint>
					</monogr>
					<note>116</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present Marian, an efficient and self-contained Neural Machine Translation framework with an integrated automatic differentiation engine based on dynamic computation graphs. Marian is written entirely in C++. We describe the design of the encoder-decoder framework and demonstrate that a research-friendly toolkit can achieve high training and translation speed.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this paper, we present Marian, <ref type="bibr">1</ref> an efficient Neu- ral Machine Translation framework written in pure C++ with minimal dependencies. It has mainly been developed at the Adam Mickiewicz Univer- sity in Pozna´nPozna´n and at the University of Edinburgh. It is currently being deployed in multiple European projects and is the main translation and training engine behind the neural MT launch at the World Intellectual Property Organization. <ref type="bibr">2</ref> In the evolving eco-system of open-source NMT toolkits, Marian occupies its own niche best char- acterized by two aspects:</p><p>• It is written completely in C++11 and inten- tionally does not provide Python bindings; model code and meta-algorithms are meant to be implemented in efficient C++ code.</p><p>• It is self-contained with its own back end, which provides reverse-mode automatic dif- ferentiation based on dynamic graphs.</p><p>Marian has minimal dependencies (only Boost and CUDA or a BLAS library) and enables barrier- free optimization at all levels: meta-algorithms such as MPI-based multi-node training, efficient batched beam search, compact implementations of new models, custom operators, and custom GPU kernels. Intel has contributed and is optimizing a CPU backend.</p><p>Marian grew out of a C++ re-implementation of Nematus ( <ref type="bibr" target="#b13">Sennrich et al., 2017b)</ref>, and still main- tains binary-compatibility for common models. Hence, we will compare speed mostly against Ne- matus. <ref type="bibr">OpenNMT (Klein et al., 2017)</ref>, perhaps one of the most popular toolkits, has been reported to have training speed competitive to Nematus.</p><p>Marian is distributed under the MIT license and available from https://marian-nmt. github.io or the GitHub repository https: //github.com/marian-nmt/marian.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Design Outline</head><p>We will very briefly discuss the design of Marian. Technical details of the implementations will be provided in later work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Custom Auto-Differentiation Engine</head><p>The deep-learning back-end included in Marian is based on reverse-mode auto-differentiation with dynamic computation graphs and among the es- tablished machine learning platforms most similar in design to <ref type="bibr">DyNet (Neubig et al., 2017)</ref>. While the back-end could be used for other tasks than machine translation, we choose to optimize specifi- cally for this and similar use cases. Optimization on this level include for instance efficient imple- mentations of various fused RNN cells, attention mechanisms or an atomic layer-normalization ( <ref type="bibr">Ba et al., 2016</ref>) operator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Extensible Encoder-Decoder Framework</head><p>Inspired by the stateful feature function framework in Moses ( <ref type="bibr" target="#b9">Koehn et al., 2007)</ref>, we implement en- coders and decoders as classes with the following (strongly simplified) interface: A Bahdanau-style encoder-decoder model would implement the entire encoder inside Encoder::build based on the content of the batch and place the resulting encoder context inside the EncoderState object.</p><p>Decoder::startState receives a list of EncoderState (one in the case of the Bahdanau model, multiple for multi-source models, none for language models) and creates the initial DecoderState.</p><p>The Decoder::step function consumes the tar- get part of a batch to produce the output logits of a model. The time dimension is either expanded by broadcasting of single tensors or by looping over the individual time-steps (for instance in the case of RNNs). Loops and other control structures are just the standard built-in C++ operations. The same function can then be used to expand over all given time steps at once during training and scoring or step-by-step during translation. Current hypothe- ses state (e.g. RNN vectors) and current logits are placed in the next DecoderState object.</p><p>Decoder states are used mostly during transla- tion to select the next set of translation hypotheses. Complex encoder-decoder models can derive from DecoderState to implement non-standard selec- tion behavior, for instance hard-attention models need to increase attention indices based on the top- scoring hypotheses.</p><p>This framework makes it possible to combine different encoders and decoders (e.g. RNN-based encoder with a Transformer decoder) and reduces implementation effort. In most cases it is enough to implement a single inference step in order to train, score and translate with a new model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Efficient Meta-algorithms</head><p>On top of the auto-diff engine and encoder-decoder framework, we implemented many efficient meta- algorithms. These include multi-device (GPU or CPU) training, scoring and batched beam search, ensembling of heterogeneous models (e.g. Deep RNN models and Transformer or language models), multi-node training and more.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Case Studies</head><p>In this section we will illustrate how we used the Marian toolkit to facilitate our own research across several NLP problems. Each subsection is meant as a showcase for different components of the toolkit and demonstrates the maturity and flexibility of the toolkit. Unless stated otherwise, all mentioned features are included in the Marian toolkit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Improving over WMT2017 systems</head><p>Sennrich et al. (2017a) proposed the highest scor- ing NMT system in terms of BLEU during the WMT 2017 shared task on English-German news translation ( <ref type="bibr" target="#b12">Bojar et al., 2017a)</ref>, trained with the Nematus toolkit ( <ref type="bibr" target="#b13">Sennrich et al., 2017b)</ref>. In this section, we demonstrate that we can replicate and slightly outperform these results with an identi- cal model architecture implemented in Marian and improve on the recipe with a Transformer-style ( <ref type="bibr" target="#b15">Vaswani et al., 2017</ref>) model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Deep Transition RNN Architecture</head><p>The model architecture in <ref type="bibr" target="#b12">Sennrich et al. (2017a)</ref> is a sequence-to-sequence model with single-layer RNNs in both, the encoder and decoder. The RNN in the encoder is bi-directional. Depth is achieved by building stacked GRU-blocks resulting in very tall RNN cells for every recurrent step (deep transi- tions). The encoder consists of four GRU-blocks per cell, the decoder of eight GRU-blocks with an attention mechanism placed between the first and second block. As in <ref type="bibr" target="#b12">Sennrich et al. (2017a)</ref>, em- beddings size is 512, RNN state size is 1024. We use layer-normalization ( <ref type="bibr">Ba et al., 2016</ref>) and varia- tional drop-out with p = 0.1 (Gal and Ghahramani, 2016) inside GRU-blocks and attention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Transformer Architecture</head><p>We very closely follow the architecture described in <ref type="bibr" target="#b15">Vaswani et al. (2017)</ref> and their "base" model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Training Recipe</head><p>Modeled after the description <ref type="bibr">3</ref>     </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>h l e n S i e e i n e n T a s t a t u r - b e - f e h l -s s a t z i m M</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.4">Performance and Results</head><p>Quality. In terms of BLEU <ref type="table">(Table 1)</ref>, we match the original Nematus models from <ref type="bibr" target="#b12">Sennrich et al. (2017a)</ref>. Replacing the deep-transition RNN model with the transformer model results in a signifi- cant BLEU improvement of 1.2 BLEU on the WMT2017 test set.</p><p>Training speed. In <ref type="figure">Figure 1</ref> we demonstrate the training speed as thousands of source tokens per second for the models trained in this recipe. All model types benefit from using more GPUs. Scal- ing is not linear (dashed lines), but close. The tokens-per-second rate (w/s) for Nematus on the same data on a single GPU is about 2800 w/s for the shallow model. Nematus does not have multi- GPU training. Marian achieves about 4 times faster training on a single GPU and about 30 times faster training on 8 GPUs for identical models.</p><p>Translation speed. The back-translation of 10M sentences with a shallow model takes about four hours on 8 GPUs at a speed of about 15,850 source tokens per second at a beam-size of 5 and a batch size of 64. Batches of sentences are translated in parallel on multiple GPUs.</p><p>In <ref type="table" target="#tab_3">Table 2</ref> we report the total number of seconds to translate newstest-2017 (3,004 sentences, 76,501 source BPE tokens) on a single GPU for different batch sizes. We omit model load time (usually below 10s). Beam size is 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">State-of-the-art in Neural Automatic</head><p>Post-Editing</p><p>In our submission to the Automatic Post-Editing shared task at WMT-2017 ( <ref type="bibr" target="#b3">Bojar et al., 2017b</ref>) and follow-up work (Junczys-Dowmunt and Grund- kiewicz, 2017a,b), we explore multiple neural ar- chitectures adapted for the task of automatic post- editing of machine translation output as implemen- tations in Marian. We focus on neural end-to-end models that combine both inputs mt (raw MT out- put) and src (source language input) in a single neural architecture, modeling {mt, src} → pe di- rectly, where pe is post-edited corrected output.</p><p>These models are based on multi-source neural translation models introduced by <ref type="bibr" target="#b16">Zoph and Knight (2016)</ref>. Furthermore, we investigate the effect of hard-attention models or neural transductors <ref type="bibr" target="#b0">(Aharoni and Goldberg, 2016</ref>) which seem to be well- suited for monolingual tasks, as well as combina- tions of both ideas. Dual-attention models that are combined with hard attention remain competitive despite applying fewer changes to the input.</p><p>The encoder-decoder framework described in section 2.2, allowed to integrate dual encoders and hard-attention without changes to beam-search or ensembling mechanisms. The dual-attention mech- anism over two encoders allowed to recover miss- ing words that would not be recognized based on raw MT output alone, see <ref type="figure">Figure 2</ref>.</p><p>Our final system for the APE shared task scored second-best according to automatic metrics and best based on human evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">State-of-the-art in Neural Grammatical Error Correction</head><p>In Junczys-Dowmunt and Grundkiewicz (2018), we use Marian for research on transferring meth- ods from low-resource NMT on the ground of au- tomatic grammatical error correction (GEC). Pre- viously, neural methods in GEC did not reach state-of-the-art results compared to phrase-based SMT baselines. We successfully adapt several low- resource MT methods for GEC.</p><p>We propose a set of model-independent meth- ods for neural GEC that can be easily applied in most GEC settings. The combined effects of these methods result in better than state-of-the-art neu- ral GEC models that outperform previously best neural GEC systems by more than 8% M 2 on the CoNLL-2014 benchmark and more than 4.5% on the JFLEG test set. Non-neural state-of-the-art sys- tems are matched on the CoNLL-2014 benchmark and outperformed by 2% on JFLEG.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Future Work and Conclusions</head><p>We introduced Marian, a self-contained neural ma- chine translation toolkit written in C++ with focus on efficiency and research. Future work on Mar- ian's back-end will look at faster CPU-bound com- putation, auto-batching mechanisms and automatic kernel fusion. On the front-end side we hope to keep up with future state-of-the-art models.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 illustrates</head><label>3</label><figDesc>Figure 3 illustrates these results on the CoNLL2014 test set. To produce this graph, 40 GEC models (four per entry) and 24 language models (one per GEC model with pre-training) have been trained. The language models follow the decoder architecture and can be used for transfer learning, weighted decode-time ensembling and re-ranking. This also includes a Transformer-style language model with self-attention layers. Proposed methods include extensions to Marian, such as source-side noise, a GEC-specific weighted training-objective, usage of pre-trained embeddings, transfer learning with pre-trained language models, decode-time ensembling of independently trained GEC models and language models, and various deep architectures.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Comparison on the CoNLL-2014 test set for investigated methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>Figure 1: Training speed in thousands of source tokens per second for shallow RNN, deep RNN and Transformer model. Dashed line projects linear scale-up based on single-GPU performance. ory to maximize speed and memory usage. This guarantees that a chosen memory budget will not be exceeded during training. All models use tied embeddings between source, target and output embeddings (Press and Wolf, 2017). Contrary to Sennrich et al. (2017a) or Vaswani et al. (2017), we do not average check- points, but maintain a continuously updated expo- nentially averaged model over the entire training run. Following Vaswani et al. (2017), the learning rate is set to 0.0003 and decayed as the inverse square root of the number of updates after 16,000 updates. When training the transformer model, a linearly growing learning rate is used during the first 16,000 iterations, starting with 0 until the base learning rate is reached.</figDesc><table>from Sennrich et al. 
(2017a), we perform the following steps: System 
test2016 test2017 

UEdin WMT17 (single) 
33.9 
27.5 
+Ensemble of 4 
35.1 
28.3 
+R2L Reranking 
36.2 
28.3 

Deep RNN (single) 
34.3 
27.7 
+Ensemble of 4 
35.3 
28.2 
+R2L Reranking 
35.9 
28.7 

Transformer (single) 
35.6 
28.8 
+Ensemble of 4 
36.4 
29.4 
+R2L Reranking 
36.8 
29.5 

Table 1: BLEU results for our replication of the 
UEdin WMT17 system for the en-de news transla-
tion task. We reproduced most steps and replaced 
the deep RNN model with a Transformer model. 

• preprocessing of training data, tokenization, 
true-casing 4 , vocabulary reduction to 36,000 
joint BPE subword units (Sennrich et al., 
2016) with a separate tool. 5 
• training of a shallow model for back-
translation on parallel WMT17 data; 
• translation of 10M German monolingual news 
sentences to English; concatenation of artifi-
cial training corpus with original data (times 
two) to produce new training data; 
• training of four left-to-right (L2R) deep mod-
els (either RNN-based or Transformer-based); 
• training of four additional deep models with 
right-to-left (R2L) orientation; 6 
• ensemble-decoding with four L2R models re-
sulting in an n-best list of 12 hypotheses per 
input sentence; 
• rescoring of n-best list with four R2L models, 
all model scores are weighted equally; 
• evaluation on newstest-2016 (validation set) 
and newstest-2017 with sacreBLEU. 7 

We train the deep models with synchronous 
Adam on 8 NVIDIA Titan X Pascal GPUs with 
12GB RAM for 7 epochs each. The back-
translation model is trained with asynchronous 
Adam on 8 GPUs. We do not specify a batch size as 
Marian adjusts the batch based on available mem-0 

20 

40 

60 

80 

100 

12.4 

23.5 

35.3 

46.6 

54.8 

67.9 
73.0 

83.9 

Source tokens per second ×10 3 

Shallow RNN 

0 

20 

40 

60 

80 

100 

7.8 
13.1 
17.2 
22.8 
28.2 
33.4 37.1 

42.5 

Source tokens per second ×10 3 

Deep RNN 

1 2 3 4 5 6 7 8 
0 

20 

40 

60 

80 

100 

9.1 

16.4 
23.4 
30.4 

37.6 
42.9 
49.0 
54.9 

Number of GPUs 
Source tokens per second ×10 3 

Transformer 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Translation time in seconds for newstest-
2017 (3,004 sentences, 76,501 source BPE tokens) 
for different architectures and batch sizes. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>55 Best Sys-Comb</head><label></label><figDesc></figDesc><table>Best SMT 

Best NMT 

30.9 

41.7 

43.3 

47.8 48.0 

51.0 51.4 

54.1 

55.2 
56.1 

48.9 

50.3 50.6 

52.5 52.9 53.4 
51.7 

54.6 
55.5 55.9 

M 2 

Average of 4 
Ensemble of 4 
Ens. with LM 

</table></figure>

			<note place="foot" n="1"> Named after Marian Rejewski, a Polish mathematician and cryptologist who reconstructed the German military Enigma cipher machine sight-unseen in 1932. https:// en.wikipedia.org/wiki/Marian_Rejewski. 2 https://slator.com/technology/neuralconquers-patent-translation-in-majorwipo-roll-out/</note>

			<note place="foot" n="3"> The entire recipe is available in form of multiple scripts at https://github.com/marian-nmt/ marian-examples.</note>

			<note place="foot" n="4"> Proprocessing was performed using scripts from Moses (Koehn et al., 2007). 5 https://github.com/rsennrich/subwordnmt 6 R2L training, scoring or decoding does not require data processing, right-to-left inversion is built into Marian. 7 https://github.com/mjpost/sacreBLEU</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The development of Marian received funding from the Eu-ropean Union's Horizon 2020 Research and Innovation Pro-gramme under grant agreements <ref type="bibr">688139 (SUMMA;</ref><ref type="bibr">-2019</ref>, 645487 <ref type="bibr">(Modern MT;</ref><ref type="bibr">2015</ref>, <ref type="bibr">644333 (TraMOOC;</ref><ref type="bibr">2015</ref>, <ref type="bibr">644402 (HimL;</ref><ref type="bibr">2015</ref>, the Amazon Aca-demic Research Awards program (to Marcin Junczys-Dow-munt and Adam Lopez), and the World Intellectual Property Organization. The CPU back-end was contributed by Intel under a partnership with the Alan Turing Institute.</p><p>This research is based upon work supported in part by the Office of the Director of National Intelligence (ODNI), Intel-ligence Advanced Research Projects Activity (IARPA), via contract #FA8650-17-C-9117. The views and conclusions contained herein are those of the authors and should not be in-terpreted as necessarily representing the official policies, either expressed or implied, of ODNI, IARPA, or the U.S. Govern-ment. The U.S. Government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright annotation therein.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Sequence to sequence transduction with hard monotonic attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roee</forename><surname>Aharoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01487</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><forename type="middle">Lei</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><forename type="middle">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.06450</idno>
		<imprint/>
	</monogr>
<note type="report_type">ton. 2016. Layer normalization. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Buck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajen</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yvette</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Huck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Jimeno-Yepes</surname></persName>
		</author>
		<title level="m">Philipp Koehn, and Julia Kreutzer, editors. 2017a. Proc. of the 2nd Conference on Machine Translation</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajen</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yvette</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shujian</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Huck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varvara</forename><surname>Logacheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Rubino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Turchi</surname></persName>
		</author>
		<title level="m">Findings of the 2017 Conference on Machine Translation (WMT17). In Proceedings of the Second Conference on Machine Translation</title>
		<meeting><address><addrLine>Copenhagen</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="169" to="214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A theoretically grounded application of dropout in recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1019" to="1027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The AMU-UEdin submission to the WMT 2017 shared task on automatic post-editing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Junczys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Dowmunt</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roman</forename><surname>Grundkiewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Conference on Machine Translation</title>
		<meeting>the Second Conference on Machine Translation</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="639" to="646" />
		</imprint>
	</monogr>
	<note>Shared Task Papers</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An exploration of neural sequence-tosequence architectures for automatic post-editing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Junczys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Dowmunt</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roman</forename><surname>Grundkiewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Joint Conference on Natural Language Processing</title>
		<meeting>the Eighth International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="120" to="129" />
		</imprint>
	</monogr>
	<note>Asian Federation of Natural Language Processing</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Approaching neural grammatical error correction as a low-resource machine translation task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Junczys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Dowmunt</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roman</forename><surname>Grundkiewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT 2018</title>
		<meeting>NAACL-HLT 2018<address><addrLine>New Orleans, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Accepted for publication</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">OpenNMT: Opensource toolkit for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuntian</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Senellart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2017, System Demonstrations</title>
		<meeting>ACL 2017, System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="67" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Moses: Open source toolkit for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brooke</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wade</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Herbst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL. The Association for Computer Linguistics</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Austin</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Waleed</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonios</forename><surname>Anastasopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Clothiaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cynthia</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Garrette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingpeng</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adhiguna</forename><surname>Kuncoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaurav</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaitanya</forename><surname>Malaviya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuke</forename><surname>Oda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naomi</forename><surname>Saphra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.03980</idno>
		<title level="m">Swabha Swayamdipta, and Pengcheng Yin. 2017. DyNet: the dynamic neural network toolkit</title>
		<imprint/>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Using the output embedding to improve language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ofir</forename><surname>Press</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lior</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="157" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">The University of Edinburgh&apos;s neural MT systems for WMT17</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Currey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Germann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Valerio Miceli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Barone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bojar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="389" to="399" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Nematus: a toolkit for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Orhan</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Hitschler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Junczys-Dowmunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Läubli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Valerio Miceli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jozef</forename><surname>Barone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Mokry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nadejde</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Software Demonstrations of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the Software Demonstrations of the 15th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="65" to="68" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Neural machine translation of rare words with subword units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1715" to="1725" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Multi-source neural translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="30" to="34" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
