<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:28+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Discovery of Treatments from Text Corpora</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>August 7-12, 2016. 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Fong</surname></persName>
							<email>christianfong@stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
								<address>
									<addrLine>655 Serra Street Stanford</addrLine>
									<postCode>94305</postCode>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Grimmer</surname></persName>
							<email>jgrimmer@stanford.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">Stanford University</orgName>
								<address>
									<addrLine>616 Serra Street Stanford</addrLine>
									<postCode>94305</postCode>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Discovery of Treatments from Text Corpora</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1600" to="1609"/>
							<date type="published">August 7-12, 2016. 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>An extensive literature in computational social science examines how features of messages, advertisements, and other corpora affect individuals&apos; decisions, but these analyses must specify the relevant features of the text before the experiment. Automated text analysis methods are able to discover features of text, but these methods cannot be used to obtain the estimates of causal effects-the quantity of interest for applied researchers. We introduce a new experimental design and statistical model to simultaneously discover treatments in a corpora and estimate causal effects for these discovered treatments. We prove the conditions to identify the treatment effects of texts and introduce the supervised Indian Buffet process to discover those treatments. Our method enables us to discover treatments in a training set using a collection of texts and individuals&apos; responses to those texts, and then estimate the effects of these interventions in a test set of new texts and survey respondents. We apply the model to an experiment about candidate biographies, recovering intuitive features of voters&apos; decisions and revealing a penalty for lawyers and a bonus for military service.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Computational social scientists are often inter- ested in inferring how blocks of text, such as mes- sages from political candidates or advertising con- tent, affect individuals' decisions ( <ref type="bibr" target="#b2">Ansolabehere and Iyengar, 1995;</ref><ref type="bibr" target="#b21">Mutz, 2011;</ref><ref type="bibr" target="#b28">Tomz and Weeks, 2013)</ref>. To do so, they typically attempt to estimate the causal effect of the text: they model the out- come of interest, Y , as a function of the block of text presented to the respondent, t, and define the treatment effect of t relative to some other block of text t as Y (t) − Y (t ) <ref type="bibr" target="#b26">(Rubin, 1974;</ref><ref type="bibr">Holland, 1986)</ref>. For example, in industrial contexts researchers design A/B tests to compare two po- tential texts for a use case. Academic researchers often design one text that has a feature of inter- est and another text that lacks that feature but is otherwise identical (for example, <ref type="bibr" target="#b1">(Albertson and Gadarian, 2015)</ref>). Both kinds of experiments as- sume researchers already know the features of text to vary and offer little help to researchers who would like to discover the features to vary.</p><p>Topic models and related methods can discover important features in corpora of text data, but they are constructed in a way that makes it difficult to use the discovered features to estimate causal effects ( <ref type="bibr" target="#b4">Blei et al., 2003)</ref>. Consider, for exam- ple, supervised latent Dirichlet allocation (sLDA) <ref type="bibr" target="#b19">(Mcauliffe and Blei, 2007)</ref>. It associates a topic- prevalence vector, θ, with each document where the estimated topics depend upon both the con- tent of documents and a label associated with each document. If K topics are included in the model, then θ is defined on the K − 1-dimensional unit simplex. It is straightforward to define a treatment effect as the difference between two treatments θ and θ (or points on the simplex) Y (θ) − Y (θ ). It is less clear how to define the marginal effect of any one dimension. This is because bigger values on some dimensions implies smaller val- ues on other dimensions, making the effect of any one topic necessarily a combination of the differ- ences obtained when averaging across all the di- mensions <ref type="bibr" target="#b0">(Aitchison, 1986;</ref><ref type="bibr" target="#b18">Katz and King, 1999</ref>). This problem will befall all topic models because the zero-sum nature of the topic-prevalence vector implies that increasing the prevalence of any one topic necessarily decreases the prevalence of some other topic. The result is that it is difficult (or im- possible) to interpret the effect of any one topic marginalizing over the other topics. Other appli- cations of topic models to estimate causal effects treat text as the response, rather than the treatment ( <ref type="bibr" target="#b25">Roberts et al., 2016)</ref>. And still other methods re- quire a difficult to interpret assumption of how text might affect individuals' responses <ref type="bibr" target="#b3">(Beauchamp, 2011)</ref>.</p><p>To facilitate the discovery of treatments and to address the limitation of existing unsupervised learning methods, we introduce a new experimen- tal design, framework, and statistical model for discovering treatments within blocks of text and then reliably inferring the effects of those treat- ments. By doing so, we combine the utility of discovering important features in a topic model with the scientific value of causal treatment ef- fects estimated in a potential outcomes frame- work. We present a new statistical model-the su- pervised Indian Buffet Process-to both discover treatments in a training set and infer the effects treatments in a test set ( <ref type="bibr" target="#b11">Ghahramani and Griffiths, 2005</ref>). We prove that randomly assigning blocks of text to respondents in an experiment is suffi- cient to identify the effects of latent treatments that comprise blocks of text.</p><p>Our framework provides the first of its kind approach to automatically discover treatment ef- fects in text, building on literatures in both social science and machine learning ( <ref type="bibr" target="#b4">Blei et al., 2003;</ref><ref type="bibr" target="#b3">Beauchamp, 2011;</ref><ref type="bibr" target="#b19">Mcauliffe and Blei, 2007;</ref><ref type="bibr" target="#b25">Roberts et al., 2016)</ref>. The use of the training and test set ensures that this discovery does not come at the expense of credibly inferring causal effects, insulating the research design from con- cerns about "p-hacking" and overfitting <ref type="bibr" target="#b17">(Ioannidis, 2005;</ref><ref type="bibr" target="#b15">Humphreys et al., 2013;</ref><ref type="bibr" target="#b9">Franco et al., 2014</ref>). Critically, we use a theoretical justification for our methodology: we select our particular ap- proach because it enables us to estimate causal ef- fect of interest. Rather than demonstrating that our method performs better at some predictive task, we prove that our method is able to estimate useful causal effects from the data.</p><p>We apply our framework to study how features of a political candidate's background affect voters' decisions. We use a collection of candidate biogra- phies collected from Wikipedia to automatically discover treatments in the biographies and then in- fer their effects. This reveals a penalty for lawyers and career politicians and a bonus for military ser- vice and advanced degrees. While we describe our procedure throughout the paper, we summa- rize our experimental protocol and strategy for dis- covering treatment effects in <ref type="table" target="#tab_0">Table 1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">A Framework for Discovering Treatments from Text</head><p>Our goal is to discover a set of features- treatments-underlying texts and then estimate the effect of those treatments on some response from an individual. We first show that randomly assigning texts to respondents is sufficient to iden- tify treatment effects. We then provide a statistical model for using both the text and responses to dis- cover latent features in the text that affect the re- sponse. Finally, we show that we can use the map- ping from text to features discovered on a training set to estimate the presence of features in a test set, which allows us to estimate treatment effects in the test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Randomizing Texts Identifies Underlying Treatment Effects</head><p>When estimating treatment effects, researchers of- ten worry that the respondents who received one treatment systematically differ from those who re- ceived some other treatment. In a study of adver- tising, if all of the people who saw one advertise- ment were men and all of the people who saw a different advertisement were women, it would be impossible to tell whether differences in their re- sponses were driven by the fact that they saw dif- ferent advertisements or by their pre-existing dif- ferences. Randomized experiments are the gold standard for overcoming this problem (Gerber and Green, 2012). However, in text experiments, in- dividuals are randomly assigned to blocks of text rather than to the latent features of the text that we analyze as the treatments. In this section, we show that randomly assigning blocks of text is sufficient to identify treatment effects.</p><p>To establish our result, we suppose we have a corpora of J texts, X . We represent a specific text with X j ∈ X , with X j ∈ D . Through- out we will assume that we have standardized the variable X j to be a per-document word usage rate with each column normalized to have mean zero and variance one. We have a sample of N respon- dents from a population, with the response of in- dividual i to text j <ref type="bibr">[i]</ref> given by the potential out- come Y i (X j <ref type="bibr">[i]</ref> ). We use the notation j[i] because multiple individuals may be assigned to the same text; if i and i are assigned to the same text, then</p><formula xml:id="formula_0">j[i] = j[i ].</formula><p>We suppose that for each document j there is a corresponding vector of K binary treat- ments Z j ∈ Z where Z contains all 2 K possible combinations of treatments, {0, 1} K . The func- tion g : X → Z maps from the texts to the set of binary treatments: we will learn this function using the supervised Indian Buffet process intro- duced in the next section. Note that distinct ele- ments of X may map to the same element of Z.</p><p>To establish our identification result, we assume <ref type="bibr">i]</ref> ) for all i. This assumption ensures that each respondent's treat- ment assignment depends only on her assigned text, a version of the Stable Unit Treatment Value Assumption (SUTVA) for our application <ref type="bibr" target="#b27">(Rubin, 1986</ref>). We also assume (Assumption 2) that</p><formula xml:id="formula_1">(Assumption 1) Y i (X) = Y i (X j[</formula><formula xml:id="formula_2">Y i (X j[i] ) = Y i (g(X j[i] )) for all X j[i] ∈ X and all i, or that Z j[i]</formula><p>is sufficent to describe the effect of a document on individual i's response. Stated dif- ferently, we assume an individual would respond in the same way to two different texts if those texts have the same latent features. We further suppose (Assumption 3) that texts are randomly assigned to respondents according to probability measure h, ensuring that</p><formula xml:id="formula_3">Y i (g(X j[i] )) ⊥ ⊥ X j[i]</formula><p>for all X j[i] ∈ X and for all individuals i. This as- sumption ensures unobserved characteristics of in- dividuals are not confounding inferences about the effects of texts. The random assignment of texts to individuals induces a distribution over a prob- ability measure on treatment vectors Z,</p><formula xml:id="formula_4">f (Z) = X 1(Z = g(X))h(X)dX. Finally, we assume (Assumption 4) that f (Z) &gt; 0 for all Z ∈ Z. 1</formula><p>This requires that every combination of treatment effects is possible from the documents in our cor- pus. In practice, when designing our study we want to ensure that the treatments are not aliased or perfectly correlated. If perfect correlation exists between factors, we are unable to disentangle the effect of individual factors.</p><p>In this paper we focus on estimating the Average Marginal Component Specific Effect for factor k (AMCE k ) ( <ref type="bibr" target="#b13">Hainmueller et al., 2014</ref>). <ref type="bibr">2</ref> The AMCE k is useful for finding the effect of one feature, k, when k interacts with the other features in some potentially complicated way. It is defined as the differ- ence in outcomes when the feature is present and when it is not present, averaged over the val- ues of all of the other features. Formally,</p><formula xml:id="formula_5">AMCE k = Z −k E [Y (Z k = 1, Z −k ) − Y (Z k = 0, Z −k )] m(Z −k )dZ −k</formula><p>where m(Z −k ) is some analyst-defined density on all elements but k of the treatment vector. For example, m(·) can be chosen as the density of Z −k in the population to obtain the marginal component effect of k in the empirical population. The most commonly used m(·) in applied work is uniform across all Z −k 's, and we follow this convention here.</p><p>We now prove that assumptions 1, 2, 3, and 4 are sufficient to identify the AMCE k for all k. Proposition 1. Assumptions 1, 2, 3, and 4 are suf-ficient to identify the AMCE k for arbitrary k.</p><p>Proof. To obtain a useful form, we first marginalize over the documents to obtain,</p><formula xml:id="formula_6">Z −k X E [Y (Z k = 1, Z −k )] f (Z −k |Z k = 1, X) − E [Y (Z k = 0, Z −k )] f (Z −k |Z k = 0, X)h(X)dXdZ −k = Z −k E [Y (Z k = 1, Z −k )] f (Z −k |Z k = 1) −E [Y (Z k = 0, Z −k )] f (Z −k |Z k = 0)dZ −k . Where f (Z −k |Z k = 1) and f (Z −k |Z k = 0) are the induced distributions over latent features from averaging over documents. If f (Z −k |Z k = 0) = f (Z −k |Z k = 1) = m(Z −k ) then this is the AMCE k . Otherwise consider m(Z) &gt; 0 for all Z ∈ Z. Because f (Z) &gt; 0, f (Z −k |Z k = 0) &gt; 0 and f (Z −k |Z k = 1) &gt; 0. Thus, there exists con- ditional densities h(Z|Z k = 1) and h(Z|Z k = 0) such that f (Z −k |Z k =1) h(Z −k |Z k =1) = f (Z −k |Z k =0) h(Z −k |Z k =0) = m(Z −k )</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">A Statistical Model for Identifying Features</head><p>The preceding section shows that if we are able to discover features in the data, we can estimate their AMCEs by randomly assigning texts to re- spondents. We now present a statistical model for discovering those features. As we argued in the in- troduction, it is difficult to use the topics obtained from topic models like sLDA because the topic vector exists on the simplex. When we compare the outcomes associated with two different topic vectors, we do not know whether the change in the response is caused by increasing the degree to which the document about one topic or decreas- ing the degree to which it is about another, be- cause the former mathematically entails the latter. Other models, such as LASSO regression, would necessarily suppose that the presence and absence of words are the treatments ( <ref type="bibr" target="#b14">Hastie et al., 2001;</ref><ref type="bibr" target="#b3">Beauchamp, 2011)</ref>. This is problematic substan- tively, because it is hard to know exactly what the presence or absence of a single word implies as a treatment in text. We therefore develop the supervised Indian Buffet Process (sIBP) to discover features in the document. For our purposes, the sIBP has two es- sential properties. First, it produces a binary topic vector, avoiding the complications of treatments assigned on the simplex. Second, unlike the Indian Buffet Process upon which it builds <ref type="bibr" target="#b11">(Ghahramani and Griffiths, 2005</ref>), it incorporates information about the outcome associated with various texts, and therefore discovers features that explain both the text and the response. 3 <ref type="figure" target="#fig_0">Figure 1</ref> describes the posterior distribution for the sIBP and a summary of the posterior is given in Equation 1. We describe the model in three steps: the treatment assignment process, document cre- ation, and response. The result is a model that creates a link between document content and re- sponse through a vector of treatment assignments.</p><p>Treatment Assignment We assume that π is a K-vector (where we take the limit as K → ∞) where π k describes the population proportion of documents that contain latent feature k. We sup- pose that π is generated by the stick-breaking con- struction (Doshi- <ref type="bibr" target="#b8">Velez et al., 2009</ref>). Specifically, we suppose that η k ∼ Beta(α, 1) for all K. We label π 1 = η 1 and for each remaining topic, we assume that π k = k z=1 η z . For document j and topic k, we suppose that z j,k ∼ Bernoulli(π k ), which importantly implies that the occurrence of treatments are not zero sum. We collect the treat- ment vector for document j into Z j and collect all the treatment vectors into Z an N texts × K binary matrix, where N texts refers to number of unique documents. Throughout we will assume that N texts = N or that the number of documents and responses are equal and index the documents with i.</p><p>Document Creation We suppose that the doc- uments are created as a combination of latent factors. For topic k we suppose that A k is a D−dimensional vector that maps latent features onto observed text. We collect the vectors into A, a K × D matrix, and suppose that</p><formula xml:id="formula_7">X i ∼ MVN(Z i A, σ 2 n I D ), where X i,d</formula><p>is the standard- ized number of times word d appears in docu- ment i. While it is common to model texts as draws from multinomial distributions, the multi- Response to Treatment Vector We assume that a K−vector of parameters β describes the re- lationship between the treatment vector and re- sponse. Specifically, we use a standard parameter- ization and suppose that τ ∼ Gamma(a, b), β ∼ MVN(0, τ −1 ) and that Y i ∼ Normal(Z i β, τ −1 ).</p><formula xml:id="formula_8">π k ∼ Stick-Breaking (α) z i,k ∼ Bernoulli(π k ) X i |Z i , A ∼ MVN(Z i A, σ 2 X I D ) A k ∼ MVN(0, σ 2 A I D ) Y i |Z i , β ∼ Normal(Z i β, τ −1 ) τ ∼ Gamma(a, b) β|τ ∼ MVN(0, τ −1 I K )<label>(1)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Inference for the Supervised Indian Buffet Process</head><p>We approximate the posterior distribution with a variational approximation, building on the algorithm introduced in (Doshi- <ref type="bibr" target="#b8">Velez et al., 2009</ref>). We approximate the non- parametric posterior setting K to be large and use a factorized approximation, assuming that p(π, Z, A, β, τ |X, Y , α, σ 2 A , σ 2 X , a, b) = q(π)q(A)q(Z)q(β, τ )</p><p>A standard derivation that builds on (Doshi- <ref type="bibr" target="#b8">Velez et al., 2009</ref>) leads to the following distribu- tional forms and update steps:</p><formula xml:id="formula_9">• q(π K ) = Beta(π k |λ k ). The update values are λ k,1 = α K + N i=1 ν i,k and λ k,2 = 1 + N i=1 (1 − ν i,k ). • q(A k ) = Multivariate Normal(A k | ¯ φ k , Φ k ).</formula><p>The updated parameter values are,</p><formula xml:id="formula_10">¯ φ k = 1 σ 2 X N i=1 ν i,k X i − l:l =k ν i,l ¯ φ l Φ k Φ k = 1 σ 2 A + N i=1 ν i,k σ 2 X −1 I • q(β, τ ) = Multivariate Normal(β|m, S) × Gamma(τ |c, d).</formula><p>The updated parameter val- ues are,</p><formula xml:id="formula_11">m = SE[Z T ]Y S = (E[Z T Z] + I K ) −1 c = a + N 2 d = b + Y T Y − Y T E[Z]SE[Z T ]Y 2</formula><p>Where typical element of E[Z T ] j,k = ν j,k and typical on-diagonal element of</p><formula xml:id="formula_12">E[Z T Z] k,k = N i=1 ν i,k and off-diagonal el- ement is E[Z T Z] j,k = N i=1 ν i,j ν i,k . • q(z i,k ) = Bernoulli(z i,k |ν i,k ). The updated parameter values are v i,k = ψ(λ k,1 ) − ψ(λ k,2 ) − 1 2σ 2 X [−2 ¯ φ k X T i +(tr(Φ k ) + ¯ φ k ¯ φ T k ) + 2 ¯ φ k l:l =k ν i,l ¯ φ T l ] − c 2d (−2m k Y i + dS k,k c−1 + m T k m k + 2m k l:l =k ν i,l m l ) ν i,k = 1 1+exp(−v i,k )</formula><p>where ψ(·) is the digamma function. We re- peat the algorithm until the change in the pa- rameter vector drops below a threshold.</p><p>To select the final model using the training set data, we perform a two-dimensional line search over values of α and σ X . <ref type="bibr">4</ref> We then run the model several times for each combination of values for α and σ X to evaluate the output at several different local modes. To create a candidate set of models, we use a quantitative measure that balances coher- ence and exclusivity <ref type="bibr" target="#b20">(Mimno et al., 2011;</ref><ref type="bibr" target="#b24">Roberts et al., 2014</ref>). Let I k be the set of documents for which ν i,k ≥ 0.5, and let I C k be the complement of this set. We identify the top ten words for inter- vention k as the ten words with the largest value in A k , t k and define N k = N i=1 I{ν i,k ≥ 0.5}. We then obtain measure CE for a particular model</p><formula xml:id="formula_13">CE = K k=1 N k l,c∈t k cov(X I k ,l , X I k ,c ) − K k=1 (N − N k ) l,c∈t k cov(X I C k ,l , X I C k ,c )</formula><p>where here X I k ,l refers to the l th column and I k th rows of X. We make a final model selection based on the model that provides the most substantively clear treatments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Inferring Treatments and Estimating Effects in Test Set</head><p>To discover the treatment effects, we first suppose that we have randomly assigned a set of respon- dents a text based treatment X i according to some probability measure h(·) and that we have ob- served their response Y i . We collect the assigned texts into X and the responses into Y . As we de- scribe below, we will often assign each respondent their own distinctive message, with the probabil- ity of receiving any one message at 1 N for all re- spondents and messages. We use the sIBP model trained our training set documents and responses to infer the effect of those treatments among the test set documents. Separating the documents and responses into training and test sets ensures that Assumption 1, SUTVA, holds. We learn the map- ping from texts to binary vectors in the training set, ˆ g(·) and then apply this mapping to the test set to infer the latent treatments present in the test set documents, without considering the test set re- sponses. Dividing texts and responses into training and test sets provides a solution to SUTVA viola- tions present in other attempts at causal inference in text analysis ( <ref type="bibr" target="#b24">Roberts et al., 2014</ref>).</p><p>We approximate the posterior distribution for the treatment vectors using the variational approximation from the training set parameters</p><formula xml:id="formula_14">( λ, ¯ φ, Φ, m, S, c, d, σ 2 X , σ 2 A )</formula><p>and a modified update step on q(z test i,k ). In this modified update step, we remove the component of the update that incorporates information about the outcome. Specifically for individual i in the test set for category k we have the following update step</p><formula xml:id="formula_15">v test i,k = ψ( λ k,1 ) − ψ( λ k,2 ) − 1 2( σ 2 X ) × [−2 ¯ φ k (X T i ) + (tr( Φ k ) + ¯ φ k ( ¯ φ k ) T ) + 2 ¯ φ k l:l =k ν i,l ¯ φ l T ] ν test i,k = 1 1+exp(−v test i,k )</formula><p>.</p><p>For each text in the test set we repeat this update several times until ν test has converged. Note that for the test set we have excluded the component of the model that links the latent features to the response, ensuring that SUTVA holds. With the approximating distribution q(Z test ) we then measure the effect of the treatments in the test set. Using the treatments, the most straightforward model to estimate assumes that there are no inter- actions between each of the components. Under the no interactions assumption, we estimate the ef- fects of the treatments and infer confidence inter- vals using the following bootstrapping procedure that incorporates uncertainty both from estimation of treatments and uncertainty about the effects of those treatments: 1) For each respondent i and component k we draw˜zdraw˜ draw˜z i,k ∼ Bernoulli(ν test i,k ), resulting in ma- trix˜Ztrix˜ trix˜Z.</p><p>2) Given the matrix˜Zmatrix˜ matrix˜Z, we sample (Y test , ˜ Z) with replacement and for each sample esti- mate the regression Y test = β test˜Ztest˜ test˜Z + .</p><p>We repeat the bootstrap steps 1000 times, keeping β test for each iteration. The result of the proce- dure is a point estimate of the effects and confi- dence interval of the treatments under no interac- tions. Technically, it is possible to estimate the treatment effects in our variational approximation. But we estimate the effects in a second-stage re- gression because variational approximations tend to understate uncertainty, the bootstrap provides a straightforward method for including uncertainty from estimation of the latent features and the ef- fect estimates, and it ensures that SUTVA is not violated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Application: Voter Evaluations of an Ideal Candidate</head><p>We demonstrate our method in an experiment to assess how features of a candidate's background affect respondents evaluations of the candidates. There is a rich literature in political science about the ideal attributes of political candidates <ref type="bibr" target="#b6">(Canon, 1990;</ref><ref type="bibr" target="#b22">Popkin, 1994;</ref><ref type="bibr" target="#b7">Carnes, 2012;</ref><ref type="bibr" target="#b5">Campbell and Cowley, 2014</ref>). We build on this literature and use a collection of candidate biographies to discover features of candidates' backgrounds that voters find appealing. To uncover the features of can- didate biographies that voters are responsive to we acquired a collection of 1,246 Congressional candidate biographies from Wikipedia. We then anonymize the biographies-replacing names and removing other identifiable information-to en- sure that the only information available to the re- spondent was explicitly present in the text.</p><p>In Section 2.1 we show that a necessary con- dition for this experiment to uncover latent treat- ments is that each vector of treatments has non- zero probability of occuring. This is equivalent to assuming that none of the treatments are aliased, or perfectly correlated ( <ref type="bibr" target="#b13">Hainmueller et al., 2014</ref>). Aliasing would be more likely if there are only a few distinct texts that are provided to partici- pants in our experiment. Therefore, we assign each respondent in each evaluation round a dis- tinct candidate biography. To bolster our statis- tical power, we ask our respondents to evaluate up to four distinct candidate biographies, resulting in each respondent evaluating 2.8 biographies on average. <ref type="bibr">5</ref> After presenting the respondents with a candidate's biography, we ask each respondent to rate the candidate using a feeling thermometer: a well-established social science scale that goes from 0 when a respodent is "cold" to a candidate to 100 when a respondent is "warm" to the candi- date.</p><p>We recruited a sample of 1,886 participants us- ing Survey Sampling International (SSI), an online survey platform. Our sample is census matched to reflect US demographics on sex, age, race, and education. Using the sample we obtain 5,303 to- tal observations. We assign 2,651 responses to the training set and 2,652 to the test set. We then apply the sIBP process to the training data. To apply the model, we standardize the feeling thermometer to have mean zero and standard deviation 1. We set K to a relatively low value (K = 10) reflecting a quantitative and qualitative search over K. We then select the final model varying the parameters and evaluating the CE score. <ref type="table" target="#tab_2">Table 2</ref> provides the top words for each of the ten treatments the sIBP discovered in the training set. We selected ten treatments using a combina- tion of guidance from the sIBP, assessment using CE scores, and our own qualitative assessment of the models <ref type="bibr" target="#b12">(Grimmer and Stewart, 2013)</ref>. While it is true that our final selection depends on human input, some reliance on human judgment at this stage is appropriate. If one set includes a treat- ment about military service but not legal training and another set includes a treatment about legal training but not military service, then model selec- tion is tantamount to deciding which hypotheses are most worthy of investigation. Our CE scores identify sets of treatments that are most likely to be interesting, but the human analyst should make the final decision about which hypotheses he would like to test. However, it is extremely important for the analyst to select a set of treatments first and only afterwards estimate the effects of those treatments. If the analyst observes the effects of some treatments and then decides he would like to test other sets, then the integrity of any p-values he might calculate are undermined by the multi- ple testing problem. A key feature of our proce- dure is that it draws a clear line between the selec- tion of hypotheses to test (which leverages human judgment) and the estimation of effects (which is purely mechanical).</p><p>The estimated treatments cover salient features of Congressional biographies from the time period that we analyze. For example, treatments 6 and 10 capture a candidate's military experience. Treat- ment 5 and 7 are about previous political experi- ence and Treatment 3 and 9 refer to a candidate's education experience. Clearly, there are many fea- tures of a candidate's background missing, but the treatments discovered provide a useful set of di- mensions to assess how voters respond to a candi- date's background. Further, the discovered treat- ments are a combination of those that are both prevalent in the biographies and have an effect on the thermometer rating. The absence of biograph- ical features that we might think matters for can- didate evaluation could be because there are few of those biographies in our data set, or because the respondents were unresponive to those features.</p><p>After training the model on the training set, we apply it to the test set to infer the treatments in the biographies. We assume there are no interactions  <ref type="table" target="#tab_2">Treatment 2 Treatment 3  Treatment 4  Treatment 5  appointed  fraternity  director  received  elected  school graduated distinguished  university  washington university  house  governor  war ii  received  years  democratic  worked  chapter  president  death  seat  older  air force  master arts  company  republican  law firm  phi  phd  training  served  elected  reserve  policy  military  committee  grandfather  delta  public  including  appointed  office  air  master  george washington  defeated  legal</ref>    between the discovered treatments in order to es- timate their effects. 6 <ref type="figure" target="#fig_2">Figure 2</ref> shows the point es- timate and 95-percent confidence intervals, which take into account uncertainty in inferring the treat- ments from the texts and the relationship between those treatments and the response.</p><p>The treatment effects reveal intuitive, though in- teresting, features of candidate biographies that af- fect respondent's evaluations. For example, Fig- ure 2 reveals a distaste for political and legal experience-even though a large share of Con- gressional candidates have previous political ex-perience and a law degree. Treatment 5, which de- scribes a candidate's previous political experience, causes an 2.26 point reduction in feeling ther- mometer evaluation (95 percent confidence inter- val, <ref type="bibr">[-4.26,-0.24]</ref>). Likewise, Treatment 9 shows that respondents dislike lawyers, with the presence of legal experience causing a 2.34 point reduction in feeling thermometer (95-percent confidence in- terval, <ref type="bibr">[-4.28,-0.29]</ref>). The aversion to lawyers is not, however, an aversion to education. Treat- ment 3, a treatment that describes advanced de- grees, causes a 2.43 point increase in feeling ther- mometer evaluations (95-percent confidence inter- val, <ref type="bibr">[0.49,4.38]</ref>). In contrast, <ref type="figure" target="#fig_2">Figure 2</ref> shows that there is a con- sistent bonus for military experience. This is consistent with intuition from political observers that the public supports veterans. For exam- ple, treatment 6, which describes a candidate's military record, causes a 3.21 point increase in feeling thermometer rating (95-percent confidence interval, <ref type="bibr">[1.34,5.12]</ref>) and treatment 10 causes a 4.00 point increase (95-percent confidence inter- val, <ref type="bibr">[1.53,6.45]</ref>).</p><p>Because simultaneously discovering treatments from labeled data and estimating their average marginal component effects is a novel task, we cannot compare the performance of our frame- work against any benchmark. Even so, one natu- ral question is whether the user could obtain much more coherent topics by foresaking the estimation of causal effects and using a more traditional topic modeling method. We provide the topics discov- ered by sLDA in <ref type="table" target="#tab_4">Table 3</ref>. sIBP discovered most of the same features sLDA did. Both find military service, legal training, political background, and higher education. The Greek life feature is less co- herent in sIBP than it is in sLDA, and sLDA finds business and ancestry features that sIBP does not. Both have a few incoherent treatments. This com- parison suggests that sIBP does almost as well as sLDA at identifying coherent latent features, while also facilitating the estimation of marginal treat- ment effects.  <ref type="table" target="#tab_0">Treatment 2  Treatment 3  Treatment 4  Treatment 5  years  father  school  family  united states  work  née  medical  father  states army  national  mother  college  white  served united  worked  business  public schools  parents  war  board  irish  attended  year  war ii  young  son  county  mother  army  local  long  city  brother  served  director  family  born  married  service  social  ancestry  schools  years  lieutenant  community  descent  studied  played  military  Treatment 6  Treatment 7  Treatment 8  Treatment 9  Treatment 10  fraternity  elected  company  board  law school  member  republican  officer  graduated  law  student  served  united</ref>   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Graphical Model for the Supervised Indian Buffet Process</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: 95% Confidence Intervals for Effects of Discovered Treatments: The mean value of the feeling thermometer is 62.3</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Experimental Protocol for Discovering 
and Estimating Treatment Effects 

1) Randomly assign texts, X j , to respon-
dents 

2) Obtain response Y i for each respondent. 

3) Divide texts and responses into training 
and test set 

4) In training set: 

a) Use supervised Indian Buffet Pro-
cess (sIBP) applied to documents 
and responses to infer latent treat-
ments in texts 
b) Model selection via quantitative fit 
and qualitative assessment 

5) In test set: 

a) Use sIBP trained on training set to 
infer latent treatments on test set 
documents 
b) Estimate effect of treatments with 
regression, with a bootstrap proce-
dure to estimate uncertainty 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Top Words for 10 Treatments sIBP Discovered 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 : Top Words for 10 Treatments sLDA Discovered</head><label>3</label><figDesc></figDesc><table>Paul Holland. 1986. Statistics and causal infer-
ence. Journal of the American Statistical Associa-
tion, 81(396):945-960. </table></figure>

			<note place="foot" n="1"> Note for this assumption to hold it is necessary, but not sufficient that g is a surjection from X onto Z. 2 The procedure here can be understood as a method for discovering the treatments that are imposed by assumption in conjoint analysis, as presented by (Hainmueller et al., 2014). We deploy the regression estimator used in conjoint analysis as a subroutine of our procedure (see Step 5b in Table 1), but otherwise our experimental design, statistical method, and proof is distinct.</note>

			<note place="foot" n="3"> We note that there is a different model also called the supervised Indian Buffet Process (Quadrianto et al., 2013). There are fundamental differences between the model presented here and the sIBP in (Quadrianto et al., 2013). Their outcome is a preference relation tuple, while ours is a realvalued scalar. Because of this difference, the two models are fundamentally different. This leads to a distinct data generating process, model inference procedures, and inferences of features on the test set. To leverage the analogy between LDA and sLDA vis a vis IBP and sIBP, we overload the term sIBP in our paper. We expect that in future applications of sIBP, it will be clear from the context which sIBP is being employed.</note>

			<note place="foot" n="4"> We assign σA, a, and b values which lead to diffuse priors.</note>

			<note place="foot" n="5"> The multiple evaluations of candidate biographies is problematic if there is spillover across rounds of our experiment. We have little reason to believe observing one candidate biography would systematically affect the response in subsequent rounds.</note>

			<note place="foot" n="6"> This assumption is not necessary for the framework we propose here. Interaction effects could be modeled, but it would require us to make much stronger parametric assumptions using a method for heterogeneous treatments such as (Imai and Ratkovic, 2013).</note>

			<note place="foot" n="4"> Conclusion We have presented a methodology for discovering treatments in text and then inferring the effect of those treatments on respondents&apos; decisions. We prove that randomizing texts is sufficient to identify the underlying treatments and introduce the supervised Indian Buffet process for discovering the effects. The use of a training and test set ensures that our method provides accurate confidence intervals and avoids the problems of overfitting or &quot;p-hacking&quot; in experiments. In an application to candidate biographies, we discover a penalty for political and legal experience and a bonus for military service and non-legal advanced degrees. Our methodology has a wide variety of applications. This includes numerous alternative experimental designs, providing a methodology that computational social scientists could use widely to discover and then confirm the effects of messages in numerous domains-including images and other high dimensional data. The methodology is also useful for observational data-for studying the effects of complicated treatments, such as how a legislator&apos;s roll call voting record affects their electoral support.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This material is based upon work supported by the National Science Foundation Graduate Research Fellowship under Grant No. DGE-114747. Any opinions, findings, and conclusions or recommen-dations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">The Statistical Analysis of Compositional Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Aitchison</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
			<publisher>Chapman and Hall</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bethany</forename><surname>Albertson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shana</forename><forename type="middle">Kushner</forename><surname>Gadarian</surname></persName>
		</author>
		<title level="m">Anxious Politics: Democratic Citizenship in a Threatening World</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Going Negative: How Political Advertisements Shrink and Polarize The Electorate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Ansolabehere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanto</forename><surname>Iyengar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<publisher>Simon &amp; Schuster, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">A bottom-up approach to linguistic persuasion in advertising. The Political Methodologist</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Beauchamp</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Latent dirichlet allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning and Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">What voters want: Reactions to candidate characteristics in a survey experiment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rosie</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Cowley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Political Studies</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="745" to="765" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Actors, Athletes, and Astronauts: Political Amateurs in the United States Congress</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">T</forename><surname>Canon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<publisher>University of Chicago Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Does the numerical underrepresentation of the working class in congress matter?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carnes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Legislative Studies Quarterly</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="34" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Variational inference for the indian buffet process</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Finale</forename><surname>Doshi-Velez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><forename type="middle">T</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jurgen</forename><surname>Van Gael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee</forename><forename type="middle">Whye</forename><surname>Teh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
		<respStmt>
			<orgName>University of Cambridge</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Publication bias in the social sciences: Unlocking the file drawer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Annie</forename><surname>Franco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Malhotra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Simonovits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">345</biblScope>
			<biblScope unit="issue">6203</biblScope>
			<biblScope unit="page" from="1502" to="1505" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Field Experiment: Design, Analysis, and Interpretation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">S</forename><surname>Gerber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><forename type="middle">P</forename><surname>Green</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>W.W. Norton &amp; Company</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Infinite latent feature models and the indian buffet process</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="475" to="482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Text as data: The promise and pitfalls of automatic content analysis methods for political texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Grimmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brandon</forename><forename type="middle">M</forename><surname>Stewart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Political Analysis</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="267" to="297" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Causal inference in conjoint analysis: Understanding multi-dimensional choices via stated preference experiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Hainmueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Hopkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teppei</forename><surname>Yamamoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Political Analysis</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="30" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerome</forename><surname>Friedman</surname></persName>
		</author>
		<title level="m">The Elements of Statistical Learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Fishing, commitment, and communication: A proposal for comprehensive nonbinding research registration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Macartan</forename><surname>Humphreys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raul</forename><surname>Sanchez De La</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sierra</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Van Der Windt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Political Analysis</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Estimating treatment effect heterogeneity in randomized program evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kosuke</forename><surname>Imai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Ratkovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Applied Statistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="443" to="470" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Why most published research findings are false</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ioannidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Medicine</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="696" to="701" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A statistical model for multiparty electoral data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary</forename><surname>King</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Political Science Review</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="15" to="32" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Supervised topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><forename type="middle">D</forename><surname>Mcauliffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">20</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Optimizing semantic coherence in topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mimno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hanna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edmund</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miriam</forename><surname>Talley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Leenders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="262" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Population-Based Survey Experiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Diana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mutz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Princeton University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">The Reasoning Voter: Communication and Persuasion in Presidential Campaigns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Samuel L Popkin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<publisher>University of Chicago Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">The supervised ibp: Neighbourhood preserving infinite latent feature models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Novi</forename><surname>Quadrianto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viktoriia</forename><surname>Sharmanska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">A</forename><surname>Knowles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page">101</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Topic models for open ended survey responses with applications to experiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Margaret E Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brandon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dustin</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Tingley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jetson</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bethany</forename><surname>Leder-Luis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shana</forename><surname>Albertson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Gadarian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Journal of Political Science</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A model of text for experimentation in the social sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><forename type="middle">E</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brandon</forename><forename type="middle">M</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edo</forename><forename type="middle">M</forename><surname>Airoldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association. Forthcoming</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Estimating causal effects of treatments in randomized and nonrandomized studies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Don</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Educational Psychology</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="688" to="701" />
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Statistics and causal inference: Comment: Which ifs have causal answers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Donald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">396</biblScope>
			<biblScope unit="page" from="961" to="962" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Public opinion and the democratic peace</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Tomz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jessica</forename><surname>Weeks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Political Science Review</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="849" to="865" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
