<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:29+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Zero-shot Learning of Classifiers from Natural Language Quantification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 15-20, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shashank</forename><surname>Srivastava</surname></persName>
							<email>ssrivastava@cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15213</postCode>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><surname>Labutov</surname></persName>
							<email>ilabutov@cs.cmu.edu tom.mitchell@cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15213</postCode>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Mitchell</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15213</postCode>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Zero-shot Learning of Classifiers from Natural Language Quantification</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="306" to="316"/>
							<date type="published">July 15-20, 2018</date>
						</imprint>
					</monogr>
					<note>306</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Humans can efficiently learn new concepts using language. We present a framework through which a set of explanations of a concept can be used to learn a classifier without access to any labeled examples. We use semantic parsing to map explanations to probabilistic assertions grounded in latent class labels and observed attributes of unlabeled data, and leverage the differential semantics of linguistic quantifiers (e.g., &apos;usually&apos; vs &apos;always&apos;) to drive model training. Experiments on three domains show that the learned classifiers outperform previous approaches for learning with limited data, and are comparable with fully supervised classifiers trained from a small number of labeled examples.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>As computer systems that interact with us in nat- ural language become pervasive (e.g., Siri, Alexa, Google Home), they suggest the possibility of let- ting users teach machines in language. The abil- ity to learn from language can enable a paradigm of ubiquitous machine learning, allowing users to teach personalized concepts (e.g., identifying 'im- portant emails' or 'project-related emails') when limited or no training data is available.</p><p>In this paper, we take a step towards solving this problem by exploring the use of quantifiers to train classifiers from declarative language. For il- lustration, consider the hypothetical example of a user explaining the concept of an "important email" through natural language statements <ref type="figure">(Fig- ure 1)</ref>. Our framework takes a set of such natural language explanations describing a concept (e.g., "emails that I reply to are usually important") and a set of unlabeled instances as input, and produces <ref type="figure">Figure 1</ref>: Supervision from language can enable concept learning from limited or even no labeled examples. Our approach assumes the learner has sensors that can extract attributes from data, such as those listed in the table, and language that can refer to these sensors and their values. a binary classifier (for important emails) as output. Our hypothesis is that language describing con- cepts encodes key properties that can aid statistical learning. These include specification of relevant attributes (e.g., whether an email was replied to), relationships between such attributes and concept labels (e.g., if a reply implies the class label of that email is 'important'), as well as the strength of these relationships (e.g., via quantifiers like 'often', 'sometimes', 'rarely'). We infer these properties automatically, and use the semantics of linguis- tic quantifiers to drive the training of classifiers without labeled examples for any concept. This is a novel scenario, where previous approaches in semi-supervised and constraint-based learning are not directly applicable. Those approaches require manual pre-specification of expert knowledge for model training. In our approach, this knowledge is automatically inferred from noisy natural language explanations from a user.</p><p>Our approach is summarized in the schematic in <ref type="figure" target="#fig_0">Figure 2</ref>. First, we map the set of natural lan- guage explanations of a concept to logical forms that identify the attributes mentioned in the explana- tion, and describe the information conveyed about the attribute and the concept label as a quantitative constraint. This mapping is done through semantic parsing. The logical forms denote quantitative con- straints, which are probabilistic assertions about observable attributes of the data and unobserved concept labels. Here the strength of a constraint is assumed to be specified by a linguistic quanti- fier (such as 'all', 'some', 'few', etc., which reflect degrees of generality of propositions). Next, we train a classification model that can assimilate these constraints by adapting the posterior regularization framework ( <ref type="bibr" target="#b9">Ganchev et al., 2010)</ref>.</p><p>Intuitively, this can be seen as defining an op- timization problem, where the objective is to find parameter estimates for the classifier that do not simply fit the data, but also agree with the human provided natural language advice to the greatest ex- tent possible. Since logical forms can be grounded in a variety of sensors and external resources, an explicit model of semantic interpretation concep- tually allows the framework to subsume a flexible range of grounding behaviors. The main contribu- tions of this work are:</p><p>1. We introduce the problem of zero-shot learn- ing of classifiers from language, and present an approach towards this. 2. We develop datasets for zero-shot classifi- cation from natural descriptions, exhibiting tasks with various levels of difficulty. 3. We empirically show that coarse probability estimates to model linguistic quantifiers can effectively supervise model training across three domains of classification tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Many notable approaches have explored incorpo- ration of background knowledge into the training of learning algorithms. However, none of them ad- dresses the issue of learning from natural language. Prominent among these are the Constraint-driven learning ( <ref type="bibr" target="#b5">Chang et al., 2007a</ref>), Generalized Expec- tation ( <ref type="bibr" target="#b20">Mann and McCallum, 2010)</ref> and Posterior Regularization ( <ref type="bibr" target="#b9">Ganchev et al., 2010</ref>) and Bayesian Measurements ( <ref type="bibr" target="#b16">Liang et al., 2009)</ref> frameworks. All of these require domain knowledge to be manually programmed in before learning. Similarly, Prob- abilistic Soft Logic ( <ref type="bibr" target="#b11">Kimmig et al., 2012</ref>) allows users to specify rules in a logical language that can be used for reasoning over graphical models. More recently, multiple approaches have explored few- shot learning from perspective of term or attribute- based transfer <ref type="bibr" target="#b14">(Lampert et al., 2014</ref>), or learning representations of instances as probabilistic pro- grams ( <ref type="bibr" target="#b13">Lake et al., 2015</ref>). Other work <ref type="bibr" target="#b15">(Lei Ba et al., 2015;</ref><ref type="bibr">Elhoseiny et al., 2013</ref>) considers language terms such as colors and textures that can be directly grounded in visual meaning in images. Some previous work <ref type="bibr" target="#b23">(Srivastava et al., 2017</ref>) has explored using language ex- planations for feature space construction in concept learning tasks, where the problem of learning to in- terpret language, and learning classifiers is treated jointly. However, this approach assumes availabil- ity of labeled data for learning classifiers. Also notable is recent work by <ref type="bibr" target="#b0">Andreas et al. (2017)</ref>, who propose using language descriptions as param- eters to model structure in learning tasks in multiple settings. More generally, learning from language has also been previously explored in tasks such as playing games <ref type="bibr" target="#b4">(Branavan et al., 2012</ref>), robot navigation ( <ref type="bibr" target="#b10">Karamcheti et al., 2017)</ref>, etc.</p><p>Natural language quantification has been studied from multiple perspectives in formal logic ( <ref type="bibr" target="#b2">Barwise and Cooper, 1981)</ref>, linguistics <ref type="bibr" target="#b19">(Löbner, 1987;</ref><ref type="bibr" target="#b1">Bach et al., 2013</ref>) and cognitive psychology <ref type="bibr" target="#b12">(Kurtzman and MacDonald, 1993)</ref>. While quantification has traditionally been defined in set-theoretic terms in linguistic theories 1 , our approach joins alternative perspectives that represent quantifiers probabilis- tically ( <ref type="bibr" target="#b21">Moxey and Sanford, 1993;</ref><ref type="bibr" target="#b26">Yildirim et al., 2013)</ref>. To the best of our knowledge, this is the first work to leverage the semantics of quantifiers to guide statistical learning models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Learning Classifiers from Language</head><p>Our approach relies on first mapping natural lan- guage descriptions to quantitative constraints that specify statistical relationships between observable attributes of instances and their latent concept la- bels (Step 1 in <ref type="figure" target="#fig_0">Figure 2</ref>). These quantitative con- straints are then imbued into the training of a classi- fier by guiding predictions from the learned models to concur with them (Step 2). We use semantic parsing to interpret sentences as quantitative con- straints, and adapt the posterior regularization prin- ciple for our setting to estimate the classifier param- eters. Next, we describe these steps in detail. Since learning in this work is largely driven by the seman- tics of linguistic quantifiers, we call our approach Learning from Natural Quantification, or LNQ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Mapping language to constraints</head><p>A key challenge in learning from language is con- verting free-form language to representations that can be reasoned over, and grounded in data. For example, a description such as 'emails that I re- ply to are usually important' may be converted to a mathematical assertion such as P (important | replied : true) = 0.7', which statistical methods can reason with. Here, we argue that this process can be automated for a large number of real-world descriptions. In interpreting statements describing concepts, we infer the following key elements:</p><p>1. Feature x, which is grounded in observed at- tributes of the data. For our example, 'emails replied to' can refer to a predicate such as replied:true, which can be evaluated in con- text of emails to indicate the whether an email was replied to. Incorporating compositional rep- resentations enables more complex reasoning. e.g., 'the subject of course-related emails usu- ally mentions CS100' can map to a composite predicate like 'isStringMatch(field:subject, stringVal('CS100'))' , which can be evaluated for different emails to reflect whether their sub- ject mentions 'CS100'. Mapping language to ex- ecutable feature functions has been shown to be effective ( <ref type="bibr" target="#b23">Srivastava et al., 2017)</ref>. For sake of sim- plicity, here we assume that a statement refers to a single feature, but the method can be extended to handle more complex descriptions. 2. Concept label y, specifying the class of in- stances a statement refers to. For binary classes, this reduces to examples or non-examples of a con- cept. For our running example, y corresponds to the positive class of important emails. 3. Constraint-type asserted by the statement. We argue that most concept descriptions belong to one of three categories shown in <ref type="table" target="#tab_1">Table 2</ref>, and these con- stitute our vocabulary of constraint types for this work. For our running example ('emails that I reply to are usually important'), the type corresponds to P (y | x), since the syntax of the statement indi- cates an assertion conditioned on the feature indi- cating whether an email was replied to. On the other hand, an assertion such as 'I usually reply to important emails' indicates an assertion condi- tioned on the set important emails, and therefore corresponds to the type P (x | y). 4. Strength of the constraint. We assume this to be specified by a quantifier. For our running ex- ample, this corresponds to the adverb 'usually'. In this work, by quantifier we specifically refer to frequency adverbs ('usually','rarely', etc.) and fre- quency determiners ('few', 'all', etc.). <ref type="bibr">2</ref> Our thesis is that the semantics of quantifiers can be leveraged to make statistical assertions about relationships involving attributes and concept labels. One way to do this might be to simply associate point esti- mates of probability values, suggesting the fraction of truth values for assertions described with these quantifiers. <ref type="table">Table 1</ref> shows probability values we assign to some common frequency quantifiers for English. These values were set simply based on the authors' intuition about their semantics, and do not reflect any empirical distributions. See Fig- ure 8 for empirical distributions corresponding to some linguistic quantifiers in our data. While these probability values maybe inaccurate, and the se- mantics of these quantifiers may also change based on context and the speaker, they can still serve as a strong signal for learning classifiers since they are not used as hard constraints, but serve to bias classifiers towards better generalization.</p><p>We use a semantic parsing model to map state- ments to formal semantic representations that spec- ify these aspects. For example, the statement 'Emails that I reply to are usually important' is  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Semantic Parser components</head><p>Given a descriptive statement s, the parsing prob- lem consists of predicting a logical form l that best represents its meaning. In turn, we formulate the probability of the logical form l as decomposing into three component factors: (i) probability of observing a feature and concept labels l xy based on the text of the sentence, (ii) probability of the type of the assertion l type based on the identified feature, concept label and syntactic properties of the sentence s, and (iii) identifying the linguistic quantifier, l quant , in the sentence.</p><formula xml:id="formula_0">P (l | s) = P (l xy | s) P (l type | l xy , s) P (l quant | s)</formula><p>We model each of the three components as fol- lows: by using a traditional semantic parser for the first component, training a Max-Ent classifier for the constraint-type for the second component, and looking for an explicit string match to identify the quantifier for the third component.</p><p>Identifying features and concept labels, l xy : For identifying the feature and concept label men- tioned in a sentence, we presume a linear score S(s, l xy ) = w T ψ(s, l xy ) indicating the goodness of assigning a partial logical form, l xy , to a sen- tence s. Here, ψ(s, l xy ) ∈ R n are features that can depend on both the sentence and the partial logical form, and w ∈ R n is a parameter weight-vector for this component. Following recent work in semantic parsing ( <ref type="bibr" target="#b17">Liang et al., 2011</ref>), we assume a loglinear distribution over interpretations of a sentence.</p><formula xml:id="formula_1">P (l xy | s) ∝ w T ψ(s, l xy )</formula><p>Provided data consisting of statements labeled with logical forms, the model can be trained via maximum likelihood estimation, and be used to predict interpretations for new statements. For training this component, we use a CCG semantic parsing formalism, and follow the feature-set from <ref type="bibr" target="#b27">Zettlemoyer and Collins (2007)</ref>, consisting of simple indicator features for occurrences of keywords and lexicon entries. This is also compatible with the semantic parsing formalism in <ref type="bibr" target="#b23">Srivastava et al. (2017)</ref>, whose data (and accom- panying lexicon) are also used in our evaluation. For other datasets with predefined features, this component is learned easily from simple lexicons consisting of trigger words for features and labels. <ref type="bibr">3</ref> This component is the only part of the parser that is domain-specific. We note that while this component assumes a domain-specific lexicon (and possibly statement annotated with logical forms), this effort is one-time-only, and will find re-use across the possibly large number of concepts in the domain (e.g., email categories).</p><p>Identifying assertion type, l type : The principal novelty in our semantic parsing model is in iden- tifying the type of constraint asserted by a state- ment. For this, we train a MaxEnt classifier, which uses positional and syntactic features based on the text-spans corresponding to feature and concept mentions to predict the constraint type. We extract the following features from a statement: 1. Boolean value indicating whether the text-span corresponding to the feature x precedes the text span for the concept label y.</p><p>2. Boolean value indicating if sentence is in pas- sive (rather than active) voice, as identified by the occurrence of nsubjpass dependency relation. 3. Boolean value indicating whether head of the text-span for x is a noun, or a verb. 4. Features indicating the occurrence of condi- tional tokens ('if', 'then' and 'that') preceding or following text-spans for x and y. 5. Features indicating presence of a linguistic quantifier in a det or an advmod relation with syntactic head of x or y.</p><p>Since the constraint type is determined by syntactic and dependency parse features, this</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Type</head><p>Example description Conversion to Expectation Constraint P (y | x) Emails that I reply to are usually important E[I y=important,reply(x):true ] − p usually × E[I reply(x):true ] = 0 P (x | y) I often reply to important emails</p><formula xml:id="formula_2">E[I y=important,reply(x):true ] − p of ten × E[I y=important ] = 0 P (y)</formula><p>I rarely get important emails Same as P (y|x 0 ), where x 0 is a constant feature  <ref type="bibr" target="#b18">(Lichman, 2013)</ref>, and used this model for all experiments.</p><p>Identifying quantifiers, l quant : Multiple linguis- tic quantifiers in a sentence are rare, and we simply look for the first occurrence of a linguistic quanti- fier in a sentence, i.e. P (l quant |s) is a deterministic function. We note that many real world descrip- tions of concepts lack an explicit quantifier. e.g., 'Emails from my boss are important'. In this work, we ignore such statements for the purpose of train- ing. Another treatment might be to models these statements as reflecting a default quantifier, but we do not explore this direction here. Finally, the decoupling of quantification from logical represen- tation is a key decision. At the cost of linguistic coarseness, this allows modeling quantification ir- respective of the logical representation (lambda calculus, predicate-argument structures, etc.).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Classifier training from constraints</head><p>In the previous section, we described how indi- vidual explanations can be mapped to probabilis- tic assertions about observable attributes (e.g., the statement 'Emails that I reply to are usually impor- tant' may map to P (y = important | replied = true) = p usually ). Here, we describe how a set of such assertions can be used in conjunction with unlabeled data to train classification models. Our approach relies on having predictions from the classifier on a set of unlabeled examples (X = {x 1 . . . x n }) agree with human-provided advice (in form of constraints). The unobserved concept la- bels (Y = {y 1 . . . y n }) for the unlabeled data con- stitute latent variables for our method. The train- ing procedure can be seen as iteratively inferring the latent concept labels for unlabeled examples so as to agree with the human advice, and updat- ing the classification models by taking these labels as given. While there are multiple approaches for training statistical models with constraints on latent variables, here we use the Posterior Regularization (PR) framework. The PR objective can be used to optimize a latent variable model subject to a set of constraints, which specify preferences for values of the posterior distributions p θ (Y | X).</p><formula xml:id="formula_3">J Q (θ) = L(θ) − min q∈Q KL(q | p θ (Y |X))</formula><p>Here, the set Q represents a set of preferred pos- terior distributions over latent variables Y , and is defined as Q := {q X (Y ) :</p><formula xml:id="formula_4">E q [φ(X, Y )] ≤ b}.</formula><p>The overall objective consists of two components, representing how well does a model θ explain the data (likelihood term L(θ)), and how far it is from the set Q (KL-divergence term).</p><p>In our case, each parsed statement defines a probabilistic constraint. The conjunction of all such constraints defines Q (representing models that exactly agree with human-provided advice). Thus, optimizing the objective reflects a tension between choosing models that increase data likelihood, and emulating language advice.</p><p>Converting to PR constraints: The set of con- straints that PR can handle can be characterized as bounds on expected values of functions (φ) of X and Y (or equivalently, from linearity of expec- tation, as linear inequalities over expected values of functions of X and Y ). To use the framework, we need to ensure that each constraint type in our vocabulary can be expressed in such a form.</p><p>Following the plan in <ref type="table" target="#tab_1">Table 2</ref>, each constraint type can be converted in an equivalent form , which leads to the lin- ear constraints seen in <ref type="table" target="#tab_1">Table 2</ref> (expected values in the table hide summations over instances for brevity). Here, I denote indicator functions. Thus, we can incorporate probability constraints into our adaptation of the PR scheme. Learning and Inference: We choose a loglinear parameterization for the concept classifier.</p><formula xml:id="formula_5">p θ (y i | x i ) ∝ exp(yθ T x)</formula><p>The training of the classifier follows the modified EM procedure described in <ref type="bibr" target="#b9">Ganchev et al. (2010)</ref>. As proposed in the original work, we solve a re- laxed version of the optimization that allows slack variables, and modifies the PR objective with a L 2 regularizer. This allows solutions even when the problem is over-constrained, and the set Q is empty (e.g. due to contradictory advice).</p><formula xml:id="formula_6">J (θ, q) = L(θ) − KL(q|p θ (Y |X)) − λ ||E q [φ(X, Y )] − b|| 2</formula><p>The key step in the training is the computation of the posterior regularizer in the E-step. argmin</p><formula xml:id="formula_7">q KL(q | p θ ) + λ ||E q [φ(X, Y )] − b|| 2</formula><p>This objective is strictly convex, and all constraints are linear in q. We follow the optimization proce- dure from <ref type="bibr" target="#b3">Bellare et al. (2009)</ref>, whereby the min- imization problem in the E-step can be efficiently solved through gradient steps in the dual space. In the M-step, we update the model parameters for the classifier based on label distributions q estimated in the E-step. This simply reduces to estimating the parameters θ for the logistic regression classifier, when class label probabilities are known. In all experiments, we run EM for 20 iterations and use a regularization coefficient of λ = 0.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Datasets</head><p>For evaluating our approach, we created datasets of classification tasks paired with descriptions of the classes, as well as used some existing resources. In this section, we summarize these steps. Shapes data: To experiment with our approach in a wider range of controlled settings, part of our evaluation focuses on synthetic concepts. For this, we created a set of 50 shape classification tasks that exhibit a range of difficulty, and elicited language descriptions spanning a variety of quantifier ex- pressions. The tasks require classifying geometric shapes with a set of predefined attributes (fill color, border, color, shape, size) into two concept-labels (abstractly named 'selected shape', and 'other'). The datasets were created through a generative pro- cess, where features x i are conditionally indepen- dent given the concept-label. Each feature's con- ditional distribution is sampled from a symmetric We sample a total of 50 such datasets, consisting of 100 training and 100 test examples each, where each example is a shape and its assigned label. For each dataset, we then collected statements from Mechanical Turk workers that describe the concept. The task required turkers to study a sam- ple of shapes presented on the screen for each of the two concept-labels (see <ref type="figure" target="#fig_3">Figure 3(a)</ref>). They were then asked to write a set of statements that would help others classify these shapes without seeing the data. In total, 30 workers participated in this task, generating a mean of 4.3 statements per dataset. Email data: <ref type="bibr" target="#b23">Srivastava et al. (2017)</ref> provide a dataset of language explanations from human users describing 7 categories of emails, as well as 1030 examples of emails belonging to those categories. While this work uses labeled examples, and focuses Shapes: If a shape doesn't have a blue border, it is prob- ably not a selected shape. Selected shapes occasionally have a yellow fill. Emails: Emails that mention the word 'meet' in the sub- ject are usually meeting requests Personal reminders almost always have the same recipient and sender Birds: A specimen that has a striped crown is likely to be a selected bird. Birds in the other category rarely ever have dagger-shaped beaks <ref type="table">Table 3</ref>: Examples of explanations for each domain <ref type="figure">Figure 4</ref>: Statement generation task for Birds data on mapping natural language explanations (∼30 explanations per email category) to compositional feature functions, we can also use statements in their data for evaluating our approach. While lan- guage quantifiers were not studied in the original work, we found about a third of the statements in this data to mention a quantifier. Birds data: The CUB-200 dataset ( <ref type="bibr" target="#b24">Wah et al., 2011</ref>) contains images of birds annotated with observable attributes such as size, primary color, wing-patterns, etc. We selected a subset of the data consisting of 10 species of birds and 53 attributes (60 examples per species). Turkers were shown examples of birds from a species, and negative examples consisting of a mix of birds from other</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Approach</head><p>Avg <ref type="table">Accuracy Labels Descriptions  LNQ  0.751  no  yes  Bayes Optimal  0.831  - - FLGE+  0.659  no  yes  FLGE  0.598  no  yes  LR  0.737  yes  no  Random  0.</ref> <ref type="table">Table 4</ref>: Classification performance on Shapes datasets (averaged over 50 classification tasks).</p><note type="other">524 - - Ablation: LNQ (coarse quant) 0.679 no yes LNQ (no quant) 0.545 no yes Human: Human teacher 0.802 yes writes Human learner 0.734 no yes</note><p>species, and were asked to describe the classes (similar to the Shapes data, see <ref type="figure">Figure 4</ref>). During the task, users also had access to a table enumerat- ing groundable attributes they could refer to. In all, 60 workers participated, generating 6.1 statements on average.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>Incorporating constraints from language has not been addressed before, and hence previous ap- proaches for learning from limited data such as <ref type="bibr" target="#b20">Mann and McCallum (2010)</ref>; <ref type="bibr" target="#b6">Chang et al. (2007b)</ref> would not directly work for this setting. Our base- lines hence consist of extended versions of previous approaches that incorporate output from the parser, as well as fully supervised classifiers trained from a small number of labeled examples. Classification performance: The top section in <ref type="table">Table 4</ref> summarizes performance of various clas- sifiers on the Shape datasets, averaged over all 50 classification tasks. FLGE+ refers to a baseline <ref type="figure">Figure 5</ref>: LNQ vs Bayes Optimal Classifier perfor- mance for Shape datasets. Each dot represents a dataset generated from a known distribution.</p><p>that uses the Feature Labeling through General- ized Expectation criterion, following the approach in <ref type="bibr" target="#b7">Druck et al. (2008)</ref>; <ref type="bibr" target="#b20">Mann and McCallum (2010)</ref>. The approach is based on labeling features are in- dicating specific class-labels, which corresponds to specifiying constraints of type P (y|x) <ref type="bibr">5</ref> . While the original approach ( <ref type="bibr" target="#b7">Druck et al., 2008)</ref> sets this value to 0.9, we provide the method the quantita- tive probabilities used by LNQ. Since the original method cannot handle language descriptions, we also provide the approach the concept label y and feature x as identified by the parser. FLGE rep- resents the version that is not provided quantifier probabilities. LR refers to a supervised logistic re- gression model trained on n = 8 randomly chosen labeled instances. <ref type="bibr">6</ref> We note that LNQ performs substantially better than both FLGE+ and LR on average. This validates our modeling principle for learning classifiers from explanations alone, and also suggests value in our PR-based formulation, which can handle multiple constraint types. We further note that not using quantifier probabilities significantly deteriorates FLGE's performance. <ref type="figure">Figure 5</ref> provides a more detailed characteriza- tion of LNQ's performance. Each blue dot repre- sents performance on a shape classification task. The horizontal axis represents the accuracy of the Bayes Optimal classifier, and the vertical repre- sents accuracy of the LNQ approach. The blue line represents the trajectory for x = y, representing a perfect statistical classifier in the asymptotic case of infinite samples. We note that LNQ is effective in learning competent classifiers for all levels of hardness. Secondly, except for a small number of outliers, the approach works especially well for learning easy concepts (towards the right). From an error-analysis, we found that a majority of these errors are due to problems in parsing (e.g., missed negation, incorrect constraint type) or due to poor explanations from the teacher (bad grammar, or simply incorrect information). <ref type="figure" target="#fig_4">Figure 6</ref> shows results for email classification tasks. In the figure, LN* refers to the approach in <ref type="bibr" target="#b23">Srivastava et al. (2017)</ref>, which uses natural lan- guage descriptions to define compositional features for email classification, but does not incorporate supervision from quantification. For this task, we found very few of the natural language descriptions to contain quantifiers for some of the individual email categories, making a direct comparison im- practical. Thus in this case, we evaluate methods by combining supervision from descriptions in ad- dition to 10 labeled examples (also in line with evaluation in the original paper). We note that addi- tionally incorporating quantification (LNQ) consis- tently improves classification performance across email categories. On this task, LNQ improves upon FLGE+ and LN* for 6 of the 7 email categories. <ref type="figure">Figure 7</ref> shows classification results on the Birds data. Here, LR refers to a logistic regression model trained on n=10 examples. The trends in this case are similar, where LNQ consistently outperforms FLGE+, and is competitive with LR. Ablating quantification: From <ref type="table">Table 4</ref>, we further observe that the differential associative strengths of linguistic quantifiers are crucial for our method's classification performance. LNQ (no quant) refers to a variant that assigns the same probability value (average of values in <ref type="table">Table 1</ref>), irrespective of quantifier. This yields a near ran- dom performance, which is what we'd expect if the learning is being driven by the differential strengths of quantifiers. LNQ (coarse quant) refers to a vari- ant that rounds assigned quantifier probabilities in <ref type="table">Table 1</ref> to 0 or 1. (i.e., quantifiers such are rarely get mapped to 0, while always gets mapped to a probability of 1). While its performance (0.679) suggests that simple binary feedback is a substan- tial signal, the difference from the full model in- dicates value in using soft probabilities. On the other hand, in a sensitivity study, we found the performance of the approach to be robust to small changes in the probability values of quantifiers. Comparison with human performance: For the Shapes data, we evaluated human teachers' own understanding of concepts they teach by evaluating <ref type="figure">Figure 7</ref>: Classification performance on Birds data them on a quiz based on predicting labels for exam- ples from the test set (see <ref type="figure" target="#fig_3">Figure 3(b)</ref>). Second, we solicit additional workers that were not exposed to examples from the dataset, and present them only with the statements describing that data (created by a teacher), which is comparable supervision to what LNQ receives. We then evaluate their perfor- mance at the same task. From <ref type="table">Table 4</ref>, we note that a human teacher's average performance is signifi- cantly worse (p &lt; 0.05, Wilcoxon signed-rank test) than the Bayes Optimal classifier indicating that the teacher's own synthesis of concepts is noisy. The human learner performance is expectedly lower, but interestingly is also significantly worse than LNQ. While this might be potentially be caused by factors such as user fatigue, this might also suggest that automated methods can be better at reasoning with constraints than humans in certain scenarios. These results need to be validated through compre- hensive experiments in more domains. Empirical semantics of quantifiers: We can es- timate the distributions of probability values for different quantifiers from our labeled data. For this, we aggregate sentences mentioning a quantifier, and calculate the empirical value of the (condi- tional) probability associated with the statement, leading to a set of probability values for each quan- tifier. <ref type="figure" target="#fig_5">Figure 8</ref> shows empirical distributions of probability values for six quantifiers. We note that while a few estimates (e.g., 'rarely' and 'often') roughly align with pre-registered beliefs, others are somewhat off (e.g., 'likely' shows a much higher value), and yet others (e.g., 'sometimes') show a large spread of values to be meaningfully modeled as point values. LNQ's performance, inspite of this, shows strong stability in the approach. We don't use these empirical probabilities in experi- ments, (instead of pre-registered values), so as not to tune the hyperparameters to a specific dataset.  <ref type="table">Table 1</ref> Such estimates would not be available for a new task without labeled data. Further, using labeled data for estimating these probabilities, and then us- ing the learned model for predicting labels would constitute overfitting, biasing evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion and Future Work</head><p>Our approach is surprisingly effective in learning from free-form language. However, it does not ad- dress linguistic issues such as modifiers (e.g., very likely), nested quantification, etc. On the other hand, we found no instances of nested quantifi- cation in the data, suggesting that people might be primed to use simpler language when teaching. While we approximate quantifier semantics as abso- lute probability values, they may vary significantly based on the context, as shown by cognitive studies such as <ref type="bibr" target="#b22">Newstead and Collis (1987)</ref>. Future work can model how these parameters can be adapted in a task specific way (e.g., cases such as cancer prediction where base rates are small), and pro- vide better models of quantifier semantics. e.g., as distributions, rather than point values.</p><p>Our approach is a step towards the idea of using language to guide learning of statistical models. This is an exciting direction, which contrasts with the predominant theme of using statistical learning methods to advance the field of NLP. We believe that language may have as much to help learning, as statistical learning has helped NLP.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Our approach to Zero-shot learning from Language. Natural language explanations on how to classify concept examples are parsed into formal constraints relating features to concept labels. The constraints are combined with unlabeled data, using posterior regularization to yield a classifier.</figDesc><graphic url="image-2.png" coords="2,72.00,62.81,226.77,176.81" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Frequency</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>E q [φ(X, Y )] = b, compatible with PR. In partic- ular, each of these constraint types in our vocab- ulary can be expressed as equations about expec- tation values of joint indicator functions of label assignments to instances and their attributes. To ex- plain, consider the assertion P (y = important | replied : true) = p usually . The probability on the LHS can be expressed as the empirical fraction i E[I y i =important,replied:true ] i E[I replied:true ]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Shapes data: Mechanical Turk tasks for (a) collecting concept descriptions, and (b) human evaluation from concept descriptions</figDesc><graphic url="image-4.png" coords="6,313.00,241.21,204.09,111.59" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Classification performance (F1) on Email data. (LN* Results from Srivastava et al. (2017))</figDesc><graphic url="image-7.png" coords="8,325.70,62.81,181.41,98.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Empirical probability distributions for six quantifiers (Shapes data). Plots show Beta distributions with Method-of-Moment estimates. Red bars correspond to values from Table 1</figDesc><graphic url="image-9.png" coords="9,307.28,62.81,226.77,115.73" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 2 : Common constraint-types, and their representation as expectations over feature values</head><label>2</label><figDesc></figDesc><table>component does not need to be retrained for 
new domains. In this work, we trained this 
classifier based on a manually annotated set of 80 
sentences describing classes in the small UCI Zoo 
dataset </table></figure>

			<note place="foot" n="1"> e.g., &apos;some A are B&apos; ⇔ A ∩ B = ∅</note>

			<note place="foot" n="2"> This is a significantly restricted definition, and does not address non-frequency determiners (e.g.,&apos;the&apos;, &apos;only&apos;, etc. ) or mass quantifiers (e.g. &apos;a lot&apos;, &apos;little&apos;), among other categories.</note>

			<note place="foot" n="3"> We also identify whether a feature x is negated, through the existence of a neg dependency relation with the head of its text-span. e.g., Important emails are usually not deleted</note>

			<note place="foot" n="4"> This is the accuracy of a theoretically optimal classifier, which knows the true distribution of the data and labels</note>

			<note place="foot" n="5"> In general, Generalized Expectation can also handle broader constraint types, similar to Posterior Regularization 6 LNQ models are indistinct from LR w.r.t. parametrization, but trained to maximize a different objective. The choice of n here is arbitrary, but is roughly twice the number of explanations for each task in this domain</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research was supported by the CMU-Yahoo! InMind project. The authors would also like to thank the anonymous reviewers for helpful com-ments and suggestions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Learning with latent language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<idno>CoRR abs/1711.00482</idno>
		<ptr target="http://arxiv.org/abs/1711.00482" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Quantification in natural languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elke</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eloise</forename><surname>Jelinek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angelika</forename><surname>Kratzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Barbara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Partee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Springer Science &amp; Business Media</publisher>
			<biblScope unit="volume">54</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Generalized quantifiers and natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Barwise</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Cooper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Linguistics and philosophy</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="159" to="219" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Alternating projections for learning with expectation constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kedar</forename><surname>Bellare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Druck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the TwentyFifth Conference on Uncertainty in Artificial Intelligence</title>
		<meeting>the TwentyFifth Conference on Uncertainty in Artificial Intelligence</meeting>
		<imprint>
			<publisher>AUAI Press</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="43" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning to win by reading manuals in a monte-carlo framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Srk Branavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="661" to="704" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Guiding semi-supervision with constraint-driven learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P07-1036" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics. Association for Computational Linguistics</title>
		<meeting>the 45th Annual Meeting of the Association of Computational Linguistics. Association for Computational Linguistics<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="280" to="287" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Guiding semi-supervision with constraint-driven learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="280" to="287" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning from labeled features using generalized expectation criteria</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Druck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gideon</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 31st annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="595" to="602" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Write a classifier: Zero-shot learning using purely textual descriptions</title>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<editor>Mohamed Elhoseiny, Babak Saleh, and Ahmed Elgammal</editor>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Posterior regularization for structured latent variable models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuzman</forename><surname>Ganchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Gillenwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Taskar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="2001" to="2049" />
			<date type="published" when="2010-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">A tale of two draggns: A hybrid approach for interpreting actionoriented and goal-oriented instructions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddharth</forename><surname>Karamcheti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Edward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mina</forename><surname>Arumugam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nakul</forename><surname>Rhee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gopalan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Lawson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tellex</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.08668</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A short introduction to probabilistic soft logic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angelika</forename><surname>Kimmig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bert</forename><surname>Broecheler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lise</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Getoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop on Probabilistic Programming: Foundations and Applications</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Resolution of quantifier scope ambiguities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maryellen</forename><forename type="middle">C</forename><surname>Howard S Kurtzman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Macdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="243" to="279" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Human-level concept learning through probabilistic program induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Brenden M Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">350</biblScope>
			<biblScope unit="issue">6266</biblScope>
			<biblScope unit="page" from="1332" to="1338" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Attribute-based classification for zero-shot visual object categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Christoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannes</forename><surname>Lampert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Nickisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Harmeling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="453" to="465" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Predicting deep zero-shot convolutional neural networks using textual descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><forename type="middle">Lei</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning from measurements in exponential families</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Michael I Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th annual international conference on machine learning</title>
		<meeting>the 26th annual international conference on machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="641" to="648" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning dependency-based compositional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Michael I Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="590" to="599" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">UCI machine learning repository</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lichman</surname></persName>
		</author>
		<ptr target="http://archive.ics.uci.edu/ml" />
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Quantification as a major module of natural language semantics. Studies in discourse representation theory and the theory of generalized quantifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Löbner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">53</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Generalized expectation criteria for semi-supervised learning with weakly labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gideon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="955" to="984" />
			<date type="published" when="2010-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Prior expectation and the interpretation of natural language quantifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Linda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony J</forename><surname>Moxey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sanford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="73" to="91" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Context and the interpretation of quantifiers of frequency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janet</forename><forename type="middle">M</forename><surname>Newstead</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Collis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ergonomics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1447" to="1462" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Joint concept learning and semantic parsing from natural language explanations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shashank</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><surname>Labutov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Mitchell</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/D17-1161" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1528" to="1537" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<title level="m">The Caltech-UCSD Birds</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dataset</surname></persName>
		</author>
		<imprint/>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Linguistic variability and adaptation in quantifier meanings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judith</forename><surname>Ilker Yildirim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Degen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Michael K Tanenhaus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jaeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CogSci</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Online learning of relaxed ccg grammars for parsing to logical form</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Luke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-CoNLL</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="678" to="687" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
