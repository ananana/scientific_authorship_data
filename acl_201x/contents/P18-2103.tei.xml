<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:23+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Breaking NLI Systems with Sentences that Require Simple Lexical Inferences</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 15-20, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Glockner</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<address>
									<settlement>Darmstadt</settlement>
									<region>TU</region>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vered</forename><surname>Shwartz</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">Bar-Ilan University</orgName>
								<address>
									<settlement>Ramat-Gan</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">Bar-Ilan University</orgName>
								<address>
									<settlement>Ramat-Gan</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Breaking NLI Systems with Sentences that Require Simple Lexical Inferences</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="650" to="655"/>
							<date type="published">July 15-20, 2018</date>
						</imprint>
					</monogr>
					<note>650</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We create a new NLI test set that shows the deficiency of state-of-the-art models in inferences that require lexical and world knowledge. The new examples are simpler than the SNLI test set, containing sentences that differ by at most one word from sentences in the training set. Yet, the performance on the new test set is substantially worse across systems trained on SNLI, demonstrating that these systems are limited in their generalization ability, failing to capture many simple inferences.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recognizing textual entailment (RTE) ( <ref type="bibr" target="#b4">Dagan et al., 2013)</ref>, recently framed as natural language inference (NLI) <ref type="bibr" target="#b0">(Bowman et al., 2015</ref>) is a task concerned with identifying whether a premise sen- tence entails, contradicts or is neutral with the hy- pothesis sentence. Following the release of the large-scale SNLI dataset <ref type="bibr" target="#b0">(Bowman et al., 2015)</ref>, many end-to-end neural models have been devel- oped for the task, achieving high accuracy on the test set. As opposed to previous-generation meth- ods, which relied heavily on lexical resources, neural models only make use of pre-trained word embeddings. The few efforts to incorporate exter- nal lexical knowledge resulted in negligible per- formance gain <ref type="bibr" target="#b2">(Chen et al., 2018)</ref>. This raises the question whether (1) neural methods are inher- ently stronger, obviating the need of external lexi- cal knowledge; (2) large-scale training data allows for implicit learning of previously explicit lexical knowledge; or (3) the NLI datasets are simpler than early RTE datasets, requiring less knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Premise/Hypothesis Label</head><p>The man is holding a saxophone contradiction 1 The man is holding an electric guitar A little girl is very sad. entailment A little girl is very unhappy.</p><p>A couple drinking wine neutral A couple drinking champagne <ref type="table">Table 1</ref>: Examples from the new test set.</p><p>In this paper we show that state-of-the-art NLI systems are limited in their generalization ability, and fail to capture many simple inferences that re- quire lexical and world knowledge. Inspired by the work of Jia and Liang (2017) on reading com- prehension, we create a new NLI test set with ex- amples that capture various kinds of lexical knowl- edge <ref type="table">(Table 1</ref>). For example, that champagne is a type of wine (hypernymy), and that saxophone and electric guitar are different musical instru- ments (co-hyponyms). To isolate lexical knowl- edge aspects, our constructed examples contain only words that appear both in the training set and in pre-trained embeddings, and differ by a single word from sentences in the training set.</p><p>The performance on the new test set is substan- tially worse across systems, demonstrating that the SNLI test set alone is not a sufficient measure of language understanding capabilities. Our results are in line with <ref type="bibr" target="#b7">Gururangan et al. (2018)</ref> and <ref type="bibr" target="#b15">Poliak et al. (2018)</ref>, who showed that the label can be identified by looking only at the hypothesis and exploiting annotation artifacts such as word choice and sentence length.</p><p>Further investigation shows that what mostly affects the systems' ability to correctly predict a test example is the amount of similar exam- ples found in the training set. Given that train- ing data will always be limited, this is a rather inefficient way to learn lexical inferences, stress- ing the need to develop methods that do this more effectively. Our test set can be used to evalu- ate such models' ability to recognize lexical infer- ences, and it is available at https://github. com/BIU-NLP/Breaking_NLI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>NLI Datasets. The SNLI dataset (Stanford Nat- ural Language Inference, <ref type="bibr" target="#b0">Bowman et al., 2015)</ref> consists of 570k sentence-pairs manually labeled as entailment, contradiction, and neutral. Premises are image captions from <ref type="bibr">Young et al. (2014)</ref>, while hypotheses were generated by crowd-sourced workers who were shown a premise and asked to generate entailing, contradicting, and neutral sen- tences. Workers were instructed to judge the re- lation between sentences given that they describe the same event. Hence, sentences that differ by a single mutually-exclusive term should be consid- ered contradicting, as in "The president visited Al- abama" and "The president visited Mississippi". This differs from traditional RTE datasets, which do not assume event coreference, and in which such sentence-pairs would be considered neutral.</p><p>Following criticism on the simplicity of the dataset, stemming mostly from its narrow domain, two additional datasets have been collected. The MultiNLI dataset (Multi-Genre Natural Language Inference, <ref type="bibr" target="#b18">Williams et al., 2018</ref>) was collected similarly to SNLI, though covering a wider range of genres, and supporting a cross-genre evaluation. The SciTail dataset ( <ref type="bibr" target="#b9">Khot et al., 2018)</ref>, created from science exams, is somewhat different from the two datasets, being smaller (27,026 examples), and labeled only as entailment or neutral. The do- main makes this dataset different in nature from the other two datasets, and it consists of more fac- tual sentences rather than scene descriptions.</p><p>Neural Approaches for NLI. Following the re- lease of SNLI, there has been tremendous inter- est in the task, and many end-to-end neural mod- els were developed, achieving promising results. <ref type="bibr">2</ref> Methods are divided into two main approaches. Sentence-encoding models (e.g. <ref type="bibr" target="#b0">Bowman et al., 2015</ref><ref type="bibr" target="#b1">Bowman et al., , 2016</ref><ref type="bibr" target="#b12">Nie and Bansal, 2017;</ref><ref type="bibr" target="#b17">Shen et al., 2018</ref>) encode the premise and hypothesis individ- ually, while attention-based models align words in the premise with similar words in the hypoth- esis, encoding the two sentences together (e.g. <ref type="bibr" target="#b16">Rockt√§schel et al., 2016;</ref><ref type="bibr" target="#b3">Chen et al., 2017</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>External Lexical Knowledge. Traditional RTE methods typically relied on resources such as</head><p>WordNet <ref type="bibr" target="#b5">(Fellbaum, 1998</ref>) to identify lexical in- ferences. Conversely, neural methods rely solely on pre-trained word embeddings, yet, they achieve high accuracy on SNLI.</p><p>The only neural model to date that incorpo- rates external lexical knowledge (from WordNet) is KIM ( <ref type="bibr" target="#b2">Chen et al., 2018)</ref>, however, gaining only a small addition of 0.6 points in accuracy on the SNLI test set. This raises the question whether the small performance gap is a result of the model not capturing lexical knowledge well, or the SNLI test set not requiring this knowledge in the first place.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data Collection</head><p>We construct a test set with the goal of evaluating the ability of state-of-the-art NLI models to make inferences that require simple lexical knowledge. We automatically generate sentence pairs ( ¬ß3.1) which are then manually verified ( ¬ß3.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Generating Adversarial Examples</head><p>In order to isolate the lexical knowledge aspects, the premises are taken from the SNLI training set. For each premise we generate several hypotheses by replacing a single word within the premise by a different word. We also allow some multi-word noun phrases ("electric guitar") and adapt deter- miners and prepositions when needed.</p><p>We focus on generating only entailment and contradiction examples, while neutral examples may be generated as a by-product. Entailment examples are generated by replacing a word with its synonym or hypernym, while contradiction ex- amples are created by replacing words with mu- tually exclusive co-hyponyms and antonyms (see <ref type="table">Table 1</ref>). The generation steps are detailed below.</p><p>Replacement Words. We collected the replace- ment words using online resources for English learning. <ref type="bibr">3</ref> The newly introduced words are all present in the SNLI training set: from occur- rence in a single training example ("Portugal") up to 248,051 examples ("man"), with a mean of 3,663.1 and a median of 149.5. The words are also available in the pre-trained embeddings vo- cabulary. The goal of this constraint is to isolate lexical knowledge aspects, and evaluate the mod- els' ability to generalize and make new inferences for known words.   Replacement words are divided into topical cat- egories detailed in <ref type="table" target="#tab_4">Table 4</ref>. In several categories we applied additional processing to ensure that ex- amples are indeed mutually-exclusive, topically- similar, and interchangeable in context. We in- cluded WordNet antonyms with the same part-of- speech and with a cosine similarity score above a threshold, using GloVe ( <ref type="bibr" target="#b14">Pennington et al., 2014)</ref>. In nationalities and countries we focused on coun- tries which are related geographically (Japan, China) or culturally (Argentina, Spain).</p><p>Sentence-Pairs. To avoid introducing new in- formation not present in the training data, we sam- pled premises from the SNLI training set that con- tain words from our lists, and generated hypothe- ses by replacing the selected word with its replace- ment. Some of the generated sentences may be un- grammatical or nonsensical, for instance, when re- placing Jordan with Syria in sentences discussing Michael Jordan. We used Wikipedia bigrams 4 to discard sentences in which the replaced word cre- ated a bigram with less than 10 occurrences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Manual Verification</head><p>We manually verify the correctness of the au- tomatically constructed examples using crowd- sourced workers in Amazon Mechanical Turk. To ensure the quality of workers, we applied a quali- fication test and required a 99% approval rate for at least 1,000 prior tasks. We assigned each anno- tation to 3 workers.</p><p>Following the SNLI guidelines, we instructed the workers to consider the sentences as describing the same event, but we simplified the annotation process into answering 3 simple yes/no questions:</p><p>1. Do the sentences describe the same event?</p><p>2. Does the new sentence (hypothesis) add new information to the original sentence (premise)? 3. Is the new sentence incorrect/ungrammatical?</p><p>We then discarded any sentence-pair in which at least one worker answered the third question positively. If the answer to the first question was negative, we considered the label as contradiction. Otherwise, we considered the label as entailment if the answer to the second question was negative and neutral if it was positive. We used the major- ity vote to determine the gold label.</p><p>The annotations yielded substantial agreement, with Fleiss' Kappa Œ∫ = 0.61 <ref type="bibr" target="#b10">(Landis and Koch, 1977)</ref>. We estimate human performance to 94.1%, using the method described in <ref type="bibr" target="#b6">Gong et al. (2018)</ref>, showing that the new test set is substantially easier to humans than SNLI. <ref type="table" target="#tab_1">Table 2</ref> provides additional statistics on the test set. <ref type="bibr">5</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Models</head><p>Without External Knowledge. We chose 3 rep- resentative models in different approaches (sen- tence encoding and/or attention): RESIDUAL- STACKED-ENCODER (Nie and Bansal, 2017) is a biLSTM-based single sentence-encoding model without attention. As opposed to traditional multi- layer biLSTMs, the input to each next layer is the concatenation of the word embedding and the summation of outputs from previous lay- ers. ESIM (Enhanced Sequential Inference Model, <ref type="bibr" target="#b3">Chen et al., 2017</ref>) is a hybrid TreeLSTM-based and biLSTM-based model. We use the biL- STM model, which uses an inter-sentence atten- tion mechanism to align words across sentences. Finally, DECOMPOSABLE ATTENTION (Parikh et al., 2016) performs soft alignment of words from the premise to words in the hypothesis us- ing attention mechanism, and decomposes the task into comparison of aligned words. Lexical-level decisions are merged to produce the final classifi- cation. We use the AllenNLP re-implementation, <ref type="bibr">6</ref> which does not implement the optional intra- sentence attention, and achieves an accuracy of 84.7% on the SNLI test set, comparable to 86.3% by the original system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Train set SNLI test set New test set ‚àÜ  We chose models which are amongst the best performing within their approaches (excluding en- sembles) and have available code. All models are based on pre-trained GloVe embeddings <ref type="bibr" target="#b14">(Pennington et al., 2014</ref>), which are either fine-tuned during training (RESIDUAL-STACKED-ENCODER and ESIM) or stay fixed (DECOMPOSABLE AT- TENTION). All models predict the label using a concatenation of features derived from the sen- tence representations (e.g. maximum, mean), for example as in <ref type="bibr" target="#b11">Mou et al. (2016)</ref>. We use the rec- ommended hyper-parameters for each model, as they appear in the provided code.</p><p>With External Knowledge. We provide a sim- ple WORDNET BASELINE, in which we classify a sentence-pair according to the WordNet relation that holds between the original word w p and the replaced word w h . We predict entailment if w p is a hyponym of w h or if they are synonyms, neutral if w p is a hypernym of w h , and contradiction if w p and w h are antonyms or if they share a common hypernym ancestor (up to 2 edges). Word pairs with no WordNet relations are classified as other.</p><p>We also report the performance of KIM (Knowledge-based Inference Model, <ref type="bibr" target="#b2">Chen et al., 2018)</ref>, an extension of ESIM with external knowl- edge from WordNet, which was kindly provided to us by Qian Chen. KIM improves the attention mechanism by taking into account the existence of WordNet relations between the words. The lex- ical inference component, operating over pairs of aligned words, is enriched with a vector encoding the specific WordNet relations between the words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental Settings</head><p>We trained each model on 3 different datasets: (1) SNLI train set, (2) a union of the SNLI train set and the MultiNLI train set, and (3) a union of the SNLI train set and the SciTail train set. The mo- tivation is that while SNLI might lack the training data needed to learn the required lexical knowl- edge, it may be available in the other datasets, which are presumably richer. <ref type="table" target="#tab_3">Table 3</ref> displays the results for all the models on the original SNLI test set and the new test set. De- spite the task being considerably simpler, the drop in performance is substantial, ranging from 11 to 33 points in accuracy. Adding MultiNLI to the training data somewhat mitigates this drop in ac- curacy, thanks to almost doubling the amount of training data. We note that adding SciTail to the training data did not similarly improve the perfor- mance; we conjecture that this stems from the dif- ferences between the datasets. KIM substantially outperforms the other neural models, demonstrating that lexical knowledge is the only requirement for good performance on the new test set, and stressing the inability of the other models to learn it. Both WordNet-informed mod- els leave room for improvement: possibly due to limited WordNet coverage and the implications of applying lexical inferences within context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Analysis</head><p>We take a deeper look into the predictions of the models that don't employ external knowledge, fo- cusing on the models trained on SNLI.  <ref type="table" target="#tab_4">Table 4</ref>: The number of instances and accuracy per category achieved by each model. on categories such as planets, which rarely occur in SNLI. These models perform better than the WordNet baseline on entailment examples (syn- onyms), suggesting that they do so due to high lexical overlap between the premise and the hy- pothesis rather than recognizing synonymy. We therefore focus the rest of the discussion on con- tradiction examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Accuracy by Category</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Accuracy by Word Similarity</head><p>The accuracies for ordinals, nationalities and countries are especially low. We conjecture that this stems from the proximity of the contradict- ing words in the embedding space. Indeed, the Decomposable Attention model-which does not update its embeddings during training-seems to suffer the most. Grouping its prediction accuracy by the cosine similarity between the contradicting words reveals a clear trend that the model errs more on contra- dicting pairs with similar pre-trained vectors: <ref type="bibr">7</ref> Similarity 0.5-0.6 0.6-0.7 0.7-0.8 0.8-0.9 0.9-1.0 Accuracy 46.2% 42.3% 37.5% 29.7% 20.2%</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Accuracy by Frequency in Training</head><p>Models that fine-tune the word embeddings may benefit from training examples consisting of test replacement pairs. Namely, for a given replace- ment pair (w p , w h ), if many training examples la- beled as contradiction contain w p in the premise and w h in the hypothesis, the model may update their embeddings to optimize predicting contradic- tion. Indeed, we show that the ESIM accuracy on test pairs increases with the frequency in which <ref type="bibr">7</ref> We ignore multi-word replacements in ¬ß5. <ref type="bibr">2 and ¬ß5.3.</ref> their replacement words appear in contradiction examples in the training data: This demonstrates that the model is capable of learning lexical knowledge when sufficient train- ing data is given, but relying on explicit training examples is a very inefficient way of obtaining simple lexical knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We created a new NLI test set with the goal of evaluating systems' ability to make inferences that require simple lexical knowledge. Although the test set is constructed to be much simpler than SNLI, and does not introduce new vocabulary, the state-of-the-art systems perform poorly on it, sug- gesting that they are limited in their generalization ability. The test set can be used in the future to as- sess the lexical inference abilities of NLI systems and to tease apart the performance of otherwise very similarly-performing systems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>SNLI</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Statistics of the test sets. 9,815 is the 
number of samples with majority agreement in the 
SNLI test set, whose full size is 9,824. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 : Accuracy of various models trained on SNLI or a union of SNLI with another dataset (MultiNLI, SciTail), and tested on the original SNLI test set and the new test set.</head><label>3</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 displays</head><label>4</label><figDesc>the accuracy of each model per replacement-word category. The neural models tend to perform well on categories which are fre- quent in the training set, such as colors, and badly</figDesc><table>Dominant 
Label 

Category 
Instances 
Example 
Words 

Decomposable 
Attention 
ESIM 
Residual 
Encoders 

WordNet 
Baseline 
KIM 

Cont. 

antonyms 
1,147 
loves -dislikes 
41.6% 
70.4% 
58.2% 
95.5% 
86.5% 
cardinals 
759 
five -seven 
53.5% 
75.5% 
53.1% 
98.6% 
93.4% 
nationalities 
755 
Greek -Italian 
37.5% 
35.9% 
70.9% 
78.5% 
73.5% 
drinks 
731 
lemonade -beer 
52.9% 
63.7% 
52.0% 
94.8% 
96.6% 
antonyms (WN) 
706 
sitting -standing 
55.1% 
74.6% 
67.9% 
94.5% 
78.8% 
colors 
699 
red -blue 
85.0% 
96.1% 
87.0% 
98.7% 
98.3% 
ordinals 
663 
fifth -16th 
2.1% 
21.0% 
5.4% 
40.7% 
56.6% 
countries 
613 
Mexico -Peru 
15.2% 
25.4% 
66.2% 
100.0% 
70.8% 
rooms 
595 kitchen -bathroom 
59.2% 
69.4% 
63.4% 
89.9% 
77.6% 
materials 
397 
stone -glass 
65.2% 
89.7% 
79.9% 
75.3% 
98.7% 
vegetables 
109 
tomato -potato 
43.1% 
31.2% 
37.6% 
86.2% 
79.8% 
instruments 
65 
harmonica -harp 
96.9% 
90.8% 
96.9% 
67.7% 
96.9% 
planets 
60 
Mars -Venus 
31.7% 
3.3% 
21.7% 
100.0% 
5.0% 

Ent. 
synonyms 
894 
happy -joyful 
97.5% 
99.7% 
86.1% 
70.5% 
92.1% 

total 
8,193 
51.9% 
65.6% 
62.2% 
85.8% 
83.5% 

</table></figure>

			<note place="foot" n="1"> The contradiction example follows the assumption in Bowman et al. (2015) that the premise contains the most prominent information in the event, hence the premise can&apos;t describe the event of a man holding both instruments.</note>

			<note place="foot" n="2"> See the SNLI leaderboard for a comprehensive list: https://nlp.stanford.edu/projects/snli/.</note>

			<note place="foot" n="3"> www.enchantedlearning.com, www.smart-words.org</note>

			<note place="foot" n="4"> github.com/rmaestre/Wikipedia-Bigram-Open-Datasets</note>

			<note place="foot" n="5"> We note that due to its bias towards contradiction, the new test set can neither be used for training, nor serve as a main evaluation set for NLI. Instead, we suggest to use it in addition to the original test set in order to test a model&apos;s ability to handle lexical inferences. 6 http://allennlp.org/models</note>

			<note place="foot">Peter Young, Alice Lai, Micah Hodosh, and Julia Hockenmaier. 2014. From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions. Transactions of the Association for Computational Linguistics 2:67-78.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank Qian Chen for evaluat-ing KIM on our test set. This work was sup-ported in part by the German Research Founda-tion through the German-Israeli Project Coopera-tion (DIP, grant DA 1600/1-1), an Intel ICRI-CI grant, Theo Hoffenberg, and the Israel Science Foundation grants 1951/17 and 1555/15. Vered is also supported by the Clore Scholars Programme <ref type="bibr">(2017)</ref>, and the AI2 Key Scientific Challenges Program (2017).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A large annotated corpus for learning natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">Christopher</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
		<idno type="doi">10.18653/v1/D15-1075</idno>
		<ptr target="https://doi.org/10.18653/v1/D15-1075" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="632" to="642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A fast unified model for parsing and sentence understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Samuel R Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gauthier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raghav</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Long Papers</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1466" to="1477" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Neural natural language inference models enhanced with external knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen-Hua</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Inkpen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Si</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 56th Annual Meeting of the Association for Computational Linguistics (ACL). Melbourne</title>
		<meeting><address><addrLine>Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Enhanced lstm for natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen-Hua</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Si</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Inkpen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1657" to="1668" />
		</imprint>
	</monogr>
	<note>Long Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Recognizing textual entailment: Models and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Ido Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><forename type="middle">Massimo</forename><surname>Sammons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zanzotto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthesis Lectures on Human Language Technologies</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="220" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christiane</forename><surname>Fellbaum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>Wiley Online Library</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Natural language inference over interaction space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>ICLR</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Annotation artifacts in natural language inference data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swabha</forename><surname>Suchin Gururangan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Swayamdipta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Samuel R Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 16th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
		<meeting><address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Adversarial examples for evaluating reading comprehension systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/D17-1215" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2021" to="2031" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">SciTail: A textual entailment dataset from science question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Thirty-Second AAAI Conference on Artificial Intelligence (AAAI)</title>
		<meeting><address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">The measurement of observer agreement for categorical data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Landis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary G</forename><surname>Koch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1977" />
			<biblScope unit="page" from="159" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Natural language inference by tree-based convolution and heuristic matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lili</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Men</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ge</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="130" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Shortcutstacked sentence encoders for multi-domain inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixin</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.02312</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A decomposable attention model for natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>T√§ckstr√∂m</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<ptr target="https://aclweb.org/anthology/D16-" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2249" to="2255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/D14-1162" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Hypothesis Only Baselines in Natural Language Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Poliak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Naradowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aparajita</forename><surname>Haldar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachel</forename><surname>Rudinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint Conference on Lexical and Computational Semantics (StarSem)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Reasoning about entailment with neural attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rockt√§schel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><forename type="middle">Moritz</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Kocisky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>ICLR</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Reinforced self-attention network: a hybrid of hard and soft attention for sequence modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqi</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.10296</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A broad-coverage challenge corpus for sentence understanding through inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adina</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikita</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 16th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACLHLT)</title>
		<meeting><address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
