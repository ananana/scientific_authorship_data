<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:56+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Model Transfer for Tagging Low-resource Languages using a Bilingual Dictionary</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Fang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
						</author>
						<title level="a" type="main">Model Transfer for Tagging Low-resource Languages using a Bilingual Dictionary</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</title>
						<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="587" to="593"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-2093</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Cross-lingual model transfer is a compelling and popular method for predicting annotations in a low-resource language, whereby parallel corpora provide a bridge to a high-resource language and its associated annotated corpora. However, parallel data is not readily available for many languages , limiting the applicability of these approaches. We address these drawbacks in our framework which takes advantage of cross-lingual word embeddings trained solely on a high coverage bilingual dictionary. We propose a novel neural network model for joint training from both sources of data based on cross-lingual word em-beddings, and show substantial empirical improvements over baseline techniques. We also propose several active learning heuristics, which result in improvements over competitive benchmark methods.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Part-of-speech (POS) tagging is an important first step in most natural language processing (NLP) applications. Typically this is modelled using sequence labelling methods to predict the con- ditional probability of taggings given word se- quences, using linear graphical models ( <ref type="bibr" target="#b9">Lafferty et al., 2001</ref>), or neural network models, such as recurrent neural networks (RNN) ( <ref type="bibr" target="#b10">Mikolov et al., 2010;</ref><ref type="bibr" target="#b7">Huang et al., 2015</ref>). These supervised learn- ing algorithms rely on large labelled corpora; this is particularly true for state-of-the-art neural net- work models. Due to the expense of annotating sufficient data, such techniques are not well suited to applications in low-resource languages.</p><p>Prior work on low-resource NLP has primarily focused on exploiting parallel corpora to project information between a high-and low-resource language <ref type="bibr" target="#b15">(Yarowsky and Ngai, 2001;</ref><ref type="bibr" target="#b14">Täckström et al., 2013;</ref><ref type="bibr" target="#b6">Guo et al., 2015;</ref><ref type="bibr">Agi´cAgi´c et al., 2016;</ref><ref type="bibr" target="#b2">Buys and Botha, 2016)</ref>. For example, POS tags can be projected via word alignments, and the pro- jected POS is then used to train a model in the low- resource language ( <ref type="bibr">Zhang et al., 2016;</ref><ref type="bibr" target="#b4">Fang and Cohn, 2016)</ref>. These meth- ods overall have limited effectiveness due to errors in the alignment and fundamental differences be- tween the languages. They also assume a large parallel corpus, which may not be available for many low-resource languages.</p><p>To address these limitations, we propose a new technique for low resource tagging, with more modest resource requirements: 1) a bilingual dic- tionary; 2) monolingual corpora in the high and low resource languages; and 3) a small annotated corpus of around 1, 000 tokens in the low-resource language. The first two resources are used as a form of distant supervision through learning cross- lingual word embeddings over the monolingual corpora and bilingual dictionary <ref type="bibr" target="#b0">(Ammar et al., 2016)</ref>. Additionally, our model jointly incor- porates the language-dependent information from the small set of gold annotations. Our approach combines these two sources of supervision us- ing multi-task learning, such that the kinds of er- rors that occur in cross-lingual transfer can be ac- counted for, and corrected automatically.</p><p>We empirically demonstrate the validity of our observation by using distant supervision to im- prove POS tagging performance with little super- vision. Experimental results show the effective- ness of our approach across several low-resource languages, including both simulated and true low- resource settings. Furthermore, given the clear su- periority of training with manual annotations, we compare several active learning heuristics. Active learning using uncertainty sampling with a word-  type bias leads to substantial gains over bench- mark methods such as token or sentence level un- certainty sampling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>POS tagging has been studied for many years. Traditionally, probabilistic models are a popular choice, such as Hidden Markov Models (HMM) and Conditional Random Fields (CRF) ( <ref type="bibr" target="#b9">Lafferty et al., 2001</ref>). Recently, neural network mod- els have been developed for POS tagging and achieved good performance, such as RNN and bidirectional long short-term memory (BiLSTM) and CRF-BiLSTM models ( <ref type="bibr" target="#b10">Mikolov et al., 2010;</ref><ref type="bibr" target="#b7">Huang et al., 2015)</ref>. For example, the CRF- BiLSTM POS tagger obtained the state-of-the- art performance on Penn Treebank WSJ cor- pus ( <ref type="bibr" target="#b7">Huang et al., 2015)</ref>.</p><p>However, in low-resource languages, these models are seldom used because of limited la- belled data. Parallel data therefore appears to be the most realistic additional source of informa- tion for developing NLP systems in low-resource languages <ref type="bibr" target="#b15">(Yarowsky and Ngai, 2001;</ref><ref type="bibr" target="#b14">Täckström et al., 2013;</ref><ref type="bibr" target="#b4">Fang and Cohn, 2016;</ref><ref type="bibr">Zhang et al., 2016)</ref>. <ref type="bibr" target="#b15">Yarowsky and Ngai (2001)</ref> pioneered the use of parallel data for projecting POS tag information from one language to another language.  used parallel data and exploited graph-based label prop- agation to expand the coverage of labelled tokens. <ref type="bibr">Täckström et al. (2013)</ref> constructed tag dictionar- ies by projecting tag information from a high- resource language to a low-resource language via alignments in the parallel text. <ref type="bibr" target="#b4">Fang and Cohn (2016)</ref> used parallel data to obtain projected tags as distant labels and proposed a joint BiLSTM model trained on both the distant data and 1, 000 tagged tokens. <ref type="bibr">Zhang et al. (2016)</ref> used a few word translations pairs to find a linear transfor- mation between two language embeddings. Then they used unsupervised learning to refine embed- ding transformations and model parameters. In- stead we use minimal supervision to refine 'dis- tant' labels through modelling the tag transforma- tion, based on a small set of annotations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model</head><p>We now describe the modelling framework for POS tagging in a low-resource language, based on very limited linguistic resources. Our approach extends the work of <ref type="bibr" target="#b4">Fang and Cohn (2016)</ref>, who present a model based on distant supervision in the form of cross-lingual projection and use pro- jected tags generated from parallel corpora as dis- tant annotations. There are three main differences between their work and ours: 1) We do not use par- allel corpora, but instead use a bilingual dictionary for knowledge transfer. 2) Our model uses a more expressive multi-layer perceptron when generat- ing the gold standard tags. The multi-layer per- ceptron can capture both language-specific infor- mation and consistent tagging errors arising from this method of supervision. 3) We propose a num- ber of active learning methods to further reduces the annotation requirements. Our method is illus- trated in <ref type="figure" target="#fig_0">Figure 1</ref>, and we now elaborate on the model components.</p><p>Distant cross-lingual supervision In order to transfer tag information between the high-and low-resource languages, we start by learning cross-lingual word embeddings, which operate by learning vector valued embeddings such that words and their translations tend to be close to- gether in the vector space. We use the embeddings from <ref type="bibr" target="#b0">Ammar et al. (2016)</ref> which trains mono- lingual word2vec distributional representations, which are then projected into a common space, learned from bilingual dictionaries. We then train a POS tagger on the high-resource language, using the cross-lingual word embed- dings as the first, fixed, layer of a bidirectional LSTM tagger. The tagger is a language-universal model based on cross-lingual word embeddings, for processing an arbitrary language, given a monolingual corpus and a bilingual dictionary, as shown in <ref type="figure" target="#fig_1">Figure 2</ref>. Next we apply this tag- ger to unannotated text in the low-resource lan- guage; this application is made possible through the use of cross-lingual word embeddings. We refer to text tagged this way as distantly super- vised data, and emphasize that although much bet- ter than chance, the outputs are often incorrect and are of limited utility on their own.</p><p>As illustrated in <ref type="figure" target="#fig_0">Figure 1</ref>, the distant compo- nents are generated directly as softmax outputs, y t ∼ Categorial(o t ), with parameters o t = Softmax(W h t + b) as a linear classifier over a sentence encoding, h t , which is the output of a bidirectional LSTM encoder over the words.</p><p>Ground truth supervision The second compo- nent of the model is manually labelled text in the low-resource language. To model this data we em- ploy the same model structure as above but aug- mented with a second perceptron output layer, as illustrated in <ref type="figure" target="#fig_0">Figure 1 (right)</ref>. Formally, ˜ y t ∼ Categorial(˜ o t ) whereõwhere˜whereõ t = MLP(o t ) is a single hidden layer perceptron with tanh activation and softmax output transformation. This component allows for a more expressive label mapping than <ref type="bibr" target="#b4">Fang and Cohn (2016)</ref>'s linear matrix translation.</p><p>Joint multi-task learning To combine the two sources of information, we use a joint objective,</p><formula xml:id="formula_0">J = −γ t∈N˜y t∈N˜t∈N˜y t , logõlog˜logõ t − t∈M y t , log o t , (1)</formula><p>where N and M index the token positions in the distant and ground truth corpora, respectively, and γ is a constant balancing the two components which we set for uniform weighting, γ = |M| |N | . Consider the training effect of the true POS tags: when performing error backpropagation, the cross-entropy error signal must pass through the transformation linkingõlinking˜linkingõ with o, which can be seen as a language-specific step, after which the gener- alised error signal can be further backpropagated to the rest of the model. Active learning Given the scarcity of ground truth labels and the high cost of annotation, a natu- ral question is whether we can optimise which text to be annotated in order achieve the high accuracy for the lowest cost. We now outline a range of active learning approaches based on the following heuristics, which are used to select the instances for annotation from a pool of candidates: TOKEN Select the token x t with the highest uncertainty, H(x, t) = − y P (y|x, t) log P (y|x, t); SENT Select the sentence x with the highest ag- gregate uncertainty, H(x) = t H(x, t); FREQTYPE Select the most frequent unanno- tated word type ( <ref type="bibr" target="#b5">Garrette and Baldridge, 2013)</ref>, in which case all token instances are annotated with the most frequent label for the type in the training corpus; 1 SUMTYPE Select a word type, z, for an- notation with the highest aggregate uncertainty over token occurrences, H(z) = i∈D x i,t =z H(x i , t), which effectively combines uncertainty sampling with a bias towards high frequency types; and RANDOM Select word types randomly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We evaluate the effectiveness of the proposed model for several different languages, including both simulated low-resource and true low-resource settings. The first evaluation set uses the CoNLL- X datasets of European languages <ref type="bibr" target="#b1">(Buchholz and Marsi, 2006</ref>), comprising Danish (da), Dutch (nl), German (de), Greek (el), Italian (it), Portuguese (pt), Spanish (es) and Swedish (sv). We use the standard corpus splits. The first 20 sentences of training set are used for training as the tiny la- belled (gold) data and the last 20 sentences are used for development (early stopping). We report accuracy on the held-out test set.</p><p>The second evaluation set includes two highly challenging languages, Turkish (tk) and Malagasy (mg), both having high morphological complexity and the latter has truly scant resources. Turkish data was drawn from CoNLL 2003 2 and Malagasy data was collected from , in both cases using the same training configuration as above.</p><p>In all cases English is used as the source 'high resource' language, on which we train a tagger using the Penn Treebank, and we evaluate on each of the remaining languages as an indepen- dent target. For cross-lingual word embeddings, we evaluate two techniques from <ref type="bibr" target="#b0">Ammar et al. (2016)</ref>: CCA-based word embeddings and cluster- based word embeddings. Both types of word em- bedding techniques are based on bilingual dictio- naries. The dictionaries were formed by trans- lating the 20k most common words in the En-glish monolingual corpus with Google Translate. <ref type="bibr">3</ref> The monolingual corpora were constructed from a combination of text from the Leipzig Corpora Collection and Europarl. We trained the language- universal POS tagger based on the cross-lingual word embeddings with the universal POS tagset , and then applied to the tar- get language using the embedding lookup table for the corresponding language embeddings. We implement our learning procedure with the DyNet toolkit <ref type="figure" target="#fig_0">(Neubig et al., 2017)</ref>. <ref type="bibr">4</ref> The BiLSTM layer uses 128 hidden units, and 32 hidden units for the transformation step. We used SGD with momen- tum to train models, with early stopping based on development performance.</p><p>For benchmarks, we compare the proposed model against various state-of-the-art supervised learning methods, namely: a BILSTM tagger, BILSTM-CRF tagger <ref type="bibr" target="#b7">(Huang et al., 2015)</ref>, and a state-of-the-art semi-supervised POS tagging algorithm, MINITAGGER <ref type="bibr" target="#b13">(Stratos and Collins, 2015)</ref>, which is also focusing on minimising the amount of labelled data. Note these meth- ods do not use cross-lingual supervision. For a more direct comparison, we include BILSTM- DEBIAS <ref type="bibr" target="#b4">(Fang and Cohn, 2016)</ref>, applied using our proposed cross-lingual supervision based on dic- tionaries, instead of parallel corpora; accordingly the key difference is their linear transformation for the distant data, versus our non-linear transforma- tion to the gold data.</p><p>Results <ref type="table">Table 1</ref> reports the tagging accuracy, showing that our models consistently outperform the baseline techniques. The poor performance of the supervised methods suggests they are overfit- ting the small training set, however this is much less of a problem for our approach (labelled Joint). Note that distant supervision alone gives reason- able performance (labelled DISTANT) however the joint modelling of the ground truth and distant data yields significant improvements in almost all cases. BILSTM-DEBIAS <ref type="bibr" target="#b4">(Fang and Cohn, 2016)</ref> performs worse than our proposed method, indi- cating that a linear transformation is insufficient for modelling distant supervision. The accuracies are higher overall for the European cf. Turkic lan- guages, presumably because these languages are  81.1 82.3 76.1 77.5 75.9 82.1 79.7 78.1 72.6 75.3 JOINT +Cluster 81.9 81.5 78.9 80.1 81.9 76.7 81.2 78.0 70.4 75.7 <ref type="table">Table 1</ref>: POS tagging accuracy on over the ten target languages, showing first approaches using only the gold data; next methods using only distant cross-lingual supervision, and lastly joint multi-task learning.</p><p>English is used as the source language and columns correspond to a specific target language. closer to English, have higher quality dictionaries and in most cases are morphologically simpler. Fi- nally, note the difference between CCA and Clus- ter methods for learning word embeddings which arise from the differing quality of distant supervi- sion between the languages. <ref type="figure" target="#fig_3">Figure 3</ref> compares various active learning heuristics (see §3) based on different taggers, ei- ther a supervised BILSTM (labelled Trad) or our multi-task model which also includes cross- lingual supervision (JOINT).</p><p>Traditional uncertainty-based sampling strate- gies (TOKEN(Trad) and SENT(Trad)) do not work well because models based on limited supervision do not provide accurate uncertainty information, <ref type="bibr">5</ref> and moreover, annotating at the type rather than token level provides a significantly stronger su- pervision signal. The difference is apparent from the decent performance of Random sampling over word types. Overall, SUMTYPE(Joint) outper- forms the other heuristics consistently, underlin- ing the importance of cross-lingual distant super-vision, as well as combining the benefits of un- certainty sampling, type selection and a frequency bias. Comparing the amount of annotation re- quired between the best traditional active learn- ing method SUMTYPE(Trad) and our best method SUMTYPE(Joint), we achieve the same perfor- mance with an order of magnitude less annotated data (100 vs. 1, 000 labelled words).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we proposed a means of tagging a low-resource language without the need for bilingual parallel corpora. We introduced a new cross-lingual distant supervision method based on a bilingual dictionary. Furthermore, deep neu- ral network models can be effective with limited supervision by incorporating distant supervision, in the form of model transfer with cross-lingual word embeddings. We show that traditional un- certainty sampling strategies do not work well on low-resource settings, and introduce new methods based around labelling word types. Overall our approach leads to consistent and substantial im- provements over benchmark methods. <ref type="bibr">Yuan Zhang, David Gaddy, Regina Barzilay, and Tommi Jaakkola. 2016</ref>. Ten pairs to tag- multilingual pos tagging via coarse mapping be- tween embeddings. In Proceedings of the 2016 Con- ference of the North American Chapter of the Asso- ciation for Computational Linguistics: Human Lan- guage Technologies (NAACL-HLT). pages 1307- 1317.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Illustration of the architecture of the joint model, which performs joint inference over both distant supervision (left) and manually labelled data (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Architecture of the universal POS tagger. Cross-lingual word embeddings are pretrained using monolingual corpora and bilingual dictionaries.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>da</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Active learning evaluation on German and Greek, using CCA trained cross-lingual word embeddings. Trad means traditional active learning; Joint means joint multi-task learning.</figDesc></figure>

			<note place="foot" n="1"> We could support more than one class label, by marginalising over the set of valid labels for all tokens in the training objective. 2 http://www.cnts.ua.ac.be/conll2003/ner/</note>

			<note place="foot" n="3"> Although the use of a translation system conveys a dependence on parallel text, high quality word embeddings can be learned directly from bilingual dictionaries such as Panlex (Kamholz et al., 2014). 4 Code available at https://github.com/mengf1/trpos</note>

			<note place="foot" n="5"> Sentence level annotation is likely to be much faster than token or type level annotation, however even if it were an order of magnitude faster it is still not a competitive active learning strategy.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>This work was sponsored by the Defense Ad- vanced Research Projects Agency Information In- novation Office (I2O) under the Low Resource Languages for Emergent Incidents (LORELEI) program issued by DARPA/I2O under Contract</head><p>No. HR0011-15-C-0114. The views expressed are those of the author and do not reflect the official policy or position of the Department of Defense or the U.S. Government. Trevor Cohn was sup- ported by the Australian Research Council Future Fellowship (project number FT130101105).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Referenceš</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Massively multilingual word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Waleed</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Mulcaire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulia</forename><surname>Tsvetkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="431" to="444" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Conll-x shared task on multilingual dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabine</forename><surname>Buchholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erwin</forename><surname>Marsi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth Conference on Computational Natural Language Learning</title>
		<meeting>the Tenth Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="149" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Cross-lingual morphological tagging for low-resource languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Buys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">A</forename><surname>Botha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL). Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics (ACL). Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1954" to="1964" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Unsupervised part-of-speech tagging with bilingual graph-based projections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACLHLT)</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACLHLT)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="600" to="609" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning when to trust distant supervision: An application to lowresource pos tagging using cross-lingual projection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th SIGNLL Conference on Computational Natural Language Learning (CoNLL)</title>
		<meeting>the 20th SIGNLL Conference on Computational Natural Language Learning (CoNLL)<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning a part-of-speech tagger from two hours of annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Garrette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Baldridge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT). Citeseer</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT). Citeseer</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="138" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Cross-lingual dependency parsing based on distributed representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1234" to="1244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Bidirectional lstm-crf models for sequence tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1508.01991</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Panlex: Building a resource for panlingual lexical translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Kamholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Pool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><forename type="middle">M</forename><surname>Colowick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC)</title>
		<meeting>the Ninth International Conference on Language Resources and Evaluation (LREC)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3145" to="3150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Conference on Machine Learning (ICML)</title>
		<meeting>the 8th International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="282" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Recurrent neural network based language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Karafiát</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Burget</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Interspeech</title>
		<imprint>
			<date type="published" when="2010-01" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note>Cernock`Cernock`y, and Sanjeev Khudanpur</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Austin</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Waleed</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonios</forename><surname>Anastasopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Clothiaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cynthia</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Garrette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingpeng</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adhiguna</forename><surname>Kuncoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaurav</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaitanya</forename><surname>Malaviya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Michel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.03980</idno>
		<title level="m">Swabha Swayamdipta, and Pengcheng Yin. 2017. Dynet: The dynamic neural network toolkit</title>
		<meeting><address><addrLine>Yusuke Oda, Matthew Richardson, Naomi Saphra</addrLine></address></meeting>
		<imprint/>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">A universal part-of-speech tagset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1104.2086</idno>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Simple semisupervised pos tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Stratos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="79" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Token and type constraints for cross-lingual part-of-speech tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Täckström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Inducing multilingual POS taggers and NP brackets via robust projection across aligned corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grace</forename><surname>Ngai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2001 Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)</title>
		<meeting>the 2001 Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
