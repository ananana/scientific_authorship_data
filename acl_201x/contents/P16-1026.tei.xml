<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:41+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Jointly Event Extraction and Visualization on Twitter via Probabilistic Modelling</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Zhou</surname></persName>
							<email>d.zhou@seu.edu.cn, gaotianmeng@seu.edu.cn, y.he@cantab.net</email>
							<affiliation key="aff1">
								<orgName type="laboratory">State Key Laboratory for Novel Software Technology</orgName>
								<orgName type="institution">Nanjing University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianmeng</forename><surname>Gao</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>He</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Engineering and Applied Science</orgName>
								<orgName type="institution">Aston University</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Science and Engineering</orgName>
								<orgName type="department" key="dep2">Ministry of Education</orgName>
								<orgName type="laboratory">Key Laboratory of Computer Network and Information Integration</orgName>
								<orgName type="institution">Southeast University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Jointly Event Extraction and Visualization on Twitter via Probabilistic Modelling</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="269" to="278"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Event extraction from texts aims to detect structured information such as what has happened, to whom, where and when. Event extraction and visualization are typically considered as two different tasks. In this paper, we propose a novel approach based on probabilistic modelling to jointly extract and visualize events from tweet-s where both tasks benefit from each other. We model each event as a joint distribution over named entities, a date, a location and event-related keywords. Moreover , both tweets and event instances are associated with coordinates in the visual-ization space. The manifold assumption that the intrinsic geometry of tweets is a low-rank, non-linear manifold within the high-dimensional space is incorporated into the learning framework using a regu-larization. Experimental results show that the proposed approach can effectively deal with both event extraction and visualiza-tion and performs remarkably better than both the state-of-the-art event extraction method and a pipeline approach for event extraction and visualization.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Event extraction, one of the important and chal- lenging tasks in information extraction, aims to detect structured information such as what has happened, to whom, where and when. The out- puts of event extraction could be beneficial for downstream applications such as summarization and personalized news systems. Data visualiza- tion, an important exploratory data analysis task, provides a simple way to reveal the relationships among data <ref type="bibr" target="#b13">(Nakaji and Yanai, 2012)</ref>.</p><p>Although event extraction and visualization are two different tasks and typically studied separately in the literature, these two tasks are highly related. Documents which are close to each other in the low-dimensional visualization space are likely to describe the same event. Events in nearby loca- tions in the visualization space are likely to share similar event elements. Therefore, jointly learn- ing the two tasks could potentially bring benefits to each other. However, it is not straightforward to learn event extraction and visualization jointly since event extraction usually relies on semantic parsing results <ref type="bibr" target="#b11">(McClosky et al., 2011</ref>) while vi- sualization is accomplished by dimensionality re- duction ( <ref type="bibr" target="#b6">Iwata et al., 2007;</ref><ref type="bibr" target="#b10">López-Rubio et al., 2002)</ref>.</p><p>In this paper, we propose a novel probabilistic model, called Latent Event Extraction &amp; Visual- ization (LEEV) model, for joint event extraction and visualization on Twitter. It is partly inspired by the Latent Event Model (LEM) ( <ref type="bibr" target="#b19">Zhou et al., 2015)</ref> where each tweet is assigned to one even- t instance and each event is modeled as a join- t distribution over named entities, a date/time, a location and the event-related keywords. Going beyond LEM, we assume that each event is not only modeled as the joint distribution over event elements as in ( <ref type="bibr" target="#b19">Zhou et al., 2015</ref>), but also asso- ciate with coordinates in the visualization space. The Euclidean distance between a tweet and each events determines which event the tweet should be assigned to. Furthermore, the manifold as- sumption that the intrinsic geometry of tweets is a low-rank, non-linear manifold within the high- dimensional space, is incorporated in the learning framework using a regularization. Experimental results show that the proposed approach can effec- tively deal with both event extraction and visual- ization tasks and performs remarkably better than both the state-of-the-art event extraction method and a pipeline approach for event extraction and visualization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Our proposed work is related to two lines of re- search, event extraction and joint topic modeling and visualization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Event Extraction</head><p>Research on event extraction of tweets can be cat- egorized into domain-specific and open domain approaches. Domain-specific approaches usual- ly have target events in mind and aim to extract events from a particular location or for emergen- cy response during natural disasters. <ref type="bibr" target="#b0">Anantharam et al. (2015)</ref> focused on extracting city events by solving a sequence labeling problem. Evaluation was carried out on a real-world dataset consist- ing of event reports and tweets collected over four months from San Francisco Bay Area. TSum4act ( <ref type="bibr" target="#b14">Nguyen et al., 2015</ref>) was designed for emergency response during disasters and was evaluated on a dataset containing 230,535 tweets.</p><p>Most of open domain approaches focused on extracting a summary of events discussed in so- cial media. For example <ref type="bibr" target="#b2">Benson et al. (2011)</ref> proposed a structured graphical model which si- multaneously analyzed individual messages, clus- tered, and induced a canonical value for each even- t. <ref type="bibr" target="#b4">Capdevila et al. (2015)</ref> proposed a model named Tweet-SCAN based on the hierarchical Dirichlet process to detect events from geo-located tweet- s. To extract more information, a system called SEEFT ( <ref type="bibr" target="#b16">Wang et al., 2015</ref>) used links in tweets and combined tweets and linked articles to identi- fy events. <ref type="bibr" target="#b18">Zhou et al. (2014;</ref> proposed an unsupervised Bayesian model called latent event model (LEM) for event extraction from Twitter by assuming that each tweet message is assigned to one event instance and each event is modeled as a joint distribution over named entities, a date/time, a location and the event-related keywords. Our proposed method is partly inspired by ( <ref type="bibr" target="#b19">Zhou et al., 2015)</ref>. However, different from previous methods, our approach not only extracts the structured rep- resentation of events, but also learns the coordi- nates of events and tweets simultaneously.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Joint Topic Modeling and Visualization</head><p>Since our proposed approach can be considered as a variant of topic model, we also review the relat- ed work of joint topic modeling and visualization here.</p><p>Traditionally, topic modeling and visualization are considered as two disjoint tasks and can be combined for pipeline processing. For example, probabilistic latent semantic analysis (Hofmann, 1999) can be first performed followed by para- metric embedding ( <ref type="bibr" target="#b6">Iwata et al., 2007)</ref>. Another pipeline approach <ref type="bibr" target="#b12">(Millar et al., 2009</ref>) is based on latent Dirichlet allocation followed by self- organizing maps <ref type="bibr" target="#b10">(López-Rubio et al., 2002</ref>).</p><p>Jointly modeling topics and visualization is a new problem explored in very few works. The state-of-the-art is a joint approach proposed in <ref type="bibr" target="#b7">(Iwata et al., 2008</ref>). In this model, both documents and topics are assumed to have latent coordinates in a visualization space. The topic proportions of a document are determined by the distances be- tween the document and the topics in the visual- ization space, and each word is drawn from one of the topics according to the document's topic pro- portions. A visualization was obtained by fitting the model to a given set of documents using the EM algorithm. Following the same line, by con- sidering the local consistency in terms of the in- trinsic geometric structure of the document mani- fold, an unsupervised probabilistic model, called SEMAFORE, was proposed in ( <ref type="bibr" target="#b8">Le and Lauw, 2014a</ref>) by preserving the manifold in the lower dimensional space. In ( <ref type="bibr" target="#b9">Le and Lauw, 2014b)</ref>, a semantic visualization model is learned by asso- ciating each document a coordinate in the visu- alization space, a multinomial distribution in the topic space, and a directional vector in a high- dimensional unit hypersphere in the word space.</p><p>Our work is partly inspired by <ref type="bibr" target="#b8">(Le and Lauw, 2014a)</ref>. However, our proposed approach differ- s from ( <ref type="bibr" target="#b8">Le and Lauw, 2014a</ref>) in that events, in- stead of topics, are modelled as the joint distribu- tion over event elements. Both tweets and events are associate with coordinates in the visualization space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head><p>We follow the same pre-processing steps de- scribed in ( <ref type="bibr" target="#b19">Zhou et al., 2015</ref>) to filter out non- event-related tweets and extract dates, locations, and named entities by temporal resolution, part- of-speech (POS) tagging and named entity recog- nition. The pre-processed tweets are then fed into our proposed model for event extraction and visu- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Notation</head><p>Definition e event index, e ∈ {1..E} W = {w m } tweets, m ∈ {1..M } Z = {z m } event labels for tweets N my number of named entities in w m N md number of dates in w m N ml number of locations in w m N mk number of keywords in w m θ ey probability of named entity y in event e φ ed probability of date d in event e ψ el probability of location l in event e ω ek probability of keyword k in event e β, γ, η, λ Dirichlet hyperparameters χ, δ</p><p>Normal hyperparameters G dimension of visualization space alization. We describe our model in more details below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Latent Event Extraction &amp; Visualization (LEEV) Model</head><p>We propose an unsupervised latent variable mod- el called the Latent Event Extraction &amp; Visualiza- tion (LEEV) model which simultaneously extracts events from tweets and generates a visualization of the events. <ref type="table" target="#tab_0">Table 1</ref> lists notations used in this paper.</p><p>In LEEV, each tweet message w m , m ∈ {1...M } is associated with a latent coordinate x m in the visualization space. Each event e ∈ {1...E} is also associated with a coordinate ϕ e . Assum- ing that each tweet message w m , m ∈ {1...M } is assigned to one event instance z m = e and e is modeled as a joint distribution over named entities y, the date d when e happened, the location l and the event-related keywords k, the generative pro- cess of the model is described as follows: Here, β, γ, η, λ, χ, δ are priors, I is an identi- ty matrix, and P (e|x m , Φ) is the probability of the tweet w m with coordinate x m belonging to the event e. It is defined as,</p><formula xml:id="formula_0">• For each event e ∈ {1..E}, draw multino- mial distributions θ e ∼ Dirichlet(β), φ e ∼ Dirichlet(γ), ψ e ∼ Dirichlet(η), ω e ∼ Dirichlet(λ), draw event coordinate ϕ e ∼ Normal(0, χ −1 I); • For each tweet w m , m ∈ {1..M } * Choose tweet coordinate: x m ∼ Normal(0, δ −1 I); * Choose an event z m = e ∼ Multinomial({P (e|x m , Φ) E e=1 }); *</formula><formula xml:id="formula_1">P (e|xm, Φ) = exp(− 1 2 ∥ xm − ϕe ∥ 2 ) ∑ E e ′ =1 exp(− 1 2 ∥ xm − ϕ e ′ ∥ 2 ) . (1)</formula><p>It is calculated as the normalized Euclidean dis- tance between a tweet w m and an event e. Us- ing this equation, when the Euclidean distance be- tween a tweet w m and and an event e is small, the probability that tweet w m belongs to event e becomes large. The graphical model of LEEV is shown in <ref type="figure" target="#fig_0">Figure 1</ref>. The parameters to be learned are</p><formula xml:id="formula_2">Θ = {θ e , φ e , ψ e , ω e } E e=1 , tweets' coordinates X = {x m } M m=1</formula><p>and events' coordinates Φ = {ϕ e } E e=1 , which are collectively denoted as B = ⟨Θ, X , Φ⟩. Let</p><formula xml:id="formula_3">H(wm, e) = Nmy ∏ n=1 P (yn|θe) N md ∏ n=1 P (dn|φe) N ml ∏ n=1 P (ln|ψe) N mk ∏ n=1 P (kn|ωe).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>271</head><p>The log likelihood of B given tweets W is,</p><formula xml:id="formula_4">L(B|W ) = M ∑ m=1 log { E ∑ e=1 P (e|xm, Φ) × H(wm, e) } + M ∑ m=1 log(P (xm)) + E ∑ e=1 log(P (ϕe)) + E ∑ e=1 {log(P (θe) * P (φe) * P (ψe) * P (ωe))}.<label>(2)</label></formula><p>For the events' coordinate ϕ e and tweets' coordi- nate x m , we use a Gaussian prior with a zero mean and a spherical covariance:</p><formula xml:id="formula_5">p(ϕ e ) = ( χ 2π ) G 2 exp(− χ 2 ∥ ϕ e ∥ 2 ) p(x m ) = ( δ 2π ) G 2 exp(− δ 2 ∥ x m ∥ 2 ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">LEEV with Manifold Regularization</head><p>Recent studies suggest that the intrinsic geome- try of textual data is a low-rank, non-linear man- ifold lying in the high dimensional space <ref type="bibr" target="#b3">(Cai et al., 2008;</ref><ref type="bibr" target="#b17">Zhang et al., 2005</ref>). We therefore as- sume that when two tweets w i and w j are close in the intrinsic geometry of the manifold Υ, their low-rank representations should be close as well.</p><p>To capture this assumption, we consider Lapla- cian Eigenmaps (LE) <ref type="bibr" target="#b1">(Belkin and Niyogi, 2003)</ref> which has been commonly used in manifold learn- ing algorithms ( <ref type="bibr" target="#b8">Le and Lauw, 2014a)</ref>. It constructs a k-nearest neighbors graph to represent data re- siding on a low-dimensional manifold embedded in a higher-dimensional space. In this paper, we use LE to incorporate neighborhood information of tweets. We construct a manifold graph with edges connecting two data points w i and w j . Set the edge weight υ ij = 1 if w j is one of the k- nearest neighbors of w i ; Otherwise υ ij = 0. That makes LEEV an special case when ξ = 0. We represent each tweet as a word-count vector, i.e., each element of a vector is weighted by its corre- sponding term frequency, and use cosine similari- ty metric to measure the distance between tweets when constructing the manifold graph. We also tried vectors with the TFIDF weighting strategy to represent tweets and found word-count vectors give better results. We apply a regularization framework to incor- porate a manifold structure into a learning model.</p><formula xml:id="formula_6">The new regularized log-likelihood function L is L(B|W, Υ) = L(B|W ) − ξ 2 R(B|Υ),<label>(3)</label></formula><p>where ξ is the regularization parameter. The sec- ond component R is a regularization function, which consists of two parts:</p><formula xml:id="formula_7">R(B|Υ) = R + (B|Υ) + R − (B|Υ),<label>(4)</label></formula><formula xml:id="formula_8">R + (B|Υ) = M ∑ i,j=1;i̸ =j υ ij · F (w i , w j ),<label>(5)</label></formula><formula xml:id="formula_9">R − (B|Υ) = M ∑ i,j=1;i̸ =j 1 − υ ij F(w i , w j ) + 1 ,<label>(6)</label></formula><p>where F is a distance function that operates on the low rank space. We define F as the squared Eu- clidean distance of coordinates in the visualization space. F(w i , w j )is computed as follows:</p><formula xml:id="formula_10">F(w i , w j ) =∥ x i − x j ∥ 2 .<label>(7)</label></formula><p>Minimizing R + leads to minimizing the distance between neighbors and minimizing R − leads to maximizing the distance between non-neighbors. By enforcing manifold learning, we capture the spirit of keeping neighbors close and keeping none-neighbors apart.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Parameter Estimation</head><p>As in Equation 2, the presence of the sum over e prevents the logarithm form directly acting on the joint distribution. Assuming that the corre- sponding latent event z m of each tweet w m is known, {W, Z} is called the complete data. Max- imizing the log likelihood of the complete data, log P (W, Z|B), can be easily done. However, in practice we don't observe the latent variables Z and only have the incomplete data W . There- fore, the expectation maximization (EM) algorith- m is employed to handle the incomplete data. EM involves an efficient iterative procedure to com- pute the Maximum Likelihood estimation of prob- abilistic models with unobserved latent variables involved.</p><p>The class posterior probability of the m th tweet under the current parameter valuesˆBvaluesˆ valuesˆB, P (z m = e|m, ˆ B), is given as follows:</p><formula xml:id="formula_11">P (z m = e|m, ˆ B) = P (z m = e|ˆxe|ˆ e|ˆx m , ˆ Φ, ˆ B) × H(w m , e) ∑ E e ′ =1 P (z m = e ′ | ˆ x m , ˆ Φ, ˆ B) × H(w m , e ′ ) ,<label>(8)</label></formula><p>which corresponds to the E-step in EM algorithm.</p><p>In M-step, model parameters B are updated by maximizing the regularized conditional expecta- tion of the complete data log likelihood with priors defined as follows:</p><formula xml:id="formula_12">Q(B|ˆBB|ˆ B|ˆB) = M ∑ m=1 E ∑ e=1 {P (zm = e|m, ˆ B) × log[P (e|xm, Φ) × H(wm, e)]} + M ∑ m=1 log(P (xm)) + E ∑ e=1 log(P (ϕe)) + E ∑ e=1 {log(P (θe) * P (φe) * P (ψe) * P (ωe))} − ξ 2 R(B|Υ),</formula><p>where P (z m = e|m, ˆ B) is calculated in E-step. By maximizing Q(B|ˆBB|ˆ B|ˆB) w.r.t θ ey , φ ed , ψ el , ω ek , the next estimates are given as follows,</p><formula xml:id="formula_13">θey = M ∑ m=1 Nmy ∑ n=1 I(ymn = y)P (zm = e|m, ˆ B) + β Y ∑ y=1 M ∑ m=1 Nmy ∑ n=1 I(ymn = y)P (zm = e|m, ˆ B) + Y β , φ ed = M ∑ m=1 N md ∑ n=1 I(dmn = d)P (zm = e|m, ˆ B) + γ D ∑ d=1 M ∑ m=1 N md ∑ n=1 I(dmn = d)P (zm = e|m, ˆ B) + Dγ , ψ el = M ∑ m=1 N ml ∑ n=1 I(lmn = l)P (zm = e|m, ˆ B) + η L ∑ l=1 M ∑ m=1 N ml ∑ n=1 I(lmn = l)P (zm = e|m, ˆ B) + Lη , ω ek = M ∑ m=1 N mk ∑ n=1 I(kmn = k)P (zm = e|m, ˆ B) + λ K ∑ k=1 M ∑ m=1 N mk ∑ n=1 I(kmn = k)P (zm = e|m, ˆ B) + Kη ,</formula><p>where Y, D, L, K are the total numbers of distinc- t named entities, dates, locations, and words ap- peared in the whole Twitter corpus, respectively. ϕ e and x m cannot be solved in a closed form, and are estimated by maximizing Q(B|ˆBB|ˆ B|ˆB) using quasi-Newton method. The gradients of Q(B|ˆBB|ˆ B|ˆB) w.r.t ϕ e and x m are as follows:</p><formula xml:id="formula_14">∂Q ∂ϕe = M ∑ m=1 p(e|m, ˆ B)(p(e|xm, Φ) − 1)(ϕe − xm) − χϕe, ∂Q ∂xm = E ∑ e=1 p(e|m, ˆ B)(p(e|xm, Φ) − 1)(xm − ϕe) − δxm − ξ 2 ∂R(B|Υ) ∂xm ,</formula><p>where the gradient of R(B|Υ) w.r.t. x m is com- puted as follows:</p><formula xml:id="formula_15">∂R(B|Υ) ∂xm = M ∑ j=1,j̸ =m 2υmj(xm − xj) − M ∑ j=1,j̸ =m 2(xm − xj) 1 − υmj (F (xm, xj) + 1) 2 .</formula><p>We set the parameter χ = 0.00005, δ = 0.05, β = γ = η = λ = 0.1 and run EM algorithm for 50 iterations. Finally we select an entity y, a date d, a location l and two keywords k with the highest probabilities to form a tuple ⟨y, d, l, k⟩ to represent each potential event.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Post-processing</head><p>In order to filter out spurious events, we calculate the correlation coefficient of each event element. Remove the event element if its correlation coef- ficient is less than a threshold C e and remove the event if the sum of the correlation coefficients of all its four event elements is less than C t .</p><p>For an event element A, its correlation coeffi- cient is calculated below:</p><formula xml:id="formula_16">C A = log ∑ B∈Ω B̸ =A #(A, B) #(A) ,<label>(0)</label></formula><p>where Ω is the set of the four event elements ⟨y, d, l, k⟩ and #(x) indicates the number of times x appeared in the whole corpus. We empirically set C e to 0.4 and C t to 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we firstly describe the datasets used in our experiments and then present the experi- mental results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Setup</head><p>We choose two datasets for model evaluation. The first one is the First Story Detection (FSD) dataset (Petrovic et al., 2013) (Dataset I) which contains 2,499 tweets published between 7th July and 12th September 2011. These tweets have been man- ually annotated with 27 events, covering a wide range of topics from accidents to science discover- ies and from disasters to celebrity news. We filter out events mentioned in less than 15 tweets since events mentioned in very few tweets are less likely to be significant. The final dataset contains 2,453 tweets annotated with 20 events. This dataset has been previously used for evaluating event extrac- tion models and the state-of-the-art results have been achieved using LEM ( <ref type="bibr" target="#b19">Zhou et al., 2015</ref>). We also create another dataset, called Dataset II, by manually annotating 1,000 tweets published in December 2010. A total of 20 events are annotat- ed. We compare our model with LEM ( <ref type="bibr" target="#b19">Zhou et al., 2015)</ref>, which also extracts events as 4-tuples ⟨ y,d,l,k ⟩. The main difference between LEM and our model is that LEM directly estimates the event distribution from the sampled latent event labels, while we derive the distribution from coordinates of tweets and events x m , ϕ e . We re-implemented the system described in ( <ref type="bibr" target="#b19">Zhou et al., 2015)</ref> and used the same evaluation metrics such as preci- sion, recall and F-measure. Precision is defined as the proportion of the correctly identified events out of the system returned events. Recall is de- fined as the proportion of correctly identified true events. For calculating the precision of the 4-tuple ⟨y, d, l, k⟩, we use following criteria:</p><p>• Do the entity y, location l, date d and key- word k that we have extracted refer to the same event?</p><p>• If the extracted representation contains key- words, are they informative enough to tell us what happened?</p><p>As mentioned in Section 2, PE ( <ref type="bibr" target="#b6">Iwata et al., 2007</ref>) is a nonlinear visualization method which takes a set of class posterior vectors as input and embeds samples in a low-dimensional Euclidean space. By minimizing the sum of Kullback- Leibler divergences, PE tries to preserve the poste- rior structure in the embedding space. In order to evaluate the visualization results, we compare our proposed method with a pipeline approach, even- t extraction using LEM ( <ref type="bibr" target="#b19">Zhou et al., 2015)</ref> fol- lowed by event visualization using PE ( <ref type="bibr" target="#b6">Iwata et al., 2007)</ref>, named as LEM+PE. <ref type="table" target="#tab_1">Table 2</ref> shows the event extraction results on the two datasets. LEEV+R is LEEV with manifold regularization incorporated, in which the model parameters are estimated by the EM algorithm de- scribed in Section 3.3. For LEEV and LEEV+R, the number of events, E, is set to 50 for both datasets. For LEEV+R, the number of neighbor- hood size k is set to 10 and the regularization pa- rameter ξ is set to 1. For LEM, E is set to 25 for both datasets following the suggestion in ( <ref type="bibr" target="#b19">Zhou et al., 2015)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Event Extraction Results</head><p>We ran our experiments on a server equipped with 3.40 GHz Intel Corel i7 CPU and 8 GB mem- ory. The average running time of LEEV is 2328.1 seconds on Dataset I and 940.7 seconds on Dataset II for one iteration. The average running time  It can be observed that both LEEV and LEEV+R outperforms the state-of-the-art result- s achieved by LEM on Dataset I. In particular, LEEV improves upon LEM by over 5% in F- measure and with regularization, LEEV-R further improves upon LEEV by over 4%. A similar trend is observed on Dataset II where both LEEV and LEEV+R outperforms LEM and the best perfor- mance is given by LEEV+R. This shows the ef- fectiveness of using regularization in LEEV. We will further demonstrate its importance in visual- ization results. Overall, we see superior perfor- mance of LEEV+R over the other two models, with the F-measure of over 89% being achieved on both datasets.</p><p>As described in Section 3.1, the coordinates of tweets and events are randomly initialized. There- fore, we would like to see whether the perfor- mance of event extraction is influenced heavily by random initialization. We repeat the experiments on the two datasets for 10 times using LEEV+R. The experimental results are shown in <ref type="figure" target="#fig_1">Figure 2</ref>. It can be observed that the performance of LEEV+R is quite stable on both datasets. The standard deviation of F-measure on both Dataset I and I- I is 0.036, which shows that random initialization does not have significant impact on the final per- formance of the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Impact of Number of Events E</head><p>We need to pre-set the number of events E in the proposed approach. <ref type="figure" target="#fig_2">Figure 3</ref> shows the perfor- mance of event extraction based on LEEV+R ver- sus different values of E on the two datasets. It can be observed that the performance of the pro- posed approach improves with the increased value of E and when E goes beyond 50, we notice a more balanced precision/recall values and a rela- tively stable F-measure. This shows that the pro- posed approach is less sensitive to the number of events E so long as E is set to a relatively larger value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Impact of Neighborhood Size</head><p>As described in Section 3.2, the neighborhood in- formation of tweets is incorporated into the learn- ing framework. A manifold graph with edges con- necting two tweets (or data points) w i and w j is constructed by setting the edge weight υ ij = 1 if w j is among the k-nearest neighbors of w i and υ ij = 0 otherwise. Therefore, it is crucial to see whether the performance of LEEV+R heavily de- pends on the setting of k. <ref type="figure" target="#fig_3">Figure 4</ref> shows the per- formance of our proposed approach with different neighborhood size k. It can be observed that the performance of LEEV+R is quite stable and inde- pendent of the k value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Visualization Results</head><p>We show the visualization results produced by d- ifferent approaches on the two datasets in <ref type="figure">Fig</ref> For Dataset I, it can be observed from <ref type="figure">Fig- ure 5(a)</ref> that the visualization result generated by LEM+PE is not informative. Tweets from d- ifferent events are mixed together and events are evenly distributed across the whole visualization space. Thus, this visualization does not provide any sensible information about the relationships between tweets and events. The result generated by LEEV without manifold Regularization unit R seems better than that from LEM+PE, as shown in <ref type="figure">Figure 5</ref>(b). However, a large amount of tweets crowded together at the center, which makes it d- ifficult to reveal the relations between tweets and events. The best visualization result is given by LEEV+R as shown in <ref type="figure">Figure 5</ref>(c) that differen- t events are well separated and related events are located nearby. For example, the three events en- closed by a red circle represent "people died in ter- rorist attacks in Delhi, Oslo and Norway" respec- tively, while three events in the blue circle rep- resent "riots in Ealing, Totteham and Croydon", respectively. And two events in the black cir- cle represent "American credit rating" and "House  <ref type="figure" target="#fig_6">Figure 7</ref>. These four events are "Senate vote on repealing gay ban", "US state governor plan to visit North Korea", "Send letter to President Obama to stop tax cut deal" and "Congress passed the Child Nutrition Bill". Their corresponding tweets are denoted as green '△', blue '2', green '2' and blue '+' in- dividually in <ref type="figure" target="#fig_6">Figure 7</ref>. It can be observed that these four events are all about government activ- ities of the United States, and they are located close to each other in the low-dimensional visu- alization space. Moreover, the tweets describing the same event are located close to each other and center around their corresponding events, while the tweets describing different events are far away from each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In this paper, we have proposed an unsupervised Bayesian model, called Latent Event Extraction &amp; Visualization (LEEV) model, to extract the struc- tured representations of events from social me- dia and simultaneously visualize them in a two- dimensional Euclidean space. The proposed ap- proach has been evaluated on two datasets. Exper- imental results show that the proposed approach outperforms the previously reported best result on  Dataset I by nearly 10% in F-measure. Visual- ization results show that the proposed approach with manifold regularization can significantly im- prove the quality of event visualization. These re- sults show that by jointly learning event extrac- tion and visualization, our proposed approach is able to give better results on both tasks. In fu- ture work, we will investigate scalable and paral- lel model learning to explore the performance of our model for large-scale real-time event extrac- tion and visualization.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Latent Event Extraction &amp; Visualization (LEEV) Model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Experimental results of LEEV+R in 10 different runs.</figDesc><graphic url="image-1.png" coords="6,307.92,63.16,217.33,163.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The performance of LEEV+R with different number of events E.</figDesc><graphic url="image-2.png" coords="7,72.64,63.16,217.33,163.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The performance of LEEV+R with different neighborhood size k.</figDesc><graphic url="image-3.png" coords="7,307.92,63.35,217.33,163.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>- ure 5 and 6 respectively. We compare LEEV and LEEV+R with the pipeline approach LEM+PE. In the figures, each point represents a tweet and d- ifferent shapes and colors represent the different events they are associated with. Each red cross represents an extracted event with coordinate ϕ z .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 5: Visualization results on Dataset I.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Four representative events and their corresponding tweets in the red circle of Figure 6(c).</figDesc><graphic url="image-4.png" coords="9,164.45,67.65,265.68,199.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 : Definition of Notations.</head><label>1</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Comparison of the event extraction re- sults on the two datasets.</figDesc><table>Dataset I 
Method 
Prec. (%) Rec. (%) F-measure (%) 
LEM 
84.00 
76.19 
80.35 
LEEV 
92.10 
80.00 
85.62 
LEEV+R 
91.91 
88.50 
89.88 
Dataset II 
Method 
Prec. (%) Rec. (%) F-measure (%) 
LEM 
80.00 
90.00 
84.70 
LEEV 
83.33 
95.00 
88.78 
LEEV+R 
86.18 
92.50 
89.19 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank the anonymous reviewers for their valuable comments and suggestions. This work was funded by the National Natural Science Foundation of China (61528302), the Innovate UK under the grant number 101779 and the Collabo-rative Innovation Center of Wireless Communica-tions Technology.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Extracting city traffic events from social streams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pramod</forename><surname>Anantharam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Payam</forename><surname>Barnaghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krishnaprasad</forename><surname>Thirunarayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Sheth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Intelligent Systems and Technology</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">110206</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Laplacian eigenmaps for dimensionality reduction and data representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikhail</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><surname>Niyogi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1373" to="1396" />
			<date type="published" when="2003-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Event discovery in social media feeds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Benson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aria</forename><surname>Haghighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="389" to="398" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Modeling hidden topics on document manifold</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deng</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaozhu</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th ACM Conference on Information and Knowledge Management, CIKM &apos;08</title>
		<meeting>the 17th ACM Conference on Information and Knowledge Management, CIKM &apos;08<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="911" to="920" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Tweet-scan: An event discovery technique for geo-located tweets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Capdevila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jess</forename><surname>Cerquides</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordi</forename><surname>Nin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordi</forename><surname>Torres</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Intelligence Research and Development: Proceedings of the 18th International Conference of the Catalan Association for Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">277</biblScope>
			<biblScope unit="page" from="110" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Probabilistic latent semantic indexing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;99</title>
		<meeting>the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;99<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="50" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Parametric embedding for class visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoharu</forename><surname>Iwata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazumi</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naonori</forename><surname>Ueda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Stromsten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2536" to="56" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Probabilistic latent semantic visualization: Topic model for visualizing documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoharu</forename><surname>Iwata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeshi</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naonori</forename><surname>Ueda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;08</title>
		<meeting>the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;08<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="363" to="371" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Manifold learning for jointly modeling topic and visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">V</forename><surname>Tuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hady</forename><forename type="middle">W</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lauw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence, AAAI&apos;14</title>
		<meeting>the Twenty-Eighth AAAI Conference on Artificial Intelligence, AAAI&apos;14</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1960" to="1967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Semantic visualization for spherical representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">V</forename><surname>Tuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hady</forename><forename type="middle">W</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lauw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;14</title>
		<meeting>the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;14<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1007" to="1016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Self-organizing dynamic graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ezequiel</forename><surname>López-Rubio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">José</forename><surname>Muñoz-Pérez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">José Antonio Gómez-Ruiz</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Processing Letters</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="93" to="109" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Association for Computational Linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1626" to="1635" />
		</imprint>
	</monogr>
	<note>Event extraction as dependency parsing</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Document clustering and visualization with latent dirichlet allocation and self-organizing maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Millar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gilbert</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mendenhall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Florida Artificial Intelligence Research Society Conference</title>
		<meeting>Florida Artificial Intelligence Research Society Conference</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Visualization of real-world events with geotagged tweet photos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuke</forename><surname>Nakaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keiji</forename><surname>Yanai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 IEEE International Conference on Multimedia and Expo Workshops, ICMEW &apos;12</title>
		<meeting>the 2012 IEEE International Conference on Multimedia and Expo Workshops, ICMEW &apos;12<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="272" to="277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Tsum4act: A framework for retrieving and summarizing actionable tweets during a disaster for reaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Tien</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asanobu</forename><surname>Kitamoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tri-Thanh</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Knowledge Discovery and Data Mining</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="64" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Can twitter replace newswire for breaking news?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saša</forename><surname>Petrovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miles</forename><surname>Osborne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Craig</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iadh</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Shrimpton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International AAAI Conference on Weblogs and Social Media</title>
		<meeting>the 7th International AAAI Conference on Weblogs and Social Media</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Seeft: Planned social event discovery and attribute extraction by fusing twitter and web content</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Fink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Agichtein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International AAAI Conference on Web and Social Media</title>
		<meeting>the Ninth International AAAI Conference on Web and Social Media</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="483" to="492" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Text classification with kernels on the multinomial manifold</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dell</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wee Sun</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;05</title>
		<meeting>the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;05<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="266" to="273" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A simple bayesian modelling approach to event extraction from twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangyu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="700" to="705" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An unsupervised framework of exploring events on twitter: Filtering, extraction and categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangyu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence, AAAI&apos;15</title>
		<meeting>the Twenty-Ninth AAAI Conference on Artificial Intelligence, AAAI&apos;15</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2468" to="2474" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
