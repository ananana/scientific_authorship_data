<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:01+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Hybrid Code Networks: practical and efficient end-to-end dialog control with supervised and reinforcement learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><forename type="middle">D</forename><surname>Williams</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kavosh</forename><surname>Asadi</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Zweig</surname></persName>
						</author>
						<title level="a" type="main">Hybrid Code Networks: practical and efficient end-to-end dialog control with supervised and reinforcement learning</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</title>
						<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="665" to="677"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-1062</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>End-to-end learning of recurrent neural networks (RNNs) is an attractive solution for dialog systems; however, current techniques are data-intensive and require thousands of dialogs to learn simple behaviors. We introduce Hybrid Code Networks (HCNs), which combine an RNN with domain-specific knowledge encoded as software and system action templates. Compared to existing end-to-end approaches, HCNs considerably reduce the amount of training data required, while retaining the key benefit of inferring a latent representation of dialog state. In addition, HCNs can be optimized with supervised learning, reinforcement learning, or a mixture of both. HCNs attain state-of-the-art performance on the bAbI dialog dataset (Bordes and Weston, 2016), and outperform two commercially deployed customer-facing dialog systems.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Task-oriented dialog systems help a user to ac- complish some goal using natural language, such as making a restaurant reservation, getting techni- cal support, or placing a phonecall. Historically, these dialog systems have been built as a pipeline, with modules for language understanding, state tracking, action selection, and language genera- tion. However, dependencies between modules in- troduce considerable complexity -for example, it is often unclear how to define the dialog state and what history to maintain, yet action selection re- lies exclusively on the state for input. Moreover, training each module requires specialized labels. * Currently at JPMorgan Chase Recently, end-to-end approaches have trained recurrent neural networks (RNNs) directly on text transcripts of dialogs. A key benefit is that the RNN infers a latent representation of state, obviat- ing the need for state labels. However, end-to-end methods lack a general mechanism for injecting domain knowledge and constraints. For example, simple operations like sorting a list of database re- sults or updating a dictionary of entities can ex- pressed in a few lines of software, yet may take thousands of dialogs to learn. Moreover, in some practical settings, programmed constraints are es- sential -for example, a banking dialog system would require that a user is logged in before they can retrieve account information.</p><p>This paper presents a model for end-to-end learning, called Hybrid Code Networks (HCNs) which addresses these problems. In addition to learning an RNN, HCNs also allow a developer to express domain knowledge via software and ac- tion templates. Experiments show that, compared to existing recurrent end-to-end techniques, HCNs achieve the same performance with considerably less training data, while retaining the key benefit of end-to-end trainability. Moreover, the neural network can be trained with supervised learning or reinforcement learning, by changing the gradi- ent update applied. This paper is organized as follows. Section 2 describes the model, and Section 3 compares the model to related work. Section 4 applies HCNs to the bAbI dialog dataset <ref type="bibr" target="#b0">(Bordes and Weston, 2016)</ref>. Section 5 then applies the method to real customer support domains at our company. Sec- tion 6 illustrates how HCNs can be optimized with reinforcement learning, and Section 7 concludes.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Model description</head><p>At a high level, the four components of a Hy- brid Code Network are a recurrent neural net- work; domain-specific software; domain-specific action templates; and a conventional entity extrac- tion module for identifying entity mentions in text. Both the RNN and the developer code maintain state. Each action template can be a textual com- municative action or an API call. The HCN model is summarized in <ref type="figure" target="#fig_1">Figure 1</ref>.</p><p>The cycle begins when the user provides an ut- terance, as text (step 1). The utterance is featurized in several ways. First, a bag of words vector is formed (step 2). Second, an utterance embedding is formed, using a pre-built utterance embedding model (step 3). Third, an entity extraction module identifies entity mentions (step 4) -for example, identifying "Jennifer Jones" as a &lt;name&gt; entity. The text and entity mentions are then passed to "Entity tracking" code provided by the developer (step 5), which grounds and maintains entities - for example, mapping the text "Jennifer Jones" to a specific row in a database. This code can option- ally return an "action mask", indicating actions which are permitted at the current timestep, as a bit vector. For example, if a target phone number has not yet been identified, the API action to place a phone call may be masked. It can also option- ally return "context features" which are features the developer thinks will be useful for distinguish- ing among actions, such as which entities are cur- rently present and which are absent.</p><p>The feature components from steps 1-5 are con- catenated to form a feature vector (step 6). This vector is passed to an RNN, such as a long short- term memory (LSTM) (Hochreiter and Schmidhu- ber, 1997) or gated recurrent unit (GRU) ( <ref type="bibr" target="#b2">Chung et al., 2014</ref>). The RNN computes a hidden state (vector), which is retained for the next timestep (step 8), and passed to a dense layer with a soft- max activation, with output dimension equal to the number of distinct system action templates (step 9). 1 Thus the output of step 9 is a distribution over action templates. Next, the action mask is applied as an element-wise multiplication, and the result is normalized back to a probability distribution (step 10) -this forces non-permitted actions to take on probability zero. From the resulting distribution (step 11), an action is selected (step 12). When RL is active, exploration is required, so in this case an action is sampled from the distribution; when RL is not active, the best action should be chosen, and so the action with the highest probability is always selected.</p><p>The selected action is next passed to "Entity output" developer code that can substitute in en- tities (step 13) and produce a fully-formed action -for example, mapping the template "&lt;city&gt;, right?" to "Seattle, right?". In step 14, control branches depending on the type of the action: if it is an API action, the corresponding API call in the developer code is invoked (step 15) -for example, to render rich content to the user. APIs can act as sensors and return features relevant to the dialog, so these can be added to the feature vector in the next timestep (step 16). If the action is text, it is rendered to the user (step 17), and cycle then re- peats. The action taken is provided as a feature to the RNN in the next timestep (step 18).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Related work</head><p>Broadly there are two lines of work applying ma- chine learning to dialog control. The first de- composes a dialog system into a pipeline, typ- ically including language understanding, dialog state tracking, action selection policy, and lan- guage generation ( <ref type="bibr" target="#b13">Levin et al., 2000;</ref><ref type="bibr" target="#b28">Singh et al., 2002;</ref><ref type="bibr" target="#b37">Williams and Young, 2007;</ref><ref type="bibr" target="#b36">Williams, 2008;</ref><ref type="bibr" target="#b9">Hori et al., 2009;</ref><ref type="bibr" target="#b12">Lee et al., 2009;</ref><ref type="bibr" target="#b5">Griol et al., 2008;</ref><ref type="bibr">Young et al., 2013;</ref><ref type="bibr" target="#b17">Li et al., 2014</ref>). Specifi- cally related to HCNs, past work has implemented the policy as feed-forward neural networks , trained with supervised learning fol- lowed by reinforcement learning ( . In these works, the policy has not been recur- rent -i.e., the policy depends on the state tracker to summarize observable dialog history into state features, which requires design and specialized la- beling. By contrast, HCNs use an RNN which au- tomatically infers a representation of state. For learning efficiency, HCNs use an external light- weight process for tracking entity values, but the policy is not strictly dependent on it: as an illustra- tion, in Section 5 below, we demonstrate an HCN- based dialog system which has no external state tracker. If there is context which is not apparent in the text in the dialog, such as database status, this can be encoded as a context feature to the RNN.</p><p>The second, more recent line of work applies recurrent neural networks (RNNs) to learn "end- to-end" models, which map from an observable dialog history directly to a sequence of output words ( <ref type="bibr" target="#b30">Sordoni et al., 2015;</ref><ref type="bibr" target="#b26">Shang et al., 2015;</ref><ref type="bibr" target="#b34">Vinyals and Le, 2015;</ref><ref type="bibr">Yao et al., 2015;</ref><ref type="bibr" target="#b24">Serban et al., 2016;</ref><ref type="bibr">Li et al., 2016a,c;</ref><ref type="bibr" target="#b20">Luan et al., 2016;</ref><ref type="bibr">Xu et al., 2016;</ref><ref type="bibr">Li et al., 2016b;</ref><ref type="bibr" target="#b21">Mei et al., 2016;</ref>). These systems can be applied to task-oriented domains by adding special "API call" actions, enumerating database output as a sequence of tokens <ref type="bibr" target="#b0">(Bordes and Weston, 2016)</ref>, then learning an RNN using Memory Networks ( <ref type="bibr" target="#b32">Sukhbaatar et al., 2015)</ref>, gated memory networks ( <ref type="bibr" target="#b18">Liu and Perez, 2016)</ref>, query reduction networks ( <ref type="bibr" target="#b23">Seo et al., 2016)</ref>, and copy- augmented networks <ref type="bibr" target="#b4">(Eric and Manning, 2017)</ref>. In each of these architectures, the RNN learns to manipulate entity values, for example by saving them in a memory. Output is produced by gen- erating a sequence of tokens (or ranking all pos- sible surface forms), which can also draw from this memory. HCNs also use an RNN to accu- mulate dialog state and choose actions. However, HCNs differ in that they use developer-provided action templates, which can contain entity refer- ences, such as "&lt;city&gt;, right?". This design re- duce learning complexity, and also enable the soft- ware to limit which actions are available via an ac- tion mask, at the expense of developer effort. To further reduce learning complexity in a practical system, entities are tracked separately, outside the the RNN, which also allows them to be substituted into action templates. Also, past end-to-end re- current models have been trained using supervised learning, whereas we show how HCNs can also be trained with reinforcement learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Supervised learning evaluation I</head><p>In this section we compare HCNs to existing ap- proaches on the public "bAbI dialog" dataset <ref type="bibr" target="#b0">(Bordes and Weston, 2016)</ref>. This dataset includes two end-to-end dialog learning tasks, in the restaurant domain, called task5 and task6. 2 Task5 consists of synthetic, simulated dialog data, with highly regu- lar user behavior and constrained vocabulary. Di- alogs include a database access action which re- trieves relevant restaurants from a database, with results included in the dialog transcript. We test on the "OOV" variant of Task5, which includes en- tity values not observed in the training set. Task6 draws on human-computer dialog data from the second dialog state tracking challenge (DSTC2), where usability subjects (crowd-workers) inter- acted with several variants of a spoken dialog sys- tem ( <ref type="bibr" target="#b6">Henderson et al., 2014a</ref>). Since the database from DSTC2 was not provided, database calls have been inferred from the data and inserted into the dialog transcript. Example dialogs are pro- vided in the Appendix Sections A.2 and A.3.</p><p>To apply HCNs, we wrote simple domain-specific software, as follows. First, for entity extraction (step 4 in <ref type="figure" target="#fig_1">Figure 1</ref>), we used a sim- ple string match, with a pre-defined list of entity names -i.e., the list of restaurants available in the database. Second, in the context update (step 5), we wrote simple logic for tracking entities: when an entity is recognized in the user input, it is retained by the software, over-writing any pre- viously stored value. For example, if the price "cheap" is recognized in the first turn, it is retained as price=cheap. If "expensive" is then recog- nized in the third turn, it over-writes "cheap" so the code now holds price=expensive. Third, system actions were templatized: for example, system actions of the form "prezzo is a nice restau- rant in the west of town in the moderate price range" all map to the template "&lt;name&gt; is a nice restaurant in the &lt;location&gt; of town in the &lt;price&gt; price range". This results in 16 tem- plates for Task5 and 58 for Task6. <ref type="bibr">3</ref> Fourth, when database results are received into the entity state, they are sorted by rating. Finally, an action mask was created which encoded common-sense depen- dencies. These are implemented as simple if-then rules based on the presence of entity values: for example, only allow an API call if pre-conditions are met; only offer a restaurant if database results have already been received; do not ask for an en- tity if it is already known; etc. For Task6, we noticed that the system can say that no restaurants match the current query with- out consulting the database (for an example dia- log, see Section A.3 in the Appendix). In a prac- tical system this information would be retrieved from the database and not encoded in the RNN. So, we mined the training data and built a table of search queries known to yield no results. We also added context features that indicated the state of the database -for example, whether there were any restaurants matching the current query. The complete set of context features is given in Ap- pendix Section A.4. Altogether this code con- sisted of about 250 lines of Python.</p><p>We then trained an HCN on the training set, employing the domain-specific software described above. We selected an LSTM for the recurrent layer <ref type="bibr" target="#b8">(Hochreiter and Schmidhuber, 1997)</ref>, with the AdaDelta optimizer <ref type="bibr">(Zeiler, 2012)</ref>. We used the development set to tune the number of hid-den units <ref type="bibr">(128)</ref>, and the number of epochs (12). Utterance embeddings were formed by averaging word embeddings, using a publicly available 300- dimensional word embedding model trained us- ing word2vec on web data ( <ref type="bibr" target="#b22">Mikolov et al., 2013</ref>). <ref type="bibr">4</ref> The word embeddings were static and not updated during LSTM training. In training, each dialog formed one minibatch, and updates were done on full rollouts (i.e., non-truncated back propagation through time). The training loss was categorical cross-entropy. Further low-level implementation details are in the Appendix Section A.1.</p><p>We ran experiments with four variants of our model: with and without the utterance embed- dings, and with and without the action mask <ref type="figure" target="#fig_1">(Fig- ure 1, steps 3 and 6 respectively)</ref>.</p><p>Following past work, we report average turn ac- curacy -i.e., for each turn in each dialog, present the (true) history of user and system actions to the network and obtain the network's prediction as a string of characters. The turn is correct if the string matches the reference exactly, and incorrect if not. We also report dialog accuracy, which indicates if all turns in a dialog are correct.</p><p>We compare to four past end-to-end approaches ( <ref type="bibr" target="#b0">Bordes and Weston, 2016;</ref><ref type="bibr" target="#b18">Liu and Perez, 2016;</ref><ref type="bibr" target="#b4">Eric and Manning, 2017;</ref><ref type="bibr" target="#b23">Seo et al., 2016)</ref>. We em- phasize that past approaches have applied purely sequence-to-sequence models, or (as a baseline) purely programmed rules <ref type="bibr" target="#b0">(Bordes and Weston, 2016)</ref>. By contrast, Hybrid Code Networks are a hybrid of hand-coded rules and learned models.</p><p>Results are shown in <ref type="table">Table 1</ref>. Since Task5 is synthetic data generated using rules, it is possi- ble to obtain perfect accuracy using rules (line 1). The addition of domain knowledge greatly simpli- fies the learning task and enables HCNs to also at- tain perfect accuracy. On Task6, rules alone fare poorly, whereas HCNs outperform past learned models.</p><p>We next examined learning curves, training with increasing numbers of dialogs. To guard against bias in the ordering of the training set, we averaged over 5 runs, randomly permuting the or- der of the training dialogs in each run. Results are in <ref type="figure" target="#fig_3">Figure 2</ref>. In Task5, the action mask and utter- ance embeddings substantially reduce the number of training dialogs required (note the horizontal axis scale is logarithmic). For Task6, the bene-</p><formula xml:id="formula_0">Task5-OOV Task6</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Turn Acc. Dialog Acc. Turn Acc. Dialog Acc. Rules 100% 100% 33.3% 0.0% <ref type="bibr" target="#b0">Bordes and Weston (2016)</ref> 77.7% 0.0% 41.1% 0.0% Liu and <ref type="bibr" target="#b18">Perez (2016)</ref> 79.4% 0.0% 48.7% 1.4% <ref type="bibr" target="#b4">Eric and Manning (2017)</ref> - - 48.0% 1.5% <ref type="bibr" target="#b23">Seo et al. (2016)</ref> 96 <ref type="table">Table 1</ref>: Results on bAbI dialog Task5-OOV and Task6 <ref type="bibr" target="#b0">(Bordes and Weston, 2016)</ref>. Results for "Rules" taken from Bordes and Weston (2016). Note that, unlike cited past work, HCNs make use of domain- specific procedural knowledge.  fits of the utterance embeddings are less clear. An error analysis showed that there are several sys- tematic differences between the training and test- ing sets. Indeed, DSTC2 intentionally used differ- ent dialog policies for the training and test sets, whereas our goal is to mimic the policy in the training set.</p><note type="other">.0% - 51.1% - HCN 100% 100% 54.0% 1.2% HCN+embed 100% 100% 55.6% 1.3% HCN+mask 100% 100% 53.1% 1.9% HCN+embed+mask 100% 100% 52.7% 1.5%</note><p>Nonetheless, these tasks are the best public benchmark we are aware of, and HCNs exceed performance of existing sequence-to-sequence models. In addition, they match performance of past models using an order of magnitude less data (200 vs. 1618 dialogs), which is crucial in practi- cal settings where collecting realistic dialogs for a new domain can be expensive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Supervised learning evaluation II</head><p>We now turn to comparing with purely hand- crafted approaches. To do this, we obtained logs from our company's text-based customer support dialog system, which uses a sophisticated rule- based dialog manager. Data from this system is attractive for evaluation because it is used by real customers -not usability subjects -and because its rule-based dialog manager was developed by customer support professionals at our company, and not the authors. This data is not publicly available, but we are unaware of suitable human- computer dialog data in the public domain which uses rules.</p><p>Customers start using the dialog system by en- tering a brief description of their problem, such as "I need to update my operating system". They are then routed to one of several hundred domains, where each domain attempts to resolve a particu- lar problem. In this study, we collected human- computer transcripts for the high-traffic domains "reset password" and "cannot access account".</p><p>We labeled the dialog data as follows. First, we enumerated unique system actions observed in the data. Then, for each dialog, starting from the beginning, we examined each system action, and determined whether it was "correct". Here, cor- rect means that it was the most appropriate action among the set of existing system actions, given the history of that dialog. If multiple actions were ar- guably appropriate, we broke ties in favor of the existing rule-based dialog manager. Example di- alogs are provided in the Appendix Sections A.5 and A.6.</p><p>If a system action was labeled as correct, we left it as-is and continued to the next system action. If the system action was not correct, we replaced it with the correct system action, and discarded the rest of the dialog, since we do not know how the user would have replied to this new system action. The resulting dataset contained a mixture of com- plete and partial dialogs, containing only correct system actions. We partitioned this set into train- ing and test dialogs. Basic statistics of the data are shown in <ref type="table">Table 2</ref>.</p><p>In this domain, no entities were relevant to the control flow, and there was no obvious mask logic since any question could follow any question. Therefore, we wrote no domain-specific software for this instance of the HCN, and relied purely on the recurrent neural network to drive the conver- sation. The architecture and training of the RNN was the same as in Section 4, except that here we did not have enough data for a validation set, so we instead trained until we either achieved 100% accuracy on the training set or reached 200 epochs.</p><p>To evaluate, we observe that conventional mea- sures like average dialog accuracy unfairly penal- ize the system used to collect the dialogs -in our case, the rule-based system. If the system used for collection makes an error at turn t, the labeled dialog only includes the sub-dialog up to turn t, and the system being evaluated off-line is only evaluated on that sub-dialog. In other words, in our case, reporting dialog accuracy would favor the HCN because it would be evaluated on fewer turns than the rule-based system. We therefore   <ref type="table">Table 2</ref>: Basic statistics of labeled customer sup- port dialogs. Test accuracy refers to whole-dialog accuracy of the existing rule-based system.</p><p>use a comparative measure that examines which method produces longer continuous sequences of correct system actions, starting from the begin- ning of the dialog. Specifically, we report ∆P =</p><formula xml:id="formula_1">C(HCN-win)−C(rule-win) C(all)</formula><p>, where C(HCN-win) is the number of test dialogs where the rule-based ap- proach output a wrong action before the HCN; C(rule-win) is the number of test dialogs where the HCN output a wrong action before the rule- based approach; and C(all) is the number of di- alogs in the test set. When ∆P &gt; 0, there are more dialogs in which HCNs produce longer con- tinuous sequences of correct actions starting from the beginning of the dialog. We run all experi- ments 5 times, each time shuffling the order of the training set. Results are in <ref type="figure" target="#fig_6">Figure 3</ref>. HCNs exceed performance of the existing rule-based system af- ter about 30 dialogs.</p><p>In these domains, we have a further source of knowledge: the rule-based dialog managers them- selves can be used to generate example "sunny- day" dialogs, where the user provides purely ex- pected inputs. From each rule-based controller, synthetic dialogs were sampled to cover each ex- pected user response at least once, and added to the set of labeled real dialogs. This resulted in 75 dialogs for the "Forgot password" domain, and 325 for the "Can't access account" domain. Train- ing was repeated as described above. Results are also included in <ref type="figure" target="#fig_6">Figure 3</ref>, with the suffix "sam- pled". In the "Can't access account" domain, the sampled dialogs yield a large improvement, proba- bly because the flow chart for this domain is large, so the sampled dialogs increase coverage. The gain in the "forgot password" domain is present but smaller.</p><p>In summary, HCNs can out-perform  ∆P , where ∆P is the fraction of test dialogs where HCNs produced longer initial correct sequences of system actions than the rules, minus the fraction where rules produced longer initial correct sequences than the HCNs. "embed" indicates whether utterance embeddings were included; "sampled" indicates whether dialogs sampled from the rule-based controller were included in the training set.</p><p>production-grade rule-based systems with a reasonable number of labeled dialogs, and adding synthetic "sunny-day" dialogs improves performance further. Moreover, unlike existing pipelined approaches to dialog management that rely on an explicit state tracker, this HCN used no explicit state tracker, highlighting an advantage of the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Reinforcement learning illustration</head><p>In the previous sections, supervised learning (SL) was applied to train the LSTM to mimic dialogs provided by the system developer. Once a system operates at scale, interacting with a large number of users, it is desirable for the system to continue to learn autonomously using reinforcement learn- ing (RL). With RL, each turn receives a measure- ment of goodness called a reward; the agent ex- plores different sequences of actions in different situations, and makes adjustments so as to max- imize the expected discounted sum of rewards, which is called the return, denoted G. For optimization, we selected a policy gradient approach <ref type="bibr" target="#b38">(Williams, 1992)</ref>, which has been suc- cessfully applied to dialog systems <ref type="bibr" target="#b10">(Jurčíček et al., 2011</ref>), robotics ( <ref type="bibr" target="#b11">Kohl and Stone, 2004)</ref>, and the board game Go ( <ref type="bibr" target="#b27">Silver et al., 2016)</ref>. In policy gradient-based RL, a model π is parameterized by w and outputs a distribution from which actions are sampled at each timestep. At the end of a tra- jectory -in our case, dialog -the return G for that trajectory is computed, and the gradients of the probabilities of the actions taken with respect to the model weights are computed. The weights are then adjusted by taking a gradient step propor- tional to the return:</p><formula xml:id="formula_2">w ← w+α( t w log π(a t |h t ; w))(G−b) (1)</formula><p>where α is a learning rate; a t is the action taken at timestep t; h t is the dialog history at time t; G is the return of the dialog; x F denotes the Jacobian of F with respect to x; b is a baseline described be- low; and π(a|h; w) is the LSTM -i.e., a stochastic policy which outputs a distribution over a given a dialog history h, parameterized by weights w. The baseline b is an estimate of the average return of the current policy, estimated on the last 100 di- alogs using weighted importance sampling. <ref type="bibr">5</ref> Intu- itively, "better" dialogs receive a positive gradient step, making the actions selected more likely; and "worse" dialogs receive a negative gradient step, making the actions selected less likely. SL and RL correspond to different methods of updating weights, so both can be applied to the same network. However, there is no guarantee that the optimal RL policy will agree with the SL train- ing set; therefore, after each RL gradient step, we check whether the updated policy reconstructs the training set. If not, we re-run SL gradient steps on the training set until the model reproduces the training set. Note that this approach allows new training dialogs to be added at any time during RL optimization.</p><p>We illustrate RL optimization on a simulated dialog task in the name dialing domain. In this system, a contact's name may have synonyms ("Michael" may also be called "Mike"), and a con- tact may have more than one phone number, such as "work" or "mobile", which may in turn have synonyms like "cell" for "mobile". This domain has a database of names and phone numbers taken from the Microsoft personnel directory, 5 entity types -firstname, nickname, lastname, phonenumber, and phonetype -and 14 ac- tions, including 2 API call actions. Simple en- tity logic was coded, which retains the most re- cent copy of recognized entities. A simple action mask suppresses impossible actions, such as plac- ing a phonecall before a phone number has been retrieved from the database. Example dialogs are provided in Appendix Section A.7.</p><p>To perform optimization, we created a simu- lated user. At the start of a dialog, the simulated user randomly selected a name and phone type, in- cluding names and phone types not covered by the dialog system. When speaking, the simulated user can use the canonical name or a nickname; usually answers questions but can ignore the system; can provide additional information not requested; and can give up. The simulated user was parameter- ized by around 10 probabilities, set by hand.</p><p>We defined the reward as being 1 for success- fully completing the task, and 0 otherwise. A dis- count of 0.95 was used to incentivize the system to complete dialogs faster rather than slower, yield- ing return 0 for failed dialogs, and G = 0.95 T −1 for successful dialogs, where T is the number of system turns in the dialog. Finally, we created a set of 21 labeled dialogs, which will be used for supervised learning.</p><p>For the RNN in the HCN, we again used an LSTM with AdaDelta, this time with 32 hidden units. RL policy updates are made after each dia- log. Since a simulated user was employed, we did not have real user utterances, and instead relied on context features, omitting bag-of-words and utter- ance embedding features.</p><p>We first evaluate RL by randomly initializing an LSTM, and begin RL optimization. After 10 RL updates, we freeze the policy, and run 500 dialogs with the user simulation to measure task comple- tion. We repeat all of this for 100 runs, and report average performance. In addition, we also report results by initializing the LSTM using supervised learning on the training set, consisting of 1, 2, 5, or 10 dialogs sampled randomly from the training set, then running RL as described above. Results are in <ref type="figure" target="#fig_7">Figure 4</ref>. Although RL alone can find a good policy, pre-training with just a hand- ful of labeled dialogs improves learning speed dra- matically. Additional experiments, not shown for space, found that ablating the action mask slowed training, agreeing with <ref type="bibr" target="#b36">Williams (2008)</ref>.</p><p>Finally, we conduct a further experiment where we sample 10 training dialogs, then add one to the training set just before RL dialog 0, 100, 200, ... , 900. Results are shown in <ref type="figure" target="#fig_7">Figure 4</ref>. This shows that SL dialogs can be introduced as RL is in progress -i.e., that it is possible to interleave RL and SL. This is an attractive property for prac- tical systems: if a dialog error is spotted by a de- veloper while RL is in progress, it is natural to add a training dialog to the training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>This paper has introduced Hybrid Code Networks for end-to-end learning of task-oriented dialog systems. HCNs support a separation of concerns where procedural knowledge and constraints can be expressed in software, and the control flow is learned. Compared to existing end-to-end ap- proaches, HCNs afford more developer control and require less training data, at the expense of a small amount of developer effort.</p><p>Results in this paper have explored three differ- ent dialog domains. On a public benchmark in the restaurants domain, HCNs exceeded performance of purely learned models. Results in two trou- bleshooting domains exceeded performance of a commercially deployed rule-based system. Fi- nally, in a name-dialing domain, results from di- alog simulation show that HCNs can also be opti- mized with a mixture of reinforcement and super- vised learning.</p><p>In future work, we plan to extend HCNs by incorporating lines of existing work, such as in- tegrating the entity extraction step into the neu- ral network ( <ref type="bibr" target="#b3">Dhingra et al., 2017)</ref>, adding richer utterance embeddings <ref type="bibr" target="#b29">(Socher et al., 2013)</ref>, and supporting text generation ( <ref type="bibr" target="#b30">Sordoni et al., 2015</ref>). We will also explore using HCNs with automatic speech recognition (ASR) input, for example by forming features from n-grams of the ASR n-best results ( <ref type="bibr" target="#b7">Henderson et al., 2014b</ref>). Of course, we also plan to deploy the model in a live dialog sys- tem. More broadly, HCNs are a general model for stateful control, and we would be interested to explore applications beyond dialog systems - for example, in NLP medical settings or human- robot NL interaction tasks, providing domain con- straints are important for safety; and in resource- poor settings, providing domain knowledge can amplify limited data. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Supplemental Material</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Model implementation details</head><p>The RNN was specified using Keras version 0.3.3, with back-end computation in Theano version 0.8.0.dev0 <ref type="bibr">(Theano Development Team, 2016;</ref><ref type="bibr" target="#b1">Chollet, 2015</ref>). The Keras model specification is given below. The input variable obs includes all features from Figure 1 step 6 except for the previ- ous action (step 18) and the action mask (step 6, top-most vector). activation='softmax', ), name='h2', input='h1' ) g.add_node <ref type="table">(  Activation(  activation=normalize,  )</ref>, name='action', inputs= <ref type="bibr">['h2','avail_actions']</ref>, merge_mode='mul', create_output=True ) g.compile( optimizer=Adadelta(clipnorm=1.), sample_weight_modes={ 'action': 'temporal' }, loss={</p><p>'action':'categorical_crossentropy' } )</p><p>Model sizes are given in <ref type="table">Table 3</ref>. Example di- alogs are given below for each of the 5 dialog sys- tems. For space and readability, the entity tags that appear in the user and system sides of the dialogs have been removed -for example, Call &lt;name&gt;Joan&lt;/name&gt; is shown as Call Joan.  <ref type="table" target="#tab_3">Task6  Presence of each entity in dialog state  4  3  Presence of each entity in current utterance  - 3  Whether DB has been queried yet  - 1  Whether DB results are empty  - 1  Whether DB results are non-empty  - 1</ref> Whether any DB results have been presented - 1 Whether all DB results have been presented - 1 Whether any DB results are available to present - 1 Whether curent query yields no results in training set - 1 Whether cuisine in current query yields no results in training set - 1 Total context features 4 14 </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Operational loop. Trapezoids refer to programmatic code provided by the software developer, and shaded boxes are trainable components. Vertical bars under "6" represent concatenated vectors which form the input to the RNN.</figDesc><graphic url="image-1.png" coords="2,78.60,111.96,83.90,145.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Training dialog count vs. turn accuracy for bAbI dialog Task5-OOV and Task6. "embed" indicates whether utterance embeddings were included; "mask" indicates whether the action masking code was active.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Forgot</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Training dialogs vs. ∆P , where ∆P is the fraction of test dialogs where HCNs produced longer initial correct sequences of system actions than the rules, minus the fraction where rules produced longer initial correct sequences than the HCNs. "embed" indicates whether utterance embeddings were included; "sampled" indicates whether dialogs sampled from the rule-based controller were included in the training set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Dialog success rate vs. reinforcement learning training dialogs. Curve marked "0" begins with a randomly initialized LSTM. Curves marked "N initial" are pre-trained with N labeled dialogs. Curve marked "10, interleaved" adds one SL training dialog before RL dialog 0, 100, 200, ... 900.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Binary context features used to convey entity and database state in Section 4. 

Sorry, I don't have a home number for Sally Smith. 
I only have a work phone. Do you want to call that 
number? 
no 
Oh, sorry about that. Goodbye. </table></figure>

			<note place="foot" n="1"> Implementation details for the RNN such as size, loss, etc. are given with each experiment in Sections 4-6.</note>

			<note place="foot" n="2"> Tasks 1-4 are sub-tasks of Task5.</note>

			<note place="foot" n="3"> A handful of actions in Task6 seemed spurious; for these, we replaced them with a special &quot;UNK&quot; action in the training set, and masked this action at test time.</note>

			<note place="foot" n="4"> Google News 100B model from https://github. com/3Top/word2vec-api</note>

			<note place="foot" n="5"> The choice of baseline does not affect the long-term convergence of the algorithm (i.e., the bias), but can dramatically affect the speed of convergence (i.e., the variance) (Williams, 1992).</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 bAbI Task5 example dialog</head><p>good morning hello what can i help you with today i'd like to book a table with italian food i'm on it <ref type="bibr">[silence]</ref> where should it be in paris how many people would be in your party for six people please which price range are looking for in a cheap price range please ok let me look into some options for you <ref type="bibr">[</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Task5 and Task6 context features</head><p>Context features used in Section 4 are in <ref type="table">Table 4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.5 Forgot password example dialog</head><p>Some system actions have been shortened for space. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Learning end-to-end goal-oriented dialog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<idno>CoRR abs/1605.07683</idno>
		<ptr target="http://arxiv.org/abs/1605.07683" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franois</forename><surname>Chollet</surname></persName>
		</author>
		<ptr target="https://github.com/fchollet/keras" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Empirical evaluation of gated recurrent neural networks on sequence modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyoung</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc NIPS 2014 Deep Learning and Representation Learning Workshop</title>
		<meeting>NIPS 2014 Deep Learning and Representation Learning Workshop</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Towards end-to-end reinforcement learning of dialogue agents for information access</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhuwan</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiujun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Nung</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Faisal</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc Association for Computational Linguistics</title>
		<meeting>Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">A copy-augmented sequence-to-sequence architecture gives good performance on taskoriented dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihail</forename><surname>Eric</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
		<idno>CoRR abs/1701.04024</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A statistical approach to spoken dialog systems design and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Griol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Llus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Encarna</forename><surname>Hurtado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emilio</forename><surname>Segarra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sanchis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Speech Communication</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="8" to="9" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The second dialog state tracking challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blaise</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc SIGdial Workshop on Discourse and Dialogue</title>
		<meeting>SIGdial Workshop on Discourse and Dialogue<address><addrLine>Philadelphia, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Word-based Dialog State Tracking with Recurrent Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blaise</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc SIGdial Workshop on Discourse and Dialogue, Philadelphia</title>
		<meeting>SIGdial Workshop on Discourse and Dialogue, Philadelphia<address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jurgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Statistical dialog management applied to WFSTbased dialog systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiori</forename><surname>Hori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiyonori</forename><surname>Ohtake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teruhisa</forename><surname>Misu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hideki</forename><surname>Kashioka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Nakamura</surname></persName>
		</author>
		<idno type="doi">10.1109/ICASSP.2009.4960703</idno>
		<ptr target="https://doi.org/10.1109/ICASSP.2009.4960703" />
	</analytic>
	<monogr>
		<title level="m">Acoustics, Speech and Signal Processing</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="4793" to="4796" />
		</imprint>
	</monogr>
	<note>IEEE International Conference on</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Natural actor and belief critic: Reinforcement algorithm for learning parameters of dialogue systems modelled as pomdps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Jurčíček</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blaise</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Speech and Language Processing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note>TSLP)</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Policy gradient reinforcement learning for fast quadrupedal locomotion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nate</forename><surname>Kohl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Stone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robotics and Automation</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="2619" to="2624" />
		</imprint>
	</monogr>
	<note>Proceedings. ICRA&apos;04</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Example-based dialog modeling for practical multi-domain dialog system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheongjae</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangkeun</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seokhwan</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary Geunbae</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Speech Communication</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="466" to="484" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A stochastic model of human-machine interaction for learning dialogue strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esther</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Pieraccini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wieland</forename><surname>Eckert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans on Speech and Audio Processing</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="11" to="23" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A diversity-promoting objective function for neural conversation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc HLT-NAACL</title>
		<meeting>HLT-NAACL<address><addrLine>San Diego, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Georgios Spithourakis, Jianfeng Gao, and Bill Dolan. 2016b. A persona-based neural conversation model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc Association for Computational Linguistics</title>
		<meeting>Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning for dialogue generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Monroe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>Conference on Empirical Methods in Natural Language essing<address><addrLine>Austin, Texas, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Temporal supervised learning for inferring a dialog policy from example conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><forename type="middle">D</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc IEEE Workshop on Spoken Language Technologies (SLT)</title>
		<meeting>IEEE Workshop on Spoken Language Technologies (SLT)<address><addrLine>South Lake Tahoe, Nevada, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Gated end-toend memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Perez</surname></persName>
		</author>
		<idno>CoRR abs/1610.04211</idno>
		<ptr target="http://arxiv.org/abs/1610.04211" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Training end-to-end dialogue systems with the ubuntu dialogue corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Thomas Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nissan</forename><surname>Pow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iulian</forename><surname>Vlad Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chia-Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dialogue and Discourse</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">LSTM based conversation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mari</forename><surname>Ostendorf</surname></persName>
		</author>
		<idno>CoRR abs/1603.09457</idno>
		<ptr target="http://arxiv.org/abs/1603.09457" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Coherent dialogue with attentionbased language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyuan</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">R</forename><surname>Walter</surname></persName>
		</author>
		<idno>CoRR abs/1611.06997</idno>
		<ptr target="http://arxiv.org/abs/1611.06997" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc Advances in Neural Information Processing Systems</title>
		<meeting>Advances in Neural Information essing Systems<address><addrLine>Lake Tahoe, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Query-regression networks for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min Joon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<idno>CoRR abs/1606.04582</idno>
		<ptr target="http://arxiv.org/abs/1606.04582" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Building end-to-end dialogue systems using generative hierarchical neural network models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Iulian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pineau</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=3016387.3016435" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence. AAAI Press, AAAI&apos;16</title>
		<meeting>the Thirtieth AAAI Conference on Artificial Intelligence. AAAI Press, AAAI&apos;16</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3776" to="3783" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">A hierarchical latent variable encoder-decoder model for generating dialogues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Iulian Vlad Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Neural responding machine for short-text conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifeng</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc Association for Computational Linguistics</title>
		<meeting>Association for Computational Linguistics<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Mastering the game of Go with deep neural networks and tree search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aja</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Guez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Sifre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Driessche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Schrittwieser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veda</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Panneershelvam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lanctot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">529</biblScope>
			<biblScope unit="issue">7587</biblScope>
			<biblScope unit="page" from="484" to="489" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Optimizing dialogue management with reinforcement leaning: experiments with the NJFun system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satinder</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><forename type="middle">J</forename><surname>Litman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Kearns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marilyn A</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="105" to="133" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Recursive deep models for semantic compositionality over a sentiment treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Perelygin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>Conference on Empirical Methods in Natural Language essing<address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A neural network approach to context-sensitive generation of conversational responses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meg</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc HLT-NAACL</title>
		<meeting>HLT-NAACL<address><addrLine>Denver, Colorado, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei-Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Gaši´gaši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Mrkši´mrkši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lina</forename><surname>Rojasbarahona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Ultes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Vandyke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsunghsien</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
		<idno>arXiv preprint: 1606.02689</idno>
		<title level="m">Continuously learning neural dialogue management</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">End-to-end memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sainbayar</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc Advances in Neural Information Processing Systems (NIPS)</title>
		<meeting>Advances in Neural Information essing Systems (NIPS)<address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Theano: A Python framework for fast computation of mathematical expressions</title>
		<idno>abs/1605.02688</idno>
		<ptr target="http://arxiv.org/abs/1605.02688" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Theano Development Team</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A neural conversational model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc ICML Deep Learning Workshop</title>
		<meeting>ICML Deep Learning Workshop</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">A network-based end-to-end trainable taskoriented dialogue system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Tsung-Hsien Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Gasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lina</forename><forename type="middle">Maria</forename><surname>Mrksic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei-Hao</forename><surname>Rojas-Barahona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Ultes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><forename type="middle">J</forename><surname>Vandyke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Young</surname></persName>
		</author>
		<idno>CoRR abs/1604.04562</idno>
		<ptr target="http://arxiv.org/abs/1604.04562" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The best of both worlds: Unifying conventional dialog systems and POMDPs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jason</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc Intl Conf on Spoken Language Processing</title>
		<meeting>Intl Conf on Spoken Language essing<address><addrLine>Brisbane, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Partially observable Markov decision processes for spoken dialog systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><forename type="middle">D</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech and Language</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="393" to="422" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Simple statistical gradientfollowing algorithms for connectionist reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ronald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="229" to="256" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
