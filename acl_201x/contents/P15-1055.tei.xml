<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:52+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning to Explain Entity Relationships in Knowledge Graphs</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Voskarides</surname></persName>
							<email>n.voskarides@uva.nl</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edgar</forename><surname>Meij</surname></persName>
							<email>emeij@yahoo-inc.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
							<email>derijke@uva.nl</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of Amsterdam</orgName>
								<address>
									<settlement>London</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Amsterdam</orgName>
								<address>
									<addrLine>Wouter Weerkamp 904Labs</addrLine>
									<settlement>Amsterdam</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Learning to Explain Entity Relationships in Knowledge Graphs</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="564" to="574"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
					<note>Manos Tsagkias 904Labs, Amsterdam</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We study the problem of explaining relationships between pairs of knowledge graph entities with human-readable descriptions. Our method extracts and enriches sentences that refer to an entity pair from a corpus and ranks the sentences according to how well they describe the relationship between the entities. We model this task as a learning to rank problem for sentences and employ a rich set of features. When evaluated on a large set of manually annotated sentences, we find that our method significantly improves over state-of-the-art baseline models.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Knowledge graphs are a powerful tool for support- ing a large spectrum of search applications includ- ing ranking, recommendation, exploratory search, and web search ( <ref type="bibr" target="#b10">Dong et al., 2014)</ref>. A knowl- edge graph aggregates information around enti- ties across multiple content sources and links these entities together, while at the same time provid- ing entity-specific properties (such as age or em- ployer) and types (such as actor or movie).</p><p>Although there is a growing interest in au- tomatically constructing knowledge graphs, e.g., from unstructured web data ( <ref type="bibr" target="#b27">Weston et al., 2013;</ref><ref type="bibr" target="#b8">Craven et al., 2000;</ref>, the prob- lem of providing evidence on why two entities are related in a knowledge graph remains largely unaddressed. Extracting and presenting evidence for linking two entities, however, is an impor- tant aspect of knowledge graphs, as it can enforce trust between the user and a search engine, which in turn can improve long-term user engagement, e.g., in the context of related entity recommenda- tion ( <ref type="bibr" target="#b4">Blanco et al., 2013)</ref>. Although knowledge graphs exist that provide this functionality to a certain degree (e.g., when hovering over Google's suggested entities, see <ref type="figure">Figure 1</ref>), to the best of our knowledge there is no previously published re- search on methods for entity relationship explana- tion.</p><p>Figure 1: Part of Google's search result page for the query "barack obama". When hovering over the related entity "Michelle Obama", an explana- tion of the relationship between her and "Barack Obama" is shown.</p><p>In this paper we propose a method for explain- ing the relationship between two entities, which we evaluate on a newly constructed annotated dataset that we make publicly available. In par- ticular, we consider the task of explaining rela- tionships between pairs of Wikipedia entities. We aim to infer a human-readable description for an entity pair given a relationship between the two entities. Since Wikipedia does not explicitly de- fine relationships between entities we use a knowl- edge graph to obtain these relations. We cast our task as a sentence ranking problem: we automat- ically extract sentences from a corpus and rank them according to how well they describe a given relationship between a pair of entities. For rank- ing purposes, we extract a rich set of features and use learning to rank to effectively combine them. Our feature set includes both traditional informa- tion retrieval and natural language processing fea- tures that we augment with entity-dependent fea- tures. These features leverage information from the structure of the knowledge graph. On top of this, we use features that capture the presence in a sentence of the relationship of interest. For our evaluation we focus on "people" entities and we use a large, manually annotated dataset of sen- tences.</p><p>The research questions we address are the fol- lowing. First, we ask what the effectiveness of state-of-the-art sentence retrieval models is for explaining a relationship between two entities (RQ1). Second, we consider whether we can im- prove over sentence retrieval models by casting the task in a learning to rank framework (RQ2). Third, we examine whether we can further improve per- formance by using relationship-dependent models instead of a relationship-independent one (RQ3). We complement these research questions with an error and feature analysis.</p><p>Our main contributions are a robust and effec- tive method for explaining entity relationships, de- tailed insights into the performance of our method and features, and a manually annotated dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>We combine ideas from sentence retrieval, learn- ing to rank, and question answering to address the task of explaining relationships between entities.</p><p>Previous work that is closest to the task we ad- dress in this paper is that of <ref type="bibr" target="#b3">Zaragoza (2010) and</ref><ref type="bibr" target="#b12">Fang et al. (2011)</ref>. First, Blanco and Zaragoza (2010) focus on finding and ranking sen- tences that explain the relationship between an en- tity and a query. Our work is different in that we want to explain the relationship between two enti- ties, rather than a query. <ref type="bibr" target="#b12">Fang et al. (2011)</ref> explore the generation of a ranked list of knowledge base relationships for an entity pair. Instead, we try to select sentences that describe a particular relation- ship, assuming that this is given.</p><p>Our approach builds on sentence retrieval, where one retrieves sentences rather than docu- ments that answer an information need. Docu- ment retrieval models such as tf-idf, BM25, and language modeling ( <ref type="bibr" target="#b2">Baeza-Yates et al., 1999</ref>) have been extended to tackle sentence retrieval. Three of the most successful sentence retrieval methods are TFISF ( <ref type="bibr" target="#b1">Allan et al., 2003)</ref>, which is a vari- ant of the vector space model with tf-idf weight- ing, language modeling with local context <ref type="bibr" target="#b24">(Murdock, 2006;</ref><ref type="bibr" target="#b13">Fernández et al., 2011)</ref>, and a recur- sive version of TFISF that accounts for local con- text ( <ref type="bibr" target="#b9">Doko et al., 2013)</ref>. TFISF is very competi- tive compared to document retrieval models tuned specifically for sentence retrieval (e.g., BM25 and language modeling <ref type="bibr" target="#b18">(Losada, 2008)</ref>) and we there- fore include it as a baseline.</p><p>Sentences that are suitable for explaining rela- tionships can have attributes that are important for ranking but cannot be captured by term-based re- trieval models. One way to combine a wide range of ranking features is learning to rank (LTR). Re- cent years have witnessed a rapid increase in the work on learning to rank, and it has proven to be a very successful method for combining large num- bers of ranking features, for web search, but also other information retrieval applications <ref type="bibr" target="#b6">(Burges et al., 2011;</ref><ref type="bibr" target="#b0">Agarwal et al., 2012)</ref>. We use learning to rank and represent each sentence with a set of features that aim to capture different dimensions of the sentence.</p><p>Question answering (QA) is the task of provid- ing direct and concise answers to questions formed in natural language <ref type="bibr" target="#b14">(Hirschman and Gaizauskas, 2001</ref>). QA can be regarded as a similar task to ours, assuming that the combination of entity pair and relationship form the "question" and that the "answer" is the sentence describing the relation- ship of interest. Even though we do not follow the QA paradigm in this paper, some of the features we use are inspired by QA systems. In addition, we employ learning to rank to combine the devised features, which has recently been successfully ap- plied for QA ( <ref type="bibr" target="#b0">Agarwal et al., 2012</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Problem Statement</head><p>We address the problem of explaining relation- ships between pairs of entities in a knowledge graph. We operationalize the problem as a prob- lem of ranking sentences from documents in a corpus that is related to the knowledge graph. More specifically, given two entities e i and e j that form an entity pair e i , e j , and a relation r be- tween them, the task is to extract a set of can-didate sentences S ij = {s ij 1 , . . . , s ij k } that refer to e i , e j and to impose a ranking on the sen- tences in S ij . The relation r has the general form type(e i ), terms(r), type(e j )), where type(e) is the type of the entity e (e.g., Person or Actor) and terms(r) are the terms of the relation (e.g., CoCastsWith or IsSpouseOf).</p><p>We are left with two specific tasks: (1) extract- ing candidate sentences S ij , and (2) ranking S ij , where the goal is to have sentences that provide a perfect explanation of the relationship at the top position of the ranking. The next section describes our methods for both tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Explaining Entity Relationships</head><p>We follow a two-step approach for automatically explaining relationships between entity pairs. First, in Section 4.1, we extract and enrich sen- tences that refer to an entity pair e i , e j from a corpus in order to construct a set of candidate sen- tences. Second, in Section 4.2, we extract a rich set of features describing the entities' relationship r and use supervised machine learning in order to rank the sentences in S ij according to how well they describe the relationship r.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Extracting candidate sentences</head><p>To create a set of candidate sentences for a given entity pair and relationship, we require a corpus of documents that is pertinent to the entities at hand. Although any kind of document collection can be used, we focus on Wikipedia in this paper, as it provides good coverage for the majority of entities in our knowledge graph.</p><p>First, we extract surface forms for the given en- tities: the title of the entity's Wikipedia article (e.g., "Barack Obama"), the titles of all redirect pages linking to that article (e.g., "Obama"), and all anchor text associated with hyperlinks to the ar- ticle within Wikipedia (e.g., "president obama"). We then split all Wikipedia articles into sentences and consider a sentence as a candidate if (i) the sentence is part of either entities' Wikipedia arti- cle and contains a surface form of, or a link to, the other entity; or (ii) the sentence contains sur- face forms of, or links to, both entities in the entity pair.</p><p>Next, we apply two sentence enrichment steps for (i) making sentences self-contained and read- able outside the context of the source document and (ii) linking the sentences to entities. For (i), we replace pronouns in candidate sentences with the title of the entity. We apply a simple heuristic for the people entities, inspired by (Wu and Weld, 2010): 1 we count the frequency of the terms "he" and "she" in the article for determining the gender of the entity, and we replace the first appearance of "he" or "she" in each sentence with the entity's title. We skip this step if any surface form of the entity occurs in the sentence.</p><p>For (ii), we apply entity linking to provide links from the sentence to additional entities . This need arises from the fact that not every sentence in an article contains ex- plicit links to the entities it mentions, as Wikipedia guidelines only allow one link to another article in the article's text. <ref type="bibr">2</ref> The algorithm takes a sentence as input and iterates over n-grams that are not yet linked to an entity. If an n-gram matches a surface form of an entity, we establish a link between the n-gram and the entity. We restrict our search space to entities that are linked from within the source article of the sentence and from within articles to which the source article links. This way, our entity linking method achieves high precision as almost no disambiguation is necessary.</p><p>As an example, consider the sentence "He gave critically acclaimed performances in the crime thriller Seven. . . " on the Wikipedia page for Brad Pitt. After applying our enrichment steps, we obtain "Brad Pitt gave critically acclaimed performances in the crime thriller Seven. . . ", making the sentence human read- able and link to the entities Brad Pitt and Seven (1995 film).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Ranking sentences</head><p>After extracting candidate sentences, we rank them by how well they describe the relationship of interest r between entities e i and e j . There are many signals beyond simple term statistics that can indicate relevance. Automatically construct- ing a ranking model using supervised machine learning techniques is therefore an obvious choice. For ranking we use learning to rank (LTR) and rep- resent each sentence with a rich set of features. <ref type="table" target="#tab_1">Ta- ble 1</ref> lists the features we use. Below we provide # Name</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gloss</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Text features 1 Sentence length Length of s in words 2 Sum of idf Sum of IDF of terms of s in Wikipedia 3 Average idf Average IDF of terms of s in Wikipedia 4 Sentence density Lexical density of s, see Equation 1 (Lee et al., 2001) 5-8 POS fractions</head><p>Fraction of verbs, nouns, adjectives, others in s <ref type="figure">(</ref> Average cosine similarity of phrases in word2vec(r) that are matched in s 40 Maximum word2vec(r)</p><p>Maximum cosine similarity of phrases in word2vec(r) that are matched in s 41 Sum word2vec(r)</p><p>Sum of cosine similarity of phrases in word2vec(r) that are matched in s 42 Score LC Lucene score of s with titles(ei, ej), terms(r), wordnet(r), word2vec(r) as query 43 Score R-TFISF R-TFISF score of s with queries constructed as above  a brief description of the more complex ones.</p><p>Text features This feature type regards the im- portance of the sentence s at the term level. We compute the density of s (feature 4) as:</p><formula xml:id="formula_0">density(s) = 1 K ⋅ (K + 1) n j=1 idf (t j ) ⋅ idf (t j+1 ) distance(t j , t j+1 ) 2 , (1)</formula><p>where K is the number of keyword terms in s and distance(t j , t j+1 ) is the number of non- keyword terms between keyword terms t j and t j+1 . We treat stop words and numbers in s as non- keywords and the remaining terms as keywords. We assume that two articles that have many common articles that point to them are strongly related . We hypothesize that, if a sentence contains common inlinks from e i and e j , the sentence might contain important in- formation about their relationship. Hence, we add whether the sentence contains a common link (fea-ture 26) and the number of common links (feature 27) as features. We score a common link l between e i and e j using:</p><formula xml:id="formula_1">score(l, e i , e j ) = sim(l, e i ) ⋅ sim(l, e j ), (2)</formula><p>where sim(⋅, ⋅) is defined as the similarity between two Wikipedia articles, computed using a vari- ant of Normalized Google Distance ( . Feature 28 then measures the sum of the scores of the common links.</p><p>Previous research shows that using surrounding sentences is beneficial for sentence retrieval ( <ref type="bibr" target="#b9">Doko et al., 2013)</ref>. We therefore consider the number of common links in the previous and next sentence (features 29-30).</p><p>Relationship features Feature 31 indicates whether any of the relationship-specific terms oc- curs in the sentence. Only matching the terms in the relationship may have low coverage since terms such as "spouse" may have many synonyms and/or highly related terms, e.g., "husband" or "married". Therefore, we use WordNet to find synonym phrases of r (feature 32); we refer to this method as wordnet(r).</p><p>Alternatively, we use word embeddings to find such similar phrases ( <ref type="bibr" target="#b20">Mikolov et al., 2013)</ref>. Such embeddings take a text corpus as input and learn vector representations of words and phrases con- sisting of real numbers. Given the set V r consist- ing of the vector representations of all the relation- ship terms and the set V which consists of the vec- tor representations of all the candidate phrases in the data, we calculate the distance between a can- didate phrase represented by a vector v i ∈ V and the vectors in V r as:</p><formula xml:id="formula_2">distance(v i , V ) = cos v i , v j ∈Vr v j ,<label>(3)</label></formula><p>where ∑ v j ∈Vr v j is the element-wise sum of the vectors in V r and the distance between two vec- tors v 1 and v 2 is measured using cosine similarity. The candidate phrases in V are then ranked using Equation 3 and the top-m phrases are selected, re- sulting in features 33, 39, 40, and 41; we refer to the ranked set of phrases that are selected using this procedure as word2vec(r).</p><p>In addition, we employ state-of-the-art retrieval functions and include the scores for queries that are constructed using the entities e i and e j , the re- lation r, wordnet(r), and word2vec(r). We use the titles of the entity articles titles(e) to repre- sent the entities in the query and two ranking func- tions, Recursive TFISF (R-TFISF) and LC, 3 (fea- tures 42-43). TFISF is a sentence retrieval model that determines the level of relevance of a sentence s given a query q as: R(s, q) = t∈q log(tf t,q + 1)⋅ log(tf t,s + 1) ⋅ log n + 1 0.5 + sf t ,</p><p>where tf t,q and tf t,s are the number of occur- rences of term t in the query q and the sentence s respectively, sf t is the number of sentences in which t appears, and n is the number of sentences in the collection. R-TFISF is an improved ex- tension of the TFISF method ( <ref type="bibr" target="#b9">Doko et al., 2013)</ref>, which incorporates context from neighboring sen- tences in the ranking function:</p><formula xml:id="formula_4">R c (s, q) = (1 − µ)R(s, q)+ (5) µ[R c (s prev (s), q) + R c (s next (s), q)],</formula><p>where µ is a free parameter and s prev (s) and s next (s) indicate functions to retrieve the previous and next sentence, respectively. We use a maxi- mum of three recursive calls.</p><p>Source features Here, we refer to features that are dependent on the source document of the sen- tences. We have three such features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental setup</head><p>In this section we describe the dataset, manual an- notations, learning to rank algorithm, and evalu- ation metrics that we use to answer our research questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Dataset</head><p>We draw entities and their relationships from a proprietary knowledge graph that is created from Wikipedia, Freebase, IMDB, and other sources, and that is used by the Yahoo web search engine. We focus on "people" entities and relationships between them. <ref type="bibr">4</ref> For our experiments we need to select a manageable set of entities, which we ob- tain as follows. We consider a year of query logs from a large commercial search engine, count the number of times a user clicks on a Wikipedia ar- ticle of an entity in the results page and perform stratified sampling of entities according to this dis- tribution. As we are bounded by limited resources for our manual assessments, we sample 1 476 en- tity pairs that together with nine unique relation- ship types form our experimental dataset. We use an English Wikipedia dump dated July 8, 2013, containing approximately 4M articles, of which 50 638 belong to "people" entities that are also in our knowledge graph. We extract sentences using the approach described in Section 4.1, re- sulting in 36 823 candidate sentences for our enti- ties. On average we have 24.94 sentences per en- tity pair (maximum 423 and minimum 0). Because of the large variance, it is not feasible to obtain ex- haustive annotations for all sentences. We rank the sentences using R-TFISF and keep the top-10 sen- tences per entity pair for annotation. This results in a total of 5 689 sentences.</p><p>Five human annotators provided relevance judg- ments, manually judging sentences based on how well they describe the relationship for an entity pair, for which we use a five-level graded rele- vance scale (perfect, excellent, good, fair, bad). <ref type="bibr">5</ref> Of all relevance grades 8.1% is perfect, 15.69% excellent, 19.98% good, 8.05% fair, and 48.15% bad. Out of 1 476 entity pairs, 1 093 have at least one sentence annotated as fair. As is common in information retrieval evaluation, we discard entity pairs that have only "bad" sentences. We examine the difficulty of the task for human annotators by measuring inter-annotator agreement on a subset of 105 sentences that are judged by 3 annotators. Fleiss' kappa is k = 0.449, which is considered to be moderate agreement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Machine learning</head><p>For ranking sentences we use a Random Forest (RF) classifier <ref type="bibr" target="#b5">(Breiman, 2001)</ref>. <ref type="bibr">6</ref> We set the num- ber of iterations to 300 and the sampling rate to 0.3. Experiments with varying these two parame- ters did not show any significant differences. We also tried several feature normalization methods, none of them being able to significantly outper- 5 https://github.com/nickvosk/acl2015- dataset-learning-to-explain-entity- relationships <ref type="bibr">6</ref> In preliminary experiments, we contrasted RF with gra- dient boosted regression trees and LambdaMART and found that RF consistently outperformed other methods.  form the runs without feature normalization. We obtain POS tags using the Stanford part-of- speech tagger and filter out a standard list of 33 English stopwords. For the word embeddings we use word2vec and train our model on all text in Wikipedia using negative sampling and the con- tinuous bag of words architecture. We set the size of the phrase vectors to 500 and m = 30.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Evaluation metrics</head><p>We employ two main evaluation metrics in our experiments, NDCG <ref type="bibr" target="#b15">(Järvelin and Kekäläinen, 2002</ref>) and ERR ( <ref type="bibr" target="#b7">Chapelle et al., 2009</ref>). The for- mer measures the total accumulated gain from the top of the ranking that is discounted at lower ranks and is normalized by the ideal cumulative gain. The latter models user behavior and mea- sures the expected reciprocal rank at which a user will stop her search. We consider these ranking- based graded evaluation metrics at two cut-off points: position 1, corresponding to showing a sin- gle sentence to a user, and 10, which accounts for users who might look at more results. We report on NDCG@1, NDCG@10, ERR@1, ERR@10, and Exc@1, which indicates whether we have an "excellent" or "perfect" sentence at the top of the ranking. Likewise, Per@1 indicates whether we have a "perfect" sentence at the top of the ranking (not all entity pairs have an excellent or a perfect sentence).</p><p>We perform 5-fold cross validation and test for statistical significance using a paired two-tailed t- test. We depict a significant difference in perfor- mance for p &lt; 0.01 with (gain) and (loss) and for p &lt; 0.05 with (gain) and (loss). Boldface indicates the best score for a metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results and Analysis</head><p>We compare the performance of typical docu- ment retrieval models and state-of-the-art sentence retrieval models in order to answer RQ1. We consider five sentence retrieval models: Lucene ranking (LC), language modeling with Dirichlet  <ref type="table">Table 3</ref>: Results for the best baseline (B5) and the learning to rank method (LTR).</p><note type="other">Has one # pairs # sentences Method NDCG@1 NDCG@10 ERR@1 ERR@10 Exc@1 Per@1 fair 1</note><p>smoothing (LM), BM25, TFISF, and Recursive TF-ISF (R-TFISF). We follow related work and set µ = 0.1 for R-TFISF, k = 1 and b = 0 for BM25 and µ = 250 for LM <ref type="bibr" target="#b13">(Fernández et al., 2011</ref>).</p><p>In our experiments, a query q is constructed us- ing various combinations of surface forms of the two entities e i and e j and the relationship r. Each entity in the entity pair can be represented by its title, the titles of any redirect pages pointing to the entity's article, the n-grams used as anchors in Wikipedia to link to the article of the entity, or the union of them all. The relationship r can be repre- sented by the terms in the relationship, synonyms in wordnet(r), or by phrases in word2vec(r).</p><p>First, we fix the way we represent r. Base- line B1 does not include any representation of r in the query. B2 includes the relationship terms of r, while B3 includes the relationship terms of r and the synonyms in wordnet(r). B4 includes the terms of r and the phrases in word2vec(r), and B5 includes the relationship terms of r, the synonyms in wordnet(r) and the phrases in word2vec(r). Combining these variations with the entity repre- sentations, we find that all combinations that use the titles as representation and R-TFISF as the retrieval function outperform all other combina- tions. <ref type="bibr">7</ref> This can be explained by the fact that titles are least ambiguous, thus reducing the possibility of accidentally referring to other entities. BM25 and LC perform almost as well as R-TFISF, with only insignificant differences in performance. <ref type="table" target="#tab_3">Table 2</ref> shows the best performing combination of each baseline, i.e., varying the representation of r and using titles and R-TFISF. B4 and B5 are the best performing baselines, suggesting that word2vec(r) and wordnet(r) are beneficial. B5 significantly outperforms all baselines except B4.</p><p>We also experiment with a supervised combina- <ref type="bibr">7</ref> We omit a full table of results due to space constraints.</p><p>tion of the baseline rankers using LTR. Here, we consider each baseline ranker as a separate feature and train a ranking model. The trained model is not able to outperform the best individual baseline, however.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Learning to rank sentences</head><p>Next, we provide the results of our method us- ing the features described in Section 4.2, exploring whether our learning to rank (LTR) approach im- proves over sentence retrieval models (RQ2). We compare an LTR model using <ref type="table" target="#tab_1">Table 1</ref>'s features against the best baseline (B5). <ref type="table">Table 3</ref> shows the results. Each group in the table contains the results for the entity pairs that have at least one candidate sentence of that relevance grade for B5 and LTR. We find that LTR significantly outperforms B5 by a large margin. The absolute performance dif- ference between LTR and B5 becomes larger for all metrics as we move from "fair" to "perfect," which shows that LTR is more robust than the baseline for entity pairs that have at least one high quality candidate sentence. LTR ranks the best possible sentence at the top of the ranking for ∼83% of the cases for entity pairs that contain an "excellent" sentence and for ∼72% of the cases for entity pairs that contain a "perfect" sentence.</p><p>Note that, as indicated in Section 5.1, we dis- card entity pairs that have only "bad" sentences in our experiments. For the sake of complete- ness, we report on the results for all entity pairs in our dataset-including those without any relevant sentences-in <ref type="table" target="#tab_6">Table 4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Relationship-dependent models</head><p>Relevant sentences may have different properties for different relationship types. For example, a sentence describing two entities being partners would have a different form than one describing that two entities costar in a movie. A similar Has one # pairs # sentences Method NDCG@1 NDCG@10 ERR@1 ERR@10 Exc@1 Per@1    <ref type="table">Table 5</ref>: Results for relationship-dependent models. Similar relationships are grouped together.</p><p>idea was investigated in the context of QA for as- sociating question and answer types ( <ref type="bibr" target="#b30">Yao et al., 2013</ref>). To answer (RQ3) we examine whether learning a relationship-dependent model improves over learning a single model for all types. We split our dataset per relationship type and train a model per type using 5-fold cross-validation within each. <ref type="table">Table 5</ref> shows the results. 8 Our method is ro- bust across different relationships in terms of NDCG. However, we observe some variation in ERR as this metric is more sensitive to the distri- bution of relevant items than NDCG-the distri- bution over relevance grades varies per relation- ship type. For example, it is much more likely to find candidate sentences that have a high relevance grade for Person, isSpouseOf , Person than for Athlete, PlaysSameSportTeamAs, Athlete in our dataset. We plan to address this issue by ex- ploring other corpora in the future. The second-to-last row in <ref type="table">Table 5</ref> shows the av- eraged results over the different relationship types, which is a significant improvement over LTR at p &lt; 0.01 for all metrics. This method ranks the best possible sentence at the top of the ranking for ∼85% of the cases for entity pairs that contain an "excellent" sentence (∼2% absolute improvement over LTR) and for ∼75% of the cases for entity pairs that contain a "perfect" sentence (∼3% abso- lute improvement over LTR). <ref type="bibr">8</ref> We omit Exc@1 and Per@1 due to space constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Feature type analysis</head><p>Next, we analyze the impact of the feature types. <ref type="table">Table 6</ref> shows how performance varies when re- moving one feature type at a time from the full feature set. Relationship type features are the most important, although entity type features are impor- tant as well. This indicates that introducing fea- tures based on entities identified in the sentences and the relationship is beneficial for this task. Fur- thermore, the limited dependency on the source feature type indicates that our method might be able to generalize in other domains. Finally, text type features do contribute to retrieval effective- ness, although not significantly. Note that calcu- lating the sentence features is straightforward, as none of our features requires heavy linguistic anal- ysis.  <ref type="table">Table 6</ref>: Results using relationship-dependent models, removing individual feature types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Error analysis</head><p>When looking at errors made by the system, we find that some are due to the fact that entity pairs might have more than one relationship (e.g., ac-tors that costar in movies also being partners) but the selected sentence covers only one of the re- lationships. <ref type="bibr">9</ref> For example, Liza Minnelli is the daughter of Judy Garland, but they have also costarred in a movie, which is the relationship of interest. The model ranks the sentence "Liza Minnelli is the daughter of singer and actress Judy Garland. . . " at the top, while the most relevant sentence is: "Judy Garland performed at the Lon- don Palladium with her then 18-year-old daughter Liza Minnelli in November 1964." Sentences that contain the relationship in which we are interested, but for which this cannot be directly inferred, are another source of error. Consider, for example, the following sentence, which explains director Christopher Nolan directed actor Christian Bale: "Jackman starred in the 2006 film The Prestige, directed by Christopher Nolan and costarring Christian Bale, Michael Caine, and Scarlett Johansson". Even though the sentence contains the relationship of in- terest, it focuses on actor Hugh Jackman. The sentence "In 2004, after completing filming for The Machinist, Bale won the coveted role of Bat- man and his alter ego Bruce Wayne in Christopher Nolan's Batman Begins. . . ", in contrast, refers to the two entities and the relationship of interest di- rectly, resulting in a higher relevance grade. Our method, however, ranks the first sentence on top, as it contains more phrases that refer to the rela- tionship.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions and Future Work</head><p>We have presented a method for explaining rela- tionships between knowledge graph entities with human-readable descriptions. We first extract and enrich sentences that refer to an entity pair and then rank the sentences according to how well they describe the relationship. For ranking, we use learning to rank with a diverse set of fea- tures. Evaluation on a manually annotated dataset of "people" entities shows that our method sig- nificantly outperforms state-of-the-art sentence re- trieval models for this task. Experimental results also show that using relationship-dependent mod- els is beneficial.</p><p>In future work we aim to evaluate how our method performs on entities and relationships of <ref type="bibr">9</ref> The annotators marked sentences that do not refer to the relationship of interest as "bad" but indicated whether they describe another relationship or not. We plan to account for such cases in future work. any type and popularity, including tail entities and miscellaneous relationships. We also want to in- vestigate moving beyond Wikipedia and extract candidate sentences from documents that are not related to the knowledge graph, such as web pages or news articles. Employing such documents also implies an investigation into more advanced co- reference resolution methods.</p><p>Our analysis showed that sentences may cover different relationships between entities or differ- ent aspects of a single relationship-we aim to ac- count for such cases in follow-up work. Further- more, sentences may contain unnecessary infor- mation for explaining the relation of interest be- tween two entities. Especially when we want to show the obtained results to end users, we may need to apply further processing of the sentences to improve their quality and readability. We would like to explore sentence compression techniques to address this. Finally, relationships between en- tities have an inherit temporal nature and we aim to explore ways to explain entity relationships and their changes over time.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Source features 44 Sentence position Position of s in document from which it originates 45 From ei or ej? Does s originate from the Wikipedia article of ei or ej? 46 #(ei or ej) Number of occurrences of ei or ej in document from which s originates, inspired by document smoothing for sentence retrieval (Murdock and Croft, 2005)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Features 5-8 capture the distribution of part-of- speech tags in the sentence. Entity features These features partly build on (Tsagkias et al., 2011; Meij et al., 2012) and de- scribe the entities and are dependent on the knowl- edge graph. Whether e i or e j is the first appearing entity in a sentence might be an indicator of impor- tance (feature 13). The spread of e i and e j in the sentence (feature 14) might be an indicator of their centrality in the sentence (Blanco and Zaragoza, 2010). Features 15-22 capture the distribution of part-of-speech tags in the sentence in a window of four words around e i or e j in s (Mintz et al., 2009), complemented by the number of entities between, to the left of, and to the right of the entity pair (features 23-25).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>-</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Mintz et al., 2009)</head><label></label><figDesc></figDesc><table>Entity features 
9 #entities 
Total number of entities in s 
10 Link to ei 
Whether s contains a link to the entity ei 
11 Link to ej 
Whether s contains a link to the entity ej 
12 Links to ei and ej 
Whether s contains links to both entities ei and ej 
13 Entity first 
Is ei or ej the first entity in the sentence? 
14 Spread of ei, ej 
Distance between the last match of ei and ej in s (Blanco and Zaragoza, 2010) 
15-22 POS fractions left/right 
Fraction of verbs, nouns, adjectives, others to the left/right window of ei and ej in 
s (Mintz et al., 2009) 
23-25 #entities left/right/between Number of entities to the left/right or between entities ei and ej in s 
26 common links ei, ej 
Whether s contains any common link of ei and ej 
27 #common links 
The number of common links of ei and ej in s 
28 Score common links ei, ej Sum of the scores of the common links of ei and ej in s 
29-30 #common links prev/next 
The number of common links of ei and ej in previous/next sentence of s 

Relationship features 
31 Match terms(r)? 
Whether s contains any term in terms(r) 
32 Match wordnet(r)? 
Whether s contains any phrase in wordnet(r) 
33 Match word2vec(r)? 
Whether s contains any phrase in word2vec(r) 
34-36 or's 
Boolean OR of feature 31 and one or both of features 32 and 33 
37-38 or(31, 32, 33) prev/next 
Boolean OR of features 31, 32, 33 for the previous/next sentence of s 
39 Average word2vec(r) 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 : Features used for sentence ranking.</head><label>1</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Results for five baseline variants. See text 
for their description and significant differences. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="true"><head>Table 4 : Results for the best baseline (B5) and the learning to rank method (LTR), using all entity pairs in the dataset, including those without any relevant sentences.</head><label>4</label><figDesc></figDesc><table>Relationship 
# pairs # sentences NDCG@1 NDCG@10 ERR@1 ERR@10 

MovieActor , CoCastsWith, MovieActor 

410 
1 403 
0.8604 
0.9436 
0.3809 
0.4546 

TvActor , CoCastsWith, TvActor 

210 
626 
0.8729 
0.9482 
0.3271 
0.3845 

MovieActor , IsDirectedBy, MovieDirector 

MovieDirector , Directs, MovieActor 

112 
492 
0.8795 
0.9396 
0.4709 
0.5261 

Person, isChildOf , Person 

Person, isParentOf , Person 

108 
716 
0.8428 
0.9081 
0.6395 
0.7136 

Person, isPartnerOf , Person 

Person, isSpouseOf , Person 

155 
877 
0.8623 
0.9441 
0.6153 
0.6939 

Athlete, PlaysSameSportTeamAs, Athlete 

98 
321 
0.8787 
0.9535 
0.3350 
0.3996 

Average results over all data 
1 093 
4 435 
0.8661 
0.9395 
0.4615 
0.5287 
LTR (Table 3; fair) 
0.8489 
0.9375 
0.4242 
0.4980 

</table></figure>

			<note place="foot">* This work was carried out while this author was visiting Yahoo Labs.</note>

			<note place="foot" n="1"> We experimented with the Stanford co-reference resolution system (Lee et al., 2011) and Apache OpenNLP and found that they were not able to consistently achieve the level of effectiveness that we require. 2 http://en.Wikipedia.org/wiki/ Wikipedia:Manual_of_Style/Linking</note>

			<note place="foot" n="3"> In preliminary experiments R-TFISF and LC were the best performing among a pool of sentence retrieval methods. 4 Note that, except for the co-reference resolution step described in Section 4.1, our method does not depend on this restriction.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research was partially supported by the Eu-ropean Community's Seventh Framework Pro-gramme <ref type="bibr">(FP7/2007</ref><ref type="bibr">(FP7/-2013</ref> </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning to rank for robust question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hema</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Subbian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prem</forename><surname>Melville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">D</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">C</forename><surname>Gondek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st ACM international conference on Information and knowledge management</title>
		<meeting>the 21st ACM international conference on Information and knowledge management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="833" to="842" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Retrieval and novelty detection at the sentence level</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Courtney</forename><surname>Wade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alvaro</forename><surname>Bolivar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval</title>
		<meeting>the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="314" to="321" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Modern information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricardo</forename><surname>Baeza-Yates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Berthier</forename><surname>Ribeiro-Neto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<publisher>ACM press New York</publisher>
			<biblScope unit="volume">463</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Finding support sentences for entities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Blanco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Zaragoza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 33rd international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="339" to="346" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Entity recommendations in web search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Blanco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Berkant Barla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Cambazoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Mika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Torzec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Semantic Web-ISWC 2013</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="33" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Random forests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leo</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning to rank using an ensemble of lambdagradient models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krysta</forename><forename type="middle">Marie</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><forename type="middle">N</forename><surname>Svore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrzej</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Pastusiak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Yahoo! Learning to Rank Challenge</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="25" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Expected reciprocal rank for graded relevance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ya</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Grinspan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th ACM conference on Information and knowledge management</title>
		<meeting>the 18th ACM conference on Information and knowledge management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="621" to="630" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning to construct knowledge bases from the world wide web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Craven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Dipasquo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dayne</forename><surname>Freitag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kamal</forename><surname>Nigam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seán</forename><surname>Slattery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="69" to="113" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A recursive TF-ISF based sentence retrieval method with local context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alen</forename><surname>Doko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Majaštulamajaˇmajaštula</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Darko</forename><surname>Stipaničev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Machine Learning and Computing</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="195" to="200" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Knowledge vault: A web-scale approach to probabilistic knowledge fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geremy</forename><surname>Heitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilko</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ni</forename><surname>Lao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Strohmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaohua</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;14</title>
		<meeting>the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;14</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="601" to="610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Kalyanpur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Suchanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pratim Partha</forename><surname>Talukdar</surname></persName>
		</author>
		<title level="m">Proceedings of the Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge Extraction (AKBC-WEKEX), chapter Proceedings of the Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge Extraction (AKBC-WEKEX). Association for Computational Linguistics</title>
		<meeting>the Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge Extraction (AKBC-WEKEX), chapter the Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge Extraction (AKBC-WEKEX). Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Rex: explaining relationships between entity pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lujun</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anish</forename><forename type="middle">Das</forename><surname>Sarma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Bohannon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the VLDB Endowment</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="241" to="252" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Extending the language modeling framework for sentence retrieval to include local context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">E</forename><surname>Ronald T Fernández</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leif</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Azzopardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="355" to="389" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Natural language question answering: the view from here</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lynette</forename><surname>Hirschman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Gaizauskas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">04</biblScope>
			<biblScope unit="page" from="275" to="300" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Cumulated gain-based evaluation of IR techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kalervo</forename><surname>Järvelin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaana</forename><surname>Kekäläinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="422" to="446" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">SiteQ: Engineering high performance QA system using lexico-semantic pattern matching and shallow NLP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungyun</forename><surname>Gary Geunbae Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seungwoo</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanmin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bong-Hyun</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changki</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Byungkwan</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeongwon</forename><surname>Kwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongseok</forename><surname>Cha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joohui</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>An</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TREC</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Stanford&apos;s multi-pass sieve coreference resolution system at the CoNLL-2011 shared task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heeyoung</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yves</forename><surname>Peirsman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angel</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifteenth Conference on Computational Natural Language Learning: Shared Task</title>
		<meeting>the Fifteenth Conference on Computational Natural Language Learning: Shared Task</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="28" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A study of statistical query expansion strategies for sentence retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGIR 2008 Workshop on Focused Retrieval</title>
		<meeting>the SIGIR 2008 Workshop on Focused Retrieval</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="37" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Adding semantics to microblog posts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edgar</forename><surname>Meij</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wouter</forename><surname>Weerkamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fifth ACM international conference on Web search and data mining</title>
		<meeting>the fifth ACM international conference on Web search and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="563" to="572" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning to link with Wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Milne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th ACM conference on Information and knowledge management</title>
		<meeting>the 17th ACM conference on Information and knowledge management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="509" to="518" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction without labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Mintz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bills</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rion</forename><surname>Snow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1003" to="1011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A translation model for sentence retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vanessa</forename><surname>Murdock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W. Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing</title>
		<meeting>the conference on Human Language Technology and Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="684" to="691" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Aspects of Sentence Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vanessa</forename><forename type="middle">Graham</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Murdock</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
		<respStmt>
			<orgName>University of Massachusetts Amherst</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning to rank answers to nonfactoid questions from web collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimiliano</forename><surname>Ciaramita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Zaragoza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="351" to="383" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Linking online news and social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manos</forename><surname>Tsagkias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wouter</forename><surname>Maarten De Rijke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weerkamp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM 2011: Fourth ACM International Conference on Web Search and Data Mining</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Connecting language and knowledge bases with embedding models for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oksana</forename><surname>Yakhnenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">An effective, lowcost measure of semantic relatedness obtained from wikipedia links</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Milne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of AAAI Workshop on Wikipedia and Artificial Intelligence: an Evolving Synergy</title>
		<meeting>eeding of AAAI Workshop on Wikipedia and Artificial Intelligence: an Evolving Synergy<address><addrLine>Chicago, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="25" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Open information extraction using wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daniel S Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="118" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Automatic coupling of answer extraction and information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuchen</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="159" to="165" />
		</imprint>
	</monogr>
	<note>Short Papers)</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
