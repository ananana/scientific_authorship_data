<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:41+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Understanding Task Design Trade-offs in Crowdsourced Paraphrase Collection</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youxuan</forename><surname>Jiang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">K</forename><surname>Kummerfeld</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walter</forename><forename type="middle">S</forename><surname>Lasecki</surname></persName>
						</author>
						<title level="a" type="main">Understanding Task Design Trade-offs in Crowdsourced Paraphrase Collection</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</title>
						<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="103" to="109"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-2017</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Linguistically diverse datasets are critical for training and evaluating robust machine learning systems, but data collection is a costly process that often requires experts. Crowdsourcing the process of paraphrase generation is an effective means of expanding natural language datasets, but there has been limited analysis of the trade-offs that arise when designing tasks. In this paper, we present the first systematic study of the key factors in crowdsourc-ing paraphrase collection. We consider variations in instructions, incentives, data domains, and workflows. We manually analyzed paraphrases for correctness, gram-maticality, and linguistic diversity. Our observations provide new insight into the trade-offs between accuracy and diversity in crowd responses that arise as a result of task design, providing guidance for future paraphrase generation procedures.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Paraphrases are useful for a range of tasks, includ- ing machine translation evaluation <ref type="bibr" target="#b2">(Kauchak and Barzilay, 2006</ref>), semantic parsing ( <ref type="bibr" target="#b16">Wang et al., 2015)</ref>, and question answering <ref type="bibr">(Fader et al., 2013)</ref>. Crowdsourcing has been widely used as a scal- able and cost-effective means of generating para- phrases ( <ref type="bibr" target="#b9">Negri et al., 2012;</ref><ref type="bibr" target="#b15">Wang et al., 2012;</ref><ref type="bibr" target="#b14">Tschirsich and Hintz, 2013)</ref>, but there has been limited analysis of the factors influencing diversity and correctness of the paraphrases workers write.</p><p>In this paper, we perform a systematic investiga- tion of design decisions for crowdsourcing para- phrases, including the first exploration of worker incentives for paraphrasing. For worker incen- tives, we either provide a bonus payment when a paraphrase is novel (encouraging diversity) or when it matches a paraphrase from another worker (encouraging agreement/correctness). We also varied the type of example paraphrases shown to workers, the number of paraphrases requested from each worker per sentence, the subject do- main of the data, whether to show answers to ques- tions, and whether the prompt sentence is the same for multiple workers or varies, with alternative prompts drawn from the output of other workers.</p><p>Effective paraphrasing has two desired proper- ties: correctness and diversity. To measure cor- rectness, we hand-labeled all paraphrases with semantic equivalence and grammaticality scores. For diversity, we measure the fraction of para- phrases that are distinct, as well as Paraphrase In N-gram Changes (PINC), a measure of n-gram variation. We have released all 2,600 paraphrases along with accuracy annotations. Our analysis shows that the most important factor is how work- ers are primed for a task, with the choice of ex- amples and the prompt sentence affecting diversity and correctness significantly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Previous work on crowdsourced paraphrase gener- ation fits into two categories: work on modifying the creation process or workflow, and studying the effect of prompting or priming on crowd worker output. Beyond crowdsourced generation, other work has explored using experts or automated sys- tems to generate paraphrases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Workflows for Crowd-Paraphrasing</head><p>The most common approach to crowdsourcing paraphrase generation is to provide a sentence as a prompt and request a single paraphrase from a worker. One frequent addition is to ask a differ- ent set of workers to evaluate whether a generated paraphrase is correct <ref type="bibr">(Buzek et al., 2010;</ref><ref type="bibr">Burrows et al., 2013)</ref>. <ref type="bibr" target="#b9">Negri et al. (2012)</ref> also explored an alternate workflow in which each worker writes two paraphrases, which are then given to other workers as the prompt sentence, forming a binary tree of paraphrases. They found that paraphrases deeper in the tree were more diverse, but under- standing how correctness and grammaticality vary across such a tree still remains an open ques- tion. Near real-time crowdsourcing <ref type="bibr">(Bigham et al., 2010</ref>) allowed <ref type="bibr" target="#b3">Lasecki et al. (2013a)</ref> to elicit vari- ations on entire conversations by providing a set- ting and goal to pairs of crowd workers. Continu- ous real-time crowdsourcing <ref type="bibr" target="#b4">(Lasecki et al., 2011)</ref> allows Chorus <ref type="bibr" target="#b5">Lasecki et al. (2013b)</ref> users to hold conversations with groups of crowd workers as if the crowd was a single individual, allowing for the collection of example conversations in more real- istic settings. The only prior work regarding in- centives we are aware of is by <ref type="bibr">Chklovski (2005)</ref>, who collected paraphrases in a game where the goal was to match an existing paraphrase, with ex- tra points awarded for doing so with fewer hints. The disadvantage of this approach was that 29% of the collected paraphrases were duplicates. In our experiments, duplication ranged from 1% to 13% in each condition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">The Effects of Priming</head><p>When crowd workers perform a task, they are primed (influenced) by the examples, instructions, and context that they see. This priming can re- sult in systematic variations in the resulting para- phrases. <ref type="bibr" target="#b8">Mitchell et al. (2014)</ref> showed that pro- viding context, in the form of previous utterances from a dialogue, only provides benefits once four or more are included. <ref type="bibr">Kumaran et al. (2014)</ref> provided drawings as prompts, obtaining diverse paraphrases, but without exact semantic equiva- lence. When each sentence expresses a small set of slot-filler predicates, <ref type="bibr" target="#b15">Wang et al. (2012)</ref> found that providing the list of predicates led to slightly faster paraphrasing than giving either a complete sentence or a short sentence for each predicate. We further expand on this work by exploring how the type of examples shown affects paraphrasing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Expert and Automated Generation</head><p>Finally, there are two general lines of research on paraphrasing not focused on using crowds. The first of these is the automatic collection of paraphrases from parallel data sources, such as translations of the same text or captions for the same image ( <ref type="bibr" target="#b0">Ganitkevitch et al., 2013;</ref><ref type="bibr">Chen and Dolan, 2011;</ref><ref type="bibr">Bouamor et al., 2012</ref>; Pavlick et al.,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Paraphrase/Reword Sentences</head><p>For each sentence below, please write 2 new sentence that express the same meaning in different ways (para- phrase/reword).</p><p>For example: 'Which 400 level courses don't have labs?' could be rewritten as:</p><p>• Of all the 400 level courses, which ones do not in- clude labs?</p><p>• What are the 400 level courses without lab sessions?</p><p>BONUS: You will receive 5 cents bonus for each sentence you write that matches one written by another worker on the task. 2015). These resources are extremely large, but usually (1) do not provide the strong semantic equivalence we are interested in, and (2) focus on phrases rather than complete sentences. The sec- ond line of work explores the creation of lattices that compactly encode hundreds of thousands of paraphrases ( <ref type="bibr">Dreyer and Marcu, 2012;</ref><ref type="bibr">Bojar et al., 2013</ref>). Unfortunately, these lattices are typically expensive to produce, taking experts one to three hours per sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Design</head><p>We conducted a series of experiments to investi- gate factors in crowdsourced paraphrase creation.</p><p>To do so in a controlled manner, we studied a sin- gle variation per condition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Definition of Valid Paraphrases</head><p>This project was motivated by the need for strongly equivalent paraphrases in semantic pars- ing datasets. We consider two sentences para- phrases if they would have equivalent interpreta- tions when represented as a structured query, i.e., "a pair of units of text deemed to be interchange- able" <ref type="bibr">(Dras, 1999</ref> We considered the above two questions as para- phrases since they are both requests for a list of classes, explicit and implicit, respectively, al- though the second one is a polar question and the first one is not. However:</p><p>Prompt:Which is easier out of EECS 378 and EECS 280? Is EECS 378 easier than EECS 280?</p><p>We did not consider the above two questions as paraphrases since the first one is requesting one of two class options and the second one is requesting a yes or no answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Baseline</head><p>We used Amazon Mechanical Turk, presenting workers with the instructions and examples in Fig- ure 1. Workers were shown prompt sentences one at a time, and asked to provide two para- phrases for each. To avoid confusion or training effects between different conditions, we only al- lowed workers to participate once across all con- ditions. The initial instructions shown to work- ers were the same across all conditions (variations were only seen after a worker accepted the task).</p><p>Workers were paid 5 cents per paraphrase they wrote plus, once all workers were done, a 5 cent bonus for paraphrases that matched another worker's paraphrase in the same condition. While we do not actually want duplicate paraphrases, this incentive may encourage workers to more closely follow the instructions, producing gram- matical and correct sentences. We chose this pay- ment rate to give around minimum wage, estimat- ing time based on prior work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Conditions</head><p>Examples We provided workers with an ex- ample prompt sentence and two paraphrases, as shown in <ref type="figure" target="#fig_0">Figure 1</ref>. We showed either: no ex- amples (No Examples), two examples with lexi- cal changes only (Lexical Examples), one exam- ple with lexical changes and one with syntactic changes (Mixed Examples), or two examples that each contained both lexical and syntactic changes (Baseline). The variations between these condi- tions may prime workers differently, leading them to generate different paraphrases.</p><p>Incentive The 5 cent bonus payment per para- phrase was either not included (No Bonus), awarded for each sentence that was a duplicate at the end of the task (Baseline), or awarded for each sentence that did not match any other worker's paraphrase (Novelty Bonus). Bonuses that depend on other workers' actions may encourage either creativity or conformity. We did not vary the base level of payment because prior work has found that workers work quality is not increased by in- creased financial incentives due to an anchoring effect relative to the base rate we define <ref type="bibr" target="#b7">(Mason and Watts, 2010)</ref>.</p><p>Workflow We considered three variations to workflow. First, for each sentence, we either asked workers to provide two paraphrases (Baseline), or one (One Paraphrase). Asking for multiple para- phrases reduces duplication (since workers will not repeat themselves), but may result in lower di- versity. Second, since our baseline prompt sen- tences are questions, we ran a condition with an- swers shown to workers (Answers). Third, we started all conditions with the same set of prompt sentences, but once workers had produced para- phrases, we had the option to either prompt future workers with the original prompt, or to use para- phrase from another worker. Treating sentences as points and the act of paraphrasing as creating an edge, the space can be characterized as a graph. We prompted workers with either the original sen- tences only (Baseline), or formed a chain struc- tured graph by randomly choosing a sentence that was (1) not a duplicate, and (2) furthest from the original sentence (Chain). These changes could impact paraphrasing because the prompt sentence is a form of priming.</p><p>Data domains We ran with five data sources: questions about university courses (Baseline), messages from dialogues between two stu- dents in a simulated academic advising ses- sion (ADVISING), questions about US geogra- phy <ref type="bibr">(GEOQUERY Tang and Mooney, 2001</ref>), text from the Wall Street Journal section of the Penn Treebank (WSJ <ref type="bibr" target="#b6">Marcus et al., 1993)</ref>, and discus- sions on the Ubuntu IRC channel (UBUNTU). We randomly selected 20 sentences as prompts from each data source with the lengths representative of the sentence length distribution in that source.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Metrics</head><p>Semantic Equivalence For a paraphrase to be valid, its meaning must match the original sen- tence. To assess this match, two of the authors- one native speaker and one non-native but fluent speaker-rated every sentence independently, then discussed every case of disagreement to determine a consensus judgement. Prior to the consensus- finding step, the inter-annotator agreement kappa scores were .50 for correctness (moderate agree- ment), and .36 for grammaticality (fair agree- ment) <ref type="bibr">(Altman, 1990)</ref>. For the results in <ref type="table">Table 1</ref>, we used a χ 2 test to measure significance, since this is a binary classification process.</p><p>Grammaticality We also judged whether the sentences were grammatical, again with two an- notators rating every sentence and resolving dis- agreements. Again, since this was a binary classi- fication, we used a χ 2 test for significance.</p><p>Time The time it takes to write paraphrases is important for estimating time-to-completion, and ensuring workers receive fair payment. We mea- sured the time between when a worker submitted one pair of paraphrases and the next. The first paraphrase was excluded since it would skew the data by including the time spent reading the in- structions and understanding the task. We report the median time to avoid skewing due to outliers, e.g. a value of five minutes when a worker prob- ably took a break. We apply Mood's Median test for statistical significance.</p><p>Diversity We use two metrics for diversity, mea- sured over correct sentences only. First, a simple measurement of exact duplication: the number of distinct paraphrases divided by the total number of paraphrases, as a percentage (Distinct). Sec- ond, a measure of n-gram diversity (PINC Chen and Dolan, 2011) 1 . In both cases, a higher score means greater diversity. For PINC, we used a t- test for statistical significance, and for Distinct we used a permutation test.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>We collected 2600 paraphrases: 10 paraphrases per sentence, for 20 sentences, for each of the 13 conditions. The cost, including initial testing, <ref type="bibr">was $196.30</ref>, of which $20.30 was for bonus pay- ments. <ref type="table">Table 1</ref> shows the results for all metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Discussion: Task Variation</head><p>Qualitatively, we observed a wide variety of lexi- cal and syntactic changes, as shown by these ex- ample prompts and paraphrases (one low PINC and one high PINC in each case): There was relatively little variation in grammat- icality or time across the conditions. The times  <ref type="table">Table 1</ref>: Variation across conditions for a range of metrics (defined in § 3.4). Bold indicates a statisti- cally significant difference compared to the base- line at the 0.05 level, and a † indicates significance at the 0.01 level, both after applying the Holm- Bonferroni method across each row <ref type="bibr" target="#b1">(Holm, 1979)</ref>.</p><p>we observed are consistent with prior work: e.g. <ref type="bibr" target="#b16">Wang et al. (2015)</ref> report ∼28 sec/paraphrase. Priming had a major impact, with the shift to lexical examples leading to a significant improve- ment in correctness, but much lower diversity. The surprising increase in correctness when providing no examples has a p-value of 0.07 and probably reflects random variation in the pool of workers. Meanwhile, changing the incentives by providing either a bonus for novelty, or no bonus at all, did not substantially impact any of the metrics.</p><p>Changing the number of paraphrases written by each worker did not significantly impact diversity (we worried that collecting more than one may lead to a decrease). We further confirmed this by calculating PINC between the two paraphrases provided by each user, which produced scores similar to comparing with the prompt. How- ever, the One Paraphrase condition did have lower grammaticality, emphasizing the value of evaluat- ing and filtering out workers who write ungram- matical paraphrases.</p><p>Changing the source of the prompt sentence to create a chain of paraphrases led to a significant increase in diversity. This fits our intuition that the prompt is a form of priming. However, cor- rectness decreases along the chain, suggesting the need to check paraphrases against the original sen- tence during the overall process, possibly using other workers as described in § 2.1. Meanwhile, showing the answer to the question being para-phrased did not significantly affect correctness or diversity, and in 2.5% of cases workers incorrectly used the answer as part of their paraphrase.</p><p>We also analyzed the distribution of incorrect or ungrammatical paraphrases by worker. 7% of workers accounted for 25% of incorrect para- phrases, while the best 30% of workers made no mistakes at all. Similarly, 8% of workers wrote 50% of the ungrammatical paraphrases, while 70% of workers wrote only grammatical para- phrases. Many crowdsourcing tasks address these issues by showing workers some gold standard in- stances, to evaluate workers' performance during annotation. Unfortunately, in paraphrasing there is no single correct answer, though other workers could be used to check outputs.</p><p>Finally, we checked the distribution of incorrect paraphrases per prompt sentence. Two prompts accounted for 22% of incorrect paraphrases:</p><p>Prompt:Which is easier out of EECS 378 and EECS 280? Is EECS 378 easier than EECS 280?</p><p>Prompt: Is Professor Stout the only person who teaches Algorithms? Are there professors other than Stout who teach Algo- rithms?</p><p>These paraphrases are not semantically equiva- lent to the original question, but they would elicit equivalent information, which explains why work- ers provided them. Providing negative examples may help guide workers to avoid such mistakes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Discussion: Domains</head><p>The bottom section of <ref type="table">Table 1</ref> shows measure- ments using the baseline setup, but with variations in the source domain of data. The only signifi- cant change in correctness is on UBUNTU, which is probably due to the extensive use of jargon in the dataset, for example: For grammaticality, GEOQUERY is particularly low; common mistakes included confusion be- tween singular/plural and has/have. WSJ is the do- main with the greatest variations. It has consider- ably longer sentences on average, which explains the greater time taken. This could also explain the lower distinctness and PINC score, because work- ers would often retain large parts of the sentence, sometimes re-arranged, but otherwise unchanged.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>While previous work has used crowdsourcing to generate paraphrases, we perform the first sys- tematic study of factors influencing the process. We find that the most substantial variations are caused by priming effects: using simpler exam- ples leads to lower diversity, but more frequent se- mantic equivalence. Meanwhile, prompting work- ers with paraphrases collected from other work- ers (rather than re-using the original prompt) in- creases diversity. Our findings provide clear guid- ance for future paraphrase generation, supporting the creation of larger, more diverse future datasets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Baseline task instructions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Prompt:</head><label></label><figDesc>How long has EECS 280 been offered for? How long has EECS 280 been offered? EECS 280 has been in the course listings how many years? Prompt: Can I take 280 on Mondays and Wednesdays? On Mondays and Wednesdays, can I take 280? Is 280 available as a Monday/Wednesday class?</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Prompt:</head><label></label><figDesc>ok, what does journalctl show That journalistic show is about what?</figDesc></figure>

			<note place="foot" n="1"> We also considered BLEU (Papineni et al., 2002), which measures n-gram overlap and is used as a proxy for correctness in MT. As expected, it strongly correlated with PINC.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Acknowledgements</head><p>We would like to thank the members of the UMich/IBM Sapphire project, as well as all of our study participants and the anonymous reviewers for their helpful suggestions on this work.</p><p>This material is based in part upon work sup-ported by IBM under contract 4915012629. Any opinions, findings, conclusions or recommenda-tions expressed above are those of the authors and do not necessarily reflect the views of IBM.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>107</head><p>Steven <ref type="bibr">Burrows, Martin Potthast, and Benno Stein. 2013</ref>. Paraphrase acquisition via crowdsourcing and machine learning. ACM Transactions on In- telligent Systems and Technology 4(3):43:1-43: <ref type="bibr">21</ref> </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">PPDB: The paraphrase database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juri</forename><surname>Ganitkevitch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/N/N13/N13-1092.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A simple sequentially rejective multiple test procedure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sture</forename><surname>Holm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scandinavian Journal of Statistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="65" to="70" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Online gaming for crowdsourcing phrase-equivalents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Kauchak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/C14-1117" />
	</analytic>
	<monogr>
		<title level="m">Proc. of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers</title>
		<meeting>of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers<address><addrLine>Melissa Densmore, and Shaishav Kumar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note>Proc. of the Human Language Technology Conference of the NAACL, Main Conference</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Conversations in the crowd: Collecting data for task-oriented dialog learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walter</forename><forename type="middle">S</forename><surname>Lasecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ece</forename><surname>Kamar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Bohus</surname></persName>
		</author>
		<ptr target="http://www.aaai.org/ocs/index.php/HCOMP/HCOMP13/paper/view/7637" />
	</analytic>
	<monogr>
		<title level="m">Scaling Speech, Language Understanding and Dialogue through Crowdsourcing Workshop at the First AAAI Conference on Human Computation and Crowdsourcing</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Realtime crowd control of existing interfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyle</forename><forename type="middle">I</forename><surname>Walter S Lasecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>White</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey P</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bigham</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=2047200" />
	</analytic>
	<monogr>
		<title level="m">Proc. of the 24th annual ACM symposium on User interface software and technology</title>
		<meeting>of the 24th annual ACM symposium on User interface software and technology</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="23" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Chorus: a crowd-powered conversational assistant</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachel</forename><surname>Walter S Lasecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Wesley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anand</forename><surname>Nichols</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey P</forename><surname>James F Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bigham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 26th annual ACM symposium on User interface software and technology</title>
		<meeting>of the 26th annual ACM symposium on User interface software and technology</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="151" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Building a large annotated corpus of English: The Penn Treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><forename type="middle">P</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatrice</forename><surname>Santorini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><forename type="middle">Ann</forename><surname>Marcinkiewicz</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/J93-2004" />
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="313" to="330" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Financial incentives and the performance of crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Winter</forename><surname>Mason</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Duncan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Watts</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=1600175" />
	</analytic>
	<monogr>
		<title level="j">ACM SigKDD Explorations Newsletter</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="100" to="108" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Crowdsourcing language generation templates for dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Bohus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ece</forename></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/W14-5003" />
	</analytic>
	<monogr>
		<title level="m">Proc. of the INLG and SIGDIAL 2014 Joint Session</title>
		<meeting>of the INLG and SIGDIAL 2014 Joint Session</meeting>
		<imprint>
			<date type="published" when="2014-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Chinese whispers: Cooperative paraphrase acquisition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yashar</forename><surname>Mehdad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Marchetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Giampiccolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luisa</forename><surname>Bentivogli</surname></persName>
		</author>
		<ptr target="http://www.lrec-conf.org/proceedings/lrec2012/pdf/772Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proc. of the Eighth International Conference on Language Resources and Evaluation (LREC&apos;12</title>
		<meeting>of the Eighth International Conference on Language Resources and Evaluation (LREC&apos;12</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">BLEU: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P/P02/P02-1040.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proc. of the 40th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>of the 40th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">PPDB 2.0: Better paraphrase ranking, fine-grained entailment relations, word embeddings, and style classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellie</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushpendre</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juri</forename><surname>Ganitkevich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris Callison-Burch Ben</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 53rd Annual Meeting of the Association for Computational Linguistics (ACL</title>
		<meeting>of the 53rd Annual Meeting of the Association for Computational Linguistics (ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Using multiple clause constructors in inductive logic programming for semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lappoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 12th European Conference on Machine Learning</title>
		<meeting>of the 12th European Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title/>
		<idno type="doi">10.1007/3-</idno>
		<ptr target="https://link.springer.com/chapter/10.1007/3-" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Leveraging crowdsourcing for paraphrase recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Tschirsich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerold</forename><surname>Hintz</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/W13-2325" />
	</analytic>
	<monogr>
		<title level="m">Proc. of the 7th Linguistic Annotation Workshop and Interoperability with Discourse</title>
		<meeting>of the 7th Linguistic Annotation Workshop and Interoperability with Discourse</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Crowdsourcing the acquisition of natural language corpora: Methods and observations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bohus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kamar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 IEEE Spoken Language Technology Workshop (SLT)</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Building a semantic parser overnight</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yushi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P15-1129" />
	</analytic>
	<monogr>
		<title level="m">Proc. of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language essing</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
