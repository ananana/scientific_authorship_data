<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:14+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Cross-lingual projection for class-based language models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Beat Gfeller</roleName><forename type="first">Vlad</forename><surname>Schogol</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Hall</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Inc</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Cross-lingual projection for class-based language models</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="83" to="88"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper presents a cross-lingual projection technique for training class-based language models. We borrow from previous success in projecting POS tags and NER mentions to that of a trained class-based language model. We use a CRF to train a model to predict when a sequence of words is a member of a given class and use this to label our language model training data. We show that we can successfully project the contextual cues for these classes across pairs of languages and retain a high quality class model in languages with no supervised class data. We present empirical results that show the quality of the projected models as well as their effect on the downstream speech recognition objective. We are able to achieve over 70% of the WER reduction when using the projected class models as compared to models trained on human annotations .</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Class-based language modeling has a long history of being used to improve the quality of speech recognition systems ( <ref type="bibr" target="#b0">Brown et al., 1992;</ref><ref type="bibr" target="#b5">Knesser and Ney, 1993)</ref>. Recent work on class-based mod- els has exploited named entity recognition (NER) approaches to label language model training data with class labels ( <ref type="bibr" target="#b8">Levit et al., 2014;</ref><ref type="bibr" target="#b12">Vasserman et al., 2015)</ref>, providing a means to assign words and phrases to classes based on their context. These contextually assigned classes have been shown to improve speech recognition significantly over grammar-based, deterministic class assignments.</p><p>In this work, we address the problem of la- beling training data in order to build a class se- quence tagger. We borrow from the successes of previous cross-lingual projection experiments for labeling tasks ( <ref type="bibr" target="#b1">Burkett et al., 2010;</ref><ref type="bibr" target="#b11">Padó and Lapata, 2009)</ref>. We focus on numeric classes (e.g., address numbers, dates, currencies, times, etc.) as the sequence-based labeling approach has been shown to be effective for identifying them. Given a model trained from human-labeled data in one language (we refer to this as the high- resource language), we label translations of sen- tences from another language (referred to as the low-resource language). We show that we can project the numeric entity boundaries and labels across the aligned translations with a phrase-based translation model. Furthermore, we show that if we train a class labeling model on the projected low-resource language and then use that to build a class-based speech recognition system, we achieve between 70% and 85% of the error reduction as we would have achieved with human-labeled ex- amples in the low-resource language.</p><p>We present empirical results projecting numeric entity labels from English to Russian, Indonesian, and Italian. We present full speech recognition results for using human annotated data (the ideal performance) and projected data with various sizes of training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>There is an increasingly large body of work based on exploiting alignments between translations of sentences in multiple languages ( <ref type="bibr" target="#b1">Burkett et al., 2010;</ref><ref type="bibr" target="#b3">Das and Petrov, 2011)</ref>. In this work we employ the simple approach of projecting anno- tations across alignments of translated sentences. Our cross-lingual approach is closely related to other NER projection approaches (Huang et al., <ref type="figure">Figure 1</ref>: Examples of cross-lingual projection for numeric entities.</p><p>2003; <ref type="bibr" target="#b9">Moore, 2003)</ref>; however, we have focused on a limited class of entities which may explain why the simple approach works reasonably well.</p><p>Our projection approach is most closely related to that presented in ( ) and <ref type="bibr" target="#b11">(Padó and Lapata, 2009)</ref>. In each of these, la- bels over sequences of words are projected across alignments directly from one language to the other. While we follow a similar approach, our goal is not necessarily to get the exact projection, but to get a projection which allows us to learn contextual cues for the classes we are labeling. Additionally, we focus on the case where we are generating the translated data rather that identify- ing existing parallel data. Similar to ), we filter out poor alignments (de- tails are described in Section 3.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Training class taggers for language modeling</head><p>We use a statistical sequence tagger to identify and replace class instances in raw text with their la- bel. For example, the tokens 10 thousand dollars in the raw training text may be replaced with a placeholder class symbol. The decision is context- dependent: the tagger is able to resolve ambi- guities among possible labels, or even leave the text unchanged. Next, this modified text is used to train a standard n-gram language model. Fi- nally, all placeholders become non-terminals in the language model and are expanded either stat- ically or dynamically with stochastic finite-state class grammars (see <ref type="figure" target="#fig_0">Figure 2</ref> for an example). Decorator tokens inside the grammars are used to mark class instances in the word lattice so that they can be converted (after recognition) to the de- sired written forms using deterministic spoken-to- written text-normalization rules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Cross-lingual Projection Techniques</head><p>The starting point for cross-lingual projection is to train a statistical sentence tagger of high quality in a high-resource language, i.e., a language where both a lot of training data and human annotators are readily available. We use English in our exper- iments.</p><p>To obtain annotated sentences in a low-resource language, we translate unlabeled sentences into the high-resource language. We use an in-house phrase-based statistical machine translation sys- tem ( <ref type="bibr" target="#b6">Koehn et al., 2003</ref>) which is trained with par- allel texts extracted from web pages; described in detail in Section 4.1 of (Nakagawa, 2015). The translation system we use provides token-by-token alignments as part of the output. This is achieved by keeping alignments along with phrase-pairs during the phrase extraction stage of training the alignment system.</p><p>The high quality sentence tagger is applied to the translated sentences. Then, using the align- ments between the translated sentences, we map class tags back to the low-resource language. See <ref type="figure">Figure 1</ref> for examples of actual mappings pro- duced by this procedure.</p><p>With this approach, we can produce arbitrar- ily large in-domain annotated training sets for the low-resource language. These annotated sen- tences are then used to train a class tagger for the low-resource language. The main question is whether the resulting class tagger is of sufficient quality for our down-stream objective.</p><p>For the goal of training a class-based language model in a low-resource language, one may con- sider a different approach than the one just de- scribed: instead of training a tagger in the low- resource language, each sentence in the language model training data could be translated to the high- resource language, tagged using the statistical tag- ger, and projected back to the low-resource lan- guage. The primary reason for not pursuing this approach is the size of the language model train- ing data (tens of billions of sentences). Translat- ing a corpus this large is prohibitive. As the high- resource language tagger is trained on approxi- mately 150K tokens, we believe that we have cov- ered a large number of the predictive cues for the set of classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Alignment details</head><p>When projecting the class labels back from a translated sentence to the original sentence, vari- ous subtle issues arise. We describe these and our solutions for each in this section.</p><p>To tag a token in the low-resource language, we see which tokens in the high-resource language are aligned to it in the translation, and look at their class tags. If all of these tokens have the same class tag, we assign the same tag to the low- resource language token. Otherwise, we use the following rules:</p><p>• If some tokens have no class tag but others have some class tag, we still assign the class tag to the original token.</p><p>• If multiple tokens with different class tags map to the original token, we consider the tagging ambiguous. In such a case, we sim- ply skip the sentence and do not use it for training the low-resource tagger. We can af- ford to do so because there is no shortage of unlabeled training sentences.</p><p>In a number of cases, we ignore sentence pairs which may have contained alignments allowing us to project labels, but also contained noise (e.g., spurious many-to-one alignments). We rejected poor alignments 2%, 31% and 14% of the time for Indonesian, Russian and Italian respectively. Date and time expressions were often affected by these noisy alignments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Empirical evaluation 4.1 Data</head><p>We trained an English conditional random field (CRF) ( <ref type="bibr" target="#b7">Lafferty et al., 2001</ref>) tagger to be used in all experiments in order to provide labels for the sentences produced by translation. To train this tagger we obtained a data set of 24,503 manually labeled sentences (150K tokens) sampled from a corpus of British English language model training material. Each token is labeled with one of 17 pos- sible tags. About 95% of the tokens are labeled with a 'none' tag, meaning that the token is not in any of the pre-determined non-lexical classes.</p><p>Separately, we obtained similar training sets to create Italian, Indonesian and Russian taggers. The models trained from these labeled data sets were used only to create baseline systems for com- parison with the cross-lingual systems.</p><p>To provide input into our cross-lingual projec- tion procedure, we also sampled datasets of unla- beled sentences of varying sizes for each evalua- tion language, using the same sampling procedure as used for the human-labeled sets.</p><p>Note that these tagger training sets have incon- sistent sizes across languages (see <ref type="table">Table 2</ref>) due to the nature of the sampling procedure: Each train- ing source is searched for sentences matching an extensive list of patterns of numeric entities. Sen- tences from each training source are collected up to a source-specific maximum number (which may not always be reached). We also apply a flattening step to increase diversity of the sample.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">CRF model</head><p>Our CRF tagger model was trained online using a variant of the MIRA algorithm <ref type="bibr" target="#b2">(Crammer and Singer, 2003)</ref>. Our feature set includes isolated features (for word identity w i , word type d i , and word cluster c i ) as well as features for neighboring words</p><formula xml:id="formula_0">w i−2 , w i−1 , w i+1 , w i+2 , w i+3 , neighbor- ing clusters c i−2 , c i−1 , c i+1 , c i+2 , c i+3 , pair fea- tures (w i , d i−1 ), (w i , d i+1 ), (d i , d i−1 ), (d i , d i+1 ),</formula><p>and domain-specific features (indicators for tokens within a given numeric range, or tokens that end in a certain number of zero digits). We also include class bias features, which capture the class prior distribution found in the training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Metrics</head><p>We use two manually transcribed test sets to eval- uate the performance of our approach in the con-  <ref type="table">Table 1</ref>: NUM refers to the NUMERIC entities test set and VS refers to the VOICE-SEARCH test set.</p><p>text of numeric transcription. The first test set VOICE-SEARCH (approximately 48K words for Italian and Russian, and approximately 36K words for Indonesian) is a sample from general voice- search traffic, and tracks any regressions that ap- pear as a result of biasing too heavily toward the selected classes. The other test set NUMERIC (ap- proximately 48K words for Italian, and approxi- mately 60K for Russian and Indonesian) contains utterances we expect to benefit from class-based modeling of numeric entities. See <ref type="table">Table 1</ref> for de- tails on these test sets.</p><p>We report word-error-rate (WER) on each test set for each model evaluated, including two base- line systems (one built without classes at all and another that has classes identified by a tagger trained on human-labeled data). We also report a labeled-bracket F1 score to show the perfor- mance of the tagger independent of the speech- recognition task. For each language, the test set used for labeled-bracket F1 is a human-labeled corpus of approximately 2K sentences that were held out from the human-labeled corpora for the baseline systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Results</head><p>The results in <ref type="table">Table 2</ref> show that all class-based systems outperform the baseline in WER on the NUMERIC test set, while performance on the VOICE-SEARCH test set was mostly flat. The flat performance on VOICE-SEARCH is expected: as seen in <ref type="table">Table 1</ref> this test set has a very low propor- tion of words that are numeric in form. We pro- vide results on this test set in order to confirm that our approach does not harm general voice-search queries. As for performance on the NUMERIC test set, larger cross-lingual data sets led to better performance for Russian and Italian, but caused a slight regression for Indonesian. The trans- lation system we use for these experiments has been optimized for a general-purpose web search  <ref type="table">Table 2</ref>: NUM refers to the NUMERIC entities test set and VS refers to the VOICE-SEARCH test set. All NUM WER results are statistically significant (p &lt; 0.1%) using a paired random permutation significance test.</p><p>translation task rather than for an academic task. When evaluated on a test set matched to the trans- lation task, performance for Russian-to-English was considerably worse than for Indonesian-to- English or Italian-to-English. For Indonesian (ID), the human-labeled sys- tem achieved a 4.5% relative WER reduction on NUMERIC, while the best cross-lingual system achieved a 3.5% relative reduction.</p><p>For Russian (RU), the human-labeled system improved more, achieving an 11.8% relative re- duction on NUMERIC, while the best cross-lingual system achieved an 8.7% relative reduction.</p><p>Finally, for Italian (IT), the human-labeled sys- tem gave an impressive 17.4% relative reduction on NUMERIC, while the best cross-lingual system achieved a 14.8% relative reduction on the same test set.</p><p>Across the three languages, the cross-lingual systems achieved relative error reductions on the NUMERIC test set that were between 70% and 85% of the reduction achieved when using only human-labeled data for training the class tagger.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Error Analysis</head><p>We noticed that the Russian cross-lingual-derived training set was of lower quality than those of the other languages, as seen in the labeled-bracket F1 metric in <ref type="table">Table 2</ref>. Looking more closely, we noticed that the per-class F1 scores tended to be lower for labels used for dates and times. This ob- servation also concides with the observation that the alignment procedure frequently ran into am- biguity issues when aligning month, day and year tokens between Russian and English, thus signifi- cantly reducing the coverage of these labels in the induced cross-lingual training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We presented a cross-lingual projection technique for training class-based language models. We ex- tend a previously successful sequence-modeling- based class labeling approach for identifying contextually-dependent class assignments by pro- jecting labels from a high-resource language to a low-resources language. This allows us to build class-based language models in low-resource lan- guages with no annotated data. Our empirical re- sults show that we are able to achieve between 70% and 85% of the error reduction that we would have obtained had we used human-labeled data.</p><p>While cross-lingual projection for sequence- labeling techniques are well known in the com- munity, our approach exploits the fact that we are generating training data from the projection rather than using the projected result directly. Further- more, noise in the class-labeling system does not cripple the language model as it learns a distribu- tion over labels (including no label).</p><p>In future work, we will experiment with alternative projection approaches including pro- jecting the training data and translating from the high-resource language to the low-resource lan- guage. We also plan to experiment with different projection approaches to address the ambiguity issues we observed when aligning time and date expressions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: This FST is a small excerpt of the full grammar for TIME. Arc weights are not shown.</figDesc><graphic url="image-1.png" coords="2,62.61,64.76,236.34,111.78" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Acknowledgments</head><p>We would like to thank the anonymous reviewers for their detailed reviews and suggestions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Class-based n-gram models of natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">V</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">L</forename><surname>Desouza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><forename type="middle">J</forename><surname>Mercer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenifer</forename><forename type="middle">C</forename><surname>Della Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="467" to="479" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning better monolingual models with unannotated bilingual text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Burkett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth Conference on Computational Natural Language Learning, CoNLL &apos;10</title>
		<meeting>the Fourteenth Conference on Computational Natural Language Learning, CoNLL &apos;10</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="46" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Ultraconservative online algorithms for multiclass problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="951" to="991" />
			<date type="published" when="2003-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Unsupervised part-of-speech tagging with bilingual graph-based projections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="600" to="609" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Automatic extraction of named entity translingual equivalence based on multi-feature cost minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Vogel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Waibel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2003 Workshop on Multilingual and Mixed-language Named Entity Recognition</title>
		<meeting>the ACL 2003 Workshop on Multilingual and Mixed-language Named Entity Recognition</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003" />
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
	<note>MultiNER &apos;03</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Improved clustering techniques for class-based statistical language modelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reinhard</forename><surname>Knesser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eurospeech. ISCA-International Speech Communication Association</title>
		<meeting>Eurospeech. ISCA-International Speech Communication Association</meeting>
		<imprint>
			<date type="published" when="1993-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Statistical phrase-based translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz</forename><forename type="middle">Josef</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology</title>
		<meeting>the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="48" to="54" />
		</imprint>
	</monogr>
	<note>of NAACL &apos;03</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">D</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><forename type="middle">C N</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighteenth International Conference on Machine Learning, ICML &apos;01</title>
		<meeting>the Eighteenth International Conference on Machine Learning, ICML &apos;01<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="282" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Word-phrase-entity language models: Getting more mileage out of n-grams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Levit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarangarajan</forename><surname>Parthasarathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuangyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Stolcke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoit</forename><surname>Dumoulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech. ISCA-International Speech Communication Association</title>
		<meeting>Interspeech. ISCA-International Speech Communication Association</meeting>
		<imprint>
			<date type="published" when="2014-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning translations of named-entity phrases from parallel corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth Conference on European Chapter of the Association for Computational Linguistics</title>
		<meeting>the Tenth Conference on European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="259" to="266" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Efficient top-down BTG parsing for machine translation preordering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tetsuji</forename><surname>Nakagawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics, ACL 2015</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics, ACL 2015</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="208" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Crosslingual annotation projection of semantic roles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Padó</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="307" to="340" />
			<date type="published" when="2009-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Sequence-based class tagging for robust transcription in asr</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucy</forename><surname>Vasserman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vlad</forename><surname>Schogol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Hall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech. ISCA-International Speech Communication Association, September</title>
		<meeting>Interspeech. ISCA-International Speech Communication Association, September</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Inducing multilingual pos taggers and np bracketers via robust projection across aligned corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grace</forename><surname>Ngai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Meeting of the North American Chapter of the Association for Computational Linguistics on Language Technologies, NAACL &apos;01</title>
		<meeting>the Second Meeting of the North American Chapter of the Association for Computational Linguistics on Language Technologies, NAACL &apos;01</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Inducing multilingual text analysis tools via robust projection across aligned corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grace</forename><surname>Ngai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Wicentowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First International Conference on Human Language Technology Research, HLT &apos;01</title>
		<meeting>the First International Conference on Human Language Technology Research, HLT &apos;01</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
