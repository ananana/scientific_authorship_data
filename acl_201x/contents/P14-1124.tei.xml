<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:37+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Can You Repeat That? Using Word Repetition to Improve Spoken Term Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>June 23-25 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Wintrode</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Language and Speech Processing</orgName>
								<orgName type="institution">Johns Hopkins University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Khudanpur</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Language and Speech Processing</orgName>
								<orgName type="institution">Johns Hopkins University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Can You Repeat That? Using Word Repetition to Improve Spoken Term Detection</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1316" to="1325"/>
							<date type="published">June 23-25 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We aim to improve spoken term detection performance by incorporating con-textual information beyond traditional N-gram language models. Instead of taking a broad view of topic context in spoken documents , variability of word co-occurrence statistics across corpora leads us to focus instead the on phenomenon of word repetition within single documents. We show that given the detection of one instance of a term we are more likely to find additional instances of that term in the same document. We leverage this bursti-ness of keywords by taking the most confident keyword hypothesis in each document and interpolating with lower scoring hits. We then develop a principled approach to select interpolation weights using only the ASR training data. Using this re-weighting approach we demonstrate consistent improvement in the term detection performance across all five languages in the BABEL program.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The spoken term detection task arises as a key sub- task in applying NLP applications to spoken con- tent. Tasks like topic identification and named- entity detection require transforming a continu- ous acoustic signal into a stream of discrete to- kens which can then be handled by NLP and other statistical machine learning techniques. Given a small vocabulary of interest (1000-2000 words or multi-word terms) the aim of the term detection task is to enumerate occurrences of the keywords within a target corpus. Spoken term detection con- verts the raw acoustics into time-marked keyword occurrences, which may subsequently be fed (e.g. as a bag-of-terms) to standard NLP algorithms.</p><p>Although spoken term detection does not re- quire the use of word-based automatic speech recognition (ASR), it is closely related. If we had perfectly accurate ASR in the language of the corpus, term detection is reduced to an exact string matching task. The word error rate (WER) and term detection performance are clearly corre- lated. Given resource constraints, domain, chan- nel, and vocabulary limitations, particularly for languages other than English, the errorful token stream makes term detection a non-trivial task.</p><p>In order to improve detection performance, and restricting ourselves to an existing ASR system or systems at our disposal, we focus on leverag- ing broad document context around detection hy- potheses. ASR systems traditionally use N-gram language models to incorporate prior knowledge of word occurrence patterns into prediction of the next word in the token stream. N-gram mod- els cannot, however, capture complex linguistic or topical phenomena that occur outside the typical 3-5 word scope of the model. Yet, though many language models more sophisticated than N-grams have been proposed, N-grams are empirically hard to beat in terms of WER.</p><p>We consider term detection rather than the tran- scription task in considering how to exploit topic context, because in evaluating the retrieval of cer- tain key terms we need not focus on improving the entire word sequence. Confidence scores from an ASR system (which incorporate N-gram prob- abilities) are optimized in order to produce the most likely sequence of words rather than the ac- curacy of individual word detections. Looking at broader document context within a more limited task might allow us to escape the limits of N-gram performance. We will show that by focusing on contextual information in the form of word repe- tition within documents, we obtain consistent im- provement across five languages in the so called Base Phase of the IARPA BABEL program.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Task Overview</head><p>We evaluate term detection and word repetition- based re-scoring on the IARPA BABEL training and development corpora 1 for five languages Can- tonese, Pashto, Turkish, Tagalog and Vietnamese <ref type="bibr" target="#b8">(Harper, 2011)</ref>. The BABEL task is modeled on the 2006 NIST Spoken Term Detection evaluation <ref type="bibr" target="#b18">(NIST, 2006</ref>) but focuses on limited resource con- ditions. We focus specifically on the so called no target audio reuse (NTAR) condition to make our method broadly applicable.</p><p>In order to arrive at our eventual solution, we take the BABEL Tagalog corpus and analyze word co-occurrence and repetition statistics in detail. Our observation of the variability in co-occurrence statistics between Tagalog training and develop- ment partitions leads us to narrow the scope of document context to same word co-occurrences, i.e. word repetitions.</p><p>We then analyze the tendency towards within- document repetition. The strength of this phe- nomenon suggests it may be more viable for im- proving term-detection than, say, topic-sensitive language models. We validate this by develop- ing an interpolation formula to boost putative word repetitions in the search results, and then inves- tigate a method for setting interpolation weights without manually tuning on a development set.</p><p>We then demonstrate that the method general- izes well, by applying it to the 2006 English data and the remaining four 2013 BABEL languages. We demonstrate consistent improvements in all languages in both the Full LP (80 hours of ASR training data) and Limited LP (10 hours) settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Motivation</head><p>We seek a workable definition of broad docu- ment context beyond N-gram models that will im- prove term detection performance on an arbitrary set of queries. Given the rise of unsupervised la- tent topic modeling with Latent Dirchlet Alloca- tion ( <ref type="bibr" target="#b0">Blei et al., 2003</ref>) and similar latent variable approaches for discovering meaningful word co- occurrence patterns in large text corpora, we ought to be able to leverage these topic contexts instead of merely N-grams. Indeed there is work in the literature that shows that various topic models, la- tent or otherwise, can be useful for improving lan-guage model perplexity and word error rate <ref type="bibr" target="#b13">(Khudanpur and Wu, 1999;</ref><ref type="bibr" target="#b2">Chen, 2009;</ref><ref type="bibr" target="#b17">Naptali et al., 2012</ref>). However, given the preponderance of highly frequent non-content words in the compu- tation of a corpus' WER, it's not clear that a 1-2% improvement in WER would translate into an im- provement in term detection.</p><p>Still, intuition suggests that knowing the topic context of a detected word ought to be useful in predicting whether or not a term does belong in that context. For example, if we determine the context of the detection hypothesis is about computers, containing words like 'monitor,' 'in- ternet' and 'mouse,' then we would be more con- fident of a term such as 'keyboard' and less con- fident of a term such as 'cheese board'. The dif- ficulty in this approach arises from the variabil- ity in word co-occurrence statistics. Using topic information will be helpful if 'monitor,' 'key- board' and 'mouse' consistently predict that 'key- board' is present. Unfortunately, estimates of co- occurrence from small corpora are not very consis- tent, and often over-or underestimate concurrence probabilities needed for term detection.</p><p>We illustrate this variability by looking at how consistent word co-occurrences are between two separate corpora in the same language: i.e., if we observe words that frequently co-occur with a key- word in the training corpus, do they also co-occur with the keywords in a second held-out corpus? <ref type="figure" target="#fig_0">Figure 1</ref>, based on the BABEL Tagalog corpus, sug- gests this is true only for high frequency keywords. Tagalog keywords used for system development by all BABEL participants. For each keyword k, we count how often it co-occurs in the same con- versation as a vocabulary word w in the ASR training data and the development data, and des- ignate the counts T (k, w) and D(k, w) respec- tively. The x-coordinate of each point in <ref type="figure" target="#fig_0">Figure 1</ref> is the frequency of k in the training data, and the y-coordinate is the correlation coefficient ρ k be- tween T (k, w) and D(k, w). A high ρ k implies that words w that co-occur frequently with k in the training data also do so in the search collection.</p><p>To further illustrate how <ref type="figure" target="#fig_0">Figure 1</ref> was obtained, consider the high-frequency keyword bukas (count = 879) and the low-frequency keyword Davao (count = 11), and plot T (k, ·) versus D(k, ·), as done in <ref type="figure">Figure 2</ref>. The correlation coefficients ρ bukas and ρ Davao from the two plots end up as two points in <ref type="figure" target="#fig_0">Figure 1</ref>. <ref type="figure" target="#fig_0">Figure 1</ref> suggests that (k, w) co-occurrences are consistent between the two corpora (ρ k &gt; 0.8) for keywords occurring 100 or more times. However, if the goal is to help a speech retrieval system de- tect content-rich (and presumably infrequent) key- words, then using word co-occurrence informa- tion (i.e. topic context) does not appear to be too promising, even though intuition suggests that such information ought to be helpful.</p><p>In light of this finding, we will restrict the type of context we use for term detection to the co- occurrence of the term itself elsewhere within the document. As it turns out this 'burstiness' of words within documents, as the term is defined by Church and Gale in their work on <ref type="bibr">Poisson mixtures (1995)</ref>, provides a more reliable framework for successfully exploiting document context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Related Work</head><p>A number of efforts have been made to augment traditional N-gram models with latent topic infor- mation ( <ref type="bibr" target="#b13">Khudanpur and Wu, 1999;</ref><ref type="bibr" target="#b7">Florian and Yarowsky, 1999;</ref><ref type="bibr" target="#b16">Liu and Liu, 2008;</ref><ref type="bibr" target="#b10">Hsu and Glass, 2006;</ref><ref type="bibr" target="#b17">Naptali et al., 2012</ref>) including some of the early work on Probabilistic Latent Semantic Analysis by <ref type="bibr" target="#b9">Hofmann (2001)</ref>. In all of these cases WER gains in the 1-2% range were observed by interpolating latent topic information with N-gram models.</p><p>The re-scoring approach we present is closely related to adaptive or cache language models <ref type="bibr" target="#b11">(Jelinek, 1997;</ref><ref type="bibr" target="#b15">Kuhn and De Mori, 1990;</ref><ref type="bibr" target="#b14">Kneser and Steinbiss, 1993)</ref>. The primary difference between this and previous work on similar language mod- els is the narrower focus here on the term detec- tion task, in which we consider each search term in isolation, rather than all words in the vocabulary. Most recently, Chiu and Rudnicky (2013) looked at word bursts in the IARPA BABEL conversational corpora, and were also able to successfully im- prove performance by leveraging the burstiness of language. One advantage of the approach pro- posed here, relative to their approach, is its sim- plicity and its not requiring an additional tuning set to estimate parameters.</p><p>In the information retrieval community, cluster- ing and latent topic models have yielded improve- ments over traditional vector space models. We will discuss in detail in the following section re- lated works by <ref type="bibr" target="#b4">Church and Gale (1995</ref><ref type="bibr" target="#b6">, and 2000</ref>. Work by <ref type="bibr" target="#b20">Wei and Croft (2006)</ref>   information retrieval, and again, interpolate latent topic models with N-grams to improve retrieval performance. However, in many text retrieval tasks, queries are often tens or hundreds of words in length rather than short spoken phrases. In these efforts, the topic model information was helpful in boosting retrieval performance above the baseline vector space or N-gram models.</p><p>Clearly topic or context information is relevant to a retrieval type task, but we need a stable, con- sistent framework in which to apply it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Term and Document Frequency Statistics</head><p>To this point we have assumed an implicit property of low-frequency words which Church and Gale state concisely in their 1999 study of inverse doc- ument frequency:</p><p>Low frequency words tend to be rich in content, and vice versa. But not all equally frequent words are equally meaningful. Church and Gale (1999).</p><p>The typical use of Document Frequency (DF) in information retrieval or text categorization is to emphasize words that occur in only a few docu- ments and are thus more "rich in content". Close examination of DF statistics by Church and Gale in their work on Poisson <ref type="bibr">Mixtures (1995)</ref> resulted in an analysis of the burstiness of content words. In this section we look at DF and burstiness statistics applying some of the analyses of Church and Gale (1999) to the BABEL Tagalog corpus. We observe, in 648 Tagalog conversations, simi- lar phenomena as observed by Church and Gale on 89,000 AP English newswire articles. We proceed in this fashion to make a case for why burstiness ought to help in the term detection task.</p><p>For the Tagalog conversations, as with En- glish newswire, we observe that the document fre- quency, DF w , of a word w is not a linear function of word frequency f w in the log domain, as would be expected under a naive Poisson generative as- sumption. The implication of deviations from a Poisson model is that words tend to be concen- trated in a small number of documents rather than occurring uniformly across the corpus. This is the burstiness we leverage to improve term detection.</p><p>The first illustration of word burstiness can be seen by plotting observed inverse document fre- quency, IDF w , versus f w in the log domain <ref type="figure" target="#fig_2">(Fig- ure 3a)</ref>. We use the same definition of IDF w as Church and Gale (1999):</p><formula xml:id="formula_0">IDF w = − log 2 DF w N ,<label>(1)</label></formula><p>where N is the number of documents (i.e. conver- sations) in the corpus. There is good linear correlation (ρ = 0.73) be- tween log f w and IDF w . Yet, visually, the rela- tionship in <ref type="figure" target="#fig_2">Figure 3a</ref> is clearly not linear. In con- trast, the AP English data exhibits a correlation of ρ = 0.93 <ref type="bibr" target="#b5">(Church and Gale, 1999</ref>). Thus the devi- ation in the Tagalog corpus is more pronounced, i.e. words are less uniformly distributed across documents.</p><p>A second perspective on word burstiness that follows from <ref type="bibr" target="#b5">Church and Gale (1999)</ref> is that a Poisson assumption should lead us to predict:</p><formula xml:id="formula_1">IDF w = − log 2 1 − e − fw N .<label>(2)</label></formula><p>Figure 4: Difference between observed and pre- dicted IDF w for Tagalog unigrams.</p><p>For the AP newswire, Church and Gale found the largest deviation between the predicted IDF w and observed IDF w to occur in the middle of the fre- quency range. We see a somewhat different pic- ture for Tagalog speech in <ref type="figure" target="#fig_2">Figure 3b</ref>. Observed IDF w values again deviate significantly from their predictions (2), but all along the frequency range.</p><p>There is a noticeable quantization effect occur- ring in the high IDF range, given that our N is at least a factor of 100 smaller than the number of AP articles they studied: 648 vs. 89,000. <ref type="figure">Figure 4</ref> also shows the difference between and observed IDF w and Poisson estimate IDF w and further il- lustrates the high variance in IDF w for low fre- quency words.</p><p>Two questions arise: what is happening with in- frequent words, and why does this matter for term detection? To look at the data from a different perspective, we consider the random variable k, which is the number of times a word occurs in a particular document. In <ref type="figure" target="#fig_3">Figure 5</ref> we plot the fol- lowing ratio, which Church and Gale (1995) define as burstiness :</p><formula xml:id="formula_2">E w [k|k &gt; 0] = f w DF w (3)</formula><p>as a function of f w . We denote this as E <ref type="bibr">[k]</ref> and can interpret burstiness as the expected word count given we see w at least once. In <ref type="figure" target="#fig_3">Figure 5</ref> we see two classes of words emerge. A similar phenomenon is observed concerning adaptive language models <ref type="bibr" target="#b6">(Church, 2000</ref>). In general, we can think of using word repetitions to re-score term detection as applying a limited form of adaptive or cache language model <ref type="bibr" target="#b11">(Jelinek, 1997</ref>). Likewise, Katz attempts to capture For the first class, burstiness increases slowly but steadily as w occurs more frequently. Let us label these Class A words. Since our corpus size is fixed, we might expect this to occur, as more word occurrences must be pigeon-holed into the same number of documents Looking close to the y-axis in <ref type="figure" target="#fig_3">Figure 5</ref>, we ob- serve a second class of exclusively low frequency words whose burstiness ranges from highly con- centrated to singletons. We will refer to these as Class B words. If we take the Class A concentra- tion trend as typical, we can argue that most Class B words exhibit a larger than average concentra- tion. In either case we see evidence that both high and low frequency words tend towards repeating within a document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Unigram Probabilities</head><p>In applying the burstiness quantity to term detec- tion, we recall that the task requires us to locate a particular instance of a term, not estimate a count, hence the utility of N-gram language models pre- dicting words in sequence.</p><p>We encounter the burstiness property of words again by looking at unigram occurrence probabili- ties. We compare the unconditional unigram prob- ability (the probability that a given word token is w) with the conditional unigram probability, given the term has occurred once in the document. We compute the conditional probability for w using frequency information.  <ref type="figure" target="#fig_4">Figure 6</ref> shows the difference between con- ditional and unconditional unigram probabilities. Without any other information, Zipf's law sug- gests that most word types do not occur in a partic- ular document. However, conditioning on one oc- currence, most word types are more likely to occur again, due to their burstiness.</p><p>Finally we measure the adaptation of a word, which is defined by <ref type="bibr" target="#b4">Church and Gale (1995)</ref> as:</p><formula xml:id="formula_3">P adapt (w) = P w (k &gt; 1|k &gt; 0)<label>(5)</label></formula><p>When we plot adaptation versus f w <ref type="figure" target="#fig_5">(Figure 7</ref>) we see that all high-frequency and a significant number of low-frequency terms have adaptation greater that 50%. To be precise, 26% of all to- kens and 25% of low-frequency (f w &lt; 100) have at least 50% adaptation. Given that adaptation val- ues are roughly an order of magnitude higher than the conditional unigram probabilities, in the next two sections we describe how we use adaptation to boost term detection scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Term Detection Re-scoring</head><p>We summarize our re-scoring of repeated words with the observation: given a correct detection, the likelihood of additional terms in the same doc- uments should increase. When we observe a term detection score with high confidence, we boost the other lower-scoring terms in the same document to reflect this increased likelihood of repeated terms. For each term t and document d we propose in- terpolating the ASR confidence score for a partic- ular detection t d with the top scoring hit in d which we'll call t d .</p><formula xml:id="formula_4">S(t d ) = (1 − α)P asr (t d |O) + αP asr ( t d |O) (6)</formula><p>We will we develop a principled approach to se- lecting α using the adaptation property of the cor- pus. However to verify that this approach is worth pursuing, we sweep a range of small α values, on the assumption that we still do want to mostly rely on the ASR confidence score for term detection. For the Tagalog data, we let α range from 0 (the baseline) to 0.4 and re-score each term detection score according to <ref type="bibr">(6)</ref>. <ref type="table" target="#tab_0">Table 1</ref> shows the results of this parameter sweep and yields us 1 to 2% ab- solute performance gains in a number of term de- tection metrics.  The primary metric for the BABEL program, Ac- tual Term Weighted Value (ATWV) is defined by NIST using a cost function of the false alarm prob- ability P (FA) and P (Miss), averaged over a set of queries <ref type="bibr" target="#b18">(NIST, 2006</ref>). The manner in which the components of ATWV are defined:</p><formula xml:id="formula_5">P (Miss) = 1 − N true (term)/f term (7) P (FA) = N false /Duration corpus<label>(8)</label></formula><p>implies that cost of a miss is inversely proportional to the frequency of the term in the corpus, but the cost of a false alarm is fixed. For this reason, we report both ATWV and the P (Miss) component. A decrease in P (Miss) reflects the fact that we are able to boost correct detections of the repeated terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Interpolation Weights</head><p>We would prefer to use prior knowledge rather than naive tuning to select an interpolation weight α. Our analysis of word burstiness suggests that adaptation, is a reasonable candidate. Adaptation also has the desirable property that we can esti- mate it for each word in the training vocabulary directly from training data and not post-hoc on a per-query basis. We consider several different es- timates and we can show that the favorable result extends across languages. Intuition suggests that we prefer per-term in- terpolation weights related to the term's adapta- tion. But despite the strong evidence of the adapta- tion phenomenon in both high and low-frequency words <ref type="figure" target="#fig_5">(Figure 7)</ref>, we have less confidence in the adaptation strength of any particular word.</p><p>As with word co-occurrence, we consider if es- timates of P adapt (w) from training data are con- sistent when estimated on development data. <ref type="figure" target="#fig_7">Fig- ure 8</ref> shows the difference between P adapt (w) measured on the two corpora (for words occurring in both).</p><p>We see that the adaptation estimates are only consistent between corpora for high-frequency words. Using this P adapt (w) estimate directly ac- tually hurts ATWV performance by 4.7% absolute on the 355 term development query set ( <ref type="table" target="#tab_1">Table 2)</ref>.</p><p>Given the variability in estimating P adapt (w), an alternative approach would be take P w as an upper bound on α, reached as the DF w increases (cf. Equation 9). We would discount the adapta- tion factor when DF w is low and we are unsure of  </p><formula xml:id="formula_6">α w = (1 − e −DFw ) · P adapt (w) (9)</formula><p>This approach shows a significant improvement (0.7% absolute) over the baseline. However, con- sidering this estimate in light of the two classes of words in <ref type="figure" target="#fig_3">Figure 5</ref>, there are clearly words in Class B with high burstiness that will be ignored by try- ing to compensate for the high adaptation variabil- ity in the low-frequency range.</p><p>Alternatively, we take a weighted average of α w 's estimated on training transcripts to obtain a single α per language (cf. Equation 10).</p><formula xml:id="formula_7">α = Avg w 1 − e −DFw · P adapt (w)<label>(10)</label></formula><p>Using this average as a single interpolation weight for all terms gives near the best performance as we observed in our parameter sweep. <ref type="table" target="#tab_1">Table 2</ref> contrasts the results for using the three different interpolation heuristics on the Tagalog develop- ment queries. Using the mean α instead of indi- vidual α w 's provides an additional 0.5% absolute  </p><formula xml:id="formula_8">Language α ATWV (%±) P (Miss) (%±)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>Now that we have tested word repetition-based re-scoring on a small Tagalog development set we want to know if our approach, and particu- larly our α estimate is sufficiently robust to apply broadly. At our disposal, we have the five BABEL languages -Tagalog, Cantonese, Pashto, Turk- ish and Vietnamese -as well as the development data from the NIST 2006 English evaluation. The BABEL evaluation query sets contain roughly 2000 terms each and the 2006 English query set con- tains roughly 1000 terms.</p><p>The procedure we follow for each language condition is as follows. We first estimate adap- tation probabilities from the ASR training tran- scripts. From these we take the weighted aver- age as described previously to obtain a single in- terpolation weight α for each training condition. We train ASR acoustic and language models from the training corpus using the Kaldi speech recog- nition toolkit <ref type="bibr" target="#b19">(Povey et al., 2011</ref>) following the default BABEL training and search recipe which is described in detail by <ref type="bibr" target="#b1">Chen et al. (2013)</ref>. Lastly, we re-score the search output by interpolating the top term detection score for a document with sub- sequent hits according to Equation 6 using the α estimated for this training condition.</p><p>For each of the BABEL languages we consider both the FullLP (80 hours) and LimitedLP (10 hours) training conditions. For the English sys- tem, we also train a Kaldi system on the 240 hours of the Switchboard conversational English cor- pus. Although Kaldi can produce multiple types of acoustic models, for simplicity we report results using discriminatively trained Subspace Gaussian Mixture Model (SGMM) acoustic output densi- ties, but we do find that similar results can be ob- tained with other acoustic model configurations.</p><p>Using our final algorithm, we are able to boost repeated term detections and improve results in all languages and training conditions. <ref type="table" target="#tab_2">Table 3</ref> lists complete results and the associated estimates for α. For the BABEL languages, we observe improve- ments in ATWV from 0.7% to 1.3% absolute and reductions in the miss rate of 0.8% to 1.9%. The only test for which P (Miss) did not improve was the Vietnamese Limited LP setting, although over- all ATWV did improve, reflecting a lower P (FA).</p><p>In all conditions we also obtain α estimates which correspond to our expectations for partic- ular languages. For example, adaptation is low- est for the agglutinative Turkish language where longer word tokens should be less likely to re- peat. For Vietnamese, with shorter, syllable length word tokens, we observe the lowest adaptation es- timates.</p><p>Lastly, the reductions in P (Miss) suggests that we are improving the term detection metric, which is sensitive to threshold changes, by doing what we set out to do, which is to boost lower confi- dence repeated words and correctly asserting them as true hits. Moreover, we are able to accomplish this in a wide variety of languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>Leveraging the burstiness of content words, we have developed a simple technique to consis- tently boost term detection performance across languages. Using word repetitions, we effectively use a broad document context outside of the typi- cal 2-5 N-gram window. Furthermore, we see im- provements across a broad spectrum of languages: languages with syllable-based word tokens (Viet- namese, Cantonese), complex morphology (Turk- ish), and dialect variability (Pashto).</p><p>Secondly, our results are not only effective but also intuitive, given that the interpolation weight parameter matches our expectations for the bursti- ness of the word tokens in the language on which it is estimated.</p><p>We have focused primarily on re-scoring results for the term detection task. Given the effective- ness of the technique across multiple languages, we hope to extend our effort to exploit our hu- man tendency towards redundancy to decoding or other aspects of the spoken document processing pipeline.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Correlation between the co-occurrence counts in the training and held-out sets for a fixed keyword (term) and all its "context" words.</figDesc><graphic url="image-1.png" coords="2,329.10,512.44,174.61,174.61" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>and Chen (2009) take a language model-based approach to (a) fw versus IDFw ' (b) Obsered versus predicted IDFw</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Tagalog corpus frequency statistics, unigrams</figDesc><graphic url="image-4.png" coords="4,93.32,62.80,153.07,153.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Tagalog burstiness.</figDesc><graphic url="image-7.png" coords="5,329.10,62.81,174.61,174.61" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Difference between conditional and unconditional unigram probabilities for Tagalog</figDesc><graphic url="image-8.png" coords="6,93.83,62.81,174.61,174.61" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Tagalog word adaptation probability</figDesc><graphic url="image-9.png" coords="6,329.10,62.81,174.61,174.61" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Difference in adaptation estimates between Tagalog training and development corpora Interpolation Weight ATWV P (Miss) None 0.470 0.430 P adapt (w) 0.423 0.474 (1 − e −DFw )P adapt (w) 0.477 0.415 α = 0.20 0.483 0.416</figDesc><graphic url="image-10.png" coords="7,329.10,62.81,174.61,174.61" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Term detection scores for swept α values 
on Tagalog development data </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Term detection performance using vari-
ous interpolation weight strategies on Tagalog dev 
data 

the effect. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Word-repetition re-scored results for available CTS term detection corpora 

improvement, suggesting that we find additional 
gains boosting low-frequency words. 

</table></figure>

			<note place="foot" n="1"> Language collection releases IARPA-babel101-v0.4c, IARPA-babel104b-v0.4bY, IARPA-babel105b-v0.4, IARPAbabel106-v0.2g and IARPA-babel107b-v0.7 respectively.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was partially supported by the In-telligence Advanced Research Projects Activity (IARPA) via Department of Defense U.S. Army Research Laboratory (DoD / ARL) contract num-ber W911NF-12-C-0015. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation thereon. Disclaimer: The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of IARPA, DoD/ARL, or the U.S. Government.</p><p>Insightful discussions with Chiu and Rudnicky (2013) are also gratefully acknowledged.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Latent Dirichlet Allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Quantifying the value of pronunciation lexicons for keyword search in low resource languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoguo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Khudanpur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Povey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Trmal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oguz</forename><surname>Yilmaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Latent topic modelling of word co-occurence information for spoken document retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Berlin Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<meeting>the International Conference on Acoustics, Speech and Signal Processing (ICASSP)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="3961" to="3964" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Using conversational word bursts in spoken term detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Rudnicky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Annual Conference of the International Speech Communication Association</title>
		<meeting>the 14th Annual Conference of the International Speech Communication Association</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2247" to="2251" />
		</imprint>
	</monogr>
	<note>ISCA</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Poisson Mixtures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Church</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Gale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="163" to="190" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Inverse Focument Frequency (IDF): A measure of deviations from Poisson</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Church</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Gale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Natural Language Processing Using Very Large Corpora</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="283" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Empirical estimates of adaptation: the chance of two Noriegas is closer to p/2 than p 2</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Church</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th Conference on Computational Linguistics</title>
		<meeting>the 18th Conference on Computational Linguistics</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2000" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="180" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Dynamic nonlocal language modeling via hierarchical topicbased adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Florian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th annual meeting of the Association for Computational Linguistics</title>
		<meeting>the 37th annual meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="167" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">IARPA Solicitation IARPABAA-11-02</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><surname>Harper</surname></persName>
		</author>
		<ptr target="http://www.iarpa.gov/solicitations_babel.html" />
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Unsupervised learning by probabilistic latent semantic analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="177" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Style &amp; topic language model adaptation using HMM-LDA</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo-June Paul</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Glass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing. ACL</title>
		<meeting>the 2006 Conference on Empirical Methods in Natural Language Processing. ACL</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Statistical Methods for Speech Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fred</forename><surname>Jelinek</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Distribution of content words and phrases in text and language modelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slava</forename><surname>Katz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="15" to="59" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A maximum entropy language model integrating n-grams and topic dependencies for conversational speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Khudanpur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</title>
		<meeting>the International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1999" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="553" to="556" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">On the dynamic adaptation of stochastic language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reinhard</forename><surname>Kneser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volker</forename><surname>Steinbiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Acoustics, Speech, and Signal Processing</title>
		<meeting>the International Conference on Acoustics, Speech, and Signal Processing</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1993" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="586" to="589" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A cachebased natural language model for speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Kuhn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renato</forename><forename type="middle">De</forename><surname>Mori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="570" to="583" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Unsupervised language model adaptation via topic modeling based on named entity hypotheses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feifan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Acoustics, Speech and Signal Processing</title>
		<meeting>the International Conference on Acoustics, Speech and Signal Processing</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="4921" to="4924" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Topic-dependent-class-based n-gram language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Welly</forename><surname>Naptali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masatoshi</forename><surname>Tsuchiya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seiichi</forename><surname>Nakagawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on Audio, Speech, and Language Processing</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1513" to="1525" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">The Spoken Term Detection (STD)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nist</forename></persName>
		</author>
		<ptr target="http://www.itl.nist.gov/iad/mig/tests/std/2006/docs/std06-evalplan-v10.pdf" />
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note>Evaluation Plan</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The Kaldi speech recognition toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Povey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnab</forename><surname>Ghoshal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gilles</forename><surname>Boulianne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Burget</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Glembek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nagendra</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirko</forename><surname>Hannemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petr</forename><surname>Motlicek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanmin</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petr</forename><surname>Schwarz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Automatic Speech Recognition and Understanding Workshop (ASRU)</title>
		<meeting>the Automatic Speech Recognition and Understanding Workshop (ASRU)</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">LDA-based document models for ad-hoc retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="178" to="185" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
