<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:06+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Understanding and Detecting Diverse Supporting Arguments on Controversial Issues</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Hua</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Wang</surname></persName>
						</author>
						<title level="a" type="main">Understanding and Detecting Diverse Supporting Arguments on Controversial Issues</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</title>
						<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="203" to="208"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-2032</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We investigate the problem of sentence-level supporting argument detection from relevant documents for user-specified claims. A dataset containing claims and associated citation articles is collected from online debate web-site idebate.org. We then manually label sentence-level supporting arguments from the documents along with their types as STUDY, FACTUAL, OPINION, or REASONING. We further characterize arguments of different types, and explore whether leveraging type information can facilitate the supporting arguments detection task. Experimental results show that LambdaMART (Burges, 2010) ranker that uses features informed by argument types yields better performance than the same ranker trained without type information.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Argumentation plays a crucial role in persuasion and decision-making processes. An argument usu- ally consists of a central claim (or conclusion) and several supporting premises. Constructing argu- ments of high quality would require the inclusion of diverse information, such as factual evidence and solid reasoning ( <ref type="bibr">Rieke et al., 1997;</ref><ref type="bibr" target="#b14">Park and Cardie, 2014</ref>). For instance, as shown in <ref type="figure" target="#fig_1">Figure 1</ref>, the editor on idebate.org -a Wikipedia-style website for gathering pro and con arguments on controversial issues, utilizes arguments based on study, factual evidence, and expert opinion to sup- port the anti-gun claim "legally owned guns are frequently stolen and used by criminals". How- ever, it would require substantial human effort to collect information from diverse resources to sup- port argument construction. In order to facilitate this process, there is a pressing need for tools that can automatically detect supporting arguments.</p><p>To date, most of the argument mining research focuses on recognizing argumentative components -A June 2013 IOM report states that "almost all guns used in criminal acts enter circulation via initial legal transaction".</p><p>[study] -Between 2005 and 2010, 1.4 million guns were stolen from US homes during property crimes (in- cluding bulglary and car theft), a yearly average of 232,400.</p><p>[factual] -Ian Ayres, JD, PhD, . . . states, "with guns being a product that can be easily carried away and quickly sold at a relatively high fraction of the initial cost, the presence of more guns can actually serve as a stimu- lus to burglary and theft."  and their structures from constructed arguments based on curated corpus ( <ref type="bibr" target="#b9">Mochales and Moens, 2011;</ref><ref type="bibr">Stab and Gurevych, 2014;</ref><ref type="bibr" target="#b6">Feng and Hirst, 2011;</ref><ref type="bibr" target="#b7">Habernal and Gurevych, 2015;</ref><ref type="bibr" target="#b11">Nguyen and Litman, 2016)</ref>. Limited work has been done for retrieving supporting arguments from external re- sources. Initial effort by <ref type="bibr">Rinott et al. (2015)</ref> inves- tigates the detection of relevant factual evidence from Wikipedia articles. However, it is unclear whether their method can perform well on docu- ments of different genres (e.g. news articles vs. blogs) for detecting distinct types of supporting in- formation.</p><p>In this work, we present a novel study on the task of sentence-level supporting argument detec- tion from relevant documents for a user-specified claim. Take <ref type="figure" target="#fig_2">Figure 2</ref> as an example: assume we are given a claim on the topic of "banning cos- metic surgery" and a relevant article (cited for argument construction), we aim to automatically pinpoint the sentence(s) (in italics) among all sen- tences in the cited article that can be used to back up the claim. We define such tasks as supporting argument detection. Furthermore, another goal of -Topic: This house would ban cosmetic surgery -Claim: An outright ban would be easier than the partial bans that have been enacted in some places. -Human Constructed Argument: . . .This poten- tially leaves difficulty drawing the line for what is al- lowed. <ref type="bibr">[1]</ref> . . . Citation Article <ref type="bibr">[1]</ref>: "Australian State Ban Cosmetic Surgery for Teens" -. . . It is unfortunate that a parent would consider let- ting a 16-year-old daughter have a breast augmenta- tion." -But others worry that similar legislation, if it ever comes to pass in the United States, would draw a largely arbitrary line -and could needlessly restrict some teens from procedures that would help their self- esteem. -Dr. Malcolm Z. Roth, director of plastic surgery at Maimondes Medical Center in Brooklyn, N.Y. , said he believes that some teens are intelligent and mature enough to comprehend the risks and benefits of cos- metic surgery.. . . this work is to understand and characterize differ- ent types of supporting arguments. Indeed, hu- man editors do use different types of information to promote persuasiveness as we will show in Sec- tion 3. Prediction performance also varies among different types of supporting arguments.</p><p>Given that none of the existing datasets is suit- able for our study, we collect and annotate a cor- pus from Idebate, which contains hundreds of de- bate topics and corresponding claims. 1 As is shown in <ref type="figure" target="#fig_2">Figure 2</ref>, each claim is supported with some human constructed argument, with cited ar- ticles marked on sentence level. After careful in- spection on the supporting arguments, we propose to label them as STUDY, FACTUAL, OPINION, or REASONING. Substantial inter-annotator agree- ment rate is achieved for both supporting argu- ment labeling (with Cohen's κ of 0.8) and argu- ment type annotation, on 200 topics with 621 ref- erence articles.</p><p>Based on the new corpus, we first carry out a study on characterizing arguments of different types via type prediction. We find that arguments <ref type="bibr">1</ref> The labeled dataset along with the annotation guideline will be released at xyhua.me.</p><p>of STUDY and FACTUAL tend to use more con- crete words, while arguments of OPINION contain more named entities of person names. We then in- vestigate whether argument type can be leveraged to assist supporting argument detection. Experi- mental results based on LambdaMART <ref type="bibr" target="#b3">(Burges, 2010)</ref> show that utilizing features composite with argument types achieves a Mean Reciprocal Rank (MRR) score of 57.65, which outperforms an un- supervised baseline and the same ranker trained without type information. Feature analysis also demonstrates that salient features have signifi- cantly different distribution over different argu- ment types.</p><p>For the rest of the paper, we summarize related work in Section 2. The data collection and anno- tation process is described in Section 3, which is followed by argument type study (Section 4). Ex- periment on supporting argument detection is pre- sented in Section 5. We finally conclude in Sec- tion 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Our work is in line with argumentation min- ing, which has recently attracted significant re- search interest. Existing work focuses on argu- ment extraction from news articles, legal docu- ments, or online comments without given user- specified claim <ref type="bibr" target="#b10">(Moens et al., 2007;</ref><ref type="bibr" target="#b12">Palau and Moens, 2009;</ref><ref type="bibr" target="#b9">Mochales and Moens, 2011;</ref><ref type="bibr" target="#b14">Park and Cardie, 2014</ref>). Argument scheme classifi- cation is also widely studied <ref type="bibr" target="#b1">(Biran and Rambow, 2011;</ref><ref type="bibr" target="#b6">Feng and Hirst, 2011;</ref><ref type="bibr">Rooney et al., 2012;</ref><ref type="bibr">Stab and Gurevych, 2014;</ref><ref type="bibr" target="#b0">Al Khatib et al., 2016)</ref>, which emphasizes on distinguishing differ- ent types of arguments. To the best of our knowl- edge, none of them studies the interaction between types of arguments and their usage to support a user-specified claim. This is the gap we aim to fill.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data and Annotation</head><p>We rely on data from idebate.org, where hu- man editors construct paragraphs of arguments, ei- ther supporting or opposing claims under contro- versial topics. We also extract textual citation arti- cles as source of information used by editors dur- ing argument construction. In total we collected 383 unique debates, out of which 200 debates are randomly selected for study. After removing in- valid ones, our final dataset includes 450 claims 204 STUDY: Results and discoveries, usually quantita- tive, as a result of some research investment. FACTUAL: Description of some occurred events or facts, or chapters in law or declaration. OPINION: Quotes from some person or group, ei- ther direct or indirect. It usually contains subjective, judgemental and evaluative languages, and might re- flect the position or stance of some entity. REASONING: Logical structures. It usually can be further broken down into causal or conditional sub- structures. and 621 citation articles with about 53,000 sen- tences. Annotation Process. As shown in <ref type="figure" target="#fig_2">Figure 2</ref>, we first annotate which sentence(s) from a citation articles is used by the editor as supporting argu- ments. Then we annotate the type for each of them as STUDY, FACTUAL, OPINION, or REASONING, based on the scheme in <ref type="table" target="#tab_0">Table 1</ref>. <ref type="bibr">2</ref> For instance, the highlighted supporting argument in <ref type="figure" target="#fig_2">Figure 2</ref> is la- beled as REASONING.</p><p>Two experienced annotators were hired to iden- tify supporting arguments by reading through the whole cited article and locating the sentences that best match the reference human constructed argu- ment. This task is rather complicated since hu- man do not just repeat or directly quote the origi- nal sentences from citation articles, they also para- phrase, summarize, and generalize. For instance, the original sentence is "The global counterfeit drug trade, a billion-dollar industry, is thriving in Africa", which is paraphrased to "This is exploited by the billion dollar global counterfeit drug trade" in human constructed argument.</p><p>The annotators were asked to annotate indepen- dently, then discuss and resolve disagreements and give feedback about current scheme. We compute inter-annotator agreement based on Cohen's κ for both supporting arguments labeling and argument type annotation. For supporting arguments we have a high degree of consensus, with Cohen's κ ranges from 0.76 to 0.83 in all rounds and 0.80 overall. For argument type annotation, we achieve Cohen's κ of 0. <ref type="bibr">61</ref>  We further analyze the source of the supporting arguments. Domain names of the citation articles are collected based on their URL, and then cat- egorized into "news", "organization", "scientific", "blog", "reference", and others, according to a tax- onomy provided by Alexa 4 with a few edits to fit our dataset. News articles are the major source for all types, which account for roughly 50% for each. We show the distribution of other four types in <ref type="figure">Figure 3</ref>. Arguments of STUDY and REASON- ING are mostly from "scientific" websites (14.9% and 22.9%), whereas "organization" websites con- tribute a large portion of arguments of FACTUAL (18.5%) and OPINION (16.7%).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">A Study On Argument Type Prediction</head><p>Here we characterize arguments of different types based on diverse features under the task of predict- ing argument types. Supporting arguments identi- fied from previous section are utilized for experi- ments. We also leverage the learned classifier in this section to label the sentences that are not sup- porting arguments, which will be used for support- ing argument detection in the next section. Four major types of features are considered.  number of seven types of named entities <ref type="bibr" target="#b5">(Chinchor and Robinson, 1997)</ref>. Sentiment Features. We also compute number of positive, negative and neutral words in MPQA lexicon ( <ref type="bibr">Wilson et al., 2005)</ref>, and number of words from a subset of semantic categories from General Inquirer ( <ref type="bibr">Stone et al., 1966)</ref>. <ref type="bibr">5</ref> Discourse Features. We use the number of dis- course connectives from the top two levels of Penn Discourse Tree Bank ( <ref type="bibr">Prasad et al., 2007)</ref>. Style Features. We measure word attributes for their concreteness (perceptible vs. conceptual), valence (or pleasantness), arousal (or intensity of emotion), and dominance (or degree of control) based on the lexicons collected by <ref type="bibr" target="#b2">Brysbaert et al. (2014)</ref> and <ref type="bibr">Warriner et al. (2013)</ref>.</p><p>We utilize Log-linear model for argument type prediction with one-vs-rest setup. Three baselines are considered: (1) random guess, (2) majority class, and (3) unigrams and bigrams as features for Log-linear model. Identified supporting argu- ments are used for experiments, and divided into training set (50%), validation set (25%) and test set (25%). From <ref type="table" target="#tab_3">Table 2</ref>, we can see that Log- linear model trained with all features outperforms the ones trained with ngram features. To further characterize arguments of different types, we dis- play sample features with significant different val- ues in <ref type="figure" target="#fig_3">Figure 4</ref>. As can be seen, arguments of STUDY and FACTUAL tend to contain more con- crete words and named entities. Arguments of OPINION mention more person names, which im- plies that expert opinions are commonly quoted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Supporting Argument Detection</head><p>We cast the sentence-level supporting argument detection problem as a ranking task. <ref type="bibr">6</ref> Features <ref type="bibr">5</ref> Categories used: Strong, Weak, Virtue, Vice, Ovrst (Overstated), Undrst (Understated), Academ (Academic), Doctrin (Doctrine), Econ (Economic), Relig (Religious), Causal, Ought, and Perceiv (Perception). <ref type="bibr">6</ref> Many sentences in the citation article is relevant to the topic to various degrees. We focus on detecting the most rel- evant ones, and thus treat it as a ranking problem instead of a  in Section 4 are also utilized here as "Sentence features" with additional features considering the sentence position in the article. We further employ features that measure similarity between claims and sentences, and the composite features that leverage argument type information.</p><p>Similarity Features. We compute similarity be- tween claim and candidate sentence based on TF- IDF and average word embeddings. We also con- sider ROUGE <ref type="bibr" target="#b8">(Lin, 2004</ref>), a recall oriented met- ric for summarization evaluation. In particular, ROUGE-L, a variation based on longest common subsequence, is computed by treating claim as reference and each candidate sentence as sample summary. In similar manner we use BLEU <ref type="bibr" target="#b13">(Papineni et al., 2002</ref>), a precision oriented metric.   We choose LambdaMART (Burges, 2010) for experiments, which is shown to be successful for many text ranking problems ( <ref type="bibr" target="#b4">Chapelle and Chang, 2011)</ref>. Our model is evaluated by Mean Recipro- cal Rank (MRR) and Normalized Discounted Cu- mulative Gain (NDCG) using 5-fold cross valida- tion. We compare to TFIDF and Word embedding similarity baselines, and LambdaMART trained with ngrams (unigrams and bigrams).</p><p>Results in <ref type="table" target="#tab_6">Table 3</ref> show that using com- posite features with argument type information (Comp(type, Sen) + Comp(type, Simi)) can im- prove the ranking performance. Specifically, the best performance is achieved by adding composite features to sentence features, similarity features, and ngram features. As can be seen, supervised methods outperform unsupervised baseline meth- ods. And similarity features have similar perfor- mance as those baselines. The best performance is achieved by combination of sentence features, N- grams, similarity, and two composite types, which is boldfaced. Feature sets that significantly outper- form all three baselines are marked with * .</p><p>For feature analysis, we conduct t-test for in- dividual feature values between supporting argu- ments and the others. We breakdown features according to their argument types and show top salient composite features in <ref type="table" target="#tab_8">Table 4</ref>. For all sen- tences of type STUDY, relevant ones tend to con- tain more "percentage" and more concrete words. We also notice those sentences with more hedging words are more likely to be considered. For sen- tences of FACTUAL, position of sentence in article  composition with different types. The number of * stands for the p-value based on t-test between support- ing argument sentences and the others after Bonferroni correction. From one * to four, the p-value scales as: 0.05, 1e-3, 1e-5, and 1e-10. When mean value of sup- porting argument sentences is larger, ↑ is used; other- wise, ↓ is displayed. Number of arrows represents the ratio of the larger value over smaller one. "-" indicates no significant difference.</p><formula xml:id="formula_0">Feature STUDY FACTUAL OPINION REASONING # PERC, NE * * ↑↑↑↑ - - - # LOC, NE - * * ↑↑ - * * ↑ position of sentence * * ↓↓ * * * * ↓↓ - * * * *</formula><p>plays an important role, as well as their similarity to the claim based on ROUGE scores. For type OPINION, unlike all other types, position of sen- tence seems to be insignificant. As we could imag- ine, opinionated information might scatter around the whole documents. For sentences of REASON- ING, the ones that can be used as supporting argu- ments tend to be less concrete and less emotional, as opposed to opinion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We presented a novel study on the task of sentence-level supporting argument detection from relevant documents for a user-specified claim. Based on our newly-collected dataset, we characterized arguments of different types with a rich feature set. We also showed that leveraging argument type information can further improve the performance of supporting argument detection.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>[expert opinion]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Three different types of arguments used to support the claim "Legally owned guns are frequently stolen and used by criminals".</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: A typical debate motion consists of a Topic, Claims, and Human Constructed Arguments. Citation article is marked at the end of sentence. Our goal is to find out supporting argument (in italics) from citation article that can back up the given claim.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Average features values for different argument types. Numbers in boldface are significantly higher than the others based on paired t-test (p &lt; 0.05).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Composite Features.</head><label></label><figDesc>We adopt composite fea- tures to study the interaction of other features with type of the sentence. Given claim c and sentence s with any feature mentioned above, a composite feature function φ M (type, feature) (s, c) is set to the actual feature value if and only if the argument type matches. For instance, if the ROUGE-L score is 0.2, and s is of type STUDY, then φ M (study, ROUGE) (s, c) = 0.2 φ M (factual, ROUGE) (s, c), φ M (opinion, ROUGE) (s, c), φ M (reasoning, ROUGE) (s, c) are all set to 0. binary classification task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Annotation scheme for our dataset. Due to 

space limit, we do not show detailed explanations and 
examples. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head></head><label></label><figDesc>Basic Features. We calculate frequencies of un- igram and bigram words, number of four major types of part-of-speech tags (verb, noun, adjective, and adverb), number of dependency relations, and</figDesc><table>in a low agreement for REASONING. 
4 http://www.alexa.com/topsites/category Acc 

F1 
Majority class 
0.520 0.171 
Random 
0.240 0.199 
Log-linear (ngrams) 
0.535 0.277 
Log-linear (all features) 0.622 0.436 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 : Results for argument type prediction. One-</head><label>2</label><figDesc></figDesc><table>vs-rest classifiers are learned for Log-linear models. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Supporting argument detection results. 

Comp(type, Sen) stands for composite features of 
argument type and sentence features, similarly for 
Comp(type,Simi). Comp(type,Claim) represents com-
posite features of type and claim features. Results that 
are statistically significantly better than all three base-
lines are marked with  *  (paired t-test, p &lt; 0.05). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 4 : Comparison of feature significance under</head><label>4</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="2"> We end up with the four-type scheme as a trade-off between complexity and its coverage of the arguments. 3 Many times annotators have different interpretation on REASONING, and frequently label it as OPINION. This results</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported in part by National Sci-ence Foundation Grant IIS-1566382 and a GPU gift from Nvidia. We thank Kechen Qin for his help on data collection. We also appreciate the valuable suggestions on various aspects of this work from three anonymous reviewers.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A news editorial corpus for mining argumentation strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Al</forename><surname>Khalid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henning</forename><surname>Khatib</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Kiesel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benno</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers</title>
		<meeting>COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers<address><addrLine>Osaka, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3433" to="3443" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Identifying justifications in written dialogs by classifying text as argumentative</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Or</forename><surname>Biran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Owen</forename><surname>Rambow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Semantic Computing</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">04</biblScope>
			<biblScope unit="page" from="363" to="381" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Concreteness ratings for 40 thousand generally known english word lemmas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Brysbaert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><forename type="middle">Beth</forename><surname>Warriner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Kuperman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior research methods</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="904" to="911" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">From ranknet to lambdarank to lambdamart: An overview</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Burges</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Learning</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">81</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Yahoo! learning to rank challenge overview</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Yahoo! Learning to Rank Challenge</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Muc7 named entity task definition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nancy</forename><surname>Chinchor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patricia</forename><surname>Robinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Conference on Message Understanding</title>
		<meeting>the 7th Conference on Message Understanding</meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Classifying arguments by scheme</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Vanessa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graeme</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hirst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="987" to="996" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Exploiting debate portals for semi-supervised argumentation mining in user-generated web discourse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Habernal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, Lisbon, Portugal</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, Lisbon, Portugal</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2127" to="2137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Rouge: A package for automatic evaluation of summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text summarization branches out: Proceedings of the ACL-04 workshop</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Argumentation mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Mochales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence and Law</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Automatic detection of arguments in legal texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Boiy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th international conference on Artificial intelligence and law</title>
		<meeting>the 11th international conference on Artificial intelligence and law</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="225" to="230" />
		</imprint>
	</monogr>
	<note>Raquel Mochales Palau, and Chris Reed</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Context-aware argumentative relation mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huy</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><surname>Litman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1127" to="1137" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Argumentation mining: the detection, classification and structure of arguments in text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><forename type="middle">Mochales</forename><surname>Palau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th international conference on artificial intelligence and law</title>
		<meeting>the 12th international conference on artificial intelligence and law</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="98" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th annual meeting on association for computational linguistics</title>
		<meeting>the 40th annual meeting on association for computational linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Identifying appropriate support for propositions in online user comments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joonsuk</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Argumentation Mining</title>
		<meeting>the First Workshop on Argumentation Mining</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="29" to="38" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
