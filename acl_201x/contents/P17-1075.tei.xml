<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:36+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Evaluation Metrics for Machine Reading Comprehension: Prerequisite Skills and Readability</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saku</forename><surname>Sugawara</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuke</forename><surname>Kido</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hikaru</forename><surname>Yokono</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akiko</forename><surname>Aizawa</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">The University of Tokyo</orgName>
								<address>
									<addrLine>7-3-1 Hongo, Bunkyo-ku</addrLine>
									<settlement>Tokyo</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Evaluation Metrics for Machine Reading Comprehension: Prerequisite Skills and Readability</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</title>
						<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="806" to="817"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-1075</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Knowing the quality of reading comprehension (RC) datasets is important for the development of natural-language understanding systems. In this study, two classes of metrics were adopted for evaluating RC datasets: prerequisite skills and readability. We applied these classes to six existing datasets, including MCTest and SQuAD, and highlighted the characteristics of the datasets according to each metric and the correlation between the two classes. Our dataset analysis suggests that the readability of RC datasets does not directly affect the question difficulty and that it is possible to create an RC dataset that is easy to read but difficult to answer.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A major goal of natural language processing (NLP) is to develop agents that can understand natural language. Such an ability can be tested with a reading comprehension (RC) task that re- quires the agent to read open-domain documents and answer questions about them. Constructing systems with RC competence is challenging be- cause RC comprises multiple processes includ- ing parsing, understanding cohesion, and infer- ence with linguistic and general knowledge.</p><p>Clarifying what a system achieves is important in the development of RC systems. To achieve robust improvement, systems should be measured according to a variety of metrics beyond simple accuracy. However, a current problem is that most RC datasets are presented only with superfi- cial categories, such as question types (e.g., what, where, and who) and answer types (e.g., numeric, location, and person). In addition, <ref type="bibr" target="#b3">Chen et al. (2016)</ref> noted that some questions in datasets may not be suited to the testing of RC systems. In such ID: SQuAD, United Methodist Church Context: The United Methodist Church (UMC) prac- tices infant and adult baptism. Baptized Members are those who have been baptized as an infant or child, but who have not subsequently professed their own faith. Question: What are members who have been baptized as an infant or child but who have not subsequently pro- fessed their own faith? Answer: Baptized Members ID: MCTest, mc160.dev.8 Context: Sara wanted to play on a baseball team. She had never tried to swing a bat and hit a baseball before. Her Dad gave her a bat and together they went to the park to practice. Question: Why was Sara practicing? Answer: She wanted to play on a team situations, it is difficult to obtain an accurate as- sessment of the RC system. <ref type="bibr" target="#b18">Norvig (1989)</ref> argued that questions that are easy for humans to answer often turn out to be difficult for machines. For example, consider the two RC questions in <ref type="figure" target="#fig_0">Figure 1</ref>. The first example is from SQuAD ( <ref type="bibr" target="#b23">Rajpurkar et al., 2016</ref>), although the document is taken from a Wikipedia article and was therefore written for adults. The question is answerable simply by noticing one sentence, with- out needing to fully understand the content of the text. On the other hand, consider the second exam- ple from MCTest ( <ref type="bibr" target="#b25">Richardson et al., 2013)</ref>, which was written for children and is easy to read. Here, answering the question involves gathering infor- mation from multiple sentences and utilizing a combination of several skills, such as understand- ing causal relations (Sara wanted... → they went to...), coreference resolution (Sara and Her Dad = they), and complementing ellipsis (baseball team = team). These two examples show that the read- ability of the text does not necessarily correlate with the difficulty of answering questions about it. Furthermore, the accompanying categories of ex- isting RC datasets cannot help with the analysis of this issue.</p><p>In this study, our goal is to investigate how these two types of difficulty, namely "answering ques- tions" and "reading text," are correlated in RC. Corresponding to each type, we formalize two classes of evaluation metrics, prerequisite skills and readability, and analyze existing RC datasets. Our intention is to provide the basis of an eval- uation methodology of RC systems to help their robust development.</p><p>Our two classes of metrics are inspired by the analysis in <ref type="bibr" target="#b16">McNamara and Magliano (2009)</ref> of human text comprehension in psychology. They considered two aspects of text comprehen- sion, namely "strategic/skilled comprehension" and "text ease of processing."</p><p>Our first class defines metrics for "strate- gic/skilled comprehension," namely the difficulty of comprehending the context when answering questions. We adopted the set of prerequisite skills that <ref type="bibr" target="#b30">Sugawara et al. (2017)</ref> proposed for the fine- grained analysis of RC capability. Their study also presented an important observation of the relation between the difficulty of an RC task and prereq- uisite skills: the more skills that are required to answer a question, the more difficult is the ques- tion. Based on this observation, in this work, we assume that the number of skills required to an- swer a question is a reasonable indication of the difficulty of the question. This is because each skill corresponds to one of the functions of an NLP system, which has to be capable of that function- ality.</p><p>Our second class defines metrics for "text ease of processing," namely the difficulty of reading the text. We regard it as readability of the text in terms of syntactic and lexical complexity. From among readability studies in NLP, we adopt a wide range of linguistic features proposed by <ref type="bibr" target="#b33">Vajjala and Meurers (2012)</ref>, which can be used for texts with no available annotations.</p><p>The contributions of this paper are as follows.</p><p>1. We adopt two classes of evaluation metrics to show the qualitative features of RC datasets. Through analyses of RC datasets, we demon- strate that there is only a weak correlation be- tween the difficulty of questions and the read- ability of context texts in RC datasets.</p><p>2. We revise a previous classification of pre- requisite skills for RC. Specifically, skills of knowledge reasoning are organized by us- ing insights of entailment phenomena in NLP and human text comprehension in psychol- ogy.</p><p>3. We annotate six existing RC datasets, com- pared to the two datasets considered in Sug- awara and Aizawa (2016), with our organized metrics being used in the comparison. We have made the results publicly available 1 and report on the characteristics of the datasets and the differences between them.</p><p>We should note that, in this study, RC datasets with different task formulations were annotated with prerequisite skills under the same conditions. Annotators first saw a context, a question, and its answer. They selected the sentences required to provide the answer, and then annotated them with appropriate prerequisite skills. That is, the datasets were annotated from the point of view of whether the context entailed the hypothesis con- structed from the pair of the question and answer. This means that our methodology cannot quantify the systems' competence in searching the context for necessary sentences and answer candidates. In other words, our methodology can be only used to evaluate the competence of understanding RC questions as contextual entailments.</p><p>The remainder of this paper is divided into the following sections. First, we discuss related work in Section 2. Next, we specify our two classes of metrics in Section 3. In Section 4, we annotate existing RC datasets with the prerequisite skills. Section 5 gives the results of our dataset analysis and Section 6 discusses their implications. Section 7 presents our conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Reading Comprehension Datasets</head><p>In this section, we present a short history of RC datasets. To our knowledge, <ref type="bibr" target="#b11">Hirschman et al. (1999)</ref> were the first to use NLP methods for RC. Their dataset comprised reading materials for grades 3-6 with simple 5W (wh-) questions. Sub- sequent investigations into questions of natural language understanding focused on other formu- lations, such as question answering <ref type="bibr" target="#b37">(Yang et al., 2015;</ref><ref type="bibr" target="#b36">Wang et al., 2007;</ref><ref type="bibr" target="#b35">Voorhees et al., 1999</ref>) and textual entailment ( <ref type="bibr" target="#b2">Bentivogli et al., 2010;</ref><ref type="bibr" target="#b27">Sammons et al., 2010;</ref><ref type="bibr" target="#b5">Dagan et al., 2006</ref>). One of the RC tasks of the time was <ref type="bibr">QA4MRE (Sutcliffe et al., 2013</ref>). The highest accuracy achieved for this task was 59% and the size of the dataset was very limited: there were only 224 gold-standard questions, which is insufficient for machine learn- ing methods.</p><p>This means that an important issue for design- ing RC datasets is their scalability. <ref type="bibr">Richardson et al. (2013) presented MCTest,</ref> which is an open- domain narrative dataset for gauging comprehen- sion at a child's level. This dataset was created by crowdsourcing and was based on a scalable methodology. Since then, additional large-scale datasets have been proposed with the development of machine learning methods in NLP. For exam- ple, the CNN/Daily Mail dataset ( <ref type="bibr" target="#b9">Hermann et al., 2015</ref>) and CBTest ( <ref type="bibr" target="#b10">Hill et al., 2016</ref>) have approx- imately 1.4M and 688K passages, respectively. These context texts and questions were automat- ically curated and generated from large corpora. However, <ref type="bibr" target="#b3">Chen et al. (2016)</ref> indicated that approx- imately 25% of the questions in the CNN/Daily Mail dataset are either unsolvable or nonsensical. This dataset-quality issue highlights the demand for more stable and robust sourcing methods.</p><p>Several additional RC datasets were presented in the last half of 2016, involving large docu- ments and sensible queries that were guaranteed by crowdsourcing or other human testing. They were intended to provide large and high-quality content for machine learning models. Nonethe- less, as shown in the examples of <ref type="figure" target="#fig_0">Figure 1</ref>, they were not offered with metrics that could evaluate NLP systems adequately with respect to the diffi- culty of questions and the surface features of texts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Reading Comprehension in Psychology</head><p>In psychology, there is a rich tradition of research on human text comprehension. The construction- integration (C-I) model <ref type="bibr" target="#b13">(Kintsch, 1988</ref>) is one of the most basic and influential theories. This model assumes a connectional and computational archi- tecture for text comprehension. It assumes that comprehension is the processing of information based on the following two steps. <ref type="bibr">2</ref> 2. Integration: associate the contents to un- derstand them consistently (e.g., coreference, discourse, and coherence).</p><p>During these steps, three levels of representa- tion are constructed <ref type="bibr" target="#b34">(van Dijk and Kintsch, 1983)</ref>: the surface code (i.e., wording and syntax), the textbase (i.e., text propositions with cohesion), and the situation model (i.e., mental represen- tation). Based on these assumptions, McNa- mara and Magliano <ref type="formula">(2009)</ref> proposed two aspects of text comprehension, namely "strategic/skilled comprehension" and "text ease of processing." We adopted these assumptions as the basis of our two classes of evaluation metrics (Section 3).</p><p>In an alternative approach, Kintsch (1993) pro- posed two dichotomies for the classification of human inferences, including the knowledge-based inference assumed in the C-I model. The first di- chotomy is between inferences that are automatic and those that are controlled. However, <ref type="bibr" target="#b8">Graesser et al. (1994)</ref> indicated that this distinction is am- biguous, because there is a continuum between the two states that depends on individuals. Therefore, this dichotomy is unsuited to empirical evaluation, which is our focus. The second dichotomy is be- tween inferences that are retrieved and those that are generated. Retrieved means that the informa- tion used for inference is retrieved entirely from the context. In contrast, when inferences are gen- erated, the reader uses external knowledge that goes beyond the context.</p><p>A similar distinction was proposed by <ref type="bibr" target="#b16">McNamara and Magliano (2009)</ref>, namely that between bridging and elaboration. A bridging inference connects current information to other information that has been encountered previously. Elaboration connects current information to external knowl- edge that is not included in the context. We use these two types of inference in the classification of knowledge reasoning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation Metrics for Datasets</head><p>Following the depiction of text comprehension by <ref type="bibr" target="#b16">McNamara and Magliano (2009)</ref>, we adopted two classes for the evaluation of RC datasets: prereq- uisite skills and readability.</p><p>For the prerequisite skills class (Section 3.1), we refined RC skills that were proposed by <ref type="bibr" target="#b30">Sugawara et al. (2017)</ref> and <ref type="bibr" target="#b29">Sugawara and Aizawa (2016)</ref>. However, a problem in these studies is that their categorization of knowledge reasoning was provisional and with a weak theoretical back- ground.</p><p>Therefore, in this study, we reorganized the cat- egory of knowledge reasoning in terms of textual entailment in NLP and human text comprehension in psychology. In research on textual entailment, several methodologies have been proposed for the precise analysis of entailment phenomena <ref type="bibr" target="#b6">(Dagan et al., 2013;</ref><ref type="bibr" target="#b15">LoBue and Yates, 2011</ref>). In psychol- ogy research, as described in Section 2.2, McNa- mara and Magliano <ref type="formula">(2009)</ref> proposed a similar dis- tinction for inferences: bridging versus elabora- tion. We utilized these insights in developing a comprehensive but not overly specific classifica- tion of knowledge reasoning.</p><p>Our prerequisite skills class includes the textbase and situation model <ref type="bibr" target="#b34">(van Dijk and Kintsch, 1983)</ref>. In our terminology, this means understanding each fact and associating multiple facts in a text, such as the relations of events, char- acters, or the topic of a story. The skills also in- volve knowledge reasoning, which is divided into several metrics according to the distinctions of hu- man inferences. This point is discussed by <ref type="bibr" target="#b14">Kintsch (1993)</ref> and <ref type="bibr" target="#b16">McNamara and Magliano (2009)</ref>. It also accords with the classification of entailment phenomena by <ref type="bibr" target="#b6">Dagan et al. (2013)</ref> and <ref type="bibr" target="#b15">LoBue and Yates (2011)</ref>.</p><p>Readability metrics (Section 3.2) are quantita- tive measures used to assess the difficulty of read- ing, with respect to vocabulary and the complexity of texts. In this study, they measure the compe- tence in understanding the first basic representa- tion of a text, called the surface code <ref type="bibr" target="#b34">(van Dijk and Kintsch, 1983</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Prerequisite Skills</head><p>Based on the 10 RC skills in <ref type="bibr" target="#b30">Sugawara et al. (2017)</ref>, we identified 13 prerequisite skills, which are presented below. (We use * and † to indicate skills that have been modified/elaborated from the original definition or have been newly introduced in this study, respectively.)</p><p>1. Object tracking * : jointly tracking or grasp- ing of multiple objects, including sets or member- ships <ref type="bibr" target="#b4">(Clark, 1975)</ref>. This skill is a version of the list/enumeration used in the original classification, renamed to emphasize its scope with respect to multiple objects.</p><p>2. Mathematical reasoning * : we merged sta- tistical and quantitative reasoning with mathemat- ical reasoning. This skill is a renamed version of mathematical operations.</p><p>3. Coreference resolution * : this skill has a small modification to include an anaphora ( <ref type="bibr" target="#b6">Dagan et al., 2013)</ref>. It is similar to direct reference <ref type="bibr" target="#b4">(Clark, 1975)</ref>.</p><p>4. Logical reasoning * : we identified this skill as the understanding of predicate logic, e.g., con- ditionals, quantifiers, negation, and transitivity. Note that this skill, together with mathematical reasoning, is intended to align with the offline skills described by <ref type="bibr" target="#b8">Graesser et al. (1994)</ref>.</p><p>5. Analogy * : understanding of metaphors in- cluding metonymy and synecdoche (see <ref type="bibr" target="#b15">LoBue and Yates (2011)</ref> for examples of synecdoche.)</p><p>6. Causal relation: understanding of causal- ity that is represented by explicit expressions such as "why," "because," and "the reason for" (only if they exist).</p><p>7. Spatiotemporal relation: understanding of spatial and/or temporal relationships between mul- tiple entities, events, and states.</p><p>In addition, we propose the following four cate- gories by refining the "commonsense reasoning" category proposed originally in <ref type="bibr" target="#b30">Sugawara et al. (2017)</ref>.</p><p>8. Ellipsis † : recognizing implicit/omitted infor- mation (argument, predicate, quantifier, time, or place). This skill is inspired by <ref type="bibr" target="#b6">Dagan et al. (2013)</ref> and the discussion in <ref type="bibr" target="#b30">Sugawara et al. (2017)</ref>.</p><p>9. Bridging † : inference supported by grammat- ical and lexical knowledge (e.g., synonymy, hy- pernymy, thematic role, part of events, idioms, and apposition). This skill is inspired by the concept of indirect reference in the literature <ref type="bibr" target="#b4">(Clark, 1975)</ref>. Note that we exclude direct reference because it is covered by coreference resolution (pronominal- ization) and elaboration (epithets).</p><p>10. Elaboration † : inference using known facts, general knowledge (e.g., kinship, exchange, typi- cal event sequence, and naming), and implicit re- lations (e.g., noun compounds and possessives) (see <ref type="bibr" target="#b6">Dagan et al. (2013)</ref> for details). Bridging and elaboration are distinguished by the knowl- edge used in inferences being grammatical/lexical or general/commonsense, respectively.</p><p>11. Meta-knowledge † : using knowledge that includes a reader, writer, or text genre (e.g., nar- ratives and expository documents) from meta- viewpoints (e.g., Who are the principal charac- ters of the story? or What is the main subject of this article?). Although this skill can be regarded as part of elaboration, we defined it as an inde- pendent skill because this knowledge is specific to RC. We were motivated by the discussion in <ref type="bibr" target="#b28">Smith et al. (2015)</ref>.</p><p>Whereas the above 11 skills involve multiple items, the final pair of skills involve only a single sentence.</p><p>12. Schematic clause relation: understand- ing of complex sentences that have coordination or subordination, including relative clauses.</p><p>13. Punctuation * : understanding of punctu- ation marks (e.g., parenthesis, dash, quotation, colon, or semicolon). This skill is a renamed ver- sion of special sentence structure. Concerning the original definition, we regarded "scheme" in fig- ures of speech as ambiguous and excluded it. We defined ellipsis as a independent skill, and appo- sition was merged into bridging. Similarly, un- derstanding of constructions was merged into the idioms in bridging.</p><p>Note that we did not construct this classification to be dependent on particular RC systems in NLP. This was because our methodology is intended to be general and applicable to many kinds of archi- tectures. For example, we did not consider the di- chotomy between automatic and controlled infer- ences because the usage of knowledge is not nec- essarily the same for all RC systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Readability Metrics</head><p>In this study, we evaluated the readability of texts based on metrics in NLP. Several studies have ex- amined readability in various applications, such as second-language learning <ref type="bibr" target="#b24">(Razon and Barnden, 2015)</ref> and text simplification ( <ref type="bibr" target="#b0">Aluisio et al., 2010)</ref>, and from various aspects, such as development measures in second-language acquisition (Vajjala and Meurers, 2012) and discourse relations <ref type="bibr" target="#b22">(Pitler and Nenkova, 2008)</ref>.</p><p>Of these, we adopted the classification of lin- guistic features proposed by <ref type="bibr" target="#b33">Vajjala and Meurers (2012)</ref>. This was because they presented a com- parison of a wide range of linguistic features fo- cusing on second-language acquisition and their method can be applied to plain text. <ref type="bibr">3</ref> We list the readability metrics in <ref type="table" target="#tab_0">Table 1</ref>, which were reported by <ref type="bibr" target="#b33">Vajjala and Meurers (2012)</ref>  the top 10 features that affect human readabil- ity. To classify these metrics, we can identify three classes: lexical features (NumChar, Num- Syll, AWL, AdvVar, and ModVar), syntactic fea- tures (MLS, CoOrd, DC/C, and CN/C), and tradi- tional features (Coleman). We applied these met- rics only to sentences that needed to be read in an- swering questions.</p><note type="other">as -Ave. no. of characters per word (NumChar) -Ave. no. of syllables per word (NumSyll) -Ave. sentence length in words (MLS) -Proportion of words in AWL (AWL) -Modifier variation (ModVar) -No. of coordinate phrases per sentence (CoOrd) -Coleman-Liau index (Coleman) -Dependent clause-to-clause ratio (DC/C) -Complex nominals per clause (CN/C) -Adverb variation (AdvVar)</note><p>However, because these metrics were proposed for human readability, they do not necessarily cor- relate with those used in RC systems. Therefore, in any system analysis, ideally we would have to consult a variety of features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Annotation of Reading Comprehension Datasets</head><p>We annotated six existing RC datasets with the prerequisite skills. We explain the annotation procedure in Section 4.1 and the annotated RC datasets in Section 4.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Annotation Procedure</head><p>We prepared annotation guidelines according to <ref type="bibr" target="#b30">Sugawara et al. (2017)</ref>. The guidelines include the definitions and examples of the skills and annota- tion instructions. Four annotators were asked to simulate the pro- cess of answering questions in RC datasets, using only the prerequisite skills, and to annotate ques- tions with one or more skills required in answer- ing. For each task in the datasets, the annotators saw simultaneously the context, question, and its answer. When a dataset contained multiple-choice questions, we showed all candidate answers and labeled the correct one with an asterisk. The an-   notators then selected the sentences that needed to be read to be able to answer the question and de- cided on the set of prerequisite skills required. The annotators were allowed to select nonsense for unsolvable or unanswerable questions (e.g., the "coreference error" and "ambiguous" ques- tions described in <ref type="bibr" target="#b3">Chen et al. (2016)</ref>) to distin- guish them from any solvable questions that re- quired no skills.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Datasets</head><p>As summarized in      the fact that QA4MRE involves technical docu- ments that contain a wide range of knowledge, multiple clauses, and punctuation. Moreover, the questions are devised by experts. MCTest achieved a high score for several skills (best for causal relation and meta-knowledge and second-best for coreference resolution and spa- tiotemporal relation), but a low score for punctua- tion. These scores seem to be because the MCTest dataset consists of narratives.</p><p>Another dataset that achieved notable scores is Who-did-What. This dataset achieved the highest score for ellipsis. This is because the questions of Who-did-What are automatically generated from articles not used as context. This methodology tends to avoid textual overlap between a question and its context, thereby requiring frequently the skills of ellipsis, bridging, and elaboration.</p><p>With regard to nonsense, MS MARCO and Who-did-What received relatively high scores. This appears to have been caused by the automated sourcing methods, which may generate a separa- tion between the contents of the context and ques- tion (i.e., web segments and a search query in MS MARCO, and a context article and question article in Who-did-What). In contrast, NewsQA had no nonsense questions. Although this result was af- fected by our filtering (described in Appendix A), it is important to note that the NewsQA dataset in- cludes annotations of meta-information whether or not a question makes sense (is question bad).</p><p>(ii) Number of required prerequisite skills (see <ref type="table" target="#tab_6">Table 4</ref>): QA4MRE had the highest score. On average, each question required 3.25 skills. There were few questions in QA4MRE that re-  quired zero or one skill, whereas such questions were contained more frequently in other datasets. <ref type="table" target="#tab_6">Table 4</ref> also indicates that more than 90% of the MS MARCO questions required fewer than three skills according to the annotation.</p><p>(iii) Readability metrics for each dataset (see <ref type="table" target="#tab_7">Table 5</ref>): SQuAD and QA4MRE achieved the highest scores for most metrics. This reflects the fact that Wikipedia articles and technical docu- ments usually require a high-grade level of un- derstanding. In contrast, MCTest had the lowest scores, with its dataset consisting of narratives for children.</p><p>(iv) Correlation between numbers of re- quired prerequisite skills and readability met- rics (see <ref type="figure">Figures 2 and 3</ref>, and <ref type="table">Table 6</ref>): our main interest was in the correlation between prerequi- site skills and readability. To investigate this, we examined the relation between the number of re- quired prerequisite skills and readability metrics.   <ref type="table">Table 6</ref>: Pearson's correlation coefficients (r) with the p-values (p) for the readability metrics and number of required prerequisite skills for all ques- tions in the RC datasets.</p><p>We used the Flesch-Kincaid grade level ( <ref type="bibr" target="#b12">Kincaid et al., 1975</ref>) as an intuitive reference for read- ability. This value represents the typical num- ber of years of education required to understand texts based on counts of syllables, words, and sen- tences. <ref type="figure">Figures 2 and 3</ref> show the relation between two values for each dataset and for each question, respectively. <ref type="figure">Figure 2</ref> shows the trends of the datasets. QA4MRE was relatively difficult both to read and to answer, whereas SQuAD was dif- ficult to read but easy to answer. For further in- vestigation, we selected three datasets (QA4MRE, MCTest, and SQuAD) and plotted all of their questions in <ref type="figure">Figure 3</ref>. Three separate domains can be seen. <ref type="table">Table 6</ref> presents Pearson's correlation coeffi- cients between the number of required prerequisite skills and each readability metric for all questions in the RC datasets. Although there are weak corre- lations, from 0.025 to 0.416, these results demon- strate that there is not necessarily a strong correla- tion between the two values. This leads to the fol- lowing two insights. First, the readability of RC datasets does not directly affect the difficulty of their questions. That is, RC datasets that are diffi- cult to read are not necessarily difficult to answer. Second, it is possible to create difficult questions from the context that are easy to read. MCTest is a good example. The context texts in the MCTest dataset are easy to read, but the difficulty of its questions compares to that for the other datasets.</p><p>To summarize our results in terms of each RC dataset, we can make the following observations. -QA4MRE is difficult both to read and to answer among the datasets analyzed. This would seem to follow its questions being devised by experts.</p><p>-MCTest is a good example of an RC dataset that is easy to read but difficult to answer. We pre- sume that this is because the corpus genre (i.e., narrative) reflects the trend in required skills for the questions.</p><p>-SQuAD is difficult to read, along with QA4MRE, but relatively easy to answer com- pared with the other datasets.</p><p>-Who-did-What performs well in terms of its query-sourcing method. Although its questions are created automatically, they are sophisticated in terms of knowledge reasoning. However, the automated sourcing method must be improved to exclude nonsense questions.</p><p>-MS MARCO is a relatively easy dataset in terms of prerequisite skills. However, one prob- lem is that the dataset contained nonsense ques- tions.</p><p>-NewsQA is advantageous in that it provides meta-information on the reliability of the ques- tions. Such information enabled us to avoid us- ing nonsense questions, as for the training of machine learning models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>In this section, we discuss several issues regarding the construction of RC datasets and the develop- ment of RC systems using our methodology. How to utilize the two classes of metrics for system development: one possible scenario for developing an RC system is that it is first built to solve an easy-to-read and easy-to-answer dataset. The next step would be to improve the system so that it can solve an easy-to-read but difficult-to- answer dataset (or its converse). Finally, only af- ter it can solve such datasets should the system be applied to difficult-to-read and difficult-to-answer datasets. The metrics of this study may be useful in preparing appropriate datasets for each step by measuring their properties. The datasets can then be ordered according to the grades of the metrics and applied to each step of the development, as in curriculum learning ( <ref type="bibr" target="#b1">Bengio et al., 2009</ref>) and transfer learning <ref type="bibr" target="#b20">(Pan and Yang, 2010)</ref>.</p><p>Corpus genre: attention should be paid to the genre of the corpus used to construct a dataset. Ex- pository documents such as news articles tend to require factorial understanding. Most existing RC datasets use such texts because of their availabil- ity. On the other hand, narrative texts may have a closer correspondence to our everyday experience, involving the emotions and intentions of charac- ters ( <ref type="bibr" target="#b8">Graesser et al., 1994)</ref>. To build agents that work in the real world, RC datasets may have to be constructed from narratives.</p><p>Question type: in contrast to factorial under- standing, comprehensive understanding of natural language texts needs a better grasp of global co- herence (e.g., the main point or moral of the text, the goal of a story, or the intention of characters) from the broad context ( <ref type="bibr" target="#b8">Graesser et al., 1994)</ref>. Most questions in current use require only local coherence (e.g., referential relations and thematic roles) within a narrow context. An example of a question based on global coherence would be to give a summary of the text, as used in <ref type="bibr" target="#b9">Hermann et al. (2015)</ref>. It could be generated automatically by techniques of abstractive text summarization ( <ref type="bibr" target="#b26">Rush et al., 2015;</ref><ref type="bibr" target="#b7">Ganesan et al., 2010)</ref>.</p><p>Annotation issues: we found questions for which there were disagreements regarding non- sense decisions. For example, some questions can be solved by external knowledge without even seeing their context. Therefore, we should clar- ify what constitutes a "solvable" or "reasonable" question for RC. In addition, annotators reported that the prerequisite skills did not easily treat questions whose answer was "none of the above" in QA4MRE. We considered these "no answer" questions difficult, in that systems have to decide not to select any of the candidate answers, and our methodology failed to specify them.</p><p>Competence in selecting necessary sentences: as mentioned in Section 1, our methodology can- not evaluate competence in selecting sentences that need to be read to answer questions. In a brief analysis, we further investigated sentences in the context of the datasets that were selected in the an- notation. Analyses were performed in two ways. For each question, we counted the number of re- quired sentences and their distance apart. <ref type="bibr">4</ref> The first row of <ref type="table">Table 7</ref> gives the average number of re- quired sentences per question for each RC dataset. Although the scores are reasonably close, MCTest required multiple sentences to be read most fre- quently. The second row gives the average dis-  <ref type="table">Table 7</ref>: Average number and distance apart of sentences that need to be read to answer a ques- tion in the RC datasets.</p><p>tance apart of the required sentences. QA4MRE required the longest distance because readers had to look for clues in the long context texts. In con- trast, SQuAD and MS MARCO had lower scores. Most of their questions seemed to be answered by reading only a single sentence. Of course, the scores for distances will depend on the length of the context texts. Metrics of RC for machines: our underlying assumption in this study is that, in the develop- ment of interactive agents such as dialogue sys- tems, it is important to make the systems behave in a human-like way. This has also become a distinguishing feature of recent RC task design, and one that has never been explicitly considered in conventional NLP tasks. To date, the differ- ence between human and machine RC has not at- tracted much research attention. We believe that our human-based evaluation metrics and analy- sis will help researchers to develop a method for the step-by-step construction of better RC datasets and improved RC systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this study, we adopted evaluation metrics that comprise two classes, namely refined prerequisite skills and readability, for analyzing the quality of RC datasets. We applied these classes to six ex- isting datasets and highlighted their characteris- tics according to each metric. Our dataset analysis suggests that the readability of RC datasets does not directly affect the difficulty of the questions and that it is possible to create an RC dataset that is easy to read but difficult to answer. In future work, we plan to use the analysis from the present study in constructing a system that can be applied to multiple datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Sampling Methods for Questions</head><p>In this appendix, we explain the method of choos- ing questions for annotation. <ref type="bibr">QA4MRE (Sutcliffe et al., 2013)</ref>: the gold- standard dataset comprised four different topics and four documents for each topic. We randomly selected 100 main and auxiliary questions so that at least one question for each document was in- cluded.</p><p>MCTest ( <ref type="bibr" target="#b25">Richardson et al., 2013)</ref>: this dataset comprised two sets: MC160 and MC500. Their development sets had 80 tasks in total, with each containing context texts and four questions. We randomly chose 25 tasks (100 questions) from the development sets.</p><p>SQuAD ( <ref type="bibr" target="#b23">Rajpurkar et al., 2016)</ref>: this dataset included Wikipedia articles involving various top- ics, with the articles being divided into paragraphs. We randomly chose 100 paragraphs from 15 arti- cles and used only one question from each para- graph for the annotation.</p><p>Who-did-What (WDW) ( <ref type="bibr" target="#b19">Onishi et al., 2016)</ref>: this dataset was constructed from the English Gi- gaword newswire corpus (v5). Its questions were automatically created using a different article from that used for context. In addition, questions that could be solved by a simple baseline method were excluded from the dataset.</p><p>MS MARCO (MARCO) <ref type="bibr" target="#b17">(Nguyen et al., 2016)</ref>: each task in this dataset comprised several seg- ments, one question, and its answer. We randomly chose 100 tasks (100 questions) and only used seg- ments whose attribute was is selected = 1 as con- text.</p><p>NewsQA ( <ref type="bibr" target="#b32">Trischler et al., 2016)</ref>: we ran- domly chose questions that satisfied the fol- lowing conditions:</p><p>is answer absent = 0, is question bad = 0, and validated answers do not include bad question or none.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Examples of RC questions from SQuAD (Rajpurkar et al., 2016) and MCTest (Richardson et al., 2013) (the Contexts are excerpts).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>RC</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>Figure 2: Flesch-Kincaid grade levels and average number of required prerequisite skills for the RC datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Metrics</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Readability metrics. AWL refers to the 
Academic Word List. 4 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>dataset</head><label></label><figDesc></figDesc><table>Genre 
Query 
sourcing 
Task 
formulation 

QA4MRE 
(2013) 
Technical 
documents 
Handcrafted 
by experts 
Multiple 
choice 
MCTest 
(2013) 
Narratives by 
crowd workers 
Crowdsourced Multiple 
choice 
SQuAD 
(2016) 
Wikipedia 
articles 
Crowdsourced Text span 
selection 
Who-did-What 
(2016) 
News articles 
Automated 
Cloze 

MS MARCO 
(2016) 
Segmented 
web pages 
Search engine 
queries 
Description 

NewsQA 
(2016) 
News articles 
Crowdsourced Text span 
selection 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Analyzed RC datasets, their genres, query 
sourcing methods, and task formulations. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 ,</head><label>2</label><figDesc>), and NewsQA (Trischler et al., 2016). We selected these datasets to enable coverage of a variety of genres, query sourcing methods, and task formulations. From each dataset, we ran- domly selected 100 questions. This number was considered sufficient for the degree of analysis of RC datasets performed by Chen et al. (2016). The questions were sampled from the gold-standard dataset of QA4MRE and the development sets of the other RC datasets. (We explain the method of choosing questions for the annotation in Appendix A.) For a variety of reasons, there were other datasets we did not annotate in this study. CNN/Daily Mail (Hermann et al., 2015) is anonymized and contains errors, according to Chen et al. (2016), making it unsuitable for anno- tation. We considered CBTest (Hill et al., 2016) to be devised as language-modeling tasks rather than RC-related tasks. LAMBADA (Paperno et al.,</figDesc><table>the annotation was per-
formed on six existing RC datasets: QA4MRE 
(Sutcliffe et al., 2013), MCTest (Richardson et al., 
2013), SQuAD (Rajpurkar et al., 2016), Who-did-
What (Onishi et al., 2016), MS MARCO (Nguyen 
et al., 2016</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Frequencies (%) of prerequisite skills 
needed for the RC datasets. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Frequencies (%) of the number of re-
quired prerequisite skills for the RC datasets. 

2016) texts are formatted for machine reading, 
with all tokens in lower case, which would seem 
to disallow inferences based on proper nouns and 
render them unsuitable for human reading and an-
notation. 

5 Results of the Dataset Analysis 

We now present the results of evaluating the RC 
datasets according to the two classes of metrics. 
In the annotation of prerequisite skills, the inter-
annotator agreement was 90.1% for 62 randomly 
sampled questions. The evaluation was performed 
with respect to the following four aspects: (i) fre-
quencies of prerequisite skills required for each 
RC dataset; (ii) number of prerequisite skills re-
quired per question; (iii) readability metrics for 
each RC dataset; and (iv) correlation between 
readability metrics and the number of required 
prerequisite skills. 
(i) Frequencies of prerequisite skills (see Ta-
ble 3): QA4MRE had the highest scores for fre-
quencies among the datasets. This seems to reflect </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Results of readability metrics for the RC 
datasets. F-K is the Flesch-Kincaid grade level 
(Kincaid et al., 1975). Words is the average word 
count of the context for each question. 

</table></figure>

			<note place="foot" n="1"> http://www-al.nii.ac.jp/rc_dataset_ analysis</note>

			<note place="foot" n="1">. Construction: read sentences or clauses as inputs; form and elaborate concepts and propositions corresponding to the inputs. 2 Note that this is a very simplified overview.</note>

			<note place="foot" n="3"> The classification in Pitler and Nenkova (2008) is more suited to measuring text quality. However, we could not use their results because we could not use discourse annotations.</note>

			<note place="foot" n="4"> http://en.wikipedia.org/wiki/ Academic_Word_List</note>

			<note place="foot" n="4"> The distance of sentences was calculated as follows. If a question required only one sentence to be read, its distance was zero. If a question required two adjacent sentences to be read, its distance was one. If a question required more than two sentences to be read, its distance was the sum of the distances of any two sentences.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank anonymous reviewers for their insightful comments. This work was supported by JSPS KAKENHI Grant Numbers 15H02754 and 16K16120.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Readability assessment for text simplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandra</forename><surname>Aluisio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caroline</forename><surname>Gasperin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carolina</forename><surname>Scarton</surname></persName>
		</author>
		<ptr target="https://aclweb.org/anthology/W10-1001" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL HLT 2010 Fifth Workshop on Innovative Use of NLP for Building Educational Applications. Association for Computational Linguistics</title>
		<meeting>the NAACL HLT 2010 Fifth Workshop on Innovative Use of NLP for Building Educational Applications. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Curriculum learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jérôme</forename><surname>Louradour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<idno type="doi">10.1145/1553374.1553380</idno>
		<ptr target="https://doi.org/10.1145/1553374.1553380" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th annual international conference on machine learning</title>
		<meeting>the 26th annual international conference on machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Building textual entailment specialized data sets: a methodology for isolating linguistic phenomena relevant to inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luisa</forename><surname>Bentivogli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Cabrio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Giampiccolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Medea</forename><surname>Lo Leggio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernardo</forename><surname>Magnini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Conference on Language Resources and Evaluation</title>
		<meeting>the 7th International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A thorough examination of the CNN/Daily Mail reading comprehension task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Bolton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<ptr target="https://aclweb.org/anthology/P16-1223" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2358" to="2367" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Bridging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Herbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Clark</surname></persName>
		</author>
		<idno type="doi">10.3115/980190.980237</idno>
		<ptr target="https://doi.org/10.3115/980190.980237" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1975 workshop on Theoretical issues in natural language processing</title>
		<meeting>the 1975 workshop on Theoretical issues in natural language processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1975" />
			<biblScope unit="page" from="169" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The PASCAL recognising textual entailment challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Ido Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernardo</forename><surname>Glickman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Magnini</surname></persName>
		</author>
		<idno type="doi">10.1007/117367909</idno>
		<ptr target="https://doi.org/10.1007/117367909" />
	</analytic>
	<monogr>
		<title level="m">Machine learning challenges. evaluating predictive uncertainty, visual object classification, and recognising tectual entailment</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="177" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Recognizing textual entailment: Models and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Ido Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><forename type="middle">Massimo</forename><surname>Sammons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zanzotto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthesis Lectures on Human Language Technologies</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="220" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Opinosis: a graph-based approach to abstractive summarization of highly redundant opinions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kavita</forename><surname>Ganesan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd international conference on computational linguistics. Association for Computational Linguistics</title>
		<meeting>the 23rd international conference on computational linguistics. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="340" to="348" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Constructing inferences during narrative text comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Arthur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Murray</forename><surname>Graesser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Trabasso</surname></persName>
		</author>
		<idno type="doi">10.1037/0033-295X.101.3.371</idno>
		<ptr target="https://doi.org/10.1037/0033-295X.101.3.371" />
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">371</biblScope>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Teaching machines to read and comprehend</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Moritz Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Kocisky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lasse</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><surname>Suleyman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1693" to="1701" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The goldilocks principle: Reading children&apos;s books with explicit memory representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations</title>
		<meeting>the International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep read: A reading comprehension system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lynette</forename><surname>Hirschman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Light</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Breck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John D</forename><surname>Burger</surname></persName>
		</author>
		<idno type="doi">10.3115/1034678.1034731</idno>
		<ptr target="https://doi.org/10.3115/1034678.1034731" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 37th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="325" to="332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Derivation of new readability formulas (automated readability index, fog count and flesch reading ease formula) for navy enlisted personnel. Chief of Naval Technical Training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J Peter</forename><surname>Kincaid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert P Fishburne</forename><surname>Jr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brad</forename><forename type="middle">S</forename><surname>Richard L Rogers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chissom</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975" />
		</imprint>
	</monogr>
	<note>Research Branch Report 8-75</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The role of knowledge in discourse comprehension: A constructionintegration model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walter</forename><surname>Kintsch</surname></persName>
		</author>
		<idno type="doi">10.1037/0033-295X.95.2.163</idno>
		<ptr target="https://doi.org/10.1037/0033-295X.95.2.163" />
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">163</biblScope>
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Information accretion and reduction in text processing: Inferences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walter</forename><surname>Kintsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Discourse processes</title>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="193" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Types of common-sense knowledge needed for recognizing textual entailment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Lobue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Yates</surname></persName>
		</author>
		<ptr target="https://aclweb.org/anthology/P11-2057" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="329" to="334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Toward a comprehensive model of comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Danielle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joe</forename><surname>Mcnamara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Magliano</surname></persName>
		</author>
		<idno type="doi">10.1016/S0079-7421(09)51009-2</idno>
		<ptr target="https://doi.org/10.1016/S0079-7421(09)51009-2" />
	</analytic>
	<monogr>
		<title level="j">Psychology of learning and motivation</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="297" to="384" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">MS MARCO: A human generated machine reading comprehension dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tri</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mir</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xia</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rangan</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<idno>CoRR abs/1611.09268</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Marker passing as a weak method for text inferencing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Norvig</surname></persName>
		</author>
		<idno type="doi">10.1207/s15516709cog13044</idno>
		<ptr target="https://doi.org/10.1207/s15516709cog13044" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="569" to="620" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Who did What: A large-scale person-centered cloze dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeshi</forename><surname>Onishi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcallester</surname></persName>
		</author>
		<ptr target="https://aclweb.org/anthology/D16-1241" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2230" to="2235" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A survey on transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yang</surname></persName>
		</author>
		<idno type="doi">10.1109/TKDE.2009.191</idno>
		<ptr target="https://doi.org/10.1109/TKDE.2009.191" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on knowledge and data engineering</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1345" to="1359" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The LAMBADA dataset: Word prediction requiring a broad discourse context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denis</forename><surname>Paperno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Germán</forename><surname>Kruszewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angeliki</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngoc</forename><forename type="middle">Quan</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raffaella</forename><surname>Bernardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandro</forename><surname>Pezzelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gemma</forename><surname>Boleda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Fernandez</surname></persName>
		</author>
		<ptr target="https://aclweb.org/anthology/P16-1144" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1525" to="1534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Revisiting readability: A unified framework for predicting text quality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Pitler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
		</author>
		<ptr target="https://aclweb.org/anthology/D08-1020" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2008 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="186" to="195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">SQuAD: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<ptr target="https://aclweb.org/anthology/D16-1264" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2383" to="2392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A new approach to automated text readability classification based on concept indexing with integrated part-of-speech n-gram features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abigail</forename><surname>Razon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Barnden</surname></persName>
		</author>
		<ptr target="https://aclweb.org/anthology/R15-1068" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference Recent Advances in Natural Language Processing</title>
		<meeting>the International Conference Recent Advances in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="521" to="528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">MCTest: A challenge dataset for the open-domain machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Matthew Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erin</forename><surname>Christopher Burges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Renshaw</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/D13-1020" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="193" to="203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A neural attention model for abstractive sentence summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<ptr target="https://aclweb.org/anthology/D15-1044" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="379" to="389" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">ask not what textual entailment can do for you</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sammons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">G</forename><surname>Vinod Vydiswaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><forename type="middle">Roth</forename></persName>
		</author>
		<ptr target="https://aclweb.org/anthology/P10-1122" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1199" to="1208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A strong lexical matching method for the machine comprehension test</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellery</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Greco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matko</forename><surname>Bosnjak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1693" to="1698" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">An analysis of prerequisite skills for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saku</forename><surname>Sugawara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akiko</forename><surname>Aizawa</surname></persName>
		</author>
		<ptr target="https://aclweb.org/anthology/W16-6001" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Uphill Battles in Language Processing: Scaling Early Achievements to Robust Methods. Association for Computational Linguistics</title>
		<meeting>the Workshop on Uphill Battles in Language Processing: Scaling Early Achievements to Robust Methods. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Prerequisite skills for reading comprehension: Multi-perspective analysis of mctest datasets and systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saku</forename><surname>Sugawara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hikaru</forename><surname>Yokono</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akiko</forename><surname>Aizawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3089" to="3096" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Yassine Benajiba, and Petya Osenova</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Sutcliffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anselmo</forename><surname>Peñas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pamela</forename><surname>Forner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alvaro</forename><surname>Rodrigo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corina</forename><surname>Forascu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Overview of QA4MRE main task at CLEF 2013. Working Notes, CLEF</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">NewsQA: A machine comprehension dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingdi</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaheer</forename><surname>Suleman</surname></persName>
		</author>
		<idno>CoRR abs/1611.09830</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">On improving the accuracy of readability classification using insights from second language acquisition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sowmya</forename><surname>Vajjala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Detmar</forename><surname>Meurers</surname></persName>
		</author>
		<ptr target="https://aclweb.org/anthology/W12-2019" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Workshop on Building Educational Applications Using NLP. Association for Computational Linguistics</title>
		<meeting>the Seventh Workshop on Building Educational Applications Using NLP. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="163" to="173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Strategies of discourse comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walter</forename><surname>Teun Adrianus Van Dijk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kintsch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983" />
			<publisher>Citeseer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The TREC-8 question answering track report</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ellen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TREC. volume</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="77" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">What is the Jeopardy model? a quasi-synchronous grammar for QA</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengqiu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teruko</forename><surname>Mitamura</surname></persName>
		</author>
		<ptr target="https://aclweb.org/anthology/D/D07/D07-1003" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning. Association for Computational Linguistics</title>
		<meeting>the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="22" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">WikiQA: A challenge dataset for opendomain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Meek</surname></persName>
		</author>
		<ptr target="https://aclweb.org/anthology/D15-1237" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2013" to="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
