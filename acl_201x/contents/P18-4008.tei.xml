<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:59+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">NLP Web Services for Resource-Scarce Languages</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 15-20, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Puttkammer</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Centre for Text Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">R</forename><surname>Eiselen</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">South African Centre for Digital Language Resources North-West University</orgName>
								<address>
									<settlement>Potchefstroom Campus</settlement>
									<country key="ZA">South Africa</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hocking</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Centre for Text Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">J</forename><surname>Koen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Centre for Text Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">NLP Web Services for Resource-Scarce Languages</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics-System Demonstrations</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics-System Demonstrations <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="43" to="49"/>
							<date type="published">July 15-20, 2018</date>
						</imprint>
					</monogr>
					<note>43</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In this paper, we present a project where existing text-based core technologies were ported to Java-based web services from various architectures. These technologies were developed over a period of eight years through various government funded projects for 10 resource-scarce languages spoken in South Africa. We describe the API and a simple web front-end capable of completing various predefined tasks.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>With the establishment of large-scale e- infrastructures, there has been an international move towards making software available as a ser- vice. Web services are a way of exposing the func- tionality of an information system and making it available through standard web technologies <ref type="bibr">(Alonso et al., 2004)</ref>. A natural language pro- cessing (NLP) web service refers to one or more technologies that focus on natural (human) speech or text and that are exposed programmatically to allow anyone with internet access, on multiple platforms, to gain access to the output of the tech- nology. By hosting NLP web services, the devel- opment of end-user-facing applications could be facilitated in the sense that software developers and researchers get access to the latest versions of such technologies via simple web queries.</p><p>A web service also provides an architecture that will allow human language technologies (HLTs) to be integrated into larger software systems. By adopting a service-orientated architecture, existing resources and tools can also be used to develop complex component-based systems <ref type="bibr">(Boehlke, 2010)</ref>. Several such systems already exist in Eu- rope and the United States, for example Stanford CoreNLP 1 <ref type="bibr" target="#b7">(Manning et al., 2014</ref>), Aylien 2 , Web- 1 http://nlp.stanford.edu:8080/corenlp/process 2 http://aylien.com/ licht 3 <ref type="bibr" target="#b4">(Hinrichs et al., 2010)</ref>, and Tanl Pipeline 4 <ref type="bibr">(Attardi et al., 2010)</ref>. etc. Furthermore, web ser- vices can be updated relatively quickly, allowing users to get the latest version of the technologies at all times.</p><p>In this paper, we describe a project where 61 existing text-based core technologies were ported to Java-based web services from various architec- tures. The first part of this paper provides a brief background and details on the relevant languages the technologies were developed for. This is fol- lowed by a short description of three previous pro- jects in which the technologies were developed, as well as a description of the technologies them- selves. We then describe the API and a simple web front-end capable of completing various pre- defined tasks in the following sections. We con- clude with some information on a current project and future considerations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>The South African community, with its rich di- versity of 11 official languages, is an emerging market where the development of language re- sources and HLTs contribute to the promotion of multilingualism and language development. The development of language resources for the official languages contributes significantly to bridging the divide between the privileged and the marginal- ised in terms of access to information.</p><p>There are 11 official languages in South Africa, generally categorised into five language family groups. The conjunctively written Nguni lan- guages include isiZulu (ZU), isiXhosa (XH), isiNdebele (NR), and SiSwati (SS). The disjunc- tively written languages include the Sotho lan- guages Sesotho (ST), Setswana (TN), Sesotho sa Leboa (NSO), and Tshivenḓ a (VE) and the dis- junctively written Tswa-Ronga language, Xitson- ga (TS). Finally, there are two Germanic lan- guages, English (EN) and Afrikaans (AF) <ref type="bibr" target="#b8">(Prinsloo &amp; de Schryver, 2002</ref>). Apart from Eng- lish, all South African languages are considered resource-scarce with relatively little data that can be used to develop NLP applications and technol- ogies.</p><p>Over the past two decades, the South African government has continuously supported HLT re- lated text and speech projects. These projects have generated NLP resources in the form of data, core technologies, applications and systems that are immensely valuable for the future development of the official South African languages. Although these resources can be obtained in a timely fash- ion from the Language Resource Management Agency of the South African Centre for Digital Language Resources 5 (SADiLaR), access to these resources can still be considered limited, in the sense that technically proficient persons or organi- sations are required to utilise these technologies. One way to improve access to these technologies is to make them available as web services. At the Centre for Text Technology, we previously devel- oped freely available web services for machine translation between several South African lan- guage pairs 6 , and build on this experience to de- velop the web services.</p><p>The web services described in this paper entails the implementation of existing technologies as web services that are accessible via an application programming interface (API) and a user-friendly web application which leverages the API, de- scribed in Section 5. These services can process word lists, running text, documents or scanned images as input. The following section provides a brief overview of the individual technologies that have been implemented in the API.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Technologies</head><p>All the technologies included in the web ser- vices were developed over a period of eight years through three projects, NCHLT Text: Phase I, II and III. These projects were initiated and funded by the National Centre for Human Language Technology (NCHLT) of the Department of Arts and Culture (South African government). The technologies and resources described below were only developed for 10 of the South African lan- guages, since there are well known and readily available text-based technologies for English, such as the Stanford CoreNLP, that can be used on South African English. The three projects and the resulting technologies of each, are briefly de- scribed in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">NCHLT Text: Phase I</head><p>The first phase of the NCHLT Text project fo- cussed on establishing the foundational resources and technologies for further development of the NLP industry in South Africa. For each language, text corpora from government domain sources were collected to develop a one-million-word cor- pus for each language. From these corpora, lan- guage experts for each of the 10 languages anno- tated 50,000 tokens per language (and an addi- tional 5,000 tokens for testing) on three levels, namely part of speech (POS), lemma, and mor- phological composition. In addition to the anno- tated corpora, five core technologies were devel- oped for each language. These technologies were sentence separators, tokenisers, lemmatisers, mor- phological decomposers, and POS taggers. Brief descriptions of each technology developed during this phase of the project and ported to web ser- vices, are provided below. More detailed descrip- tions of the technologies are available in <ref type="bibr" target="#b2">Eiselen and Puttkammer (2014)</ref>.</p><p>Sentence separation is a pre-processing step for tokenisation in a typical NLP pipeline. The sen- tence separators developed during this project are rule-based and split sentences based on language specific characteristics, to ensure that abbrevia- tions and numbering correctly remain part of dif- ferent sentences.</p><p>The tokenisers are also language-specific, rule- based technologies that split sentences into tokens, typically words and punctuation, and are a neces- sary pre-process for all other NLP tasks.</p><p>The POS taggers developed during the project were trained on the 50,000 POS annotated data tokens developed in the project. The implementa- tion uses the open source Hidden Markov Model (HMM) tagger, HunPos <ref type="bibr" target="#b3">(Halácsy et al., 2007)</ref>. Since HunPos is not a Java-compliant library, it was necessary to port the POS taggers to a Java library, nlp4j <ref type="bibr">7</ref> .</p><p>For the initial development and release of the web services, the lemmatisers and morphological decomposers were not included as they are rule- based technologies, with more than 150 rules each. See Section 7 for more detail on a current project tasked with additional annotation in order to develop machine learning-based technologies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">NCHLT Text: Phase II</head><p>Building on the resources created during the first NCHLT Text project, the second phase fo- cussed on named entity recognition, phrase chunking and language identification. Named en- tity recognisers and phrase chunkers were devel- oped from an additional 15,000 tokens per lan- guage annotated during the project. The language identifier (LID), which was developed to classify text as one of the 11 official languages, was trained on the text corpora collected during the first NCHLT Text project along with an English corpus also collected from government domain sources.</p><p>The named entity recognisers were trained us- ing linear-chain conditional random fields (CRF) with L2 regularisation. See Eiselen (2016a) for details on development, evaluation, and accuracy.</p><p>The phrase chunkers were also trained with lin- ear-chain CRFs from annotated data, and addi- tionally use the POS tags as a feature by employ- ing the previously developed POS taggers. Eiselen (2016b) provides the full details on development, evaluation, and accuracy of the phrase chunkers.</p><p>Both the named entity recognition and phrase chunking core technologies were implemented in the web services using the CRF++ 8 Java library.</p><p>LID employs character level n-gram language models (n=6) and measures the Euclidean dis- tance between the relative frequencies of a test model and all language models, selecting the one with the lowest distance as the probable language. In the web services, LID is performed on line lev- el, and returns the probable language for each line in the input text. The first version of the LID was implemented in Python, and the web services ver- sion was implemented in Java. Evaluation results and implementation details are available in Hocking (2014).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">NCHLT Text: Phase III</head><p>The third phase of the NCHLT Text project saw the development of Optical Character Recognition (OCR) models as well as improving access to all the technologies through the development of the web services.</p><p>The OCR models for the South African lan- guages were developed using Tesseract <ref type="bibr">9</ref> and ac- commodate the diacritic characters required for four of the South African languages. See <ref type="bibr" target="#b6">Hocking and Puttkammer (2016)</ref> for the development and evaluation results of these OCR models. For the implementation of OCR in the web services, tess4j 10 was used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Implementation</head><p>The web services are implemented as a simple three-tiered Java application, consisting of the API, a Core Technology Manager (Manager for the remainder of the paper) and the individual core technology modules.</p><p>The API is responsible for handling all incom- ing requests, validating parameters and headers, sending parameter data to the Manager for pro- cessing and for relaying processing results back to the requestor. The Manager is responsible for ini- tialising and loading the technologies, processing the data from the API, and sending the result back to the API. The core technology modules process the input data and perform the various required analyses. Each of these tiers are described in more detail below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">NCHLT web services API</head><p>The API is a RESTful web service that is both maintainable and scalable. The service is based on the Jersey framework 11 , as it is an open source, production quality framework for developing RESTful services in Java. The API is also de- signed in such a way that new language and tech- nologies can be added at any point without affect- ing existing API calls. The API uses an authentica- tion process providing restricted access to the available services of the API. The authentication process uses token-based authentication and pro- vides the requestor with a session token that gives the requestor permission to access any future re- quests made to the API until the requestor's ses- sion expires. The access to the list of languages and technologies requests is not protected by the authentication process, and is therefore open to use without obtaining a session token. The API al- so allows the requestor to request the progress of a ened name;</p><p>• the ISO-639 two-letter language code;</p><p>• Unicode text that should be processed by the technology; and • the authentication token included in the re- quest header as the authToken property. Upon receiving a request, the API validates the parameters and the session token to ensure that all the information needed to use the relevant tech- nology is present. If the request passes the valida- tion, the input and language information is sub- mitted to the Manager that handles the initialisa- tion of the requested core technology module. The Manager then validates the parameter data once again, sends the data for processing by the rele- vant core technology and returns the result back to the API. <ref type="bibr">12</ref> http://{server:port}/CTexTWebAPI/services? core={technology}&amp;lang={code}&amp;text={text}</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Core technology manager</head><p>The Manager is tasked with handling the dif- ferent core technology modules that are loaded for different languages across one or more threads or servers. The Manager controls this by keeping a register of all the modules that have been launched, as well as progress information to de- termine whether any given module is available for processing when a new request is received from the API. Technologies are loaded in memory as they are requested by the Manager. This allows the technologies to process the data more effi- ciently and in effect improves the response times to the requestor. Since many of the modules load- ed by the Manager require relatively large statisti- cal models to process data, and many of the mod- ules are reused in several of the module pipelines, modules are not immediately discarded. Rather than destroying the loaded module, it is kept in memory to be available for a new call, which sig- nificantly reduces the processing time, since it is not necessary to reload the module or its underly- ing models for each new API call.</p><p>In addition to managing the individual modules that are loaded at any given time, the Manager al- so manages shared tasks, such as file handles and error handling, which can be reused by any of the core technology modules as necessary. This simp- ly ensures that all file upload and download pro- cedures are managed in a consistent, reusable fashion. Finally, it is also important to note that all the modules reuse models and attributes that are shared between multiple instances of the class and are thread-safe. Consequently, running multiple instances simultaneously does not cause any in- formation corruption, race conditions, or related multithreading problems, while limiting the load time and memory required to process data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Core technology modules</head><p>As mentioned earlier, the development of the web services focussed on transferring existing lin- guistic core technologies for South African lan- guages to a shared code base that was accessible via a RESTful API. Over the course of the previ- ous projects, various developers used different underlying technologies and programming lan- guages to implement the core technologies. Dur- ing this project, it was decided to consolidate these disparate technologies into a single code base, with various shared components that will make maintenance and updates of these technolo- gies significantly more efficient.</p><p>During the design phase it was decided to port all core technologies to Java, for three reasons. First, Java is supported across most operating sys- tems, allowing the deployment of the technologies and services across many different architectures. Second, Java provides a wide array of freely available and well tested libraries to facilitate the development and distribution of the technologies and web services. A third factor that was taken in- to consideration is that the core technology mod- ules developed for the web service could also be reused in other user-facing applications, specifi- cally an offline corpus search and processing envi- ronment developed in parallel to the web services, CTexTools, version 2 13 . To facilitate distributed computing across multiple servers, each of the core technology modules are also implemented as servlets, which can be initialised by the manager. This allows for multiple versions of the same technology to be run on multiple threads and serv- ers as necessary.</p><p>Although the primary focus of transferring the modules was for inclusion in the web services, this transfer also allowed for better integration be- tween the different modules that have been devel- oped at the Centre for Text Technology. All the transferred modules are based on a shared inter- face class, ICoreTechnology, which in turn im- plements a shared abstract class CoreTechnology. These are relatively simple shared classes, but have the significant benefit that all the core tech- nologies can be called and handled by the Manag- er in a systematic, consequent manner. This in turn means that adding technologies to the set of available modules is relatively straightforward, and would immediately iterate through the rest of the API architecture, without requiring updates to the API or Manager itself.</p><p>Another consideration in the transfer of the technologies to a shared code base, is the fact that most of the technologies have an interdependence, typically forming pipelines that are required to process a string. As an example, the phrase chunker for a particular language is dependent on the output of the POS tagger as one of its features. The POS tagger in turn is dependent on tokenisa- tion for that language, and tokenisation is depend- ent on sentence separation to complete its pro- cessing. This means that for phrase chunking to be The modules required for each technology module are entirely handled by the Manager, which means that core technologies that are typi- cally used in most modules, such as tokenisation, can effectively be reused by various instances of modules that require the shared module.</p><p>Due to several factors, the web services are cur- rently only deployed on a single 12 core virtual server with 32Gb memory. In order to test the re- liability of the technologies and the responsive- ness of the service, a set of load tests were per- formed on the web services, simulating 70 users simultaneously processing text files of approxi- mately 100,000 tokens, with different technolo- gies in different languages. The entire scenario of processing the approximately 7 million tokens completes within 10 minutes, equating to a pro- cessing rate of around 11,700 tokens per second. In a secondary test on the slowest of the technolo- gies, i.e. named entity recognition, for 10 concur- rent users, each processing 100,000 words, the service completes in 3.5 minutes, for a rate of 1,400 tokens per second. This is primarily due to the fact that named entity recognition uses the most intricate pipeline, including tokenisation, <ref type="figure">Figure 1</ref>: Example of system workflow sentence separation, part of speech tagging, and extended feature extraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Web application</head><p>To make the technologies developed during the various phases of the NCHLT project more acces- sible, a simple web application was also created. This application specifically aims to accommo- date users who are unaccustomed to service- orientated architectures, and for whom using these types of architectures can be quite challenging. As such, it was prudent to develop a basic interface to assist users in using the services to complete cer- tain tasks. Thus, we developed a web-based, user- friendly graphical user interface capable of com- pleting various tasks by providing predefined chains of the web services detailed above. For ex- ample, if a user needs to perform POS tagging on a document, the user can upload the document and select POS tagging and the relevant language. The system will automatically perform tokenisation and sentence separation before using the POS tag- ging service to tag the user's document. To facili- tate easy and quick processing, a user can provide text, select the required options, process the text, and view or download the results. Detailed docu- mentation on using the API, as well as the web application, is also provided. The tag sets used for all annotation are provided in the help page. The web application is available at http://hlt.nwu.ac.za/.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and future work</head><p>In this paper, we provided an overview of a new web service and application that provides ac- cess to 61 different text technologies for South Af- rican languages. This implementation allows any developer to access and integrate one of these lan- guage technologies in their own environment, while ensuring that the latest versions of these technologies are used at any time. Finally, a sim- ple, user-friendly, web application was described that provides access to predefined chains of NLP technologies for use by end-users who are not as technically proficient, but can use the technologies in their own research work.</p><p>Given the flexible nature of the web services and underlying infrastructure, it is foreseen that other language technologies will be included in the service as they become available. The South African government also recently established SADiLaR, a national research infrastructure fo- cussing on the development and distribution of linguistic and natural language processing re- sources.</p><p>There is currently a project underway to ex- tend the set of annotated text corpora from 50,000 to approximately 100,000 tokens. These extended annotated data sets could then be used to create improved core technologies for the South African languages.</p></div>
			<note place="foot" n="3"> http://weblicht.sfs.uni-tuebingen.de/weblichtwiki/ 4 http://tanl.di.unipi.it/en/api</note>

			<note place="foot" n="5"> http://repo.sadilar.org/handle/20.500.12185/7 6 https://mt.nwu.ac.za/</note>

			<note place="foot" n="7"> https://emorynlp.github.io/nlp4j/</note>

			<note place="foot" n="8"> https://github.com/taku910/crfpp</note>

			<note place="foot" n="9"> https://github.com/tesseract-ocr/ 10 http://tess4j.sourceforge.net 11 https://jersey.github.io/</note>

			<note place="foot" n="13"> https://hdl.handle.net/20.500.12185/480 performed, first sentence separation must be performed, then tokenisation, then POS tagging, and only then can the feature set be created for the string that must be phrase chunked. In the current architecture, this entire chain is inherently implemented, and the phrase chunker only needs to call the POS tagging module for the specific language, which then in turn calls the module(s) that are necessary for tagging to be performed. See Figure 1.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Acknowledgements</head><p>The NCHLT web services project was funded by the Department of Arts and Culture, Govern-ment of South Africa. The expansion of the anno-tated data is funded as a specialisation project by SADiLaR. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Government Domain Named Entity Recognition for South African Languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Eiselen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC 2016). European Language Resources Association (ELRA)</title>
		<meeting>the Tenth International Conference on Language Resources and Evaluation (LREC 2016). European Language Resources Association (ELRA)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3344" to="3348" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">South African Language Resources: Phrase Chunking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Eiselen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC 2016). European Language Resources Association (ELRA)</title>
		<meeting>the Tenth International Conference on Language Resources and Evaluation (LREC 2016). European Language Resources Association (ELRA)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="689" to="693" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Developing Text Resources for Ten South African Languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Eiselen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Puttkammer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC</title>
		<meeting>the Ninth International Conference on Language Resources and Evaluation (LREC</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3698" to="3703" />
		</imprint>
	</monogr>
	<note>European Language Resources Association (ELRA)</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">HunPos: an open source trigram tagger</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Halácsy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kornai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Oravecz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 45th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="209" to="212" />
		</imprint>
	</monogr>
	<note>Proceedings of the Demo and Poster Sessions</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">WebLicht: Web-based LRT services for German</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hinrichs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hinrichs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zastrow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 48th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>48th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="25" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Language identification for South African languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hocking</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Pattern Recognition Association of South Africa and Robotics and Mechatronics International Conference</title>
		<meeting>the Annual Pattern Recognition Association of South Africa and Robotics and Mechatronics International Conference</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page">307</biblScope>
		</imprint>
	</monogr>
	<note>PRASA-RobMech): Poster session</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Optical character recognition for South African languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hocking</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Puttkammer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pattern Recognition Association of South Africa and Robotics and Mechatronics International Conference (PRASA-RobMech)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations. The Association for Computational Linguistics</title>
		<meeting>52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations. The Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Towards an 11 x 11 array for the degree of conjunctivism/disjunctivism of the South African languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Prinsloo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-M</forename><surname>De Schryver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nordic Journal of African Studies</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="249" to="265" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
