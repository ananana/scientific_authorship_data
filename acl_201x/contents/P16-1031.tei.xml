<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:39+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Bi-Transferring Deep Neural Networks for Domain Adaptation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangyou</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer</orgName>
								<orgName type="institution">Central China Normal University</orgName>
								<address>
									<postCode>430079</postCode>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwen</forename><surname>Xie</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer</orgName>
								<orgName type="institution">Central China Normal University</orgName>
								<address>
									<postCode>430079</postCode>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><forename type="middle">Xiangji</forename><surname>Huang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Information Technology</orgName>
								<orgName type="institution">York University</orgName>
								<address>
									<settlement>Toronto</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tingting</forename><surname>He</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer</orgName>
								<orgName type="institution">Central China Normal University</orgName>
								<address>
									<postCode>430079</postCode>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Bi-Transferring Deep Neural Networks for Domain Adaptation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="322" to="332"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Sentiment classification aims to automatically predict sentiment polarity (e.g., positive or negative) of user generated sentiment data (e.g., reviews, blogs). Due to the mismatch among different domains, a sentiment classifier trained in one domain may not work well when directly applied to other domains. Thus, domain adaptation for sentiment classification algorithms are highly desirable to reduce the domain discrepancy and manual labeling costs. To address the above challenge, we propose a novel domain adaptation method, called Bi-Transferring Deep Neu-ral Networks (BTDNNs). The proposed BTDNNs attempts to transfer the source domain examples to the target domain, and also transfer the target domain examples to the source domain. The linear transformation of BTDNNs ensures the feasibility of transferring between domains, and the distribution consistency between the transferred domain and the desirable domain is constrained with a linear data reconstruction manner. As a result, the transferred source domain is supervised and follows similar distribution as the target domain. Therefore, any supervised method can be used on the transferred source domain to train a classifier for sentiment classification in a target domain. We conduct experiments on a benchmark composed of reviews of 4 types of Amazon products. Experimental results show that our proposed approach significantly outperforms the several baseline methods, and achieves an accuracy which is competitive with the state-of-the-art method for domain adaptation .</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>With the rise of social media (e.g., blogs and so- cial networks etc.), more and more user generated sentiment data have been shared on the Web ( <ref type="bibr" target="#b32">Pang et al., 2002;</ref><ref type="bibr" target="#b31">Pang and Lee, 2008;</ref><ref type="bibr" target="#b27">Liu, 2012;</ref><ref type="bibr" target="#b49">Zhou et al., 2011</ref>). They exist in the form of user re- views on shopping or opinion sites, in posts of blogs/questions or customer feedbacks. This has created a surge of research in sentiment classifi- cation (or sentiment analysis), which aims to au- tomatically determine the sentiment polarity (e.g., positive or negative) of user generated sentiment data (e.g., reviews, blogs, questions).</p><p>Machine learning algorithms have been proved promising and widely used for sentiment classifi- cation ( <ref type="bibr" target="#b32">Pang et al., 2002;</ref><ref type="bibr" target="#b31">Pang and Lee, 2008;</ref><ref type="bibr" target="#b27">Liu, 2012)</ref>. However, the performance of these models relies on manually labeled training data. In many practical cases, we may have plentiful labeled data in the source domain, but very few or no labeled data in the target domain with a different data dis- tribution. For example, we may have many labeled books reviews, but we are interested in detect- ing the polarity of electronics reviews. Reviews for different products might have different vocab- ularies, thus classifiers trained on one domain of- ten fail to produce satisfactory results when trans- ferring to another domain. This has motivated much research on cross-domain (domain adapta- tion) sentiment classification which transfers the knowledge from the source domain to the target domain ( <ref type="bibr" target="#b38">Thomas et al., 2006;</ref><ref type="bibr" target="#b33">Snyder and Barzilay, 2007;</ref><ref type="bibr" target="#b5">Blitzer et al., 2007;</ref><ref type="bibr" target="#b12">Daume III, 2007;</ref><ref type="bibr" target="#b23">Li and Zong, 2008;</ref><ref type="bibr" target="#b24">Li et al., 2009;</ref><ref type="bibr" target="#b30">Pan et al., 2010;</ref><ref type="bibr" target="#b22">Kumar et al., 2010;</ref><ref type="bibr" target="#b16">Glorot et al., 2011;</ref><ref type="bibr" target="#b8">Chen et al., 2011a;</ref><ref type="bibr" target="#b25">Li et al., 2012;</ref><ref type="bibr" target="#b41">Xia et al., 2013a;</ref><ref type="bibr" target="#b26">Li et al., 2013;</ref><ref type="bibr" target="#b51">Zhou et al., 2015a;</ref><ref type="bibr" target="#b54">Zhuang et al., 2015)</ref>.</p><p>Depending on whether the labeled data are available for the target domain, cross-domain sen-timent classification can be divided into two cat- egories: supervised domain adaptation and unsu- pervised domain adaptation. In scenario of super- vised domain adaptation, labeled data is available in the target domain but the number is usually too small to train a good sentiment classifier, while in unsupervised domain adaptation only unlabeled data is available in the target domain, which is more challenging. This work focuses on the un- supervised domain adaptation problem of which the essence is how to employ the unlabeled data of target domain to guide the model learning from the labeled source domain.</p><p>The fundamental challenge of cross-domain sentiment classification lies in that the source do- main and the target domain have different data dis- tribution. Recent work has investigated several techniques for alleviating the domain discrepancy: instance-weight adaptation <ref type="bibr" target="#b19">(Huang et al., 2007;</ref><ref type="bibr" target="#b20">Jiang and Zhai, 2007;</ref><ref type="bibr" target="#b23">Li and Zong, 2008;</ref><ref type="bibr" target="#b29">Mansour et al., 2009;</ref><ref type="bibr" target="#b13">Dredze et al., 2010;</ref><ref type="bibr" target="#b9">Chen et al., 2011b;</ref><ref type="bibr" target="#b8">Chen et al., 2011a;</ref><ref type="bibr" target="#b26">Li et al., 2013;</ref><ref type="bibr" target="#b41">Xia et al., 2013a</ref>) and feature repre- sentation adaptation ( <ref type="bibr" target="#b38">Thomas et al., 2006;</ref><ref type="bibr" target="#b33">Snyder and Barzilay, 2007;</ref><ref type="bibr" target="#b5">Blitzer et al., 2007;</ref><ref type="bibr" target="#b24">Li et al., 2009;</ref><ref type="bibr" target="#b30">Pan et al., 2010;</ref><ref type="bibr" target="#b51">Zhou et al., 2015a;</ref><ref type="bibr" target="#b54">Zhuang et al., 2015)</ref>. The first kind of methods assume that some training data in the source domain are very useful for the target do- main and these data can be used to train models for the target domain after re-weighting. In con- trast, feature representation approaches attempt to develop an adaptive feature representation that is effective in reducing the difference between do- mains.</p><p>Recently, some efforts have been initiated on learning robust feature representations with deep neural networks (DNNs) in the context of cross- domain sentiment classification <ref type="bibr" target="#b16">(Glorot et al., 2011;</ref>). <ref type="bibr" target="#b16">Glorot et al. (2011)</ref> pro- posed to learn robust feature representations with stacked denoising auto-encoders (SDAs) <ref type="bibr" target="#b39">(Vincent et al., 2008)</ref>. Denoising auto-encoders are one- layer neural networks that are optimized to recon- struct input data from partial and random corrup- tion. These denoisers can be stacked into deep learning architectures. The outputs of their in- termediate layers are then used as input features for SVMs <ref type="bibr" target="#b14">(Fan et al., 2008)</ref>.  proposed a marginalized SDA (mSDA) that ad- dressed the two crucial limitations of SDAs: high computational cost and lack of scalability to high- dimensional features. However, these methods learn the unified domain-invariable feature repre- sentations by combining the source domain data and that of the target domain data together, which cannot well characterize the domain-specific fea- tures as well as the commonality of domains.</p><p>To this end, we propose a Bi-Transferring Deep Neural Networks (BTDNNs) which can transfer the source domain examples to the target domain and also transfer the target domain examples to the source domain, as shown in <ref type="figure" target="#fig_0">Figure 1</ref>. In BTDNNs, the linear transformation makes the fea- sibility of transferring between domains, and the linear data reconstruction manner ensures the dis- tribution consistency between the transferred do- main and the desirable domain. Specifically, our BTDNNs has one common encoder f c , two de- coders g s and g t which can map an example to the source domain and the target domain respectively. As a result, the source domain can be transferred to the target domain along with its sentiment la- bel, and any supervised method can be used on the transferred source domain to train a classifier for sentiment classification in the target domain, as the transferred source domain data share the sim- ilar distribution as the target domain. Experimen- tal results show that the proposed approach signifi- cantly outperforms several baselines, and achieves an accuracy which is competitive with the state-of-the-art method for cross-domain sentiment classi- fication.</p><p>The remainder of this paper is organized as fol- lows. Section 2 introduces the related work. Sec- tion 3 describes our proposed bi-transferring deep neural networks (BTDNNs). Section 4 presents the experimental results. In Section 5, we con- clude with ideas for future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Domain adaptation aims to generalize a classifier that is trained on a source domain, for which typi- cally plenty of training data is available, to a target domain, for which data is scarce. Cross-domain generalization is important in many real applica- tions, the key challenge is that data in the source and the target domain are often distributed differ- ently.</p><p>Recent work has investigated several techniques for alleviating the difference in the context of cross-domain sentiment classification task. <ref type="bibr" target="#b5">Blitzer et al. (2007)</ref> proposed a structural correspon- dence learning (SCL) algorithm to train a cross- domain sentiment classifier. SCL is motivated by a multi-task learning algorithm, alternating struc- tural optimization (ASO), proposed by Ando and <ref type="bibr" target="#b0">Zhang (2005)</ref>. Given labeled data from a source domain and unlabeled data from both source and target domains, SCL attempts to model the rela- tionship between "pivot features" and "non-pivot features". <ref type="bibr" target="#b30">Pan et al. (2010)</ref> proposed a spectral feature alignment (SFA) algorithm to align the domain-specific words from the source and target domains into meaningful clusters, with the help of domain-independent words as a bridge. In the way, the cluster can be used to reduce the gap between domain-specific words of two domains. <ref type="bibr" target="#b13">Dredze et al. (2010)</ref> combined classifier weights using confidence-weighted learning, which repre- sented the covariance of the weight vectors. <ref type="bibr" target="#b41">Xia et al. (2013a)</ref> proposed an instance selection and instance weighting method for cross-domain sen- timent classification. After that, <ref type="bibr" target="#b42">Xia et al. (2013b)</ref> proposed a feature ensemble plus sample selection method to further improve the sentiment classifi- cation adaptation. <ref type="bibr" target="#b52">Zhou et al. (Zhou et al., 2015b)</ref> proposed to bridge the domain gap with the help of topical correspondence. <ref type="bibr" target="#b24">Li et al. (2009)</ref> proposed to transfer common lexical knowledge across do- mains via matrix factorization techniques. <ref type="bibr" target="#b51">Zhou et al. (2015a)</ref> further improved the matrix fac- torization techniques via a regularization term on the pivots and domain-specific words, ensuring that the pivots capture only correspondence as- pects and the domain-specific words capture only individual aspects. <ref type="bibr" target="#b23">Li and Zong (2008)</ref> pro- posed the multi-label consensus training approach which combined several base classifiers trained with SCL.  proposed a domain adaptation algorithm based on sample and feature selection. <ref type="bibr" target="#b26">Li et al. (2013)</ref> proposed an active learn- ing algorithm for cross-domain sentiment classifi- cation.  investigated the on- line active domain adaptation problem in a novel but practical setting where the labels can be ac- quired with a lower cost in the source domain than in the target domain.</p><p>There has also been research in exploring care- ful structuring of features or prior knowledge for domain adaptation. Daumé III <ref type="formula" target="#formula_2">(2007)</ref> proposed a kernel-mapping function which maps both source and target domains data to a high-dimensional fea- ture space so that data points from the same do- main are twice as similar as those form different domains. <ref type="bibr" target="#b11">Dai et al. (2008)</ref>   <ref type="bibr" target="#b47">Yang and Eisenstein (2015)</ref> proposed to use feature embeddings with metadata domain at- tributes for multi-domain adaptation. In this paper, our proposed approach BTDNNs tackles the do- main discrepancy with a linear data construction manner, which can effectively model the domain- specific features as well as the commonality of domains. Deep learning techniques have also been proposed to heterogeneous transfer learn- ing ( <ref type="bibr" target="#b35">Socher et al., 2013;</ref><ref type="bibr" target="#b21">Kan et al., 2015;</ref><ref type="bibr" target="#b28">Long et al., 2015)</ref>, where knowledge is transferred from one modality to another based on the correspondences at hand. Our proposed framework can be considered as a more general case, where the bias of the correspondences be- tween the source and target domains is constrained with a linear data reconstruction manner.</p><p>Besides, other researchers also explore the DNNs for sentiment analysis <ref type="bibr" target="#b34">(Socher et al., 2011;</ref><ref type="bibr" target="#b36">Tang et al., 2014;</ref><ref type="bibr" target="#b37">Tang et al., 2015;</ref><ref type="bibr">Zhai and Zhang, 2016;</ref><ref type="bibr" target="#b7">Chandar et al., 2014</ref>). However, all these methods focus on the sentiment analysis without considering the domain discrepancy. In this paper, we focus on domain adaptation for sen- timent classification with a different model formu- lation and task definition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Bi-Transferring Deep Neural Networks</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem Definition</head><p>Given two domains X s and X t , where X s and X t are referred to a source domain and a target domain, respectively. Suppose we have a set of labeled sentiment examples as well as some un- labeled examples in the source domain X s with size n s , containing terms from a vocabulary V with size m. The examples in the source domain X s can be represented as a term-document matrix X s = {x s 1 , · · · , x s ns } ∈ R m×ns , with their senti- ment labels y s = {y s 1 , · · · , y s ns }, where x s i ∈ R m is the feature representation of the i-th source do- main example with a tf-idf weight of the corre- sponding term and y s i ∈ {+1, −1} is its sentiment label. <ref type="bibr">1</ref> Similarly, suppose we have a set of unlabeled examples in the target domain X t with size n t , containing terms from a vocabulary V with size m. The examples in target domain X t can also be represented as a term-document matrix X t = {x</p><formula xml:id="formula_0">(t) 1 , · · · , x (t)</formula><p>nt } ∈ R m×nt , where each example denotes a tf-idf weight of the corresponding term. The task of cross-domain sentiment classification is to learn a robust classifier to predict the polarity <ref type="bibr">1</ref> We use upper case and lower case characters represent the matrices and vectors respectively throughout the paper. of unseen examples from X t . Note that we only consider one source domain and one target domain in this paper. However, our proposed algorithm is a general framework and can be easily adapted to multi-domain problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Basic Auto-Encoder</head><p>An auto-encoder is an unsupervised neural net- work which is trained to reconstruct a given in- put vector from its latent representation ( <ref type="bibr" target="#b2">Bengio et al., 2007)</ref>. It can be seen as a special neural network with three layers: the input layer, the la- tent layer, and the reconstruction layer. An auto- encoder contains two parts: encoder and decoder. The encoder, denoted as f , attempts to map an in- put vector x ∈ R m×1 to the latent representation z ∈ R k×1 , in which k is the number of neurons in the latent layer. Usually, f is a nonlinear function as follows:</p><formula xml:id="formula_1">z = f (x) = se(Wx + b)<label>(1)</label></formula><p>where s e is the activation function of the en- coder, whose input is called the activation func- tion, which is usually non-linear, such as sigmoid function or tanh function is a linear transform pa- rameter, and b ∈ R k×1 is the basis. The decoder, denoted as g, tries to map the la- tent representation z back to a reconstruction:</p><formula xml:id="formula_2">g(z) = s d (W z + b )<label>(2)</label></formula><p>Similarly, s d is the activation function of the de- coder with parameters {W , b }.</p><p>The training objective is the determination of parameters {W, b} and {W , b } that minimize the average reconstruction errors:</p><formula xml:id="formula_3">L = min W,b,W ,b N i=1 xi − g(f (xi)) 2 2<label>(3)</label></formula><p>where x i represents the i-th one of N training ex- amples. Parameters {W, b} and {W , b } can be optimized by stochastic or mini-batch gradient de- scent. By minimizing the reconstruction error, we require the latent features should be able to recon- struct the original input as much as possible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Bi-Transferring Deep Neural Networks</head><p>The traditional auto-encoder in subsection 3.2 at- tempts to reconstruct the input itself, which is usually used for feature representation learning. Nevertheless, our proposed bi-transferring deep neural networks (BTDNNs) attempts to transfer examples between domains to deal with the do- main discrepancy, with the inspiration of DNNs in computer vision ( <ref type="bibr" target="#b21">Kan et al., 2015</ref>). Moti- vated by the successful application in computer vision ( <ref type="bibr" target="#b21">Kan et al., 2015)</ref>, we construct the archi- tecture of BTDNNs with one encoder f e , and two decoders, g s and g t shown in <ref type="figure" target="#fig_0">Figure 1</ref>, which can transform an input example to the source domain and the target domain respectively. <ref type="bibr">2</ref> Specifically, the encoder f c tries to map an input example x into the latent feature representation z, which is common to both the source and target do- mains as follows:</p><formula xml:id="formula_4">z = fc(x) = se(Wcx + bc)<label>(4)</label></formula><p>The decoder g s attempts to map the latent rep- resentation to the source domain, and the decoder g t attempts to map the latent representation to the target domain as follows:</p><formula xml:id="formula_5">gs(x) = s d (Wsz + bs)<label>(5)</label></formula><formula xml:id="formula_6">gt(x) = s d (Wtz + bt)<label>(6)</label></formula><p>where s e (·) and s d (·) are the element-wise nonlin- ear activation function, e.g., sigmoid or tanh func- tion, W c and b c are the parameters for encoder f c , W s and b s are the parameters for decoder g s , W t and b t are the parameters for decoder g t . Following the literature ( <ref type="bibr" target="#b21">Kan et al., 2015)</ref>, we attempt to map the source domain examples X s to the source domain (e.g., X s itself) with an encoder f c and a decoder g s . Similarly, given an encoder f c and a decoder g t , we aim to map the source domain examples X s to the target domain. Al- though it is unknown what the mapped examples look like, they are expected to follow the similar distribution as the target domain. This kind of dis- tribution consistency between two domains can be characterized from the perspective of a linear data reconstruction manner.</p><p>The two domains X s and X t can be gener- ally reconstructed from each other, and their dis- tances can be used to measure the domain discrep- ancy. Following the literature ( <ref type="bibr" target="#b18">He et al., 2012)</ref>, BTDNNs attempt to represent a transferred source domain g t (f c (x s i )) with a linear reconstruction function from the target domain:</p><formula xml:id="formula_7">gt(fc(x s i )) − Xtβ t i ) 2 2<label>(7)</label></formula><p>where β t i is the coefficients for the reconstruction of transferred source domain examples. Equa- tion (7) enforces that each example of transferred domain is consistent with that of target domain, which ensures that the transferred source domain follows the similar distribution as the target do- main. The overall objective for the examples of source domain X s can be formulated as below:</p><formula xml:id="formula_8">min fc,gs,g t ,β s i Xs − gs(fc(Xs)) 2 2 + gt(fc(Xs)) − XtBt) 2 2 s.t. β t i 2 2 &lt; τ, Bt = [β t 1 , β t 2 , · · · , β t ns ] T ∈ R ns×n t where g s (f c (X s ) = [g s (f c (x s 1 )), · · · , g s (f c (x s nt ))] and g t (f c (X s ) = [g t (f c (x t 1 )), g t (f c (x t ns ))].</formula><p>The same simplifications are used hereinafter if without misunderstanding.</p><p>Similarly, for the examples of target domain X t , with encoder f c and decoder g t they should be mapped on the target domain. Also, with encoder f c and decoder g s they should be mapped to the source domain, where they can be reconstructed by the source domain examples from the point of view of a linear data reconstruction manner <ref type="bibr" target="#b18">(He et al., 2012</ref> </p><formula xml:id="formula_9">+ γ ns i=1 β t i 2 2 + n t j=1 β s j 2 2<label>(8)</label></formula><p>where γ is a regularization parameter controlling the amount of shrinkage. With the optimization of equation <ref type="formula" target="#formula_9">(8)</ref>, our proposed approach BTDNNs can map any input examples to the source and tar- get domains respectively. Especially, the source domain examples X s can transferred to the tar- get domain along with their sentiment labels. The transferred source domain data g t (f s (X s )) share the similar distribution as the target domain, so any supervised method can be used to learn a clas- sifier for sentiment classification in the target do- main. In this paper, a linear support vector ma- chine (SVM) <ref type="bibr" target="#b14">(Fan et al., 2008</ref>) is employed for building sentiment classification models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Learning Algorithm</head><p>Note that the optimization problem in equation <ref type="formula" target="#formula_9">(8)</ref> is not convex in variables {f c , g s , g t , B s , B t } to- gether. However, when considering one variable at a time, the cost function turns out to be con- vex. For example, given {g s , g t , B s , B t }, the cost function is a convex function w.r.t. f c . Therefore, although we cannot expect to get a global min- imum of the above problem, we shall develop a simple and efficient optimization algorithm via al- ternative iterations.</p><p>3.4.1 Optimize {f c , g s , g t } given {B s , B t } When B s and B t are fixed, the objective function in equation <ref type="formula" target="#formula_9">(8)</ref> can be formulated as:</p><formula xml:id="formula_10">min fc,gs,g t Xs − gs(fc(Xs)) 2 2 + gt(fc(Xs)) − ¯ Xt) 2 2 + Xt − gt(fc(Xt)) 2 2 + gs(fc(Xt)) − ¯ Xs) 2 2 (9)</formula><p>where ¯ X s = X s B s and ¯ X t = X t B t . Equation (9) can easily optimized by gradient descent as the basic auto-encoder ( <ref type="bibr" target="#b2">Bengio et al., 2007</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Optimize</head><p>{B s , B t } given {f c , g s , g t } When {f c , g s , g t } are fixed, the objective function in equation <ref type="formula" target="#formula_9">(8)</ref> can be written as:</p><formula xml:id="formula_11">min Bs,B t Gt − XtBt) 2 2 + Gs − XsBs) 2 2 + γ ns i=1 β t i 2 2 + n t j=1 β s j 2 2</formula><p>where</p><formula xml:id="formula_12">g s (f c (X t )) = G s = [g s 1 , · · · , g s nt ] and g t (f c (X s )) = G t = [g t 1 , · · · , g t ns ]</formula><p>. Since G s and G t are independent with each other, so they can be optimized independently. The optimization of G s with other variables fixed is a least squares prob- lem with 2 -regularization. It can also be decom- posed into n t optimization problems, with each corresponding to one β s j and can be solved in par- allel:</p><formula xml:id="formula_13">min β s j g s j − Xsβ s j 2 2 + γβ s j 2 2<label>(10)</label></formula><p>for j = 1, 2, · · · , n t . It is a standard 2 -regularized least squares problem and the solution is:</p><formula xml:id="formula_14">β s j = X T s Xs + γI −1 X T s g s j (11)</formula><p>where I is an identity matrix with all entries equal to 1. Similarly, The optimization of G t can also be decomposed into n s 2 -regularized least squares problems and the solution of each one is:</p><formula xml:id="formula_15">β t i = X T t Xt + γI −1 X T t g t i<label>(12)</label></formula><p>for i = 1, 2, · · · , n s . We repeat the above equa- tions until f c , g s , g t , B s and B t converge or a maximum number of iterations is exceeded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Algorithm Complexity</head><p>In this section, we analyze the computational complexity of the learning algorithm described in equations <ref type="formula">(9)</ref>, <ref type="formula" target="#formula_1">(11)</ref> and <ref type="formula" target="#formula_1">(12)</ref>. Besides express- ing the complexity of the algorithm using big O notation, we also count the number of arithmetic operations to provide more details about the run time. Computational complexity of learning ma- trix G s is O(m × n s × k) per iteration. Simi- larly, for each iteration, learning matrices G t takes O(m × n t × k). Learning matrices B s and B t takes O(m 2 × n s ) and O(m 2 × n t ) operations per iteration. In real applications, we have k m. Therefore, the overall complexity of the algorithm, dominated by computation of matrices B s and B t , is O(m 2 × n) where n = max(n s , n t ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data Set</head><p>Domain adaptation for sentiment classification has been widely studied in the NLP community. A large majority experiments are performed on the benchmark made of reviews of Amazon products gathered by . This data set contains 4 different domains: Book (B), DVDs (D), Electronics (E) and Kitchen (K). For sim- plicity and comparability, we follow the conven- tion of <ref type="bibr" target="#b30">Pan et al., 2010;</ref><ref type="bibr" target="#b16">Glorot et al., 2011;</ref>) and only con- sider the binary classification problem whether a review is positive (higher than 3 stars) or negative (3 stars or lower). There are 1000 positive and 1000 negative reviews for each domain, as well as approximately 4,000 unlabeled reviews (vary- ing slightly between domains). The positive and negative reviews are also exactly balanced.</p><p>Following the literature (Pan et al., 2010), we can construct 12 cross-domain sentiment classifi- cation tasks:</p><formula xml:id="formula_16">D → B, E → B, K → B, K → E, D → E, B → E, B → D, K → D, E → D, B → K, D → K, E → K,</formula><p>where the word before an arrow corre- sponds with the source domain and the word after an arrow corresponds with the target domain. To be fair to other algorithms that we compare to, we use the raw bag-of-words unigram/bigram features as their input and pre-process with tf-idf (     <ref type="table">Table 1</ref>: Amazon review statistics. This table de- picts the number of training, testing and unlabeled reviews for each domain, as well as the portion of negative training reviews of the data set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Compared Methods</head><p>As a baseline method, we train a linear SVM ( For SCL, PJNMF, SDA, mSDA and TLDA, we use the source codes provided by the authors. For SFA and MCT, we re-implement them based on the original papers. The above methods serve as comparisons in our empirical evaluation. For fair comparison, all hyper-parameters are set by 5-fold cross validation on the training set from the source domain. <ref type="bibr">3</ref> For our proposed BTDNNs, the number of hidden neurons is set as 1000, the regularization parameter γ is tuned via 5-fold cross-validation.</p><p>For SDA, mSDA, TLDA and BTDNNs, we can construct the classifiers for the target domain in two ways. The first way is directly to use the stacking SVM on top of the output of the hidden layer. The second way is to apply the standard SVM to train a classifier for source domain in the embedding space. Then the classifiers is applied to predict sentiment labels for target domain data. For fair comparison with the shallow models, we choose the second way in this paper. <ref type="figure" target="#fig_2">Figure 2</ref> shows the accuracy of classification re- sults for all methods and for all source-target do- main pairs. We can check that all compared meth- ods achieve the similar performance with the re- sults reported in the original papers. <ref type="figure" target="#fig_2">From Fig- ure 2</ref>, we can see that our proposed approach BTDNNs outperforms all other eight comparison methods in general. The baseline performs poorly on all the 12 tasks, while the other seven domain adaptation methods, SCL, MCT, SFA, PJNMF, SDA, mSDA and TLDA, consistently outperform the baseline method across all the 12 tasks, which demonstrates that the transferred knowledge from the source domain to the tar- get domain is useful for sentiment classification. Nevertheless, the improvements achieved by these seven methods over the baseline are much smaller than the proposed approach BTDNNs.</p><p>Surprisingly, we note that the deep learning based methods (SDA, mSDA and TLDA) perform worse than our approach, the reason may be that SDA, mSDA and TLDA learn the unified domain- invariable feature representations by combining the source domain data and that of the target do- main data together, which cannot well characterize the domain-specific features as well as the com- monality of domains. On the contrary, our pro- posed BTDNNs ensures the feasibility of transfer- ring between domains, and the distribution con- sistency between the transferred domain and the desirable domain is constrained with a linear data reconstruction manner.</p><p>We also conduct significance tests for our pro- posed approach BTDNNs and the state-of-the-art method (TLDA) using a McNemar paired test for labeling disagreements <ref type="bibr" target="#b15">(Gillick and Cox, 1989)</ref>. In general, the average result on the 12 source- target domain pairs indicates that the difference benchmark set by the authors.  <ref type="figure">Figure 3</ref>: Proxy A-distance between domains of the Amazon benchmark for the 6 different pairs. between BTDNNs and TLDA is mildly significant with p &lt; 0.08. Furthermore, we also conduct the experiments on a much larger industrial-strength data set of 22 domains <ref type="bibr" target="#b16">(Glorot et al., 2011</ref>). The preliminary results show that BTDNNs signifi- cantly outperforms TLDA (p &lt; 0.05). Therefore, we will report our detailed results and discussions in our future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Domain Divergence</head><p>In this subsection, we look into how similar two domains are to each other. <ref type="bibr" target="#b1">Ben-David et al. (2006)</ref> showed that the A-distance as a measure of how different between the two domains. They hypoth- esized that it should be difficult to discriminate be- tween the source and target domains in order to have a good transfer between them. In practice, computing the exact A-distance is impossible and one has to compute a proxy. Similar to <ref type="bibr" target="#b16">(Glorot et al., 2011</ref>), the proxy for the A-distance is then defined as 2(1 − 2), where is the generaliza- tion error of a linear SVM classifier trained on the binary classification problem to distinguish inputs between the two domains. <ref type="figure">Figure 3</ref> presents the results for each pair of domains. Surprisingly, the distance is increased with the help of new feature representations, e.g., distinguishing between domains becomes easier with the BTDNNs features. We explain this effect through the fact that BTDNNs can ensure the fea- sibility of transferring between domains, and the distribution consistency between the transferred domain and the desirable domain is constrained with a linear data reconstruction manner, which can learn a generally better representations for the input data. This helps both tasks, distinguish- ing between domains and sentiment classification (e.g., in the book domain BTDNNs might inter- polate the feature "exciting" from "boring", both are not particularly relevant for sentiment classifi- cation but might help distinguish the review from the Electronic domain.).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions and Future Work</head><p>In this paper, we propose a novel Bi-Transferring Deep Neural Networks (BTDNNs) for cross- domain sentiment classification. The proposed BTDNNs attempts to transfer the source domain examples to the target domain, and also trans- fer the target domain examples to the source do- main. The linear transformation of BTDNNs en- sures the feasibility of transferring between do- mains, and the distribution consistency between the transferred domain and the desirable domain is constrained with a linear data reconstruction man- ner. Experimental results show that BTDNNs sig- nificantly outperforms the several baselines, and achieves an accuracy which is competitive with the state-of-the-art method for sentiment classification adaptation.</p><p>There are some ways in which this research could be continued. First, since deep learning may obtain better generalization on large-scale data sets <ref type="bibr" target="#b3">(Bengio, 2009)</ref>, a straightforward path of the future research is to apply the proposed BTDNNs for domain adaptation on a much larger industrial-strength data set of 22 domains <ref type="bibr" target="#b16">(Glorot et al., 2011</ref>). Second, we will try to investigate the use of the proposed approach for other kinds of data set, such as 20 newsgroups and Reuters- 21578 ( <ref type="bibr" target="#b25">Li et al., 2012;</ref><ref type="bibr" target="#b53">Zhuang et al., 2013</ref>).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The framework of Bi-transferring Deep Neural Networks (BTDNNs). Through BTDNNs, a source domain example can be transferred to the target domain where it can be reconstructed by the target domain examples, and vice versa.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>proposed translated learning which used a language model to link the class labels to the features in the source domain, which in turn is translated to the features in the target domain. Xia et al. (2010) proposed a POS- based ensemble model for cross-domain sentiment classification. Xiao et al. (2013) proposed a super- vised representation learning method to tackle do- main adaptation by inducing predictive latent fea- tures based on supervised word clustering. He et al. (2011) employed a joint sentiment-topic model for cross-domain sentiment classification; Bolle- gala et al. (2011) used a sentiment sensitive the- saurus to perform cross-domain sentiment classi- fication. Xiao and Guo (2015) proposed to learn distributed state representations for cross-domain sequence predictions. Recently, some efforts have been initiated on learning robust feature representations with deep neural networks (DNNs) for cross-domain nat- ural language processing. Glorot et al. (2011) and Chen et al. (2012) proposed to use deep learning for cross-domain sentiment classification. Most recently, Yang and Eisenstein (2014) pro- posed an unsupervised domain adaptation method with marginalized structured dropout. Further- more,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Average results for cross-domain sentiment classification on the Amazon product benchmark of 4 domains.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Fan et al., 2008) on the raw bag-of-words representa- tion of the labeled source domain and test it on the target domain. In the original paper regarding the benchmark data set, Blitzer et al. (2006) adapted Structural Correspondence Learning (SCL) for sentiment analysis. Li and Zong (2008) proposed the Multi-label Consensus Training (MCT) ap- proach which combined several base classifiers trained with SCL. Pan et al. (2010) first used a Spectral Feature Alignment (SFA) algorithm to align words from the source and target domains to help bridge the gap between them. Zhou et al. (2015a) proposed a method called PJNMF, which linked heterogeneous input features with pivots via joint non-negative matrix factorization. Recently, some efforts have been initiated on learning robust feature representations with DNNs for cross-domain sentiment classification. Glo- rot et al. (2011) first employed stacked Denois- ing Auto-encoders (SDA) to extract meaningful representation for domain adaptation. Chen et al. (2012) proposed marginalized SDA (mSDA) that addressed the high computational cost and lack of scalability to high-dimensional features. Zhuang et al. (2015) proposed a state-of-the-art method called transfer learning with deep auto- encoders (TLDA).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>), so as to ensure a similar distribution be- tween the source domain and the transferred target domain. The overall objective for the examples of target domain X t can be written as:</figDesc><table>min 

fc,gs,g t ,β t 

i 

Xt − gt(fc(Xt)) 2 
2 + gs(fc(Xt)) − XsBs) 2 

2 

s.t. β s 
j 2 
2 &lt; τ, Bs = [β s 
1 , β s 
2 , · · · , β s 
n t ] T ∈ R n t ×ns 

Combining the above equations, the overall ob-
jective of BTDNNs can be formulated as follows: 

min 

fc,gs,g t ,Bs,B t 

Xs − gs(fc(Xs)) 2 
2 + gt(fc(Xs)) − XtBt) 2 

2 

+ Xt − gt(fc(Xt)) 2 
2 + gs(fc(Xt)) − XsBs) 2 

2 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>) . Table 1 presents</head><label>.1</label><figDesc></figDesc><table>the statistics of the 
data set. B-&gt;D 

E-&gt;D 
K-&gt;D 
71 

72 

73 

74 

75 

76 

77 

78 

79 

80 

81 

82 

Accuracy (%) 

baseline 
SCL 
MCT 
SFA 
PJNMF 
SDA 
mSDA 
TLDA 
BTDNNs 

D-&gt;B 
E-&gt;B 
K-&gt;B 
71 

72 

73 

74 

75 

76 

77 

78 

79 

80 

81 

Accuracy (%) 

baseline 
SCL 
MCT 
SFA 
PJNMF 
SDA 
mSDA 
TLDA 
BTDNNs 

B-&gt;E 
D-&gt;E 
K-&gt;E 

72 

74 

76 

78 

80 

82 

84 

86 

Accuracy (%) 

baseline 
SCL 
MCT 
SFA 
PJNMF 
SDA 
mSDA 
TLDA 
BTDNNs 

B-&gt;K 
D-&gt;K 
E-&gt;K 
74 

76 

78 

80 

82 

84 

86 

88 

Accuracy (%) 

baseline 
SCL 
MCT 
SFA 
PJNMF 
SDA 
mSDA 
TLDA 
BTDNNs 

</table></figure>

			<note place="foot" n="2"> In the implementation, we use the stacked denoising auto-encoders (SDA) (Vincent et al., 2008) to model the source and the target domain data.</note>

			<note place="foot" n="3"> We keep the default value of some of the parameters in SCL and SFA, e.g., the number of stop-words removed and stemming parameters − as they were already tuned for this</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A framework for learning predictive structures from multiple tasks and unlabeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kubota</forename><surname>Rie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Ando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1817" to="1853" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Analysis of representations for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shai</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="137" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Greedy layer-wise training of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Popovici</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="153" to="160" />
		</imprint>
		<respStmt>
			<orgName>Universite De Montreal, and Montreal Quebec</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Learning deep architectures for AI. Foundations and Trends in Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Domain adaptation with structural correspondence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="120" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Biographies, bollywood, boom-boxes and blenders: domain adaptation for sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dredze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="120" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Using multiple sources to construct a sentiment sensitive thesaurus for cross-domain sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danushka</forename><surname>Bollegala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Weir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Carroll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="132" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An autoencoder approach to learning bilingual word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarath</forename><surname>Chandar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislas</forename><surname>Lauly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mitesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaraman</forename><surname>Khapra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikas</forename><surname>Ravindran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amrita</forename><surname>Raykar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Saha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Co-training for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minmin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Automatic feature decomposition for single view co-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minmin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixin</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="953" to="960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Marginalized denoising autoencoders for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minmin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhixiang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Sha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="767" to="774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Translated learning: transfer learning across different feature spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="353" to="360" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Frustratingly easy domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daume</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="256" to="263" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Multi-domain learning by confidenceweighted parameter combination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="123" to="149" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Liblinear: A library for large linear classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><forename type="middle">K</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><forename type="middle">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1871" to="1874" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Some statistical issues in the comparison of speech recoginition algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gillick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP</title>
		<imprint>
			<date type="published" when="1989" />
			<biblScope unit="page" from="532" to="535" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Domain adaptation for large-scale sentiment classification: A deep learning approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="513" to="520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Automatically extracting polarity-bearing topics for cross-domain sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenghua</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harith</forename><surname>Alani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="123" to="131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Document summarization based on data reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanying</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Can</forename><surname>Jiajun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lijun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofei</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="620" to="626" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Correcting samples selection bias by unlabeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bordwardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Scholkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="601" to="608" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Instance weighting for domain adaptation in nlp</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="264" to="271" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Bi-shifting auto-encoder for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meina</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiguang</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xilin</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3846" to="3854" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A co-regularization based semi-supervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avishek</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="478" to="486" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Multidomain adaption for sentiment classification: Using multiple classifier combining classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shoushan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqing</forename><surname>Zong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NLPKE</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Knowledge transformation for cross-domain sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikas</forename><surname>Sindhwani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">Q</forename><surname>Chris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="716" to="717" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Topic correlation analysis for cross-domain text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lianghao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="998" to="1004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Active learning for crossdomain sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shoushan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunxia</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongqing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2127" to="2133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Sentiment analysis and opinion mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Morgan &amp; Claypool Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning transferable features with deep adaptation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="97" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Domain adatation with multiple sources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mansour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mohri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rostamizadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="264" to="271" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Cross-domain sentiment classification via spectral feature alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaochuan</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Tao</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="751" to="760" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Opinion mining and sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Found. Trends Inf. Retr</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1" to="135" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Thumbs up? sentiment classification using machine learning techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vaithyanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Multiple aspect ranking using the good grief algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Snyder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="300" to="307" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Semi-supervised recursive autoencoders for predicting sentiment distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="151" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Zero-shot learning through cross-modal transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milind</forename><surname>Ganjoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="935" to="943" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Learning sentimentspecific word embedding for twitter sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1555" to="1565" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Document modeling with gated recurrent neural network for sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1422" to="1432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Get out the vote: Determining support or opposition from congressional floor-debate transcripts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="327" to="335" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Extracting and composing robust features with denoising autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre-Antoine</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1096" to="1103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A pos-based ensemble model for cross-domain sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">,</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqing</forename><surname>Zong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCNLP</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="614" to="622" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Instance selection and instance weighting for cross-domain sentiment classification via pu learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuelei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqing</forename><surname>Zong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2276" to="2182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Feature ensemble plus sample selection: Domain adaptation for sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqing</forename><surname>Zong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuelei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cambria</forename><surname>Erik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="10" to="18" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Online active learning for cost-sensitive domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhong</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CoNLL</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Learning hidden markov models with distributed state representations for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhong</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="524" to="529" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Learning latent word representations for domain adaptation using supervised word clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feipeng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhong</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="152" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Fast easy unsupervised domain adaptation with marginalized structured dropout</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="538" to="544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Unsupervised multi-domain adaptation with feature embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="672" to="682" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Semi-supervised autoencoder for sentiment analysis</title>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<editor>Shuangfei Zhai and Zhongfei (Mark) Zhang</editor>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1394" to="1400" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Phrase-based translation model for question retrieval in community question answer archives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangyou</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="653" to="662" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Hybrid heterogeneous transfer learning through deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joey</forename><forename type="middle">Tianyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ivorw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2213" to="2219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Linking heterogeneous input features with pivots for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangyou</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tingting</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wensheng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1419" to="1425" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Cross-domain sentiment classification via topical correspondence transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangyou</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiyue</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinhui</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tingting</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">159</biblScope>
			<biblScope unit="page" from="298" to="305" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Concept learning for crossdomain text classification: A general probabilistic framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuzhen</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peifeng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongzhi</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1960" to="1966" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Supervised representation learning: Transfer learning with deep autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuzhen</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohu</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4119" to="4125" />
		</imprint>
	</monogr>
	<note>Sinno Jialin Pan, and Qing He</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
