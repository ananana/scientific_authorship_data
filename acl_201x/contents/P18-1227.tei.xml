<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:26+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Incorporating Chinese Characters of Words for Lexical Sememe Prediction</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 15-20, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huiming</forename><surname>Jin</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Shenyuan Honors College</orgName>
								<orgName type="institution" key="instit2">Beihang University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Beijing National Research Center for Information Science and Technology</orgName>
								<orgName type="department" key="dep2">Department of Computer Science and Technology</orgName>
								<orgName type="laboratory">State Key Laboratory of Intelligent Technology and Systems</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">†</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Beijing National Research Center for Information Science and Technology</orgName>
								<orgName type="department" key="dep2">Department of Computer Science and Technology</orgName>
								<orgName type="laboratory">State Key Laboratory of Intelligent Technology and Systems</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Jiangsu Collaborative Innovation Center for Language Ability</orgName>
								<orgName type="institution">Jiangsu Normal University</orgName>
								<address>
									<postCode>221009</postCode>
									<settlement>Xuzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruobing</forename><surname>Xie</surname></persName>
							<affiliation key="aff3">
								<orgName type="department" key="dep1">Search Product Center</orgName>
								<orgName type="department" key="dep2">WeChat Search Application Department</orgName>
								<address>
									<region>Tencent</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Beijing National Research Center for Information Science and Technology</orgName>
								<orgName type="department" key="dep2">Department of Computer Science and Technology</orgName>
								<orgName type="laboratory">State Key Laboratory of Intelligent Technology and Systems</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Jiangsu Collaborative Innovation Center for Language Ability</orgName>
								<orgName type="institution">Jiangsu Normal University</orgName>
								<address>
									<postCode>221009</postCode>
									<settlement>Xuzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fen</forename><surname>Lin</surname></persName>
							<affiliation key="aff3">
								<orgName type="department" key="dep1">Search Product Center</orgName>
								<orgName type="department" key="dep2">WeChat Search Application Department</orgName>
								<address>
									<region>Tencent</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leyu</forename><surname>Lin</surname></persName>
							<affiliation key="aff3">
								<orgName type="department" key="dep1">Search Product Center</orgName>
								<orgName type="department" key="dep2">WeChat Search Application Department</orgName>
								<address>
									<region>Tencent</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Incorporating Chinese Characters of Words for Lexical Sememe Prediction</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2439" to="2449"/>
							<date type="published">July 15-20, 2018. 2018</date>
						</imprint>
					</monogr>
					<note>2439</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Sememes are minimum semantic units of concepts in human languages, such that each word sense is composed of one or multiple sememes. Words are usually manually annotated with their sememes by linguists, and form linguistic common-sense knowledge bases widely used in various NLP tasks. Recently, the lexical se-meme prediction task has been introduced. It consists of automatically recommending sememes for words, which is expected to improve annotation efficiency and consistency. However, existing methods of lexical sememe prediction typically rely on the external context of words to represent the meaning, which usually fails to deal with low-frequency and out-of-vocabulary words. To address this issue for Chinese, we propose a novel framework to take advantage of both internal character information and external context information of words. We experiment on HowNet, a Chinese sememe knowledge base, and demonstrate that our framework outperforms state-of-the-art baselines by a large margin, and maintains a robust performance even for low-frequency words. i</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A sememe is an indivisible semantic unit for hu- man languages defined by linguists <ref type="bibr" target="#b2">(Bloomfield, 1926)</ref>. The semantic meanings of concepts (e.g., words) can be composed by a finite number of se- memes. However, the sememe set of a word is * Work done while doing internship at Tsinghua University.</p><p>† Equal contribution. Huiming Jin proposed the overall idea, designed the first experiment, conducted both experiments, and wrote the paper; Hao Zhu made suggestions on ensembling, proposed the second experiment, and spent a lot of time on proofreading the paper and making revisions. All authors helped shape the research, analysis and manuscript. ‡ Corresponding author: Z. Liu (liuzy@tsinghua.edu.cn) i Code is available at https://github.com/thunlp/Character-enhanced-Sememe-Prediction Figure 1: Sememes of the word "铁 匠" (iron- smith) in HowNet, where occupation, human and industrial can be inferred by both external (con- texts) and internal (characters) information, while metal is well-captured only by the internal infor- mation within the character " 铁" (iron). not explicit, which is why linguists build knowl- edge bases (KBs) to annotate words with sememes manually.</p><p>HowNet is a classical widely-used sememe KB ( <ref type="bibr" target="#b10">Dong and Dong, 2006</ref>). In HowNet, linguists manually define approximately 2, 000 sememes, and annotate more than 100, 000 common words in Chinese and English with their relevant se- memes in hierarchical structures. HowNet is well developed and has a wide range of applications in many NLP tasks, such as word sense disambigua- tion ( <ref type="bibr" target="#b11">Duan et al., 2007)</ref>, sentiment analysis ( <ref type="bibr" target="#b14">Fu et al., 2013;</ref><ref type="bibr" target="#b17">Huang et al., 2014</ref>) and cross-lingual word similarity <ref type="bibr" target="#b36">(Xia et al., 2011</ref>).</p><p>Since new words and phrases are emerging ev- ery day and the semantic meanings of existing concepts keep changing, it is time-consuming and work-intensive for human experts to annotate new concepts and maintain consistency for large-scale sememe KBs. To address this issue,  propose an automatic sememe prediction framework to assist linguist annotation. They assumed that words which have similar seman- tic meanings are likely to share similar sememes. Thus, they propose to represent word meanings as embeddings ( <ref type="bibr" target="#b28">Pennington et al., 2014;</ref><ref type="bibr" target="#b22">Mikolov et al., 2013</ref>) learned from a large-scale text cor- pus, and they adopt collaborative filtering <ref type="bibr" target="#b29">(Sarwar et al., 2001</ref>) and matrix factorization ( <ref type="bibr" target="#b20">Koren et al., 2009</ref>) for sememe prediction, which are con- cluded as Sememe Prediction with Word Embed- dings (SPWE) and Sememe Prediction with Se- meme Embeddings (SPSE) respectively. How- ever, those methods ignore the internal informa- tion within words (e.g., the characters in Chinese words), which is also significant for word under- standing, especially for words which are of low- frequency or do not appear in the corpus at all. In this paper, we take Chinese as an example and explore methods of taking full advantage of both external and internal information of words for se- meme prediction.</p><p>In Chinese, words are composed of one or mul- tiple characters, and most characters have corre- sponding semantic meanings. As shown by <ref type="bibr" target="#b38">Yin (1984)</ref>, more than 90% of Chinese characters in modern Chinese corpora are morphemes. Chinese words can be divided into single-morpheme words and compound words, where compound words ac- count for a dominant proportion. The meanings of compound words are closely related to their internal characters as shown in <ref type="figure">Fig. 1</ref>. Taking a compound word "铁匠" (ironsmith) for instance, it consists of two Chinese characters: "铁" (iron) and "匠" (craftsman), and the semantic meaning of "铁匠" can be inferred from the combination of its two characters (iron + craftsman → iron- smith). Even for some single-morpheme words, their semantic meanings may also be deduced from their characters. For example, both charac- ters of the single-morpheme word "徘徊" (hover) represent the meaning of "hover" or "linger". Therefore, it is intuitive to take the internal char- acter information into consideration for sememe prediction.</p><p>In this paper, we propose a novel framework for Character-enhanced Sememe Prediction (CSP), which leverages both internal character informa- tion and external context for sememe prediction. CSP predicts the sememe candidates for a tar- get word from its word embedding and the corre- sponding character embeddings. Specifically, we follow SPWE and SPSE as introduced by  to model external information and pro- pose Sememe Prediction with Word-to-Character Filtering (SPWCF) and Sememe Prediction with Character and Sememe Embeddings (SPCSE) to model internal character information. In our ex- periments, we evaluate our models on the task of sememe prediction using HowNet. The results show that CSP achieves state-of-the-art perfor- mance and stays robust for low-frequency words.</p><p>To summarize, the key contributions of this work are as follows: (1) To the best of our knowl- edge, this work is the first to consider the inter- nal information of characters for sememe predic- tion. (2) We propose a sememe prediction frame- work considering both external and internal infor- mation, and show the effectiveness and robustness of our models on a real-world dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Knowledge Bases. Knowledge Bases (KBs), aiming to organize human knowledge in structural forms, are playing an increasingly important role as infrastructural facilities of artificial intelligence and natural language processing. KBs rely on manual efforts ( <ref type="bibr" target="#b4">Bollacker et al., 2008)</ref>, automatic extraction ( <ref type="bibr" target="#b0">Auer et al., 2007)</ref>, manual evaluation ( <ref type="bibr" target="#b31">Suchanek et al., 2007)</ref>, automatic completion and alignment <ref type="bibr" target="#b5">(Bordes et al., 2013;</ref><ref type="bibr" target="#b34">Toutanova et al., 2015;</ref><ref type="bibr" target="#b40">Zhu et al., 2017</ref>) to build, verify and enrich their contents. WordNet <ref type="bibr" target="#b23">(Miller, 1995)</ref> and <ref type="bibr">BabelNet (Navigli and Ponzetto, 2012)</ref> are the repre- sentative of linguist KBs, where words of similar meanings are grouped to form thesaurus <ref type="bibr" target="#b25">(Nastase and Szpakowicz, 2001</ref>). Apart from other linguis- tic KBs, sememe KBs such as HowNet ( <ref type="bibr" target="#b10">Dong and Dong, 2006</ref>) can play a significant role in under- standing the semantic meanings of concepts in hu- man languages and are favorable for various NLP tasks: information structure annotation <ref type="bibr" target="#b16">(Gan and Wong, 2000</ref>), word sense disambiguation ( <ref type="bibr" target="#b15">Gan et al., 2002</ref>), word representation learning ( <ref type="bibr" target="#b27">Niu et al., 2017;</ref><ref type="bibr" target="#b13">Faruqui et al., 2015)</ref>, and sentiment analysis ( <ref type="bibr" target="#b14">Fu et al., 2013</ref>) inter alia. Hence, lexi- cal sememe prediction is an important task to con- struct sememe KBs.</p><p>Automatic Sememe Prediction. Automatic se- meme prediction is proposed by .</p><p>For this task, they propose SPWE and SPSE, which are inspired by collaborative filtering <ref type="bibr" target="#b29">(Sarwar et al., 2001</ref>) and matrix factorization ( <ref type="bibr" target="#b20">Koren et al., 2009)</ref> respectively. SPWE recommends the sememes of those words that are close to the unla- belled word in the embedding space. SPSE learns sememe embeddings by matrix factorization <ref type="bibr" target="#b20">(Koren et al., 2009)</ref> within the same embedding space of words, and it then recommends the most rele- vant sememes to the unlabelled word in the em- bedding space. In these methods, word embed- dings are learned based on external context infor- mation ( <ref type="bibr" target="#b28">Pennington et al., 2014;</ref><ref type="bibr" target="#b22">Mikolov et al., 2013</ref>) on large-scale text corpus. These meth- ods do not exploit internal information of words, and fail to handle low-frequency words and out- of-vocabulary words. In this paper, we propose to incorporate internal information for lexical se- meme prediction.</p><p>Subword and Character Level NLP. Subword and character level NLP models the internal in- formation of words, which is especially useful to address the out-of-vocabulary (OOV) problem. Morphology is a typical research area of sub- word level NLP. Subword level NLP has also been widely considered in many NLP applications, such as keyword spotting <ref type="bibr" target="#b24">(Narasimhan et al., 2014</ref>), parsing (Seeker and C ¸ etino˘ glu, 2015), machine translation ( <ref type="bibr" target="#b12">Dyer et al., 2010)</ref>, speech recogni- tion ( <ref type="bibr" target="#b9">Creutz et al., 2007)</ref>, and paradigm comple- tion ( <ref type="bibr" target="#b33">Sutskever et al., 2014;</ref><ref type="bibr" target="#b1">Bahdanau et al., 2015;</ref><ref type="bibr">Cotterell et al., 2016a;</ref><ref type="bibr" target="#b18">Jin and Kann, 2017)</ref>. Incorporating subword information for word embeddings <ref type="bibr" target="#b3">(Bojanowski et al., 2017;</ref><ref type="bibr" target="#b8">Cotterell et al., 2016b;</ref><ref type="bibr" target="#b35">Wieting et al., 2016;</ref><ref type="bibr" target="#b39">Yin et al., 2016</ref>) facilitates modeling rare words and can improve the performance of several NLP tasks to which the embeddings are applied. Besides, people also consider character embeddings which have been utilized in Chinese word segmentation <ref type="bibr" target="#b32">(Sun et al., 2014</ref>).</p><p>The success of previous work verifies the feasi- bility of utilizing internal character information of words. We design our framework for lexical se- meme prediction inspired by these methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Background and Notation</head><p>In this section, we first introduce the organization of sememes, senses and words in HowNet. Then we offer a formal definition of lexical sememe pre- diction and develop our notation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Sememes, Senses and Words in HowNet</head><p>HowNet provides sememe annotations for Chi- nese words, where each word is represented as a hierarchical tree-like sememe structure. Specifi- cally, a word in HowNet may have various senses, which respectively represent the semantic mean- ings of the word in the real world. Each sense is defined as a hierarchical structure of sememes. For instance, as shown in the right part of <ref type="figure">Fig. 1</ref>, the word "铁匠" (ironsmith) has one sense, namely ironsmith. The sense ironsmith is defined by the sememe "人" (human) which is modified by se- meme "职位" (occupation), "金属" (metal) and "工" (industrial). In HowNet, linguists use about 2, 000 sememes to describe more than 100, 000 words and phrases in Chinese with various com- binations and hierarchical structures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Formalization of the Task</head><p>In this paper, we focus on the relationships be- tween the words and the sememes. Following the settings of , we simply ignore the senses and the hierarchical structure of sememes, and we regard the sememes of all senses of a word together as the sememe set of the word.</p><p>We now introduce the notation used in this pa- per. Let G = (W, S, T ) denotes the sememe KB, where W = {w 1 , w 2 , . . . , w |W | } is the set of words, S is the set of sememes, and T ⊆ W × S is the set of relation pairs between words and se- memes. We denote the Chinese character set as C, with each word w i ∈ C + . Each word w has its sememe set S w = {s|(w, s) ∈ T }. Take the word "铁匠" (ironsmith) for example, the sememe set S 铁匠 (ironsmith) consists of "人" (human), "职 位" (occupation), "金属" (metal) and "工" (indus- trial).</p><p>Given a word w ∈ C + , the task of lexical se- meme prediction aims to predict the correspond- ing P (s|w) of sememes in S to recommend them to w.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Methodology</head><p>In this section, we present our framework for lex- ical sememe prediction (SP). For each unlabelled word, our framework aims to recommend the most appropriate sememes based on the internal and ex- ternal information. Because of introducing char- acter information, our framework can work for both high-frequency and low-frequency words.</p><p>Our framework is the ensemble of two parts: sememe prediction with internal information (i.e., internal models), and sememe prediction with ex- ternal information (i.e., external models). Explic- itly, we adopt SPWE, SPSE, and their ensemble (  as external models, and we take SPWCF, SPCSE, and their ensemble as internal models.</p><p>In the following sections, we first introduce SPWE and SPSE. Then, we show the details of SPWCF and SPCSE. Finally, we present the method of model ensembling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">SP with External Information</head><p>SPWE and SPSE are introduced by  as the state of the art for sememe predic- tion. These methods represent word meanings with embeddings learned from external informa- tion, and apply the ideas of collaborative filtering and matrix factorization in recommendation sys- tems for sememe predication.</p><p>SP with Word Embeddings (SPWE) is based on the assumption that similar words should have similar sememes. In SPWE, the similarity of words are measured by cosine similarity. The score function P (s j |w) of sememe s j given a word w is defined as:</p><formula xml:id="formula_0">P (s j |w) ∼ w i ∈W cos(w, w i ) · M ij · c r i , (1)</formula><p>where w and w i are pre-trained word embeddings of words w and w i . M ij ∈ {0, 1} indicates the annotation of sememe s j on word w i , where M ij = 1 indicates the word s j ∈ S w i and other- wise is not. r i is the descend cosine word simi- larity rank between w and w i , and c ∈ (0, 1) is a hyper-parameter.</p><p>SP with Sememe Embeddings (SPSE) aims to map sememes into the same low-dimensional space of the word embeddings to predict the se- mantic correlations of the sememes and the words. This method learns two embeddings s and ¯ s for each sememe by solving matrix factorization with the loss function defined as:</p><formula xml:id="formula_1">L = w i ∈W,s j ∈S wi · (sj + ¯ sj) + bi + b j − Mij 2 + λ s j ,s k ∈S (sj · ¯ s k − C jk ) 2 ,<label>(2)</label></formula><p>where M is the same matrix used in SPWE. C indicates the correlations between sememes, in which C jk is defined as the point-wise mutual in- formation PMI(s j , s k ). The sememe embeddings are learned by factorizing the word-sememe ma- trix M and the sememe-sememe matrix C syn- chronously with fixed word embeddings. b i and b j denote the bias of w i and s j , and λ is a hyper- parameter. Finally, the score of sememe s j given a word w is defined as:</p><formula xml:id="formula_2">P (s j |w) ∼ w · (s j + ¯ s j ) .<label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">SP with Internal Information</head><p>We design two methods for sememe prediction with only internal character information without considering contexts as well as pre-trained word embeddings.</p><p>4.2.1 SP with Word-to-Character Filtering (SPWCF) Inspired by collaborative filtering ( <ref type="bibr" target="#b29">Sarwar et al., 2001</ref>), we propose to recommend sememes for an unlabelled word according to its similar words based on internal information. Instead of using pre-trained word embeddings, we consider words as similar if they contain the same characters at the same positions.</p><p>In Chinese, the meaning of a character may vary according to its position within a word ). We consider three positions within a word: Begin, Middle, and End. For example, as shown in <ref type="figure" target="#fig_1">Fig. 2</ref>, the character at the Begin po- sition of the word "火车站" (railway station) is "火" (fire), while "车" (vehicle) and "站" (station) are at the Middle and End position respectively. The character "站" usually means station when it is at the End position, while it usually means stand at the Begin position like in "站立" (stand), "站 岗 哨 兵" (standing guard) and "站 起 来" (stand up). Formally, for a word w = c 1 c 2 ...c |w| , we de- fine π B (w) = {c 1 }, π M (w) = {c 2 , ..., c |w−1| }, π E (w) = {c |w| }, and</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>高 等 教 育</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Begin End Middle</head><formula xml:id="formula_3">P p (s j |c) ∼ w i ∈W ∧c∈πp(w i ) M ij w i ∈W ∧c∈πp(w i ) |S w i | ,<label>(4)</label></formula><p>that represents the score of a sememe s j given a character c and a position p, where π p may be π B , π M , or π E . M is the same matrix used in Eq. (1). Finally, we define the score function P (s j |w) of sememe s j given a word w as:</p><formula xml:id="formula_4">P (s j |w) ∼ p∈{B,M,E} c∈πp(w) P p (s j |c).<label>(5)</label></formula><p>SPWCF is a simple and efficient method. It performs well because compositional semantics are pervasive in Chinese compound words, which makes it straightforward and effective to find sim- ilar words according to common characters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">SP with Character and Sememe</head><p>Embeddings (SPCSE) The method Sememe Prediction with Word-to- Character Filtering (SPWCF) can effectively rec- ommend the sememes that have strong correla- tions with characters. However, just like SPWE, it ignores the relations between sememes. Hence, inspired by SPSE, we propose Sememe Predic- tion with Character and Sememe Embeddings (SPCSE) to take the relations between sememes into account. In SPCSE, we instead learn the se- meme embeddings based on internal character in- formation, then compute the semantic distance be- tween sememes and words for prediction.</p><p>Inspired by GloVe ( <ref type="bibr" target="#b28">Pennington et al., 2014</ref>) and SPSE, we adopt matrix factorization in SPCSE, by decomposing the word-sememe matrix and the sememe-sememe matrix simultaneously. In- stead of using pre-trained word embeddings in SPSE, we use pre-trained character embeddings in SPCSE. Since the ambiguity of characters is stronger than that of words, multiple embeddings are learned for each character . We select the most representative character and its embedding to represent the word meaning. Because low-frequency characters are much rare than those low-frequency words, and even low- frequency words are usually composed of com- mon characters, it is feasible to use pre-trained character embeddings to represent rare words. During factorizing the word-sememe matrix, the character embeddings are fixed.</p><p>We set N e as the number of embeddings for each character, and each character c has N e em- beddings c 1 , ..., c Ne . Given a word w and a se- meme s, we select the embedding of a charac- ter of w closest to the sememe embedding by co- sine distance as the representation of the word w, as shown in <ref type="figure" target="#fig_2">Fig. 3</ref>. Specifically, given a word w = c 1 ...c |w| and a sememe s j , we definê</p><formula xml:id="formula_5">铁 (iron) 1 铁 (iron) 2 铁 (iron) 3 匠 (craftsman) 1 匠 (craftsman) 2 匠 (craftsman) 3 金属 (metal) 金属 (metal) prediction 铁匠 (ironsmith)</formula><formula xml:id="formula_6">definê k, ˆ r = arg min k,r 1 − cos(c r k , (s j + ¯ s j )) ,<label>(6)</label></formula><p>wherê k andˆrandˆ andˆr indicate the indices of the character and its embedding closest to the sememe s j in the semantic space. With the same word-sememe ma- trix M and sememe-sememe correlation matrix C in Eq. <ref type="formula" target="#formula_1">(2)</ref>, we learn the sememe embeddings with the loss function:</p><formula xml:id="formula_7">L = w i ∈W,s j ∈S c ˆ r ˆ k · s j + ¯ s j + b c ˆ k + b j − Mij 2 + λ s j ,sq ∈S s j · ¯ s q − Cjq 2 ,<label>(7)</label></formula><p>where s j and ¯ s j are the sememe embeddings for sememe s j , and c ˆ r ˆ k is the embedding of the char- acter that is the closest to sememe s j within w i . Note that, as the characters and the words are not embedded into the same semantic space, we learn new sememe embeddings instead of using those learned in SPSE, hence we use different notations for the sake of distinction. b c k and b j denote the biases of c k and s j , and λ is the hyper-parameter adjusting the two parts. Finally, the score function of word w = c 1 ...c |w| is defined as:</p><formula xml:id="formula_8">P (s j |w) ∼ c ˆ r ˆ k · s j + ¯ s j .<label>(8)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Model Ensembling</head><p>SPWCF / SPCSE and SPWE / SPSE take differ- ent sources of information as input, which means that they have different characteristics: SPWCF / SPCSE only have access to internal information, while SPWE / SPSE can only make use of external information. On the other hand, just like the dif- ference between SPWE and SPSE, SPWCF origi- nates from collaborative filtering, whereas SPCSE uses matrix factorization. All of those methods have in common that they tend to recommend the sememes of similar words, but they diverge in their interpretation of similar. Hence, to obtain better prediction performance, it is necessary to combine these models. We de- note the ensemble of SPWCF and SPCSE as the internal model, and we denote the ensemble of SPWE and SPSE as the external model. The ensemble of the internal and the external mod- els is our novel framework CSP. In practice, for words with reliable word embeddings, i.e., high- frequency words, we can use the integration of the internal and the external models; for words with extremely low frequencies (e.g., having no reliable word embeddings), we can just use the internal model and ignore the external model, because the external information is noise in this case. <ref type="figure" target="#fig_3">Fig. 4</ref> shows model ensembling in different scenarios. For the sake of comparison, we use the integration of SPWCF, SPCSE, SPWE, and SPSE as CSP in our all experiments. In this paper, two models are integrated by simple weighted addition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>In this section, we evaluate our models on the task of sememe prediction. Additionally, we analyze the performance of different methods for various word frequencies. We also execute an elaborate case study to demonstrate the mechanism of our methods and the advantages of using internal in- formation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Dataset</head><p>We use the human-annotated sememe KB HowNet for sememe prediction. In HowNet, 103, 843 words are annotated with 212, 539 senses, and each sense is defined as a hierarchical structure of sememes. There are about 2, 000 sememes in HowNet. However, the frequencies of some se- memes in HowNet are very low, such that we con- sider them unimportant and remove them. Our fi- nal dataset contains 1, 400 sememes. For learning the word and character embeddings, we use the Sogou-T corpus ii ( <ref type="bibr" target="#b21">Liu et al., 2012)</ref>, which contains 2.7 billion words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experimental Settings</head><p>In our experiments, we evaluate SPWCF, SPCSE, and SPWCF + SPCSE which only use internal information, and the ensemble framework CSP which uses both internal and external informa- tion for sememe prediction. We use the state- of-the-art models from  as our baselines. Additionally, we use the SPWE model with word embeddings learned by fastText <ref type="bibr" target="#b3">(Bojanowski et al., 2017</ref>) that considers both internal and external information as a baseline.</p><p>For the convenience of comparison, we select 60, 000 high-frequency words in Sogou-T corpus from HowNet. We divide the 60, 000 words into train, dev, and test sets of size 48, 000, 6, 000, and 6, 000, respectively, and we keep them fixed throughout all experiments except for Section 5.4. In Section 5.4, we utilize the same train and dev sets, but use other words from HowNet as the test set to analyze the performance of our methods for different word frequency scenarios. We select the hyper-parameters on the dev set for all models in- cluding the baselines and report the evaluation re- sults on the test set.</p><p>We set the dimensions of the word, sememe, and character embeddings to be 200. The word embeddings are learned by <ref type="bibr">GloVe (Pennington et al., 2014</ref>). For the baselines, in SPWE, the hyper-parameter c is set to 0.8, and the model con- siders no more than K = 100 nearest words. We set the probability of decomposing zero elements in the word-sememe matrix in SPSE to be 0.5%. λ in Eq. (2) is 0.5. The model is trained for 20 epochs, and the initial learning rate is 0.01, which decreases through iterations. For fastText, we use skip-gram with hierarchical softmax to learn word embeddings, and we set the minimum length of character n-grams to be 1 and the maximum length ii Sogou-T corpus is provided by Sogou Inc., a Chinese commercial search engine company. https://www. sogou.com/labs/resource/t.php of character n-grams to be 2. For model ensem- bling, we use λ SPWE λ SPSE = 2.1 as the addition weight. For SPCSE, we use Cluster-based Character Embeddings ( ) to learn pre- trained character embeddings, and we set N e to be 3. We set λ in Eq. <ref type="formula" target="#formula_7">(7)</ref> to be 0.1, and the model is trained for 20 epochs. The initial learning rate is 0.01 and decreases during training as well. Since generally each character can relate to about 15 - 20 sememes, we set the probability of decompos- ing zero elements in the word-sememe matrix in SPCSE to be 2.5%. The ensemble weight of SP- WCF and SPCSE λ SPWCF λ SPCSE = 4.0. For better per- formance of the final ensemble model CSP, we set λ = 0.1 and λ SPWE λ SPSE = 0.3125, though 0.5 and 2.1 are the best for SPSE and SPWE + SPSE. Finally, we choose λ internal λ external = 1.0 to integrate the internal and external models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Sememe Prediction</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Evaluation Protocol</head><p>The task of sememe prediction aims to recom- mend appropriate sememes for unlabelled words. We cast this as a multi-label classification task, and adopt mean average precision (MAP) as the evaluation metric. For each unlabelled word in the test set, we rank all sememe candidates with the scores given by our models as well as baselines, and we report the MAP results. The results are reported on the test set, and the hyper-parameters are tuned on the dev set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">Experiment Results</head><p>The evaluation results are shown in  <ref type="table" target="#tab_0">Table 1</ref>: Evaluation results on sememe prediction. The result of SPWCF + SPCSE is bold for com- paring with other methods (SPWCF and SPCSE) which use only internal information.</p><p>(1) Considerable improvements are obtained via model ensembling, and the CSP model achieves state-of-the-art performance. CSP combines the internal character information with the external context information, which significantly and con- sistently improves performance on sememe pre- diction. Our results confirm the effectiveness of a combination of internal and external information for sememe prediction; since different models fo- cus on different features of the inputs, the ensem- ble model can absorb the advantages of both meth- ods.</p><p>(2) The performance of SPWCF + SPCSE is better than that of SPSE, which means using only internal information could already give good re- sults for sememe prediction as well. Moreover, in internal models, SPWCF performs much better than SPCSE, which also implies the strong power of collaborative filtering.</p><p>(3) The performance of SPWCF + SPCSE is worse than SPWE + SPSE. This indicates that it is still difficult to figure out the semantic mean- ings of a word without contextual information, due to the ambiguity and meaning vagueness of in- ternal characters. Moreover, some words are not compound words (e.g., single-morpheme words or transliterated words), whose meanings can hardly be inferred directly by their characters. In Chi- nese, internal character information is just partial knowledge. We present the results of SPWCF and SPCSE merely to show the capability to use the in- ternal information in isolation. In our case study, we will demonstrate that internal models are pow- erful for low-frequency words, and can be used to predict senses that do not appear in the corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Analysis on Different Word Frequencies</head><p>To verify the effectiveness of our models on differ- ent word frequencies, we incorporate the remain- ing words in HowNet iii into the test set. Since the remaining words are low-frequency, we mainly fo- cus on words with long-tail distribution. We count the number of occurrences in the corpus for each word in the test set and group them into eight cat- egories by their frequency. The evaluation results are shown in <ref type="table" target="#tab_2">Table 2</ref>, from which we can observe that:</p><p>iii In detail, we do not use the numeral words, punctua- tions, single-character words, the words do not appear in Sogou-T corpus (because they need to appear at least for one time to get the word embeddings), and foreign abbre- viations.</p><p>word frequency 50 51-100 101 -1,000 1,001 -5,000 5,001 -10,000 10,001 -30,000   <ref type="table">Table 3</ref>: Examples of sememe prediction. For each word, we present the top 5 sememes predicted by the internal model, external model and the final ensemble model (CSP). Bold sememes are correct.</p><formula xml:id="formula_9">钟表匠 (clockmaker) internal 人 人 人(human), 职 职 职位 位 位(occupation), 部件(part), 时 时 时间 间 间(time), 告 告 告诉 诉 诉(tell) external 人 人 人(human), 专(ProperName), 地方(place), 欧洲(Europe), 政(politics) ensemble 人 人 人(human), 职 职 职位 位 位(occupation), 告 告 告诉 诉 诉(tell), 时 时 时间 间 间(time), 用 用 用具 具 具(tool) 奥斯卡 (Oscar) internal 专 专 专(ProperName), 地方(place), 市(city), 人(human), 国都(capital) external 奖 奖 奖励 励 励(reward), 艺 艺 艺(entertainment), 专 专 专(ProperName), 用具(tool), 事 事 事情 情 情(fact) ensemble 专 专 专(ProperName), 奖 奖 奖励 励 励(reward), 艺 艺 艺(entertainment), 著名(famous), 地方(place)</formula><p>(1) The performances of SPSE, SPWE, and SPWE + SPSE decrease dramatically with low-frequency words compared to those with high-frequency words. On the contrary, the performances of SPWCF, SPCSE, and SP- WCF + SPCSE, though weaker than that on high- frequency words, is not strongly influenced in the long-tail scenario. The performance of CSP also drops since CSP also uses external information, which is not sufficient with low-frequency words. These results show that the word frequencies and the quality of word embeddings can influence the performance of sememe prediction methods, es- pecially for external models which mainly con- centrate on the word itself. However, the internal models are more robust when encountering long- tail distributions. Although words do not need to appear too many times for learning good word embeddings, it is still hard for external models to recommend sememes for low-frequency words. While since internal models do not use external word embeddings, they can still work in such sce- nario. As for the performance on high-frequency words, since these words are used widely, the ambiguity of high-frequency words is thus much stronger, while the internal models are still stable for high-frequency words.</p><p>(2) The results also indicate that even low- frequency words in Chinese are mostly composed of common characters, and thus it is possible to utilize internal character information for se- meme prediction on words with long-tail distribu- tion (even on those new words that never appear in the corpus). Moreover, the stability of the MAP scores given by our methods on various word fre- quencies also reflects the reliability and universal- ity of our models in real-world sememe annota- tions in HowNet. We will give detailed analysis in our case study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Case Study</head><p>The results of our main experiments already show the effectiveness of our models. In this case study, we further investigate the outputs of our models to confirm that character-level knowledge is truly incorporated into sememe prediction.</p><p>In <ref type="table">Table 3</ref>, we demonstrate the top 5 sememes for "钟 表 匠" (clockmaker) and "奥 斯 卡" (Os- car, i.e., the Academy Awards). "钟表匠" (clock- maker) is a typical compound word, while "奥 斯卡" (Oscar) is a transliterated word. For each word, the top 5 results generated by the internal model (SPWCF + SPCSE), the external model (SPWE + SPSE) and the ensemble model (CSP) are listed.</p><p>The word "钟表匠" (clockmaker) is composed of three characters: "钟" (bell, clock), "表" (clock, watch) and "匠" (craftsman). Humans can intu- itively conclude that clock + craftsman → clock- maker. However, the external model does not per-form well for this example. If we investigate the word embedding of "钟表匠" (clockmaker), we can know why this method recommends these un- reasonable sememes. The closest 5 words in the train set to "钟表匠" (clockmaker) by cosine sim- ilarity of their embeddings are: "瑞士" (Switzer- land), "卢 梭" (Jean-Jacques Rousseau), "鞋 匠" (cobbler), "发明家" (inventor) and "奥地利人" (Austrian). Note that none of these words are di- rectly relevant to bells, clocks or watches. Hence, the sememes "时间" (time), "告诉" (tell), and "用 具" (tool) cannot be inferred by those words, even though the correlations between sememes are in- troduced by SPSE. In fact, those words are related to clocks in an indirect way: Switzerland is fa- mous for watch industry; Rousseau was born into a family that had a tradition of watchmaking; cob- bler and inventor are two kinds of occupations as well. With the above reasons, those words usu- ally co-occur with "钟表匠" (clockmaker), or usu- ally appear in similar contexts as "钟表匠" (clock- maker). It indicates that related word embeddings as used in an external model do not always recom- mend related sememes.</p><p>The word "奥斯卡" (Oscar) is created by the pronunciation of Oscar. Therefore, the meaning of each character in "奥斯卡" (Oscar) is unrelated to the meaning of the word. Moreover, the char- acters "奥", "斯", and "卡" are common among transliterated words, thus the internal method rec- ommends "专" (ProperName) and "地方" (place), etc., since many transliterated words are proper nouns or place names.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>In this paper, we introduced character-level inter- nal information for lexical sememe prediction in Chinese, in order to alleviate the problems caused by the exclusive use of external information. We proposed a Character-enhanced Sememe Predic- tion (CSP) framework which integrates both inter- nal and external information for lexical sememe prediction and proposed two methods for utiliz- ing internal information. We evaluated our CSP framework on the classical manually annotated se- meme KB HowNet. In our experiments, our meth- ods achieved promising results and outperformed the state of the art on sememe prediction, espe- cially for low-frequency words.</p><p>We will explore the following research direc- tions in the future: (1) Concepts in HowNet are an- notated with hierarchical structures of senses and sememes, but those are not considered in this pa- per. In the future, we will take structured anno- tations into account. (2) It would be meaningful to take more information into account for blend- ing external and internal information and design more sophisticated methods. (3) Besides Chinese, many other languages have rich subword-level in- formation. In the future, we will explore meth- ods of exploiting internal information in other lan- guages. (4) We believe that sememes are universal for all human languages. We will explore a general framework to recommend and utilize sememes for other NLP tasks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: An example of the position of characters in a word.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: An example of adopting multipleprototype character embeddings. The numbers are the cosine distances. The sememe "金属" (metal) is the closest to one embedding of "铁" (iron).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The illustration of model ensembling.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 .</head><label>1</label><figDesc></figDesc><table>We 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>MAP scores on sememe prediction with different word frequencies. 

words 
models 
Top 5 sememes 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research is part of the NExT++ project, supported by the National Research Founda-tion, Prime Minister's Office, Singapore under its IRC@Singapore Funding Initiative. This work is also supported by the National Natural Science </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Dbpedia: A nucleus for a web of open data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sören</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Bizer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgi</forename><surname>Kobilarov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Cyganiak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Ives</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ISWC</title>
		<meeting>ISWC</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="722" to="735" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A set of postulates for the science of language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonard</forename><surname>Bloomfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="153" to="164" />
			<date type="published" when="1926" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Enriching word vectors with subword information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TACL</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="135" to="146" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Freebase: A collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGMOD</title>
		<meeting>SIGMOD</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1247" to="1250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multirelational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Garciaduran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oksana</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2787" to="2795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Joint learning of character and word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinxiong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan-Bo</forename><surname>Luan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI</title>
		<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1236" to="1242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Jason Eisner, and Mans Hulden. 2016a. The SIGMORPHON 2016 shared task-morphological reinflection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christo</forename><surname>Kirov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Sylak-Glassman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGMORPHON</title>
		<meeting>SIGMORPHON</meeting>
		<imprint>
			<biblScope unit="page" from="10" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Morphological smoothing and extrapolation of word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1651" to="1660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Analysis of morph-based speech recognition and the modeling of out-ofvocabulary words across languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathias</forename><surname>Creutz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teemu</forename><surname>Hirsimäki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikko</forename><surname>Kurimo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antti</forename><surname>Puurula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janne</forename><surname>Pylkkönen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vesa</forename><surname>Siivola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matti</forename><surname>Varjokallio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Processings of HLT-NAACL</title>
		<meeting>essings of HLT-NAACL</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="380" to="387" />
		</imprint>
	</monogr>
	<note>Ebru Arisoy, Murat Saraçlar, and Andreas Stolcke</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">HowNet and the computation of meaning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhendong</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Dong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>World Scientific</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Word sense disambiguation through sememe labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Xiangyu Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI</title>
		<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1594" to="1599" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">cdec: A decoder, alignment, and learning framework for finite-state and context-free translation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Weese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hendra</forename><surname>Setiawan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferhan</forename><surname>Ture</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Eidelman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juri</forename><surname>Ganitkevitch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2010 System Demonstrations</title>
		<meeting>the ACL 2010 System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="7" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Retrofitting word vectors to semantic lexicons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujay</forename><surname>Kumar Jauhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of HLT-NAACL</title>
		<meeting>HLT-NAACL</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1606" to="1615" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Multi-aspect sentiment analysis for Chinese online social reviews based on topic modeling and HowNet lexicon. Knowledge-Based Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianghua</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liu</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guo</forename><surname>Yanyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Zhiqiang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="186" to="195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Knowledge-based sense pruning using the HowNet: an alternative to word sense disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Yung</forename><surname>Kok-Wee Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ISCSLP</title>
		<meeting>ISCSLP</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Annotating information structures in Chinese texts using HowNet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><forename type="middle">Wai</forename><surname>Kok Wee Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The Second Chinese Language Processing Workshop</title>
		<meeting>The Second Chinese Language Processing Workshop</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="85" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">New word detection for sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Borui</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haiqiang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjun</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyan</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="531" to="541" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Exploring cross-lingual transfer of morphological knowledge in sequence-to-sequence models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huiming</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katharina</forename><surname>Kann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SCLeM</title>
		<meeting>SCLeM</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="70" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">One-shot neural cross-lingual transfer for paradigm completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katharina</forename><surname>Kann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1993" to="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Matrix factorization techniques for recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">42</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Identifying web spam with the wisdom of the crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiqun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weize</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huijia</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoping</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liyun</forename><surname>Ru</surname></persName>
		</author>
		<idno>2:1-2:30</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on the Web</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">WordNet: A lexical database for English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Morphological segmentation for keyword spotting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Damianos</forename><surname>Karakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stavros</forename><surname>Tsakalidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="880" to="885" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Word sense disambiguation in Roget&apos;s thesaurus using WordNet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vivi</forename><surname>Nastase</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><surname>Szpakowicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on WordNet and Other Lexical Resources: Applications, Extensions and Customizations</title>
		<meeting>the Workshop on WordNet and Other Lexical Resources: Applications, Extensions and Customizations</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">BabelNet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><forename type="middle">Paolo</forename><surname>Ponzetto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">193</biblScope>
			<biblScope unit="page" from="217" to="250" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Improved word representation learning with sememes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yilin</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruobing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2049" to="2058" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Item-based collaborative filtering recommendation algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Badrul</forename><surname>Sarwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WWW</title>
		<meeting>WWW</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="285" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A graph-based lattice dependency parser for joint morphological segmentation and syntactic analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Seeker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TACL</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="359" to="373" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Yago: A core of semantic knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><forename type="middle">M</forename><surname>Suchanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gjergji</forename><surname>Kasneci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WWW</title>
		<meeting>WWW</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="697" to="706" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Radical-enhanced Chinese character embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaming</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenzhou</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICONIP</title>
		<meeting>ICONIP</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="279" to="286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Representing text for joint embedding of text and knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Pantel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoifung</forename><surname>Poon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pallavi</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Gamon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1499" to="1509" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Charagram: Embedding words and sentences via character n-grams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Wieting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Livescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1504" to="1515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Measuring Chinese-English cross-lingual word similarity with HowNet and parallel corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunqing</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taotao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CICLing</title>
		<meeting>CICLing</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="221" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Lexical sememe prediction via word embeddings and matrix factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruobing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingchi</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI</title>
		<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4200" to="4206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Quantitative research on Chinese morphemes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Binyong Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Studies of the Chinese Language</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="338" to="347" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Multi-granularity Chinese word embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rongchao</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="981" to="986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Iterative entity alignment via joint knowledge embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruobing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI</title>
		<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4258" to="4264" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
