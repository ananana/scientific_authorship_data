<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:38+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Network Framework for Noisy Label Aggregation in Social Media</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueying</forename><surname>Zhan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaowei</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanghui</forename><surname>Rao</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoran</forename><surname>Xie</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fu</forename><forename type="middle">Lee</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tak-Lam</forename><surname>Wong</surname></persName>
						</author>
						<title level="a" type="main">A Network Framework for Noisy Label Aggregation in Social Media</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</title>
						<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="484" to="490"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-2077</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper focuses on the task of noisy label aggregation in social media, where users with different social or culture backgrounds may annotate invalid or malicious tags for documents. To aggregate noisy labels at a small cost, a network framework is proposed by calculating the matching degree of a document&apos;s topics and the annotators&apos; meta-data. Unlike using the back-propagation algorithm, a probabilis-tic inference approach is adopted to estimate network parameters. Finally, a new simulation method is designed for validating the effectiveness of the proposed framework in aggregating noisy labels.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Social media allows users to share their views, opinions, emotion tendencies, and other person- al information online. It is quite valuable to ana- lyze and predict user opinions from these materials ( <ref type="bibr" target="#b14">Wang and Pal, 2015)</ref>, in which supervised learn- ing is one of the effective paradigms ( <ref type="bibr" target="#b17">Xu et al., 2015)</ref>. However, the performance of a supervised learning algorithm relies heavily on the quality of training labels <ref type="bibr" target="#b11">(Song et al., 2015)</ref>. In social media, many training data are collected via simple heuris- tic rules or online crowdsourcing systems, such as Amazon's Mechanical Turk (www.mturk.com) which allows multiple labelers to annotate the same object ( <ref type="bibr" target="#b19">Zhang et al., 2013)</ref>. Due to the lack * The corresponding author. of quality control, it can be hard for a model to reconcile such noise in training labels.</p><p>This study aims to aggregate noisy labels by matching annotators and documents. Unlike other noisy label aggregation and integration tasks (or algorithms), such as Learning to Rank (LtR) and integrating crowdsourced labels which rely on ac- curate instance sources ( <ref type="bibr" target="#b12">Ustinovskiy et al., 2016)</ref> or confidence scores ( <ref type="bibr" target="#b5">Oyama et al., 2013)</ref>, we on- ly need features that can be obtained with a small cost (i.e., topics). Compared with acquiring accu- rate instance sources or confidence scores, which is very hard, extracting topics can be done con- veniently by many existing topic models. Note that label noise is not always random, as adver- sarial noise may occur in real-world environments when a malicious agent is permitted to select la- bels for certain instances <ref type="bibr" target="#b0">(Auer and Cesa-Bianchi, 1998)</ref>. For example, a fake annotator is purchased to promote defective goods by giving high ratings. Noisy labels in such a manner are extremely dif- ficult to be handled ( <ref type="bibr" target="#b4">Nicholson et al., 2015)</ref>. To validate the effectiveness of aggregating the afore- mentioned noisy labels, we propose to design a new simulation method in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>To aggregate or refine noisy labels, several ap- proaches have been proposed recently. <ref type="bibr" target="#b15">Whitehill et al. (Whitehill et al., 2009</ref>) explored a proba- bilistic model to combine labels from both human labelers and automatic classifiers in image classi- fication. <ref type="bibr" target="#b7">Raykar et al. (Raykar et al., 2010</ref>) used a Bayesian approach for supervised learning over noisy labels from multiple annotators. <ref type="bibr" target="#b5">Oyama et al. (Oyama et al., 2013)</ref> proposed to integrate la- bels of crowdsourcing workers using their con- fidence scores. <ref type="bibr" target="#b11">Song et al. (Song et al., 2015</ref>) developed a single-label refinement algorithm to adjust noisy and missing labels. <ref type="bibr" target="#b12">Ustinovskiy et al. (Ustinovskiy et al., 2016)</ref> proposed an opti- mization framework via remapping and reweight- ing methods to solve the problem of LtR with the existence of noisy labels.</p><p>Different from the previous study that modeled the difficulties of instances and the user's author- ity ( <ref type="bibr" target="#b15">Whitehill et al., 2009)</ref>, we target at integrat- ing multiple labels for each instance by estimat- ing the matching degree of documents and anno- tators. Consequently, our work is applicable to aggregating individual sentiment labels in social media, where users under various scenarios (e.g., character and preference) may express invalid or noisy sentiments to different topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Noisy Label Aggregation Framework</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem Definition</head><p>The problem of noisy label aggregation is defined as follows: Given N documents (instances) anno- tated by M users (annotators) over C kinds of la- bels, we generate D topics by existing unsuper- vised topic models. Let T ∈ R N ×D be topics of all instances, where the i-th row of T (i.e., T i ) is the topic distribution of document i, and the size of T i (i.e., |T i |) is D. Let F ∈ R M ×U be features (e.g., age and gender) of all annotators, where F j is the feature distribution of user j and |F j | = U . To model different dimensions of document topics (D) and annotator features (U ) jointly, we map T i and F j to K latent factors denoted as S i and A j , i.e.,  To estimate the ground truth label Z i , we pro- pose a novel network framework via aggregating the observable labels V i , as shown in <ref type="figure" target="#fig_1">Fig. 1</ref>. In our framework, the correctness of V ij depends on whether annotator j matches document i.</p><formula xml:id="formula_0">|S i | = |A j | = K.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Detailed Steps</head><p>Topic Extraction (TE): For document features, it is rough to use tf or tf-idf since they ignore the versatility of semantics among various contexts. Without considering the semantic units called top- ics, the accurate category of each document may be hard to access <ref type="bibr" target="#b10">(Song et al., 2016</ref>). Short mes- sages (e.g., tweets) are prevalent in social media, which differ from normal documents insofar as the number of words is fewer and most words only oc- cur once in each instance. To extract topics from such a sparse word space, we employ the Biterm Topic Model (BTM) by breaking each document into biterms and leveraging the information of the whole corpus ( <ref type="bibr" target="#b18">Yan et al., 2013)</ref>.</p><p>Fully-connected Operation (FcO): There can be a large difference between dimensions of doc- ument topics and annotator features, so we need convert T and F to the same latent space. This step conducts linear transformation by introduc- ing fully-connected weights W T ∈ R D×K and W F ∈ R U ×K , as follows: S = TW T and A = FW F . The values of S and A are propor- tional to the label correctness probability.</p><p>Since more cohesive topics may indicate that the document's category is more concentrated and can be correctly annotated by more users, the topic distribution embeds key information on the document factors S. To map T to S well, we propose the concept of topic entropy that acts as the constraint factor, by calculating the cen- tralization of each document's topics:</p><formula xml:id="formula_1">H(d i ) = − ∑ D z=1 p(t z |d i ) log D ( p(t z |d i ) ) , where p(t z |d i )</formula><p>is the probability of the z-th topic conditioned to document i, and D constrains the values ranging from 0 to 1. The lower H(d i ), the higher the con- centration of topics and the label correctness for document i. We thus infer the relationship be- tween</p><formula xml:id="formula_2">S i and H(d i ) as ||S i || 2 ∝ 1/H(d i ), where ||S i || 2 is the Euclidean norm of S i .</formula><p>Matching Degree Calculation (MDC): This step calculates the matching degree of document i and annotator j, which is denoted as g ij by the similarity/distance between latent factors S i and A j . Intuitively, a basketball enthusiast j matches close to a document i that contains the "basket- ball" topic, which indicates that the "matching de- gree" of i and j is high with a large similarity. The inner product is used here, and it can be replaced by distance measures.</p><p>Weight Transformation (WT): We employ transformation to distinguish different scores ef- fectively. The activation function is sigmoid (soft- max) or tanh. Since most document labels are as- sumed to be discrete independent variables, we en- code V ij as a binary vector. The higher g ij of a label, the closer it is to the ground truth. Namely, we should weight these labels in such a way that if a label has high g ij , its weight will be increased; meanwhile, other labels should be punished. For sigmoid and tanh, the punishment is 1 − w ij and −w ij , respectively. Take four labels, the transfor- mation weight w ij and V ij = (1, 0, 0, 0) as an ex- ample, the label weight via sigmoid is</p><formula xml:id="formula_3">V new ij = (w ij , 1 − w ij , 1 − w ij , 1 − w ij ).</formula><p>Label Weighting (LW) and One-max Pooling: The final step is to output by integrating weight- ed labels, where the multiplicative combination is used in aggregation, and the output is the maxi- mum one of aggregated labels Z iC .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Parameter Estimation</head><p>Since training labels may contain noise, it is in- accurate to employ the back-propagation method which uses the error between predicted and train- ing labels as feedback for parameter estimation. Thus, we turn the estimation of model parameters W T and W F into a probabilistic problem. The graphical representation is illustrated in <ref type="figure" target="#fig_2">Fig. 2</ref>. Firstly, we define W = {W T , W F } for sim- plicity. Secondly, the parameter distribution is de- termined by the Maximum A Posteriori (MAP) principal:</p><formula xml:id="formula_4">W * = arg max W P r(W|V, T, F) = arg max W ∑ Z P r(Z)P r(W|V, T, F, Z).</formula><p>Finally, the following Expectation Maximiza- tion (EM) algorithm is used to estimate W * .</p><p>Initialization: We first initialize W randomly. The prior of ground truth Z can be set to 1/C or the frequency of each observable label.</p><p>Expectation (E): We then compute the expecta- tion of the joint log-likelihood of observable and hidden variables given W (i.e., the Q function), as follows:</p><formula xml:id="formula_5">Q(W) = E[lnP r(V, Z, T, F|W)] = E[lnP r(V|Z, T, F, W)]+E[lnP r(Z, T, F|W)].</formula><p>Maximization (M): According to the Q func- tion, the maximum likelihood of hidden variables is estimated by the gradient ascent method.</p><p>Alternation:</p><p>The above E and M steps are alter- nately performed until the likelihood converges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets and Baselines</head><p>As sentiment and emotion detection are widely studied in social media analysis ( <ref type="bibr" target="#b14">Wang and Pal, 2015</ref>), we test model performance based on the Stanford Twitter Sentiment (STS) and the Interna- tional Survey on Emotion Antecedents and Reac- tions (ISEAR) corpus. The original STS dataset ( <ref type="bibr" target="#b3">Go et al., 2009</ref>) contains 1.6 million tweets that were automatically labeled as positive or negative using emoticons as labels, in which 80K (5%) randomly selected tweets were used to speed up the training process, 16K (1%) randomly select- ed tweets were used as the validation set, and 359 tweets were manually annotated as the test- ing set (dos <ref type="bibr" target="#b2">Santos and Gatti, 2014)</ref>. ISEAR is composed of 7, 666 sentences annotated by 1, 096 participants with different culture backgrounds ( <ref type="bibr" target="#b8">Scherer and Wallbott, 1994)</ref>. These participants completed questionnaires about their 34 kinds of personal information (e.g., age, gender, city, coun- try, and religion), as well as their experiences and reactions over seven emotions. For the ISEAR corpus, we randomly selected 60% of sentences as the training set, 20% as the validation set, and the remaining 20% as the testing set.</p><p>We use the following models for comparison: Majority Voting (MV) ( <ref type="bibr" target="#b9">Sheng et al., 2008)</ref>, Maxi- mum Likelihood Estimator (MLE) ( <ref type="bibr" target="#b7">Raykar et al., 2010</ref>), and Generative model of Labels, Abilities and Difficulties (GLAD) ( <ref type="bibr" target="#b15">Whitehill et al., 2009</ref>). The baselines of MV and MLE are implement- ed by following <ref type="bibr" target="#b9">(Sheng et al., 2008;</ref><ref type="bibr" target="#b7">Raykar et al., 2010)</ref>, and GLAD is run by the software that is available in public at ( <ref type="bibr" target="#b15">Whitehill et al., 2009</ref>). We also implement the multivariate version of GLAD, called MGLAD as the baseline for the ISEAR corpus with seven emotions. Although there are some more recent models on label aggregation ( <ref type="bibr" target="#b5">Oyama et al., 2013</ref>) or refinement ( <ref type="bibr" target="#b11">Song et al., 2015;</ref><ref type="bibr" target="#b12">Ustinovskiy et al., 2016)</ref>, they either require additional features like users' reported confidence scores, or are only suitable to a corpus with one label for each document. To compare sentiment and emotion classification performance using the aggregated labels for training, we further apply the above noisy label aggregation models to a lin- ear Support Vector Machine (SVM) with squared hinge loss ( <ref type="bibr" target="#b1">Chang and Lin, 2011</ref>). As shown in the existing studies with refined labels, the lin- ear SVM performed well on sentiment classifi- cation of reviews ( <ref type="bibr" target="#b6">Pang et al., 2002</ref>) and tweets (Vo and Zhang, 2015).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental Design</head><p>To evaluate the performance of noisy label ag- gregation models, each instance should be anno- tated by multiple users. Unlike previous studies which introduced a parameter to disturb ground truth labels ( <ref type="bibr" target="#b9">Sheng et al., 2008</ref>) or employed online crowdsourcing systems ( <ref type="bibr" target="#b15">Whitehill et al., 2009;</ref><ref type="bibr" target="#b7">Raykar et al., 2010</ref>) to generate noisy an- notations, we design a new simulation approach by following the process of Profile Injection Attack in Collaborative Recommender Systems ( <ref type="bibr" target="#b16">Williams and Mobasher, 2006</ref>). This is because the existing methods can not assign multiple labels to each instance, or are difficult to generate virtual users and access their information (e.g., age and gender). In particular, the following steps have been performed. First, we generate virtual user- s with different features, making them the neigh- bors of existing (actual) annotators. For each di- mension of the actual annotators' features, we take the mean value if the attribute is continuous. For discrete attributes, we randomly select one type from the existing attribute values. If the dataset has no user features, we set it as a unit vector. Second, we generate document annotating vectors for virtual users. Each annotating vector is com- posed of three parts: annotating for filler instances (I F ), which is a set of randomly chosen filler in- stances drawn from the whole dataset, untagged instances (I ∅ ), and the target instance (i t ). The purpose of setting I F and I ∅ is to make the vir- tual user looks like an ordinary annotator. We select three simulation types from Profile Injec- tion Attack ( <ref type="bibr" target="#b16">Williams and Mobasher, 2006</ref>), i.e., random, average, and love/hate. In the random method, the label for each instance i ∈ I F is drawn from a normal distribution around the an- notations across the whole dataset, and the prob- ability of labeling correctly to i is 1/C. The cor- responding probabilities are 0.5 and 1 for the av- erage and love/hate methods, respectively. In all these methods, the annotation for i t is randomly selected from wrong labels.</p><p>We tune the number of topics D and annota- tor features U by performing a grid search over all D and U values, with D ∈ {2, 3, 4, ..., 10} on both datasets, U = 34 on ISEAR, and U ∈ {1, 10, 100, 500, 1000} on STS that contains user ID only. The value of K is set to the maximum of D and U . Based on the performance on the vali- dation set, we set D = 6, U = 1000, K = 1000 for STS, and D = 2, U = 34, K = 34 for ISEAR. For the sum of |I F | and |i t | (i.e., attack size) for each virtual user, we set it as the mean number of annotations in actual users. The sum of se- lecting i t in each simulation is called the profile size, and the percentage of the profile size is de- noted as o. Following the previous criterion of choosing the noise rate <ref type="bibr" target="#b0">(Auer and Cesa-Bianchi, 1998</ref>), we set o ∈ {0.05, 0.1, 0.2, 0.5}. Ac- cording to ( <ref type="bibr" target="#b12">Ustinovskiy et al., 2016)</ref>, each target instance except for those in I F is annotated by three users. Thus, the number of virtual users is set to 2oN . We set the parameter values of MV, MLE, and M/GLAD according to <ref type="bibr" target="#b9">(Sheng et al., 2008;</ref><ref type="bibr" target="#b7">Raykar et al., 2010;</ref><ref type="bibr" target="#b15">Whitehill et al., 2009)</ref>, and apply the grid search method to obtain the op- timal parameters for SVM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results and Analysis</head><p>Firstly, we evaluate the noisy label aggregation performance of different models by comparing the proportion of estimated labels which match the ac- tual categories (i.e., accuracy). The results are shown in <ref type="figure" target="#fig_3">Fig. 3</ref>, which indicates that our model performs the best under various conditions. From the aspect of simulation methods, the accuracy of the random one is the lowest and the Love/Hate one is the highest, which is consistent to the cor- rectly labeling probability for each method. The results of the random and average ones over STS are similar, because C = 2 on STS.</p><p>Particularly, our model performs better than baselines in aggregating noisy labels, especially when the noise scale becomes large. For instance, our model achieves 85% and 57% accuracies on STS and ISEAR when using the random method and o = 0.5, which indicates that our model has higher capability of recognizing adversarial noise (i t ). In the random method, we can also observe that the performance differences are more signifi- cant on ISEAR than STS. This is because ISEAR has more elaborate, i.e., 34 kinds of observable user information, which validates the joint influ- ence of users and documents on noisy label aggre- gation. To evaluate the performance differences statistically, we use the 12 groups of results over all methods and o values based on the convention- al significance level (i.e., p value) of 0.05. The p values of t-tests between our model and MV, M/GLAD, MLE are 0.0087, 0.0009, 0.0067 over STS, and 0.0535, 0.1037, 0.0007 over ISEAR, which indicates that the performance differences between our model and baselines are statistically significant on both datasets, except for MV and MGLAD in the love/hate method over ISEAR. The reason may be that each virtual user annotates around seven instances on ISEAR, and only one label is incorrect for the love/hate method, which makes the simple MV perform competitively. Secondly, we compare the classification perfor- mance of SVM using labels from different noisy label aggregation models for training. The accura- cies are shown in <ref type="figure" target="#fig_4">Fig. 4</ref>, in which dotted lines rep- resent results on benchmark datasets without con- ducting the Profile Injection Attack process. Com- pared to other methods, the performance of SVM based on the aggregated labels from our model is almost closer to that of SVM using benchmark datasets. For the average method and o = 0.2 over STS, we can observe that SVM in conjunc- tion with our model performs even better than that on the benchmark dataset. This is because emoti- cons are used as annotations for STS, which may introduce errors to the original labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In this paper, we proposed a network frame- work for noisy label aggregation by calculating the matching degree of documents and annotators. Experiments using a new simulation method of generating noisy labels validated the effectiveness of the proposed framework. As our model is linear in feature transformation, it is flexible to handle large-scale datasets. In the future, we plan to com- pare the model performance using different topic models, improve our model by exploiting the feed- back of a small proportion of refined labels, and recruit actual participants to provide noisy labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>488</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A ISEAR's Annotator Features</head><p>The ISEAR corpus contains 34 kinds of personal information of participants. For clarity, the total set of annotator features is given below.</p><p>• Subject's backgrounds: (1) city, (2) Country, (3) ID suffix, (4) gender, (5) age, (6) reli- gion, (7) practising religion, (8) father's job, (9) mother's job, and (10) field of study.</p><p>• Questionnaire: (11) when did the situation or event happen? (12) how long did you feel the emotion? (13) how intense was this feeling?</p><p>• Physiological symptoms of participants: <ref type="formula">(14)</ref> ergotropic arousal, (15) trophotropic arousal, and (16) felt temperature.</p><p>• Expressive behavior and other features of participants: <ref type="formula">(17)</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Noisy Label Aggregation Algorithm</head><p>In our method of noisy label aggregation as shown in Algorithm 1, the cost of calculating S and A by FcO (line 6) is linear to the number of Algorithm 1 Noisy Label Aggregation Input:</p><p>V: Observable labels; F: Features of users; ω: Words of documents; δ: Threshold of convergence. Output:</p><p>Aggregated labels. 1: T ← TE(ω); 2: Initialize parameter W randomly; 3: Q ← 0; 4: repeat</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>lastQ ← Q;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6:</head><p>{S, A} ← FcO(W, T, F);</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7:</head><p>for each i ∈ <ref type="bibr">[1, N ]</ref>  Q ← E-Step(Z iC );</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>15:</head><p>W ← M-Step(Q, W); 16: until |Q -lastQ| &lt; δ; 17: return Z i , i.e., the maximum one of Z iC . instances, i.e., O(N DK), and the total number of users, i.e., O(M U K), respectively. Before the EM iteration (lines 7 to 13), it takes O(N M (K + C)) to weigh all labels V. For each iteration of EM (lines 14 to 15), the optimization with stochas- tic gradient descent takes O(N M C +N K +M K) when each user annotates all documents. Assume that our algorithm converges after t iterations (t &lt; 10 in our experiments), the overall time complex- ity is O(N M (K + C)t), which is linear to the numbers of instances and users. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Gradient Derivation</head><formula xml:id="formula_6">= ∑ i Z iC (V ij − w ij )S ik .</formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Our proposed network framework.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Probabilistic graphical representation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Label aggregation performance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Classification performance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>do 8: for each j ∈ [1, M ] do 9: g ij = M DC(S i , A j ); 10: V new ij = W T (g ij , V ij , sigmoid); 11: end for 12: Z iC = LW(V new i ); 13: end for 14:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Given the estimated value of Z iC , the Q function can be calculated by Q(W) = ∑ ij Z iC lnV new ij + const. Since the vector V new ij has two possible values when using sigmoid (i.e., w ij and 1 − w ij ), the gradient of lnV new ij on parameter W i,k T is (V ij − w ij )A jk , i.e., [w ij (1 − w ij )]/w ij A jk and [−w ij (1−w ij )]/(1−w ij )A jk , respectively. Then, the gradient of Q on parameter W i,k T can be de- rived as ∂Q/∂W i,k T = ∑ j Z iC (V ij − w ij )A jk . Similarly, the gradient of Q on parameter W j,k F is given by ∂Q/∂W j,k F</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors are thankful to the reviewers for their constructive comments and suggestions on this pa-per. The work described in this paper was support-ed by the National Natural Science Foundation of China (61502545), a grant from the Research Grants Council of the Hong Kong Special Admin-istrative Region, China (UGC/FDS11/E03/16), the Start-Up Research Grant <ref type="bibr">(RG 37/2016</ref>, and the Internal Research Grant <ref type="bibr">(RG 66/2016</ref><ref type="bibr">(RG 66/-2017</ref> of The Education University of Hong Kong.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">On-line learning with malicious noise and the closure algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Mathematics and Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="83" to="99" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">LIBSVM: A library for support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of ACM Transactions on Intelligent Systems and Technology</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">27</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Deep convolutional neural networks for sentiment analysis of short texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">N</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gatti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on Computational Linguistics (COLING)</title>
		<meeting>the 25th International Conference on Computational Linguistics (COLING)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="69" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Twitter sentiment classification using distant supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Go</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bhayani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
<note type="report_type">Cs224n Project Report</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Label noise correction methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Nicholson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">S</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Data Science and Advanced Analytics (DSAA)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Accurate integration of crowdsourced labels using workers&apos; self-reported confidence scores</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Oyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Baba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sakurai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kashima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<meeting>the 23rd International Joint Conference on Artificial Intelligence (IJCAI)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2554" to="2560" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Thumbs up? sentiment classification using machine learning techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vaithyanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning from crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">C</forename><surname>Raykar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">H</forename><surname>Valadez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Florin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bogoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Moy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1297" to="1322" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Evidence for universality and cultural variation of differential emotion response patterning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Scherer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">G</forename><surname>Wallbott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Personality &amp; Social Psychology</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="310" to="328" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Get another lable? improving data quality and data mining using multiple, noisy labelers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">S</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Provost</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">G</forename><surname>Ipeirotis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (SIGKDD)</title>
		<meeting>the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (SIGKDD)</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="614" to="622" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Build emotion lexicon from the mood of crowd via topic-assisted joint non-negative matrix factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval (SIGIR)</title>
		<meeting>the 39th International ACM SIGIR conference on Research and Development in Information Retrieval (SIGIR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="773" to="776" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Spectral label refinement for noisy and missing text labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th AAAI Conference on Artificial Intelligence (AAAI)</title>
		<meeting>the 29th AAAI Conference on Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2972" to="2978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">An optimization framework for remapping and reweighting noisy relevance labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ustinovskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Fedorova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gusev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Serdyukov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)</title>
		<meeting>the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="105" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Target-dependent twitter sentiment classification with rich automatic features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<meeting>the 24th International Joint Conference on Artificial Intelligence (IJCAI)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1347" to="1353" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Detecting emotions in social media: A constrained optimization approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<meeting>the 24th International Joint Conference on Artificial Intelligence (IJCAI)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="996" to="1002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Whose vote should count more: Optimal integration of labels from labelers of unknown expertise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Whitehill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ruvolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bergsma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Movellan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd Annual Conference on Neural Information Processing Systems (NIPS)</title>
		<meeting>the 23rd Annual Conference on Neural Information Processing Systems (NIPS)</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="2035" to="2043" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Thesis: Profile injection attack detection for securing collaborative recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mobasher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Service Oriented Computing &amp; Applications</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="157" to="170" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Word embedding composition for data imbalances in sentiment and emotion classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Computation</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="226" to="240" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A biterm topic model for short texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on World Wide Web (WWW)</title>
		<meeting>the 22nd International Conference on World Wide Web (WWW)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1445" to="1456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Imbalanced multiple noisy labeling for supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">S</forename><surname>Sheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th AAAI Conference on Artificial Intelligence (AAAI)</title>
		<meeting>the 27th AAAI Conference on Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1080" to="1085" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
