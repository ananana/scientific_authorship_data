<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:15+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Distant Supervision for Relation Extraction with Matrix Completion</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>June 23-25 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miao</forename><surname>Fan</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">HTC Beijing Advanced Technology and Research Center</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deli</forename><surname>Zhao</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">HTC Beijing Advanced Technology and Research Center</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Zhou</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">HTC Beijing Advanced Technology and Research Center</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Fang Zheng</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><forename type="middle">Y</forename><surname>Chang</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">HTC Beijing Advanced Technology and Research Center</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Division of Technical Innovation and Development</orgName>
								<orgName type="department" key="dep2">Tsinghua National Laboratory for Information Science and Technology</orgName>
								<orgName type="department" key="dep3">Department of Computer Science and Technology</orgName>
								<orgName type="institution" key="instit1">CSLT</orgName>
								<orgName type="institution" key="instit2">Tsinghua University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Distant Supervision for Relation Extraction with Matrix Completion</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="839" to="849"/>
							<date type="published">June 23-25 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The essence of distantly supervised relation extraction is that it is an incomplete multi-label classification problem with sparse and noisy features. To tackle the s-parsity and noise challenges, we propose solving the classification problem using matrix completion on factorized matrix of minimized rank. We formulate relation classification as completing the unknown labels of testing items (entity pairs) in a sparse matrix that concatenates training and testing textual features with training labels. Our algorithmic framework is based on the assumption that the rank of item-by-feature and item-by-label joint matrix is low. We apply two optimization models to recover the underlying low-rank matrix leveraging the sparsity of feature-label matrix. The matrix completion problem is then solved by the fixed point continuation (FPC) algorithm, which can find the global optimum. Experiments on two widely used datasets with different dimensions of textual features demonstrate that our low-rank matrix completion approach significantly outperforms the baseline and the state-of-the-art methods.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Relation Extraction (RE) is the process of gen- erating structured relation knowledge from un- structured natural language texts. Traditional su- pervised methods ( <ref type="bibr" target="#b28">Zhou et al., 2005;</ref><ref type="bibr" target="#b0">Bach and Badaskar, 2007</ref>) on small hand-labeled corpora, such as MUC <ref type="bibr">1</ref> and ACE 2 , can achieve high pre- cision and recall. However, as producing hand- labeled corpora is laborius and expensive, the su- pervised approach can not satisfy the increasing demand of building large-scale knowledge reposi- tories with the explosion of Web texts. To address the lacking training data issue, we consider the dis- tant ( <ref type="bibr" target="#b18">Mintz et al., 2009</ref>) or weak ( <ref type="bibr" target="#b12">Hoffmann et al., 2011</ref>) supervision paradigm attractive, and we im- prove the effectiveness of the paradigm in this pa- per.</p><p>The intuition of the paradigm is that one can take advantage of several knowledge bases, such as WordNet <ref type="bibr">3</ref> , Freebase <ref type="bibr">4</ref> and YAGO 5 , to automatically label free texts, like Wikipedia <ref type="bibr">6</ref> and New York Times corpora <ref type="bibr">7</ref> , based on some heuristic alignment assumptions. An example accounting for the basic but practical assumption is illustrated in <ref type="figure" target="#fig_0">Figure 1</ref>, in which we know that the two entities (&lt;Barack Obama, U.S.&gt;) are not only involved in the rela- tion instances 8 coming from knowledge bases (President-of(Barack Obama, U.S.) and Born-in(Barack Obama, U.S.)),</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Error Matrix Completed Low−rank Matrix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Observed Sparse Matrix</head><p>Training Items</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Testing Items</head><p>Incomplete Labels Noisy Features <ref type="figure">Figure 2</ref>: The procedure of noise-tolerant low-rank matrix completion. In this scenario, distantly super- vised relation extraction task is transformed into completing the labels for testing items (entity pairs) in a sparse matrix that concatenates training and testing textual features with training labels. We seek to recover the underlying low-rank matrix and to complete the unknown testing labels simultaneously. but also co-occur in several relation mentions 9 appearing in free texts (Barack Obama is the 44th and current President of the U.S. and Barack Obama was born in Honolulu, Hawaii, U.S., etc.). We extract diverse textual features from all those relation mentions and combine them into a rich feature vector labeled by the relation names <ref type="bibr">(President-of and Born-in)</ref> to produce a weak training corpus for relation classification.</p><p>This paradigm is promising to generate large- scale training corpora automatically. However, it comes up against three technical challeges:</p><p>• Sparse features. As we cannot tell what kinds of features are effective in advance, we have to use NLP toolkits, such as Stanford CoreNLP <ref type="bibr">10</ref> , to extract a variety of textual fea- tures, e.g., named entity tags, part-of-speech tags and lexicalized dependency paths. Un- fortunately, most of them appear only once in the training corpus, and hence leading to very sparse features.</p><p>• Noisy features. Not all relation mentions express the corresponding relation instances. For example, the second relation mention in <ref type="figure" target="#fig_0">Figure 1</ref> does not explicitly describe any rela- tion instance, so features extracted from this sentence can be noisy. Such analogous cases commonly exist in feature extraction.</p><p>• Incomplete labels. Similar to noisy fea- <ref type="bibr">9</ref> The sentences that contain the given entity pair are called relation mentions.</p><p>10 http://nlp.stanford.edu/downloads/corenlp.shtml tures, the generated labels can be in- complete.</p><p>For example, the fourth re- lation mention in <ref type="figure" target="#fig_0">Figure 1</ref> should have been labeled by the relation Senate-of. However, the incomplete knowledge base does not contain the corresponding relation instance (Senate-of(Barack Obama, U.S.)). Therefore, the distant supervision paradigm may generate incomplete labeling corpora.</p><p>In essence, distantly supervised relation extrac- tion is an incomplete multi-label classification task with sparse and noisy features.</p><p>In this paper, we formulate the relation- extraction task from a novel perspective of using matrix completion with low rank criterion. To the best of our knowledge, we are the first to apply this technique on relation extraction with distant super- vision. More specifically, as shown in <ref type="figure">Figure 2</ref>, we model the task with a sparse matrix whose rows present items (entity pairs) and columns contain noisy textual features and incomplete relation la- bels. In such a way, relation classification is trans- formed into a problem of completing the unknown labels for testing items in the sparse matrix that concatenates training and testing textual features with training labels, based on the assumption that the item-by-feature and item-by-label joint matrix is of low rank. The rationale of this assumption is that noisy features and incomplete labels are semantically correlated. The low-rank factoriza- tion of the sparse feature-label matrix delivers the low-dimensional representation of de-correlation for features and labels.</p><p>We contribute two optimization models, DRM- C 11 -b and DRMC-1, aiming at exploiting the s- parsity to recover the underlying low-rank matrix and to complete the unknown testing labels simul- taneously. Moreover, the logistic cost function is integrated in our models to reduce the influence of noisy features and incomplete labels, due to that it is suitable for binary variables. We also modify the fixed point continuation (FPC) algorithm ) to find the global optimum.</p><p>Experiments on two widely used datasets demonstrate that our noise-tolerant approaches outperform the baseline and the state-of-the-art methods. Furthermore, we discuss the influence of feature sparsity, and our approaches consistently achieve better performance than compared meth- ods under different sparsity degrees.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>The idea of distant supervision was firstly pro- posed in the field of bioinformatics <ref type="bibr" target="#b7">(Craven and Kumlien, 1999</ref>). <ref type="bibr" target="#b22">Snow et al. (2004)</ref> used Word- Net as the knowledge base to discover more h- pyernym/hyponym relations between entities from news articles. However, either bioinformatic database or WordNet is maintained by a few ex- perts, thus hardly kept up-to-date.</p><p>As we are stepping into the big data era, the explosion of unstructured Web texts simulates us to build more powerful models that can automat- ically extract relation instances from large-scale online natural language corpora without hand- labeled annotation. <ref type="bibr" target="#b18">Mintz et al. (2009</ref><ref type="bibr">) adopted Freebase (Bollacker et al., 2008</ref><ref type="bibr" target="#b1">Bollacker et al., 2007)</ref>, a large-scale crowdsourcing knowl- edge base online which contains billions of rela- tion instances and thousands of relation names, to distantly supervise Wikipedia corpus. The basic alignment assumption of this work is that if a pair of entities participate in a relation, all sentences that mention these entities are labeled by that rela- tion name. Then we can extract a variety of textu- al features and learn a multi-class logistic regres- sion classifier. Inspired by multi-instance learn- ing <ref type="bibr" target="#b16">(Maron and Lozano-Pérez, 1998</ref>), <ref type="bibr" target="#b20">Riedel et al. (2010)</ref> relaxed the strong assumption and replaced all sentences with at least one sentence. Hoff- mann et al. (2011) pointed out that many entity pairs have more than one relation. They extend- 11 It is the abbreviation for Distant supervision for Relation extraction with Matrix Completion ed the multi-instance learning framework ( <ref type="bibr" target="#b20">Riedel et al., 2010</ref>) to the multi-label circumstance. Sur- deanu et al. <ref type="formula" target="#formula_2">(2012)</ref> proposed a novel approach to multi-instance multi-label learning for relation ex- traction, which jointly modeled all the sentences in texts and all labels in knowledge bases for a giv- en entity pair. Other literatures ( <ref type="bibr" target="#b24">Takamatsu et al., 2012;</ref><ref type="bibr" target="#b17">Min et al., 2013;</ref><ref type="bibr" target="#b27">Zhang et al., 2013;</ref><ref type="bibr" target="#b26">Xu et al., 2013</ref>) addressed more specific issues, like how to construct the negative class in learning or how to adopt more information, such as name en- tity tags, to improve the performance.</p><p>Our work is more relevant to <ref type="bibr">Riedel et al.'s (2013)</ref> which considered the task as a matrix fac- torization problem. Their approach is composed of several models, such as PCA ( <ref type="bibr" target="#b6">Collins et al., 2001</ref>) and collaborative filtering <ref type="bibr" target="#b14">(Koren, 2008)</ref>. However, they did not concern about the data noise brought by the basic assumption of distant super- vision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model</head><p>We apply a new technique in the field of ap- plied mathematics, i.e., low-rank matrix comple- tion with convex optimization. The breakthrough work on this topic was made by <ref type="bibr" target="#b4">Candès and Recht (2009)</ref> who proved that most low-rank matrices can be perfectly recovered from an incomplete set of entries. This promising theory has been successfully applied on many active research ar- eas, such as computer vision (Cabral et al., 2011), recommender system (Rennie and <ref type="bibr" target="#b19">Srebro, 2005)</ref> and system controlling ( <ref type="bibr" target="#b8">Fazel et al., 2001</ref>). Our models for relation extraction are based on the theoretic framework proposed by <ref type="bibr" target="#b9">Goldberg et al. (2010)</ref>, which formulated the multi-label trans- ductive learning as a matrix completion problem. The new framework for classification enhances the robustness to data noise by penalizing differen- t cost functions for features and labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Formulation</head><p>Suppose that we have built a training corpus for relation classification with n items (entity pairs), d-dimensional textual features, and t labels (rela- tions), based on the basic alignment assumption proposed by <ref type="bibr" target="#b18">Mintz et al. (2009)</ref>. Let X train ∈ R n×d and Y train ∈ R n×t denote the feature matrix and the label matrix for training, respectively. The linear classifier we adopt aims to explicitly learn the weight matrix W ∈ R d×t and the bias column vector b ∈ R t×1 with the constraint of minimizing the loss function l,</p><formula xml:id="formula_0">arg min W,b l(Y train , 1 X train b T W ), (1)</formula><p>where 1 is the all-one column vector. Then we can predict the label matrix Y test ∈ R m×t of m testing items with respect to the feature matrix X test ∈ R m×d . Let</p><formula xml:id="formula_1">Z = X train Y train X test Y test .</formula><p>This linear classification problem can be trans- formed into completing the unobservable entries in Y test by means of the observable entries in X train , Y train and X test , based on the assumption that the rank of matrix Z ∈ R (n+m)×(d+t) is low. The model can be written as, arg min</p><formula xml:id="formula_2">Z∈R (n+m)×(d+t) rank(Z) s.t. ∀(i, j) ∈ Ω X , z ij = x ij , (1 ≤ i ≤ n + m, 1 ≤ j ≤ d), ∀(i, j) ∈ Ω Y , z i(j+d) = y ij , (1 ≤ i ≤ n, 1 ≤ j ≤ t),<label>(2)</label></formula><p>where we use Ω X to represent the index set of ob- servable feature entries in X train and X test , and Ω Y to denote the index set of observable label en- tries in Y train . Formula (2) is usually impractical for real prob- lems as the entries in the matrix Z are corrupted by noise. We thus define</p><formula xml:id="formula_3">Z = Z * + E,</formula><p>where Z * as the underlying low-rank matrix</p><formula xml:id="formula_4">Z * = X * Y * = X * train Y * train X * test Y * test ,</formula><p>and E is the error matrix</p><formula xml:id="formula_5">E = E X train E Y train E Xtest 0 .</formula><p>The rank function in Formula (2) is a non-convex function that is difficult to be optimized. The sur- rogate of the function can be the convex nucle- ar norm ||Z|| * = σ k (Z) <ref type="bibr" target="#b4">(Candès and Recht, 2009)</ref>, where σ k is the k-th largest singular val- ue of Z. To tolerate the noise entries in the error matrix E, we minimize the cost functions C x and C y for features and labels respectively, rather than using the hard constraints in Formula (2).</p><formula xml:id="formula_6">According to Formula (1), Z * ∈ R (n+m)×(d+t) can be represented as [X * , WX * ] instead of [X * , Y * ]</formula><p>, by explicitly modeling the bias vector b. Therefore, this convex optimization model is called DRMC-b,</p><formula xml:id="formula_7">arg min Z,b µ||Z|| * + 1 |Ω X | (i,j)∈Ω X C x (z ij , x ij ) + λ |Ω Y | (i,j)∈Ω Y C y (z i(j+d) + b j , y ij ),<label>(3)</label></formula><p>where µ and λ are the positive trade-off weights. More specifically, we minimize the nuclear norm ||Z|| * via employing the regularization terms, i.e., the cost functions C x and C y for features and la- bels.</p><p>If we implicitly model the bias vector b, Z * ∈ R (n+m)×(1+d+t) can be denoted by</p><formula xml:id="formula_8">[1, X * , W X * ] instead of [X * , Y * ], in which W takes the role of [b T ; W] in DRMC-b. Then we derive another optimization model called DRMC- 1, arg min Z µ||Z|| * + 1 |Ω X | (i,j)∈Ω X C x (z i(j+1) , x ij ) + λ |Ω Y | (i,j)∈Ω Y C y (z i(j+d+1) , y ij ) s.t. Z(:, 1) = 1,<label>(4)</label></formula><p>where Z(:, 1) denotes the first column of Z. For our relation classification task, both features and labels are binary. We assume that the actual entry u belonging to the underlying matrix Z * is randomly generated via a sigmoid function (Jor- dan, 1995): P r(u|v) = 1/(1 + e −uv ), given the observed binary entry v from the observed sparse matrix Z. Then, we can apply the log-likelihood cost function to measure the conditional probabil- ity and derive the logistic cost function for C x and C y , C(u, v) = − log P r(u|v) = log(1 + e −uv ),</p><p>After completing the entries in Y test , we adop- t the sigmoid function to calculate the conditional probability of relation r j , given entity pair p i per- taining to y ij in Y test ,</p><formula xml:id="formula_9">P r(r j |p i ) = 1 1 + e −y ij , y ij ∈ Y test .</formula><p>Finally, we can achieve Top-N predicted relation instances via ranking the values of P r(r j |p i ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>842</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Algorithm</head><p>The matrix rank minimization problem is NP- hard. Therefore, <ref type="bibr">Candés and Recht (2009)</ref> sug- gested to use a convex relaxation, the nuclear nor- m minimization instead. Then,  proposed the fixed point continuation (FPC) algo- rithm which is fast and robust. Moreover, Gold- frab and Ma (2011) proved the convergence of the FPC algorithm for solving the nuclear norm mini- mization problem. We thus adopt and modify the algorithm aiming to find the optima for our noise- tolerant models, i.e., Formulae (3) and (4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Fixed point continuation for DRMC-b</head><p>Algorithm 1 describes the modified FPC algorithm for solving DRMC-b, which contains two steps for each iteration, Gradient step: In this step, we infer the ma- trix gradient g(Z) and bias vector gradient g(b) as follows,</p><formula xml:id="formula_10">g(z ij ) =        1 |Ω X | −x ij 1+e x ij z ij , (i, j) ∈ Ω X λ |Ω Y | −y i(j−d) 1+e y i(j−d) (z ij +b j ) , (i, j − d) ∈ Ω Y 0, otherwise and g(b j ) = λ |Ω Y | i:(i,j)∈Ω Y −y ij 1 + e y ij (z i(j+d) +b j ) .</formula><p>We use the gradient descents A = Z − τ z g(Z) and b = b − τ b g(b) to gradually find the global minima of the cost function terms in Formula (3), where τ z and τ b are step sizes.</p><p>Shrinkage step: The goal of this step is to min- imize the nuclear norm ||Z|| * in Formula (3). We perform the singular value decomposition (SVD) ( <ref type="bibr" target="#b11">Golub and Kahan, 1965</ref>) for A at first, and then cut down each singular value. During the iteration, any negative value in Σ − τ z µ is assigned by zero, so that the rank of reconstructed matrix Z will be reduced, where</p><formula xml:id="formula_11">Z = Umax(Σ − τ z µ, 0)V T .</formula><p>To accelerate the convergence, we use a con- tinuation method to improve the speed. µ is ini- tialized by a large value µ 1 , thus resulting in the fast reduction of the rank at first. Then the conver- gence slows down as µ decreases while obeying µ k+1 = max(µ k η µ , µ F ). µ F is the final value of µ, and η µ is the decay parameter.</p><p>For the stopping criteria in inner iterations, we define the relative error to measure the residual of matrix Z between two successive iterations,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 FPC algorithm for solving DRMC-b Input:</head><p>Initial matrix Z 0 , bias b 0 ; Parameters µ, λ;</p><p>Step sizes τ z , τ b .</p><formula xml:id="formula_12">Set Z = Z 0 , b = b 0 . foreach µ = µ 1 &gt; µ 2 &gt; ... &gt; µ F do while relative error &gt; ε do Gradient step: A = Z − τ z g(Z), b = b − τ b g(b).</formula><p>Shrinkage step:</p><formula xml:id="formula_13">UΣV T = SVD(A), Z = U max(Σ − τ z µ, 0) V T . end while end foreach Output: Completed Matrix Z, bias b. ||Z k+1 − Z k || F max(1, ||Z k || F ) ≤ ε,</formula><p>where ε is the convergence threshold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Fixed point continuation for DRMC-1</head><p>Algorithm 2 is similar to Algorithm 1 except for two differences. First, there is no bias vector b. Second, a projection step is added to enforce the first column of matrix Z to be 1. In addition, The matrix gradient g(Z) for DRMC-1 is</p><formula xml:id="formula_14">g(z ij ) =        1 |Ω X | −x i(j−1) 1+e x i(j−1) z ij , (i, j − 1) ∈ Ω X λ |Ω Y | −y i(j−d−1) 1+e y i(j−d−1) z ij , (i, j − d − 1) ∈ Ω Y 0, otherwise .</formula><p>Algorithm 2 FPC algorithm for solving DRMC-1 Input: Initial matrix Z 0 ; Parameters µ, λ;</p><p>Step sizes τ z .</p><formula xml:id="formula_15">Set Z = Z 0 . foreach µ = µ 1 &gt; µ 2 &gt; ... &gt; µ F do while relative error &gt; ε do Gradient step: A = Z − τ z g(Z).</formula><p>Shrinkage step:   <ref type="table"># of testing  tuples  % with more  than one label  # of features # of relation  labels  NYT'10  4,700  1,950  7.5%  244,903  51  NYT'13  8,077  3,716  0%  1,957  51   Table 1</ref>: Statistics about the two widely used datasets.</p><formula xml:id="formula_16">UΣV T = SVD(A), Z = U max(Σ − τ z µ, 0) V T .</formula><p>Model NYT'10 (θ=2) NYT'10 (θ=3) NYT'10 (θ=4) NYT'10 (θ=5) NYT'13 DRMC-b 51.4 ± 8.7 (51) 45.6 ± 3.4 (46) 41.6 ± 2.5 (43) 36.2 ± 8.8(37) 84.6 ± 19.0 (85) DRMC-1 16.0 ± 1.0 (16) 16.4 ± 1.1 <ref type="formula">(17)</ref> 16 ± 1.4 <ref type="formula">(17)</ref> 16.8 ± 1.5(17) 15.8 ± 1.6 (16) <ref type="table">Table 2</ref>: The range of optimal ranks for DRMC-b and DRMC-1 through five-fold cross validation. The threshold θ means filtering the features that appear less than θ times. The values in brackets pertaining to DRMC-b and DRMC-1 are the exact optimal ranks that we choose for the completed matrices on testing sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>In order to conduct reliable experiments, we adjust and estimate the parameters for our approaches, DRMC-b and DRMC-1, and compare them with other four kinds of landmark methods <ref type="bibr" target="#b18">(Mintz et al., 2009;</ref><ref type="bibr" target="#b12">Hoffmann et al., 2011;</ref><ref type="bibr" target="#b23">Surdeanu et al., 2012;</ref><ref type="bibr" target="#b21">Riedel et al., 2013</ref>) on two public datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Dataset</head><p>The two widely used datasets that we adopt are both automatically generated by aligning Freebase to New York Times corpora. The first dataset 12 , NYT'10, was developed by <ref type="bibr" target="#b20">Riedel et al. (2010)</ref>, and also used by <ref type="bibr" target="#b12">Hoffmann et al. (2011) and</ref><ref type="bibr" target="#b23">Surdeanu et al. (2012)</ref>. Three kinds of features, name- ly, lexical, syntactic and named entity tag fea- tures, were extracted from relation mentions. The second dataset 13 , NYT'13, was also released by <ref type="bibr" target="#b21">Riedel et al. (2013)</ref>, in which they only regarded the lexicalized dependency path between two enti- ties as features. <ref type="table">Table 1</ref> shows that the two datasets differ in some main attributes. More specifically, NYT'10 contains much higher dimensional fea- tures than NYT'13, whereas fewer training and testing items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Parameter setting</head><p>In this part, we address the issue of setting param- eters: the trade-off weights µ and λ, the step sizes τ z and τ b , and the decay parameter η µ . We set λ = 1 to make the contribution of the cost function terms for feature and label matrices equal in Formulae <ref type="formula" target="#formula_7">(3)</ref>  We follow the suggestion in ( <ref type="bibr" target="#b9">Goldberg et al., 2010)</ref> that µ starts at σ 1 η µ , and σ 1 is the largest singular value of the matrix Z. We set η µ = 0.01. The final value of µ, namely µ F , is equal to 0.01.  revealed that as long as the non- negative step sizes satisfy τ z &lt; min(</p><formula xml:id="formula_17">4|Ω Y | λ , |Ω X |) and τ b &lt; 4|Ω Y | λ(n+m)</formula><p>, the FPC algorithm will guaran- tee to converge to a global optimum. Therefore, we set τ z = τ b = 0.5 to satisfy the above con- straints on both two datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Rank estimation</head><p>Even though the FPC algorithm converges in iter- ative fashion, the value of ε varying with different datasets is difficult to be decided. In practice, we record the rank of matrix Z at each round of iter- ation until it converges at a rather small threshold ε = 10 −4 . The reason is that we suppose the opti- mal low-rank representation of the matrix Z con- veys the truly effective information about underly- ing semantic correlation between the features and the corresponding labels.</p><p>We use the five-fold cross validation on the val- idation set and evaluate the performance on each fold with different ranks. At each round of itera- tion, we gain a recovered matrix and average the F1 14 scores from Top-5 to Top-all predicted rela- tion instances to measure the performance. <ref type="figure" target="#fig_9">Figure  3</ref> illustrates the curves of average F1 scores. After recording the rank associated with the highest F1 score on each fold, we compute the mean and the standard deviation to estimate the range of optimal rank for testing. <ref type="table">Table 2</ref> lists the range of optimal ranks for DRMC-b and DRMC-1 on NYT'10 and NYT'13.       On both two datasets, we observe an identical phenomenon that the performance gradually in- creases as the rank of the matrix declines before reaching the optimum. However, it sharply de- creases if we continue reducing the optimal rank. An intuitive explanation is that the high-rank ma- trix contains much noise and the model tends to be overfitting, whereas the matrix of excessively low rank is more likely to lose principal information and the model tends to be underfitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Method Comparison</head><p>Firstly, we conduct experiments to compare our approaches with Mintz-09 ( <ref type="bibr" target="#b18">Mintz et al., 2009</ref> sity degree through a threshold θ which filters the features that appears less than θ times. They set θ = 5 in the original code by default. Therefore, we follow their settings and adopt the same way to filter the features. In this way, we guarantee the fair comparison for all methods. <ref type="figure" target="#fig_12">Figure 4</ref> (a) shows that our approaches achieve the significant improvement on performance.</p><p>We also perform the experiments to compare our approaches with the state-of-the-art NFE-13 <ref type="bibr">16</ref> ( <ref type="bibr" target="#b21">Riedel et al., 2013</ref>) and its sub-methods (N-13, F-13 and NF-13) on NYT'13 dataset. <ref type="figure" target="#fig_12">Figure 4</ref> (b) illustrates that our approaches still outperform the state-of-the-art methods. In practical application- s, we also concern about the precision on Top-N predicted relation instances. Therefore, We com- pare the precision of Top-100s, Top-200s and Top- 500s for DRMC-1, DRMC-b and the state-of-the- <ref type="bibr">16</ref> Readers may refer to the website, http://www.riedelcastro.org/uschema for the details of those methods. We bypass the description due to the limitation of space.    82.0% 80.0% Top-200 57.1% 77.0% 80.0% Top-500 37.2% 70.2% 77.0% Average 52.4% 76.4% 79.0% <ref type="table">Table 3</ref>: Precision of NFE-13, DRMC-b and DRMC-1 on Top-100, Top-200 and Top-500 pre- dicted relation instances.</p><p>art method NFE-13 ( <ref type="bibr" target="#b21">Riedel et al., 2013)</ref>. <ref type="table">Table 3</ref> shows that DRMC-b and DRMC-1 achieve 24.0% and 26.6% precision increments on average, re- spectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>We have mentioned that the basic alignment as- sumption of distant supervision ( <ref type="bibr" target="#b18">Mintz et al., 2009</ref>) tends to generate noisy (noisy features and incomplete labels) and sparse (sparse features) da- ta. In this section, we discuss how our approaches tackle these natural flaws.</p><p>Due to the noisy features and incomplete label- s, the underlying low-rank data matrix with tru- ly effective information tends to be corrupted and the rank of observed data matrix can be extremely high. <ref type="figure" target="#fig_13">Figure 5</ref> demonstrates that the ranks of da- ta matrices are approximately 2,000 for the initial optimization of DRMC-b and DRMC-1. Howev- er, those high ranks result in poor performance. As the ranks decline before approaching the op- timum, the performance gradually improves, im- plying that our approaches filter the noise in data and keep the principal information for classifica- tion via recovering the underlying low-rank data matrix.</p><p>Furthermore, we discuss the influence of the feature sparsity for our approaches and the state-  of-the-art methods. We relax the feature filtering threshold (θ = 4, 3, 2) in <ref type="bibr">Surdeanu et al.'s (2012)</ref> open source program to generate more sparse fea- tures from NYT'10 dataset. <ref type="figure" target="#fig_14">Figure 6</ref> shows that our approaches consistently outperform the base- line and the state-of-the-art methods with diverse feature sparsity degrees. <ref type="table">Table 2</ref> also lists the range of optimal rank for DRMC-b and DRMC- 1 with different θ. We observe that for each ap- proach, the optimal range is relatively stable. In other words, for each approach, the amount of tru- ly effective information about underlying seman- tic correlation keeps constant for the same dataset, which, to some extent, explains the reason why our approaches are robust to sparse features.</p><formula xml:id="formula_18">DRMC−1(Rank=2148) DRMC−b(Rank=2291) DRMC−1(Rank=1285) DRMC−b(Rank=1448) DRMC−1(Rank=404) DRMC−b(Rank=489) DRMC−1(Rank=17) DRMC−b(Rank=43) 0</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion and Future Work</head><p>In this paper, we contributed two noise-tolerant optimization models 17 , DRMC-b and DRMC-1, for distantly supervised relation extraction task from a novel perspective. Our models are based on matrix completion with low-rank criterion. Exper-</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Training corpus generated by the basic alignment assumption of distantly supervised relation extraction. The relation instances are the triples related to President Barack Obama in the Freebase, and the relation mentions are some sentences describing him in the Wikipedia.</figDesc><graphic url="image-1.png" coords="1,309.83,204.54,213.15,76.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Completed Matrix Z.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>(</head><label></label><figDesc>c) DRMC-b on NYT'13 validation set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Five-fold cross validation for rank estimation on two datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>), MultiR-11 (Hoffmann et al., 2011), MIML-12 and MIML-at-least-one-12 (Surdeanu et al., 2012) on NYT'10 dataset. Surdeanu et al. (2012) released the open source code 15 to reproduce the experi- mental results on those previous methods. More- over, their programs can control the feature spar- 15 http://nlp.stanford.edu/software/mimlre.shtml</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Method comparison on two testing sets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Precision-Recall curve for DRMC-b and DRMC-1 with different ranks on two testing sets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Feature sparsity discussion on NYT'10 testing set. Each row (from top to bottom, θ = 4, 3, 2) illustrates a suite of experimental results. They are, from left to right, five-fold cross validation for rank estimation on DRMC-b and DRMC-1, method comparison and precision-recall curve with different ranks, respectively.</figDesc></figure>

			<note place="foot" n="1"> http://www.itl.nist.gov/iaui/894.02/related projects/muc/ 2 http://www.itl.nist.gov/iad/mig/tests/ace/</note>

			<note place="foot" n="3"> http://wordnet.princeton.edu 4 http://www.freebase.com 5 http://www.mpi-inf.mpg.de/yago-naga/yago 6 http://www.wikipedia.org 7 http://catalog.ldc.upenn.edu/LDC2008T19 8 According to convention, we regard a structured triple r(ei, ej) as a relation instance which is composed of a pair of entities &lt;ei, ej&gt;and a relation name r with respect to them.</note>

			<note place="foot" n="14"> F 1 = 2×precision×recall precision+recall</note>

			<note place="foot" n="17"> The source code can be downloaded from https:// github.com/nlpgeek/DRMC/tree/master iments demonstrated that the low-rank representation of the feature-label matrix can exploit the underlying semantic correlated information for relation classification and is effective to overcome the difficulties incurred by sparse and noisy features and incomplete labels, so that we achieved significant improvements on performance. Our proposed models also leave open questions for distantly supervised relation extraction task. First, they can not process new coming testing items efficiently, as we have to reconstruct the data matrix containing not only the testing items but also all the training items for relation classification, and compute in iterative fashion again. Second, the volume of the datasets we adopt are relatively small. For the future work, we plan to improve our models so that they will be capable of incremental learning on large-scale datasets (Chang, 2011).</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">A review of relation extraction. Literature review for Language and Statistics II</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nguyen</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Badaskar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Freebase: A shared database of structured general human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Tufts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the national conference on Artificial Intelligence</title>
		<meeting>the national conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2007" />
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page">1962</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Freebase: a collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 ACM SIGMOD international conference on Management of data</title>
		<meeting>the 2008 ACM SIGMOD international conference on Management of data</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1247" to="1250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Matrix completion for multi-label image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ricardo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Cabral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Torre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>João</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Costeira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bernardino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="190" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Exact matrix completion via convex optimization. Foundations of Computational mathematics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Emmanuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Candès</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Recht</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="717" to="772" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Foundations of Large-Scale Multimedia Information Management and Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Edward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A generalization of principal components analysis to the exponential family</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjoy</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="617" to="624" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Constructing biological knowledge bases by extracting information from text sources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Craven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Kumlien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISMB</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">1999</biblScope>
			<biblScope unit="page" from="77" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A rank minimization heuristic with application to minimum order system approximation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maryam</forename><surname>Fazel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haitham</forename><surname>Hindi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen P</forename><surname>Boyd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">American Control Conference</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2001" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="4734" to="4739" />
		</imprint>
	</monogr>
	<note>Proceedings of the</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Transduction with matrix completion: Three birds with one stone</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junming</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Nowak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojin</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="757" to="765" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Convergence of fixed-point continuation algorithms for matrix rank minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><surname>Goldfarb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiqian</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations of Computational Mathematics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="183" to="210" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Calculating the singular values and pseudo-inverse of a matrix</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gene</forename><surname>Golub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Kahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Society for Industrial &amp; Applied Mathematics, Series B: Numerical Analysis</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="205" to="224" />
			<date type="published" when="1965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Knowledge-based weak supervision for information extraction of overlapping relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Congle</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011-06" />
			<biblScope unit="page" from="541" to="550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Why the logistic function? a tutorial discussion on probabilities and neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Cognitive Science Technical Report</title>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Factorization meets the neighborhood: a multifaceted collaborative filtering model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 14th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="426" to="434" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Fixed point and bregman iterative methods for matrix rank minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiqian</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><surname>Goldfarb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifeng</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Programming</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="321" to="353" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A framework for multiple-instance learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oded</forename><surname>Maron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomás</forename><surname>Lozano-Pérez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="570" to="576" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction with an incomplete knowledge base</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonan</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Gondek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Atlanta, Georgia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-06" />
			<biblScope unit="page" from="777" to="782" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction without labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Mintz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bills</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rion</forename><surname>Snow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1003" to="1011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Fast maximum margin matrix factorization for collaborative prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Jasson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Rennie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Srebro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd international conference on Machine learning</title>
		<meeting>the 22nd international conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="713" to="719" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Modeling relations and their mentions without labeled text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning and Knowledge Discovery in Databases</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="148" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Relation extraction with matrix factorization and universal schemas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><forename type="middle">M</forename><surname>Marlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Atlanta, Georgia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-06" />
			<biblScope unit="volume">848</biblScope>
			<biblScope unit="page" from="74" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning syntactic patterns for automatic hypernym discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rion</forename><surname>Snow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 17</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Multi-instance multi-label learning for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julie</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="455" to="465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Reducing wrong labels in distant supervision for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shingo</forename><surname>Takamatsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Issei</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroshi</forename><surname>Nakagawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th</title>
		<meeting>the 50th</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<title level="m">Annual Meeting of the Association for Computational Linguistics: Long Papers</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="721" to="729" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Filling knowledge base gaps for distant supervision of relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-08" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="665" to="670" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Towards accurate distant supervision for relational facts extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingxing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyu</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifang</forename><surname>Sui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-08" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="810" to="815" />
		</imprint>
	</monogr>
	<note>Sofia</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Exploring various knowledge in relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 43rd Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="427" to="434" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
