<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:53+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Stylometric Inquiry into Hyperpartisan and Fake News</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 15-20, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Potthast</surname></persName>
							<email>martin.potthast@uni-leipzig.de</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Leipzig University</orgName>
								<orgName type="institution" key="instit2">Bauhaus-Universität Weimar</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Kiesel</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Leipzig University</orgName>
								<orgName type="institution" key="instit2">Bauhaus-Universität Weimar</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Reinartz</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Leipzig University</orgName>
								<orgName type="institution" key="instit2">Bauhaus-Universität Weimar</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janek</forename><surname>Bevendorff</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Leipzig University</orgName>
								<orgName type="institution" key="instit2">Bauhaus-Universität Weimar</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benno</forename><surname>Stein</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Leipzig University</orgName>
								<orgName type="institution" key="instit2">Bauhaus-Universität Weimar</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A Stylometric Inquiry into Hyperpartisan and Fake News</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="231" to="240"/>
							<date type="published">July 15-20, 2018</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.5281/zenodo.1239675</idno>
					<note>231</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We report on a comparative style analysis of hyperpartisan (extremely one-sided) news and fake news. A corpus of 1,627 articles from 9 political publishers, three each from the mainstream, the hyperpar-tisan left, and the hyperpartisan right, have been fact-checked by professional journalists at BuzzFeed: 97% of the 299 fake news articles identified are also hyperpartisan. We show how a style analysis can distinguish hyperpartisan news from the mainstream (F 1 = 0.78), and satire from both (F 1 = 0.81). But stylometry is no silver bullet as style-based fake news detection does not work (F 1 = 0.46). We further reveal that left-wing and right-wing news share significantly more stylistic similarities than either does with the mainstream. This result is robust: it has been confirmed by three different modeling approaches, one of which employs Unmasking in a novel way. Applications of our results include partisanship detection and pre-screening for semi-automatic fake news detection.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The media and the public are currently discussing the recent phenomenon of "fake news" and its po- tential role in swaying elections, how it may af- fect society, and what can and should be done about it. Prone to misunderstanding and misue, the term "fake news" arose from the observation that, in social media, a certain kind of 'news' spreads much more successfully than others, and this kind of 'news' is typically extremely one-sided (hyper- partisan), inflammatory, emotional, and often rid- dled with untruths. Although traditional yellow press has been spreading 'news' of varying de- grees of truthfulness long before the digital revolu- tion, its amplification over real news within social media gives many people pause. The fake news hype caused a widespread disillusionment about so- cial media, and many politicians, news publishers, IT companies, activists, and scientists concur that this is where to draw the line. For all their good in- tentions, however, it must be drawn very carefully (if at all), since nothing less than free speech is at stake-a fundamental right of every free society.</p><p>Many favor a two-step approach where fake news items are detected and then countermeasures are implemented to foreclose rumors and to dis- courage repetition. While some countermeasures are already tried in practice, such as displaying warnings and withholding ad revenue, fake news detection is still in its infancy. At any rate, a near- real time reaction is crucial: once a fake news item begins to spread virally, the damage is done and un- doing it becomes arduous. Since knowledge-based and context-based approaches to fake news detec- tion can only be applied after publication, i.e., as news events unfold and as social interactions occur, they may not be fast enough.</p><p>We have identified style-based approaches as a viable alternative, allowing for instantaneous re- actions, albeit not to fake news, but to hyperpar- tisanship. In this regard we contribute (1) a large news corpus annotated by experts with respect to veracity and hyperpartisanship, (2) extensive exper- iments on discriminating fake news, hyperpartisan news, and satire based solely on writing style, and (3) validation experiments to verify our finding that the writing style of the left and the right have more in common than any of the two have with the main- stream, applying Unmasking in a novel way.</p><p>After a review of related work, Section 3 details the corpus and its construction, Section 4 intro- duces our methodology, and Section 5 reports the results of the aforementioned experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Approaches to fake news detection divide into three categories ( <ref type="figure">Figure 1</ref>): they can be knowledge-based (by relating to known facts), context-based (by an- alyzing news spread in social media), and style- based (by analyzing writing style).</p><p>Knowledge-based fake news detection. Methods from information retrieval have been proposed early on to determine the veracity of web docu- ments. For example, <ref type="bibr" target="#b9">Etzioni et al. (2008)</ref> propose to identify inconsistencies by matching claims ex- tracted from the web with those of a document in question. Similarly, <ref type="bibr" target="#b17">Magdy and Wanas (2010)</ref> measure the frequency of documents that support a claim. Both approaches face the challenges of web data credibility, namely expertise, trustworthiness, quality, and reliability ( <ref type="bibr" target="#b10">Ginsca et al., 2015)</ref>.</p><p>Other approaches rely on knowledge bases, in- cluding the semantic web and linked open data. <ref type="bibr" target="#b34">Wu et al. (2014)</ref> "perturb" a claim in question to query knowledge bases, using the result variations as indicator of the support a knowledge base of- fers for the claim. <ref type="bibr" target="#b7">Ciampaglia et al. (2015)</ref> use the shortest path between concepts in a knowledge graph, whereas <ref type="bibr" target="#b24">Shi and Weninger (2016)</ref> use a link prediction algorithm. However, these approaches are unsuited for new claims without corresponding entries in a knowledge base, whereas knowledge bases can be manipulated ( <ref type="bibr" target="#b11">Heindorf et al., 2016</ref>).</p><p>Context-based fake news detection. Here, fake news items are identified via meta information and spread patterns. For example, <ref type="bibr" target="#b15">Long et al. (2017)</ref> show that author information can be a useful fea- ture for fake news detection, and <ref type="bibr" target="#b8">Derczynski et al. (2017)</ref> attempt to determine the veracity of a claim based on the conversation it sparks on Twitter as one of the RumourEval tasks. The Facebook analy- sis of <ref type="bibr" target="#b18">Mocanu et al. (2015)</ref> shows that unsubstan- tiated claims spread as widely as well-established ones, and that user groups predisposed to conspir- acy theories are more open to sharing the former. Similarly, <ref type="bibr" target="#b0">Acemoglu et al. (2010)</ref>, <ref type="bibr" target="#b14">Kwon et al. (2013)</ref>, <ref type="bibr" target="#b16">Ma et al. (2017)</ref>, and  model the spread of (mis-)information, while <ref type="bibr" target="#b5">Budak et al. (2011)</ref> and <ref type="bibr" target="#b19">Nguyen et al. (2012)</ref> propose algorithms to limit its spread. The efficacy of coun- termeasures like debunking sites is studied by <ref type="bibr" target="#b28">Tambuscio et al. (2015)</ref>. While achieving good results, context-based approaches suffer from working only a posteriori, requiring large amounts of data, and disregarding the actual news content. Social network analysis Fake news detection <ref type="bibr" target="#b15">Long et al., 2017</ref><ref type="bibr" target="#b18">Mocanu et al., 2015</ref><ref type="bibr" target="#b0">Acemoglu et al., 2010</ref><ref type="bibr" target="#b14">Kwon et al., 2013</ref><ref type="bibr" target="#b16">Ma et al., 2017</ref><ref type="bibr" target="#b5">Budak et al., 2011</ref><ref type="bibr" target="#b19">Nguyen et al. 2012</ref><ref type="bibr" target="#b8">Derczynski et al., 2017</ref><ref type="bibr" target="#b28">Tambuscio et al., 2015</ref><ref type="bibr" target="#b1">Afroz et al., 2012</ref><ref type="bibr" target="#b3">Badaskar et al., 2008</ref><ref type="bibr" target="#b23">Rubin et al., 2016</ref><ref type="bibr" target="#b21">Rashkin et al., 2017</ref><ref type="bibr" target="#b12">Horne and Adali, 2017</ref><ref type="bibr" target="#b20">Pérez-Rosas et al., 2017</ref><ref type="bibr" target="#b31">Wang et al., 2017</ref><ref type="bibr" target="#b4">Bourgonje et al., 2017</ref><ref type="bibr" target="#b34">Wu et al., 2014</ref><ref type="bibr" target="#b7">Ciampaglia et al, 2015</ref><ref type="bibr" target="#b24">Shi and Weninger, 2016</ref><ref type="bibr">Etzioni et al., 2018</ref><ref type="bibr" target="#b17">Magdy and Wanas, 2010</ref><ref type="bibr" target="#b10">Ginsca et al., 2015</ref> Figure 1: Taxonomy of paradigms for fake news detec- tion alongside a selection of related work.</p><p>Style-based fake news detection. Deception detec- tion originates from forensic linguistics and builds on the Undeutsch hypothesis-a result from foren- sic psychology which asserts that memories of real- life, self-experienced events differ in content and quality from imagined events <ref type="bibr" target="#b29">(Undeutsch, 1967)</ref>. The hypothesis led to the development of forensic tools to assess testimonies at the statement level. Some approaches operationalize deception detec- tion at scale to detect uncertainty in social media posts, for example  and . In this regard,  use rhetorical structure theory as a measure of story coherence and as an indicator for fake news. Re- cently, <ref type="bibr" target="#b31">Wang (2017)</ref> collected a large dataset con- sisting of sentence-length statements along their veracity from the fact-checking site PolitiFact.com, and then used style features to detect false state- ments. A related task is stance detection, where the goal is to detect the relation between a claim about an article, and the article itself ( <ref type="bibr" target="#b4">Bourgonje et al., 2017</ref>). Most prominently, stance detection was the task of the Fake News Challenge 1 which ran in 2017 and received 50 submissions, albeit hardly any participants published their approach.</p><p>Where deception detection focuses on single statements, style-based text categorization as pro- posed by <ref type="bibr" target="#b2">Argamon-Engelson et al. (1998)</ref> assesses entire texts. Common applications are author pro- filing (age, gender, etc.) and genre classification. Though susceptible to authors who can modify their writing style, such obfuscations may be de- tectable (e.g., <ref type="bibr" target="#b1">Afroz et al. (2012)</ref>). As an early precursor to fake news detection, <ref type="bibr" target="#b3">Badaskar et al. (2008)</ref> train models to identify news items that were automatically generated. Currently, text cate- gorization methods for fake news detection focus mostly on satire detection (e.g., <ref type="bibr" target="#b23">Rubin et al. (2016)</ref>, ). <ref type="bibr" target="#b21">Rashkin et al. (2017)</ref> perform a statistical analysis of the stylistic differences be- tween real, satire, hoax, and propaganda news. We make use of their results by incorporating the best- performing style features identified.</p><p>Finally, two preprint papers have been recently shared. <ref type="bibr" target="#b12">Horne and Adali (2017)</ref> use style features for fake news detection. However, the relatively high accuracies reported must be taken with a grain of salt: their two datasets comprise only 70 news ar- ticles each, whose ground-truth is based on where an article came from, instead of resulting from a per-article expert review as in our case; their final classifier uses only 4 features (number of nouns, type-token ratio, word count, number of quotes), which can be easily manipulated; and based on their experimental setup, it cannot be ruled out that the classifier simply differentiates news por- tals rather than fake and real articles. We avoid this problem by testing our classifiers on articles from portals which were not represented in the training data. Similarly, <ref type="bibr" target="#b20">Pérez-Rosas et al. (2017)</ref> also report on constructing two datasets compris- ing around 240 and 200 news article excerpts (i.e., the 5-sentence lead) with a balanced distribution of fake vs. real. The former was collected via crowd- sourcing, asking workers to write a fake news item based on a real news item, the latter was collected from the web. For style analysis, the former dataset may not be suitable, since the authors note them- selves that "workers succeeded in mimicking the reporting style from the original news". The lat- ter dataset encompasses only celebrity news (i.e., yellow press), which introduces a bias. Their fea- ture selection follows that of <ref type="bibr" target="#b23">Rubin et al. (2016)</ref>, which is covered by our experiments, but also in- corporates topic features, rendering the resulting classifier not generalizable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The BuzzFeed-Webis Fake News Corpus</head><p>This section introduces the BuzzFeed-Webis Fake News Corpus 2016, detailing its construction and annotation by professional journalists employed at BuzzFeed, as well as key figures and statistics. <ref type="bibr">2</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Corpus Construction</head><p>The corpus encompasses the output of 9 publish- ers on 7 workdays close to the US presidential elections 2016, namely September 19 to 23, 26, and 27. <ref type="table">Table 1</ref>   <ref type="formula">(2016)</ref> reported key insights as a data journalism article. The annotations were published alongside the ar- ticle. <ref type="bibr">3</ref> However, this data only comprises URLs to the original Facebook posts. To construct our corpus, we archived the posts, the linked articles, and attached media as well as relevant meta data to ensure long-term availability. Due to the rapid pace at which the publishers change their websites, we were able to recover only 1,627 articles, 826 main- stream, 256 left-wing, and 545 right-wing.</p><p>Manual fact-checking. A binary distinction be- tween fake and real news turned out to be infeasi- ble, since hardly any piece of fake news is entirely false, and pieces of real news may not be flawless. Therefore, posts were rated "mostly true," "mixture of true and false," "mostly false," or, if the post was opinion-driven or otherwise lacked a factual claim, "no factual content." Four BuzzFeed journalists worked on the manual fact-checks of the news arti- cles: to minimize costs, each article was reviewed only once and articles were assigned round robin. The ratings "mixture of true and false" and "mostly false" had to be justified, and, when in doubt about a rating, a second opinion was collected, whereas disagreements were resolved by a third one. Fi- nally, all news rated "mostly false" underwent a final check to ensure the rating was justified, lest the respective publishers would contest it.</p><p>The journalists were given the following guidance:</p><p>Mostly true: The post and any related link or image are based on factual information and por- tray it accurately. The authors may interpret the event/info in their own way, so long as they do not misrepresent events, numbers, quotes, reactions, etc., or make information up. This rating does not allow for unsupported speculation or claims.</p><p>Mixture of true and false (mix, for short): Some elements of the information are factually accurate, but some elements or claims are not. This rating should be used when speculation or unfounded claims are mixed with real events, numbers, quotes, etc., or when the headline of the link being shared makes a false claim but the text of the story is largely accurate. It should also only be used when the unsupported or false information is roughly equal to the accurate information in the post or link. Finally, use this rating for news articles that are based on unconfirmed information.</p><p>Mostly false: Most or all of the information in the post or in the link being shared is inaccurate. This should also be used when the central claim being made is false.</p><p>No factual content (n/a, for short): This rating is used for posts that are pure opinion, comics, satire, or any other posts that do not make a factual claim. This is also the category to use for posts that are of the "Like this if you think..." variety.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Limitations</head><p>Given the significant workload (i.e., costs) required to carry out the aforementioned annotations, the corpus is restricted to the given temporal period and biased toward the US culture and political land- scape, comprising only English news articles from a limited number of publishers. Annotations were recorded at the article level, not at statement level. For text categorization, this is sufficient. At the time of writing, our corpus is the largest of its kind that has been annotated by professional journalists. <ref type="table">Table 1</ref> shows the fact-checking results and some key statistics per article. Unsurprisingly, none of the mainstream articles are mostly false, whereas 8 across all three publishers are a mixture of true and false. Disregarding non-factual articles, a little more than a quarter of all hyperpartisan left-wing articles were found faulty: 15 articles mostly false, and 51 a mixture of true and false. Publisher "The Other 98%" sticks out by achieving an almost per- fect score. By contrast, almost 45% of the right- wing articles are a mixture of true and false <ref type="formula">(153)</ref> or mostly false (72). Here, publisher "Right Wing News" sticks out by supplying more than half of mixtures of true and false alone, whereas mostly false articles are equally distributed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Corpus Statistics</head><p>Regarding key statistics per article, it is interest- ing that the articles from all mainstream publish- ers are on average about 20 paragraphs long with word counts ranging from 550 words on average at ABC News to 800 at Politico. Except for one pub- lisher, left-wing articles and right-wing articles are shorter on average in terms of paragraphs as well as word count, averaging at about 420 words and 400 words, respectively. Left-wing articles quote on average about 10 words more than the mainstream, and right-wing articles 6 words more. When arti- cles comprise links, they are usually external ones, whereas ABC News rather uses internal links, and only half of the links found at Politico articles are external. Left-wing news articles stick out by con- taining almost double the amount of links across publishers than mainstream and right-wing ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Operationalizing Fake News</head><p>In our experiments, we operationalize the category of fake news by joining the articles that were rated mostly false with those rated a mixture of true and false. Arguably, the latter may not be exactly what is deemed "fake news" (as in: a complete fabrica- tion), however, practice shows fake news are hardly ever devoid of truth. More often, true facts are mis- construed or framed badly. In our experiments, we hence call mostly true articles real news, mostly false plus mixtures of true and false-except for satire-fake news, and disregard all articles rated non-factual.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Methodology</head><p>This section covers our methodology, including our feature set to capture writing style, and a brief recap of Unmasking by <ref type="bibr" target="#b13">Koppel et al. (2007)</ref>, which we employ for the first time to distinguish genre styles as opposed to author styles. For sake of reproducibility, all our code has been published. <ref type="bibr">4</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Style Features and Feature Selection</head><p>Our writing style model incorporates common fea- tures as well as ones specific to the news domain. The former are n-grams, n in <ref type="bibr">[1,</ref><ref type="bibr">3]</ref>, of characters, stop words, and parts-of-speech. Further, we em- ploy 10 readability scores <ref type="bibr">5</ref> and dictionary features, each indicating the frequency of words from a tailor-made dictionary in a document, using the General Inquirer Dictionaries as a basis <ref type="bibr" target="#b27">(Stone et al., 1966</ref>). The domain-specific features include ratios of quoted words and external links, the num- ber of paragraphs, and their average length.</p><p>In each of our experiments, we carefully select from the aforementioned features the ones worth- while using: all features are discarded that are hardly represented in our corpus, namely word to- kens that occur in less than 2.5% of the documents, and n-gram features that occur in less than 10% of the documents. Discarding these features pre- vents overfitting and improves the chances that our model will generalize.</p><p>If not stated otherwise, our experiments share a common setup. In order to avoid biases from the respective training sets, we balance them us- ing oversampling. Furthermore, we perform 3-fold cross-validation where each fold comprises one publisher from each orientation, so that the clas- sifier does not learn a publisher's style. For non- Unmasking experiments we use WEKA's random forest implementation with default settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Unmasking Genre Styles</head><p>Unmasking, as proposed by <ref type="bibr" target="#b13">Koppel et al. (2007)</ref>, is a meta learning approach for authorship verifi- cation. We study for the first time whether it can be used to assess the similarity of more broadly defined style categories, such as left-wing vs. right- wing vs. mainstream news. This way, we uncover relations between the writing styles that people may involuntarily adopt as per their political orientation.</p><p>Originally, Unmasking takes two documents as input and outputs its confidence whether they have been written by the same author. Three steps are taken to accomplish this: first, each document is chunked into a set of at least 500-word long chunks; second, classification errors are measured while it- eratively removing the most discriminative features of a style model consisting of the 250 most fre- quent words, separating the two chunk sets with a linear classifier; and third, the resulting classifica- tion accuracy curves are analyzed with regard to their slope. A steep decrease is more likely than a shallow decrease if the two documents have been written by the same author, since there are pre- sumably less discriminating features between docu- ments written by the same author than between doc- uments written by different authors. Training a clas- sifier on many examples of error curves obtained from same-author document pairs and different- author document pairs yields an effective author- ship verifier-at least for long documents that can be split up into a sufficient number of chunks.</p><p>It turns out that what applies to the style of au- thors also applies to genre styles. We adapt Un- masking by skipping its first step and using two sets of documents (e.g., left-wing articles and right- wing articles) as input. When plotting classification error curves for visual inspection, steeper decreases in these plots, too, indicate higher style similarity of the two input document sets, just as with chunk sets of two documents written by the same author.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Baselines</head><p>We employ four baseline models: a topic-based bag of words model, often used in the literature, but less practical since news topics change frequently and drastically; a model using only the domain-specific news style features to check whether the differences between categories measured as corpus statistics play a significant role; and naive baselines that clas- sify all items into one of the categories in question, relating our results to the class distributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Performance Measures</head><p>Classification performance is measured as accuracy, and class-wise precision, recall, and F 1 . We favor these measures over, e.g., areas under the ROC curve or the precision recall curve for simplicity sake. Also, the tasks we are tackling are new, so that little is known to date about user preferences. This is also why we chose the evenly-balanced F 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>We report on the results of two series of experi- ments that investigate style differences and similar- ities between hyperpartisan and mainstream news, and between fake, real, and satire news, shedding light on the following questions:</p><p>1. Can (left/right) hyperpartisanship be distin- guished from the mainstream? 2. Is style-based fake news detection feasible? 3. Can fake news be distinguished from satire? Our first experiment addressing the first ques- tion uncovered an odd behavior of our classifier: it would often misjudge left-wing for right-wing news, while being much better at distinguishing both combined from the mainstream. To explain this behavior, we hypothesized that maybe the writ- ing style of the hyperpartisan left and right are more similar to one another than to the mainstream. To investigate this hypothesis, we devised two additional validation experiments, yielding three sources of evidence instead of just one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Hyperpartisanship vs. Mainstream</head><p>A. Predicting orientation. <ref type="table" target="#tab_1">Table 2</ref> shows the classi- fication performance of a ternary classifier trained to discriminate left, right, and mainstream-an ob- vious first experiment for our dataset. Separating the left and right orientation from the mainstream does not work too well: the topic baseline out- performs the style-based models with regard to accuracy, whereas the results for class-wise pre- cision and recall are a mixed bag. The left-wing articles are apparently significantly more difficult to be identified compared to articles from the other two orientations. When we inspected the confu- sion matrix (not shown), it turned out that 66% of misclassifications of left-wing articles are falsely classified as right-wing articles, whereas 60% of all misclassified right-wing articles are classified as mainstream articles. Misclassified mainstream arti- cles spread almost evenly across the other classes.</p><p>The poor performance of the domain-specific news style features by themselves demonstrate that orientation cannot be discriminated based on the basic corpus characteristics observed with respect to paragraphs, quotations, and hyperlinks. This holds for all subsequent experiments.</p><p>B. Predicting hyperpartisanship. Given the appar- ent difficulty of telling apart individual orientations, we did not frantically add features or switch classi- fiers to make it work. Rather, we trained a binary all left right main. left right main. left right main.</p><p>Style 0.60 0.21 0.56 0.75 0.20 0.59 0.74 0.20 0.57 0.75 Topic 0.64 0.24 0.62 0.72 0.15 0.54 0.86 0.19 0.58 0.79 News style 0.39 0.09 0.35 0.59 0.14 0.36 0.49 0.11 0.    classifier to discriminate hyperpartisanship in gen- eral from the mainstream. <ref type="table" target="#tab_2">Table 3</ref> shows the per- formance values. This time, the best classification accuracy of 0.75 at a remarkable 0.89 recall for the hyperpartisan class is achieved by the style-based classifier, outperforming the topic baseline.</p><p>Comparing <ref type="table" target="#tab_1">Table 2 and Table 3</ref>, we were left with a riddle: all other things being equal, how could it be that hyperpartisanship in general can be much better discriminated from the mainstream than individual orientation? Attempts to answer this question gave rise to our aforementioned hy- pothesis that, perhaps, the writing style of hyper- partisan left and right are not altogether different, despite their opposing agendas. Or put another way, if style and topic are orthogonal concepts, then be- ing an extremist should not exert a different style dependent on political orientation. Excited, we sought ways to independently disprove the hypoth- esis, and found two: Experiments C and D.</p><p>C. Validation using leave-out classification. If left- wing and right-wing articles have a more similar style than either of them compared to mainstream articles, then what class would a binary classifier as- sign to a left-wing article, if it were trained to distin- guish only the right-wing from the mainstream, and vice versa? <ref type="table" target="#tab_3">Table 4</ref> shows the results of this experi- ment. As indicated by proportions well above 0.50, full style-based classifiers have a tendency of clas- sifying left as right and right as left. The topic baseline, though, gets confused especially when omitting right articles from the training set with performance close to random. The fact that the topic baseline works better when omitting left from the training set may be explainable: leading up to the elections, the hyperpartisan left was often merely reacting to topics prompted by the hyper- partisan right, instead of bringing up their own.</p><p>D. Validation using Unmasking. Based on Kop- pel et al.'s original approach in the context of au- thorship verification, for the first time, we gener- alize Unmasking to assess genre styles: just like author style similarity, genre style similarity will be characterized by the slope of a given Unmasking curve, where a steeper decrease indicates higher similarity. We apply Unmasking as described in Section 4.2 onto pairs of sets of left, right, and mainstream articles. <ref type="figure" target="#fig_4">Figure 2</ref> shows the result- ing Unmasking curves (Unmasking is symmetrical, hence three curves). The curves are averaged over 5 runs, where each run comprised sets of 100 arti- cles from each orientation. In case of the left-wing orientation, where less than 500 articles are avail- able in our corpus, once all of them had been used, they were shuffled again to select articles for the remainder of the runs. As can be seen, the curve comparing left vs. right has a distinctly steeper slope than either of the others. This result hence matches the findings of the previous experiments.</p><p>With caution, we conclude that the evidence gained from our three independent experimental setups supports our hypothesis that the hyperparti- san left and the hyperpartisan right have more in common in terms of writing style than any of the two have with the mainstream. Another more tangi- ble (e.g., practical) outcome of Experiment B is the finding that hyperpartisan news can apparently be  discriminated well from the mainstream: in particu- lar the high recall of 0.89 at a reasonable precision of 0.69 gives us confidence that, with some fur- ther effort, a practical classifier can be built that detects hyperpartisan news at scale and in real time, since an article's style can be assessed immediately without referring to external information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Fake vs. Real (vs. Satire)</head><p>This series of experiments targets research ques- tions (2) and (3). Again, we conduct three experi- ments, where the first is about predicting veracity, and the last two about discriminating satire.</p><p>A. Predicting veracity. When taking into account that the mainstream news publishers in our corpus did not publish any news items that are mostly false, and only very few instances that are mixtures of true and false, we may safely disregard them for the task of fake news detection. A reliable classifier for hyperpartisan news can act as a pre- filter for a subsequent, more in-depth fake news detection approach, which may in turn be tailored to a much more narrowly defined classification task. We hence use only the left-wing articles and the right-wing articles of our corpus for our attempt at a style-based fake news classifier. <ref type="table" target="#tab_6">Table 5</ref> shows the performance values for a generic classifier that predicts fake news across ori- entations, and orientation-specific classifiers that have been individually trained on articles from ei- ther orientation. Although all classifiers outper- form the naive baselines of classifying everything into one of the classes in terms of precision, the slight increase comes at the cost of a large decrease in recall. While the orientation-specific classifiers are slightly better for most metrics, none of them outperform the naive baselines regarding the F - Measure. We conclude that style-based fake news classification simply does not work in general.    B. Predicting satire. Yet, not all fake news are the same. One should distinguish satire from the rest, which takes the form of news but lies more or less obviously to amuse its readers. Regardless the problems that spreading fake news may cause, satire should never be filtered, but be discriminated from other fakes. <ref type="table" target="#tab_7">Table 6</ref> shows the performance values of our classifier in the satire-detection set- ting used by <ref type="bibr" target="#b23">Rubin et al. (2016)</ref> (the S-n-L News DB corpus), distinguishing satire from real news. This setting uses a balanced 3:1 training-to-test set split over 360 articles (180 per class). As can be seen, our style-based model significantly out- performs all baselines across the board, achieving an accuracy of 0.82, and an F score of 0.81. It clearly improves over topic classification, but does not outperform Rubin et al.'s classifier, which in- cludes features based on topic, absurdity, grammar, and punctuation. We argue that incorporating topic into satire detection is not appropriate, since the topics of satire change along the topics of news. A classifier with topic features therefore does not generalize. Apparently, a style-based model is com- petitive, and we believe that satire can be detected at scale this way, so as to prevent other fake news detection technology from falsely filtering it.</p><p>C. Unmasking satire. Given the above results on stylistic similarities between left and right news, the question remains how satire fits into the pic- ture. We assess the style similarity of satire from Rubin et al.'s corpus compared to fake news and real news from ours, again applying Unmasking to compare pairs of the three categories of news as described above. <ref type="figure" target="#fig_5">Figure 3</ref> shows the resulting Un- masking curves. The curve for the pair of fake vs. real news drops faster compared to the other two pairs. Apparently, the style of fake news has more in common with that of real news than either of the two have with satire. These results are encouraging: satire is distinct enough from fake and real news, so that, just like with hyperpartisan news compared to mainstream news, it can be discriminated with reasonable accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>Fact-checking for fake news detection poses an in- terdisciplinary challenge: technology is required to extract factual statements from text, to match facts with a knowledge base, to dynamically re- trieve and maintain knowledge bases from the web, to reliably assess the overall veracity of an entire article rather than individual statements, to do so in real time as news events unfold, to monitor the spread of fake news within and across social media, to measure the reputation of information sources, and to raise awareness in readers. These are only the most salient things that need be done to tackle the problem, and as our cross-section of related work shows, a large body of work must be covered. Notwithstanding the many attacks on fake news by developing one way or another of fact-checking, we believe it worthwhile to mount our attack from another angle: writing style. We show that news articles conveying a hyper- partisan world view can be distinguished from more balanced news by writing style alone. More- over, for the first time, we found quantifiable ev- idence that the writing styles of news of the two opposing orientations are in fact very similar: there appears to be a common writing style of left and right extremism. We further show that satire can be distinguished well from other news, ensuring that humor will not be outcast by fake news detection technology. All of these results offer new, tangible, short-term avenues of development, lest large-scale fact-checking is still far out of reach. Employed as pre-filtering technologies to separate hyperpartisan news from mainstream news, our approach allows for directing the attention of human fact checkers to the most likely sources of fake news.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Knowledge-based (also called fact checking) Style-based Information retrieval Semantic web / LOD Text categorization Deception detection Context-based</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>gives an overview. Among the selected publishers are six prolific hyperpartisan ones (three left-wing and three right-wing), and three mainstream ones. All publishers earned Face- book's blue checkmark , indicating authenticity and an elevated status within the network. Every post and linked news article has been fact-checked by 4 BuzzFeed journalists, including about 19% of posts forwarded from third parties. Having checked a total of 2,282 posts, 1,145 mainstream, 471 left- wing, and 666 right-wing, Silverman et al.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Unmasking applied to pairs of political orientations. The steeper a curve, the more similar the respective styles.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Unmasking applied to pairs of sets of news that are fake, real, and satire.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Features</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 2 : Performance of predicting orientation.</head><label>2</label><figDesc></figDesc><table>Features 
Accuracy 
Precision 
Recall 
F1 

all 
hyp. main. 
hyp. main. 
hyp. main. 

Style 
0.75 
0.69 0.86 
0.89 0.62 
0.78 0.72 
Topic 
0.71 
0.66 0.79 
0.83 0.60 
0.74 0.68 
News style 
0.56 
0.54 0.58 
0.65 0.47 
0.59 0.52 

All-hyp. 
0.49 
0.49 
-
1.00 
0.0 
0.66 
-
All-main. 
0.51 
-
0.51 
0.0 
1.00 
-
0.68 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 3 : Performance of predicting hyperpartisanship.</head><label>3</label><figDesc></figDesc><table>Features 
Left 
Right 

Trained on: right+main. all 
left+main. all 

Style 
0.74 
0.90 
0.66 
0.89 
Topic 
0.68 
0.79 
0.48 
0.85 
News style 
0.52 
0.61 
0.47 
0.66 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 4 :</head><label>4</label><figDesc>Ratio of left articles misclassified right when omitting left articles from training, and vice versa.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="true"><head>Table 5 : Performance of predicting veracity.</head><label>5</label><figDesc></figDesc><table>Features 
Accuracy 
Precision 
Recall 
F1 

all 
sat. 
real 
sat. 
real 
sat. 
real 

Style 
0.82 
0.84 
0.80 
0.78 0.85 
0.81 0.82 
Topic 
0.77 
0.78 
0.75 
0.74 0.79 
0.76 0.77 

All-sat. 
0.50 
0.50 
-
1.00 
0.0 
0.67 
-
All-real 
0.50 
-
0.50 
0.00 1.00 
-
0.67 

Rubin et al. 
n/a 
0.90 
n/a 
0.84 
n/a 
0.87 
n/a 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Performance of predicting satire (sat.). 

</table></figure>

			<note place="foot" n="1"> http://www.fakenewschallenge.org/</note>

			<note place="foot" n="2"> Corpus download: https://doi.org/10.5281/zenodo.1239675 3 http://github.com/BuzzFeedNews/2016-10-facebook-fact-check</note>

			<note place="foot" n="4"> Code download: http://www.github.com/webis-de/ACL-18 5 Automated Readability Index, Coleman Liau Index, Flesh Kincaid Grade Level and Reading Ease, Gunning Fog Index, LIX, McAlpine EFLAW Score, RIX, SMOG Grade, Strain Index</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank Craig Silverman, Lauren Strapagiel, Hamza Shaban, Ellie Hall, and Jeremy Singer-Vine from BuzzFeed for making their data available, en-abling our research.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Spread of (Mis)Information in Social Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daron</forename><surname>Acemoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asuman</forename><surname>Ozdaglar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Parandehgheibi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Games and Economic Behavior</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="194" to="227" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Detecting Hoaxes, Frauds, and Deception in Writing Style Online</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadia</forename><surname>Afroz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Brennan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachel</forename><surname>Greenstadt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 IEEE Symposium on Security and Privacy</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="461" to="475" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Style-based text categorization: What newspaper am i reading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shlomo</forename><surname>Argamon-Engelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moshe</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Galit</forename><surname>Avneri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the AAAI Workshop on Text Categorization</title>
		<meeting>of the AAAI Workshop on Text Categorization</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Identifying real or fake articles: Towards better language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Badaskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shilpa</forename><surname>Arora</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Third International Joint Conference on Natural Language Processing</title>
		<meeting><address><addrLine>Hyderabad, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-01-07" />
			<biblScope unit="page" from="817" to="822" />
		</imprint>
	</monogr>
	<note>The Association for Computer Linguistics</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">From clickbait to fake news detection: An approach based on detecting the stance of headlines to articles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Bourgonje</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julián</forename><forename type="middle">Moreno</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Rehm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Workshop: Natural Language Processing meets Journalism</title>
		<meeting>the 2017 Workshop: Natural Language Processing meets Journalism<address><addrLine>NLPmJ@EMNLP, Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-09-07" />
			<biblScope unit="page" from="84" to="89" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Limiting the spread of misinformation in social networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ceren</forename><surname>Budak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Divyakant</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amr</forename><forename type="middle">El</forename><surname>Abbadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th International Conference on World Wide Web, WWW &apos;11</title>
		<meeting>the 20th International Conference on World Wide Web, WWW &apos;11<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="665" to="674" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">News in an Online World: The Need for an</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yimin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niall</forename><forename type="middle">J</forename><surname>Conroy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victoria</forename><forename type="middle">L</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 78th ASIS&amp;T Annual Meeting: Information Science with Impact: Research in and for the Community, ASIST &apos;15</title>
		<meeting>the 78th ASIS&amp;T Annual Meeting: Information Science with Impact: Research in and for the Community, ASIST &apos;15<address><addrLine>Silver Springs, MD, USA</addrLine></address></meeting>
		<imprint>
			<publisher>American Society for Information Science</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="1" to="81" />
		</imprint>
	</monogr>
	<note>Automatic Crap Detector</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Computational Fact Checking from Knowledge Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giovanni</forename><surname>Luca Ciampaglia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prashant</forename><surname>Shiralkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Luis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Rocha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filippo</forename><surname>Bollen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Menczer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Flammini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">128193</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Semeval-2017 task 8: Rumoureval: Determining rumour veracity and support for rumours</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Derczynski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kalina</forename><surname>Bontcheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Liakata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Procter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluation</title>
		<meeting>the 11th International Workshop on Semantic Evaluation<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-08-03" />
			<biblScope unit="page" from="69" to="76" />
		</imprint>
	</monogr>
	<note>Geraldine Wong Sak Hoi, and Arkaitz Zubiaga</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Open Information Extraction from the Web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michele</forename><surname>Banko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="68" to="74" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Alexandru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrian</forename><surname>Ginsca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lupu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Credibility in Information Retrieval. Found. Trends Inf. Retr</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="355" to="475" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Vandalism Detection in Wikidata</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Heindorf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregor</forename><surname>Engels</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM International Conference on Information and Knowledge Management (CIKM 16)</title>
		<meeting>the 25th ACM International Conference on Information and Knowledge Management (CIKM 16)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="327" to="336" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">This just in: Fake news packs a lot in title, uses simpler, repetitive content in text body, more similar to satire than real news</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Benjamin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sibel</forename><surname>Horne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adali</surname></persName>
		</author>
		<idno>abs/1703.09398</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Measuring differentiability: Unmasking pseudonymous authors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moshe</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Schler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisheva</forename><surname>Bonchek-Dokow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1261" to="1276" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Prominent Features of Rumor Propagation in Online Social Media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meeyoung</forename><surname>Sejeong Kwon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyomin</forename><surname>Cha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yajun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 13th International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1103" to="1108" />
		</imprint>
	</monogr>
	<note>Data Mining (ICDM)</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Fake news detection through multi-perspective speaker profiles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunfei</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qin</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minglei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chu-Ren</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Joint Conference on Natural Language Processing</title>
		<meeting>the Eighth International Joint Conference on Natural Language Processing<address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2017-11-27" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="252" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Detect rumors in microblog posts using propagation structure via kernel learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kam-Fai</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="0304" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="708" to="717" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Web-based Statistical Fact Checking of Textual Documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amr</forename><surname>Magdy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nayer</forename><surname>Wanas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2Nd International Workshop on Search and Mining User-generated Contents, SMUC &apos;10</title>
		<meeting>the 2Nd International Workshop on Search and Mining User-generated Contents, SMUC &apos;10<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="103" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Collective Attention in the Age of (Mis)Information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Delia</forename><surname>Mocanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marton</forename><surname>Karsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walter</forename><surname>Quattrociocchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Hum. Behav</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="1198" to="1204" />
			<date type="published" when="2015" />
			<publisher>PB</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Containment of Misinformation Spread in Online Social Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nam</forename><forename type="middle">P</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guanhua</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">My</forename><forename type="middle">T</forename><surname>Thai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Eidenbenz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Annual ACM Web Science Conference, WebSci &apos;12</title>
		<meeting>the 4th Annual ACM Web Science Conference, WebSci &apos;12<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="213" to="222" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Automatic detection of fake news</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Verónica</forename><surname>Pérez-Rosas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bennett</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Lefevre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
		<idno>abs/1708.07104</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Truth of varying shades: Analyzing language in fake news and political fact-checking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Hannah Rashkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><forename type="middle">Yea</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svitlana</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Volkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-09-09" />
			<biblScope unit="page" from="2931" to="2937" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Towards News Verification: Deception Detection Methods for News Discourse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victoria</forename><surname>Rubin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niall</forename><surname>Conroy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yimin</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Hawaii International Conference on System Sciences (HICSS48) Symposium on Rapid Screening Technologies, Deception Detection and Credibility Assessment Symposium</title>
		<meeting>the Hawaii International Conference on System Sciences (HICSS48) Symposium on Rapid Screening Technologies, Deception Detection and Credibility Assessment Symposium<address><addrLine>Kauai, Hawaii, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Fake News or Truth? Using Satirical Cues to Detect Potentially Misleading News</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victoria</forename><surname>Rubin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niall</forename><surname>Conroy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yimin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarah</forename><surname>Cornwell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Workshop on Computational Approaches to Deception Detection</title>
		<meeting>the Second Workshop on Computational Approaches to Deception Detection<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="7" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Fact Checking in Heterogeneous Information Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoxu</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Weninger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference Companion on World Wide Web, WWW &apos;16 Companion</title>
		<meeting>the 25th International Conference Companion on World Wide Web, WWW &apos;16 Companion<address><addrLine>Republic and Canton of Geneva, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="101" to="102" />
		</imprint>
	</monogr>
	<note>International World Wide Web Conferences Steering Committee</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Craig</forename><surname>Silverman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lauren</forename><surname>Strapagiel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamza</forename><surname>Shaban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellie</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Singer-Vine</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Hyperpartisan Facebook Pages are Publishing False and Misleading Information at an Alarming Rate</title>
		<ptr target="https://www.buzzfeed.com/craigsilverman/partisan-fb-pages-analysis" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">The General Inquirer: A Computer Approach to Content Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">J</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dexter</forename><forename type="middle">C</forename><surname>Dunphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marshall</forename><forename type="middle">S</forename><surname>Smith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1966" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Fact-checking Effect on Viral Hoaxes: A Model of Misinformation Spread in Social Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcella</forename><surname>Tambuscio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giancarlo</forename><surname>Ruffo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Flammini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filippo</forename><surname>Menczer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on World Wide Web, WWW &apos;15 Companion</title>
		<meeting>the 24th International Conference on World Wide Web, WWW &apos;15 Companion<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="977" to="982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Beurteilung der glaubhaftigkeit von aussagen</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Udo</forename><surname>Undeutsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Handbuch der Psychologie</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="26" to="181" />
			<date type="published" when="1967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Separating facts from fiction: Linguistic models to classify suspicious and trusted news posts on twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svitlana</forename><surname>Volkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyle</forename><surname>Shaffer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><forename type="middle">Yea</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><forename type="middle">Oken</forename><surname>Hodas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2017-07-30" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="647" to="653" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">liar, liar pants on fire&quot;: A new benchmark dataset for fake news detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William Yang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2017-07-30" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="422" to="426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">An empirical study on uncertainty identification in social media context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongyu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junwen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Binyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lanjun</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kam-Fai</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st</title>
		<meeting>the 51st</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<title level="m">Annual Meeting of the Association for Computational Linguistics</title>
		<meeting><address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="58" to="62" />
		</imprint>
	</monogr>
	<note>Short Papers)</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Toward Computational Fact-checking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">You</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pankaj</forename><forename type="middle">K</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengkai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VLDB Endow</title>
		<meeting>VLDB Endow</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="589" to="600" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Satirical news detection and analysis using attention mechanism and linguistic features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><forename type="middle">Constantin</forename><surname>Dragut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-09-09" />
			<biblScope unit="page" from="1979" to="1989" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
