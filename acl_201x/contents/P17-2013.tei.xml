<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:55+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">On the Distribution of Lexical Features at Multiple Levels of Analysis</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fatemeh</forename><surname>Almodaresi</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lyle</forename><surname>Ungar</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vivek</forename><surname>Kulkarni</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohsen</forename><surname>Zakeri</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salvatore</forename><surname>Giorgi</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">Andrew</forename><surname>Schwartz</surname></persName>
						</author>
						<title level="a" type="main">On the Distribution of Lexical Features at Multiple Levels of Analysis</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</title>
						<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="79" to="84"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-2013</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Natural language processing has increasingly moved from modeling documents and words toward studying the people behind the language. This move to working with data at the user or community level has presented the field with different characteristics of linguistic data. In this paper, we empirically characterize various lexical distributions at different levels of analysis , showing that, while most features are decidedly sparse and non-normal at the message-level (as with traditional NLP), they follow the central limit theorem to become much more Log-normal or even Normal at the user-and county-levels. Finally , we demonstrate that modeling lexical features for the correct level of analysis leads to marked improvements in common social scientific prediction tasks.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>NLP for studying people has grown rapidly as more than one-third of the human population use social media actively. <ref type="bibr">1</ref> While traditional NLP tasks (e.g. POS tagging, parsing, sentiment anal- ysis) mostly work at the word, sentence, or doc- ument level, the increased focus on social scien- tific applications has shifted attention to new lev- els of analysis (e.g. user-level and community- level) ( <ref type="bibr" target="#b6">Koppel et al., 2009;</ref><ref type="bibr" target="#b10">Sarawgi et al., 2011;</ref><ref type="bibr" target="#b11">Schwartz et al., 2013a;</ref><ref type="bibr" target="#b1">Coppersmith et al., 2014;</ref><ref type="bibr" target="#b3">Flekova et al., 2016)</ref>. <ref type="figure">Figure 1</ref> shows the distribution of two uni- grams, 'the' and 'love' at three levels of analy- sis. While both words have zero counts in most messages, 'the' starts to look Normal across 1 Social Insights; Global social media research summary 2017 users, and both words are approximately Normal at the county level. Methods performing optimally at the document level may suffer at the user or community level due to this shift in the distribu- tion of lexical features. <ref type="bibr">2</ref> In this paper, we ask a fundamental statistical question: How does the shift in unit-of-analysis from document-level to user-or-community level shift lexical distributions in social media? <ref type="bibr">3</ref> The central limit theorem suggests that count data is better approximated by a Normal distribution as one increases the number of events, or as one ag- gregates more features (e.g. combining words us- ing LDA topics or hand-built word sets). However, we do not know how far towards a Normal these new levels of analysis bring us.</p><p>Related work. The question we ask harks back to work from pioneers in corpus-based computational linguistics, including Shannon (1948) who suggested that probabilistic distribu- tions of ngrams could be used to solve a range of communications problems, and <ref type="bibr" target="#b8">Mosteller and Wallace (1963)</ref> who found that a negative bino- mial distribution seemed to model unigram usage by authors of the Federalist Papers. Numerous works have since continued the tradition of ex- amining the distribution of lexical features. For example, <ref type="bibr" target="#b7">McCallum et al. (1998)</ref> compares the results of probabilistic models based on multi- variate Bernoulli with those based on multinomial distributions for document classification. Jansche <ref type="figure">Figure 1</ref>: Histograms for unigrams "the" (a very frequent feature) and "love" (less frequent) at different levels of analysis: message, user, and community (from left to right). The bars at zero are cut-off at the message and user levels to increase readability of the remaining distribution.</p><p>(2003) extended this line of work, observing lex- ical count data often display an extra probability mass concentrated at zero and suggesting Zero- Inflated negative binomial distributions can cap- ture this phenomenon better and are easier to im- plement than alternatives such as overdispersed bi- nomial models. While these works are numerous, none, to the best of our knowledge, have focused on distributions across social media or at multiple levels of analysis.</p><p>Contributions. Our study is perhaps unconven- tional in modern computational linguistics due to the elementary nature of our contributions, focus- ing on understanding the empirical distributions of lexical features in Twitter. First, we use zero- inflated kernel density estimated plots to show how distributions of different language features (words, LDA topics, and hand-curated word sets) vary with level of analysis (message, user, and county). Second, we quantify which distributions best describe the different feature types and anal- ysis levels of social media. Finally, we show the utility of such information, finding that us- ing the appropriate model for each feature type improves Naive Bayes classification results across three common social scientific tasks: sarcasm de- tection at the message-level, gender identification at the user-level, and political ideology classifica- tion at the community-level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>Examining data at three different levels of analy- sis and across three different lexical feature types (unigrams, data-driven topics, and manual lexica), we seek to (1) visually characterize distributions, (2) empirically test which distributions best fit the data, and (3) evaluate classification models utiliz- ing multiple distributions at each level. Unigrams underlie all data where as each level of analysis and feature type represent a different degree of ag- gregation and covariance structure.</p><p>Data preparation. We start with a set of about two million Twitter posts and supplemental infor- mation about the users: their ID, county, and gen- der. The data was based on that of <ref type="bibr" target="#b15">Volkova et al. (2013)</ref>, who provide tweet ids and gender, and mapped to counties using the method of <ref type="bibr" target="#b11">Schwartz et al. (2013a)</ref>. We limit our data to users who have used at least 1000 words and counties that have at least 30 users and a total word count of 5000. Applying these constraints, the final set of data consists of 1,639,750 tweets (representing the message-level) from 5,226 users in 420 different counties (representing the community-level).</p><p>We consider three lexical features that are commonly used in NLP for social science: 1- grams (the top 10,000 most common unigrams found with happierFunTokenizing social media tokenizer), 2000 LDA topics downloaded from <ref type="bibr" target="#b12">Schwartz et al. (2013b)</ref>), and lexica (64 categories from the linguistic inquiry and word count dictio- nary ( <ref type="bibr" target="#b9">Pennebaker et al., 2007)</ref>). Note that the fea- tures progress from most sparse (1grams) to least sparse (lexica).</p><p>Distributions. <ref type="figure" target="#fig_0">Figure 2</ref> shows the empirical dis- tributions of different lexical features at differ- ent levels of analysis. 500 features were sampled from the top 20,000 unigrams 4 , 2000 social me- dia LDA topics ( <ref type="bibr" target="#b11">Schwartz et al., 2013a)</ref>, and all 64 categories from the LIWC lexica ( <ref type="bibr" target="#b9">Pennebaker et al., 2007)</ref>. To encode the variables continu- ously we used relative frequencies for unigrams and lexica (count of word or category divided by count of all words), and probability of topics, cal- culated from the posterior probabilities from the LDA models. Each line in the kernel density plot is semi-transparent such that an aggregate trend across multiple features will emerge darkest. As we move along a row ranging specific features (unigrams) to generic features (lexicon), the em- pirical distribution gradually changes from resem- bling a "power law" (or binomial distribution with low number of trials and probability of success) to something more "Normal". Similar shifts are also observed as we move across levels of modeling.</p><p>We investigate whether the best-fitting distribu- tions vary across the three levels of analysis and three types of lexical features. We consider the following candidate distributions to see how well they fit each of these empirical distributions: Since most of the distributions outlined above are standard distributions, we only briefly describe the zero-inflated variants which handle excess zero counts. Zero-inflated models explicitly model the idea that a distribution does not fully capture the mass at 0 in real world data. They assume that the data is generated from two components. The first component is governed by a Bernoulli distribution that generates excess zeros, while the second com- ponent generates counts, some of which also could be zero (Jansche, 2003).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation</head><p>We evaluate the distributions we considered by first characterizing the goodness of fit at different levels of analyses and then by their predictive per- formance on social media prediction tasks, both of which we describe below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Goodness of fit</head><p>Following the central limit theorem, we seek to de- termine across the range levels of analysis and fea- ture types, whether the distribution can be approx- imated by a Normal. Focusing just on the non-zero portions of data encoded as relative frequencies, we quantify the fit of each candidate distribution to the data. We estimate the parameters for each distribu- tion using MLE on a training data set (i.e. 80% of data). Then, we evaluate their likelihoods of a held-out test dataset, given the estimated param- eters. Since we are trying to approximate the dis- crete distribution with a continuous model, all data were converted to relative frequencies. Finally, the distribution under which the test data is most likely <ref type="table" target="#tab_1">Dist   Message  User  County  1gram Topic Lex. 1gram Topic Lex. 1gram Topic Lex.  Power Law  71  10  0  4  0  0  7  0  0  Log-Normal  25  89  100  96  97  64  92  86  44  Normal  4  1  0  0  3  36  1  14  56   Table 1</ref>: Percentage of best-fitted distributions in each level of message, user, and county for different types of features such as "Lexicons", "Topics", and "1grams". Note that the best-fitting distribution for each feature type is a function of the level of analysis.</p><p>is chosen as the 'best fit' distribution. We repeat this 100 times and pick the most likely distribution over all these 100 independent runs.</p><p>Results. <ref type="table">Table 1</ref> shows the percentage of fea- tures in each level that were best fit from an un- derlying distribution of Normal, Log-Normal, or Power Law. We see empirically that there is a trend toward Normal approximation moving from message to county level, as well as 1grams to lex- ica. In fact, a majority of lexica at the county-level were best approximated by a Normal distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Predictive Power</head><p>In the previous section, we showed that the dis- tribution of lexical features depends on the scale of analysis considered (for example, the message level or the user level). Here, we demonstrate that predictive models which use these lexical fea- tures as co-variates can leverage this information to boost predictive performance. We consider three predictive tasks using a generative predictive model. The primary purpose of this evaluation is not to characterize the best distribution at a level or task, but to demonstrate that the choice of distribu- tion assumed when modeling features significantly affects the predictive performance.</p><p>Predictive Tasks : We consider the following common predictive tasks and also outline details of the datasets considered:</p><p>1. Sarcasm Detection (Message level): This task consists of determining whether tweets contain a sarcastic expression ( <ref type="bibr" target="#b0">Bamman and Smith, 2015)</ref>. The dataset consists of 16,833 messages with an average of 12 words per message.</p><p>2. Gender Identification (User level): This task involves determining the gender of the author utilizing a previously described Twit- ter dataset ( <ref type="bibr" target="#b15">Volkova et al., 2013)</ref>. This dataset consists of 5,044 users each of which have at least a 1,000 tokens as is standard in user- level analyses ( <ref type="bibr" target="#b12">Schwartz et al., 2013b</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Ideology Classification (Community level):</head><p>We utilized county voting records from 2012 along with a dataset of tweets mapped to counties. This data consists of 2,175 counties with atleast 10,000 unigrams as is common in community level analyses <ref type="bibr" target="#b2">(Eichstaedt et al., 2015</ref>).</p><p>We consider a Naive Bayes classifier (a gener- ative model) which enables one to directly incor- porate the inferred feature distribution at a partic- ular level of analysis, the results of which we dis- cuss in <ref type="table" target="#tab_1">Table 2</ref>. Variable encoding for the clas- sifiers varied from binary encoding of present or not (Bernoulli), to counts (Poisson, Zero-inflated Poisson), multivariate counts (Multinomial), and continuous relative frequencies (Normal). All dis- tributions have closed form MLE solutions ex- cept for Zero-Inflated Poisson, in which case we used LBFGS optimization to fit both of its param- eters ( <ref type="bibr" target="#b4">Head and Zerner, 1985)</ref>.</p><p>Results. We report macro F1-score for each of the underlying distributions in <ref type="table" target="#tab_1">Table 2</ref>. For each of the tasks, we used 80% of the data for train- ing and evaluate on the held-out 20%. We observe a similar pattern as that observed in the goodness of fit setting, with a shift in the best performing distribution from Bernoulli (which simply models if a feature exists or not) toward something more Gaussian (Poisson or Normal) as we move along from message-level to county-level analysis and from unigrams to lexica. Specifically note that at higher levels of analysis (at user and county levels) as the distribution of features becomes closer to Normal, modeling features as Bernoulli is clearly sub-optimal where as at the message level model- ing unigrams as a Bernoulli is superior. These ob- servations underscore the main insight that the dis- tribution family used to model features can be con-  sidered a function of level of analysis and feature- type considered and has a significant bearing on predictive performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>While computational linguistics has a long his- tory of studying the distributions of lexical fea- tures, social media and social scientific studies have brought about a need to understand how these change at multiple levels of analyses. Here, we explored empirical distributions of different types of linguistic features (unigrams, topics, lexica) in three different levels of analysis in Twitter data (message, user, and community). To show which distribution can better describe features of differ- ent levels, we approached the problem in three dif- ferent ways: (1) visualization of empirical distri- butions, (2) goodness-of-fit comparisons, and <ref type="formula">(3)</ref> for predictive tasks.</p><p>We showed that the best-fit distribution depends on feature-type (i.e. unigram versus lexica) and the level of analysis (i.e. message-, user-, or community-level). Following the central limit the- orem, all user-level features were predominantly Log-normal, while a power law best fit unigrams at the message level and a Normal distribution best approximated lexica at the community level. Finally, we demonstrated that predictive perfor- mance can also vary considerably by the level of analysis and feature-type, following a similar trend from Bernoulli distributions at the message- level to Poisson or Normal at the community-level. Our results underscore the significance of the level of analysis for the ever-growing focus in NLP on social scientific problems which seek to not only better model words and documents but also the people and communities generating them.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Kernel Density Estimate (KDE) plots showing the distribution of 500 random features at different levels of analysis. Each row represents a specific level of analysis (county, user, message) and each column represents a specific type of feature (Lexicon, Topic, Unigram). The bar on the left of each plot represents the percentage of observations that are zero for each feature where the shading represents the percent of features reaching the given threshold. As the bar gets darker it means more features out of 500 are zero in that percentage of individuals. The right portion of each plot is based on standardized relative frequencies of the variables (mean centered and divided by the standard deviation).</figDesc><graphic url="image-2.png" coords="3,85.61,62.81,426.33,228.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>•</head><label></label><figDesc>Continuous Distributions: (a) Power-law, (b), Log-normal and (c) Normal • Discrete Distributions: (a) Bernoulli, (b) Multinomial, (c) Poisson, and (d) Zero In- flated Poisson</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>F1-Score of Naive Bayes classifiers using various distributions and levels of analysis across tasks of sarcasm detec-

tion, gender identification, and political ideology classification. Observe that predictive power is once again a function of the 
distribution family used to model feature distribution and depends on level of analysis. 

</table></figure>

			<note place="foot" n="2"> While the distribution of word frequencies (i.e. a Zipfian distribution) is often discussed in NLP, it is important to note that we are focused on the distribution of single features (e.g. words) over documents, users, or communities. 3 While other sources of corpora can also be aggregated to the user-or community-level (e.g. newswire, books), we believe the question of distributions is particularly important in social media because it often contains very short posts and a growing body of work in NLP for social science focuses on social media.</note>

			<note place="foot" n="4"> In social media analyses, the top 20,000 features are often used (Schwartz and Ungar, 2015)</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was supported in part by the Templeton Religion Trust, Grant TRT-0048.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Contextualized sarcasm detection on twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Bamman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings to the International Conference on Web-blogs and Social Media</title>
		<meeting>to the International Conference on Web-blogs and Social Media</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="574" to="577" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Quantifying mental health signals in twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Glen</forename><surname>Coppersmith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Craig</forename><surname>Harman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL workshop on Computational Linguistics and Clinical Psychology</title>
		<meeting>the ACL workshop on Computational Linguistics and Clinical Psychology</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Psychological language on twitter predicts countylevel heart disease mortality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Johannes C Eichstaedt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><forename type="middle">L</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Kern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raina</forename><forename type="middle">M</forename><surname>Darwin R Labarthe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sneha</forename><surname>Merchant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Megha</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lukasz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>Dziurzynski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Analyzing Biases in Human Perception of User Age and Gender from Text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucie</forename><surname>Flekova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Carpenter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salvatore</forename><surname>Giorgi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lyle</forename><surname>Ungar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Preoctiuc-Pietro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th annual meeting of the Association for Computational Linguistics. ACL</title>
		<meeting>the 54th annual meeting of the Association for Computational Linguistics. ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A broydenfletchergoldfarbshanno optimization procedure for molecular geometries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Head</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zerner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chemical physics letters</title>
		<imprint>
			<biblScope unit="volume">122</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="264" to="270" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Parametric models of linguistic count data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Jansche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 41st Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="288" to="295" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Computational methods in authorship attribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moshe</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Schler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shlomo</forename><surname>Argamon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Society for information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="9" to="26" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A comparison of event models for naive bayes text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kamal</forename><surname>Nigam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI-98 workshop on learning for text categorization. Citeseer</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">752</biblScope>
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Inference in an authorship problem: A comparative study of discrimination methods applied to the authorship of the disputed federalist papers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederick</forename><surname>Mosteller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>David L Wallace</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">302</biblScope>
			<biblScope unit="page" from="275" to="309" />
			<date type="published" when="1963" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Liwc2007: Linguistic inquiry and word count</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>James W Pennebaker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Roger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><forename type="middle">E</forename><surname>Booth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Francis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>LIWC.net</publisher>
			<pubPlace>Austin, Texas</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Gender attribution: tracing stylometric evidence beyond topic and genre</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruchita</forename><surname>Sarawgi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kailash</forename><surname>Gajulapalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifteenth Conference on Computational Natural Language Learning</title>
		<meeting>the Fifteenth Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="78" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Characterizing geographic variation in wellbeing using tweets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H Andrew</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><forename type="middle">C</forename><surname>Eichstaedt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><forename type="middle">L</forename><surname>Kern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Dziurzynski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">E</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Megha</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gregory</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shrinidhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sneha</forename><surname>Lakshmikanth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Seligman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International AAAI Conference on Web and Social Media. ICWSM</title>
		<meeting>the 7th International AAAI Conference on Web and Social Media. ICWSM</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Personality, gender, and age in the language of social media: The open-vocabulary approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H Andrew</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><forename type="middle">C</forename><surname>Eichstaedt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><forename type="middle">L</forename><surname>Kern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Dziurzynski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Megha</forename><surname>Stephanie M Ramones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Achal</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Kosinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stillwell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Seligman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">73791</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Datadriven content analysis of social media a systematic overview of automated methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lyle H</forename><surname>Ungar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The ANNALS of the American Academy of Political and Social Science</title>
		<imprint>
			<biblScope unit="volume">659</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="78" to="94" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A mathematical theory of communication, bell system technical journal 27: 379-423 and 623-656</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claude</forename><forename type="middle">E</forename><surname>Shannon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Reviews</title>
		<imprint>
			<biblScope unit="page">133</biblScope>
			<date type="published" when="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Exploring demographic language variations to improve multilingual sentiment analysis in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svitlana</forename><surname>Volkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1815" to="1827" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
