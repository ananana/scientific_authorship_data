<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:04+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Labeled Grammar Induction with Minimal Supervision</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Bisk</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">The University of Illinois at Urbana-Champaign</orgName>
								<address>
									<addrLine>201 N. Goodwin Ave</addrLine>
									<postCode>61801</postCode>
									<settlement>Urbana</settlement>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Christodoulopoulos</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">The University of Illinois at Urbana-Champaign</orgName>
								<address>
									<addrLine>201 N. Goodwin Ave</addrLine>
									<postCode>61801</postCode>
									<settlement>Urbana</settlement>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hockenmaier</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">The University of Illinois at Urbana-Champaign</orgName>
								<address>
									<addrLine>201 N. Goodwin Ave</addrLine>
									<postCode>61801</postCode>
									<settlement>Urbana</settlement>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Labeled Grammar Induction with Minimal Supervision</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="870" to="876"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Nearly all work in unsupervised grammar induction aims to induce unlabeled dependency trees from gold part-of-speech-tagged text. These clean linguistic classes provide a very important, though unreal-istic, inductive bias. Conversely, induced clusters are very noisy. We show here, for the first time, that very limited human supervision (three frequent words per cluster) may be required to induce labeled dependencies from automatically induced word clusters.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Despite significant progress on inducing part-of-speech (POS) tags from raw text ( <ref type="bibr" target="#b7">Christodoulopoulos et al., 2010;</ref><ref type="bibr" target="#b4">Blunsom and Cohn, 2011</ref>) and a small number of notable exceptions <ref type="bibr" target="#b27">(Seginer, 2007;</ref><ref type="bibr" target="#b28">Spitkovsky et al., 2011;</ref><ref type="bibr" target="#b9">Christodoulopoulos et al., 2012</ref>), most approaches to grammar induction or unsupervised parsing ( <ref type="bibr" target="#b22">Klein and Manning, 2004;</ref><ref type="bibr" target="#b29">Spitkovsky et al., 2013;</ref><ref type="bibr" target="#b3">Blunsom and Cohn, 2010)</ref> are based on the assumption that gold POS tags are available to the induction system. Although most approaches treat these POS tags as arbitrary, if relatively clean, clusters, it has also been shown that the linguistic knowledge implicit in these tags can be exploited in a more explicit fashion ( <ref type="bibr" target="#b23">Naseem et al., 2010)</ref>. The presence of POS tags is also essential for approaches that aim to return richer structures than the standard unlabeled dependencies. <ref type="bibr" target="#b5">Boonkwan and Steedman (2011)</ref> train a parser that uses a semi-automatically constructed Combinatory Categorial Grammar <ref type="bibr">(CCG, Steedman (2000)</ref>) lexicon for POS tags, while <ref type="bibr" target="#b0">Bisk and Hockenmaier (2012;</ref><ref type="bibr" target="#b33">2013)</ref> show that CCG lexicons can be induced automatically if POS tags are used to identify nouns and verbs. However, assuming clean POS tags is highly unrealistic for most scenarios in which one would wish to use an otherwise unsupervised parser.</p><p>In this paper we demonstrate that the simple "universal" knowledge of <ref type="bibr" target="#b1">Bisk and Hockenmaier (2013)</ref> can be easily applied to induced clus- ters given a small number of words labeled as noun, verb or other, and that this small amount of knowledge is sufficient to produce labeled syn- tactic structures from raw text, something that has not yet been proposed in the literature. Specifi- cally, we will provide a labeled evaluation of in- duced CCG parsers against the English <ref type="bibr" target="#b19">(Hockenmaier and Steedman, 2007)</ref> and Chinese <ref type="bibr" target="#b33">(Tse, 2013)</ref> CCGbanks. To provide a direct compari- son to the dependency induction literature, we will also provide an unlabeled evaluation on the 10 de- pendency corpora that were used for the task of grammar induction from raw text in the PASCAL Challenge on Grammar Induction ( <ref type="bibr" target="#b14">Gelling et al., 2012)</ref>.</p><p>The system of Christodoulopoulos et al. (2012) was the only participant competing in the PAS- CAL Challenge that operated over raw text (in- stead of gold POS tags). However, their approach did not outperform the six baseline systems pro- vided. These baselines were two versions of the DMV model ( <ref type="bibr" target="#b22">Klein and Manning, 2004;</ref><ref type="bibr" target="#b15">Gillenwater et al., 2011</ref>) run on varying numbers of in- duced Brown clusters (described in section 2.1). We will therefore compare against these baselines in our evaluation.</p><p>Outside of the shared task, Spitkovsky et al. (2011) demonstrated impressive performance us- ing Brown clusters but did not provide evaluation for languages other than English.</p><p>The system we propose here will use a coarse- grained labeling comprised of three classes, which makes it substantially simpler than traditional tagsets, and uses far fewer labeled tokens than is customary for weakly-supervised approaches <ref type="bibr" target="#b16">(Haghighi and Klein, 2006;</ref><ref type="bibr" target="#b13">Garrette et al., 2015</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Our Models</head><p>Our goal in this work will be to produce la- beled dependencies from raw text. Our approach is based on the HDP-CCG parser of <ref type="bibr" target="#b2">Bisk and Hockenmaier (2015)</ref> with their extensions to cap- ture lexicalization and punctuation, which, to our knowledge, is the only unsupervised approach to produce labeled dependencies. It first induces a CCG from POS-tagged text, and then estimates a model based on Hierarchical Dirichlet Processes ( <ref type="bibr" target="#b32">Teh et al., 2006</ref>) over the induced parse forests. The HDP model uses a hyperparameter which controls the amount of smoothing to the base mea- sure of the HDP. Setting this value will prove im- portant when moving between datasets of drasti- cally different sizes.</p><p>The induction algorithm assumes that a) verbs may be predicates (with category S), b) verbs can take nouns (with category N) or sentences as ar- guments (leading to categories of the form S|N, (S|N)|N, (S|N)|S etc.), c) any word can act as a modifier, i.e. have a category of the form X|X if it is adjacent to a word with category X or X|Y, and d) modifiers X|X can take nouns or sen- tences as arguments ((X|X)|N). Our contribution in this paper will be to show that we can replace the gold POS tags used by <ref type="bibr" target="#b1">Bisk and Hockenmaier (2013)</ref> with automatically induced word clusters, and then use very minimal supervision to identify noun and verb clusters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Inducing Word Clusters</head><p>We will evaluate three clustering approaches:</p><p>Brown Clusters Brown clusters ( <ref type="bibr" target="#b6">Brown et al., 1992)</ref> assign each word to a single cluster using an aglomerative clustering that maximizes the proba- bility of the corpus under a bigram class condi- tional model. We use Liang's implementation <ref type="bibr">1</ref> .</p><p>BMMM The Bayesian Multinomial Mixture Model 2 (BMMM, <ref type="bibr" target="#b8">Christodoulopoulos et al. 2011</ref>) is also a hard clustering system, but has the ability to incorporate multiple types of features either at a token level (e.g. ±1 context word) or at a type level (e.g. morphology features derived from the Morfessor system <ref type="bibr" target="#b11">(Creutz and Lagus, 2006)</ref>). The combination of these features allows BMMM to better capture morphosyntactic information.</p><p>Bigram HMM We also evaluate unsupervised bigram HMMs, since the soft clustering they pro- vide may be advantageous over the hard Brown and BMMM clusters. But it is known that un- supervised HMMs may not find good POS tags <ref type="bibr" target="#b20">(Johnson, 2007)</ref>, and in future work, more sophis- ticated models (e.g. <ref type="bibr" target="#b4">Blunsom and Cohn (2011)</ref>), might outperform the systems we use here.</p><p>In all cases, we assume that we can identify punctuation marks, which are moved to their own cluster and ignored for the purposes of tagging and parsing evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Identifying Noun and Verb Clusters</head><p>To induce CCGs from induced clusters, we need to label them as {noun, verb, other}. This needs to be done judiciously; providing every cluster the verb label, for example, leads to the model iden- tifying prepositions as the main sentential predi- cates.</p><p>We demonstrate here that labeling three fre- quent words per cluster is sufficient to outperform state-of-the-art performance on grammar induc- tion from raw text in many languages. We emu- late having a native speaker annotate words for us by using the universal tagset ( <ref type="bibr" target="#b24">Petrov et al., 2012)</ref> as our source of labels for the most frequent three words per cluster (we map the tags NOUN, NUM, PRON to noun, VERB to verb, and all others to other). The final labeling is a majority vote, where each word type contributes a vote for each label it can take (see <ref type="table">Table 4</ref> for some examples). This ap- proach could easily be scaled to allow more words per cluster to vote. But we will see that three per cluster is sufficient to label most tokens correctly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Setup</head><p>We will focus first on producing CCG labeled predicate-argument dependencies for English and Chinese and will then apply our best settings to produce a comparison with the tree structures of the languages of the PASCAL Shared Task. All languages will be trained on sentences of up to length 20 (not counting punctuation). All clus- ter induction algorithms are treated as black boxes and run over the complete datasets in advance. This alleviates having to handle tagging of un- known words.</p><p>To provide an intuition for the performance of the induced word clusters, we provide two stan- dard metrics for unsupervised tagging:</p><p>Many-to-one (M-1) A commonly used mea- sure, M-1 relies on mapping each cluster to the most common POS tag of its words. However, M- 1 can be easily inflated by inducing more clusters. V-Measure Proposed by <ref type="bibr" target="#b25">Rosenberg and Hirschberg (2007)</ref>, V-Measure (VM) measures the information-theoretic distance between two clusterings and has been shown to be robust to the number of induced clusters <ref type="bibr" target="#b7">(Christodoulopoulos et al., 2010</ref>). Both of these metrics are known to be highly dependent on the gold annotation standards they are compared against, and may not correlate with downstream performance at parsing.</p><p>Of more immediate relevance to our task is the ability to accurately identify nouns and verbs:</p><p>Noun, Verb, and Other Recall We measure the (token-based) recall of our three-way labeling scheme of clusters as noun/verb/other against the universal POS tags of each token.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiment 1: CCG-based Evaluation</head><p>Experimental Setup For our primary experi- ments, we train and test our systems on the English and Chinese CCGbanks, and report directed la- beled F1 (LF1) and undirected unlabeled F1 (UF1) over CCG dependencies <ref type="bibr" target="#b10">(Clark et al., 2002</ref>). For the labeled evaluation, we follow the simplifica- tion of CCGbank categories proposed by <ref type="bibr" target="#b2">Bisk and Hockenmaier (2015)</ref>: for English to remove mor- phosyntactic features, map NP to N and change VP modifiers (S\NP)|(S\NP) to sentential modi- fiers (S|S); for Chinese we map both M and QP to N. In the CCG literature, UF1 is commonly used because undirected dependencies do not penalize argument vs. adjunct distinctions, e.g. for prepo- sitional phrases. For this reason we will include UF1 in the final test set evaluation <ref type="table" target="#tab_2">(Table 2)</ref>.</p><p>We use the published train/dev/test splits, using the dev set for choosing a cluster induction algo- rithm, and then present final performance on the test data. We induce 36 tags for English and 37 for Chinese to match the number of tags present in the treebanks (excluding symbol and punctuation tags). Results <ref type="table">Table 1</ref> presents the parsing and tagging development results on the two CCG corpora. In terms of tagging performance, we can see that the two hard clustering systems significantly outper- form the HMM, but the relative performance of Brown and BMMM is mixed. More importantly, we see that, at least for En- glish, despite clear differences in tagging perfor- mance, the parsing results (LF1) are much more similar. In Chinese, we see that the performance of the two hard clustering systems is almost iden- tical, again, not representative of the differences in the tagging scores. The N/V/O recall scores in both languages are equally poor predictors of pars- ing performance. However, these scores show that having only three labeled tokens per class is suffi- cient to capture most of the necessary distinctions for the HDP-CCG. All of this confirms the ob- servations of <ref type="bibr" target="#b17">Headden et al. (2008)</ref> that POS tag- ging metrics are not correlated with parsing per- formance. However, since BMMM seems to have a slight overall advantage, we will be using it as our clustering system for the remaining experi- ments.</p><p>Since the goal of this work was to produce la- beled syntactic structures, we also wanted to eval- uate our performance against that of the HDP- CCG system that uses gold-standard POS tags. As we can see in the last two columns of our develop- ment results in <ref type="table" target="#tab_2">Table 1 and in the final test results  of Table 2</ref>, our system is within 2/3 of the labeled performance of the gold-POS-based HDP-CCG <ref type="bibr">3</ref> . <ref type="figure">Figure 1</ref> shows an example labeled syntactic structure induced by the model. We can see the system successfully learns to attach the final  </p><formula xml:id="formula_0">N/N N S \N (S\S)/N N/N N (N\N)/N N/N N (S\S)/N N/N N/N , N/N , N/N and N/N N . &gt; &gt; &gt;punc &gt;punc &gt; N N N /N N /N N /N N &lt; &gt; S N \N &lt; &gt; N N &gt; N &gt; &gt; S\S N &gt; N &lt; &gt; S N &gt; S\S &lt; S &gt;punc S</formula><p>hertz equipment is a major supplier of rental equipment in the u.s. , france , spain and the u.k .</p><formula xml:id="formula_1">N/N N S \N (S\S)/N N/N N (N\N)/N N/N N (S\S)/N N/N N/N , N/N , N/N and N/N N . &gt; &gt; &gt;punc &gt;punc &gt; N N N /N N /N N /N N &lt; &gt; S N \N &lt; &gt; N N &gt; N &gt; &gt; S\S N &gt; N &lt; &gt; S N &gt; S\S &lt; S &gt;punc S</formula><p>hertz equipment is a major supplier of rental equipment in the u.s. , france , spain and the u.k .</p><formula xml:id="formula_2">N/N N S \N (S\S)/N N/N N (N\N)/N N/N N (S\S)/N N/N N/N , N/N , N/N and N/N N . &gt; &gt; &gt;punc &gt;punc &gt; N N N /N N /N N /N N &lt; &gt; S N \N &lt; &gt; N N &gt; N &gt; &gt; S\S N &gt; N &lt; &gt; S N &gt; S\S &lt; S &gt;punc S</formula><p>hertz equipment is a major supplier of rental equipment in the u.s. , france , spain and the u.k .</p><formula xml:id="formula_3">N/N N S \N (S\S)/N N/N N (N\N)/N N/N N (S\S)/N N/N N/N , N/N , N/N and N/N N . &gt; &gt; &gt;punc &gt;punc &gt; N N N /N N /N N /N N &lt; &gt; S N \N &lt; &gt; N N &gt; N &gt; &gt; S\S N &gt; N &lt; &gt; S N &gt; S\S &lt; S &gt;punc S</formula><p>hertz equipment is a major supplier of rental equipment in the u.s. , france , spain and the u.k .</p><formula xml:id="formula_4">N/N N S \N (S\S)/N N/N N (N\N)/N N/N N (S\S)/N N/N N/N , N/N , N/N and N/N N . &gt; &gt; &gt;punc &gt;punc &gt; N N N /N N /N N /N N &lt; &gt; S N \N &lt; &gt; N N &gt; N &gt; &gt; S\S N &gt; N &lt; &gt; S N &gt; S\S &lt; S &gt;punc S</formula><p>hertz equipment is a major supplier of rental equipment in the u.s. , france , spain and the u.k .</p><formula xml:id="formula_5">N/N N S \N (S\S)/N N/N N (N\N)/N N/N N (S\S)/N N/N N/N , N/N , N/N and N/N N . &gt; &gt; &gt;punc &gt;punc &gt; N N N /N N /N N /N N &lt; &gt; S N \N &lt; &gt; N N &gt; N &gt; &gt; S\S N &gt; N &lt; &gt; S N &gt; S\S &lt; S &gt;punc S</formula><p>hertz equipment is a major supplier of rental equipment in the u.s. , france , spain and the u.k .</p><formula xml:id="formula_6">N/N N S \N (S\S)/N N/N N (N\N)/N N/N N (S\S)/N N/N N/N , N/N , N/N and N/N N . &gt; &gt; &gt;punc &gt;punc &gt; N N N /N N /N N /N N &lt; &gt; S N \N &lt; &gt; N N &gt; N &gt; &gt; S\S N &gt; N &lt; &gt; S N &gt; S\S &lt; S &gt;punc S</formula><p>hertz equipment is a major supplier of rental equipment in the u.s. , france , spain and the u.k .</p><formula xml:id="formula_7">N/N N S \N (S\S)/N N/N N (N\N)/N N/N N (S\S)/N N/N N/N , N/N , N/N and N/N N . &gt; &gt; &gt;punc &gt;punc &gt; N N N /N N /N N /N N &lt; &gt; S N \N &lt; &gt; N N &gt; N &gt; &gt; S\S N &gt; N &lt; &gt; S N &gt; S\S &lt; S &gt;punc S</formula><p>Hertz equipment is a major supplier of rental equipment</p><formula xml:id="formula_8">N/N N S \N (S\S)/N N/N N (N\N)/N N/N N &gt; &gt; N N &lt; &gt; S N \N &lt; N &gt; N &gt; S\S &lt; S 1</formula><p>Figure 1: A sample derivation from the WSJ Sec- tion 22 demonstrating the system is learning most of the correct categories of CCGbank but has in- correctly analyzed the determiner as a preposition.</p><p>prepositional phrase, but mistakes the verb for in- transitive and treats the determiner a as a prepo- sition. The labeled and undirected recall for this parse are 5/8 and 7/8 respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiment 2: PASCAL Shared Task</head><p>Experimental Setup During the PASCAL shared task, participants were encouraged to train over the complete union of the data splits. We do the same here, use the dev set for choosing a HDP-CCG hyperparameter, and then present final results for comparison on the test section. We vary the hyperparamter for this evaluation because the datasets fluctuate dramatically in size from 9K to 700K tokens on sentences up to length 20. Rather than match all of the tagsets, we simply induce 49 (excluding punctuation) classes for every language. The actual tagsets vary from 20 to 304 tags (median 39, mean 78).</p><p>Results We now present results for the 10 cor- pora of the PASCAL shared task (evaluated on all sentence lengths). <ref type="table" target="#tab_4">Table 3</ref> presents the test per- formance for each language with the best hyper- parameter chosen from the set {100, 1000, 2500}. Also included are the best published results from the joint tag/dependency induction shared task (ST) as well as the results from Bisk and Hock- enmaier (2013), the only existing numbers for multilingual CCG induction (BH) with gold part- of-speech tags. Note that the systems in ST do not have access to any gold-standard POS tags, whereas our system has access to the gold tags for  the three most frequent words of each cluster. The languages are sorted by the number of non- punctuation tokens in sentences of up to length 20. Despite our average performance (34.2) being slightly higher than the shared task (31.8), the st. deviation is substantial (σ = 15.2 vs σ ST = 7.5). It seems apparent from the results that while data sparsity may play a role in affecting performance, the more linguistically interesting thread appears to be morphology. Czech is perhaps a prime ex- ample, as it has twice the data of the next largest language (700K tokens vs 336K in English), but our approach still performs poorly.</p><p>Finally, while we saw that the hard clustering systems outperformed the HMM for our experi- ments, this is perhaps best explained by analyzing the average number of gold fine-grained tags per lexical type in each of the corpora. We found, counterintuitively, that the "difficult" languages had lower average number of tags per type (1.01 for Czech, 1.03 for Arabic) than English (1.17) which was the most ambiguous. This is likely due to morphology distinguishing otherwise ambigu- ous lemmas.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Cluster Analysis</head><p>In <ref type="table">Table 4</ref>, we present the three most frequent words from several clusters produced by the BMMM for English and Chinese. We also pro- vide a noun/verb/other label for each of the words in the list. One can clearly see that there are many ambiguous cases where having three labels voting</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>English</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Labels</head><p>Chinese Chinese gloss Labels shares, sales, business N, N, N , , simultaneously, politics, production O, N, N the, its, their O, N, N , , advance, hold, begin <ref type="table">Table 4</ref>: The top three words in BMMM clusters with their noun/verb/other labels. In two cases (marked with *) all three of the most frequent words also occurred as a verb at least one third of the time.</p><formula xml:id="formula_9">V, V, V other, interest, chief O, N, O , , in, have, for O, V, O of, in, on O, O, O , , China, Taiwan, USA N, N, N up, expected, made O, V, V , , also, will, then O, O, O be, make, sell V, V, V , , big, many, high O, N, O * offer, issue, work N, N, N * , , is, desire, representative V, V, N</formula><p>on the class label proves a beneficial signal. We have also marked two classes with * to draw the reader's attention to a fully noun cluster in En- glish and an other cluster in Chinese which are highly ambiguous. Specifically, in both of these cases the frequent words also occur frequently as verbs, providing additional motivation for a better soft-clustering algorithm in future work. How to most effectively use seed knowledge and annotation is still an open question. Ap- proaches range from labeling frequent words like the work of <ref type="bibr" target="#b12">Garrette and Baldridge (2013)</ref> to the recently introduced active learning approach of <ref type="bibr" target="#b31">Stratos and Collins (2015)</ref>. In this work, we were able to demonstrate high noun and verb recall with the use of a very small set of labeled words be- cause they correspond to an existing clustering. In contrast, we found that labeling even the 1000 most frequent words led to very few clusters being correctly identified; e.g. in English, using the 1000 most frequent words results in identifying 2 verb and 5 noun clusters, compared to our method's 9 verb and 16 noun clusters. This is because the most frequent words tend to be clustered in a few very large clusters resulting in low coverage. <ref type="bibr" target="#b31">Stratos and Collins (2015)</ref> demonstrated, simi- larly, that using a POS tagger's confidence score to find ambiguous classes can lead to a highly ef- fective adaptive learning procedure, which strate- gically labels very few words for a very highly ac- curate system. Our results align with this research, leading us to believe that this paradigm of guided minimal supervision is a fruitful direction for fu- ture work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>In this paper, we have produced the first labeled syntactic structures from raw text. There remains a noticeable performance gap due to the use of in- duced clusters in lieu of gold tags. Based on our final PASCAL results, there are several languages where our performance greatly exceeds the cur- rently published results, but equally many where we fall short. It also appears to be the case that this problem correlates with morphology (e.g. Arabic, Danish, Slovene, Basque, Czech) and some of the lowest performing intrinsic evaluations of the clus- tering and N/V/O labeling (Czech and Basque).</p><p>In principle, the BMMM is taking morphologi- cal information into account, as it is provided with the automatically produced suffixes of Morfessor. Unfortunately, its treatment of them simply as fea- tures from a "black box" appears to be too naive for our purposes. Properly modeling the rela- tionship between prefixes, stems and suffixes both within the tag induction and parsing framework is likely necessary for a high performing system.</p><p>Moving forward, additional raw text for train- ing, as well as enriching the clustering with in- duced syntactic information ( <ref type="bibr" target="#b9">Christodoulopoulos et al., 2012</ref>) may close this gap.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 : CCG parsing performance (LF1/UF1) on the test set with and without gold tags.</head><label>2</label><figDesc></figDesc><table>hertz equipment 
is 
a 
major supplier 
of 
rental equipment 
in 
the 
u.s. , france , spain and the u.k . 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Tagging VM and N/V/O Recall along-
side Directed Accuracy for our approach and the 
best shared task baseline. Additionally, we pro-
vide results for length 15 to compare to previ-
ously published results ([ST]: Best of the PAS-
CAL joint tag/dependency induction shared task 
systems; [BH]: Bisk and Hockenmaier (2013). 

</table></figure>

			<note place="foot" n="1"> https://github.com/percyliang/brown-cluster 2 https://github.com/christos-c/bmmm</note>

			<note place="foot" n="3"> To put this result into its full perspective, the LF1 performance of a supervised CCG system (Hockenmaier and Steedman, 2002), HWDep model, trained on the same length-20 dataset and tested on the simplified CCGbank test set is 80.3.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Acknowledgments</head><p>We want to thank Dan Roth and Cynthia Fisher for their insight on the task. Additionally, we would like to thank the anonymous reviewers for their useful questions and comments. This material is based upon work supported by the National Science Foundation under Grants No. 1053856, 1205627, 1405883, by the National In-stitutes of Health under Grant HD054448, and by DARPA under agreement number FA8750-13-2-0008. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation, the National Institutes of Health, DARPA or the U.S. Government.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Simple Robust Grammar Induction with Combinatory Categorial Grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hockenmaier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the TwentySixth Conference on Artificial Intelligence (AAAI12)</title>
		<meeting>the TwentySixth Conference on Artificial Intelligence (AAAI12)<address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-07" />
			<biblScope unit="page" from="1643" to="1649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An HDP Model for Inducing Combinatory Categorial Grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hockenmaier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="75" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Probing the linguistic strengths and limitations of unsupervised grammar induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hockenmaier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Unsupervised Induction of Tree Substitution Grammars for Dependency Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on Empirical Methods of Natural Language Processing</title>
		<meeting>the 2010 Conference on Empirical Methods of Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2010-10" />
			<biblScope unit="page" from="1204" to="1213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A hierarchical pitman-yor process hmm for unsupervised part of speech induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-06" />
			<biblScope unit="page" from="865" to="874" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Grammar Induction from Text Using Small Syntactic Prototypes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prachya</forename><surname>Boonkwan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 5th International Joint Conference on Natural Language Processing</title>
		<meeting>5th International Joint Conference on Natural Language Processing<address><addrLine>Chiang Mai, Thailand</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-11" />
			<biblScope unit="page" from="438" to="446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Class-Based n-gram Models of Natural Language. Computational Linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Peter F Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">L</forename><surname>Peter V Desouza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent J Della</forename><surname>Mercer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenifer C</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Two decades of unsupervised PoS induction: How far have we come?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Christodoulopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Goldwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="575" to="584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A Bayesian Mixture Model for Part-of-Speech Induction Using Multiple Features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Christodoulopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Goldwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Edinburgh, Scotland, UK.</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Turning the pipeline into a loop: iterated unsupervised dependency parsing and PoS induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Christodoulopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Goldwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WILS &apos;12: Proceedings of the NAACL-HLT Workshop on the Induction of Linguistic Structure</title>
		<imprint>
			<date type="published" when="2012-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Building deep dependency structures using a wide-coverage ccg parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hockenmaier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 40th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>40th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Philadelphia, Pennsylvania, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-07" />
			<biblScope unit="page" from="327" to="334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Morfessor in the Morpho challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathias</forename><surname>Creutz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krista</forename><surname>Lagus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the PASCAL Challenge Workshop on Unsupervised Segmentation of Words into Morphemes</title>
		<meeting>the PASCAL Challenge Workshop on Unsupervised Segmentation of Words into Morphemes</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="12" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning a Part-of-Speech Tagger from Two Hours of Annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Garrette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Baldridge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Atlanta, Georgia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-06" />
			<biblScope unit="page" from="138" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Weakly-Supervised GrammarInformed Bayesian CCG Parser Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Garrette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Baldridge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Association for the Advancement of Artificial Intelligence</title>
		<meeting>the Association for the Advancement of Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The PASCAL Challenge on Grammar Induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Gelling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Graca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL HLT Workshop on Induction of Linguistic Structure</title>
		<meeting><address><addrLine>Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-06" />
			<biblScope unit="page" from="64" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Posterior Sparsity in Unsupervised Dependency Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Gillenwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuzman</forename><surname>Ganchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>João</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Graca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Taskar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="455" to="490" />
			<date type="published" when="2011-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Prototype-Driven Grammar Induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aria</forename><surname>Haghighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics</title>
		<meeting><address><addrLine>Morristown, NJ, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="881" to="888" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Evaluating unsupervised part-ofspeech tagging for grammar induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">P</forename><surname>Headden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22Nd International Conference on Computational Linguistics</title>
		<meeting>the 22Nd International Conference on Computational Linguistics<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="329" to="336" />
		</imprint>
	</monogr>
	<note>COLING &apos;08</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Generative models for statistical parsing with combinatory categorial grammar</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hockenmaier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 40th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>40th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Philadelphia, Pennsylvania, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-07" />
			<biblScope unit="page" from="335" to="342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">CCGbank: A Corpus of CCG Derivations and Dependency Structures Extracted from the Penn Treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hockenmaier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="355" to="396" />
			<date type="published" when="2007-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Why doesn&apos;t EM find good HMM POS-taggers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the</title>
		<meeting>the</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<title level="m">Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)</title>
		<imprint>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">CorpusBased Induction of Syntactic Structure: Models of Dependency and Constituency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL&apos;04), Main Volume</title>
		<meeting>the 42nd Meeting of the Association for Computational Linguistics (ACL&apos;04), Main Volume<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-07" />
			<biblScope unit="page" from="478" to="485" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Using universal linguistic knowledge to guide grammar induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tahira</forename><surname>Naseem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harr</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2010 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-10" />
			<biblScope unit="page" from="1234" to="1244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A Universal Part-of-Speech Tagset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC-2012)</title>
		<meeting>the Eighth International Conference on Language Resources and Evaluation (LREC-2012)<address><addrLine>Istanbul, Turkey</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-05" />
			<biblScope unit="page" from="2089" to="2096" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Vmeasure: A conditional entropy-based external cluster evaluation measure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hirschberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the</title>
		<meeting>the</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<title level="m">Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)</title>
		<meeting><address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="410" to="420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Fast Unsupervised Incremental Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Seginer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics</title>
		<meeting>the 45th Annual Meeting of the Association of Computational Linguistics<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-06" />
			<biblScope unit="page" from="384" to="391" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Unsupervised Dependency Parsing without Gold Part-of-Speech Tags</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiyan</forename><surname>Valentin I Spitkovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Alshawi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Angel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Edinburgh, Scotland, UK.</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-07" />
			<biblScope unit="page" from="1281" to="1290" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Breaking Out of Local Optima with Count Transforms and Model Recombination: A Study in Grammar Induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiyan</forename><surname>Valentin I Spitkovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Alshawi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">The Syntactic Process</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000-09" />
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Simple semisupervised pos tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Stratos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Workshop on Vector Space Modeling for Natural Language Processing</title>
		<meeting>the 1st Workshop on Vector Space Modeling for Natural Language Processing</meeting>
		<imprint>
			<publisher>Denver, Colorado</publisher>
			<date type="published" when="2015-06" />
			<biblScope unit="page" from="79" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Hierarchical Dirichlet Processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee-Whye</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">J</forename><surname>Beal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">476</biblScope>
			<biblScope unit="page" from="1566" to="1581" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Chinese CCGBank: Deep Derivations and Dependencies for Chinese CCG Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Tse</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
		<respStmt>
			<orgName>The University of Sydney</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
