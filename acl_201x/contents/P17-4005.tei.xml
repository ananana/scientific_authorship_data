<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:51+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ESTEEM: A Novel Framework for Qualitatively Evaluating and Visualizing Spatiotemporal Embeddings in Social Media</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dustin</forename><surname>Arendt</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svitlana</forename><surname>Volkova</surname></persName>
						</author>
						<title level="a" type="main">ESTEEM: A Novel Framework for Qualitatively Evaluating and Visualizing Spatiotemporal Embeddings in Social Media</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of ACL 2017, System Demonstrations</title>
						<meeting>ACL 2017, System Demonstrations <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="25" to="30"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-4005</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Analyzing and visualizing large amounts of social media communications and contrasting short-term conversation changes over time and geolocations is extremely important for commercial and government applications. Earlier approaches for large-scale text stream summarization used dynamic topic models and trending words. Instead, we rely on text embeddings-low-dimensional word representations in a continuous vector space where similar words are embedded nearby each other. This paper presents ESTEEM, 1 a novel tool for visualizing and evaluating spa-tiotemporal embeddings learned from streaming social media texts. Our tool allows users to monitor and analyze query words and their closest neighbors with an interactive interface. We used state-of-the-art techniques to learn embeddings and developed a visualization to represent dynamically changing relations between words in social media over time and other dimensions. This is the first interactive visualization of streaming text representations learned from social media texts that also allows users to contrast differences across multiple dimensions of the data.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Motivation</head><p>Social media is an example of high volume dy- namic communications. Understanding and sum- marizing large amounts of streaming text data is extremely challenging. Traditional techniques that rely on experts, keywords and ontologies do not scale in this scenario. Dynamic topic models, <ref type="bibr">1</ref> Demo video: http://goo.gl/3N9Ozj</p><p>trending topics are widely used as text stream sum- marization techniques but they are biased and do not allow exploring dynamically changing rela- tionship between concepts in social media or con- trasting them across multiple dimensions.</p><p>Text embeddings represent words as nu- meric vectors in a continuous space, where words within similar contexts appear close to one another <ref type="bibr" target="#b8">(Harris, 1954)</ref>. Mapping words into a lower-dimensional vector space not only solves the dimensionality problem for predictive tasks <ref type="bibr" target="#b12">(Mikolov et al., 2013a</ref>), but also goes beyond topics and word clouds by capturing word simi- larities on syntactic, semantic and morphological levels ( <ref type="bibr" target="#b3">Gladkova and Drozd, 2016)</ref>.</p><p>Most past work has learned text representations from static corpora and visualized 2 the relation- ships between embedding vectors, measured us- ing cosine or Euclidian distance similarity, us- ing Principal Component Analysis (PCA) pro- jection in 2D ( <ref type="bibr" target="#b7">Hamilton et al., 2016b;</ref><ref type="bibr" target="#b18">Smilkov et al., 2016)</ref> or t-Distributed Stochastic Neighbor Embedding (t-SNE) technique (Van Der Maaten, 2014). Unlike static text corpora, in dynamically changing text streams the associations between words are changing over time e.g., days (Hamil- ton et al., 2016b,a), years ( <ref type="bibr" target="#b9">Kim et al., 2014</ref>) or centuries ( <ref type="bibr" target="#b5">Gulordava and Baroni, 2011</ref>). These changes are compelling to evaluate quantitatively, but, given the scale and complexity of the data, in- teresting findings are very difficult to capture with- out qualitative evaluation through visualization.</p><p>Moreover, the majority of NLP applications are using word embeddings as features for down- stream prediction tasks e.g., part-of-speech tag- ging ( <ref type="bibr" target="#b16">Santos and Zadrozny, 2014)</ref>, named entity recognition ( <ref type="bibr" target="#b14">Passos et al., 2014</ref>) and dependency parsing ( <ref type="bibr" target="#b10">Lei et al., 2014</ref>). However, in the compu- tational social sciences domain, embeddings are used to explore and characterize specific aspects of a text corpus by measuring, tracking and vi- sualizing relationships between words. For ex- ample, <ref type="bibr" target="#b1">Bolukbasi et al. (2016)</ref> evaluate cultural stereotypes between occupation and gender, <ref type="bibr" target="#b19">Stewart et al. (2017)</ref> predicted short-term changes in word meaning and usage in social media.</p><p>In this paper we present and publicly release a novel tool ESTEEM 3 for visualizing text represen- tations learned from dynamic text streams across multiple dimensions e.g., time and space. <ref type="bibr">4</ref> We present several practical use cases that focus on visualizing text representation changes in stream- ing social media data. These include visualizing word embeddings learned from tweets over time and across (A) geo-locations during crisis (Brus- sels Bombing Dataset), (B) verified and suspicious news posts (Suspicious News Dataset).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Embedding Types</head><p>Most existing algorithms for learning text rep- resentations model the context of words using a continuous bag-of-words approach ( <ref type="bibr" target="#b12">Mikolov et al., 2013a</ref>), skip-grams with negative sam- pling ( <ref type="bibr" target="#b13">Mikolov et al., 2013b</ref>) -Word2Vec, 5 mod- ified skip-grams with respect to the dependency tree of the sentence ( <ref type="bibr" target="#b11">Levy and Goldberg, 2014)</ref>, or optimized ratio of word co-occurrence proba- bilities ( <ref type="bibr" target="#b15">Pennington et al., 2014</ref>) -GloVe. <ref type="bibr">6</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Embedding Evaluation</head><p>There are two principle ways one can evaluate em- beddings: (a) intrinsically and (b) extrinsically.</p><p>(a) Intrinsic evaluations directly test syntactic or semantic relationships between the words, and rely on existing NLP resources e.g., WordNet and subjective human judgements e.g., crowdsourcing. (b) Extrinsic methods evaluate word vectors by measuring their performance when used for downstream NLP tasks e.g., dependency parsing, named entity recognition ( <ref type="bibr" target="#b14">Passos et al., 2014;</ref><ref type="bibr" target="#b4">Godin et al., 2015</ref>).</p><p>Recent work suggests that intrinsic and extrin- sic measures correlate poorly with one another ( <ref type="bibr" target="#b17">Schnabel et al., 2015;</ref><ref type="bibr" target="#b3">Gladkova and Drozd, 2016;</ref><ref type="bibr" target="#b21">Zhang et al., 2016</ref>). In many cases we want an embedding not just to capture relationships within the data, but also to do so in a way which can be usefully applied. In these cases, both intrinsic and extrinsic evaluation must be taken into account.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Use Cases</head><p>For demonstration purposes we rely on the Word2Vec implementation in gensim, but our tool can take any type of pre-trained embedding vec- tors. To ensure the quality of embeddings learned from social media streams, we lowercased, tok- enized and stemmed raw posts, <ref type="bibr">7</ref> and also applied standard NLP preprocessing to clean noisy social media texts e.g., remove punctuation, mentions, digits, emojis etc. Below we discuss two Twitter datasets we collected to demonstrate our tool for visualizing spatiotemporal text representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Brussels Bombing Dataset</head><p>We collected a large sample of tweets (with geo- locations and language IDs assigned to each tweet) from 240 countries in 66 languages from Twitter. Data collection lasted two weeks, beginning on March 15th, 2016 and ending March 29th, 2016. We chose this 15 day period because it includes the attacks on Brussels on March 22 (a widely- discussed event) as well as one whole week before and after the attacks. We used 140 million tweets in English to learn daily spatiotemporal embed- dings over time and across 10 European countries. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Suspicious News Dataset</head><p>We manually constructed a list of trusted news accounts that tweet in English and checked whether they are verified on Twitter. The exam- ple verified accounts include @cnn,@bbcnews, @foxnews. We found the list of accounts that spread suspicious news -propaganda, click- bait, hoaxes and satire, 8 e.g., @TheOnion, @ActivistPost,@DRUDGE_REPORT. We collected retweets generated in 2016 by any user that mentions one of these accounts and assigned the corresponding label propagated from suspi- cious or trusted news sources. In total, we col- lected 9.6 million verified news posts and 8.4 mil- lion suspicious news tweets. We used 18 million tweets to learn monthly embeddings over time and across suspicious and verified news account types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Visualization</head><p>Our objective was to provide users with a way to to visually understand how embeddings are chang- ing across multiple dimensions. Lets consider the Brussels Twitter dataset as an example where text representations vary over time and space. We ac- complish this by allowing the user to query our tool with a given keyword across set of locations, which produces corresponding visual representa- tions of the embeddings across time and space. The user can then inspect these visual embedding representations side by side, or combine them into a single representation for a more explicit compar- ison across regions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Design</head><p>The main challenge we faced in designing dy- namic embedding representations was with the scale and complexity of the embeddings, which have tens of thousands of words and hundreds of dimensions. Existing embedding visualiza- tion techniques have primarily relied on scatter plot representations of projected data <ref type="bibr" target="#b7">(Hamilton et al., 2016b</ref>), using principal components anal- ysis or other dimension reduction techniques e.g., t-Distributed Stochastic Neighbor Embedding.</p><p>However, these techniques are problematic be- cause they can create visual clutter if too many en- tities are projected, and they can be difficult to in- terpret. Embeddings, having high dimension, can not necessarily be projected into a 2-or 3-dimen- sional space without incurring significant visual distortion, which can degrade users' trust in the visualization ( <ref type="bibr" target="#b2">Chuang et al., 2012</ref>). Furthermore, <ref type="figure">Figure 1</ref>: Our visual metaphor stems from an adjacency rep- resentation A of the nearest neighbors of the query term. The rows of the matrix correspond to nearest neighbors, and the columns correspond to time windows. The cell aij is filled if word i is a neighbor of the query term at time j. To this ma- trix to make the matrix more readable by the user, we apply a visual transformation.</p><p>in our experience, many non-expert users are con- fused by the meaninglessness of the x-and y-co- ordinate space of the projected data, and have to be trained how to interpret such visualizations.</p><p>These problems are amplified when we consider dynamic data, where entities move throughout an embedding space over time. In our case, because embeddings are trained online, the meanings of the dimensions in the embeddings are changing, in addition to the words embedded therein. So, it is not correct to use traditional approaches to project an entities at different time points into the same space using the features directly.</p><p>Our solution was to rely on a user driven query- ing and nearest neighbor technique to address these challenges. We allow users to query the embedding using a single keyword, as we as- sume the user has a few items of interest they wish to explore, and is not concerned with un- derstanding the entire embedding. This allows us to frame our dynamic embedding visualization problem as a dynamic graph visualization prob- lem ( <ref type="bibr" target="#b0">Beck et al., 2014</ref>), specifically visualizing dynamic ego-networks.</p><p>Our visual representation shows how the nearest neighbors of a user-provided query term change over time. The user can choose the k nearest neighbor words shown in the visualization. We en- code time on the x-axis, whereas the y-axis is used to represent each nearest neighbor word returned by the query. This is a matrix representation of the nearest neighbors of the query term over time, as illustrated in <ref type="figure">Figure 1</ref>.</p><p>We apply a visual transformation to this ma- trix to make it easier to understand by replacing adjacent matrix cells with contiguous lines, and adding spacing between rows to help distinguish the query results. The words on the y-axis are sorted in the order they first become a neighbor of the query term. This helps the user see more recent terms, as they will float to the top, versus more persistent terms, which sink to the bottom, and have longer lines. <ref type="figure" target="#fig_0">Figure 2</ref> shows a screenshot of our interface containing three of regional dy- namic embeddings available for the term "bomb."</p><p>Users can compare visualizations of query re- sults side by side in the interface, but we also de- signed a more explicit comparison of embeddings using a modified version of our visualization tech- nique. Our goal for this comparison was to high- light similarities across two or more dynamic em- bedding queries over time. We accomplish this by first finding the shared neighbors of these queries within each time step, which is illustrated in <ref type="figure" target="#fig_1">Fig- ure 3</ref>. We show the results of these queries using the same visual metaphor as described above with an additional embellishment. The thickness of the line at a given time now encodes the number of shared neighbors across the query results at that time. Also, when a query result is shared by more than one query in the combined chart, its corre- sponding line is filled black, otherwise it retains its original color corresponding to its region. <ref type="figure" target="#fig_2">Figure 4</ref> shows an example of combining the query results for "bomb" across regions "Belgium," "Germany," and "United Kingdom."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Implementation</head><p>Our tool is a web application (i.e., client-server model) implemented using Python and Flask 9 for the server and React 10 and D3 11 for the client. The server is responsible for executing the query on the embeddings, whereas the client is respon- sible managing the users queries and visualizing the results. This separation of concerns means that the server assumes a large memory footprint 12 and processing burden, allowing the clients (i.e., web browsers) to be lightweight. This enables the in- terface to be used on a typical desktop or even a mobile device by multiple users simultaneously.  Finding the k-nearest neighbors of a query term in the embedding could take a long time to query for dynamic embeddings with many dimensions and entities. We relied on the "ball tree" data structure available in scikit-learn <ref type="bibr">13</ref> to help speed up the query. This data structure relies on the Eu- clidean distance metric, instead of cosine distance, which is considered a best practice. However, af- ter spot checking a few relevant queries using co- sine distance, we did not see a qualitative differ- ence between the two metrics, and continued us- ing the ball tree because of the performance ad- vantage. One ball tree is computed for each re- gion and time window, which has a large up front cost, but afterwards our tool provides embedding queries responsively (within 1 second per region). This approach is scalable because each query can divided independently into (region × time win- dow) sub-tasks, allowing the overall calculation to be distributed easily in a map-reduce architecture. <ref type="figure" target="#fig_2">Figure 4</ref> shows an example of combining the query re- sults for "bomb" across regions "Belgium," "Ger- many," and "United Kingdom." We observe that the shared neighbors of the query word "bomb" are Istanbul (March 22 -25), suicide (March 20 - 29), arrest (March 23 -27), and bomber (March 22 -29). The words Paris and Abdeslam are the neighbors only in Belgium, wound, Yemen and Iraq -in the UK, and Europe, suspect and Russia -in Germany. <ref type="figure">Fig- ure 5</ref> shows the results for an example query word pairs: (a) "zika" and "risk" and (b) "Europe" and "refugee" learned from content extracted from suspicious and verified news in 2016. We found that potential, mosquito, increase, virus and con- cern are shared neighbors of two query words "zika" and "risk". We observed that European, Greece, Germany and migrant are shared neigh- bors of two query words "Europe" and "refugee".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analyzing Brussels Embeddings</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analyzing Suspicious News Embeddings</head><p>(a) Zika and Risk (b) Europe and Refugee <ref type="figure">Figure 5</ref>: Visualization of dynamic embeddings for the words "zika" and "risk" with 2 neighbors learned from verified (green) and unverified (orange) news on Twitter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We have presented ESTEEM, a novel frame- work for visualizing and qualitatively evaluat- ing spatiotemporal embeddings learned from large amounts of dynamic text data. Our system allows users to explore specific aspects of text stream- ing corpus using continuous word representations. Unlike any other embedding visualization, our tool allows contrasting word representation differ- ences over time across other dimensions e.g., ge- olocation, news types etc. For future work we plan to improve the tool by allowing the user to query using phrases and hashtags.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Acknowledgments</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Visualization of dynamic embedding queries for the word "bomb" across the regions "Belgium," "Germany," and "United Kingdom" are shown. Time is encoded on the horizontal axis, and words are sorted by first occurrence (as a nearest neighbor) for the query term.</figDesc><graphic url="image-4.png" coords="4,72.00,407.60,218.26,78.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Dynamic embedding queries are combined by finding the shared neighbors across their query results at each time step. This example shows how three separate queries {q1, q2, q3} across two regions could have overlap in the result words within a single timestamp.</figDesc><graphic url="image-5.png" coords="4,329.10,481.80,174.61,134.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The dynamic embedding queries from Figure 2 are combined into a single chart to support a more explicit comparison of the dynamic embeddings across countries-Belgium (green), German (purple), UK (orange). Where the results overlap from the individual queries, a thicker black line is drawn.</figDesc><graphic url="image-6.png" coords="5,72.00,62.81,453.55,171.47" type="bitmap" /></figure>

			<note place="foot" n="2"> TensorBoard Embedding Visualization: https://www.tensorflow.org/get_started/ embedding_viz</note>

			<note place="foot" n="3"> Live demo: http://esteem.labworks.org 4 Code: https://github.com/pnnl/esteem/ 5 Word2Vec in gensim: https://radimrehurek. com/gensim/models/word2vec.html 6 GloVe: https://cran.r-project.org/web/ packages/text2vec/vignettes/glove.html</note>

			<note place="foot" n="7"> Stemming is rarely done when learning embeddings. We stemmed our data because we are not interested in recovering syntactic relationships between the words.</note>

			<note place="foot" n="8"> http://www.fakenewswatch.com/ http://www.propornot.com/p/the-list.html</note>

			<note place="foot" n="9"> http://flask.pocoo.org 10 https://facebook.github.io/react/ 11 http://d3js.org 12 For our Brussels data set, each dynamic embedding requires approximately 500MB of disk space and 2GB in memory after the data structures are created.</note>

			<note place="foot" n="13"> http://scikit-learn.org/stable/ modules/generated/sklearn.neighbors. BallTree.html</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The state of the art in visualizing dynamic graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Diehl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Weiskopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EuroVis STAR</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Man is to computer programmer as woman is to homemaker? debiasing word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tolga</forename><surname>Bolukbasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">Y</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Venkatesh</forename><surname>Saligrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam T</forename><surname>Kalai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4349" to="4357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Interpretation and trust: Designing model-driven visualizations for text analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Ramage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGCHI</title>
		<meeting>SIGCHI</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="443" to="452" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Intrinsic evaluations of word embeddings: What can we do better?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Gladkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandr</forename><surname>Drozd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Named entity recognition for twitter microposts using distributed word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fréderic</forename><surname>Godin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baptist</forename><surname>Vandersmissen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wesley</forename><surname>De Neve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rik</forename><surname>Van De Walle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-IJCNLP</title>
		<meeting>ACL-IJCNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A distributional similarity approach to the detection of semantic change in the Google Books Ngram corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Gulordava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of GEMS</title>
		<meeting>GEMS</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="67" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Diachronic word embeddings reveal statistical laws of semantic change</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Cultural shift or linguistic drift? comparing two computational measures of semantic change</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>William L Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zellig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Harris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Distributional structure. Word</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="146" to="162" />
			<date type="published" when="1954" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Temporal analysis of language through neural language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-I</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kentaro</forename><surname>Hanaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Darshan</forename><surname>Hegde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Low-rank tensors for scoring dependency structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommi</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Dependencybased word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionally</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Lexicon infused phrase embeddings for named entity resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vineet</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL</title>
		<meeting>CoNLL</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning character-level representations for part-ofspeech tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nogueira</forename><surname>Cícero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bianca</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zadrozny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Evaluation methods for unsupervised word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Schnabel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><surname>Labutov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mimno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Embedding projector: Interactive visualization and interpretation of embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Smilkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhil</forename><surname>Thorat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Nicholson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Reif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernanda</forename><forename type="middle">B</forename><surname>Viégas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Wattenberg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.05469</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Measuring, predicting and visualizing short-term change in word representation and usage in vkontakte social network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dustin</forename><surname>Arendt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svitlana</forename><surname>Volkova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICWSM</title>
		<meeting>ICWSM</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Accelerating t-sne using tree-based algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3221" to="3245" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Towards understanding word embeddings: Automatically explaining similarity of terms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yating</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Jatowt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katsumi</forename><surname>Tanaka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Big Data</title>
		<meeting>Big Data</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="823" to="832" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
