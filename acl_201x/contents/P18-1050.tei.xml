<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:04+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Temporal Event Knowledge Acquisition via Identifying Narratives</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 15-20, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenlin</forename><surname>Yao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Texas A&amp;M University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruihong</forename><surname>Huang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Texas A&amp;M University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Temporal Event Knowledge Acquisition via Identifying Narratives</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="537" to="547"/>
							<date type="published">July 15-20, 2018</date>
						</imprint>
					</monogr>
					<note>537</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Inspired by the double temporality characteristic of narrative texts, we propose a novel approach for acquiring rich temporal &quot;before/after&quot; event knowledge across sentences in narrative stories. The double temporality states that a narrative story often describes a sequence of events following the chronological order and therefore , the temporal order of events matches with their textual order. We explored narratology principles and built a weakly supervised approach that identifies 287k narrative paragraphs from three large text corpora. We then extracted rich temporal event knowledge from these narrative paragraphs. Such event knowledge is shown useful to improve temporal relation classification and outperform several recent neural network models on the narrative cloze task.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Occurrences of events, referring to changes and actions, show regularities. Specifically, certain events often co-occur and in a particular temporal order. For example, people often go to work af- ter graduation with a degree. Such "before/after" temporal event knowledge can be used to recog- nize temporal relations between events in a doc- ument even when their local contexts do not in- dicate any temporal relations. Temporal event knowledge is also useful to predict an event given several other events in the context. Improving event temporal relation identification and event prediction capabilities can benefit various NLP applications, including event timeline generation, text summarization and question answering.</p><p>While being in high demand, temporal event  knowledge is lacking and difficult to obtain. Ex- isting knowledge bases, such as Freebase ( <ref type="bibr" target="#b3">Bollacker et al., 2008</ref>) or Probase ( <ref type="bibr">Wu et al., 2012)</ref>, often contain rich knowledge about entities, e.g., the birthplace of a person, but contain little event knowledge. Several approaches have been pro- posed to acquire temporal event knowledge from a text corpus, by either utilizing textual patterns ( <ref type="bibr" target="#b8">Chklovski and Pantel, 2004</ref>) or building a tempo- ral relation identifier ( <ref type="bibr">Yao et al., 2017)</ref>. However, most of these approaches are limited to identifying temporal relations within one sentence. Inspired by the double temporality character- istic of narrative texts, we propose a novel ap- proach for acquiring rich temporal "before/after" event knowledge across sentences via identify- ing narrative stories. The double temporality states that a narrative story often describes a se- quence of events following the chronological or- der and therefore, the temporal order of events matches with their textual order <ref type="bibr">(Walsh, 2001</ref>; <ref type="bibr">Riedl and Young, 2010;</ref><ref type="bibr" target="#b16">Grabes, 2013)</ref>. There- fore, we can easily distill temporal event knowl- edge if we have identified a large collection of narrative texts. Consider the two narrative ex- amples in <ref type="figure" target="#fig_0">figure 1</ref>, where the top one is from a news article of New York Times and the bot- tom one is from a novel book. From the top one, we can easily extract one chronologically or- dered event sequence {graduated, marry, attend, receive, work, take over, expand, increase}, with all events related to the main character Michael Kennedy. While some parts of the event sequence are specific to this story, the event sequence con- tains regular event temporal relations, e.g., people often {graduate} first and then get {married}, or {take over} a role first and then {expand} a goal. Similarly, from the bottom one, we can easily ex- tract another event sequence {pay, jump out, head, reach into, enter, undress, shower, change, grab, leave} that contains routine actions when people take a shower and change clothes.</p><p>There has been recent research on narrative identification from blogs by building a text clas- sifier in a supervised manner <ref type="bibr" target="#b15">(Gordon and Swanson, 2009;</ref><ref type="bibr" target="#b5">Ceran et al., 2012</ref>). However, narra- tive texts are common in other genres as well, including news articles and novel books, where little annotated data is readily available. There- fore, in order to identify narrative texts from rich sources, we develop a weakly supervised method that can quickly adapt and identify narrative texts from different genres, by heavily exploring the principles that are used to characterize narrative structures in narratology studies. It is generally agreed in narratology <ref type="bibr" target="#b14">(Forster, 1962;</ref><ref type="bibr" target="#b25">Mani, 2012;</ref><ref type="bibr" target="#b31">Pentland, 1999;</ref><ref type="bibr" target="#b0">Bal, 2009</ref>) that a narrative is a dis- course presenting a sequence of events arranged in their time order (the plot) and involving specific characters (the characters). First, we derive spe- cific grammatical and entity co-reference rules to identify narrative paragraphs that each contains a sequence of sentences sharing the same actantial syntax structure (i.e., NP VP describing a charac- ter did something) <ref type="bibr" target="#b19">(Greimas, 1971)</ref> and mention- ing the same character. Then, we train a classifier using the initially identified seed narrative texts and a collection of grammatical, co-reference and linguistic features that capture the two key princi- ples and other textual devices of narratives. Next, the classifier is applied back to identify new narra- tives from raw texts. The newly identified narra- tives will be used to augment seed narratives and the bootstrapping learning process iterates until no enough new narratives can be found.</p><p>Then by leveraging the double temporality char- acteristic of narrative paragraphs, we distill gen- eral temporal event knowledge. Specifically, we extract event pairs as well as longer event se- quences consisting of strongly associated events that often appear in a particular textual order in narrative paragraphs, by calculating Causal Poten- tial <ref type="bibr" target="#b1">(Beamer and Girju, 2009;</ref><ref type="bibr" target="#b20">Hu et al., 2013</ref>) be- tween events.</p><p>Specifically, we obtained 19k event pairs and 25k event sequences with three to five events from the 287k narrative paragraphs we identified across three genres, news articles, novel books and blogs. Our evaluation shows that both the automatically identified narrative paragraphs and the extracted event knowledge are of high quality. Furthermore, the learned temporal event knowledge is shown to yield additional performance gains when used for temporal relation identification and the Narrative Cloze task. The acquired event temporal knowl- edge and the knowledge acquisition system are publicly available 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Several previous works have focused on acquir- ing temporal event knowledge from texts. Ver- bOcean ( <ref type="bibr" target="#b8">Chklovski and Pantel, 2004</ref>) used pre- defined lexico-syntactic patterns (e.g., "X and then Y") to acquire event pairs with the temporal hap- pens before relation from the Web. <ref type="bibr">Yao et al. (2017)</ref> simultaneously trained a temporal "be- fore/after" relation classifier and acquired event pairs that are regularly in a temporal relation by exploring the observation that some event pairs tend to show the same temporal relation regardless of contexts. Note that these prior works are limited to identifying temporal relations within individual sentences. In contrast, our approach is designed to acquire temporal relations across sentences in a narrative paragraph. Interestingly, only 195 (1%) out of 19k event pairs acquired by our approach can be found in VerbOcean or regular event pairs learned by the previous two approaches.</p><p>Our design of the overall event knowledge ac- quisition also benefits from recent progress on nar- rative identification. <ref type="bibr" target="#b15">Gordon and Swanson (2009)</ref> annotated a small set of paragraphs presenting sto- ries in the ICWSM Spinn3r Blog corpus ( <ref type="bibr" target="#b4">Burton et al., 2009</ref>) and trained a classifier using bag-of- words features to identify more stories. <ref type="bibr" target="#b5">(Ceran et al., 2012</ref>) trained a narrative classifier using se- mantic triplet features on the CSC Islamic Extrem- ist corpus. Our weakly supervised narrative iden- tification method is closely related to <ref type="bibr" target="#b11">Eisenberg and Finlayson (2017)</ref>, which also explored the two key elements of narratives, the plot and the charac- ters, in designing features with the goal of obtain- ing a generalizable story detector. But different from this work, our narrative identification method does not require any human annotations and can quickly adapt to new text sources.</p><p>Temporal event knowledge acquisition is re- lated to script learning ( <ref type="bibr" target="#b7">Chambers and Jurafsky, 2008)</ref>, where a script consists of a sequence of events that are often temporally ordered and rep- resent a typical scenario. However, most of the existing approaches on script learning <ref type="bibr" target="#b6">(Chambers and Jurafsky, 2009;</ref><ref type="bibr" target="#b32">Pichotta and Mooney, 2016;</ref><ref type="bibr" target="#b18">Granroth-Wilding and Clark, 2016)</ref> were designed to identify clusters of closely related events, not to learn the temporal order between events though. For example, <ref type="bibr">Jurafsky (2008, 2009)</ref> learned event scripts by first identifying closely re- lated events that share an argument and then rec- ognizing their partial temporal orders by a separate temporal relation classifier trained on the small la- beled dataset TimeBank ( <ref type="bibr" target="#b33">Pustejovsky et al., 2003)</ref>. Using the same method to get training data, <ref type="bibr" target="#b22">Jans et al. (2012)</ref>; <ref type="bibr" target="#b18">Granroth-Wilding and Clark (2016)</ref>; <ref type="bibr" target="#b32">Pichotta and Mooney (2016)</ref>; <ref type="bibr">Wang et al. (2017)</ref> applied neural networks to learn event embed- dings and predict the following event in a con- text. Distinguished from the previous script learn- ing works, we focus on acquiring event pairs or longer script-like event sequences with events ar- ranged in a complete temporal order. In addi- tion, recent works ( <ref type="bibr">Regneri et al., 2010;</ref><ref type="bibr" target="#b28">Modi et al., 2016)</ref> collected script knowledge by directly asking Amazon Mechanical Turk (AMT) to write down typical temporally ordered event sequences in a given scenario (e.g., shopping or cooking). In- terestingly, our evaluation shows that our approach can yield temporal event knowledge that covers 48% of human-provided script knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Key Elements of Narratives</head><p>It is generally agreed in narratology <ref type="bibr" target="#b14">(Forster, 1962;</ref><ref type="bibr" target="#b25">Mani, 2012;</ref><ref type="bibr" target="#b31">Pentland, 1999;</ref><ref type="bibr" target="#b0">Bal, 2009</ref>) that a narrative presents a sequence of events arranged in their time order (the plot) and involving specific characters (the characters).</p><p>Plot. The plot consists of a sequence of closely re- lated events. According to <ref type="bibr" target="#b0">(Bal, 2009)</ref>, an event in a narrative often describes a "transition from one state to another state, caused or experienced by ac- tors". Moreover, as Mani <ref type="formula" target="#formula_0">(2012)</ref> illustrates, a nar- rative is often "an account of past events in some- one's life or in the development of something". These prior studies suggest that sentences contain- ing a plot event are likely to have the actantial syn- tax "NP VP" 2 ( <ref type="bibr" target="#b19">Greimas, 1971)</ref> with the main verb in the past tense. Character. A narrative usually describes events caused or experienced by actors. Therefore, a nar- rative story often has one or two main characters, called protagonists, who are involved in multiple events and tie events together. The main character can be a person or an organization. Other Textual Devices. A narrative may contain peripheral contents other than events and charac- ters, including time, place, the emotional and psy- chological states of characters etc., which do not advance the plot but provide essential information to the interpretation of the events <ref type="bibr" target="#b31">(Pentland, 1999</ref>). We use rich Linguistic Inquiry and Word Count (LIWC) ( <ref type="bibr" target="#b30">Pennebaker et al., 2015</ref>) features to cap- ture a variety of textual devices used to describe such contents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Phase One: Weakly Supervised Narrative Identification</head><p>In order to acquire rich temporal event knowledge, we first develop a weakly supervised approach that can quickly adapt to identify narrative paragraphs from various text sources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">System Overview</head><p>The weakly supervised method is designed to cap- ture key elements of narratives in each of two stages. As shown in <ref type="figure">figure 2</ref>, in the first stage, we identify the initial batch of narrative paragraphs that satisfy strict rules and the key principles of narratives. Then in the second stage, we train a sta- tistical classifier using the initially identified seed narrative texts and a collection of soft features for capturing the same key principles and other tex- tual devices of narratives. Next, the classifier is applied to identify new narratives from raw texts again. The newly identified narratives will be used to augment seed narratives and the bootstrapping <ref type="figure">Figure 2</ref>: Overview of the Narrative Learning System learning process iterates until no enough (specifi- cally, less than 2,000) new narratives can be found. Here, in order to specialize the statistical classifier to each genre, we conduct the learning process on news, novels and blogs separately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Rules for Identifying Seed Narratives</head><p>Grammar Rules for Identifying Plot Events. Guided by the prior narratology studies <ref type="bibr" target="#b19">(Greimas, 1971;</ref><ref type="bibr" target="#b25">Mani, 2012)</ref> and our observations, we use context-free grammar production rules to identify sentences that describe an event in an actantial syntax structure. Specifically, we use three sets of grammar rules to specify the overall syntactic structure of a sentence. First, we require a sen- tence to have the basic active voiced structure "S → NP VP" or one of the more complex sentence structures that are derived from the basic struc- ture considering Coordinating Conjunctions (CC), Adverbial Phrase (ADVP) or Prepositional Phrase (PP) attachments 3 . For example, in the narrative of <ref type="figure" target="#fig_0">Figure 1</ref>, the sentence "Michael Kennedy earned a bachelor's degree from Harvard University in 1980." has the basic sentence structure "S → NP VP", where the "NP" governs the character men- tion of 'Michael Kennedy' and the "VP" governs the rest of the sentence and describes a plot event.</p><p>In addition, considering that a narrative is usu- ally "an account of past events in someone's life or in the development of something" <ref type="bibr" target="#b25">(Mani, 2012;</ref><ref type="bibr" target="#b10">Dictionary, 2007)</ref>, we require the headword of the VP to be in the past tense. Furthermore, the sub- ject of the sentence is meant to represent a char- acter. Therefore, we specify 12 grammar rules 4 to require the sentence subject noun phrase to have a simple structure and have a proper noun or pro- noun as its head word.</p><p>For seed narratives, we consider paragraphs containing at least four sentences and we require 60% or more sentences to satisfy the sentence structure specified above. We also require a nar- rative paragraph to contain no more than 20% of sentences that are interrogative, exclamatory or di- alogue, which normally do not contain any plot events. The specific parameter settings are mainly determined based on our observations and anal- ysis of narrative samples. The threshold of 60% for "sentences with actantial structure" was set to reflect the observation that sentences in a narra- tive paragraph usually (over half) have an actan- tial structure. A small portion (20%) of interroga- tive, exclamatory or dialogue sentences is allowed to reflect the observation that many paragraphs are overall narratives even though they may contain 1 or 2 such sentences, so that we achieve a good coverage in narrative identification.</p><p>The Character Rule. A narrative usually has a protagonist character that appears in multiple sen- tences and ties a sequence of events, therefore, we also specify a rule requiring a narrative para- graph to have a protagonist character. Concretely, inspired by <ref type="bibr" target="#b11">Eisenberg and Finlayson (2017)</ref>, we applied the named entity recognizer ( <ref type="bibr" target="#b13">Finkel et al., 2005</ref>) and entity coreference resolver ( <ref type="bibr" target="#b23">Lee et al., 2013</ref>) from the CoreNLP toolkit ( <ref type="bibr" target="#b26">Manning et al., 2014</ref>) to identify the longest entity chain in a para- graph that has at least one mention recognized as a Person or Organization, or a gendered pronoun. Then we calculate the normalized length of this entity chain by dividing the number of entity men- tions by the number of sentences in the paragraph. We require the normalized length of this longest entity chain to be ≥ 0.4, meaning that 40% or more sentences in a narrative mention a character 5 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">The Statistical Classifier for Identifying New Narratives</head><p>Using the seed narrative paragraphs identified in the first stage as positive instances, we train a sta- tistical classifier to continue to identify more nar- rative paragraphs that may not satisfy the specific rules. We also prepare negative instances to com- pete with positive narrative paragraphs in train- ing. Negative instances are paragraphs that are not likely to be narratives and do not present a plot or protagonist character, but are similar to seed narra- tives in others aspects. Specifically, similar to seed narratives, we require a non-narrative paragraph to contain at least four sentences with no more than 20% of sentences being interrogative, exclamatory or dialogue; but in contrast to seed narratives, a non-narrative paragraph should contain 30% of or fewer sentences that have the actantial sentence structure, where the longest character entity chain should not span over 20% of sentences. We ran- domly sample such non-narrative paragraphs that are five times of narrative paragraphs <ref type="bibr">6</ref> . In addition, since it is infeasible to apply the trained classifier to all the paragraphs in a large text corpus, such as the Gigaword corpus ( <ref type="bibr" target="#b17">Graff and Cieri, 2003)</ref>, we identify candidate narrative paragraphs and only apply the statistical classifier to these candidate paragraphs. Specifically, we re- quire a candidate paragraph to satisfy all the con- straints used for identifying seed narrative para- graphs but contain only 30% 7 or more sentences with an actantial structure and have the longest character entity chain spanning over 20% 8 of or more sentences.</p><p>We choose Maximum Entropy ( <ref type="bibr" target="#b2">Berger et al., 1996)</ref> as the classifier. Specifically, we use the MaxEnt model implementation in the LIBLIN-EAR library <ref type="bibr">9 (Fan et al., 2008</ref>) with default pa- rameter settings. Next, we describe the features used to capture the key elements of narratives.</p><p>Features for Identifying Plot Events: Realiz- ing that grammar production rules are effective in identifying sentences that contain a plot event, we encode all the production rules as features in the statistical classifier. Specifically, for each narra- tive paragraph, we use the frequency of all syntac- tic production rules as features. Note that the bot- tom level syntactic production rules have the form of POS tag → WORD and contain a lexical word, which made these rules dependent on specific con- texts of a paragraph. Therefore, we exclude these bottom level production rules from the feature set in order to model generalizable narrative elements rather than specific contents of a paragraph.</p><p>In addition, to capture potential event sequence overlaps between new narratives and the already learned narratives, we build a verb bigram lan- guage model using verb sequences extracted from the learned narrative paragraphs and calculate the perplexity score (as a feature) of the verb sequence in a candidate narrative paragraph. Specifically, we calculate the perplexity score of an event se- quence that is normalized by the number of events, P P (e 1 , ..., e N ) = N N i=1 1 P (e i |e i−1 ) , where N is the total number of events in a sequence and e i is a event word. We approximate P (e i |e i−1 ) = C(e i−1 ,e i ) C(e i−1 ) , where C(e i−1 ) is the number of oc- currences of e i−1 and C(e i−1 , e i ) is the number of co-occurrences of e i−1 and e i . C(e i−1 , e i ) and C(e i−1 ) are calculated based on all event se- quences from known narrative paragraphs.</p><p>Features for the Protagonist Characters: We consider the longest three coreferent entity chains in a paragraph that have at least one mention rec- ognized as a Person or Organization, or a gen- dered pronoun. Similar to the seed narrative iden- tification stage, we obtain the normalized length of each entity chain by dividing the number of entity mentions with the number of sentences in the paragraph. In addition, we also observe that a protagonist character appears frequently in the surrounding paragraphs as well, therefore, we cal- culate the normalized length of each entity chain based on its presences in the target paragraph as well as one preceding paragraph and one follow-0 <ref type="table" target="#tab_2">(Seeds)  1  2  3  4  Total  News  20k  40k  12k  5k  1k  78k  Novels  75k  82k  24k  6k  2k 189k  Blogs  6k  10k  3k  1k  - 20k  Sum  101k  132k 39k 12k 3k 287k   Table 1</ref>: Number of new narratives generated after each bootstrapping iteration ing paragraph. We use 6 normalized lengths (3 from the target paragraph 10 and 3 from surround- ing paragraphs) as features.</p><p>Other Writing Style Features: We create a fea- ture for each semantic category in the Linguistic Inquiry and Word Count (LIWC) dictionary <ref type="bibr" target="#b30">(Pennebaker et al., 2015)</ref>, and the feature value is the total number of occurrences of all words in that category. These LIWC features capture presences of certain types of words, such as words denoting relativity (e.g., motion, time, space) and words re- ferring to psychological processes (e.g., emotion and cognitive). In addition, we encode Parts-of- Speech (POS) tag frequencies as features as well which have been shown effective in identifying text genres and writing styles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Identifying Narrative Paragraphs from Three Text Corpora</head><p>Our weakly supervised system is based on the principles shared across all narratives, so it can be applied to different text sources for identify- ing narratives. We considered three types of texts:</p><p>(1) News Articles. News articles contain narrative paragraphs to describe the background of an im- portant figure or to provide details for a significant event. We use English Gigaword 5th edition ( <ref type="bibr" target="#b17">Graff and Cieri, 2003;</ref><ref type="bibr" target="#b29">Napoles et al., 2012</ref>), which con- tains 10 million news articles. (2) Novel Books. Novels contain rich narratives to describe actions by characters. BookCorpus ( <ref type="bibr">Zhu et al., 2015</ref>) is a large collection of free novel books written by un- published authors, which contains 11,038 books of 16 different sub-genres (e.g., Romance, Historical, Adventure, etc.). (3) Blogs. Vast publicly accessi- ble blogs also contain narratives because "personal life and experiences" is a primary topic of blog posts <ref type="bibr" target="#b24">(Lenhart, 2006</ref>). We use the Blog Author- ship Corpus ( <ref type="bibr">Schler et al., 2006</ref>) collected from the blogger.com website, which consists of 680k posts written by thousands of authors. We applied the Stanford CoreNLP tools ( <ref type="bibr" target="#b26">Manning et al., 2014)</ref> to the three text corpora to obtain POS tags, parse trees, named entities, coreference chains, etc. In order to combat semantic drifts <ref type="bibr" target="#b27">(McIntosh and Curran, 2009</ref>) in bootstrapping learning, we set the initial selection confidence score produced by the statistical classifier at 0.5 and increase it by 0.05 after each iteration. The bootstrapping sys- tem runs for four iterations and learns 287k narra- tive paragraphs in total. <ref type="table">Table 1</ref> shows the num- ber of narratives that were obtained in the seed- ing stage and in each bootstrapping iteration from each text corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Phase Two: Extract Event Temporal</head><p>Knowledge from Narratives</p><p>Narratives we obtained from the first phase may describe specific stories and contain uncommon events or event transitions. Therefore, we apply Pointwise Mutual Information (PMI) based statis- tical metrics to measure strengths of event tempo- ral relations in order to identify general knowl- edge that is not specific to any particular story. Our goal is to learn event pairs and longer event chains with events completely ordered in the tem- poral "before/after" relation. First, by leveraging the double temporality char- acteristic of narratives, we only consider event pairs and longer event chains with 3-5 events that have occurred as a segment in at least one event sequence extracted from a narrative paragraph. Specifically, we extract the event sequence (the plot) from a narrative paragraph by finding the main event in each sentence and chaining the main events 11 according to their textual order.</p><p>Then we rank candidate event pairs based on two factors, how strongly associated two events are and how common they appear in a particu- lar temporal order. We adopt the existing met- ric, Causal Potential (CP), which has been ap- plied to acquire causally related events (Beamer and Girju, 2009) and exactly measures the two as- pects. Specifically, the CP score of an event pair is calculated using the following equation:</p><formula xml:id="formula_0">cp(ei, ej) = pmi(ei, ej) + log P (ei → ej) P (ej → ei)<label>(1)</label></formula><p>where, the first part refers to the Pointwise Mutual Information (PMI) between two events and the second part measures the relative ordering or two events. P (e i → e j ) refers to the probability that e i occurs before e j in a text, which is proportional to the raw frequency of the pair. PMI measures the association strength of two events, formally, pmi(e i , e j ) = log P (e i ,e j )</p><formula xml:id="formula_1">P (e i )P (e j ) , P (e i ) = C(e i ) x C(ex)</formula><p>and P (e i , e j ) = C(e i ,e j )</p><p>x y C(ex,ey) , where, x and y refer to all the events in a corpus, C(e i ) is the num- ber of occurrences of e i , C(e i , e j ) is the number of co-occurrences of e i and e j .</p><p>While each candidate pair of events should have appeared consecutively as a segment in at least one narrative paragraph, when calculating the CP score, we consider event co-occurrences even when two events are not consecutive in a narra- tive paragraph but have one or two other events in between. Specifically, the same as in ( <ref type="bibr" target="#b21">Hu and Walker, 2017)</ref>, we calculate separate CP scores based on event co-occurrences with zero (consec- utive), one or two events in between, and use the weighted average CP score for ranking an event pair, formally,</p><formula xml:id="formula_2">CP (e i , e j ) = 3 d=1 cp d (e i ,e j ) d</formula><p>. Then we rank longer event sequences based on CP scores for individual event pairs that are in- cluded in an event sequence. However, an event sequence of length n is more than n − 1 event pairs with any two consecutive events as a pair. We prefer event sequences that are coherent over- all, where the events that are one or two events away are highly related as well. Therefore, we de- fine the following metric to measure the quality of an event sequence:</p><formula xml:id="formula_3">CP (e1, e2, · · · , en) = 3 d=1 n−d j=1 CP (e j ,e j+d ) d n − 1 . (2)</formula><p>6 Evaluation</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Precision of Narrative Paragraphs</head><p>From all the learned narrative paragraphs, we ran- domly selected 150 texts, with 25 texts selected from narratives learned in each of the two stages (i.e., seed narratives and bootstrapped narratives) using each of the three text corpora (i.e., news, novels, and blogs). Following the same definition "A story is a narrative of events arranged in their time sequence" <ref type="bibr" target="#b14">(Forster, 1962;</ref><ref type="bibr" target="#b15">Gordon and Swanson, 2009</ref>), two human adjudicators were asked to judge whether each text is a narrative or a non- narrative. In order to obtain high inter-agreements, before the official annotations, we trained the two annotators for several iterations. Note that the   texts we used in training annotators are different from the final texts we used for evaluation pur- poses. The overall kappa inter-agreement between the two annotators is 0.77. <ref type="table" target="#tab_2">Table 2</ref> shows the precision of narratives learned in the two stages using the three corpora. We determined that a text is a correct narrative if both annotators labeled it as a narrative. We can see that on average, the rule-based classifier achieves the precision of 88% on initializing seed narratives and the statistical classifier achieves the precision of 84% on bootstrapping new ones. Us- ing narratology based features enables the statis- tical classifier to extensively learn new narrative, and meanwhile maintain a high precision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Precision of Event Pairs and Chains</head><p>To evaluate the quality of the extracted event pairs and chains, we randomly sampled 20 pairs (2%) from every 1,000 event pairs up to the top 18,929 pairs with CP score ≥ 2.0 (380 pairs selected in to- tal), and 10 chains (1%) from every 1,000 up to the top 25,000 event chains 12 (250 chains selected in total). The average CP scores for all event pairs and all event chains we considered are 2.9 and 5.1 respectively. Two human adjudicators were asked to judge whether or not events are likely to occur in the temporal order shown. For event chains, we have one additional criterion requiring that events form a coherent sequence overall. An  As we know, coverage on acquired knowledge is often hard to evaluate because we do not have a complete knowledge base to compare to. Thus, we propose a pseudo recall metric to evaluate the coverage of event knowledge we acquired. <ref type="bibr">Regneri et al. (2010)</ref> collected Event Sequence De- scriptions (ESDs) of several types of human ac- tivities (e.g., baking a cake, going to the theater, etc.) using crowdsourcing. Our first pseudo re- call score is calculated based on how many con- secutive event pairs in human-written scripts can be found in our top-ranked event pairs. <ref type="figure" target="#fig_1">Figure 3</ref> illustrates the precision of top-ranked pairs based on human annotation and the pseudo recall score based on ESDs. We can see that about 75% of the top 19k event pairs are correct, which captures 48% of human-written script knowledge in ESDs. In addition, table 4 shows the precision of top- ranked event chains with 3 to 5 events. Among the top 25k event chains, about 70% are correctly ordered with the temporal "after" relation. <ref type="table" target="#tab_3">Table 3</ref> shows several examples of event pairs and chains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Improving Temporal Relation Classification by Incorporating Event Knowledge</head><p>To find out whether the learned temporal event knowledge can help with improving temporal re- Models Acc.(%) <ref type="bibr" target="#b9">Choubey and Huang (2017)</ref> 51.2 + CP score 52.3  <ref type="bibr" target="#b7">(Chambers and Jurafsky, 2008)</ref> 30.92 <ref type="bibr" target="#b18">(Granroth-Wilding and Clark, 2016)</ref> 43.28 <ref type="bibr" target="#b32">(Pichotta and Mooney, 2016)</ref> 43.17 ( <ref type="bibr">Wang et al., 2017)</ref> 46.67 Our Results 48.83 To facilitate direct comparisons, we used the same state-of-the-art temporal relation classifica- tion system as described in our previous work <ref type="bibr" target="#b9">Choubey and Huang (2017)</ref> and considered all the 14 relations in classification. <ref type="bibr" target="#b9">Choubey and Huang (2017)</ref> forms three sequences (i.e., word forms, POS tags, and dependency relations) of context words that align with the dependency path between two event mentions and uses three bi- directional LSTMs to get the embedding of each sequence. The final fully connected layer maps the concatenated embeddings of all sequences to 14 fine-grained temporal relations. We applied the same model here, but if an event pair appears in our learned list of event pairs, we concatenated the CP score of the event pair as additional evidence in the final layer. To be consistent with <ref type="bibr" target="#b9">Choubey and Huang (2017)</ref>, we used the same train/test split- ting, the same parameters for the neural network and only considered intra-sentence event pairs. <ref type="table" target="#tab_5">Table 5</ref> shows that by incorporating our learned event knowledge, the overall prediction accuracy was improved by 1.1%. Not surprisingly, out of the 14 temporal relations, the performance on the relation before was improved the most by 4.9%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Narrative Cloze</head><p>Multiple Choice version of the Narrative Cloze task (MCNC) proposed by <ref type="bibr" target="#b18">Granroth-Wilding and Clark (2016)</ref>; <ref type="bibr">Wang et al. (2017)</ref>, aims to eval- <ref type="bibr">Michaela Regneri, Alexander Koller, and Manfred Pinkal. 2010</ref> </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Two narrative examples</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Top-ranked event pairs evaluation</figDesc><graphic url="image-2.png" coords="8,87.53,62.81,187.20,140.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Precision of narratives based on human 
annotation 

pairs 

graduate → teach (5.7), meet → marry (5.3) 
pick up → carry (6.3), park → get out (7.3) 
turn around → face (6.5), dial → ring (6.3) 

chains 

drive → park → get out (7.8) 
toss → fly → land (5.9) 
grow up → attend → graduate → marry (6.9) 
contact → call → invite → accept (4.2) 
knock → open → reach → pull out → hold (6.0) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Examples of event pairs and chains (with 
CP scores). → represents before relation. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Precision of top-ranked event chains 

event pair/chain is deemed correct if both anno-
tators labeled it as correct. The two annotators 
achieved kappa inter-agreement scores of 0.71 and 
0.66, on annotating event pairs and event chains 
respectively. 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 5 : Results on TimeBank corpus</head><label>5</label><figDesc></figDesc><table>Method 
Acc.(%) 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Results on MCNC task 

lation classification performance, we conducted 
experiments on a benchmark dataset -TimeBank 
corpus v1.2, which contains 2308 event pairs that 
are annotated with 14 temporal relations 13 . 
</table></figure>

			<note place="foot" n="1"> http://nlp.cs.tamu.edu/resources.html</note>

			<note place="foot" n="2"> NP is Noun Phrase and VP is Verb Phrase.</note>

			<note place="foot" n="3"> We manually identified 14 top-level sentence production rules, for example, &quot;S → NP ADVP VP&quot;, &quot;S → PP , NP VP&quot; and &quot;S → S CC S&quot;. Appendix shows all the rules. 4 The example NP rules include &quot;NP → NNP&quot;, &quot;NP → NP CC NP&quot; and &quot;NP → DT NNP&quot;.</note>

			<note place="foot" n="5"> 40% was chosen to reflect that a narrative paragraph often contains a main character that is commonly mentioned across sentences (half or a bit less than half of all the sentences). 6 We used the skewed pos:neg ratio of 1:5 in all bootstrapping iterations to reflect the observation that there are generally many more non-narrative paragraphs than narrative paragraphs in a document. 7 This value is half of the corresponding thresshold used for identifying seed narrative paragraphs. 8 This value is half of the corresponding thresshold used for identifying seed narrative paragraphs.</note>

			<note place="foot" n="9"> https://www.csie.ntu.edu.tw/ ˜ cjlin/ liblinear/</note>

			<note place="foot" n="10"> Specifically, the lengths of the longest, second longest and third longest entity chains.</note>

			<note place="foot" n="11"> We only consider main events that are in base verb forms or in the past tense, by requiring their POS tags to be VB, VBP, VBZ or VBD.</note>

			<note place="foot" n="12"> It turns out that many event chains have a high CP score close to 5.0, so we decided not to use a cut-off CP score of event chains but simply chose to evaluate the top 25,000 event chains.</note>

			<note place="foot" n="13"> Specifically, the 14 relations are simultaneous, before, after, ibefore, iafter, begins, begun by, ends, ended by, includes, is included, during, during inv, identity</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Acknowledgments</head><p>We thank our anonymous reviewers for providing insightful review comments.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>This paper presents a novel approach for leverag- ing the double temporality characteristic of narra- tive texts and acquiring temporal event knowledge across sentences in narrative paragraphs. We de- veloped a weakly supervised system that explores narratology principles and identifies narrative texts from three text corpora of distinct genres. The temporal event knowledge distilled from narrative texts were shown useful to improve temporal re- lation classification and outperform several neural language models on the narrative cloze task. For the future work, we plan to expand event temporal knowledge acquisition by dealing with event sense disambiguation and event synonym identification (e.g., drag, pull and haul).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix</head><p>Here is the full list of grammar rules for identify- ing plot events in the seeding stage (Section 4.2). Sentence rules (14): S → S CC S S → S PRN CC S S → NP VP S → NP ADVP VP S → NP VP ADVP S → CC NP VP S → PP NP VP S → NP PP VP S → PP NP ADVP VP S → ADVP S NP VP S → ADVP NP VP S → SBAR NP VP S → SBAR ADVP NP VP S → CC ADVP NP VP Noun Phrase rules (12):</p><p>NP → PRP NP → NNP NP → NNS NP → NNP NNP NP → NNP CC NNP NP → NP CC NP NP → DT NN NP → DT NNS NP → DT NNP NP → DT NNPS NP → NP NNP NP → NP NNP NNP</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Narratology: Introduction to the theory of narrative</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mieke</forename><surname>Bal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>University of Toronto Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Using a bigram event model to predict causal potential</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brandon</forename><surname>Beamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roxana</forename><surname>Girju</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CICLing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="430" to="441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A maximum entropy approach to natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent J Della</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen A Della</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pietra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="71" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Freebase: a collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 ACM SIGMOD international conference on Management of data</title>
		<meeting>the 2008 ACM SIGMOD international conference on Management of data</meeting>
		<imprint>
			<publisher>AcM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1247" to="1250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The icwsm 2009 spinn3r dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Burton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akshay</forename><surname>Java</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Soboroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Third Annual Conference on Weblogs and Social Media</title>
		<imprint>
			<publisher>AAAI</publisher>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note>ICWSM</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A hybrid model and memory based story classifier</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Betul</forename><surname>Ceran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravi</forename><surname>Karad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Corman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hasan</forename><surname>Davulcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Workshop on Computational Models of Narrative</title>
		<meeting>the 3rd Workshop on Computational Models of Narrative</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="58" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Unsupervised learning of narrative schemas and their participants</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="602" to="610" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Unsupervised learning of narrative event chains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">94305</biblScope>
			<biblScope unit="page" from="789" to="797" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Verbocean: Mining the web for fine-grained semantic verb relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Chklovski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Pantel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2004 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A sequential model for classifying temporal relations between intra-sentence events</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Kumar Choubey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruihong</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1796" to="1802" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Oxford english dictionary online</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Oxford English Dictionary</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A simpler and more generalizable story detector using verb and character features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Eisenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Finlayson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2698" to="2705" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Liblinear: A library for large linear classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Wei</forename><surname>Rong-En Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho-Jui</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangrui</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Jen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1871" to="1874" />
			<date type="published" when="2008-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Incorporating non-local information into information extraction systems by gibbs sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><forename type="middle">Rose</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trond</forename><surname>Grenager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd annual meeting on association for computational linguistics. Association for Computational Linguistics</title>
		<meeting>the 43rd annual meeting on association for computational linguistics. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="363" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Aspects of the novel</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward Morgan</forename><surname>Forster</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1927" />
			<publisher>Oliver Stallybrass</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Identifying personal stories in millions of weblog entries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reid</forename><surname>Swanson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Third International Conference on Weblogs and Social Media, Data Challenge Workshop</title>
		<meeting><address><addrLine>San Jose, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">46</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hebert</forename><surname>Grabes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sequentiality. Handbook of Narratology</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="765" to="76" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">English gigaword corpus. Linguistic Data Consortium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Graff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cieri</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">What happens next? event prediction using a compositional neural network model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Granroth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Wilding</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2727" to="2733" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Narrative grammar: Units and levels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Algirdas Julien</forename><surname>Greimas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MLN</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="793" to="806" />
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Unsupervised induction of contingent event pairs from film scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhichao</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elahe</forename><surname>Rahimtoroghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larissa</forename><surname>Munishkina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reid</forename><surname>Swanson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marilyn A</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="369" to="379" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Inferring narrative causality between event pairs in films</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhichao</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marilyn</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue</title>
		<meeting>the 18th Annual SIGdial Meeting on Discourse and Dialogue</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="342" to="351" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Skip n-grams and ranking functions for predicting script events</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bram</forename><surname>Jans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vuli´cvuli´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie</forename><forename type="middle">Francine</forename><surname>Moens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 13th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="336" to="344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deterministic coreference resolution based on entity-centric, precision-ranked rules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heeyoung</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angel</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yves</forename><surname>Peirsman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="885" to="916" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Bloggers: A portrait of the internet&apos;s new storytellers. Pew Internet &amp; American Life Project</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanda</forename><surname>Lenhart</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Computational modeling of narrative</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inderjeet</forename><surname>Mani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthesis Lectures on Human Language Technologies</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="142" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The stanford corenlp natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Christopher D Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><forename type="middle">Rose</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (System Demonstrations)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Reducing semantic drift with bagging and distributional similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tara</forename><surname>Mcintosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>James R Curran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="396" to="404" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Inscript: Narrative texts annotated with script information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashutosh</forename><surname>Modi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatjana</forename><surname>Anikina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Ostermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><surname>Pinkal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3485" to="3493" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Annotated gigaword</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Courtney</forename><surname>Napoles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Gormley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge Extraction. Association for Computational Linguistics</title>
		<meeting>the Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge Extraction. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="95" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">The development and psychometric properties of liwc2015</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><forename type="middle">L</forename><surname>James W Pennebaker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kayla</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Blackburn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Building process theory with narrative: From description to explanation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brian T Pentland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Academy of management Review</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="711" to="724" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning statistical scripts with lstm recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Pichotta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Raymond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2800" to="2806" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The timebank corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Hanks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roser</forename><surname>Sauri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>See</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Gaizauskas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Setzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beth</forename><surname>Sundheim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Day</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lisa</forename><surname>Ferro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Corpus linguistics</title>
		<meeting><address><addrLine>Lancaster, UK.</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page">40</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
