<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:36+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Syntax for Semantic Role Labeling, To Be, Or Not To Be</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 15-20, 2018. 2018. 2061</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shexia</forename><surname>He</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Key Laboratory of Shanghai Education Commission for Intelligent Interaction and Cognitive Engineering</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zuchao</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Key Laboratory of Shanghai Education Commission for Intelligent Interaction and Cognitive Engineering</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Key Laboratory of Shanghai Education Commission for Intelligent Interaction and Cognitive Engineering</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongxiao</forename><surname>Bai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Key Laboratory of Shanghai Education Commission for Intelligent Interaction and Cognitive Engineering</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gongshen</forename><surname>Liu</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Cyber Security</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Syntax for Semantic Role Labeling, To Be, Or Not To Be</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2061" to="2071"/>
							<date type="published">July 15-20, 2018. 2018. 2061</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Semantic role labeling (SRL) is dedicated to recognizing the predicate-argument structure of a sentence. Previous studies have shown syntactic information has a remarkable contribution to SRL performance. However, such perception was challenged by a few recent neural SRL models which give impressive performance without a syntactic backbone. This paper intends to quantify the importance of syntactic information to dependency SRL in deep learning framework. We propose an enhanced argument labeling model companying with an extended k-order argument pruning algorithm for effectively exploiting syntactic information. Our model achieves state-of-the-art results on the CoNLL-2008, 2009 benchmarks for both English and Chinese, showing the quantitative significance of syntax to neu-ral SRL together with a thorough empirical survey over existing models.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Semantic role labeling (SRL), namely semantic parsing, is a shallow semantic parsing task, which aims to recognize the predicate-argument structure of each predicate in a sentence, such as who did what to whom, where and when, etc. Specifically, we seek to identify arguments and label their se- mantic roles given a predicate. SRL is an impor-tant method to obtain semantic information ben- eficial to a wide range of natural language pro- cessing (NLP) tasks, including machine transla- tion ( <ref type="bibr" target="#b26">Shi et al., 2016)</ref>, question answering ( <ref type="bibr" target="#b0">Berant et al., 2013;</ref><ref type="bibr" target="#b29">Yih et al., 2016)</ref> and discourse relation sense classification <ref type="bibr" target="#b18">(Mihaylov and Frank, 2016)</ref>.</p><p>There are two formulizations for semantic predicate-argument structures, one is based on constituents (i.e., phrase or span), the other is based on dependencies. The latter proposed by the CoNLL-2008 shared task ( <ref type="bibr" target="#b28">Surdeanu et al., 2008</ref>) is also called semantic dependency pars- ing, which annotates the heads of arguments rather than phrasal arguments. Generally, SRL is de- composed into multi-step classification subtasks in pipeline systems, consisting of predicate identi- fication and disambiguation, argument identifica- tion and classification.</p><p>In prior work of SRL, considerable attention has been paid to feature engineering that struggles to capture sufficient discriminative information, while neural network models are capable of ex- tracting features automatically. In particular, syn- tactic information, including syntactic tree feature, has been show extremely beneficial to SRL since a larger scale of empirical verification of <ref type="bibr" target="#b23">Punyakanok et al. (2008)</ref>. However, all the work had to take the risk of erroneous syntactic input, lead- ing to an unsatisfactory performance.</p><p>To alleviate the above issues,  propose a simple but effective model for dependency SRL without syntactic input. It seems that neural SRL does not have to rely on syntactic features, contradicting with the belief that syntax is a necessary prerequisite for SRL as early as <ref type="bibr" target="#b8">Gildea and Palmer (2002)</ref>. This dramatic contradiction motivates us to make a thorough ex- ploration on syntactic contribution to SRL. This paper will focus on semantic dependency parsing and formulate SRL as one or two se-quence tagging tasks with predicate-specific en- coding. With the help of the proposed k-order argument pruning algorithm over syntactic tree, our model obtains state-of-the-art scores on the CoNLL benchmarks for both <ref type="bibr">English and Chinese.</ref> In order to quantitatively evaluate the contri- bution of syntax to SRL, we adopt the ratio be- tween labeled F 1 score for semantic dependencies (Sem-F 1 ) and the labeled attachment score (LAS) for syntactic dependencies introduced by CoNLL- 2008 Shared Task 1 as evaluation metric. Consid- ering that various syntactic parsers contribute dif- ferent syntactic inputs with various range of qual- ity levels, the ratio provides a fairer comparison between syntactically-driven SRL systems, which will be surveyed by our empirical study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Model</head><p>To fully disclose the predicate-argument structure, typical SRL systems have to step by step perform four subtasks. Since the predicates in <ref type="bibr">CoNLL2009</ref><ref type="bibr" target="#b9">(Hajič et al., 2009</ref>) corpus have been pre- identified, we need to tackle three other subtasks, which are formulized into two-step pipeline in this work, predicate disambiguation and argument la- beling. Namely, we do the work of argument iden- tification and classification in one model. Argument structure for each known predicate will be disclosed by our argument labeler over a sequence including possible arguments (candi- dates). There are two ways to determine the se- quence, one is to simply input the entire sentence as a syntax-agnostic SRL system does, the other is to select words according to syntactic parse tree around the predicate as most previous SRL systems did. The latter strategy usually works through a syntactic tree based argument pruning algorithm. We will use the proposed k-order ar- gument pruning algorithm (Section 2.1) to get a sequence w = (w 1 , . . . , w n ) for each predicate. Then, we represent each word w i ∈ w as x i (Sec- tion 2.2). Eventually, we obtain contextual fea- tures with sequence encoder (Section 2.3). The overall role labeling model is depicted in <ref type="figure" target="#fig_0">Figure 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Argument Pruning</head><p>As pointed out by <ref type="bibr" target="#b23">Punyakanok et al. (2008)</ref>, syn- tactic information is most relevant in identifying <ref type="bibr">1 CoNLL-2008</ref> is an English-only task, while CoNLL- 2009 extends to a multilingual one. Their main difference is that predicates have been beforehand indicated for the latter.  the arguments, and the most crucial contribution of full parsing is in the pruning stage. In this pa- per, we propose a k-order argument pruning al- gorithm inspired by <ref type="bibr" target="#b32">Zhao et al. (2009b)</ref>. First of all, for node n and its descendant n d in a syn- tactic dependency tree, we define the order to be the distance between the two nodes, denoted as D(n, n d ). Then we define k-order descendants of given node satisfying D(n, n d ) = k, and k-order traversal that visits each node from the given node to its descendant nodes within k-th order. Note that the definition of k-order traversal is somewhat different from tree traversal in terminology. A brief description of the proposed k-order pruning algorithm is given as follow. Initially, we set a given predicate as the current node in a syn- tactic dependency tree. Then, collect all its argu- ment candidates by the strategy of k-order traver- sal. Afterwards, reset the current node to its syn- tactic head and repeat the previous step till the root of the tree. Finally, collect the root and stop. The k-order argument algorithm is presented in Algo- rithm 1 in detail. An example of a syntactic de- pendency tree for sentence She began to trade the art for money is shown in <ref type="figure" target="#fig_2">Figure 2</ref>.</p><p>The main reasons for applying the extended k- order argument pruning algorithm are two-fold.</p><p>Algorithm 1 k-order argument pruning algorithm Input: A predicate p, the root node r given a syn- tactic dependency tree T , the order k Output: The set of argument candidates S 1: initialization set p as current node c, c = p 2: for each descendant n i of c in T do goto step 2 12: end if 13: return argument candidates set S First, previous standard pruning algorithm may hurt the argument coverage too much, even though indeed arguments usually tend to surround their predicate in a close distance. As a sequence tag- ging model has been applied, it can effectively handle the imbalanced distribution between argu- ments and non-arguments, which is hardly tack- led by early argument classification models that commonly adopt the standard pruning algorithm. Second, the extended pruning algorithm provides a better trade-off between computational cost and performance by carefully tuning k.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Word Representation</head><p>We produce a predicate-specific word represen- tation x i for each word w i , where i stands for the word position in an input sequence, follow- ing . However, we dif- fer by (1) leveraging a predicate-specific indicator embedding, (2) using deeper refined representa- tion, including character and dependency relation embeddings, and (3) applying recent advances in RNNs, such as highway connections ( <ref type="bibr" target="#b27">Srivastava et al., 2015)</ref>.</p><p>In this work, word representation x i is the con- catenation of four types of features: predicate- specific feature, character-level, word-level and linguistic features. Unlike previous work, we leverage a predicate-specific indicator embedding x ie i rather than directly using a binary flag either 0 or 1. At character level, we exploit convolu- tional neural network (CNN) with bidirectional LSTM (BiLSTM) to learn character embedding x ce i . As shown in <ref type="figure" target="#fig_0">Figure 1</ref>, the representation calculated by the CNN is fed as input to BiL- STM. At word level, we use a randomly initial- ized word embedding x re i and a pre-trained word embedding x pe i . For linguistic features, we em- ploy a randomly initialized lemma embedding x le i and a randomly initialized POS tag embedding x pos i . In order to incorporate more syntactic in- formation, we adopt an additional feature, the de- pendency relation to syntactic head. Likewise, it is a randomly initialized embedding x de i . The resulting word representation is concatenated as</p><formula xml:id="formula_0">x i = [x ie i , x ce i , x re i , x pe i , x le i , x pos i , x de i ].</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Sequence Encoder</head><p>As Long short-term memory (LSTM) net- works <ref type="bibr" target="#b11">(Hochreiter and Schmidhuber, 1997</ref>) have shown significant representational effectiveness to NLP tasks, we thus use BiLSTM as the sen- tence encorder. Given an input sequence x = (x 1 , . . . , x n ), BiLSTM processes the sequence in both forward and backward direction to obtain two separated hidden states, − → h i which handles data from x 1 to x i and ← − h i which tackles data from x n to x i for each word representation. Finally, we get a contextual representation</p><formula xml:id="formula_1">h i = [ − → h i , ← − h i ]</formula><p>by con- catenating the states of BiLSTM networks.</p><p>To get the final predicted semantic roles, we ex- ploit a multi-layer perceptron (MLP) with high- way connections on the top of BiLSTM networks, which takes as input the hidden representation h i of all time steps. The MLP network consists of 10 layers with highway connections and we employ ReLU activations for the hidden layers. Finally, we use a softmax layer over the outputs to maxi- mize the likelihood of labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Predicate Disambiguation</head><p>Although predicates have been identified given a sentence, predicate disambiguation is an in- dispensable task, which aims to determine the predicate-argument structure for an identified predicate in a particular context. Here, we also use the identical model (BiLSTM composed with MLP) for predicate disambiguation, in which the only difference is that we remove the syntactic de- pendency relation feature in corresponding word representation (Section 2.2). Exactly, given a predicate p, the resulting word representation is</p><formula xml:id="formula_2">p i = [p ie i , p ce i , p re i , p pe i , p le i , p pos i ].</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>Our model 2 is evaluated on the CoNLL-2009 shared task both for English and Chinese datasets, following the standard training, development and test splits. The hyperparameters in our model were selected based on the development set, and are summarized in <ref type="table" target="#tab_2">Table 1</ref>. Note that the parame- ters of predicate model are the same as these in argument model. All real vectors are randomly initialized, and the pre-trained word embeddings for English are GloVe vectors ( <ref type="bibr" target="#b20">Pennington et al., 2014</ref>). For Chinese, we exploit Wikipedia doc- uments to train Word2Vec embeddings (Mikolov  <ref type="bibr" target="#b13">Kingma and Ba, 2015)</ref>. We train models for a maximum of 20 epochs and obtain the nearly best model based on development re- sults. For argument labeling, we preprocess cor- pus with k-order argument pruning algorithm. In addition, we use four CNN layers with single- layer BiLSTM to induce character representations derived from sentences. For English 3 , to fur- ther enhance the representation, we adopt CNN- BiLSTM character embedding structure from Al- lenNLP toolkit ( <ref type="bibr" target="#b21">Peters et al., 2018</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Preprocessing</head><p>During the pruning of argument candidates, we use the officially predicted syntactic parses pro- vided by CoNLL-2009 shared-task organizers on both English and Chinese. <ref type="figure" target="#fig_3">Figure 3</ref> shows chang- ing curves of coverage and reduction following k on the English train set. According to our statis- tics, the number of non-arguments is ten times more than that of arguments, where the data dis- tribution is fairly unbalanced. However, a proper pruning strategy could alleviate this problem. Ac- cordingly, the first-order pruning reduces more than 50% candidates at the cost of missing 5.5% true ones on average, and the second-order prunes about 40% candidates with nearly 2.0% loss. The coverage of third-order has achieved 99% and it reduces approximately 1/3 corpus size.</p><p>It is worth noting that as k is larger than 19, <ref type="bibr" target="#b1">Björkelund et al. (2010)</ref> 87.1 84.5 85.8 <ref type="bibr" target="#b14">Lei et al. (2015)</ref> − − 86.6 <ref type="bibr" target="#b5">FitzGerald et al. (2015)</ref> − − 86.7 Roth and Lapata <ref type="formula">(2016)</ref> 88  there will come full coverage on all argument can- didates for English training set, which let our high order pruning algorithm degrade into a syntax- agnostic setting. In this work, we use the tenth- order pruning for pursuing the best performance.</p><formula xml:id="formula_3">System (syntax-aware) P R F 1 Single model Zhao et al. (2009a) − − 86.2 Zhao et al. (2009c) − − 85.4</formula><note type="other">.1 85.3 86.7 Marcheggiani and Titov (2017) 89.1 86.8 88.0 Ours 89.7 89.3 89.5 Ensemble model FitzGerald et al. (2015) − − 87.7 Roth and Lapata (2016) 90.3 85.7 87.9 Marcheggiani and Titov (2017) 90.5 87.7 89.</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results</head><p>Our system performance is measured with the of- ficial script from CoNLL-2009 benchmarks, com- bining the output of our predicate disambigua- tion with our semantic role labeling. Our predi- cate disambiguation model achieves the accuracy of 95.01% and 95.58% 4 on development and test sets, respectively. We compare our model per- formance with the state-of-the-art models for de- pendency SRL. 5 Noteworthily, our model is lo- cal and single without reranking, which neither includes global inference nor combines multiple models. The experimental results on the English in-domain (WSJ) and out-of-domain (Brown) test sets are shown in <ref type="table" target="#tab_3">Tables 2 and 3</ref>, respectively. For English, our syntax-aware model outper- forms previously published best single model, scoring 89.5% F 1 with 1.5% absolute improve- ment on the in-domain (WSJ) test data. Compared   with ensemble models, our single model even pro- vides better performance (+0.4% F 1 ) than the sys- tem , and signifi- cantly surpasses all the rest models. In the syntax- agnostic setting (without pruning and dependency relation embedding), we also reach the new state- of-the-art, achieving a performance gain of 1% F 1 .</p><note type="other">System (syntax-aware) P R F 1 Single model Zhao et al. (2009a) − − 74.6 Zhao et al. (2009c) − − 73.3 Björkelund et al. (2010) 75.7 72.2 73.9 Lei et al. (2015) − − 75.6 FitzGerald et al. (2015) − − 75.2 Roth and Lapata (2016) 76.9 73.8 75.3 Marcheggiani and Titov (2017) 78.5 75.9 77.2 Ours 81.9 76.9 79.3 Ensemble model FitzGerald et al. (2015) − − 75.5 Roth and Lapata (2016) 79.7 73.6 76.5 Marcheggiani and Titov (2017) 80.8 77.1 78.</note><p>On the out-of-domain (Brown) test set, we achieve the new best results of 79.3% (syntax- aware) and 78.8% (syntax-agnostic) in F 1 scores. Moreover, our syntax-aware model performs bet- ter than the syntax-agnostic one.   <ref type="table">Table 6</ref>: Ablation on development set. The "+" denotes a specific version over the basic model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Analysis</head><p>To evaluate the contributions of key factors in our method, a series of ablation studies are performed on the English development set. In order to demonstrate the effectiveness of our k-order pruning algorithm, we report the SRL per- formance excluding predicate senses in evalua- tion, eliminating the performance gain from pred- icate disambiguation. <ref type="table" target="#tab_8">Table 5</ref> shows the results from our syntax-aware model with lower order ar- gument pruning. Compared to the best previous model, our system still yields an increment in re- call by more than 1%, leading to improvements in F 1 score. It demonstrates that refining syntactic parser tree based candidate pruning does help in argument recognition. <ref type="table">Table 6</ref> presents the performance of our syntax- agnostic SRL system with a basic configuration, which removes components, including indicator and character embeddings. Note that the first row is the results of BiLSTM (removing MLP from basic model), whose encoding is the same as . Experiments show that both enhanced representations improve over our basic model, and our adopted labeling model is superior to the simple BiLSTM. <ref type="figure">Figure 4</ref> shows F 1 scores in different k-order pruning together with our syntax-agnostic model. It also indicates that the least first-order pruning fails to give satisfactory performance, the best per- forming setting coming from a moderate setting of k = 10, and the largest k shows that our argu- syntax-aware syntax-agnostic</p><p>Figure 4: F 1 scores by k-order pruning and the syntax-agnostic result on English development set. ment pruning falls back to syntax-agnostic type. Meanwhile, from the best k setting to the lower order pruning, we receive a much faster perfor- mance drop, compared to the higher order prun- ing until the complete syntax-agnostic case. The proposed k-order pruning algorithm always works even it reaches the syntax-agnostic setting, which empirically explains why the current syntax-aware and syntax-agnostic SRL models hold little per- formance difference, as maximum k-order prun- ing actually removes few words just like syntax- agnostic model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">End-to-end SRL</head><p>In this work, we consider additional model that integrates predicate disambiguation and argument labeling into one sequence labeling model. In or- der to implement an end-to-end model, we intro- duce a virtual root (VR) for predicate disambigua- tion similar to <ref type="bibr" target="#b35">Zhao et al. (2013)</ref> who handled the entire SRL task as word pair classification. Con- cretely, we add a predicate sense feature to the in- put sequence by concatenating a VR. The word representation of VR is randomly initialized dur- ing training. In <ref type="figure" target="#fig_4">Figure 5</ref>, we give an example se- quence with the labels for the given sentence. We also report results of our end-to-end model on CoNLL-2009 test set with syntax-aware and syntax-agnostic settings. As shown in <ref type="table">Table 7</ref>, our end-to-end model yields slightly weaker per- formance compared with our pipeline. A reason- able account for performance degradation is that the training data has completely different genre distributions over predicate senses and argument roles, which may be somewhat confusing for inte- grative model to make classification decisions. 89.5 87.9 88.7 <ref type="table">Table 7</ref>: Comparison of results on CoNLL-2009 data between our end-to-end and pipeline models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">CoNLL-2008 SRL Setting</head><p>For a full SRL task, the predicate identification subtask is also indispensable, which has been in- cluded in CoNLL-2008 shared task. We thus eval- uate our model in terms of data and setting of the CoNLL-2008 benchmark (WSJ).</p><p>To identify predicates, we train the BiLSTM- MLP sequence labeling model with same param- eters in Section 2.4 to tackle the predicate identi- fication and disambiguation subtasks in one shot, and the only difference is that we remove the predicate-specific indicator feature. The F 1 score of our predicate labeling model is 90.53% on in- domain (WSJ) data. Compared with the best re- ported results, we observe absolute improvements in semantic F 1 of 0.8% (in <ref type="table" target="#tab_10">Table 8</ref>). Note that as predicate identification is introduced, our same model shows about 6% performance loss for either syntax-agnostic or syntax-aware case, which indi- cates that predicate identification should be care- fully handled, as it is very needed in a complete practical SRL system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Syntactic Contribution</head><p>Syntactic information plays an informative role in semantic role labeling. However, few studies were done to quantitatively evaluate the syntac- tic contribution to SRL. Furthermore, we observe that most of the above compared neural SRL sys- tems took the syntactic parser of <ref type="bibr" target="#b1">(Björkelund et al., 2010)</ref> as syntactic inputs instead of the one from CoNLL-2009 shared task, which adopted a much weaker syntactic parser. Especially , adopted an external syntactic System LAS Sem-F 1 Johansson and Nugues (2008) 90.13 81.75 <ref type="bibr" target="#b34">Zhao and Kit (2008)</ref> 87.52 77.67 <ref type="bibr" target="#b32">Zhao et al. (2009b)</ref> 88.39 82.1 (80.53) 89.28 82.5 (80.94) <ref type="bibr" target="#b35">Zhao et al. (2013)</ref> 88.39 82.5 (80.91) 89.28 82.4 (80.88) Ours (syntax-agnostic) − 82.9 Ours (syntax-aware) 86.0 83.3 parser with even higher parsing accuracy. Con- trarily, our SRL model is based on the automati- cally predicted parse with moderate performance provided by CoNLL-2009 shared task, but outper- forms their models. This section thus attempts to explore how much syntax contributes to dependency-based SRL in deep learning framework and how to effectively evaluate relative performance of syntax-based SRL. To this end, we conduct experiments for em- pirical analysis with different syntactic inputs.</p><p>Syntactic Input In order to obtain different syn- tactic inputs, we design a faulty syntactic tree gen- erator (refer to STG hereafter), which is able to produce random errors in the output parse tree like a true parser does. To simplify implementation, we construct a new syntactic tree based on the gold standard parse tree. Given an input error probabil- ity distribution estimated from a true parser output, our algorithm presented in Algorithm 2 stochasti- cally modifies the syntactic heads of nodes on the premise of a valid tree. Evaluation Measure For SRL task, the primary evaluation measure is the semantic labeled F 1 score. However, the score is influenced by the quality of syntactic input to some extent, lead- ing to unfaithfully reflecting the competence of syntax-based SRL system. Namely, this is not the outcome of a true and fair quantitative comparison for these types of SRL models. To normalize the semantic score relative to syntactic parse, we take into account additional evaluation measure to esti- mate the actual overall performance of SRL. Here, we use the ratio between labeled F 1 score for se- mantic dependencies (Sem-F 1 ) and the labeled at- tachment score (LAS) for syntactic dependencies System LAS (%) P (%) R (%) Sem-F 1 (%) Sem-F 1 /LAS (%) <ref type="bibr" target="#b33">Zhao et al. (2009c)</ref>  <ref type="bibr">[SRL-only]</ref> 86  <ref type="table" target="#tab_4">Table 9</ref>: Results on English test set, in terms of labeled attachment score for syntactic dependencies (LAS), semantic precision (P), semantic recall (R), semantic labeled F 1 score (Sem-F 1 ), the ratio Sem- F 1 /LAS. A superscript * indicates LAS results from our personal communication with the authors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 2 Faulty Syntactic Tree Generator</head><p>Input: A gold standard syntactic tree GT , the specific error probability p Output: The new generative syntactic tree N T 1: N denotes the number of nodes in GT 2: for each node n ∈ GT do find the syntactic head n h of n in GT end if 14: end for 15: return the new generative tree N T proposed by <ref type="bibr" target="#b28">Surdeanu et al. (2008)</ref> as evaluation metric. <ref type="bibr">6</ref> The benefits of this measure are twofold: quantitatively evaluating syntactic contribution to SRL and impartially estimating the true perfor- mance of SRL, independent of the performance of the input syntactic parser. <ref type="table" target="#tab_4">Table 9</ref> reports the performance of existing models 7 in term of Sem-F 1 /LAS ratio on CoNLL- 2009 English test set. Interestingly, even though our system has significantly lower scores than oth- ers by 3.8% LAS in syntactic components, we <ref type="bibr">6</ref> The idea of ratio score in <ref type="bibr" target="#b28">Surdeanu et al. (2008)</ref> actually was from author of this paper, Hai Zhao, which has been indi- cated in the acknowledgement part of <ref type="bibr" target="#b28">Surdeanu et al. (2008)</ref>. <ref type="bibr">7</ref> Note that several SRL systems without providing syntac- tic information are not listed in the table. obtain the highest results both on Sem-F 1 and the Sem-F 1 /LAS ratio, respectively. These results show that our SRL component is relatively much stronger. Moreover, the ratio comparison in <ref type="table" target="#tab_4">Table  9</ref> also shows that since the CoNLL-2009 shared task, most SRL works actually benefit from the enhanced syntactic component rather than the im- proved SRL component itself. All post-CoNLL SRL systems, either traditional or neural types, did not exceed the top systems of CoNLL-2009 shared task, ( <ref type="bibr" target="#b33">Zhao et al., 2009c</ref>) (SRL-only track using the provided predicated syntax) and ( <ref type="bibr" target="#b31">Zhao et al., 2009a</ref>) (Joint track using self-developed parser). We believe that this work for the first time reports both higher Sem-F 1 and higher Sem-F 1 /LAS ratio since CoNLL-2009 shared task.</p><p>We also perform our first and tenth order prun- ing models with different erroneous syntactic in- puts generated from STG and evaluate their per-formance using the Sem-F 1 /LAS ratio. <ref type="figure" target="#fig_7">Figure 6</ref> shows Sem-F 1 scores at different quality of syn- tactic parse inputs on the English test set whose LAS varies from 85% to 100%. Compared to pre- vious state-of-the-arts . Our tenth-order pruning model gives quite stable SRL performance no matter the syntactic in- put quality varies in a broad range, while our first- order pruning model yields overall lower results (1-5% F 1 drop), owing to missing too many true arguments. These results show that high-quality syntactic parses may indeed enhance dependency SRL. Furthermore, it indicates that our model with an accurate enough syntactic input as , namely, 90% LAS, will give a Sem-F 1 exceeding 90% for the first time in the research timeline of semantic role labeling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Semantic role labeling was pioneered by <ref type="bibr" target="#b7">Gildea and Jurafsky (2002)</ref>. Most traditional SRL models rely heavily on feature templates ( <ref type="bibr" target="#b22">Pradhan et al., 2005;</ref><ref type="bibr" target="#b32">Zhao et al., 2009b;</ref><ref type="bibr" target="#b2">Björkelund et al., 2009</ref>). Among them, <ref type="bibr" target="#b22">Pradhan et al. (2005)</ref> combined fea- tures derived from different syntactic parses based on SVM classifier, while <ref type="bibr" target="#b32">Zhao et al. (2009b)</ref> pre- sented an integrative approach for dependency SRL by greedy feature selection algorithm. <ref type="bibr">Later, Collobert et al. (2011)</ref> proposed a convolutional neural network model of inducing word embed- dings substituting for hand-crafted features, which was a breakthrough for SRL task.</p><p>With the impressive success of deep neural net- works in various NLP tasks ( <ref type="bibr" target="#b30">Zhang et al., 2016;</ref><ref type="bibr" target="#b24">Qin et al., 2017;</ref><ref type="bibr" target="#b3">Cai et al., 2017)</ref>, a series of neu- ral SRL systems have been proposed. <ref type="bibr" target="#b6">Foland and Martin (2015)</ref> presented a dependency semantic role labeler using convolutional and time-domain neural networks, while <ref type="bibr" target="#b5">FitzGerald et al. (2015)</ref> ex- ploited neural network to jointly embed arguments and semantic roles, akin to the work ( <ref type="bibr" target="#b14">Lei et al., 2015)</ref>, which induced a compact feature represen- tation applying tensor-based approach. Recently, researchers consider multiple ways to effectively integrate syntax into SRL learning. Roth and La- pata (2016) introduced dependency path embed- ding to model syntactic information and exhib- ited a notable success.  leveraged the graph convolutional network to incorporate syntax into neural models. Dif- ferently,  proposed a syntax-agnostic model using effective word repre- sentation for dependency SRL, which for the first time achieves comparable performance as state- of-the-art syntax-aware SRL models.</p><p>However, most neural SRL works seldom pay much attention to the impact of input syntactic parse over the resulting SRL performance. This work is thus more than proposing a high perfor- mance SRL model through reviewing the high- lights of previous models, and presenting an ef- fective syntactic tree based argument pruning. Our work is also closely related to <ref type="bibr" target="#b23">(Punyakanok et al., 2008;</ref><ref type="bibr" target="#b10">He et al., 2017)</ref>. Under the traditional meth- ods, <ref type="bibr" target="#b23">Punyakanok et al. (2008)</ref> investigated the significance of syntax to SRL system and shown syntactic information most crucial in the pruning stage. <ref type="bibr" target="#b10">He et al. (2017)</ref> presented extensive error analysis with deep learning model for span SRL, including discussion of how constituent syntactic parser could be used to improve SRL performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>This paper presents a simple and effective neural model for dependency-based SRL, incorporating syntactic information with the proposed extended k-order pruning algorithm. With a large enough setting of k, our pruning algorithm will result in a syntax-agnostic setting for the argument labeling model, which smoothly unifies syntax-aware and syntax-agnostic SRL in a consistent way. Experi- mental results show that with the help of deep en- hanced representation, our model outperforms the previous state-of-the-art models in both syntax- aware and syntax-agnostic situations.</p><p>In addition, we consider the Sem-F1/LAS ra- tio as a mean of evaluating syntactic contribution to SRL, and true performance of SRL independent of the quality of syntactic parser. Though we again confirm the importance of syntax to SRL with em- pirical experiments, we are aware that since <ref type="bibr" target="#b22">(Pradhan et al., 2005</ref>), the gap between syntax-aware and syntax-agnostic SRL has been greatly re- duced, from as high as 10% to only 1-2% perfor- mance loss in this work. However, maybe we will never reach a satisfying conclusion, as whenever one proposes a syntax-agnostic SRL system which can outperform all syntax-aware ones at then, al- ways there comes argument that you have never fully explored creative new method to effectively exploit the syntax input.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The Argument Labeling Model</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>if</head><label></label><figDesc>D(c, n i ) ≤ k and n i / ∈ S then 4: S = S + n i 5: end if 6: end for 7: find the syntactic head c h of c, and let c = c h 8: if c = r then 9: S = S + r 10: else 11:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: An example of first-order, second-order and third-order argument pruning. Shadow part indicates the given predicate.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Changing curves of coverage and reduction with different k value on English training set. The coverage rate is the proportion of true arguments in pruning output, while the reduction is the one of pruned argument candidates in total tokens.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: An example sequence with labels of endto-end model (makes is the given predicate).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: The Sem-F 1 scores of our models with different quality of syntactic inputs vs. GCNs (Marcheggiani and Titov, 2017) on test set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>1</head><label>1</label><figDesc></figDesc><table>System (syntax-agnostic) 
P 
R F 1 
Marcheggiani et al. (2017) 
88.7 86.8 87.7 
Ours 
89.5 87.9 88.7 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Results on the English test set (WSJ). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>9</head><label>9</label><figDesc></figDesc><table>System (syntax-agnostic) 
P 
R F 1 
Marcheggiani et al. (2017) 
79.4 76.2 77.7 
Ours 
81.7 76.1 78.8 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Results on English out-of-domain test set 
(Brown). 

System (syntax-aware) 
P 
R F 1 
Zhao et al. (2009a) 
80.4 75.2 77.7 
Björkelund et al. (2009) 
82.4 75.1 78.6 
Roth and Lapata (2016) 
83.2 75.9 79.4 
Marcheggiani and Titov (2017) 84.6 80.4 82.5 
Ours 
84.2 81.5 82.8 

System (syntax-agnostic) 
P 
R F 1 
Marcheggiani et al. (2017) 
83.4 79.1 81.2 
Ours 
84.5 79.3 81.8 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 : Results on the Chinese test set.</head><label>4</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 4 presents</head><label>4</label><figDesc>the results on Chinese test set. Even though we use the same parameters as for English, our model also outperforms the best re- ported results by 0.3% (syntax-aware) and 0.6% (syntax-agnostic) in F 1 scores.</figDesc><table>System(without predicate sense) 
P 
R F 1 
1st-order 
84.4 82.6 83.5 
2nd-order 
84.8 83.0 83.9 
3rd-order 
85.1 83.3 84.2 
Marcheggiani and Titov (2017) 85.2 81.6 83.3 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="true"><head>Table 5 : SRL results without predicate sense.</head><label>5</label><figDesc></figDesc><table>Our system 
P 
R 
F 1 
BiLSTM 
86.5 85.1 85.8 
basic model 
86.3 85.7 86.0 
+ indicator embedding 86.8 85.8 86.3 
+ character embedding 87.2 86.6 86.9 
+ both 
87.7 87.0 87.3 
BiLSTM + both 
87.3 86.7 87.0 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="false"><head>Table 8 :</head><label>8</label><figDesc></figDesc><table>Results on the CoNLL-2008 in-domain 
(WSJ) test set. The results in parenthesis are on 
WSJ + Brown test set. 

</table></figure>

			<note place="foot" n="2"> The code is available at https://github.com/ bcmi220/srl_syn_pruning.</note>

			<note place="foot" n="3"> For Chinese, we do not use character embedding.</note>

			<note place="foot" n="4"> Note that we give a slightly better predicate model than Roth and Lapata (2016), with 94.77% and 95.47% accuracy on development and test sets, respectively. 5 Here, we do not compare against span-based SRL models, which annotate roles for entire argument spans instead of semantic dependencies.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Semantic parsing on Freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1533" to="1544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A high-performance syntactic and semantic dependency parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Björkelund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bohnet</forename><surname>Bernd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Love</forename><surname>Hafdell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Nugues</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics</title>
		<meeting>the 23rd International Conference on Computational Linguistics<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="33" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Multilingual semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Björkelund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Love</forename><surname>Hafdell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Nugues</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth Conference on Computational Natural Language Learning</title>
		<meeting>the Thirteenth Conference on Computational Natural Language Learning<address><addrLine>Boulder, Colorado</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="43" to="48" />
		</imprint>
	</monogr>
	<note>Shared Task</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Fast and accurate neural word segmentation for Chinese</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deng</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhisong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongjian</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feiyue</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL). Vancouver</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (ACL). Vancouver</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="608" to="615" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Semantic role labeling with neural network factors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Tckstrm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuzman</forename><surname>Ganchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="960" to="970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Dependencybased semantic role labeling using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Foland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Martin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint Conference on Lexical and Computational Semantics</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="279" to="288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Automatic labeling of semantic roles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="245" to="288" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The necessity of parsing for predicate argument recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 40th Annual Meeting of the Association for Computational Linguistics (ACL). Philadelphia</title>
		<meeting>40th Annual Meeting of the Association for Computational Linguistics (ACL). Philadelphia<address><addrLine>Pennsylvania, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="239" to="246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The CoNLL2009 shared task: Syntactic and semantic dependencies in multiple languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Hajič</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimiliano</forename><surname>Ciaramita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daisuke</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><forename type="middle">Antònia</forename><surname>Martí</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lluís</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Meyers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Padó</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaň</forename><surname>Stěpánek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Straňák</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth Conference on Computational Natural Language Learning</title>
		<meeting>the Thirteenth Conference on Computational Natural Language Learning<address><addrLine>Boulder, Colorado</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1" to="18" />
		</imprint>
	</monogr>
	<note>Shared Task</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep semantic role labeling: What works and what&apos;s next</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (ACL)<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="473" to="483" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jrgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Dependency-based syntactic-semantic analysis with propbank and nombank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Nugues</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth Conference on Computational Natural Language Learning (CoNLL)</title>
		<meeting>the Twelfth Conference on Computational Natural Language Learning (CoNLL)</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="183" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Conference on Learning Representations (ICLR)</title>
		<meeting>the 3rd International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">High-order lowrank tensors for semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lluís</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL: HLT)</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL: HLT)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1150" to="1160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A simple and accurate syntax-agnostic neural model for dependency-based semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Marcheggiani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Frolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st Conference on Computational Natural Language Learning</title>
		<meeting>the 21st Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Canada</forename><surname>Vancouver</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="411" to="420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Encoding sentences with graph convolutional networks for semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Marcheggiani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP). Copenhagen, Denmark</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP). Copenhagen, Denmark</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1506" to="1515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Discourse relation sense classification using cross-argument semantic similarity based on word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todor</forename><surname>Mihaylov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anette</forename><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twentieth Conference on Computational Natural Language Learning-Shared Task (CoNLL)</title>
		<meeting>the Twentieth Conference on Computational Natural Language Learning-Shared Task (CoNLL)<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="100" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Deep contextualized word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL: HLT)</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL: HLT)<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Semantic role labeling using different syntactic views</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wayne</forename><surname>Sameer Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kadri</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hacioglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 43rd Annual Meeting of the Association for Computational Linguistics (ACL)<address><addrLine>Ann Arbor, Michigan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="581" to="588" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The importance of syntactic parsing and inference in semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasin</forename><surname>Punyakanok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="257" to="287" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Adversarial connectiveexploiting networks for implicit discourse relation classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lianhui</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhisong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiting</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (ACL)<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1006" to="1017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Neural semantic role labeling with dependency path embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics (ACL)<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1192" to="1202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Knowledge-based semantic embedding for machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shujie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuo</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houfeng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics (ACL)<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2245" to="2254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Training very deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rupesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Greff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2377" to="2385" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The conll 2008 shared task on joint parsing of syntactic and semantic dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Meyers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lluís</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth Conference on Computational Natural Language Learning-Shared Task</title>
		<meeting>the Twelfth Conference on Computational Natural Language Learning-Shared Task</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="159" to="177" />
		</imprint>
		<respStmt>
			<orgName>CoNLL). Manchester, England</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The value of semantic parse labeling for knowledge base question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingwei</forename><surname>Meek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jina</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Suh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics (ACL)<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="201" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Probabilistic graph-based dependency parsing with convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhisong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lianhui</forename><surname>Qin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics (ACL)<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1382" to="1392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Multilingual dependency learning: Exploiting rich features for tagging syntactic and semantic dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenliang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiyotaka</forename><surname>Jun&amp;apos;ichi Kazama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kentaro</forename><surname>Uchimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Torisawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth Conference on Computational Natural Language Learning-Shared Task (CoNLL)</title>
		<meeting>the Thirteenth Conference on Computational Natural Language Learning-Shared Task (CoNLL)<address><addrLine>Boulder, Colorado</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="61" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Semantic dependency parsing of NomBank and PropBank: An efficient integrated approach via a largescale feature selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenliang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyu</forename><surname>Kit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2009 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="30" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Multilingual dependency learning: A huge feature engineering method to semantic dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenliang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth Conference on Computational Natural Language LearningShared Task (CoNLL)</title>
		<meeting>the Thirteenth Conference on Computational Natural Language LearningShared Task (CoNLL)<address><addrLine>Boulder, Colorado</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Parsing syntactic and semantic dependencies with two single-stage maximum entropy models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyu</forename><surname>Kit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth Conference on Computational Natural Language Learning (CoNLL)</title>
		<meeting>the Twelfth Conference on Computational Natural Language Learning (CoNLL)</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="203" to="207" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Integrative semantic dependency parsing via efficient large-scale feature selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaotian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyu</forename><surname>Kit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="203" to="233" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
