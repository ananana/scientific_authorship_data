<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:39+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Do Neural Network Cross-Modal Mappings Really Bridge Modalities?</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 15-20, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillem</forename><surname>Collell</surname></persName>
							<email>gcollell@kuleuven.be</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science KU Leuven</orgName>
								<orgName type="department" key="dep2">Department of Computer Science KU Leuven</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science KU Leuven</orgName>
								<orgName type="department" key="dep2">Department of Computer Science KU Leuven</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Do Neural Network Cross-Modal Mappings Really Bridge Modalities?</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="462" to="468"/>
							<date type="published">July 15-20, 2018</date>
						</imprint>
					</monogr>
					<note>462</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Feed-forward networks are widely used in cross-modal applications to bridge modalities by mapping distributed vectors of one modality to the other, or to a shared space. The predicted vectors are then used to perform e.g., retrieval or labeling. Thus, the success of the whole system relies on the ability of the mapping to make the neighborhood structure (i.e., the pairwise similarities) of the predicted vectors akin to that of the target vectors. However, whether this is achieved has not been investigated yet. Here, we propose a new similarity measure and two ad hoc experiments to shed light on this issue. In three cross-modal benchmarks we learn a large number of language-to-vision and vision-to-language neural network mappings (up to five layers) using a rich diversity of image and text features and loss functions. Our results reveal that, surprisingly, the neighborhood structure of the predicted vectors consistently resembles more that of the input vectors than that of the target vectors. In a second experiment, we further show that untrained nets do not significantly disrupt the neighborhood (i.e., semantic) structure of the input vectors.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Neural network mappings are widely used to bridge modalities or spaces in cross-modal re- trieval ( <ref type="bibr" target="#b20">Qiao et al., 2017;</ref><ref type="bibr" target="#b25">Wang et al., 2016;</ref><ref type="bibr" target="#b27">Zhang et al., 2016)</ref>, zero-shot learning ( <ref type="bibr" target="#b16">Lazaridou et al., 2015b</ref><ref type="bibr" target="#b14">Lazaridou et al., , 2014</ref><ref type="bibr" target="#b24">Socher et al., 2013</ref>) in building mul- timodal representations ( <ref type="bibr" target="#b6">Collell et al., 2017)</ref> or in word translation ( <ref type="bibr" target="#b15">Lazaridou et al., 2015a</ref>), to name a few. Typically, a neural network is firstly trained to predict the distributed vectors of one modality (or space) from the other. At test time, some op- eration such as retrieval or labeling is performed based on the nearest neighbors of the predicted (mapped) vectors. For instance, in zero-shot im- age classification, image features are mapped to the text space and the label of the nearest neigh- bor word is assigned. Thus, the success of such systems relies entirely on the ability of the map to make the predicted vectors similar to the tar- get vectors in terms of semantic or neighborhood structure. <ref type="bibr">1</ref> However, whether neural nets achieve this goal in general has not been investigated yet. In fact, recent work evidences that considerable information about the input modality propagates into the predicted modality ( <ref type="bibr" target="#b6">Collell et al., 2017;</ref><ref type="bibr" target="#b16">Lazaridou et al., 2015b;</ref><ref type="bibr" target="#b8">Frome et al., 2013)</ref>.</p><p>To shed light on these questions, we first in- troduce the (to the best of our knowledge) first existing measure to quantify similarity between the neighborhood structures of two sets of vec- tors. Second, we perform extensive experiments in three benchmarks where we learn image-to-text and text-to-image neural net mappings using a rich variety of state-of-the-art text and image features and loss functions. Our results reveal that, con- trary to expectation, the semantic structure of the mapped vectors consistently resembles more that of the input vectors than that of the target vectors of interest. In a second experiment, by using six concept similarity tasks we show that the seman- tic structure of the input vectors is preserved after mapping them with an untrained network, further evidencing that feed-forward nets naturally pre- serve semantic information about the input. Over- all, we uncover and rise awareness of a largely <ref type="figure" target="#fig_2">Figure 1</ref>: Effect of applying a mapping f to a (dis- connected) manifold M with three hypothetical classes (, and •).</p><formula xml:id="formula_0">f(M ) M f(M )</formula><p>ignored phenomenon relevant to a wide range of cross-modal / cross-space applications such as re- trieval, zero-shot learning or image annotation.</p><p>Ultimately, this paper aims at: (1) Encouraging the development of better architectures to bridge modalities / spaces; (2) Advocating for the use of semantic-based criteria to evaluate the quality of predicted vectors such as the neighborhood-based measure proposed here, instead of purely geomet- ric measures such as mean squared error (MSE). In the context of zero-shot learning, short- comings of cross-space neural mappings have also been identified.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work and Motivation</head><p>For instance, "hub- ness" <ref type="bibr" target="#b21">(Radovanovi´cRadovanovi´c et al., 2010)</ref> and "pollu- tion" ( <ref type="bibr" target="#b15">Lazaridou et al., 2015a</ref>) relate to the high- dimensionality of the feature spaces and to overfit- ting respectively. Crucially, we do not assume that our cross-modal problem has any class labels, and we study the similarity between input and mapped vectors and between output and mapped vectors.</p><p>Recent work evidences that the predicted vec- tors of cross-modal neural net mappings are still largely informative about the input vectors. <ref type="bibr" target="#b16">Lazaridou et al. (2015b)</ref> qualitatively observe that abstract textual concepts are grounded with the visual input modality. Counterintuitively, <ref type="bibr" target="#b6">Collell et al. (2017)</ref> find that the vectors "imagined" from a language-to-vision neural map, outperform the original visual vectors in concept similarity tasks. The paper argued that the reconstructed visual vectors become grounded with language because the map preserves topological properties of the in- put. Here, we go one step further and show that the mapped vectors often resemble the input vec- tors more than the target vectors in semantic terms, which goes against the goal of a cross-modal map.</p><p>Well-known theoretical work shows that net- works with as few as one hidden layer are able to approximate any function <ref type="bibr" target="#b13">(Hornik et al., 1989)</ref>. However, this result does not reveal much nei- ther about test performance nor about the semantic structure of the mapped vectors. Instead, the phe- nomenon described is more closely tied to other properties of neural networks. In particular, conti- nuity guarantees that topological properties of the input, such as connectedness, are preserved <ref type="bibr" target="#b0">(Armstrong, 2013</ref>). Furthermore, continuity in a topol- ogy induced by a metric also ensures that points that are close together are mapped close together. As a toy example, <ref type="figure" target="#fig_2">Fig. 1</ref> illustrates the distortion of a manifold after being mapped by a neural net. <ref type="bibr">2</ref> In a noiseless world with fully statistically de- pendent modalities, the vectors of one modality could be perfectly predicted from those of the other. However, in real-world problems this is unrealistic given the noise of the features and the fact that modalities encode complementary information ( <ref type="bibr" target="#b4">Collell and Moens, 2016)</ref>. Such unpredictability combined with continuity and topology-preserving properties of neural nets pro- pel the phenomenon identified, namely mapped vectors resembling more the input than the target vectors, in nearest neighbors terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Proposed Approach</head><p>To bridge modalities X and Y, we consider two popular cross-modal mappings f : X → Y.</p><p>(i) Linear mapping (lin): (ii) Feed-forward neural network (nn):</p><formula xml:id="formula_1">f (x) = W 0 x + b 0 with W 0 ∈ R dy×dx , b 0 ∈ R dy ,</formula><formula xml:id="formula_2">f (x) = W 1 σ(W 0 x + b 0 ) + b 1 with W 1 ∈ R dy×d h , W 0 ∈ R d h ×dx , b 0 ∈ R d h , b 1 ∈ R dy</formula><p>where d h is the number of hidden units and σ() the non-linearity (e.g., tanh or sigmoid). Although single hidden layer networks are already universal approximators <ref type="bibr" target="#b13">(Hornik et al., 1989</ref>), we explored whether deeper nets with 3 and 5 hid- den layers could improve the fit (see Supplement).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Loss:</head><p>Our primary choice is the MSE: Notice that losses that do not require class labels such as MSE are suitable for a wider, more general set of tasks than discriminative losses (e.g., cross-entropy). In fact, cross-modal retrieval tasks often do not exhibit any class labels. Additionally, our research ques- tion concerns the cross-space mapping problem in isolation (independently of class labels). Let us denote a set of N input and output vec- tors by X ∈ R N ×dx and Y ∈ R N ×dy respectively. Each input vector x i is paired to the output vec- tor y i of the same index (i = 1, · · · , N ). Let us henceforth denote the mapped input vectors by f (X) ∈ R N ×dy . In order to explore the similarity between f (X) and X, and between f (X) and Y , we propose two ad hoc settings below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Neighborhood Structure of Mapped</head><p>Vectors (Experiment 1)</p><p>To measure the similarity between the neighbor- hood structure of two sets of paired vectors V and Z, we propose the mean nearest neighbor overlap measure (mNNO K (V, Z)). We define the near- est neighbor overlap NNO K (v i , z i ) as the num- ber of K nearest neighbors that two paired vec- tors v i , z i share in their respective spaces. E.g., if the 3 (= K) nearest neighbors of v cat in V are {v dog , v tiger , v lion } and those of z cat in Z are {z mouse , z tiger , z lion }, the NNO 3 (v cat , z cat ) is 2.</p><formula xml:id="formula_3">Definition 1 Let V = {v i } N i=1 and Z = {z i } N i=1</formula><p>be two sets of N paired vectors. We define:</p><formula xml:id="formula_4">mNNO K (V, Z) = 1 KN N i=1 NNO K (v i , z i ) (1) with NNO K (v i , z i ) = |NN K (v i ) ∩ NN K (z i )|,</formula><p>where NN K (v i ) and NN K (z i ) are the indexes of the K nearest neighbors of v i and z i , respectively.</p><p>The normalizing constant K simply scales mNNO K (V, Z) between 0 and 1, making it independent of the choice of K.</p><p>Thus, a mNNO K (V, Z) = 0.7 means that the vectors in V and Z share, on average, 70% of their near- est neighbors. Notice that mNNO implicitly per- forms retrieval for some similarity measure (e.g., Euclidean or cosine), and quantifies how semanti- cally similar two sets of paired vectors are.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Mapping with Untrained Networks (Experiment 2)</head><p>To complement the setting above (Sect. 3.1), it is instructive to consider the limit case of an un- trained network. Concept similarity tasks provide a suitable setting to study the semantic structure of distributed representations ( <ref type="bibr" target="#b18">Pennington et al., 2014</ref>). That is, semantically similar concepts should ideally be close together. In particular, our interest is in comparing X with its projection f (X) through a mapping with random parameters, to understand the extent to which the mapping may disrupt or preserve the semantic structure of X.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Setup</head><p>4.1 Experiment 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Datasets</head><p>To test the generality of our claims, we select a rich diversity of cross-modal tasks involving texts at three levels: word level (ImageNet), sentence level (IAPR TC-12), and document level (Wiki). ImageNet ( <ref type="bibr" target="#b22">Russakovsky et al., 2015</ref>). Consists of ∼14M images, covering ∼22K WordNet synsets (or meanings). Following <ref type="bibr" target="#b6">Collell et al. (2017)</ref>, we take the most relevant word for each synset and keep only synsets with more than 50 images. This yields 9,251 different words (or instances). IAPR TC-12 ( <ref type="bibr" target="#b10">Grubinger et al., 2006</ref>). Contains 20K images (18K train / 2K test) annotated with 255 labels. Each image is accompanied with a short description of one to three sentences. Wikipedia ( <ref type="bibr" target="#b19">Pereira et al., 2014</ref>). Has 2,866 sam- ples (2,173 train / 693 test). Each sample is a sec- tion of a Wikipedia article paired with one image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Hyperparameters and Implementation</head><p>See the Supplement (Sect. 1) for details.  ) and <ref type="bibr">WordSim-353 (Finkelstein et al., 2001</ref>); (iii) Visual similarity: VisSim (Silberer and Lap- ata, 2014) which includes the same word pairs as SemSim, rated for visual similarity instead of se- mantic. All six test sets contain human ratings of similarity for word pairs, e.g., ('cat','dog').</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Image and Text Features</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Hyperparameters and Implementation</head><p>The parameters in W 0 , W 1 are drawn from a ran- dom uniform distribution [−1, 1] and b 0 , b 1 are set to zero. We use a tanh activation σ(). <ref type="bibr">6</ref> The output dimension d y is set to 2,048 for all embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Image and Text Features</head><p>Textual and visual features are the same as de- scribed in Sect. 4.1.3 for the ImageNet dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.4">Similarity Predictions</head><p>We compute the prediction of similarity between two vectors z 1 , z 2 with both the cosine z 1 z 2 z 1 z 2 and the Euclidean similarity</p><formula xml:id="formula_5">1 1+z 1 −z 2 . 7 4</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>.2.5 Performance Metrics</head><p>As is common practice, we evaluate the predic- tions of similarity of the embeddings (Sect. 4.2.4) against the human similarity ratings with the Spearman correlation ρ. We report the average of 10 sets of randomly generated parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and Discussion</head><p>We test statistical significance with a two-sided Wilcoxon rank sum test adjusted with Bonferroni. The null hypothesis is that a compared pair is equal. In Tab. 1, * indicates that mNNO(X, f (X)) differs from mNNO(Y, f (X)) (p &lt; 0.001) on the same mapping, embedding and direction. In Tab. 2, * indicates that performance of mapped and input vectors differs (p &lt; 0.05) in the 10 runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experiment 1</head><p>Results below are with cosine neighbors and K = 10. Euclidean neighbors yield similar results and are thus left to the Supplement. Similarly, results in ImageNet with GloVe embeddings are shown below and word2vec results in the Supplement. The choice of K = {5, 10, 30} had no visible effect on results. Results with 3-and 5-layer nets did not show big differences with the results below (see Supplement). The cosine and max-margin losses ts mNNO(X,f(X)) tr mNNO(X,f(X))</p><formula xml:id="formula_6">ts mNNO(Y,f(X)) tr mNNO(Y,f(X))</formula><p>ts MSE tr MSE <ref type="figure">Figure 2</ref>: Learning a nn model in Wiki (left), IAPR TC-12 (middle) and ImageNet (right).</p><p>performed slightly worse than MSE (see Supple- ment). Although <ref type="bibr" target="#b15">Lazaridou et al. (2015a)</ref> and <ref type="bibr" target="#b26">Weston et al. (2011)</ref> find that max-margin performs the best in their tasks, we do not find our result en- tirely surprising given that max-margin focuses on inter-class differences while we look also at intra- class neighbors (in fact, we do not require classes). Tab. 1 shows our core finding, namely that the semantic structure of f (X) resembles more that of X than that of Y , for both lin and nn maps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ResNet</head><p>VGG-128  <ref type="table">Table 1</ref>: Test mean nearest neighbor over- lap. Boldface indicates the largest score at each mNNO 10 (X, f (X)) and mNNO 10 (Y, f (X)) pair, which are abbreviated by X, f (X) and Y, f (X). <ref type="figure">Fig. 2</ref> is particularly revealing. If we would only look at train performance (and allow train MSE to reach 0) then f (X) = Y and clearly train mNNO(f (X), Y ) = 1 while mNNO(f (X), X) can only be smaller than 1. However, the inter- est is always on test samples, and (near-)perfect test prediction is unrealistic. Notice in fact in <ref type="figure">Fig. 2</ref> that even if we look at train fit, MSE needs to be close to 0 for mNNO(f (X), Y ) to be reasonably large. In all the combinations from Tab. 1, the test mNNO(f (X), Y ) never surpasses test mNNO(f (X), X) for any number of epochs, even with an oracle (not shown).</p><formula xml:id="formula_7">X, f (X) Y, f (X) X, f (X) Y, f (X) ImageNet I → T lin 0.681 * 0.262</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experiment 2</head><p>Tab. 2 shows that untrained linear (f lin ) and neural net (f nn ) mappings preserve the semantic structure of the input X, complementing thus the findings of Experiment 1. Experiment 1 concerns learning, while, by "ablating" the learning part and random- izing weights, Experiment 2 is revealing about the natural tendency of neural nets to preserve seman- tic information about the input, regardless of the choice of the target vectors and loss function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>WS-353</head><p>Men  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>Overall, we uncovered a phenomenon neglected so far, namely that neural net cross-modal map- pings can produce mapped vectors more akin to the input vectors than the target vectors, in terms of semantic structure. Such finding has been pos- sible thanks to the proposed measure that explic- itly quantifies similarity between the neighbor- hood structure of two sets of vectors. While other measures such as mean squared error can be mis- leading, our measure provides a more realistic estimate of the semantic similarity between pre- dicted and target vectors. In fact, it is the semantic structure (or pairwise similarities) what ultimately matters in cross-modal applications.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Neural network and linear mappings are popu- lar tools to bridge modalities in cross-modal re- trieval systems. Lazaridou et al. (2015b) leverage a text-to-image linear mapping to retrieve images given text queries. Weston et al. (2011) map la- bel and image features into a shared space with a linear mapping to perform image annotation. Al- ternatively, Frome et al. (2013), Lazaridou et al. (2014) and Socher et al. (2013) perform zero-shot image classification with an image-to-text neural network mapping. Instead of mapping to latent features, Collell et al. (2018) use a 2-layer feed- forward network to map word embeddings directly to image pixels in order to visualize spatial ar- rangements of objects. Neural networks are also popular in other cross-space applications such as cross-lingual tasks. Lazaridou et al. (2015a) learn a linear map from language A to language B and then translate new words by returning the nearest neighbor of the mapped vector in the B space.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>where d x and d y are the input and output dimensions respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>1 2</head><label>1</label><figDesc>f (x) − y 2 , where y is the target vector. We also tested other losses such as the co- sine: 1 − cos(f (x), y) and the max-margin: max{0, γ + f (x) − y − f (˜ x) − y}, where˜x where˜ where˜x belongs to a different class than (x, y), and γ is the margin. As in Lazaridou et al. (2015a) and Weston et al. (2011), we choose the first˜xfirst˜ first˜x that violates the constraint.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>2014</head><label>2014</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>SemSim</head><label></label><figDesc></figDesc><table>Cos 
Eucl 
Cos 
Eucl 
Cos 
Eucl 

f nn (GloVe) 
0.632 0.634  *  0.795 0.791  *  0.75  *  0.744  *  
f lin (GloVe) 
0.63 
0.606 0.798 0.781 0.763 0.712 
GloVe 
0.632 
0.601 0.801 0.782 0.768 0.716 

f nn (ResNet) 0.402 0.408  *  0.556 0.554  *  0.512 0.513 
f lin (ResNet) 0.425 
0.449 0.566 0.534 0.533 0.514 
ResNet 
0.423 
0.457 0.567 0.535 0.534 0.516 

VisSim 
SimLex 
SimVerb 

Cos 
Eucl 
Cos 
Eucl 
Cos 
Eucl 

f nn (GloVe) 
0.594  *  0.59  *  0.369 0.363  *  0.313 0.301  *  
f lin (GloVe) 0.602  *  0.576 0.369 0.341 0.326 
0.23 
GloVe 
0.606 
0.58 
0.371 
0.34 
0.32 
0.235 

f nn (ResNet) 0.527  *  0.526  *  0.405 0.406 0.178 0.169 
f lin (ResNet) 0.541 
0.498 0.409 0.404 0.198 0.182 
ResNet 
0.543 
0.501 0.409 0.403 0.211 0.199 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Spearman correlations between human 
ratings and the similarities (cosine or Euclidean) 
predicted from the embeddings. Boldface denotes 
best performance per input embedding type. 

</table></figure>

			<note place="foot" n="1"> We indistinctly use the terms semantic structure, neighborhood structure and similarity structure. They refer to all pairwise similarities of a set of N vectors, for some similarity measure (e.g., Euclidean or cosine).</note>

			<note place="foot" n="2"> Parameters of these mappings were generated at random.</note>

			<note place="foot" n="3"> http://liir.cs.kuleuven.be/software.html 4 http://nlp.stanford.edu/projects/glove 5 http://liir.cs.kuleuven.be/software.html</note>

			<note place="foot" n="6"> We find that sigmoid and ReLu yield similar results. 7 Notice that papers generally use only cosine similarity (Lazaridou et al., 2015b; Pennington et al., 2014).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work has been supported by the CHIST-ERA EU project MUSTER 8 and by the KU Leuven grant RUN/15/005.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Basic topology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armstrong</forename><surname>Mark Anthony</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elia</forename><surname>Bruni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nam-Khanh</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multimodal distributional semantics. JAIR</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="1" to="47" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Return of the devil in the details: Delving deep into convolutional nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ken</forename><surname>Chatfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.1078</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Is an Image Worth More than a Thousand Words? On the Fine-Grain Semantic Differences between Visual and Linguistic Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillem</forename><surname>Collell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING. ACL</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2807" to="2817" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Acquiring Common Sense Spatial Knowledge through Implicit Spatial Templates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillem</forename><surname>Collell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</author>
		<editor>AAAI. AAAI</editor>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Imagined Visual Representations as Multimodal Embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillem</forename><surname>Collell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teddy</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI. AAAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4378" to="4384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Placing search in context: The concept revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Finkelstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yossi</forename><surname>Matias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehud</forename><surname>Rivlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zach</forename><surname>Solan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gadi</forename><surname>Wolfman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eytan</forename><surname>Ruppin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW. ACM</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="406" to="414" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Devise: A deep visual-semantic embedding model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Frome</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2121" to="2129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Simverb-3500: A largescale evaluation set of verb similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniela</forename><surname>Gerz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vuli´cvuli´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.00869</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The iapr tc-12 benchmark: A new evaluation resource for visual information systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Grubinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Deselaers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International workshop ontoImage</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.03385</idno>
		<title level="m">Deep residual learning for image recognition</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Simlex-999: Evaluating semantic models with (genuine) similarity estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="665" to="695" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Multilayer feedforward networks are universal approximators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Hornik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxwell</forename><surname>Stinchcombe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Halbert</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural networks</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="359" to="366" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Is this a wampimuk? cross-modal mapping between distributional semantics and the visual world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angeliki</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elia</forename><surname>Bruni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1403" to="1414" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Hubness and pollution: Delving into cross-space mapping for zero-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angeliki</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgiana</forename><surname>Dinu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="270" to="280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Combining language and vision with a multimodal skip-gram model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angeliki</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nghia The</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baroni</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1501.02598</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">On the role of correlation and abstraction in cross-modal multimedia retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Costa Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emanuele</forename><surname>Coviello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Doyle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhil</forename><surname>Rasiwasia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">G</forename><surname>Gert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Lanckriet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nuno</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="521" to="535" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Chunhua Shen, and Anton van den Hengel</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruizhi</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingqiao</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.05427</idno>
	</analytic>
	<monogr>
		<title level="m">Visually aligned word embeddings for improving zero-shot learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">On the existence of obstinate results in vector space models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milos</forename><surname>Radovanovi´cradovanovi´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandros</forename><surname>Nanopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirjana</forename><surname>Ivanovi´civanovi´c</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR. ACM</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="186" to="193" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning grounded meaning representations with autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carina</forename><surname>Silberer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="721" to="732" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Zero-shot learning through cross-modal transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milind</forename><surname>Ganjoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="935" to="943" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiye</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiyue</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.06215</idno>
		<title level="m">A comprehensive survey on cross-modal retrieval</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Wsabie: Scaling up to large vocabulary image annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="2764" to="2770" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Fast zero-shot image tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubarak</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR. IEEE</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="5985" to="5994" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
