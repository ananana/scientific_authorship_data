<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:39+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Pre-training of Hidden-Unit CRFs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 26-31, 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Bum</forename><surname>Kim</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Stratos</surname></persName>
							<email>stratos@cs.columbia.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">Columbia University</orgName>
								<address>
									<settlement>New York</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
							<email>{ybkim, ruhi.sarikaya}@microsoft.com</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Corporation</orgName>
								<address>
									<settlement>Redmond</settlement>
									<region>WA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Pre-training of Hidden-Unit CRFs</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="192" to="198"/>
							<date type="published">July 26-31, 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In this paper, we apply the concept of pre-training to hidden-unit conditional random fields (HUCRFs) to enable learning on unlabeled data. We present a simple yet effective pre-training technique that learns to associate words with their clusters , which are obtained in an unsuper-vised manner. The learned parameters are then used to initialize the supervised learning process. We also propose a word clustering technique based on canonical correlation analysis (CCA) that is sensitive to multiple word senses, to further improve the accuracy within the proposed framework. We report consistent gains over standard conditional random fields (CRFs) and HUCRFs without pre-training in semantic tagging, named entity recognition (NER), and part-of-speech (POS) tagging tasks, which could indicate the task independent nature of the proposed technique.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Despite the recent accuracy gains of the deep learning techniques for sequence tagging prob- lems <ref type="bibr" target="#b5">(Collobert and Weston, 2008;</ref><ref type="bibr" target="#b6">Collobert et al., 2011;</ref><ref type="bibr" target="#b26">Mohamed et al., 2010;</ref><ref type="bibr" target="#b7">Deoras et al., 2012;</ref><ref type="bibr" target="#b35">Xu and Sarikaya, 2013;</ref><ref type="bibr" target="#b36">Yao et al., 2013;</ref><ref type="bibr" target="#b24">Mesnil et al., 2013;</ref><ref type="bibr" target="#b34">Wang and Manning, 2013;</ref><ref type="bibr" target="#b8">Devlin et al., 2014</ref>), conditional random fields (CRFs) ( <ref type="bibr" target="#b20">Lafferty et al., 2001;</ref><ref type="bibr" target="#b32">Sutton and McCallum, 2006</ref>) still have been widely used in many research and production systems for the problems due to the effectiveness and simplicity of train- ing, which does not involve task specific param- eter tuning <ref type="bibr" target="#b4">(Collins, 2002;</ref><ref type="bibr" target="#b23">McCallum and Li, 2003;</ref><ref type="bibr" target="#b31">Sha and Pereira, 2003;</ref><ref type="bibr" target="#b33">Turian et al., 2010;</ref><ref type="bibr" target="#b14">Kim and Snyder, 2012;</ref><ref type="bibr" target="#b3">Celikyilmaz et al., 2013;</ref><ref type="bibr" target="#b30">Sarikaya et al., 2014;</ref><ref type="bibr" target="#b0">Anastasakos et al., 2014;</ref><ref type="bibr" target="#b16">Kim et al., 2015a;</ref><ref type="bibr" target="#b18">Kim et al., 2015c;</ref><ref type="bibr" target="#b17">Kim et al., 2015b</ref>). The objective function for CRF training operates globally over sequence structures and can incorporate arbitrary features. Furthermore, this objective is convex and can be optimized relatively efficiently using dynamic pro- gramming.</p><p>Pre-training has been widely used in deep learn- ing ( <ref type="bibr" target="#b10">Hinton et al., 2006</ref>) and is one of the distin- guishing advantages of deep learning models. The best results obtained across a wide range of tasks involve unsupervised pre-training phase followed by the supervised training phase. The empirical results ( <ref type="bibr" target="#b9">Erhan et al., 2010)</ref> suggest that unsuper- vised pre-training has the regularization effect on the learning process and also results in a model parameter configuration that places the model near the basins of attraction of minima that support bet- ter generalization.</p><p>While pre-training became a standard steps in many deep learning model training recipes, it has not been applied to the family of CRFs. There were several reasons for that; (i) the shallow and linear nature of basic CRF model topology, which limits their expressiveness to the inner product be- tween data and model parameters, and (ii) Lack of a training criterion and configuration to employ pre-training on unlabeled data in a task indepen- dent way.</p><p>Hidden-unit CRFs (HUCRFs) of Maaten et al. (2011) provide a deeper model topology and im- prove the expressive power of the CRFs but it does not address how to train them in a task inde- pendent way using unlabeled data. In this paper, we present an effective technique for pre-training of HUCRFs that can potentially lead to accuracy gains over HUCRF and basic linear chain CRF models. We cluster words in the text and treat clus- ters as pseudo-labels to train an HUCRF. Then we transfer the parameters corresponding to observa- tions to initialize the training process on labeled data. The intuition behind this is that words that are clustered together tend to assume the same la- bels. Therefore, learning the model parameters to assign the correct cluster ID to each word should accrue to assigning the correct task specific label during supervised learning.</p><p>This pre-training step significantly reduces the challenges in training a high-performance HUCRF by (i) acquiring a broad feature coverage from un- labeled data and thus improving the generalization of the model to unseen events, (ii) finding a good a initialization point for the model parameters, and (iii) regularizing the parameter learning by min- imizing variance and introducing a bias towards configurations of the parameter space that are use- ful for unsupervised learning.</p><p>We also propose a word clustering technique based on canonical correlation analysis (CCA) that is sensitive to multiple word senses. For ex- ample, the resulting clusters can differentiate the instance of "bank" in the sense of financial insti- tutions and the land alongside the river. This is an important point as different senses of a word are likely to have a different task specific tag. Putting them in different clusters would enable the HU- CRF model to learn the distinction in terms of la- bel assignment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">HUCRF definition</head><p>A HUCRF incorporates a layer of binary-valued hidden units z = z 1 . . . z n ∈ {0, 1} for each pair of observation sequence x = x 1 . . . x n and label sequence y = y 1 . . . y n . It is parameterized by <ref type="figure">Figure 2</ref>: Illustration of a pre-training scheme for HUCRFs.</p><p>θ ∈ R d and γ ∈ R d and defines a joint probability of y and z conditioned on x as follows:</p><formula xml:id="formula_0">p θ,γ (y, z|x) = exp(θ Φ(x, z) + γ Ψ(z, y)) z ∈{0,1} n y ∈Y(x,z ) exp(θ Φ(x, z ) + γ Ψ(z , y ))</formula><p>where Y(x, z) is the set of all possible label sequences for x and z, and Φ(x, z) ∈ R d and Ψ(z, y) ∈ R d are global feature func- tions that decompose into local feature functions:</p><formula xml:id="formula_1">Φ(x, z) = n j=1 φ(x, j, z j ) and Ψ(z, y) = n j=1 ψ(z j , y j−1 , y j ).</formula><p>HUCRF forces the interaction between the ob- servations and the labels at each position j to go through a latent variable z j : see <ref type="figure" target="#fig_0">Figure 1</ref> for illus- tration. Then the probability of labels y is given by marginalizing over the hidden units,</p><formula xml:id="formula_2">p θ,γ (y|x) = z∈{0,1} n p θ,γ (y, z|x)</formula><p>As in restricted Boltzmann machines <ref type="bibr" target="#b21">(Larochelle and Bengio, 2008)</ref>, hidden units are conditionally independent given observations and labels. This allows for efficient inference with HUCRFs de- spite their richness (see <ref type="bibr" target="#b22">Maaten et al. (2011)</ref> for details). We use a perceptron-style algorithm of Maaten et al. (2011) for training HUCRFs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Pre-training HUCRFs</head><p>How parameters are initialized for training is im- portant for HUCRFs because the objective func- tion is non-convex. Instead of random initializa- tion, we use a simple and effective initialization scheme (in a similar spirit to the pre-training meth- ods in neural networks) that can leverage a large body of unlabeled data. This scheme is a simple two-step approach.</p><p>In the first step, we cluster observed tokens in M unlabeled sequences and treat the clusters as la- bels to train an intermediate HUCRF. Let C(u (i) ) be the "cluster sequence" of the i-th unlabeled se- quence u (i) . We compute:</p><formula xml:id="formula_3">(θ 1 , γ 1 ) ≈ arg max θ,γ M i=1 log p θ,γ (C(u (i) )|u (i) ))</formula><p>In the second step, we train a final model on the labeled data {(x (i) , y (i) )} N i=1 using θ 1 as an ini- tialization point:</p><formula xml:id="formula_4">(θ 2 , γ 2 ) ≈ arg max θ,γ: init(θ,θ 1 ) N i=1 log p θ,γ (y (i) |x (i) )</formula><p>While we can use γ 1 for initialization as well, we choose to only use θ 1 since the label space is task- specific. This process is illustrated in <ref type="figure">Figure 2</ref>.</p><p>In summary, the first step is used to find generic parameters between observations and hid- den states; the second step is used to specialize the parameters to a particular task. Note that the first step also generates additional feature types absent in the labeled data which can be useful at test time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Multi-Sense Clustering via CCA</head><p>The proposed pre-training method requires assign- ing a cluster to each word in unlabeled text. Since it learns to associate the words to their clusters, the quality of clusters becomes important. A straight- forward approach would be to perform Brown clustering ( <ref type="bibr" target="#b1">Brown et al., 1992)</ref>, which has been very effective in a variety of NLP tasks <ref type="bibr" target="#b25">(Miller et al., 2004;</ref><ref type="bibr" target="#b19">Koo et al., 2008)</ref>.</p><p>However, Brown clustering has some undesir- able aspects for our purpose. First, it assigns a single cluster to each word type. Thus a word that can be used very differently depending on its con- text (e.g., "bank") is treated the same across the corpus. Second, the Brown model uses only un- igram and bigram statistics; this can be an issue if we wish to capture semantics in larger contexts. Finally, the algorithm is rather slow in practice for large vocabulary size.</p><p>To mitigate these limitations, we propose multi- sense clustering via canonical correlation analy- sis (CCA). While there are previous work on in- ducing multi-sense representations (Reisinger and</p><formula xml:id="formula_5">CCA-PROJ Input: samples (x (1) , y (1) ) . . . (x (n) , y (n) ) ∈ {0, 1} d × {0, 1} d , dimension k Output: projections A ∈ R d×k and B ∈ R d ×k • Calculate B ∈ R d×d , u ∈ R d , and v ∈ R d : Bi,j = n l=1 [[x (l) i = 1]][[y (l) j = 1]] ui = n l=1 [[x (l) i = 1]] vi = n l=1 [[y (l) i = 1]] • Definê Ω = diag(u) −1/2 Bdiag(v) −1/2 . • Calculate rank-k SVDˆΩSVDˆ SVDˆΩ. Let U ∈ R d×k (V ∈ R d ×k )</formula><p>be a matrix of the left (right) singular vector corre- sponding to the largest k singular values.</p><p>• </p><formula xml:id="formula_6">Let A = diag(u) −1/2 U and B = diag(v) −1/2 V .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Review of CCA</head><p>CCA is a general technique that operates on a pair of multi-dimensional variables. CCA finds k dimensions (k is a parameter to be specified) in which these variables are maximally correlated. Let x (1) . . . x (n) ∈ R d and y <ref type="bibr">(1)</ref> . . . y (n) ∈ R d be n samples of the two variables. For simplicity, as- sume that these variables have zero mean. Then CCA computes the following for i = 1 . . . k:</p><p>arg max</p><formula xml:id="formula_7">a i ∈R d , b i ∈R d : a i a i =0 ∀i &lt;i b i b i =0 ∀i &lt;i n l=1 (a i x (l) )(b i y (l) ) n l=1 (a i x (l) ) 2 n l=1 (b i y (l) ) 2</formula><p>In other words, each (a i , b i ) is a pair of pro- jection vectors such that the correlation between the projected variables a i x (l) and b i y (l) (now scalars) is maximized, under the constraint that this projection is uncorrelated with the previous i − 1 projections. A method based on singu- lar value decomposition (SVD) provides an effi- cient and exact solution to this problem <ref type="bibr" target="#b12">(Hotelling, 1936)</ref>. The resulting solution A ∈ R d×k (whose i-th column is a i ) and B ∈ R d ×k (whose i-th col- umn is b i ) can be used to project the variables from Input: word-context pairs from a corpus of length n:</p><formula xml:id="formula_8">D = {(w (l) , c (l) )} n l=1 , dimension k Output: cluster C(l) ≤ k for l = 1 . . . n</formula><p>• Use the algorithm in <ref type="figure" target="#fig_1">Figure 3</ref> to compute projection matrices (ΠW , ΠC ) = CCA-PROJ(D, k).</p><p>• For each word type w, perform k-means clustering on Cw = {Π C c (l) ∈ R k : w (l) = w} to partition occur- rences of w in the corpus into at most k clusters.</p><p>• Label each word w (l) with the cluster obtained from the previous step. Let ¯ D = {( ¯ w (l) , ¯ c (l) )} n l=1 denote this new dataset.</p><p>•</p><formula xml:id="formula_9">(Π ¯ W , Π ¯ C ) = CCA-PROJ( ¯ D, k) • Perform k-means clustering on {Π ¯ W ¯ w (l) ∈ R k }.</formula><p>• Let C(l) be the cluster corresponding to P i</p><formula xml:id="formula_10">¯ W v (l) .</formula><p>Figure 4: Algorithm for clustering of words in a corpus sensitive to multiple word senses.</p><p>the original d-and d -dimensional spaces to a k- dimensional space:</p><formula xml:id="formula_11">x ∈ R d −→ A x ∈ R k y ∈ R d −→ B y ∈ R k</formula><p>The new k-dimensional representation of each variable now contains information about the other variable. The value of k is usually selected to be much smaller than d or d , so the representation is typically also low-dimensional. The CCA algo- rithm is given in <ref type="figure" target="#fig_1">Figure 3</ref>: we assume that samples are 0-1 indicator vectors. In practice, calculating the CCA projections is fast since there are many efficient SVD implantations available. Also, CCA can incorporate arbitrary context definitions unlike the Brown algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Multi-sense clustering</head><p>CCA projections can be used to obtain vector representations for both words and contexts. If we wished for only single-sense clusters (akin to Brown clusters), we could simply perform k- means on word embeddings. However, we can exploit context embeddings to infer word senses. For each word type, we create a set of context embeddings corresponding to all occurrences of that word type. Then we cluster these embeddings; we use an implementation of k-means which automatically determines the num- ber of clusters upper bounded by k. The number of word senses, k, is set to be the number of la- bel types occurring in labeled data (for each task- specific training set).</p><p>We use the resulting context clusters to deter- mine the sense of each occurrence of that word type. For instance, an occurrence of "bank" might be labeled as "bank 1 " near "financial" or "Chase" and "bank 2 " near "shore" or "edge".</p><p>This step is for disambiguating word senses, but what we need for our pre-training method is the partition of words in the corpus. Thus we perform a second round of CCA on these disambiguated words to obtain corresponding word embeddings. As a final step, we perform k-means clustering on the disambiguated word embeddings to obtain the partition of words in the corpus. The algorithm is shown in <ref type="table">Table 4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>To validate the effectiveness of our pre-training method, we experiment on three sequence label- ing tasks: semantic tagging, named entity recogni- tion (NER), and part-of-speech (POS) tagging. We used L-BFGS for training CRFs 1 and the averaged perceptron for training HUCRFs. The number of hidden variables was set to 500.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Semantic tagging</head><p>The goal of semantic tagging is to assign the cor- rect semantic tag to a words in a given utter- ance. We use a training set of 50-100k queries across domains and the test set of 5-10k queries. For pre-training, we collected 100-200k unlabeled text from search log data and performed a stan- dard preprocessing step. We use n-gram features up to n = 3, regular expression features, do- main specific lexicon features and Brown clus- ters. We present the results for various config- urations in <ref type="table">Table 1</ref>. HUCRF with random ini- tialization from Gaussian distribution (HUCRF G ) boosts the average performance up to 90.52% (from 90.39% of CRF). HUCRF with pre-training with Brown clusters (HUCRF B ) and CCA-based clusters (HUCRF C ) further improves performance to 91.36% and 91.37%, respectively.</p><p>Finally, when we use multi-sense cluster (HUCRF C+ ), we obtain an F1-score of 92.01%. We also compare other alternative pre-training methods.</p><p>HUCRF with pre-training RBM  <ref type="table">Table 1</ref>: Comparison of slot F1 scores on nine personal assistant domains. The numbers in boldface are the best performing method. Subscripts mean the following: G = random initialization from a Gaussian distribution with variance 10 −4 , R = pre-training with Restricted Boltzmann Machine (RBM) using contrastive divergence of <ref type="bibr" target="#b11">(Hinton, 2002</ref>), C = pre-training with CCA-based clusters, B = pre- training with Brown clusters, S = pre-training with skip-ngram multi-sense clusters with fixed cluster size 5, N S = pre-training with non-parametric skip-ngram multi-sense clusters, C+ = pre-training with CCA-based multi-sense clusters.</p><p>(HUCRF R ) does not perform better than with random initialization. The skip-gram clusters (HUCRF S , HUCRF SN ) do not perform well ei- ther. Some examples of disambiguated word oc- currences are shown below, demonstrating that the algorithm in <ref type="figure" target="#fig_1">Figure 3</ref>     </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">NER &amp; POS tagging</head><p>We use CoNLL 2003 dataset for NER and POS with the standard train/dev/test split. For pre- training, we used the Reuters-RCV1 corpus. It contains 205 millions tokens with 1.6 million types. We follow same preprocessing steps as in semantic tagging. Also, we use the NER features used in <ref type="bibr" target="#b33">Turian et al. (2010)</ref> and POS features used in <ref type="bibr" target="#b22">Maaten et al. (2011)</ref>.</p><p>We present the results for both tasks in <ref type="table" target="#tab_2">Table 2</ref>. In both tasks, the HUCRF C+ yields the best per- formance, achieving error reduction of 20% (Test- A) and 13% (Test-B) for NER as well as 15% (Test-A) and 8% (Test-B) for POS over HUCRF R . Note that HUCRF does not always perform bet- ter than CRF when initialized randomly. How- ever, However, HUCRF consistently outperforms CRF with the pre-training methods proposed in this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We presented an effective technique for pre- training HUCRFs. Our method transfers observa- tion parameters trained on clustered text to initial- ize the training process. We also proposed a word clustering scheme based on CCA that is sensitive to multiple word senses. Using our pre-training method, we reported significant improvement over several baselines in three sequence labeling tasks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Graphical representation of hidden unit CRFs.</figDesc><graphic url="image-1.png" coords="2,72.00,62.80,218.27,163.51" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Algorithm for deriving CCA projections from samples of two variables.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>word context Book a book(1) store within 5 miles of my address find comic book(1) stores in novi michigan book(2) restaurant for tomorrow book(2) taxi to pizza hut look for book(3) chang dong tofu house in pocono find book(3) bindery seattle High restaurant nearby with high(1) ratings show me high(1) credit restaurant nearby the address for shelley high(2) school directions to leota junior high(2) school what's the distance to kilburn high(3) road domino's pizza in high(3) ridge missouri</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>F1 Score for NER task and Accuracy for 
POS task. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Examples of disambiguated word occur-
rences. 

</table></figure>

			<note place="foot" n="1"> For CRFs, we found that L-BFGS had higher performance than SGD and the average percetpron.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Task specific continuous word representations for mono and multi-lingual spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tasos</forename><surname>Anastasakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Bum</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anoop</forename><surname>Deoras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3246" to="3250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Peter F Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">L</forename><surname>Desouza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent J Della</forename><surname>Mercer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenifer C</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Class-based n-gram models of natural language</title>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="467" to="479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Semi-supervised semantic tagging of conversational understanding using markov topic regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asli</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dilek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gökhan</forename><surname>Hakkani-Tür</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Tür</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sarikaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="914" to="923" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL-02 conference on Empirical methods in natural language processing</title>
		<meeting>the ACL-02 conference on Empirical methods in natural language processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A unified architecture for natural language processing: Deep neural networks with multitask learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="160" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Joint decoding for speech recognition and semantic tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anoop</forename><surname>Deoras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gökhan</forename><surname>Tür</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek Z Hakkani-Tür</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fast and robust neural network joint models for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rabih</forename><surname>Zbib</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongqiang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Lamar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Makhoul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1370" to="1380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Why does unsupervised pre-training help deep learning?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Dumitru Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre-Antoine</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Manzagol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="625" to="660" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A fast learning algorithm for deep belief nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee-Whye</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1527" to="1554" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Training products of experts by minimizing contrastive divergence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1771" to="1800" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Relations between two sets of variates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harold</forename><surname>Hotelling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3/4</biblScope>
			<biblScope unit="page" from="321" to="377" />
			<date type="published" when="1936" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Improving Word Representations via Global Context and Multiple Word Prototypes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL. Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Universal grapheme-to-phoneme prediction over latin alphabets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Bum</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Snyder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="332" to="343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Training a korean srl system with rich morphological features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Bum</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heemoon</forename><surname>Chae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Snyder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Seop</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="637" to="642" />
		</imprint>
	</monogr>
	<note>ACL</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Weakly supervised slot tagging with partially labeled sequences from web search click logs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Bum</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minwoo</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Stratos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="84" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Compact lexicon selection with spectral methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Bum</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Stratos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL. Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">New transfer learning techniques for disparate label sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Bum</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Stratos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minwoo</forename><surname>Jeong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Simple semi-supervised dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Carreras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando Cn</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="282" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Classification using discriminative restricted boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Hidden-unit conditional random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence K</forename><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTAT</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Early results for named entity recognition with conditional random fields, feature induction and web-enhanced lexicons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="188" to="191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Investigation of recurrent-neuralnetwork architectures and learning methods for spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grégoire</forename><surname>Mesnil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3771" to="3775" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Name tagging with word clusters and discriminative training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jethran</forename><surname>Guinness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Zamanian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2004" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="337" to="342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Investigation of full-sequence training of deep belief networks for speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdel-Rahman</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="2846" to="2849" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Efficient nonparametric estimation of multiple embeddings per word in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeevan</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Multi-prototype vector-space models of word meaning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Reisinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Raymond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies: The</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<title level="m">Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="page" from="109" to="117" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Shrinkage based features for slot tagging with conditional random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asli</forename><surname>Celikyilmaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Anoop Deoras, and Minwoo Jeong</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Proc. of Interspeech</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Shallow parsing with conditional random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Conference of the North American Chapter</title>
		<meeting>the 2003 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="134" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">An introduction to conditional random fields for relational learning. Introduction to statistical relational learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="93" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Word representations: a simple and general method for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Turian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th annual meeting of the association for computational linguistics</title>
		<meeting>the 48th annual meeting of the association for computational linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="384" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Effect of non-linear deep architecture in sequence labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengqiu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML Workshop on Deep Learning for Audio, Speech and Language Processing</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Convolutional neural network based triangular crf for joint intent detection and slot filling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Puyang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="78" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Recurrent neural networks for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaisheng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Zweig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mei-Yuh</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangyang</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2524" to="2528" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
