<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:00+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Sparse, Contextually Informed Models for Irony Detection: Exploiting User Communities, Entities and Sentiment</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Byron</forename><forename type="middle">C</forename><surname>Wallace</surname></persName>
							<email>byron.wallace@utexas.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Texas at Austin</orgName>
								<orgName type="institution" key="instit2">Brown University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Do</forename><forename type="middle">Kook</forename><surname>Choe</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Texas at Austin</orgName>
								<orgName type="institution" key="instit2">Brown University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Texas at Austin</orgName>
								<orgName type="institution" key="instit2">Brown University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Sparse, Contextually Informed Models for Irony Detection: Exploiting User Communities, Entities and Sentiment</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1035" to="1044"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Automatically detecting verbal irony (roughly, sarcasm) in online content is important for many practical applications (e.g., sentiment detection), but it is difficult. Previous approaches have relied predominantly on signal gleaned from word counts and grammatical cues. But such approaches fail to exploit the context in which comments are embedded. We thus propose a novel strategy for verbal irony classification that exploits contex-tual features, specifically by combining noun phrases and sentiment extracted from comments with the forum type (e.g., conservative or liberal) to which they were posted. We show that this approach improves verbal irony classification performance. Furthermore, because this method generates a very large feature space (and we expect predictive contextual features to be strong but few), we propose a mixed regularization strategy that places a sparsity-inducing 1 penalty on the contextual feature weights on top of the 2 penalty applied to all model coefficients. This increases model sparsity and reduces the variance of model performance.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction and Motivation</head><p>Automated verbal irony detection is a challenging problem. <ref type="bibr">1</ref> But recognizing when an author has in- tended a statement ironically is practically impor- tant for many text classification tasks (e.g., senti- ment detection).</p><p>Previous models for irony detection <ref type="bibr" target="#b11">Lukin and Walker, 2013</ref>; Riloff et al., <ref type="figure">Figure 1</ref>: A reddit comment illustrating contextualizing fea- tures that we propose leveraging to improve classification. Here the highlighted entities (external the comment text it- self) provide contextual signals indicating that the shown comment was intended ironically. As we shall see, Oba- macare is in general a strong indicator of irony when present in posts to the conservative subreddit, but less so in posts to the progressive subreddit. <ref type="bibr">2013</ref>) have relied predominantly on features in- trinsic to the texts to be classified. By contrast, here we propose exploiting contextualizing infor- mation, which is often available for web-based classification tasks. More specifically, we exploit signal gleaned from the conversational threads to which comments belong. Our approach capital- izes on the intuition that members of different user communities are likely to be sarcastic about dif- ferent things. As a proxy for user community, we leverage knowledge of the specific forums to which comments were posted. For example, one may surmise that the statement 'I really am proud of Obama' is likely to have been intended iron- ically if it was posted to a forum frequented by political conservatives. But if this same utterance were posted to a liberal-leaning forum, it is more likely to have been intended in earnest. This sort of information is often directly or indirectly avail- able on social media, but previous models have not capitalized on it. This is problematic; recent work has shown that humans require such contextualiz- ing information to infer ironic intent ( <ref type="bibr" target="#b21">Wallace et al., 2014)</ref>.</p><p>As a concrete example, we consider the task of identifying verbal irony in comments posted to reddit (http://www.reddit.com), a social- news website. Users post content (e.g., links to news stories) to reddit, which are then voted on by the community. Users may also discuss this con- tent on the website; these are the comments that we will work with here. Reddit comprises many subreddits, which are user communities centered around specific topics of interest. In this work we consider comments posted to two pairs of po- larized user communities, or subreddits: (1) pro- gressive and conservative subreddits (comprising individuals on the left and right of the US polit- ical spectrum, respectively), and (2) atheism and Christianity subreddits.</p><p>Our aim is to develop a model that can recog- nize verbal irony in comments posted to such fo- rums, e.g., automatically discern that the user who posted the comment shown in <ref type="figure">Figure 1</ref> intended his or her comment ironically. To this end, we pro- pose a strategy that capitalizes on available con- textualizing information, such as interactions be- tween the user community (subreddit) that com- ments were posted to, extracted entities (here we use noun phrases, or NNPs) and inferred senti- ment.</p><p>The contributions of this work are summarized as follows.</p><p>• We demonstrate that contextual information, such as inferred user-community (in this case, the subreddit) can be crossed with ex- tracted entities and sentiment to improve de- tection of verbal irony. This improves perfor- mance over baseline models (including those that exploit inferred sentiment, but not con- text).</p><p>• We introduce a novel composite regular- ization strategy that applies a sparsifying 1 penalty to the contextual/sentiment/entity feature weights in addition to the standard squared 2 penalty to all feature weights. This induces more compact, interpretable models that exhibit lower variance.</p><p>While discerning ironic comments on reddit is our immediate task, the proposed approach is generally applicable to a wide-range of subjec- tive, web-based text classification tasks. Indeed, this approach would be useful for any scenario in which we expect different groups of individuals producing content to tend to discuss different en- tities in a way that correlates with the target cate- gorization. The key is in identifying an available proxy for user groupings (here we rely on the sub- reddits to which a comment was posted). Such information is often available (or can be derived) for comments posted to different mediums on the web: for example on Twitter we know who a user follows; and on YouTube we know the channels to which videos belong.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Exploiting context 2.1 Communities and sentiment</head><p>As discussed above, a shortcoming with existing models for detecting sarcasm/verbal irony on the web is their failure to capitalize on contextualiz- ing information. But such information is critical to discerning irony. A large body of work on the use and interpretation of verbal irony supports this supposition <ref type="bibr" target="#b9">(Grice, 1975;</ref><ref type="bibr" target="#b3">Clark and Gerrig, 1984;</ref><ref type="bibr" target="#b22">Wallace, 2013;</ref><ref type="bibr" target="#b21">Wallace et al., 2014</ref>). Individu- als will be more likely, in general, to use sarcasm when discussing specific entities. Which entities will depend in part on the community to which the individual belongs. As a proxy for user com- munity, here we leverage the subreddits to which comments were posted.</p><p>Sentiment may also play an important role. In general, verbal irony is almost always used to con- vey negative views via ostensibly positive utter- ances ( <ref type="bibr" target="#b16">Sperber and Wilson, 1981)</ref>. And recent work ( <ref type="bibr" target="#b14">Riloff et al., 2013</ref>) has exploited features based on sentiment to improve irony detection.</p><p>To summarize: when assuming an ironic voice we expect that individuals will convey ostensibly positive sentiment about entities, and that these en- tities will depend on the type of individual in ques- tion. We propose capitalizing on such informa- tion by introducing features that encode subred- dits, sentiment and noun phrases (NNPs), as we describe next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Features</head><p>We leverage the feature sets enumerated in Ta- ble 1. Subreddits are observed variables. Noun phrase (NNP) extraction and sentiment inference are performed automatically via state of the art NLP tools. In particular, we use the Stanford Sen- timent Analysis tool <ref type="bibr" target="#b15">(Socher et al., 2013</ref>) to infer sentiment. To extract NNPs we use the Stanford Feature Description Sentiment The inferred sentiment (nega- tive/neutral or positive) for a given comment. Subreddit the subreddit (e.g., progressive or con- servative; atheism or Christianity) to which a comment was posted. NNP Noun phrases (e.g., proper nouns) ex- tracted from comment texts. NNP+ Noun phrases extracted from comment texts and the thread to which they be- long (for example, 'Obamacare' from the title in <ref type="figure">Figure 1</ref>). <ref type="table">Table 1</ref>: Feature types that we exploit. We view the (ob- served) subreddit as a proxy for user type. We combine this with sentiment and extracted noun phrases (NNPs) to im- prove classifier performance.</p><p>Part of Speech tagger ( <ref type="bibr" target="#b18">Toutanova et al., 2003</ref>). We then introduce 'bag-of-NNP' features and features that indicate whether the sentiment inferred for a given sentence was positive or not.</p><p>Additionally, we introduce 'interaction' fea- tures that capture combinations of these. For ex- ample, a feature that indicates whether a given sentence mentions Obamacare (which will be one of many NNPs automatically extracted) and was posted in the conservative subreddit. This is an example of a two-way interaction. We also exper- iment with three-way interactions, crossing senti- ment with NNPs and subreddits. An example is a feature that indicates if a sentence was: inferred to be positive and mentions Obamacare (NNP) and was part of a comment made in the conserva- tive subreddit. Finally, we experiment with adding NNPs extracted from the comment thread in addi- tion to the comment text.</p><p>These are rich features that capture signal not directly available from the sentences themselves. Features that encode subreddits crossed with ex- tracted NNP's, in particular, offer a chance to ex- plicitly account for differences in how the ironic device is used by individuals in different com- munities. However, this has the downside of in- troducing a large number of irrelevant terms into the model: we expect, a priori, that many enti- ties will not correlate with the use of verbal irony. We would therefore expect this strategy to exhibit high variance in terms of predictive performance, and we later confirm this empirically. Ideally, a model would perform feature selection during pa- rameter estimation, thus dropping irrelevant inter- action terms. We next introduce a composite 1 / 2 regularization strategy toward this end.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Enforcing sparsity 3.1 Preliminaries</head><p>In this work we consider linear models with bi- nary outputs (y ∈ {−1, +1}). We will assume we have access to a training dataset comprising n instances, x = {x 1 , ..., x n } and associated labels y = {y 1 , ..., y n }. We then aim to find a weight- vector w that optimizes the following objective.</p><formula xml:id="formula_0">argmin w n i=1 L(sign{w · x i }, y i ) + αR(w) (1)</formula><p>Where L is a loss function, R(w) is a regulariza- tion term and α is a parameter expressing the rel- ative emphasis placed on achieving minimum em- pirical loss versus producing a simple model (i.e., a weight vector with small weights). Typically one searches for a good α using the available train- ing data. For L, we will use the log-loss in this work, though other loss functions may be used in its place.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Sparsity via Regularization</head><p>Concerning R, one popular regularization func- tion is the squared 2 norm:</p><formula xml:id="formula_1">j w 2 j (2)</formula><p>This is the norm used in the standard Support Vec- tor Machine (SVM) formulation, for example, and has been shown empirically to work well for text classification <ref type="bibr" target="#b10">(Joachims, 1998</ref>). An alternative is to use the 1 norm:</p><formula xml:id="formula_2">j |w j | (3)</formula><p>Which has the advantage of inducing sparse mod- els: i.e., using the 1 norm as a penalty tends to drive feature weights to 0. Returning to the present task of detecting ver- bal irony in comments, it seems reasonable to as- sume that there will be a relatively small set of entities that correlate with sarcasm. But because we are introducing 'interaction' features that enu- merate the cross-product of subreddits and entities (and, in some cases, sentiment), we have a large feature-space. This space includes features that correspond to NNPs extracted from, and sentiment inferred for, the sentence itself: we will denote the indices for these by I. Other interaction features correspond to entities extracted from the threads associated with comments: we denote the corre- sponding set of indices by T . We expect only a fraction of the features comprising both I and T to have non-zero weights (i.e., to signal ironic in- tent).</p><p>This scenario is prone to the undesirable prop- erty of high-variance, and hence calls for stronger regularization.</p><p>But in general replacing the squared 2 norm with an 1 penalty (over all weights) hampers classification performance (in- deed, as we later report, this strategy performs very poorly here). Therefore, in our scenario we would like to place a sparsifying 1 regularizer over the contextual (interaction) features while still leveraging the squared 2 -norm penalty for the standard bag-of-words (BoW) features. <ref type="bibr">2</ref> We thus propose the following composite penalty:</p><formula xml:id="formula_3">j w 2 j + k∈I |w k |+ l∈T |w l | (4)</formula><p>The idea is that this will drive many of the weights associated with the contextual features to zero, which is desirable in light of the intuition that a relatively small number of entities will likely in- dicate sarcasm. At the same time, this composite penalty applies only the squared 2 norm to the standard BoW features, given the comparatively strong predictive performance realized with this strategy. Putting this together, we modify the original ob- jective (Equation 1) as follows:</p><formula xml:id="formula_4">argmin w n i=1 L(sign{w · x i }, y i )+ α 0 j w 2 j + α 1 k∈I |w k |+α 2 l∈T |w l | (5)</formula><p>Where we have placed separate α scalars on the re- spective penalty terms. Note that this is similar to the elastic net ( <ref type="bibr" target="#b25">Zou and Hastie, 2005</ref>) joint regu- larization and variable selection strategy. The dis- tinction here is that we only apply the 1 penalty to (i.e., perform feature selection for) the subset of 'interaction' feature weights, which is in con- trast to the elastic net, which imposes the compos- ite penalty to all feature weights. One can view this as using the regularizer to encourage a spar- sity pattern specific to the task at hand.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Inference</head><p>We fit this model via Stochastic Gradient Descent (SGD). <ref type="bibr">3</ref> During each update, we impose both the squared 2 and 1 penalties; the latter is applied only to the contextual/interaction features in I and T . For the 1 penalty, we adopt the cumulative truncated gradient method proposed by <ref type="bibr" target="#b20">Tsuruoka et al. (2009)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Setup</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>For our development dataset, we used a subset of the reddit irony corpus ( <ref type="bibr" target="#b21">Wallace et al., 2014</ref>) com- prising annotated comments from the progressive and conservative subreddits. We also report re- sults from experiments performed using a sepa- rate, held-out portion of this data, which we did not use during model refinement. Furthermore, we later present results on comments from the athe- ism and Christianity subreddits (we did not use this data during model development, either). The development dataset includes 1,825 anno- tated comments (876 and 949 from the progressive and conservative subreddits, respectively). These comprise 5,625 sentences in total, each of which was independently labeled by three annotators as having been intended ironically or not. For addi- tional details on the annotation process, see <ref type="bibr" target="#b21">(Wallace et al., 2014</ref>). For simplicity, we consider a sentence to be 'ironic' (y = 1) when at least two of the three annotators designated it as such, and 'unironic' (y = −1) otherwise. Using this crite- ria, 286 (5%) of the labeled sentences are labeled 'ironic'.</p><p>The test portion of the political dataset com- prises 996 annotated comments (409 progressive and 587 conservative comments), totalling 2,884 sentences. Using the same criteria as above -at least 2/3 annotators labeling a given sentence as 'ironic' -we have 154 'ironic' sentences (again about 5%).</p><p>The 'religion' dataset (comments from athe- ism and Christianity) contains 1,682 labeled com- ments comprising 5615 sentences (2,966 and 2,649 from the atheism and Christian subreddits, respectively); 313 (∼6%) were deemed 'ironic'.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental Details</head><p>We recorded results from 500 independently per- formed experiments on random train (80%)/test (20%) splits of the data. These splits were per- formed at the comment (rather than sentence) level, so as not to test on sentences belonging to comments encountered in the training set. We measured performance, however, at the sentence level (often only a single sentence in a given com- ment will have been labeled as 'ironic').</p><p>Our baseline approach is a standard squared-2 regularized log-loss linear model (fit via SGD) that leverages uni-and bi-grams and features indicat- ing grammatical cues, such as exclamation points and emoticons. We also experiment with a model that includes inferred sentiment indicators, but not context. We performed standard English stop- wording, and we used Term Frequency Inverse- Document Frequency (TF-IDF) feature weighting. For the gradient descent procedure, we used a de- caying learning rate (specifically, 1 t , where t is the update count). We performed a coarse grid search to find values for α that maximize F 1 on the train- ing datasets. We took five full passes over the training data before terminating descent.</p><p>We report paired recalls and precisions, as ob- served on each random train/test split of the data. The former is defined as T P T P +F N and the latter as T P T P +F P , where T P denotes the true positive count, F N the number of false negatives and F P the false positive count. We report these sepa- rately -rather than collapsing into F 1 -because it is not clear that one would value recall and pre- cision equally for irony detection, and because this allows us to tease out how the models differ in per- formance. Notably, for example, sentiment and context features both improve recall, but the lat- ter does so without harming precision. <ref type="figure">Figure 2</ref> and Table 2 summarize the performance of the different approaches over 500 indepen- dently performed train/test splits of the political development corpus. For reference, a random chance strategy (which predicts 'ironic' with prob- ability equal to the observed prevalence) achieves a median recall of 0.048 and a median precision of 0.047. <ref type="figure">Figure 2</ref> shows histograms of the observed ab- solute differences between the baseline linear clas- sifier and the proposed augmentations. Adding the proposed features (which capitalize on senti- ment and NNP-mentions on specific subreddits) increases absolute median recall by 3.4 percent- age points (a relative gain of ∼12%). And this is achieved without sacrificing precision (in contrast to exploiting only sentiment). Furthermore, as we can see in <ref type="figure" target="#fig_2">Figures 2 and 3</ref>, the proposed regular- ization strategy shrinks the variance of the classi- fier. This variance reduction is achieved through greater model sparsity, as can be seen in <ref type="figure" target="#fig_0">Figure  4</ref>, which improves interpretability. We note that leveraging only an 1 regularization penalty (with the full feature-set) results in very poor perfor- mance (median recall and precision of 0.05 and 0.09, respectively). Similarly, the elastic-net strat- egy ( <ref type="bibr" target="#b25">Zou and Hastie, 2005</ref>) (in which we do not specify which features to apply the 1 penalty to), here achieves a median recall of 0.11 and a median precision of 0.07. <ref type="table">Table 4</ref> reports results on the held-out political test dataset, achieved after training the models on the entirety of the development corpus. To account for the variance inherent to inference via SGD, we performed 100 runs of the SGD procedure and re- port median results from these runs. These results mostly agree with those reported for the develop- ment corpus: the proposed strategy improves me- dian recall on the held-out corpus by nearly 4.0 percentage points, at a median cost of about 1 point in precision. By contrast, sentiment alone provides a 2% absolute improvement in recall at mean; median (25th, 75th) mean; median (25th, 75th) baseline (BoW) 0.288; 0.283 (0.231, 0.333) 0.129; 0.124 (0.103, 0.149) ∆ recall ∆ precision (overall) sent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Results on the Development Corpus</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results on the Held-out (Test) Corpus</head><p>+0.036; +0.037 (+0.015, +0.063) -0.008; -0.007 (-0.018, +0.003) NNP +0.021; +0.018 (+0.000, +0.036) -0.008; -0.008 (-0.016, -0.001) NNP × subreddit +0.013; +0.016 (+0.000, +0.031) -0.002; -0.003 (-0.009, +0.004) NNP × subreddit <ref type="formula">(1 2)</ref> +0.010; +0.000 (+0.000, +0.021) -0.002; -0.002 (-0.007, +0.004) NNP+ × sent. × subreddit + sent.</p><p>+0.036; +0.038 (+0.000, +0.065) -0.000; -0.001 (-0.012, +0.011) NNP+ × sent. × subreddit + sent. <ref type="formula">(1 2)</ref> +0.035; +0.034 (+0.000, +0.062) +0.001; +0.000 (-0.011, +0.011) <ref type="table">Table 2</ref>: Summary results over 500 random train/test splits of the development dataset. The top row reports mean and median baseline (BoW) recall and precision and lower and upper (25th and 75th) percentiles. We report pairwise differences w.r.t. this baseline in terms of recall and precision for each strategy. Exploiting NNP features and subreddits improves recall with little to not cost in precision. Capitalizing on sentiment alone improves recall but at a greater cost in precision. The proposed 12 regularization strategy achieves comparable performance with fewer features, and shrinks the variance over different train/test splits (as can bee seen in <ref type="figure">Figure 2</ref>  <ref type="formula">(1 2)</ref> +0.013; +0.015 (+0.000, +0.033) +0.002; +0.002 (-0.009, +0.011) NNP+ × sent. × subreddit + sent.</p><p>+0.023; +0.024 (+0.000, +0.046) +0.001; +0.001 (-0.012, +0.013) NNP+ × sent. × subreddit + sent. <ref type="formula">(1 2)</ref> +0.014; +0.015 (+0.000, +0.036) -0.008; -0.008 (-0.021, +0.004) <ref type="table">Table 3</ref>: Results on the atheism and Christianity subreddits. In general sentiment does not help on this dataset (see row 1). But the NNP and subreddit features again consistently improve recall without hurting precision. And, as above, 12 regularization shrinks variance (see <ref type="figure" target="#fig_2">Figures 2 and 3</ref>). <ref type="figure">Figure 2</ref>: Results from 500 independent train/test splits of the development subset of our political data. Shown are histograms with smoothed kernel density estimates of differences in recall and precision between the baseline bag-of-words based approach and each feature space/method (one per row). The solid black line at 0 indicates no difference; solid and dotted blue lines demarcate means and medians, respectively. Features are as in <ref type="table">Table 1</ref>. The × symbol denotes interactions; + indicates addition. The proposed contextual features substantially improve recall, with little to no loss in precision. Moreover, in general, the 12 regularization approach reduces variance. (We note that in constructing histograms we have excluded a handful of points -never more than 1% -where the difference exceeded 0.15).  <ref type="table">Table 4</ref>: Results on the held-out political dataset, using the entire development corpus as a training set. Abbreviations are as described in the caption for <ref type="figure">Figure 2</ref>. Due to the variance inherent to the stochastic gradient descent procedure, we repeat the experiment 100 times and report the median performance and standard deviations (of different SGD runs). Results are consistent with those reported for the development corpus. the expense of more than 2 points in precision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Results on the religion dataset</head><p>To assess the general applicability of the proposed approach, we also evaluate the method on com- ments from a separate pair of polarized communi- ties: atheism and Christianity, as described in Sec- tion 4.1. This dataset was not used during model development. We follow the experimental setup described in Section 4.2.</p><p>In this case, capitalizing on the NNP × subred- dit features produces a mean 2.3% absolute gain in recall (median: 2.4%) over the baseline approach, with a (very) slight gain in precision. The 1 2 approach achieves a lower expected gain in recall (median: 1.5%), but again shrinks the variance w.r.t. model performance (see <ref type="figure" target="#fig_2">Figure 3)</ref>. More- over, as we show in <ref type="figure" target="#fig_0">Figure 4</ref>, this is achieved with a much more compact (sparser) model. We note that for the religion data, inferred sentiment fea- tures do not seem to improve performance, in con- trast to the results on the political subreddits. At present, we are not sure why this is the case.</p><p>These results demonstrate that introducing fea- tures that encode entities and user communities (NNPs × subreddit) improve recall for irony de- tection in comments addressing relatively diverse topics (politics and religion).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Predictive features</head><p>We report the interaction features that are the best predictors of verbal irony in the respective subred-  dits (for both polar community pairs). Specifically, we estimated the weights for every interaction fea- ture using the entire training dataset, and repeated this process 100 times to account for variation due to the SGD procedure. <ref type="table" target="#tab_2">Table 5</ref> displays the top 10 NNP × subreddit features for the political subreddits, with respect to the mean magnitude of the weights associated with them. We report these means and the standard de- viations calculated across the 100 runs. This table implies, for example, that mentions of 'freedom' and 'kenya' indicate irony in the progressive sub- reddit; while mentions of 'obamacare' and 'pres- ident' (for example) in the conservative subreddit tend to imply irony. <ref type="table" target="#tab_4">Table 6</ref> reports analagous results for the religion subreddits. Here we can see, e.g., that 'god' is a good predictor of irony in the atheism subreddit, and 'professor' is in the Christianity subreddit.</p><p>We also report the top ranking 'three-way' in- teraction features that cross NNP's extracted from   sentences with subreddits and the inferred senti- ment for the political corpus <ref type="table" target="#tab_5">(Table 7)</ref>. This would imply, e.g., that if a sentence in the progressive subreddit conveys an ostensibly positive sentiment about the political commentator 'Ollie', 4 then this sentence is likely to have been intended ironically. Some of these may seem counter-intuitive, such as ostensibly positive sentiment regarding 'Cruz' (as in the conservative senator Ted Cruz) in the conservative subreddit. On inspection of the com- ments, it would seem Ted Cruz does not find general support even in this community. Exam- ple comments include: "Stay classy Ted Cruz" and "Great idea on the talkathon Cruz". The 'mr' and 'king' terms are almost exclusively ref- erences to Obama in the conservative subreddit. In any case, because these are three-way interac- tion terms, they are all relatively rare: therefore we would caution against over interpretation here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>The task of automated irony detection has recently received a great deal of attention from the NLP and ML communities <ref type="bibr" target="#b17">(Tepperman et al., 2006;</ref><ref type="bibr" target="#b1">Carvalho et al., 2009;</ref><ref type="bibr" target="#b0">Burfoot and Baldwin, 2009;</ref><ref type="bibr" target="#b8">González-Ibáñez et al., 2011;</ref><ref type="bibr" target="#b7">Filatova, 2012;</ref><ref type="bibr" target="#b13">Reyes et al., 2012;</ref><ref type="bibr" target="#b11">Lukin and Walker, 2013;</ref><ref type="bibr" target="#b14">Riloff et al., 2013)</ref>. This work has mostly focussed on exploiting token- 4 'Ollie' is a conservative political commentator. based indicators of verbal irony. For example, it is clear that gratuitous punctuation (e.g. "oh re- ally??!!!") signals irony ( <ref type="bibr" target="#b1">Carvalho et al., 2009)</ref>.  proposed a semi- supervised approach in which they look for sen- tence templates indicative of irony. Elsewhere, <ref type="bibr" target="#b14">Riloff et al. (2013)</ref> proposed a method that ex- ploits apparently contrasting sentiment in the same utterance to detect irony. While innovative, these approaches still rely on features intrinsic to com- ments; i.e., they do not attempt to capitalize on contextualizing features external to the comment text. This means that there will necessarily be cer- tain (subtle) ironies that escape detection by such approaches. For example, without any additional information about the speaker, it would be impos- sible to deduce whether the comment "Obamacare is a great program" is intended sarcastically.</p><p>Other related recent work has shown the promise of sparse models, both for prediction and interpretation <ref type="bibr" target="#b5">(Eisenstein et al., 2011a;</ref><ref type="bibr" target="#b6">Eisenstein et al., 2011b;</ref><ref type="bibr" target="#b23">Yogatama and Smith, 2014a)</ref>. <ref type="bibr" target="#b23">Yogatama (2014a;</ref><ref type="bibr" target="#b24">2014b)</ref>, e.g., has leveraged the group lasso approach to impose 'structured' spar- sity on feature weights. Our work here may simi- larly be viewed as assuming a specific sparsity pat- tern (specifically that feature weights for 'interac- tion features' will be sparse) and expressing this via regularization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions and Future Directions</head><p>We have shown that we can leverage contextual- izing information to improve identification of ver- bal irony in online comments. This is in contrast to previous models, which have relied predomi- nantly on features that are intrinsic to the texts to be classified. We exploited features that indi- cate user communities crossed with sentiment and extracted noun phrases. This led to consistently improved recall with little to no cost in precision. We also proposed a novel composite regulariza- tion strategy that imposes a sparsifying 1 penalty on the interaction features, as we expect most of these to be irrelevant. This reduced performance variance.</p><p>Future work will include expanding the corpus and experimenting with datasets outside of the po- litical domain. We also plan to evaluate this strat- egy on data from different online sources, e.g., Twitter or YouTube.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Empirical distributions (violin plots) of non-zero feature counts in the NNP × subreddit model (rows 3 and 4 in Figure 3) using standard 2-norm (left) and the proposed 12-norm (right) regularization approaches on the atheism/Christianity data over 500 independent train/test splits. The composite norm achieves much greater sparsity, resulting in lower variance. This sparsity also (arguably) provides greater interpretability; one can inspect contextual features with non-zero weights.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Results from 500 independent train/test splits of the development subset of the religion corpus). The description is the same as for Figure 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Average weights (and standard deviations calculated 
across samples) for top 10 NNP × subreddit features from 
the progressive and conservative subreddits. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Top 10 NNP × subreddit features from the atheism 
and Christianity subreddits. 

progressive 
conservative 
feature 
weight 
feature 
weight 
american (+) 
0.045 (0.023) 
mr (+) 
0.041 (0.021) 
yay (+) 
0.042 (0.022) 
cruz (+) 
0.040 (0.021) 
ollie (+) 
0.036 (0.019) 
king (+) 
0.036 (0.019) 
north (+) 
0.036 (0.019) 
onion (+) 
0.035 (0.018) 
fuck (+) 
0.034 (0.018) 
russia (+) 
0.034 (0.018) 
washington (+) 
0.034 (0.018) 
oprah (+) 
0.030 (0.016) 
times* (+) 
0.034 (0.018) 
science (+) 
0.027 (0.015) 
world (+) 
0.030 (0.016) 
math (+) 
0.027 (0.015) 
magic (+) 
0.024 (0.013) 
america (+) 
0.026 (0.014) 
where (+) 
0.024 (0.013) 
ben (+) 
0.020 (0.011) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table>Average weights for top 10 NNP × subreddit × 
sentiment features. The parenthetical '+' indicates that the 
inferred sentiment was positive. In general, (ostensibly) pos-
itive sentiment indicates irony. 

</table></figure>

			<note place="foot" n="1"> In this paper we will be a bit cavalier in using the terms &apos;verbal irony&apos; and &apos;sarcasm&apos; interchangeably. We recognize that the latter is a special type of the former, the definition of which is difficult to pin down precisely. Guys who the fuck cares?! Leave him alone, there are real problems like bridge-gate scandal with Chris Cristie</note>

			<note place="foot" n="2"> Note that we apply both 1 and 2 penalties to the features in I and T .</note>

			<note place="foot" n="3"> We have implemented this within the sklearn package (Pedregosa et al., 2011).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was supported by ARO grant W911NF-14-1-0442.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Automatic satire detection: are you having a laugh?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Burfoot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL-IJCNLP</title>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="161" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Clues for detecting irony in user-generated contents: oh</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Carvalho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sarmento</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Oliveira</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">s so easy;-)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">!!</forename><surname>It</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM workshop on Topic-sentiment analysis for mass opinion</title>
		<imprint>
			<publisher>ACM</publisher>
			<biblScope unit="page" from="53" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">On the pretense theory of irony</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">H</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="page" from="121" to="126" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Semisupervised recognition of sarcastic sentences in twitter and amazon</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Davidov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tsur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rappoport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Natural Language Learning (CoNLL)</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">107</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Sparse additive generative models of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Eisenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Discovering sociolinguistic associations with structured sparsity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Eisenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1365" to="1374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Irony and sarcasm: Corpus generation and analysis using crowdsourcing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Filatova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="392" to="398" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Identifying sarcasm in twitter: a closer look</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>González-Ibáñez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Muresan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wacholder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="581" to="586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Logic and conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hp Grice</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975" />
			<biblScope unit="page" from="41" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Text categorization with support vector machines: Learning with many relevant features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Really? well. apparently bootstrapping improves the performance of sarcasm and nastiness classifiers for online dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lukin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NAACL</title>
		<imprint>
			<biblScope unit="page" from="30" to="40" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Passos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A multidimensional approach for detecting irony in twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Reyes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Veale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">LREC</title>
		<imprint>
			<biblScope unit="page" from="1" to="30" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Sarcasm as contrast between a positive sentiment and negative situation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Riloff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Qadir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Surve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="704" to="714" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Recursive deep models for semantic compositionality over a sentiment treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Perelygin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1631" to="1642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Irony and the usemention distinction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sperber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wilson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Yeah Right&quot;: Sarcasm Recognition for Spoken Dialogue Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tepperman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Traum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Narayanan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Feature-rich part-of-speech tagging with a cyclic dependency network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Conference of the North American Chapter</title>
		<meeting>the 2003 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="173" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">ICWSMa great catchy name: Semi-supervised recognition of sarcastic sentences in online product reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Tsur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Davidov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rappoport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Weblogs and Social Media</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Stochastic gradient descent training for l1regularized log-linear models with cumulative penalty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tsuruoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tsujii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ananiadou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the Annual Meeting of the ACL and the International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the Annual Meeting of the ACL and the International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="477" to="485" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Humans require context to infer ironic intent (so computers probably do, too)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bc Wallace</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kertz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Charniak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="512" to="516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Computational irony: A survey and new perspectives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bc Wallace</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence Review</title>
		<imprint>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Linguistic structured sparsity in text categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="786" to="796" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Making the most of bag of words: Sentence regularization with alternating direction method of multipliers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 31st International Conference on Machine Learning</title>
		<meeting>The 31st International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="656" to="664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Regularization and variable selection via the elastic net</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Statistical Methodology)</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="301" to="320" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
