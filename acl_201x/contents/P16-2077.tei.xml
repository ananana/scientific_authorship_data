<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:48+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Specifying and Annotating Reduced Argument Span Via QA-SRL</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Stanovsky</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">Bar-Ilan University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meni</forename><surname>Adler</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">Bar-Ilan University</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
							<email>dagan@cs.biu.ac.il</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">Bar-Ilan University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Specifying and Annotating Reduced Argument Span Via QA-SRL</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="474" to="478"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Prominent semantic annotations take an inclusive approach to argument span annotation , marking arguments as full constituency subtrees. Some works, however , showed that identifying a reduced argument span can be beneficial for various semantic tasks. While certain practical methods do extract reduced argument spans, such as in Open-IE , these solutions are often ad-hoc and system-dependent, with no commonly accepted standards. In this paper we propose a generic argument reduction criterion, along with an annotation procedure, and show that it can be consistently and intuitively annotated using the recent QA-SRL paradigm.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Representations of predicate-argument structure need to determine the span of predicates and their corresponding arguments. Surprisingly, there are no accepted NLP-standards which specify what the "right" span of an argument should be.</p><p>Semantic representations typically take an in- clusive (or maximal) approach: PropBank anno- tation ( <ref type="bibr" target="#b7">Palmer et al., 2005</ref>), for example, marks arguments as full constituency subtrees. From an application perspective, this maximal approach ensures that all arguments are indeed embedded within the annotated span, yet it is often not trivial how to accurately recover them.</p><p>In contrast to this maximal-span approach, Open-IE systems ( <ref type="bibr" target="#b2">Etzioni et al., 2008;</ref><ref type="bibr" target="#b3">Fader et al., 2011</ref>) put emphasis on extracting readable stand- alone propositions, typically producing shorter ar- guments (see examples in Section 2.1). Several recent works have exploited this property, using Open-IE extractions as an intermediate represen- tation within a larger framework. <ref type="bibr" target="#b0">Angeli et al. (2015)</ref> built an Open-IE system which focuses on shorter argument spans. They hypothesize that "shorter arguments <ref type="bibr">[are]</ref> more likely to be useful for downstream applications", and demonstrate this by using their system to ex- tract facts about predefined entities in a state-of- the-art Knowledge Base Population system.</p><p>Further, <ref type="bibr" target="#b8">Stanovsky et al. (2015)</ref> compared the performance of several off-the-shelf parsers in dif- ferent semantic tasks. Most relevant to this work is the comparison between Open-IE and SRL. Specifically, they suggest that SRL's longer argu- ments introduce noise which hurts performance for downstream tasks. This is sustained empiri- cally by showing that extractions from Open-IE4 1 significantly outperform ClearNLP's SRL <ref type="bibr" target="#b1">(Choi, 2012</ref>) in textual similarity, analogies, and reading comprehension tasks. <ref type="bibr">2</ref> While Open-IE extractors do provide a reduc- tion of argument span, they lack consistency and principled rigor -there is no clear definition for the desired argument span, which is defined de- facto by the different implementations. This lack of a common system-independent definition, let alone an annotation methodology, hinders the cre- ation of gold standard argument-span annotation.</p><p>In this work we propose a concrete argument span reduction criterion and an accompanying annotation procedure, based on the recent QA- SRL paradigm <ref type="bibr" target="#b4">(He et al., 2015)</ref>. We show that this criterion can be consistently annotated with high agreement, and that it is intuitive enough to be obtained through crowd-sourcing.</p><p>As future work, we intend to apply the reduction criterion to other types of predicates (e.g., nomi-nal and adjectival predication). Subsequently, we would like to create a comprehensive annotated resource, as a benchmark for the detection of re- duced argument spans.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Argument Span</head><p>As discussed in the Introduction, PropBank takes an inclusive approach to annotating arguments, by marking them as full constituency subtrees. For example, given the sentence "Obama, the newly elected president, flew to Russia", PropBank will mark "Obama, the newly elected president" as ARG0 of the predicate flew.</p><p>However, in certain applications, such as ques- tion answering or abstractive summarization, a re- duced argument is preferred (i.e., "Obama"). No- tably, different implementations of Open-IE pro- vide an applicable generic way to reduce argument span. Since there are no common guidelines for this task, each Open-IE extractor produces differ- ent argument spans. We cover briefly some of the main differences in a few prominent Open-IE sys- tems.</p><p>ReVerb <ref type="bibr" target="#b3">(Fader et al., 2011</ref>) uses part-of-speech- based regular expressions to decide whether a word should be included within an argument span. For example, they move certain light verb com- pliments and prepositions from the argument to the predicate slot (e.g., "gave a talk at"). OLLIE ( <ref type="bibr" target="#b6">Mausam et al., 2012</ref>) learns lexical-syntactic pat- terns and splits extractions across certain prepo- sitions. For example, given "I flew from Paris to Berlin", OLLIE yields (I; flew; from Paris) and (I; flew; to Berlin). More recently, ( <ref type="bibr" target="#b0">Angeli et al., 2015)</ref> used natural logic to remove non-integral parts of arguments (e.g., removing the underlined non-restrictive prepositional phrase in "Heinz Fis- cher of Austria").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">QA-SRL</head><p>SRL is typically perceived as answering argu- ment role questions, such as who, what, to whom, when, or where, regarding a target predicate. For instance, PropBank's ARG0 for the predicate say answers the question "who said something?".</p><p>QA-SRL ( <ref type="bibr" target="#b4">He et al., 2015)</ref> follows this per- spective, and suggests that answering explicit role questions is an intuitive means to solicit predicate- argument structures from non-expert annotators. Annotators are presented with a sentence in which a target predicate 3 was marked, and are requested to annotate argument role questions (from a re- stricted grammar) and corresponding answers.</p><p>For example, given the previous sentence and the target predicate flew, an annotator can intu- itively provide the following QA pairs: (1) Who flew somewhere? Obama, and (2) Where did someone fly? Russia.</p><p>The annotation guidelines further solicit multi- ple shorter answers, each typically embedded in the span of a maximal PropBank-style argument, while providing a different answer to the (same) argument role question.</p><p>In Section 4 we make use of QA-SRL's frame- work in order to produce annotations by our re- duction argument criterion, which is defined in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Argument Reduction</head><p>In this section, we propose annotation criteria and process for obtaining minimal argument spans. Given an original, non-reduced argument, we aim to reduce it to a set of (one or more) smaller argu- ments, which jointly specify the same answer to the argument's role question.</p><p>Formally, given a non-reduced argument a = {w 1 , ..., w n }, along with its role question Q(a) with respect to predicate p in sentence s, we seek to find a set of minimally-scoped arguments, M (a), such that:</p><p>(1) Each m ∈ M (a) is a proper subset of a.</p><p>(2) Each m ∈ M (a) provides a different, inde- pendently interpreted answer to Q(a).</p><p>(3) M (a) is equivalent to a, in the sense that when taken jointly, M (a) specifies the same answers as a does for Q(a).</p><p>(4) Each m ∈ M (a) is minimal, meaning it can- not be further reduced without violating the equivalence criterion (3).</p><p>Note that this definition relies on human judg- ments, which are used to decide whether two ar- guments provide the same or different answers.</p><p>Generally speaking, a non-minimal argument a can be reduced in one of two ways:</p><p>(a) Removal of tokens from a, forming a smaller argument.</p><p>(b) Splitting a, yielding multiple arguments.</p><p>In our context, we would like to apply these two operations as long as they maintain the equiv- alence criterion (3). We empirically observe that the first case (removal) corresponds to the omis- sion of non-restrictive modifiers, that is, modifiers for which the content of the modifier presents a separate, parenthetical unit of information about the NP <ref type="figure">(Huddleston et al., 2002</ref>). For example, re- visiting the sentence: "Obama, the newly elected president, flew to Russia.", the non-reduced argu- ment "Obama, the newly elected president" can be re- duced to the minimal argument "Obama", as both specify the same answer to the role question "who flew to Russia?".</p><p>In contrast, a restrictive modifier is an integral part of the meaning of the containing NP, and hence should not be removed, as in "She wore the necklace that her mother gave her".</p><p>The second reduction operation (splitting) cor- responds to decoupling distributive coordinations, that is, cases in which a predicate applies sepa- rately to all of the elements in the coordination. For example, in: "Obama and Clinton were born in America.", the non-reduced PropBank-style ar- gument "Obama and Clinton" can be reduced to two arguments {"Obama", "Clinton"}. Each of these ar- guments independently answers the role question "Who was born in America?", while jointly they correspond to the longer, non-reduced argument.</p><p>Note that splitting a shorter distributive argu- ment does not necessarily produce disjoint argu- ments. For example, consider: "The tall boys and girls were born in America.", in which "The tall boys and girls" would reduce to two overlapping argu- ments: {"The tall boys", "The tall girls"}.</p><p>In contrast, non-distributive conjuncts cannot be split. These are cases in which the predicate ap- plies to the conjuncts taken together, while apply- ing it separately to each element changes the inter- pretation of the clause. Consider for example the reciprocal structure of: "Obama and Putin met in Moscow", in which we cannot split the argument "Obama and Putin" since the predicate met implies that Obama and Putin met with each other, which will be lost if we split the argument to two inde- pendent answers.</p><p>Based on these two operations, a set of mini- mal arguments, M (a), can be obtained from a in a top-down manner: first apply removal, if possi- ble; then splitting, if possible. <ref type="bibr">4</ref> Next, apply recur- sively to each of the smaller arguments, stopping when none of the two reduction operations can be applied. This annotation process might yield different sets of minimal arguments by different annotators, depending on their decisions regarding the reduc- tion steps. As we show empirically in the next sec- tion, high agreement levels can be obtained, sup- porting the validity of our proposed criterion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Annotation Experiment</head><p>In this section we describe the compilation and analysis of a small-scale expert annotation corpus. Creating such corpus serves 3 goals: (1) It allows us to test the applicability of the argument reduc- ing procedure, (2) By comparing it with Propbank we can examine how often, and in which cases, we reduce arguments (Section 4.1), and (3) We can as- sess the plausibility of crowd-sourcing argument span annotation (Sections 4.2 and 4.3).</p><p>In order to achieve these goals, we sample 100 predicates of the Propbank corpus, which covered 260 arguments. To allow comparisons, we sample predicates which were annotated by QA-SRL and whose arguments were aligned by <ref type="bibr" target="#b4">(He et al., 2015</ref>) with a matching Propbank argument. <ref type="bibr">5</ref> Two expert annotators used the QA-SRL's inter- face to re-answer the original QA-SRL annotated questions with minimally-scoped arguments, ac- cording to the procedure described in Section 3. Prior to annotating the expert dataset, the annota- tors discussed the process and resolved conflicts on a separate development set of 20 predicates.</p><p>Annotator agreement From an argument per- spective, the annotators fully agreed on the span of 94.6% of the arguments.</p><p>Looking into the word token level, we found that for a given PropBank argument a = (w 1 , ..., w n ), the respective reduced arguments al- ways constitute a subset of a. This allows us to look at the annotation process as a list of n map- ping decisions -for each w i , an annotator decides whether he (1) Maps it to one or more of the argu-ments of M (a), or (2) Deletes it. The complete annotation required each annotator to make 985 such mappings decisions. Word level agreement between the annotators was calculated as the per- cent of the decisions on which they agreed, and found to be 97.1%.</p><p>Overall, the annotators achieved a high level of agreement, suggesting that the reduction criterion can be consistently applied by trained annotators. An analysis of the few disagreements revealed that the deviations between the annotators stem from semantic ambiguities, where two legitimate read- ings of the sentence led to different span annota- tions. <ref type="bibr">6</ref> Finally, we compose the expert annotation dataset from 247 arguments on which both anno- tators fully agreed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Comparison with Propbank</head><p>Comparing our annotation with PropBank showed that we reduced roughly 24% of the arguments: 19% of the arguments were reduced by omitting non-restrictive modifications and 5% of the argu- ments were split across distributive co-ordinations (see discussion on both types of reductions in Sec- tion 3).</p><p>The average reduced argument shrunk by roughly 58%. In general, these numbers sug- gest that our annotation scheme targets commonly recurring phenomena, and significantly deviates from PropBank's annotation of arguments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Crowdsourcing</head><p>We created an Amazon Mechanical Turk 7 project to investigate the possible scalability of our anno- tation using non-trained annotators.</p><p>Similarly to the setting used by the expert an- notators, turkers were presented with a sentence, followed by a list of questions regarding a target predicate. The sentences, predicates and questions were taken from the expert corpus, which aligns between QA-SRL and Propbank. <ref type="bibr">8</ref> The guidelines for annotators refined those of <ref type="bibr" target="#b4">He et al. (2015)</ref>, soliciting answers which follow</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Annotation</head><p>Argument Word</p><p>Expert -IAA 94.6% 97.1%</p><p>QA-SRL -Expert 80% 88.5% Our Crowdsourcing -Expert 89.1%</p><p>93.5% <ref type="table">Table 1</ref>: Agreement levels between the different annotations: (1) IAA -Inter-Annotator agreement between the expert annotators (2) Agreement of QA-SRL corpus with our expert annotation and (3) Our Crowdsourcing -agreement of the Ama- zon Mechanical Turk annotations with our expert annotation. See Section 4.</p><p>our formal criterion. In cases of multiple answers referring to the same entity, annotators are asked to provide the most specific answer, otherwise (if the answers refer to different entities), the annotators are asked to list all of the answers. Furthermore, the annotators are requested to provide the shortest answer they can, while preserving its correctness. We chose annotations which were agreed upon by at least two annotators. In cases where the three annotators gave different answers (26% of the time), we used a fourth annotator to arbitrate, and calculated agreement using the same metrics dis- cussed above. Cases where annotators disagreed were mostly semantically ambigouos. For exam- ple, given the sentence "Our pilot simply laughed , fired up the burner and with another blast of flame lifted us , oh , a good 12 -inches above the water level ." and the question "how much did someone lift someone?", one annotator replied 12 -inches while another replied a good 12 -inches.</p><p>We found that the crowdsourcing annotations to be of high quality, reaching 89.1% argument agreement and 93.5% word agreement with our expert annotation. These results suggest that the annotation of argument span is efficiently and accurately attainable using crowd-sourcing tech- niques, with only subtle refinements over the orig- inal QA-SRL guidelines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Comparison with QA-SRL</head><p>Finally, we want to compare our crowdsourcing annotation versus that of QA-SRL, with respect to argument span. Using the previously mentioned agreement metric, we find that QA-SRL agrees with our expert dataset on 80% of the arguments and 88.5% of the word-level decisions. Although it is outperformed by our crowdsourcing annota-tion project, QA-SRL still manages to capture sig- nificant amounts of the minimally-reduced argu- ments. This is interesting, as the QA-SRL guide- lines did not address this issue specifically, but in- stead solicited annotators to provide "as many an- swers as possible". This suggests that the question answering format intuitively prompts human an- notators to reduce the span of their answers.</p><p>To conclude this section, the entire comparison measurements are summarized in <ref type="table">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>In this work we proposed a concrete criterion for specifying minimally-scoped arguments. While this issue was applicably addressed by previous work, it was not consistently defined or anno- tated. Following this definition, we created an expert annotation dataset over texts from Prop- Bank, using the QA-SRL paradigm. This annota- tion achieved high levels of inter-annotator agree- ment, and was shown to be intuitive enough so that it can be scaled to crowdsourcing annotation. As future work, we plan to extend this annotation project to larger volumes of text, and to additional types of (non-verbal) predications, which will al- low to develop learning-based methods that iden- tify minimally-reduced argument span.</p></div>
			<note place="foot" n="1"> http://knowitall.github.io/openie 2 Open IE-4 is based on ClearNLPs SRL, allowing for a direct comparison.</note>

			<note place="foot" n="3"> Currently these consist of automatically annotated verbs.</note>

			<note place="foot" n="4"> This order is arbitrary, chosen solely to provide a deterministic process. Alternating the steps would yield an identical set. 5 An annotated answer is judged to match the PropBank argument if either (1) the gold argument head is within the annotated answer span, or (2) the gold argument head is a preposition and at least one of its children is within the answer span.</note>

			<note place="foot" n="6"> For example, in &quot;The American Stock Exchange said a seat was sold for $ 160,000 , down $ 5,000 from the previous sale last Friday .&quot;, one annotator did not reduce ARG1, while the second annotator chose to restrict the span of the argument to &quot;a seat was sold for $ 160,00&quot;, interpreting the remaining part of the clause as an addition by the author. 7 https://www.mturk.com 8 To be clear, the annotators saw only the raw text and questions from QA-SRL and were not exposed to the PropBank annotations.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank Luheng He and Luke Zettlemoyer for the fruitful discussions, and the anonymous reviewers for their helpful comments.</p><p>This work was supported in part by grants from the MAGNET program of the Israeli Office of the Chief Scientist (OCS), the Israel Science Founda-tion grant 880/12, and the German Research Foun-dation through the German-Israeli Project Cooper-ation (DIP, grant DA 1600/1-1).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Leveraging linguistic structure for open domain information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melvin</forename><forename type="middle">Johnson</forename><surname>Premkumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics (ACL</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics (ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Optimization of Natural Language Processing Components for Robustness and Scalability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jinho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Choi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<pubPlace>Boulder, CO, USA. AAI3549172</pubPlace>
		</imprint>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Open information extraction from the Web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michele</forename><surname>Banko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="68" to="74" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Identifying relations for open information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1535" to="1545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Question-answer driven semantic role labeling: Using natural language to annotate natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the Conference on Empirical Methods in Natural Language Processing</title>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">The cambridge grammar of english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodney</forename><surname>Huddleston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">K</forename><surname>Pullum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Language. Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Open language learning for information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mausam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Schmitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Bart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012-07" />
			<biblScope unit="page" from="523" to="534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The proposition bank: An annotated corpus of semantic roles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Kingsbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="71" to="106" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Open IE as an intermediate structure for semantic tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Stanovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mausam</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
