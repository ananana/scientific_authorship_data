<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:42+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MMFEAT: A Toolkit for Extracting Multi-Modal Features</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
							<email>douwe.kiela@cl.cam.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">Computer Laboratory University of Cambridge</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">MMFEAT: A Toolkit for Extracting Multi-Modal Features</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics-System Demonstrations</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics-System Demonstrations <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="55" to="60"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Research at the intersection of language and other modalities, most notably vision, is becoming increasingly important in natural language processing. We introduce a toolkit that can be used to obtain feature representations for visual and auditory information. MMFEAT is an easy-to-use Python toolkit, which has been developed with the purpose of making non-linguistic modalities more accessible to natural language processing researchers.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Distributional models are built on the assumption that the meaning of a word is represented as a distribution over others <ref type="bibr" target="#b40">(Turney and Pantel, 2010;</ref><ref type="bibr" target="#b9">Clark, 2015)</ref>, which implies that they suffer from the grounding problem <ref type="bibr" target="#b13">(Harnad, 1990)</ref>. That is, they do not account for the fact that human se- mantic knowledge is grounded in the perceptual system <ref type="bibr" target="#b28">(Louwerse, 2008)</ref>. There has been a lot of interest within the Natural Language Processing community for making use of extra-linguistic per- ceptual information, much of it in a subfield called multi-modal semantics. Such multi-modal models outperform language-only models on a range of tasks, including modelling semantic similarity and relatedness <ref type="bibr" target="#b7">(Bruni et al., 2014;</ref><ref type="bibr" target="#b35">Silberer and Lapata, 2014</ref>), improving lexical entailment ( <ref type="bibr" target="#b20">Kiela et al., 2015b</ref>), predicting compositionality (Roller and Schulte im <ref type="bibr" target="#b33">Walde, 2013)</ref>, bilingual lexicon induction (Bergsma and Van Durme, 2011) and metaphor identification ( <ref type="bibr" target="#b34">Shutova et al., 2016)</ref>. Al- though most of this work has relied on vision for the perceptual input, recent approaches have also used auditory ( <ref type="bibr" target="#b27">Lopopolo and van Miltenburg, 2015;</ref><ref type="bibr" target="#b17">Kiela and Clark, 2015)</ref> and even olfactory ( <ref type="bibr" target="#b19">Kiela et al., 2015a</ref>) information.</p><p>In this demonstration paper, we describe MM- FEAT, a Python toolkit that makes it easy to ob- tain images and sound files and extract visual or auditory features from them. The toolkit in- cludes two standalone command-line tools that do not require any knowledge of the Python pro- gramming language: one that can be used for automatically obtaining files from a variety of sources, including Google, Bing and FreeSound (miner.py); and one that can be used for extract- ing different types of features from directories of data files (extract.py). In addition, the package comes with code for manipulating multi-modal spaces and several demos to illustrate the wide range of applications. The toolkit is open source under the BSD license and available at https: //github.com/douwekiela/mmfeat.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Bag of multi-modal words</head><p>Although it is possible to ground distributional se- mantics in perception using e.g. co-occurrence patterns of image tags ( <ref type="bibr" target="#b1">Baroni and Lenci, 2008)</ref> or surrogates of human semantic knowledge such as feature norms <ref type="bibr" target="#b0">(Andrews et al., 2009)</ref>, the de facto method for grounding representations in per- ception has relied on processing raw image data <ref type="bibr" target="#b2">(Baroni, 2016)</ref>. The traditional method for ob- taining visual representations <ref type="bibr" target="#b11">(Feng and Lapata, 2010;</ref><ref type="bibr" target="#b26">Leong and Mihalcea, 2011;</ref><ref type="bibr" target="#b4">Bruni et al., 2011</ref>) has been to apply the bag-of-visual-words (BoVW) approach <ref type="bibr" target="#b37">(Sivic and Zisserman, 2003)</ref>. The method can be described as follows:</p><p>1. obtain relevant images for a word or set of words; 2. for each image, get local feature descriptors; 3. cluster feature descriptors with k-means to find the centroids, a.k.a. the "visual words";</p><p>4. quantize the local descriptors by comparing them to the cluster centroids; and 5. combine relevant image representations into an overall visual representation for a word.</p><p>The local feature descriptors in step (2) tend to be variants of the dense scale-invariant feature transform (SIFT) algorithm <ref type="bibr" target="#b29">(Lowe, 2004)</ref>, where an image is laid out as a dense grid and feature descriptors are computed for each keypoint.</p><p>A similar method has recently been applied to the auditory modality ( <ref type="bibr" target="#b27">Lopopolo and van Miltenburg, 2015;</ref><ref type="bibr" target="#b17">Kiela and Clark, 2015)</ref>, using sound files from FreeSound ( <ref type="bibr" target="#b12">Font et al., 2013)</ref>. Bag-of-audio-words (BoAW) uses mel-frequency cepstral coefficients (MFCCs) <ref type="bibr" target="#b31">(O'Shaughnessy, 1987)</ref> for the local descriptors, although other lo- cal frame representations may also be used. In MFCC, frequency bands are spaced along the mel scale ( <ref type="bibr" target="#b38">Stevens et al., 1937)</ref>, which has the advan- tage that it approximates human auditory percep- tion more closely than e.g. linearly-spaced fre- quency bands.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Convolutional neural networks</head><p>In computer vision, the BoVW method has been superseded by deep convolutional neural networks (CNNs) ( <ref type="bibr" target="#b24">LeCun et al., 1998;</ref><ref type="bibr" target="#b22">Krizhevsky et al., 2012)</ref>. <ref type="bibr" target="#b16">Kiela and Bottou (2014)</ref> showed that such networks learn high-quality representations that can successfully be transfered to natural language processing tasks. Their method works as follows:</p><p>1. obtain relevant images for a word or set of words; 2. for each image, do a forward pass through a CNN trained on an image recognition task and extract the pre-softmax layer; 3. combine relevant image representations into an overall visual representation for a word.</p><p>They used the pre-softmax layer (referred to as FC7) from a CNN trained by <ref type="bibr" target="#b30">Oquab et al. (2014)</ref>, which was an adaptation of the well-known CNN by <ref type="bibr">Krizhevsky</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Related work</head><p>The process for obtaining perceptual representa- tions thus involves three distinct steps: obtaining files relevant to words or phrases, obtaining repre- sentations for the files, and aggregating these into visual or auditory representations. To our knowl- edge, this is the first toolkit that spans this entire process. There are libraries that cover some of these steps. Notably, VSEM ( <ref type="bibr" target="#b6">Bruni et al., 2013</ref>) is a Matlab library for visual semantics represen- tation that implements BoVW and useful func- tionality for manipulating visual representations. DISSECT ( <ref type="bibr" target="#b10">Dinu et al., 2013</ref>) is a toolkit for dis- tributional compositional semantics that makes it easy to work with (textual) distributional spaces. <ref type="bibr" target="#b27">Lopopolo and van Miltenburg (2015)</ref> have also re- leased their code for obtaning BoAW representa- tions 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">MMFeat Overview</head><p>The MMFeat toolkit is written in Python. There are two command-line tools (described below) for obtaining files and extracting representations that do not require any knowledge of Python. The Python interface maintains a modular structure and contains the following modules:</p><p>• mmfeat.miner</p><formula xml:id="formula_0">• mmfeat.bow • mmfeat.cnn • mmfeat.space</formula><p>Source files (images or sounds) can be obtained with the miner module, although this is not a re- quirement: it is straightforward to build an in- dex of a data directory that matches words or phrases with relevant files. The miner module au- tomatically generates this index, a Python dictio- nary mapping labels to lists of filenames, which is stored as a Python pickle file index.pkl in the data directory. The index is used by the bow and cnn modules, which together form the core of the package for obtaining perceptual representations. The space package allows for the manipulation and combination of multi-modal spaces.</p><p>miner Three data sources are currently sup- ported: Google Images 2 (GoogleMiner), Bing Im- ages 3 (BingMiner) and FreeSound 4 (FreeSound- Miner). All three of them require API keys, which can be obtained online and are stored in the miner.yaml settings file in the root folder.</p><p>bow The bag-of-words methods are contained in this module. BoVW and BoAW are accessible through the mmfeat.bow.vw and mmfeat.bow.aw modules respectively, through the BoVW and BoAW classes. These classes obtain feature de- scriptors and perform clustering and quantization through a standard set of methods. BoVW uses dense SIFT for its local feature descriptors; BoAW uses MFCC. The modules also contain an inter- face for loading local feature descriptors from Matlab, allowing for simple integraton with e.g. VLFeat <ref type="bibr">5</ref> . The centroids obtained by the clustering (sometimes also called the "codebook") are stored in the data directory for re-use at a later stage. space An additional module is provided for making it easy to manipulate perceptual represen- tations. The module contains methods for aggre- gating image or sound file representations into vi- sual or auditory representations; combining per- ceptual representations with textual representa- tions into multi-modal ones; computing nearest neighbors and similarity scores; and calculating Spearman ρ s correlation scores relative to human similarity and relatedness judgments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dependencies</head><p>MMFeat has the following dependencies: scipy, scikit-learn and numpy. These are standard Python libraries that are easy to install using your favorite package manager. The BoAW module addition- ally requires librosa 6 to obtain MFCC descriptors. The CNN module requires Caffe <ref type="bibr">7</ref> . It is recom- mended to make use of Caffe's GPU support, if available, for increased processing speeds. More detailed installation instructions are provided in the readme file online and in the documentation of the respective projects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Tools</head><p>MMFeat comes with two easy-to-use command- line tools for those unfamiliar with the Python pro- gramming language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Mining: miner.py</head><p>The miner.py tool takes three arguments: the data source (bing, google or freesound), a query file that contains a line-by-line list of queries, and a data directory to store the mined image or sound files in. Its usage is as follows:</p><p>miner.py {bing,google,freesound} \ query_file data_dir <ref type="bibr">[-n int]</ref> The -n option can be used to specify the number of images to download per query. The following ex- amples show how to use the tool to get 10 images from Bing and 100 sound files from FreeSound for the queries "dog" and "cat":</p><p>$ echo -e "dog\ncat" &gt; queries.txt $ python miner.py -n 10 bing \ queries.txt ./img_data_dir $ python miner.py -n 100 freesound \ queries.txt ./sound_data_dir</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Feature extraction: extract.py</head><p>The extract.py tool takes three arguments: the type of model to apply (boaw, bovw or cnn), the data directory where relevant files and the index are stored, and the output file where the representa- tions are written to. Its usage is as follows:</p><formula xml:id="formula_1">extract.py [-k int] [-c string] \ [-o {pickle,json,csv}] [-s float] \ [-m {vgg,alexnet,googlenet}] \ {boaw,bovw,cnn} data_dir out_file</formula><p>The -k option sets the number of clusters to use in the bag of words methods (the k in k-means). The -c option allows for pointing to an existing code- book, if available. The -s option allows for sub- sampling the number of files to use for the cluster- ing process (which can require significant amounts of memory) and is in the range 0-1. The tool can output representation in Python pickle, JSON and CSV formats. The following examples show how the three models can easily be applied: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Getting Started</head><p>The command-line tools mirror the Python in- terface, which allows for more fine-grained con- trol over the process. In what follows, we walk through an example illustrating the process. The code should be self-explanatory.</p><p>Mining The first step is to mine some images from Google Images: These short examples are meant to show how one can straightforwardly obtain perceptual represen- tations that can be applied in a wide variety of ex- periments.</p><formula xml:id="formula_2">datadir</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Demos</head><p>To illustrate the range of possible applications, the toolkit comes with a set of demonstrations of its usage. The following demos are available:</p><p>1-Similarity and relatedness The demo down- loads images for the concepts in the well-known MEN ( <ref type="bibr" target="#b5">Bruni et al., 2012</ref>) and SimLex-999 ( ) datasets, obtains CNN-derived vi- sual representations and calculates the Spearman ρ s correlations for textual, visual and multi-modal representations.</p><p>2-ESP game To illustrate that it is not necessary to mine images or sound files and that an exist- ing data directory can be used, this demo builds an index for the ESP Game dataset <ref type="bibr" target="#b41">(Von Ahn and Dabbish, 2004</ref>) and obtains and stores CNN rep- resentations for future use in other applications.</p><p>3-Matlab interface To show that local fea- ture descriptors from Matlab can be used, this demo contains Matlab code (run dsift.m) that uses VLFeat to obtain descriptors, which are then used in the BoVW model to obtain visual representa- tions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4-Instrument clustering</head><p>The demo downloads sound files from FreeSound for a set of instru- ments and applies BoAW. The mean auditory rep- resentations are clustered and the cluster assign- ments are reported to the screen, showing similar instruments in similar clusters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5-Image dispersion This demo obtains images</head><p>for the concepts of elephant and happiness and ap- plies BoVW. It then shows that the former has a lower image dispersion score and is consequently more concrete than the latter, as described in .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>The field of natural language processing has broadened in scope to address increasingly chal- lenging tasks. While the core NLP tasks will re- main predominantly focused on linguistic input, it is important to address the fact that humans ac- quire and apply language in perceptually rich en- vironments. Moving towards human-level AI will require the integration and modeling of multiple modalities beyond language. Advances in multi-modal semantics show how textual information can fruitfully be combined with other modalities, opening up many avenues for further exploration. Some NLP researchers may consider non-textual modalities challenging or outside of their area of expertise. We hope that this toolkit enables them in carrying out research that uses extra-linguistic input.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>cnn</head><label></label><figDesc>The CNN module uses Python bindings to the Caffe deep learning framework (Jia et al., 2014). It supports the pre-trained reference adaptation of AlexNet (Krizhevsky et al., 2012), GoogLeNet (Szegedy et al., 2015) and VGGNet (Simonyan and Zisserman, 2015). The interface is identical to the bow interface.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>python extract.</head><label></label><figDesc>py -k 100 -s 0.1 bovw \ ./img_data_dir ./output_vectors.pkl python extract.py -gpu -o json cnn \ ./img_data_dir ./output_vectors.json python extract.py -k 300 -s 0.5 -o csv \ boaw ./sound_data_dir ./out_vecs.csv</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>= '/path/to/data' words = ['dog', 'cat'] n_images = 10 from mmfeat.miner import * miner = GoogleMiner(datadir, \ '/path/to/miner.yaml') miner.getResults(words, n_images) miner.save() Applying models We then apply both the BoVW and CNN models, in a manner familiar to scikit-learn users, by calling the fit() method: from mmfeat.bow import * from mmfeat.cnn import * b = BoVW(k=100, subsample=0.1) c = CNN(modelType='alexnet', gpu=True) b.load(data_dir) b.fit() c.load(data_dir) c.fit() Building the space We subsequently construct the aggregated space of visual representations and print these to the screen: from mmfeat.space import * for lkp in [b.toLookup(), c.toLookup()]: vs = AggSpace(lkp, 'mean') print vs.space</figDesc></figure>

			<note place="foot" n="1"> https://github.com/evanmiltenburg/soundmodels-iwcs 2 https://images.google.com 3 https://www.bing.com/images 4 https://www.freesound.org</note>

			<note place="foot" n="5"> http://www.vlfeat.org 6 https://github.com/bmcfee/librosa 7 http://caffe.berkeleyvision.org</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The author was supported by EPSRC grant EP/I037512/1 and would like to thank Anita Verö, Stephen Clark and the reviewers for helpful sug-gestions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Integrating experiential and distributional data to learn semantic representations. Psychological review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Andrews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriella</forename><surname>Vigliocco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Vinson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="page">463</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Concepts and properties in word spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Lenci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Italian Journal of Linguistics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="55" to="88" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Grounding distributional semantics in the visual world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language and Linguistics Compass</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="13" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning bilingual lexicons using the visual similarity of labeled web images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shane</forename><surname>Bergsma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1764" to="1769" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Distributional semantics from text and images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elia</forename><surname>Bruni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Giang Binh Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the GEMS 2011 workshop on geometrical models of natural language semantics</title>
		<meeting>the GEMS 2011 workshop on geometrical models of natural language semantics</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="22" to="32" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Distributional semantics in technicolor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elia</forename><surname>Bruni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gemma</forename><surname>Boleda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Namkhanh</forename><surname>Tran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="136" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Vsem: An open library for visual semantics representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elia</forename><surname>Bruni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulisse</forename><surname>Bordignon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Liska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jasper</forename><surname>Uijlings</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irina</forename><surname>Sergienya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="187" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Multimodal distributional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elia</forename><surname>Bruni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nam-Khanh</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artifical Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="1" to="47" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Vision and Feature Norms: Improving automatic feature norm learning through cross-modal maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luana</forename><surname>Bulat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT 2016</title>
		<meeting>NAACL-HLT 2016<address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Vector Space Models of Lexical Meaning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Contemporary Semantics, chapter 16</title>
		<editor>Shalom Lappin and Chris Fox</editor>
		<meeting><address><addrLine>Oxford</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley-Blackwell</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">DISSECT-DIStributional SEmantics Composition Toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgiana</forename><surname>Dinu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nghia The</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="31" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Visual information in semantic representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yansong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Freesound technical demo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederic</forename><surname>Font</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Roma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Serra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st acm international conference on multimedia</title>
		<meeting>the 21st acm international conference on multimedia</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="411" to="412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The symbol grounding problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stevan</forename><surname>Harnad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physica D</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="335" to="346" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">SimLex-999: Evaluating semantic models with (genuine) similarity estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
		<idno>abs/1408.3456</idno>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Caffe: Convolutional architecture for fast feature embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Karayev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Multimedia</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="675" to="678" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning image embeddings using convolutional neural networks for improved multi-modal semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="36" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multi-and cross-modal semantics beyond vision: Grounding in auditory perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2461" to="2470" />
		</imprint>
	</monogr>
	<note>Portugal, September. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Improving multi-modal representations using image dispersion: Why less is sometimes more</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="835" to="841" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Grounding semantics in olfactory perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luana</forename><surname>Bulat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-07" />
			<biblScope unit="page" from="231" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Exploiting image generality for lexical entailment detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Rimell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vuli´cvuli´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-07" />
			<biblScope unit="page" from="119" to="124" />
		</imprint>
	</monogr>
	<note>Short Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Visual bilingual lexicon induction with transferred convnet features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vuli´cvuli´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-09" />
			<biblScope unit="page" from="148" to="158" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">ImageNet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1106" to="1114" />
		</imprint>
	</monogr>
	<note>Hinton</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Unveiling the dreams of word embeddings: Towards languagedriven image generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angeliki</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raffaella</forename><surname>Dat Tien Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Bernardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baroni</surname></persName>
		</author>
		<idno>abs/1506.03500</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<biblScope unit="page" from="436" to="444" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Going beyond text: A hybrid image-text approach for measuring word relatedness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Chee Wee Leong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mihalcea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCNLP</title>
		<meeting>IJCNLP</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1403" to="1407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Soundbased distributional models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lopopolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Van Miltenburg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Conference on Computational Semantics</title>
		<meeting>the 11th International Conference on Computational Semantics</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>IWCS 2015</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Symbol interdependency in symbolic and embodied cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><forename type="middle">M</forename><surname>Louwerse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Topics in Cognitive Science</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="617" to="645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning and transferring mid-level image representations using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxime</forename><surname>Oquab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Sivic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1717" to="1724" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Speech communication: human and machine. Addison-Wesley series in electrical engineering: digital signal processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>O&amp;apos;shaughnessy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
			<publisher>Universities Press</publisher>
			<pubPlace>India) Pvt</pubPlace>
		</imprint>
	</monogr>
	<note>Limited</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">CNN features off-theshelf: an astounding baseline for recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Razavian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hossein</forename><surname>Azizpour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josephine</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Carlsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="806" to="813" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A multimodal LDA model integrating textual, cognitive and visual modalities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabine</forename><surname>Schulte Im Walde</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1146" to="1157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Black holes and white rabbits: Metaphor identification with visual features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekaterina</forename><surname>Shutova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Maillard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HTL 2016</title>
		<meeting>NAACL-HTL 2016<address><addrLine>San Diego</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning grounded meaning representations with autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carina</forename><surname>Silberer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="721" to="732" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Video google: A text retrieval approach to object matching in videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="1470" to="1477" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A scale for the measurement of the psychological magnitude pitch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanley</forename><forename type="middle">Smith</forename><surname>Stevens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Volkmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edwin</forename><forename type="middle">B</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="185" to="190" />
			<date type="published" when="1937" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">From Frequency to Meaning: vector space models of semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Turney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pantel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artifical Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="141" to="188" />
			<date type="published" when="2010-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Labeling images with a computer game</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luis</forename><surname>Von Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Dabbish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI conference on human factors in computing systems</title>
		<meeting>the SIGCHI conference on human factors in computing systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="319" to="326" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
