<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:23+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Grapheme-to-Phoneme Models for (Almost) Any Language</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aliya</forename><surname>Deri</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Information Sciences Institute Department of Computer Science</orgName>
								<orgName type="institution">University of Southern California</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
							<email>{aderi, knight}@isi.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Information Sciences Institute Department of Computer Science</orgName>
								<orgName type="institution">University of Southern California</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Grapheme-to-Phoneme Models for (Almost) Any Language</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="399" to="408"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Grapheme-to-phoneme (g2p) models are rarely available in low-resource languages, as the creation of training and evaluation data is expensive and time-consuming. We use Wiktionary to obtain more than 650k word-pronunciation pairs in more than 500 languages. We then develop phoneme and language distance metrics based on phono-logical and linguistic knowledge; applying those, we adapt g2p models for high-resource languages to create models for related low-resource languages. We provide results for models for 229 adapted languages .</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Grapheme-to-phoneme (g2p) models convert words into pronunciations, and are ubiquitous in speech-and text-processing systems. Due to the diversity of scripts, phoneme inventories, phono- tactic constraints, and spelling conventions among the world's languages, they are typically language- specific. Thus, while most statistical g2p learning methods are language-agnostic, they are trained on language-specific data-namely, a pronunciation dictionary consisting of word-pronunciation pairs, as in <ref type="table" target="#tab_0">Table 1</ref>.</p><p>Building such a dictionary for a new language is both time-consuming and expensive, because it re- quires expertise in both the language and a notation system like the International Phonetic Alphabet, applied to thousands of word-pronunciation pairs. Unsurprisingly, resources have been allocated only to the most heavily-researched languages. Global- Phone, one of the most extensive multilingual text and speech databases, has pronunciation dictionar- ies in only 20 languages (   <ref type="bibr">1</ref> . <ref type="bibr">1</ref> We have been unable to obtain this dataset.  ɡ ɪ f tʰ ɡ ɪ f t ɣ ɪ f t class kʰ l ae s k l aː s k l ɑ s send s e̞ n d z ɛ n t s ɛ n t <ref type="table">Table 2</ref>: Example pronunciations of English words using English, German, and Dutch g2p models.</p><p>For most of the world's more than 7,100 lan- guages ( <ref type="bibr" target="#b6">Lewis et al., 2009)</ref>, no data exists and the many technologies enabled by g2p models are in- accessible.</p><p>Intuitively, however, pronouncing an unknown language should not necessarily require large amounts of language-specific knowledge or data. A native German or Dutch speaker, with no knowl- edge of English, can approximate the pronuncia- tions of an English word, albeit with slightly differ- ent phonemes. <ref type="table">Table 2</ref> demonstrates that German and Dutch g2p models can do the same.</p><p>Motivated by this, we create and evaluate g2p models for low-resource languages by adapting ex- isting g2p models for high-resource languages us- ing linguistic and phonological information. To fa- cilitate our experiments, we create several notable data resources, including a multilingual pronunci- ation dictionary with entries for more than 500 lan- guages.</p><p>The contributions of this work are:</p><p>• Using data scraped from Wiktionary, we clean and normalize pronunciation dictionar- ies for 531 languages. To our knowledge, this is the most comprehensive multilingual pro- nunciation dictionary available.</p><p>• We synthesize several named entities corpora to create a multilingual corpus covering 384 languages.</p><p>• We develop a language-independent distance metric between IPA phonemes. • We extend previous metrics for language- language distance with additional information and metrics.</p><p>• We create two sets of g2p models for "high resource" languages: 97 simple rule-based models extracted from Wikipedia's "IPA Help" pages, and 85 data-driven models built from Wiktionary data.</p><p>• We develop methods for adapting these g2p models to related languages, and describe re- sults for 229 adapted models.</p><p>• We release all data and models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Because of the severe lack of multilingual pro- nunciation dictionaries and g2p models, different methods of rapid resource generation have been proposed. <ref type="bibr" target="#b17">Schultz (2009)</ref> reduces the amount of exper- tise needed to build a pronunciation dictionary, by providing a native speaker with an intuitive rule- generation user interface. <ref type="bibr" target="#b13">Schlippe et al. (2010)</ref> crawl web resources like Wiktionary for word- pronunciation pairs. More recently, attempts have been made to automatically extract pronunciation dictionaries directly from audio data ( <ref type="bibr" target="#b18">Stahlberg et al., 2016)</ref>. However, the requirement of a na- tive speaker, web resources, or audio data specific to the language still blocks development, and the number of g2p resources remains very low. Our method avoids these issues by relying only on text data from high-resource languages.</p><p>Instead of generating language-specific re- sources, we are instead inspired by research on cross-lingual automatic speech recognition (ASR) by  and <ref type="bibr" target="#b22">Vu et al. (2014)</ref>, who exploit linguistic and phonetic relationships in low-resource scenarios. Although these works focus on ASR instead of g2p models and rely on audio data, they demonstrate that speech technol- ogy is portable across related languages. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>Given a low-resource language l without g2p rules or training data, we adapt resources (either an existing g2p model or a pronunciation dictio- nary) from a high-resource language h to create a g2p for l. We assume the existence of two modules: a phoneme-to-phoneme distance metric phon2phon, which allows us to map between the phonemes used by h to the phonemes used by l, and a closest language module lang2lang, which provides us with related language h.</p><p>Using these resources, we adapt resources from h to l in two different ways:</p><p>• Output mapping ( <ref type="figure">Figure 1a</ref>): We use g2p h to pronounce word l , then map the output to the phonemes used by l with phon2phon.</p><p>• Training data mapping <ref type="figure">(Figure 1b</ref>): We use phon2phon to map the pronunciations in h's pronunciation dictionary to the phonemes used by l, then train a g2p model using the adapted data. The next sections describe how we collect data, create phoneme-to-phoneme and language- to-language distance metrics, and build high- resource g2p models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Data</head><p>This section describes our data sources, which are summarized in <ref type="table">Table 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Phoible</head><p>Phoible ( <ref type="bibr" target="#b9">Moran et al., 2014</ref>) is an online reposi- tory of cross-lingual phonological data. We use  <ref type="table">Table 3</ref>: Summary of data resources obtained from Phoible, named entity resources, Wikipedia IPA Help tables, and Wiktionary. Note that, although our Wiktionary data technically covers over 500 languages, fewer than 100 include more than 250 entries (Wiktionary train).</p><p>two of its components: language phoneme inven- tories and phonetic features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Phoneme inventories</head><p>A phoneme inventory is the set of phonemes used to pronounce a language, represented in IPA. Phoible provides 2156 phoneme inventories for 1674 languages. (Some languages have multiple inventories from different linguistic studies.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Phoneme feature vectors</head><p>For each phoneme included in its phoneme in- ventories, Phoible provides information about 37 phonological features, such as whether the phoneme is nasal, consonantal, sonorant, or a tone. Each phoneme thus maps to a unique feature vec- tor, with features expressed as +, -, or 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Named Entity Resources</head><p>For our language-to-language distance metric, it is useful to have written text in many languages. The most easily accessible source of this data is multi- lingual named entity (NE) resources.</p><p>We synthesize 7 different NE corpora: Chinese- English names ( <ref type="bibr" target="#b4">Ji et al., 2009</ref> glish translation, named entity type, and script in- formation where possible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Wikipedia IPA Help tables</head><p>To explain different languages' phonetic notations, Wikipedia users have created "IPA Help" pages, 3 which provide tables of simple grapheme exam- ples of a language's phonemes. For example, on the English page, the phoneme z has the examples "zoo" and "has." We automatically scrape these tables for 97 languages to create simple grapheme- phoneme rules.</p><p>Using the phon2phon distance metric and map- ping technique described in Section 5, we clean each table by mapping its IPA phonemes to the lan- guage's Phoible phoneme inventory, if it exists. If it does not exist, we map the phonemes to valid Phoible phonemes and create a phoneme inventory for that language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Wiktionary pronunciation dictionaries</head><p>Ironically, to train data-driven g2p models for high-resource languages, and to evaluate our low-resource g2p models, we require pronunci- ation dictionaries for many languages. A com- mon and successful technique for obtaining this data ( <ref type="bibr" target="#b13">Schlippe et al., 2010;</ref><ref type="bibr" target="#b14">Schlippe et al., 2012a;</ref><ref type="bibr" target="#b23">Yao and Kondrak, 2015</ref>) is scraping Wik- tionary, an open-source multilingual dictionary maintained by Wikimedia. We extract unique word-pronunciation pairs from the English, Ger- man, Greek, Japanese, Korean, and Russian sites of Wiktionary. (Each Wiktionary site, while writ- ten in its respective language, contains word en- tries in multiple languages.) Since Wiktionary data is very noisy, we ap- ply length filtering as discussed by <ref type="bibr" target="#b15">Schlippe et al. (2012b)</ref>, as well as simple regular expression fil- ters for HTML. We also map Wiktionary pronun- ciations to valid Phoible phonemes and language phoneme inventories, if they exist, as discussed in Section 5. This yields 658k word-pronunciation pairs for 531 languages. However, this data is not uniformly distributed across languages-German, English, and French account for 51% of the data.</p><p>We extract test and training data as follows: For each language with at least 1 word-pron pair with a valid word (at least 3 letters and alphabetic), we extract a test set of a maximum of 200 valid words. From the remaining data, for every language with 50 or more entries, we create a training set with the available data.</p><p>Ultimately, this yields a training set with 629k word-pronunciation pairs in 85 languages, and a test set with 26k pairs in 501 languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Phonetic Distance Metric</head><p>Automatically comparing pronunciations across languages is especially difficult in text form. Al- though two versions of the "sh" sound, "ʃ" and "ɕ," sound very similar to most people and very dif- ferent from "m," to a machine all three characters seem equidistant.</p><p>Previous research <ref type="bibr" target="#b12">(Özbal and Strapparava, 2012;</ref><ref type="bibr" target="#b22">Vu et al., 2014</ref>) has addressed this issue by matching exact phonemes by character or manually selecting comparison fea- tures; however, we are interested in an automatic metric covering all possible IPA phoneme pairs. We handle this problem by using Phoible's phoneme feature vectors to create phon2phon, a distance metric between IPA phonemes. In this section we also describe how we use this met- ric to clean open-source data and build phoneme- mapping models between languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">phon2phon</head><p>As described in Section 4.1.2, each phoneme in Phoible maps to a unique feature vector; each feature value is +, -, or 0, representing whether a feature is present, not present, or not applica- ble. (Tones, for example, can never be syllabic or stressed.)</p><p>We convert each feature vector into a bit repre- sentation by mapping each value to 3 bits. + to 110, -to 101, and 0 to 000. This captures the idea that  </p><formula xml:id="formula_0">in S do if p s / ∈ P and ASCII(p s ) ∈ P then p s = ASCII(p s ); end p p = min ∀ p t ∈T (phon2phon(p s , p t ));</formula><p>add p s → p p to M ; end Algorithm 1: A condensed version of our pro- cedure for mapping scraped phoneme sets from Wikipedia and Wiktionary to Phoible language inventories. The full algorithm handles segmen- tation of the scraped pronunciation and heuristi- cally promotes coverage of the Phoible inventory. the features + and -are more similar than 0.</p><p>We then compute the normalized Hamming dis- tance between every phoneme pair p 1,2 with fea- ture vectors f 1,2 and feature vector length n as fol- lows:</p><formula xml:id="formula_1">phon2phon(p 1 , p 2 ) = ∑ n i=1 1, iff i 1 ̸ = f i 2 n</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Data cleaning</head><p>We now combine phon2phon distances and Phoible phoneme inventories to map phonemes from scraped Wikipedia IPA help tables and Wiktionary pronunciation dictionaries to Phoible phonemes and inventories. We describe a con- densed version of our procedure in Algorithm 1, and provide examples of cleaned Wiktionary out- put in <ref type="table" target="#tab_4">Table 4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Phoneme mapping models</head><p>Another application of phon2phon is to transform pronunciations in one language to another lan- guage's phoneme inventory. We can do this by <ref type="table" target="#tab_5">lang   avg  phon  script  English  German  Latin  French  Hindi  Gujarati  Bengali Sanskrit  Vietnamese Indonesian Sindhi  Polish   Table 5</ref>: Closest languages with Wikipedia ver- sions, based on lang2lang averaged metrics, pho- netic inventory distance, and script distance.</p><p>creating a single-state weighted finite-state trans- ducer (wFST) W for input language inventory I and output language inventory O:</p><formula xml:id="formula_2">∀ p i ∈I,po∈O W.add(p i , p o , 1 − phon2phon(p i , p o ))</formula><p>W can then be used to map a pronunciation to a new language; this has the interesting effect of modeling accents by foreign-language speakers: think in English (pronounced "θ ɪ ŋ kʰ") becomes "s̪ ɛ ŋ k" in German; the capital city Dhaka (pro- nounced in Bengali with a voiced aspirated "ɖ ̤ ") be- comes the unaspirated "d ae kʰ ae" in English.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Language Distance Metric</head><p>Since we are interested in mapping high-resource languages to low-resource related languages, an important subtask is finding the related languages of a given language. The URIEL Typological Compendium ( <ref type="bibr" target="#b8">Littell et al., 2016</ref>) is an invaluable resource for this task. By using features from linguistic databases (in- cluding Phoible), URIEL provides 5 distance met- rics between languages: genetic, geographic, com- posite (a weighted composite of genetic and ge- ographic), syntactic, and phonetic. We extend URIEL by adding two additional metrics, provid- ing averaged distances over all metrics, and adding additional information about resources. This cre- ates lang2lang, a table which provides distances between and information about 2,790 languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Phoneme inventory distance</head><p>Although URIEL provides a distance metric be- tween languages based on Phoible features, it only takes into account broad phonetic features, such as whether each language has voiced plosives. This can result in some non-intuitive results: based on this metric, there are almost 100 languages pho- netically equivalent to the South Asian language Gujarati, among them Arawak and Chechen.</p><p>To provide a more fine-grained phonetic dis- tance metric, we create a phoneme inventory dis- tance metric using phon2phon. For each pair of language phoneme inventories L 1,2 in Phoible, we compute the following:</p><formula xml:id="formula_3">d(L 1 , L 2 ) = ∑ p 1 ∈L 1 min p 2 ∈L 2 (phon2phon(p 1 , p 2 ))</formula><p>and normalize by dividing by</p><formula xml:id="formula_4">∑ i d(L 1 , L i ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Script distance</head><p>Although Urdu is very similar to Hindi, its dif- ferent alphabet and writing conventions would make it difficult to transfer an Urdu g2p model to Hindi. A better candidate language would be Nepali, which shares the Devanagari script, or even Bengali, which uses a similar South Asian script. A metric comparing the character sets used by two languages is very useful for capturing this relation- ship.</p><p>We first use our multilingual named entity data to extract character sets for the 232 languages with more than 500 NE pairs; then, we note that Uni- code character names are similar for linguistically related scripts. This is most notable in South Asian scripts: for example, the Bengali ক, Gujarati ક, and Hindi क have Unicode names BENGALI LETTER KA, GUJARATI LETTER KA, and DEVANAGARI LETTER KA, respectively.</p><p>We remove script, accent, and form identifiers from the Unicode names of all characters in our character sets, to create a set of reduced character names used across languages. Then we create a bi- nary feature vector f for every language, with each feature indicating the language's use of a reduced character (like LETTER KA). The distance between two languages L 1,2 can then be computed with a spatial cosine distance:</p><formula xml:id="formula_5">d(L 1 , L 2 ) = 1 − f 1 · f 2 ∥f 1 ∥ 2 ∥f 2 ∥ 2</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Resource information</head><p>Each entry in our lang2lang distance table also includes the following features for the second lan- guage: the number of named entities, whether it is in Europarl ( <ref type="bibr" target="#b5">Koehn, 2005)</ref>, whether it has its own Wikipedia, whether it is primarily written in the same script as the first language, whether it has an IPA Help page, whether it is in our Wiktionary test set, and whether it is in our Wiktionary training set.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Evaluation Metrics</head><p>The next two sections describe our high-resource and adapted g2p models. To evaluate these models, we compute the following metrics:</p><p>• % of words skipped: This shows the coverage of the g2p model. Some g2p models do not cover all character sequences. All other met- rics are computed over non-skipped words.</p><p>• word error rate (WER): The percent of incor- rect 1-best pronunciations.</p><p>• word error rate 100-best (WER 100): The percent of 100-best lists without the correct pronunciation.</p><p>• phoneme error rate (PER): The percent of er- rors per phoneme. A PER of 15.0 indicates that, on average, a linguist would have to edit 15 out of 100 phonemes of the output. We then average these metrics across all lan- guages (weighting each language equally).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">High Resource g2p Models</head><p>We now build and evaluate g2p models for the "high-resource" languages for which we have ei- ther IPA Help tables or sufficient training data from Wiktionary. <ref type="table" target="#tab_7">Table 6</ref> shows our evaluation of these models on Wiktionary test data, and <ref type="table" target="#tab_6">Table 7</ref> shows results for individual languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">IPA Help models</head><p>We first use the rules scraped from Wikipedia's IPA Help pages to build rule-based g2p models. We build a wFST for each language, with a path for each rule g → p and weight w = 1/count(g).</p><p>This method prefers rules with longer grapheme segments; for example, for the word tin, the output "ʃ n" is preferred over the correct "tʰ ɪ n" because of the rule ti→ʃ. We build 97 IPA Help models, but have test data for only 91-some languages, like Mayan, do not have any Wiktionary entries.</p><p>As shown in <ref type="table" target="#tab_7">Table 6</ref>, these rule-based models do not perform very well, suffering especially from a high percentage of skipped words. This is be- cause IPA Help tables explain phonemes' relation- ships to graphemes, rather than vice versa. Thus, the English letter x is omitted, since its composite phonemes are better explained by other letters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Wiktionary-trained models</head><p>We next build models for the 85 languages in our Wiktionary train data set, using the wFST- based Phonetisaurus <ref type="bibr" target="#b10">(Novak et al., 2011</ref>) and MITLM ( <ref type="bibr" target="#b2">Hsu and Glass, 2008)</ref>, as described by <ref type="bibr" target="#b11">Novak et al (2012)</ref>. We use a maximum of 10k pairs of training data, a 7-gram language model, and 50 iterations of EM.</p><p>These data-driven models outperform IPA Help models by a considerable amount, achieving a WER of 44.69 and PER of 15.06 averaged across all 85 languages. Restricting data to 2.5k or more training examples boosts results to a WER of 28.02 and PER of 7.20, but creates models for only 29 languages.</p><p>However, in some languages good results are ob- tained with very limited data; <ref type="figure" target="#fig_2">Figure 2</ref> shows the varying quality across languages and data avail- ability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">Unioned models</head><p>We also use our rule-based IPA Help tables to im- prove Wiktionary model performance. We accom- plish this very simply, by prepending IPA help rules like the German sch→ʃ to the Wiktionary training data as word-pronunciation pairs, then running the Phonetisaurus pipeline.</p><p>Overall, the unioned g2p models outperform both the IPA help and Wiktionary models; how- ever, as shown in   <ref type="table" target="#tab_6">Table 7</ref>: WER scores for Bengali, Tagalog, Turkish, and German models. Unioned models with IPA Help rules tend to perform better than Wiktionary-only models, but not consistently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Adapted g2p Models</head><p>Having created a set of high-resource models and our phon2phon and lang2lang metrics, we now explore different methods for adapting high- resource models and data for related low-resource languages. For comparable results, we restrict the set of high-resource languages to those covered by both our IPA Help and Wiktionary data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.1">No mapping</head><p>The simplest experiment is to run our g2p models on related low-resource languages, without adap- tation. For each language l in our test set, we determine the top high-resource related languages h 1,2,... according to the lang2lang averaged met- ric that have both IPA Help and Wiktionary data and the same script, not including the language it- self. For IPA Help models, we choose the 3 most related languages h 1,2,3 and build a g2p model from their combined g-p rules. For Wiktionary and unioned models, we compile 5k words from the closest languages h 1,2,... such that each h con- tributes no more than one third of the data (adding IPA Help rules for unioned models) and train a model from the combined data.</p><p>For each test word-pronunciation pair, we triv- ially map the word's letters to the characters used in h 1,2,... by removing accents where necessary; we then use the high-resource g2p model to produce a pronunciation for the word. For example, our Czech IPA Help model uses a model built from g-p rules from Serbo-Croatian, Polish, and Slovenian; the Wiktionary and unioned models use data and rules from these languages and Latin as well.</p><p>This expands 56 g2p models (the languages cov- ered by both IPA Help and Wiktionary models) to models for 211 languages. However, as shown in <ref type="table" target="#tab_9">Table 8</ref>, results are very poor, with a very high WER of 92% using the unioned models and a PER of more than 50%. Interestingly, IPA Help models perform better than the unioned models, but this is primarily due to their high skip rate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2">Output mapping</head><p>We next attempt to improve these results by creat- ing a wFST that maps phonemes from the inven- tories of h 1,2... to l (as described in Section 5.3). As shown in <ref type="figure">Figure 1a</ref>, by chaining this wFST to h 1,2... 's g2p model, we map the g2p model's output phonemes to the phonemes used by l. In each base model type, this process considerably improves ac- curacy over the no mapping approach; however, the IPA Help skip rate increases <ref type="table" target="#tab_9">(Table 8</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.3">Training data mapping</head><p>We now build g2p models for l by creating syn- thetic data for the Wiktionary and unioned mod- els, as in <ref type="figure">Figure 1b</ref>. After compiling word- pronunciation pairs and IPA Help g-p rules from closest languages h 1,2,... , we then map the pronun- ciations to l and use the new pronunciations as training data. We again create unioned models by adding the related languages' IPA Help rules to the training data.</p><p>This method performs slightly worse in accu- racy than output mapping, a WER of 87%, but has a much lower skip rate of 7%.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.4">Rescripting</head><p>Adaptation methods thus far have required that h and l share a script. However, this excludes lan- guages with related scripts, like Hindi and Bengali. We replicate our data mapping experiment, but now allow related languages h 1,2,... with different scripts from l but a script distance of less than 0.2. We then build a simple "rescripting" table based on matching Unicode character names; we can then map not only h's pronunciations to l's phoneme set, but also h's word to l's script.</p><p>Although performance is relatively poor, re- scripting adds 10 new languages, including Telugu, Gujarati, and Marwari. <ref type="table" target="#tab_9">Table 8</ref> shows evaluation metrics for all adaptation methods. We also show results using all 85 Wik- tionary models (using unioned where IPA Help is available) and rescripting, which increases the to- tal number of languages to 229. <ref type="table" target="#tab_10">Table 9</ref> provides examples of output with different languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.5">Discussion</head><p>In general, mapping combined with IPA Help rules in unioned models provides the best results.</p><p>Training data mapping achieves similar scores as output mapping as well as a lower skip rate. Word skipping is problematic, but could be lowered by collecting g-p rules for the low-resource language.</p><p>Although the adapted g2p models make many individual phonetic errors, they nevertheless cap- ture overall pronunciation conventions, without re- quiring language-specific data or rules. Specific points of failure include rules that do not exist in related languages (e.g., the silent "e" at the end of "fuse" and the conversion of "d̪ ʃ" to "ɡ" in Egyp- tian Arabic), mistakes in phoneme mapping, and overall "pronounceability" of the output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.6">Limitations</head><p>Although our adaptation strategies are flexible, several limitations prevent us from building a g2p model for any language. If there is not enough information about the language, our lang2lang table will not be able to provide related high- resource languages. Additionally, if the language's script is not closely related to another language's and thus cannot be rescripted (as with Thai and Ar- menian), we are not able to adapt related g2p data or models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">Conclusion</head><p>Using a large multilingual pronunciation dic- tionary from Wiktionary and rule tables from Wikipedia, we build high-resource g2p models and show that adding g-p rules as training data can improve g2p performance. We then lever- age lang2lang distance metrics and phon2phon phoneme distances to adapt g2p resources for high- resource languages for 229 related low-resource languages. Our experiments show that adapting training data for low-resource languages outper- forms adapting output. To our knowledge, these are the most broadly multilingual g2p experiments to date.</p><p>With this publication, we release a number of resources to the NLP community: a large multilin- gual Wiktionary pronunciation dictionary, scraped Wikipedia IPA Help tables, compiled named entity resources (including a multilingual gazetteer), and our phon2phon and lang2lang distance tables. <ref type="bibr">4</ref> Future directions for this work include further improving the number and quality of g2p mod- els, as well as performing external evaluations of the models in speech-and text-processing tasks. We plan to use the presented data and methods for other areas of multilingual natural language pro- cessing.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Figure 1: Strategies for adapting existing language resources through output mapping (a) and training data mapping (b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Training data size vs. PER for 85 models trained from Wiktionary. Labeled languages: English (eng), Serbo-Croatian (hbs), Russian (rus), Tagalog (tgl), and Chinese macrolanguage (zho).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>method</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Examples of English, Polish, Bengali, 
and Hebrew pronunciation dictionary entries, with 
pronunciations represented with the International 
Phonetic Alphabet (IPA). 

word 
eng 
deu 
nld 
gift 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Examples of scraped and cleaned Wik-
tionary pronunciation data in Czech, Pashto, Kan-
nada, Armenian, and Ukrainian. 

Data: all phonemes P , scraped phoneme set 
S, language inventory T 
Result: Mapping table M 
initialize empty table M ; 
for p s </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 5 shows</head><label>5</label><figDesc>examples of the closest languages to English, Hindi, and Vietnamese, according to different lang2lang metrics.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 7 ,</head><label>7</label><figDesc></figDesc><table>the effects vary across 
different languages. It is unclear what effect lan-
guage characteristics, quality of IPA Help rules, 
and training data size have on unioned model im-
provement. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Results for high-resource models. The top portion of the table shows results for all models; the 
bottom shows results only for languages with both IPA Help and Wiktionary models. 

lang 
ben 
tgl 
tur 
deu 
# train 
114 
126 2.5k 10k 
ipa-help 100.0 64.8 69.0 40.2 
wikt 
85.6 34.2 39.0 32.5 
unioned 66.2 36.2 39.0 24.5 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head>Table 8 :</head><label>8</label><figDesc></figDesc><table>Results for adapted g2p models. Final adapted results (using the 85 languages covered by Wik-
tionary and unioned high-resource models, as well as rescripting) cover 229 languages. 

lang 
method 
base model 
rel langs 
word 
gold 
hyp 
eng 
no mapping 
ipa-help 
deu, nld, swe 
fuse 
f j uː z 
f ʏ s ɛ 

arz 
output mapping 
unioned 
fas, urd 
‫جو‬ ‫بان‬ 
b aeː n̪ ɡ uː 
b a n̪ d̪ ʃ uː 

afr training mapping 
unioned 
nld, lat, isl 
dood 
d ɔ t 
d uː t 

sah training mapping 
unioned 
rus, bul, ukr 
хатырык k a t ̪ ɯ r̪ ɯ k k a t ̪ i r̪ i k 
kan 
rescripted 
unioned 
hin, ben 

ದುï¿¿ಷ 

d̪ u ʂ ʈʰ a 
d̪ ̤ uː ʂ ʈʰ 

guj 
rescripted 
unioned 
san, ben, hin ગળૠોએિશઆ k ɾ o e ç ɪ a k ɾ õː ə ʂ ɪ a 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="false"><head>Table 9 :</head><label>9</label><figDesc></figDesc><table>Sample words, gold pronunciations, and hypothesis pronunciations for English, Egyptian Arabic, 
Afrikaans, Yakut, Kannada, and Gujarati. 

</table></figure>

			<note place="foot" n="3"> https://en.wikipedia.org/wiki/Category: International_Phonetic_Alphabet_help</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11">Acknowledgements</head><p>We would like to thank the anonymous re-viewers for their helpful comments, as well as our colleagues Marjan Ghazvininejad, Jonathan May, Nima Pourdamghani, Xing Shi, and Ashish Vaswani for their advice. We would also like to thank Deniz Yuret for his invaluable help with data collection. This work was supported in part by DARPA (HR0011-15-C-0115) and ARL/ARO (W911NF-10-1-0533). Computation for the work described in this paper was supported by the Uni-versity of Southern California's Center for High-Performance Computing.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Report of NEWS 2015 machine transliteration shared task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Rafael E Banchs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haizhou</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kumaran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NEWS Workshop</title>
		<meeting>NEWS Workshop</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>4 Instructions for obtaining this data are available at the authors&apos; websites</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">The Concise Dictionary of World Place-Names</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Everett-Heath</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Iterative language model estimation: efficient data structure &amp; algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo-June Paul</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James R</forename><surname>Glass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Transliterating from all languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ann</forename><surname>Irvine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Klementiev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AMTA</title>
		<meeting>AMTA</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Name extraction and translation for distillation. Handbook of Natural Language Processing and Machine Translation: DARPA Global Autonomous Language Exploitation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dayne</forename><surname>Freitag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Blume</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shahram</forename><surname>Khadivi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Europarl: A parallel corpus for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MT Summit</title>
		<meeting>MT Summit</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Ethnologue: Languages of the world. SIL international</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M Paul</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Gary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles D</forename><surname>Simons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fennig</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<pubPlace>Dallas</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Unsupervised language-independent name translation mining from Wikipedia infoboxes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Pin</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Snover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Workshop on Unsupervised Learning in NLP</title>
		<meeting>Workshop on Unsupervised Learning in NLP</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Littell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mortensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lori</forename><surname>Levin</surname></persName>
		</author>
		<ptr target="http://www.cs.cmu.edu/~dmortens/uriel.html.Accessed" />
		<title level="m">URIEL. Pittsburgh: Carnegie Mellon University</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2016" to="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">PHOIBLE Online. Max Planck Institute for Evolutionary Anthropology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Mccloy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Wright</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<pubPlace>Leipzig</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Phonetisaurus: A WFST-driven phoneticizer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Josef R Novak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Minematsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hirose</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
		<respStmt>
			<orgName>The University of Tokyo, Tokyo Institute of Technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">WFST-based grapheme-to-phoneme conversion: open source tools for alignment, modelbuilding and decoding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nobuaki</forename><surname>Josef R Novak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keikichi</forename><surname>Minematsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hirose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Workshop on Finite State Methods and Natural Language Processing</title>
		<meeting>International Workshop on Finite State Methods and Natural Language essing</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A computational approach to the automation of creative naming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gözde</forename><surname>Özbal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlo</forename><surname>Strapparava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Wiktionary as a source for automatic pronunciation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Schlippe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ochs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tanja</forename><surname>Schultz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Grapheme-to-phoneme model generation for Indo-European languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Schlippe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ochs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tanja</forename><surname>Schultz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Automatic error recovery for pronunciation dictionaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Schlippe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ochs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngoc</forename><forename type="middle">Thang</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tanja</forename><surname>Schultz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">GlobalPhone: A multilingual text &amp; speech database in 20 languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tanja</forename><surname>Schultz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngoc</forename><forename type="middle">Thang</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Schlippe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Rapid language adaptation tools and technologies for multilingual speech processing systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tanja</forename><surname>Schultz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Workshop on Automatic Speech Recognition</title>
		<meeting>IEEE Workshop on Automatic Speech Recognition</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Word segmentation and pronunciation extraction from phoneme sequences through cross-lingual word-to-phoneme alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Stahlberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Schlippe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Vogel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tanja</forename><surname>Schultz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="234" to="261" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">JRC-Names: A freely available, highly multilingual named entity resource</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralf</forename><surname>Steinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bruno</forename><surname>Pouliquen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mijail</forename><surname>Kabadjov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Van Der Goot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Recent Advances in Natural Language Processing</title>
		<meeting>Recent Advances in Natural Language essing</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Geonames ontology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernard</forename><surname>Vatant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Wick</surname></persName>
		</author>
		<ptr target="http://www.geonames.org/ontology" />
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Multilingual multilayer perceptron for rapid language adaptation between and across language families</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngoc</forename><forename type="middle">Thang</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tanja</forename><surname>Schultz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Multilingual deep neural network based acoustic modeling for rapid language adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngoc</forename><forename type="middle">Thang</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Imseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Povey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petr</forename><forename type="middle">Motlicek</forename><surname>Motlicek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tanja</forename><surname>Schultz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hervé</forename><surname>Bourlard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Joint generation of transliterations from multiple representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Kondrak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NAACL HLT</title>
		<meeting>NAACL HLT</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
