<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:32+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Joint Optimization of User-desired Content in Multi-document Summaries by Learning from User Feedback</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avinesh</forename><surname>Pvs</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><forename type="middle">M</forename><surname>Meyer</surname></persName>
						</author>
						<title level="a" type="main">Joint Optimization of User-desired Content in Multi-document Summaries by Learning from User Feedback</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</title>
						<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1353" to="1363"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-1124</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In this paper, we propose an extractive multi-document summarization (MDS) system using joint optimization and active learning for content selection grounded in user feedback. Our method interactively obtains user feedback to gradually improve the results of a state-of-the-art integer linear programming (ILP) framework for MDS. Our methods complement fully automatic methods in producing high-quality summaries with a minimum number of iterations and feedbacks. We conduct multiple simulation-based experiments and analyze the effect of feedback-based concept selection in the ILP setup in order to maximize the user-desired content in the summary.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The task of producing summaries from a clus- ter of multiple topic-related documents has gained much attention during the Document Understand- ing Conference <ref type="bibr">1</ref> (DUC) and the Text Analysis Conference 2 (TAC) series. Despite a lot of re- search in this area, it is still a major challenge to automatically produce summaries that are on par with human-written ones. To a large extent, this is due to the complexity of the task: a good sum- mary must include the most relevant information, omit redundancy and irrelevant information, sat- isfy a length constraint, and be cohesive and gram- matical. But an even bigger challenge is the high degree of subjectivity in content selection, as it can be seen in the small overlap of what is considered important by different users. Optimizing a sys- tem towards one single best summary that fits all users, as it is assumed by current state-of-the-art systems, is highly impractical and diminishes the usefulness of a system for real-world use cases.</p><p>In this paper, we propose an interactive concept- based model to assist users in creating a personal- ized summary based on their feedback. Our model employs integer linear programming (ILP) to max- imize user-desired content selection while using a minimum amount of user feedback and iterations. In addition to the joint optimization framework us- ing ILP, we explore pool-based active learning to further reduce the required feedback. Although there have been previous attempts to assist users in single-document summarization, no existing work tackles the problem of multi-document summaries using optimization techniques for user feedback. Additionally, most existing systems produce only a single, globally optimal solution. Instead, we put the human in the loop and create a personal- ized summary that better captures the users' needs and their different notions of importance.</p><p>Need for personalization. <ref type="table">Table 1</ref> shows the ROUGE scores <ref type="bibr" target="#b19">(Lin, 2004</ref>) of multiple existing summarization systems, namely TF*IDF <ref type="bibr" target="#b21">(Luhn, 1958)</ref>, <ref type="bibr">LexRank (Erkan and Radev, 2004</ref>), Text- Rank ( <ref type="bibr" target="#b24">Mihalcea and Tarau, 2004</ref>), LSA (Gong and <ref type="bibr" target="#b10">Liu, 2001</ref>), KL-Greedy (Haghighi and Van- derwende, 2009), provided by the sumy package <ref type="bibr">3</ref> and ICSI <ref type="bibr">4</ref> ( <ref type="bibr" target="#b9">Gillick and Favre, 2009;</ref><ref type="bibr" target="#b3">Boudin et al., 2015)</ref>, a strong state-of-the-art approach <ref type="bibr" target="#b13">(Hong et al., 2014</ref>) in comparison to the extractive up- per bound on DUC'04 and DBS. DUC'04 is an English dataset of abstractive summaries from ho- <ref type="figure">Figure 1</ref>: Lexical overlap of a reference summary <ref type="bibr">(cluster D31043t in DUC 2004</ref>) with the summary produced by ICSI's state-of-the-art system ( <ref type="bibr" target="#b3">Boudin et al., 2015)</ref>   <ref type="table">Table 1</ref>: ROUGE-1 (R1), ROUGE-2 (R2), and ROUGE-SU4 (SU4) scores of multiple systems compared to the extractive upper bound (UB) mogenous news texts, whereas DBS ( <ref type="bibr" target="#b0">Benikova et al., 2016</ref>) is a German dataset of cohesive ex- tracts from heterogeneous sources from the educa- tional domain (see details in section 4.1). For each dataset, we compute an extractive upper bound (UB) by optimizing the sentence selection which maximizes ROUGE-2, i.e., the occurrence of bi- grams as in the reference summary <ref type="bibr" target="#b4">(Cao et al., 2016)</ref>. Although some systems achieve state-of- the-art performance, their scores are still far from the extractive upper bound of individual reference summaries as shown in <ref type="figure">Figure 1</ref>. This is due to low inter-annotator agreement for concept selec- tion: Zechner (2002) reports, for example, κ = .13 and Benikova et al. (2016) κ = .23. Most systems try to optimize for all reference summaries instead of personalizing, which we consider essential to capture user-desired content.</p><p>Need for user feedback. The goal of concept selection is finding the important information within a given set of source documents. Although existing summarization algorithms come up with a generic notion of importance, it is still far from the user-specific importance as shown in <ref type="figure">Figure 1</ref>. In contrast, humans can easily assess importance given a topic or a query. One way to achieve personalized summarization is thus by combining the advantages of both human feedback and the generic notion of importance built in a system. This allows users to interactively steer the summa- rization process and integrate their user-specific notion of importance.</p><p>Contributions. In this work, (1) we propose a novel ILP-based model using an interactive loop to create multi-document user-desired summaries, and (2) we develop models using pool-based ac- tive learning and joint optimization techniques to collect user feedback on identifying important concepts of a topic. In order to encourage the community to advance research and replicate our results, we provide our interactive summarizer im- plementation as open-source software. 5 .</p><p>Our proposed method and our new interactive summarization framework can be used in multiple application scenarios: as an interactive annotation tool, which highlights important sentences for the annotators, as a journalistic writing aid that sug- gests important, user-adapted content from multi- ple source feeds (e.g., live blogs), and as a medical data analysis tool that suggests key information as- sisting a patient's personalized medical diagnosis.</p><p>The rest of the paper is structured as follows: In section 2, we discuss related work. Section 3 introduces our computer-assisted summarization framework using the concept-based optimization. Section 4 describes our experiment data and setup. In section 5, we then discuss our results and an- alyze the performance of our models across dif- ferent datasets. Finally, we conclude the paper in section 6 and discuss future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Previous works related to our research address ex- tractive summarization as a budgeted subset selec- tion problem, computer-assisted approaches, and personalized summarization models.</p><p>Bugeted subset selection. Extractive summa- rization systems that compose a summary from a number of important sentences from the source documents are by far the most popular solution for MDS. This task can be modeled as a budgeted maximum coverage problem. Given a set of sen- tences in the document collection, the task is to maximize the coverage of the subset of sentences under a length constraint. The scoring function estimates the importance of the content units for a summary. Most previous works consider sen- tences as content units and try different scoring functions to optimize the summary.</p><p>One of the earliest systems by McDonald (2007) models a scoring function by simultane- ously maximizing the relevance scores of the se- lected content units and minimizing their pairwise redundancy scores. They solve the global opti- mization problem using an ILP framework. Later, several state-of-the-art results employed an ILP to maximize the number of relevant concepts in the created summary: <ref type="bibr" target="#b9">Gillick and Favre (2009)</ref> use an ILP with bigrams as concepts and hand-coded deletion rules for compression. <ref type="bibr" target="#b1">Berg-Kirkpatrick et al. (2011)</ref> combine grammatical features relat- ing to the parse tree and use a maximum-margin SVM trained on annotated gold-standard com- pressions. <ref type="bibr" target="#b36">Woodsend and Lapata (2012)</ref> jointly optimize content selection and surface realiza- tion, <ref type="bibr" target="#b18">Li et al. (2013)</ref> estimate the weights of the concepts using supervised methods, and <ref type="bibr" target="#b3">Boudin et al. (2015)</ref> propose an approximation algorithm to achieve the optimal solution. Although these approaches achieve state-of-the-art performance, they produce only one globally optimal summary which is impractical for various users due to the subjectivity of the task. Therefore, we research in- teractive computer-assisted approaches in order to produce personalized summaries.</p><p>Computer-assisted summarization. The ma- jority of the existing computer-assisted summa- rization tools <ref type="bibr" target="#b5">(Craven, 2000;</ref><ref type="bibr" target="#b26">Narita et al., 2002;</ref><ref type="bibr" target="#b29">OrˇasanOrˇasan et al., 2003;</ref><ref type="bibr" target="#b27">OrˇasanOrˇasan and Hasler, 2006</ref>) present important elements of a document to the user. Creating a summary then requires the hu- man to cut, paste, and reorganize the important el- ements in order to formulate a final text. The work by Orˇasan <ref type="bibr" target="#b27">Orˇasan and Hasler (2006)</ref> is closely related to ours, since they assist users in creating summaries for a source document based on the output of a given automatic summarization system. However, their system is neither interactive nor does it con- sider the user's feedback in any way. Instead, they suggest the output of the state-of-the-art (single- document) summarization method as a summary draft and ask the user to construct the summary without further interaction.</p><p>Personalized summarization. While most pre- vious work focuses on generic summaries, there have been a few attempts to take a user's prefer- ences into account. The study by <ref type="bibr" target="#b2">Berkovsky et al. (2008)</ref> shows that users prefer personalized sum- maries that precisely reflect their interests. These interests are typically modeled with the help of a query <ref type="bibr" target="#b31">(Park and An, 2010)</ref> or keyword annotations reflecting the user's opinions ( <ref type="bibr" target="#b38">Zhang et al., 2003)</ref>.</p><p>In another strand of research, <ref type="bibr" target="#b7">Díaz and Gervás (2007)</ref> create user models based on social tag- ging and <ref type="bibr" target="#b14">Hu et al. (2012)</ref> rank sentences by com- bining informativeness scores with a user's in- terests based on fuzzy clustering of social tags. Extending the use of social content, another re- cent work showed how personalized review sum- maries ( <ref type="bibr" target="#b34">Poussevin et al., 2015</ref>) can be useful in recommender systems beyond rating predictions. Although these approaches show that personal- ized summaries are more useful than generic sum- maries, they do not attempt to iteratively refine a summary in an interactive user-system dialog.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Approach</head><p>The goal of our work is maximizing the user- desired content in a summary within a minimum number of iterations. To this end, we propose an interactive loop that alternates the automatic cre- ation of a summary and the acquisition of user feedback to refine the next iteration's summary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Summary Creation</head><p>Our starting point is the concept-based ILP sum- marization framework by <ref type="bibr" target="#b3">Boudin et al. (2015)</ref>. Let C be the set of concepts in a given set of source documents D, c i the presence of the concept i in the resulting summary, w i a concept's weight, j the length of sentence j, s j the presence of sen- tence j in the summary, and Occ ij the occurrence of concept i in sentence j. Based on these defini- tions, we formulate the following ILP:</p><formula xml:id="formula_0">max i w i c i (1) ∀j. j j s j ≤ L (2) ∀i, j. j s j Occ ij ≥ c i (3) ∀i, j. s j Occ ij ≤ c i (4) ∀i. c i ∈ {0, 1} (5) ∀j. s j ∈ {0, 1}<label>(6)</label></formula><p>The objective function (1) maximizes the oc- currence of concepts c i in the summary based on their weights w i . The constraint formalized in <ref type="bibr">(2)</ref> ensures that the summary length is restricted to a maximum length L, (3) ensures the selection of all concepts in a sentence s j if s j has been selected for the summary. Constraint (4) ensures that a con- cept is only selected if it is present in at least one of the selected sentences.</p><p>The two key factors for the performance of this ILP are defining the concept set C and a method to estimate the weights w i ∈ W . Previous works have used word bigrams as concepts <ref type="bibr" target="#b9">(Gillick and Favre, 2009;</ref><ref type="bibr" target="#b18">Li et al., 2013;</ref><ref type="bibr" target="#b3">Boudin et al., 2015)</ref> and either use document frequency (i.e. the num- ber of source documents containing the concept) as weights <ref type="bibr" target="#b36">(Woodsend and Lapata, 2012;</ref><ref type="bibr" target="#b9">Gillick and Favre, 2009)</ref> or estimate them using a su- pervised regression model ( <ref type="bibr" target="#b18">Li et al., 2013</ref>). For our implementation, we likewise use bigrams as concepts and document frequency as weights, as <ref type="bibr" target="#b3">Boudin et al. (2015)</ref> report good results with this simple strategy. Our approach is, however, not limited to this setup, as our interactive approach allows for any definition of C and W , including potentially more sophisticated weight estimation methods, e.g., based on deep neural networks. In section 5.2, we additionally analyze how other no- tions of concepts can be integrated into our ap- proach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Interactive Summarization Loop</head><p>Algorithm 1 provides an overview of our interac- tive summarization approach. The system takes the set of source documents D as input, derives the set of concepts C, and initializes their weights W . In line 5, we start the interactive feedback loop iterating over t = 0, . . . , T . We first create a summary S t (line 6) by solving the ILP and then extract a set of concepts Q t (line 7), for which we query the user in line 11 As the user feed- back in the current time step, we use the concepts I t ⊆ Q t that have been considered important by the user. For updating the weights W in line 12, we may use all feedback collected until the cur- rent time step t, i.e., I t 0 = t j=0 I j and the set of concepts Q t 0 = t j=0 Q j seen by the user (with</p><formula xml:id="formula_1">Q −1 0 = ∅).</formula><p>If there are no more concepts to query (i.e., Q t = ∅), we stop the iteration and return the personalized summary S t . </p><formula xml:id="formula_2">I t ← obtainFeedback(S t , Q t ) 12: W ← updateWeights(W, I t 0 , Q t 0 ) 13:</formula><p>end if</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>14:</head><p>end for 15: end procedure</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">User Feedback Optimization</head><p>To optimize the summary creation based on user feedback, we iteratively change the concept weights in the objective function of the ILP setup. We define the following models:</p><p>Accept model (ACCEPT). This model presents the current summary S t with highlighted concepts Q t to a user and asks him/her to select all impor- tant concepts I t . We assign the maximum weight MAX to all concepts in I t and consider the re- maining Q t − I t as unimportant by setting their weight to 0 (see equation 7 and 8). The intuition behind this baseline is that the modified scores cause the ILP to prefer the user-desired concepts while avoiding unimportant ones.</p><formula xml:id="formula_3">∀i ∈ I t 0 . w i = MAX (7) ∀i ∈ Q t 0 − I t 0 . w i = 0<label>(8)</label></formula><p>Joint ILP with User Feedback (JOINT). The ACCEPT model fails in cases where the user could not accept concepts that never appear in one of the S t summaries. To tackle this, in our JOINT model, we change the objective function of the ILP in or- der to create S t by jointly optimizing importance and user feedback. We thus replace the equation (1) with:</p><formula xml:id="formula_4">max i ∈Q t 0 w i c i − i∈Q t 0 w i c i if t ≤ τ i w i c i if t &gt; τ<label>(9)</label></formula><p>Equation <ref type="formula" target="#formula_4">(9)</ref> maximizes the use of concepts for which we yet lack feedback (i ∈ Q t 0 ) and min- imizes the use of concepts for which we already have feedback (i ∈ Q t 0 ). In this JOINT model, we use an exploration phase t = 0 . . . τ to collect the feedback, which terminates when the user does not return any important concepts (i.e., I t = ∅). In the exploratory phase, the minus term in the equation 9 helps to reduce the score of the sentences whose concepts have received feedback already. In other words, it causes higher scores for sentences con- sisting of concepts which yet lack feedback. Af- ter the exploration step, we fall back to the orig- inal importance-based optimization function from equation (1).</p><p>Active learning with uncertainty sampling (AL). Our JOINT model explores well in terms of prioritizing the concepts which yet lack user feedback. However, it gives equal probabilities to all the unseen concepts. The AL model em- ploys pool-based active learning ( <ref type="bibr" target="#b17">Kremer et al., 2014</ref>) during the exploration phase in order to pri- oritize concepts for which the model is most un- certain. We distinguish the unlabeled concept pool C u = {Φ(˜ x 1 ), Φ(˜ x 2 ), ..., Φ(˜ x N )} and the labeled concept pool C = {(Φ(x 1 ), y 1 ), (Φ(x 2 ), y 2 ), . . . , (Φ(x N ), y N )}, where each concept x i is repre- sented as a d-dimensional feature vector Φ(x i ) ∈ R d . The labels y i ∈ {−1, 1} are 1 for all important concepts in I t 0 and −1 for all unimportant concepts in Q t 0 − I t 0 . Initially, the labeled concept pool C is small or empty, whereas the unlabeled concept pool C u is relatively large. The learning algorithm is presented with a C = C ∪ C u and is first called to learn a decision function f (0) : R d → R, where the function f (0) (Φ(˜ x)) is taken to predict the label of the input vector Φ(˜ x). Then, in each t th iteration, where t = 1, 2, . . . , τ , the querying algorithm selects an in- stance of˜xof˜ of˜x t ∈ C u for which the learning algorithm is least certain. Thus, our learning goal of active learning is to minimize the expected loss L (i.e., hinge loss) with limited querying opportunities to obtain a decision function f (1) , f (2) , . . . , f (τ ) that can achieve low error rates:</p><formula xml:id="formula_5">min E (Φ(x),y)∈C L(f (t) (Φ(x)), y)<label>(10)</label></formula><p>As the learning algorithm, we use a support vec- tor machine (SVM) with a linear kernel. To obtain the probability distribution over classes we use Platt's calibration <ref type="bibr" target="#b33">(Platt, 1999)</ref>, an effective ap- proach for transforming classification models into a probability distribution. Equation (11) shows the probability estimates for f (t) , where f (t) is the un- calibrated output of the SVM in the t th iteration and A, B are scalar parameters that are learned by the calibration algorithm. The uncertainty scores are calculated as described in the equation (12) for all the concepts which lack feedback (C u ).</p><formula xml:id="formula_6">p(y | f (t) ) = 1 1 + exp(Af (t) + B)<label>(11)</label></formula><formula xml:id="formula_7">u i = 1 − max y∈{−1,1} p(y | f (t) )<label>(12)</label></formula><p>For our AL model, we now change the objec- tive function in order to create S t by multiplying uncertainty scores u i to the weights w i . We thus replace the objective function from (9) with</p><formula xml:id="formula_8">max i ∈Q t 0 u i w i c i if t ≤ τ i w i c i if t &gt; τ<label>(13)</label></formula><p>Active learning with positive sampling (AL+). One way to sample the unseen concepts is using uncertainty as in AL, but another way is to actively choose samples for which the learning algorithm predicts as a possible important concept. In AL+, we introduce the notion of certainty (1−u i ) for the positively predicted samples (f (t) (Φ(˜ x i )) = 1) in <ref type="table">Dataset   Lang Topics Summary type  Length   DBS  de  10  Coherent extracts ≈ 500 words  DUC'01  en  30  Abstracts  100 words  DUC'02  en  59  Abstracts  100 words  DUC'04  en  50  Abstracts  100 words   Table 2</ref>: Statistics of the MDS datasets used the objective function (1) for producing S t max i ∈Q t</p><formula xml:id="formula_9">0 (1 − u i ) i w i c i if t ≤ τ i w i c i if t &gt; τ<label>(14)</label></formula><p>where</p><formula xml:id="formula_10">i = 0 if f (t) (Φ(˜ x i )) = −1 1 if f (t) (Φ(˜ x i )) = 1<label>(15)</label></formula><p>4 Experimental Setup</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data</head><p>For our experiments, we mainly focus on the DBS corpus, which is an MDS dataset of coher- ent extracts created from heterogeneous sources about multiple educational topics ( <ref type="bibr" target="#b0">Benikova et al., 2016)</ref>. This corpus is well-suited for our evalu- ation setup, since we are able to easily simulate a user's feedback based on the overlap between gen- erated and reference summary. Additionally, we carry out experiments on the most commonly used evaluation corpora pub- lished by DUC/NIST from the generic multi- document summarization task carried out in DUC'01, DUC'02 and DUC'04. The documents are all from the news domain and are grouped into various topic clusters. <ref type="table">Table 2</ref> shows the proper- ties of these corpora.</p><p>For evaluating the summaries against the refer- ence summary we use ROUGE <ref type="bibr" target="#b19">(Lin, 2004</ref>) with the parameters suggested by <ref type="bibr" target="#b30">(Owczarzak et al., 2012</ref>) yielding high correlation with human judg- ments (i.e., with stemming and without stopword removal). <ref type="bibr">6</ref> Since DBS summaries do not have a fixed length, we use a variable length parameter L for evaluation, where L denotes the length of the reference summary. All results are averaged across all topics and reference summaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Data Pre-processing and Features</head><p>To pre-process the datasets, we perform tokeniza- tion and stemming with NLTK ( <ref type="bibr" target="#b20">Loper and Bird, 2002</ref>) and constituency parsing with the Stanford parser ( <ref type="bibr" target="#b15">Klein and Manning, 2003</ref>) for English and <ref type="bibr">6</ref> -n 4 -m -a -x -c 95 -r 1000 -f A -p 0.5 -t 0 -2 -4 -u German. The parse trees will be used in sec- tion 5.2 below to experiment with a syntactically motivated concept notion.</p><p>As a concept's feature representation Φ for our active learning setups AL and AL+, we use pre-trained word embeddings. We use the Google News embeddings with 300 dimensions by <ref type="bibr" target="#b25">Mikolov et al. (2013)</ref> for English and the 100- dimensional news-and Wikipedia-based embed- dings by <ref type="bibr" target="#b35">Reimers et al. (2014)</ref> for German. Ad- ditionally, we add TF*IDF, number of stop words, presence of named entities, and word capitaliza- tion as features. Discrete features, such as part-of- speech tags, are mapped into the word representa- tion via lookup tables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Oracle-Based Simulation of User Feedback</head><p>The presence of a human in the loop typically de- mands for a user study based evaluation, but to collect sufficient data for various settings of our models would be too expensive. Therefore, we resort to an oracle-based approach, where the or- acle is a system simulating the user by generat- ing the feedback based on reference outputs. This idea has been widely used in the development of interactive systems <ref type="bibr" target="#b11">(González-Rubio et al., 2012;</ref><ref type="bibr" target="#b16">Knowles and Koehn, 2016</ref>) for studying the prob- lem and exhibiting solutions in a theoretical and controlled environment.</p><p>To simulate user feedback in our setting, we consider all concepts I t ⊆ Q t from the system- suggested summary S t as important if they are present in the reference summary. Let Ref be the set of concepts in the reference summary. In the t th iteration, we return I t = Q t ∩ Ref as the simu- lated user feedback. Thus, the goal of our system is to reach the upper bound for a user's reference summary within a minimal number of iterations.</p><p>We limit our experiments to ten iterations, since it appears unrealistic that users are willing to par- ticipate in more feedback cycles. <ref type="bibr" target="#b32">Petrie and Bevan (2009)</ref> even report only three to five iterations. <ref type="table">Table 3</ref> shows the evaluation results of our four models. When evaluating a summarization sys- tem, it is common to report the mean ROUGE scores across clusters using all the reference sum- maries. However, since we aim at personalizing <ref type="table">Datasets   ICSI  UB  ACCEPT  JOINT  AL  AL+  R1 R2 SU4 R1 R2 SU4 R1 R2 SU4 R1 R2 SU4 R1 R2 SU4 R1 R2 SU4</ref> Concept Notion: Bigrams DBS . <ref type="bibr">451 .183 .190 .848 .750 .532 .778 .654 .453 .815 .707 .484 .833 .729 .498 .828 .721 .500 DUC'04 .374 .090 .118 .470 .212 .185 .442 .176 .165 .444 .180 .166 .440 .178 .160 .427 .166 .154 DUC'02 .350 .085 .110 .474 .216 .187 .439 .178 .161 .444 .182 .165 .448 .188 .165 .448 .184 .170 DUC'01 .333 .073 .105 .450 .213 .181 .414 .171 .156 .418 .167 .149 .435 .186 .163 .426 .181 .158 Concept Notion: Content Phrases DBS .403 .135 .154 .848 .750 .532 .691 .531 .430 .742 .597 .419 .776 .652 .448 .767 .629 .440 DUC'04 .374 .090 .118 .470 .212 .185 .441 .176 .160 .441 .179 .162 .444 .180 .162 .422 .164 .150 DUC'02 .350 .085 .110 .474 .216 .187 .436 .181 .162 .444 .183 .165 .446 .185 .168 .442 .182 .162 DUC'01 .333 .073 .105 .450 .213 .181 .410 .165 .153 .417 .170 .156 .433 .182 .161 .420 .179 .154</ref> Table 3: ROUGE-1 (R1), ROUGE-2 (R2) and ROUGE SU-4 (SU4) achieved by our models after the tenth iteration of the interactive loop in comparison to the upper bound and the basic ILP setup  <ref type="table">Table 4</ref>: Average amount of user feedback (#F) considered by our models at the end of the tenth iteration of the interactive summarization loop the summary for an individual user, we evaluate our models based on the mean ROUGE scores across clusters per reference summary. In <ref type="table">Table 4</ref>, we additionally evaluate the models based on the amount of feedback (#F = |I T 0 |) taken by the or- acles to converge to the upper bound within ten iterations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Methods</head><p>To examine the system performance based on user feedback, we analyze our models' perfor- mance on multiple datasets. The results in <ref type="table">Table 3</ref> show that our idea of interactive multi-document summarization allows users to steer a general sum- mary towards a personalized summary consis- tently across all datasets. From the results, we can see that the AL model starts from the concept- based ILP summarization and nearly reaches the upper bound for all the datasets within ten itera- tions. AL+ performs similar to AL in terms of ROUGE, but requires less feedback (compare <ref type="table">Ta- ble 4</ref>). Furthermore, the ACCEPT and JOINT models get stuck in a local optimum due to the less exploratory nature of the models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Concept Notion</head><p>Our interactive summarization approach is based on the scalable global concept-based model which uses bigrams as concepts. Thus, it is intuitive to use bigrams for collecting user feedback as well. <ref type="bibr">7</ref> Although our models reach the upper bound when using bigram-based feedback, they require a sig- nificantly large number of iterations and much feedback to converge, as shown in <ref type="table">Table 4</ref>.</p><p>To reduce the amount of feedback, we also con- sider content phrases to collect feedback. That is, syntactic chunks from the constituency parse trees consisting of non-function words (i.e., nouns, verbs, adjectives, and adverbs). For DBS be- ing extractive dataset, we use bigrams and con- tent phrases as concepts, both for the objective function in equation (1) and as feedback items, whereas for the DUC datasets, the concepts are always bigrams for both the feedback types (bi- grams/content phrases). For DUC being abstrac- tive, in the case of feedback given on content phrases, they are projected back to the bigrams to change the concept weights in order to have more overlap of simulated feedback. <ref type="table">Table 4</ref> shows feedbacks based on the content phrases reduces the number of feedbacks by a factor of 2. Further- more, when content phrases are used as concepts for DBS, the performance of the models is lower compared to bigrams, as seen in <ref type="table">Table 3</ref>. on DBS. For DUC'04, the improvements are +.1 ROUGE-2 after ten iterations, which is relatively notable considering the lower upper bound of .21 ROUGE-2. This is primarily because DBS is a corpus of cohesive extracts, whereas DUC'04 con- sists of abstractive summaries. As a result, the ora- cles created using abstractive reference summaries have lower overlap of concepts as compared to that of the oracles created using extractive summaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Datasets</head><p>For DBS, it becomes clear that the JOINT model converges faster with an optimum amount of feedback as compared to other models. AC- CEPT takes relatively more feedbacks than JOINT, but performs low in terms of ROUGE scores. The best performing models are AL and AL+, which reach closest to the upper bound. This is clearly due to the exploratory nature of the models which use semantic representations of the concepts to predict uncertainty and importance of possible concepts for user feedback.</p><p>For DUC'04, the JOINT model reaches the closest to the upper bound, closely followed by AL. The JOINT model consistently stays above all other models and it gathers more important con- cepts due to optimizing feedbacks for concepts which lack feedback. Interestingly, AL+ performs rather worse in terms of both ROUGE scores and gathering important concepts. The primary reason for this is the fewer feedback collected from the simulation due to the abstractive property of ref- erence summaries, which makes the AL+ model's prediction inconsistent. <ref type="figure">Figure 3</ref> shows the performance of different mod- els in comparison to two different oracles for the same document cluster. For DBS, the JOINT, AL, and AL+ models consistently converge to the upper bound in 4 iterations for different oracles, whereas ACCEPT takes longer for one oracle and does not reach the upper bound for the other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Personalization</head><p>For DUC'04, JOINT and AL show consistent performance across the oracles, whereas AL+ per- forms worse than the state-of-the-art system (iter- ation 0) for oracle created using abstractive sum- maries as shown in <ref type="figure">Figure 3</ref> (right) for User:1.  <ref type="figure">Figure 3</ref>: Analysis of models over cluster 7 from DBS (left) and cluster d30051t from DUC'04 (right) respectively for different oracles However, for User:2, we observe a ROUGE-2 im- provement of +.1 indicating that the predictions of the active learning system are better if there is more feedback. Nevertheless, we expect that in practical use, the human summarizers may give more feedback similar to DBS in comparison to DUC'04 simulation setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>We propose a novel ILP-based approach using in- teractive user feedback to create multi-document user-desired summaries. In this paper, we investi- gate pool-based active learning and joint optimiza- tion techniques to collect user feedback for iden- tifying important concepts for a summary. Our models show that interactively collecting feedback consistently steers a general summary towards a user-desired personalized summary. We empiri- cally checked the validity of our approach on stan- dard datasets using simulated user feedback and observed that our framework shows promising re- sults in terms of producing personalized multi- document summaries.</p><p>As future work, we plan to investigate more sophisticated sampling strategies based on active learning and concept graphs to incorporate lexical- semantic information for concept selection. We also plan to look into ways to propagate feedback to similar and related concepts with partial feed- back, to reduce the total amount of feedback. This is a promising direction as we have shown that in- teractive methods help to create user-desired per- sonalized summaries, and with minimum amount of feedbacks, it has propitious use in scenarios where user-adapted content is a requirement.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 comparesFigure 2 :</head><label>22</label><figDesc>Figure 2 compares the ROUGE-2 scores and the amount of feedback used over time when applied to the DBS and the DUC'04 corpus. We can see from the figure that all models show an improvement of +.45 ROUGE-2 after merely 4 iterations</figDesc></figure>

			<note place="foot" n="1"> http://duc.nist.gov/ 2 http://www.nist.gov/tac/</note>

			<note place="foot" n="3"> https://github.com/miso-belica/sumy 4 https://github.com/boudinfl/sume</note>

			<note place="foot" n="5"> https://github.com/UKPLab/ acl2017-interactive_summarizer</note>

			<note place="foot" n="7"> We prune bigrams consisting of only functional words.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work has been supported by the German Re-search Foundation as part of the Research Training Group Adaptive Preparation of Information from Heterogeneous Sources (AIPHES) under grant No. GRK 1994/1. We also acknowledge the use-ful comments and suggestions of the anonymous reviewers.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Bridging the gap between extractive and abstractive summaries: Creation and evaluation of coherent extracts from heterogeneous sources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Darina</forename><surname>Benikova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margot</forename><surname>Mieskes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><forename type="middle">M</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/C16-1099" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on Computational Linguistics (COLING)</title>
		<meeting>the 26th International Conference on Computational Linguistics (COLING)<address><addrLine>Osaka, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1039" to="1050" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Jointly learning to extract and compress</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Gillick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL/HLT)</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL/HLT)<address><addrLine>Portland, OR, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="481" to="490" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Aspect-based personalized text summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shlomo</forename><surname>Berkovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ingrid</forename><surname>Zukerman</surname></persName>
		</author>
		<idno type="doi">10.1007/978-3-540-70987-931</idno>
		<ptr target="https://doi.org/10.1007/978-3-540-70987-931" />
	</analytic>
	<monogr>
		<title level="m">Adaptive Hypermedia and Adaptive Web-Based Systems. Proceedings of the 5th International Conference</title>
		<meeting><address><addrLine>Berlin/Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="267" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Concept-based summarization using integer linear programming: From concept pruning to multiple optimal solutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Boudin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Mougard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoit</forename><surname>Favre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMLNP)</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing (EMLNP)<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1914" to="1918" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">TGSum: Build Tweet Guided Multi-Document Summarization Dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziqiang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengyao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<ptr target="http://www.aaai.org/ocs/index.php/AAAI/AAAI16" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence (AAAI)</title>
		<meeting>the Thirtieth AAAI Conference on Artificial Intelligence (AAAI)<address><addrLine>Phoenix, AZ, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2906" to="2912" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Abstracts produced using computer assistance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">C</forename><surname>Craven</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="745" to="756" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<idno type="doi">10.1002/(SICI)1097-4571</idno>
		<idno>51:8 &lt;745::AID-ASI70&gt;3.0.CO;2-Z</idno>
		<ptr target="https://doi.org/10.1002/(SICI)1097-4571" />
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Usermodel based personalized summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Díaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Gervás</surname></persName>
		</author>
		<idno type="doi">10.1016/j.ipm.2007.01.009</idno>
		<ptr target="https://doi.org/10.1016/j.ipm.2007.01.009" />
	</analytic>
	<monogr>
		<title level="j">Process Management</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1715" to="1734" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">LexRank: Graph-based Lexical Centrality As Salience in Text Summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Günes</forename><surname>Erkan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dragomir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Radev</surname></persName>
		</author>
		<ptr target="https://www.jair.org/papers/paper1523.html" />
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="457" to="479" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A scalable global model for summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Gillick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoit</forename><surname>Favre</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/W09-1802" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Integer Linear Programming for Natural Langauge Processing</title>
		<meeting>the Workshop on Integer Linear Programming for Natural Langauge Processing<address><addrLine>Boulder, CO, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="10" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Generic text summarization using relevance measure and latent semantic analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yihong</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Liu</surname></persName>
		</author>
		<idno type="doi">10.1145/383952.383955</idno>
		<ptr target="https://doi.org/10.1145/383952.383955" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)</title>
		<meeting>the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)<address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="19" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Active learning for interactive machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesús</forename><surname>González-Rubio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Ortiz-Martínez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Casacuberta</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/E12-1025" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics (EACL)</title>
		<meeting>the 13th Conference of the European Chapter of the Association for Computational Linguistics (EACL)<address><addrLine>Avignon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="245" to="254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Exploring content models for multi-document summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aria</forename><surname>Haghighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucy</forename><surname>Vanderwende</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/N09-1041" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)</title>
		<meeting>Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)<address><addrLine>Boulder, CO, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="362" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A repository of state of the art and competitive baseline summaries for generic news summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">M</forename><surname>Conroy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoˆıtbenoˆıt</forename><surname>Favre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
		</author>
		<ptr target="http://www.lrec-conf.org/proceedings/lrec2014/summaries/1093.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC). Reykjavik</title>
		<meeting>the Ninth International Conference on Language Resources and Evaluation (LREC). Reykjavik<address><addrLine>Iceland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1608" to="1616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Context-enhanced personalized social summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Po</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghong</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>Teng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujing</forename><surname>Guo</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/C12-1075" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on Computational Linguistics (COLING)</title>
		<meeting>the 24th International Conference on Computational Linguistics (COLING)<address><addrLine>Mumbai, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1223" to="1238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Accurate unlexicalized parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
		<idno type="doi">10.3115/1075096.1075150</idno>
		<ptr target="https://doi.org/10.3115/1075096.1075150" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st Annual Meeting on Association for Computational Linguistics (ACL)</title>
		<meeting>the 41st Annual Meeting on Association for Computational Linguistics (ACL)<address><addrLine>Sapporo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="423" to="430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Neural interactive translation prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Knowles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the Association for Machine Translation in the Americas (AMTA)</title>
		<meeting>the Conference of the Association for Machine Translation in the Americas (AMTA)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Active learning with support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Kremer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kim</forename><surname>Steenstrup Pedersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Igel</surname></persName>
		</author>
		<idno type="doi">10.1002/widm.1132</idno>
		<ptr target="https://doi.org/10.1002/widm.1132" />
	</analytic>
	<monogr>
		<title level="j">Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="313" to="326" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Using supervised bigram-based ILP for extractive summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xian</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/P13-1099" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1004" to="1013" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">ROUGE: A Package for Automatic Evaluation of Summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/W04-1013" />
	</analytic>
	<monogr>
		<title level="m">Text Summarization Branches Out: Proceedings of the ACL-04 Workshop</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="74" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">NLTK: The Natural Language Toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Loper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<idno type="doi">10.3115/1118108.1118117</idno>
		<ptr target="https://doi.org/10.3115/1118108.1118117" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL-02 Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics</title>
		<meeting>the ACL-02 Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="63" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The automatic creation of literature abstracts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">P</forename><surname>Luhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Journal of Research and Development</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="159" to="165" />
			<date type="published" when="1958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title/>
		<idno type="doi">10.1147/rd.22.0159</idno>
		<ptr target="https://doi.org/10.1147/rd.22.0159" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A study of global inference algorithms in multi-document summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<idno type="doi">10.1007/978-3-540-71496-551</idno>
		<ptr target="https://doi.org/10.1007/978-3-540-71496-551" />
	</analytic>
	<monogr>
		<title level="m">Advances in Information Retrieval. Proceedings of the 29th European Conference on IR Research</title>
		<meeting><address><addrLine>Berlin/Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007" />
			<biblScope unit="volume">4425</biblScope>
			<biblScope unit="page" from="557" to="564" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">TextRank: Bringing Order into Text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Tarau</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/W04-3252" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2004 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="404" to="411" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno>CoRR abs/1301.3781</idno>
		<ptr target="http://arxiv.org/abs/1301.3781" />
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A Web-based English Abstract Writing Tool Using a Tagged E-J Parallel Corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masumi</forename><surname>Narita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuya</forename><surname>Kurokawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takehito</forename><surname>Utsuro</surname></persName>
		</author>
		<ptr target="http://www.lrec-conf.org/proceedings/lrec2002/sumarios/137.htm" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third International Conference on Language Resources and Evaluation (LREC)</title>
		<meeting>the Third International Conference on Language Resources and Evaluation (LREC)<address><addrLine>Las Palmas, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Computeraided Summarisation: What the User Really Wants</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Constantin</forename><surname>Orˇasanorˇasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Hasler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC)</title>
		<meeting>the 5th International Conference on Language Resources and Evaluation (LREC)</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Italy</forename><surname>Genoa</surname></persName>
		</author>
		<ptr target="http://www.lrec-conf.org/proceedings/lrec2006/summaries/52.html" />
		<imprint>
			<biblScope unit="page" from="1548" to="1551" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">CAST: a computer-aided summarisation tool</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Constantin</forename><surname>Orˇasanorˇasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Mitkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Hasler</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/E03-1066" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the tenth conference on European chapter of the Association for Computational Linguistics (EACL)</title>
		<meeting>the tenth conference on European chapter of the Association for Computational Linguistics (EACL)<address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="135" to="138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">An assessment of the accuracy of automatic evaluation in summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karolina</forename><surname>Owczarzak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">M</forename><surname>Conroy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoa</forename><forename type="middle">Trang</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/W12-2601" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of Workshop on Evaluation Metrics and System Comparison for Automatic Summarization</title>
		<meeting>Workshop on Evaluation Metrics and System Comparison for Automatic Summarization<address><addrLine>Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Automatic Query-based Personalized Summarization That Uses Pseudo Relevance Feedback with NMF</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sun</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dong Un An</surname></persName>
		</author>
		<idno type="doi">10.1145/2108616.2108690</idno>
		<ptr target="https://doi.org/10.1145/2108616.2108690" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th International Conference on Ubiquitous Information Management and Communication (ICUIMC). pages</title>
		<meeting>the 4th International Conference on Ubiquitous Information Management and Communication (ICUIMC). pages</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="1" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The evaluation of accessibility, usability, and user experience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helen</forename><surname>Petrie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nigel</forename><surname>Bevan</surname></persName>
		</author>
		<idno type="doi">10.1201/9781420064995-c20</idno>
		<ptr target="https://doi.org/10.1201/9781420064995-c20" />
	</analytic>
	<monogr>
		<title level="j">Human Factors and Ergonomics</title>
		<editor>Constantine Stephanidis</editor>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2009" />
			<publisher>CRC Press</publisher>
		</imprint>
	</monogr>
	<note>The Universal Access Handbook</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Platt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances In Large Margin Classifiers</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="61" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Extended recommendation framework: Generating the text of a user review as a personalized summary</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mickaël</forename><surname>Poussevin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Guigue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Gallinari</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-1448/paper7.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on New Trends on Content-Based Recommender Systems co-located with 9th ACM Conference on Recommender Systems</title>
		<meeting>the 2nd Workshop on New Trends on Content-Based Recommender Systems co-located with 9th ACM Conference on Recommender Systems<address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-09-16" />
			<biblScope unit="page" from="34" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">GermEval2014: Nested Named Entity Recognition with Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judith</forename><surname>Eckle-Kohler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Schnober</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungi</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop Proceedings of the 12th Edition of the KONVENS Conference</title>
		<meeting><address><addrLine>Hildesheim, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="117" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Multiple aspect summarization using integer linear programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristian</forename><surname>Woodsend</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/D12-1022" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP/CoNLL)</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP/CoNLL)<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="233" to="243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Automatic summarization of open-domain multiparty dialogues in diverse genres</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Zechner</surname></persName>
		</author>
		<idno type="doi">10.1162/089120102762671945</idno>
		<ptr target="https://doi.org/10.1162/089120102762671945" />
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="447" to="485" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A study for documents summarization based on personal annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haiqin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng Chen Wei-Ying</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingsheng</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the HLT-NAACL 03</title>
		<meeting>the HLT-NAACL 03</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
				<idno type="doi">10.3115/1119467.1119473</idno>
		<ptr target="https://doi.org/10.3115/1119467.1119473" />
		<title level="m">on Text Summarization Workshop</title>
		<imprint>
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
