<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:38+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Entities&apos; Sentiment Relevance</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>June 23-25</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zvi</forename><surname>Ben-Ami</surname></persName>
							<email>zvi.benami@mail.huji.a c.il</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronen</forename><surname>Feldman</surname></persName>
							<email>ronen.feldman@huji.ac .il</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Binyamin</forename><surname>Rosenfeld</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">The Hebrew University Jerusalem</orgName>
								<address>
									<country key="IL">ISRAEL</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">The Hebrew University Jerusalem</orgName>
								<address>
									<country>ISRAEL, USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Entities&apos; Sentiment Relevance</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers)</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers) <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="87" to="92"/>
							<date type="published">June 23-25</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Sentiment relevance detection problems occur when there is a sentiment expression in a text, and there is the question of whether or not the expression is related to a given entity or, more generally, to a given situation. The paper discusses variants of the problem, and shows that it is distinct from other somewhat similar problems occurring in the field of sentiment analysis and opinion mining. We experimentally demonstrate that using the information about relevancy significantly affects the final sentiment evaluation of the entities. We then compare a set of different algorithms for solving the relevance detection problem. The most accurate results are achieved by algorithms that use certain document level information about the target entities. We show that this information can be accurately extracted using supervised classification methods.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Sentiment extraction by modern sentiment analy- sis (SA) systems is usually based on searching the input text for sentiment-bearing words and expressions, either general (language-wide) or domain-specific. In most common SA approach- es, each such expression carries a polarity value ("positive" or "negative") which is possibly weighted. The sum of all polarity values from all expressions found in a text becomes the senti- ment score for the whole text.</p><p>People are, however, usually interested in sen- timents regarding some entity or situation, and not in sentiments of a particular document. A natural way to make the SA more focused is to explicitly bind each sentiment expression to a specific entity, or to a small set of entities from among all entities mentioned in the document.</p><p>The choice of which entity to bind a sentiment expression to, can be made according to the proximity (physical, syntactical, and/or semantic) and/or salience of the entities.</p><p>In this paper, we argue that all of these meth- ods can be useful in different contexts, and so the best single algorithm should use all available proximity information, of all kinds, together with additional context information -position in the document, section, or paragraph; proximity of other entities; lexical contents; etc. One of the most important context information is the type of relation between the target entity and the docu- ment -whether the entity is the main topic of the document, or one of several main topics, or men- tioned in passing, etc.</p><p>Another layer that we'd like to add concerns the interaction of different entity types during SA. In a typical situation, there is only one entity type which is the target for SA. In such cases, clearly distinguishing between the relevancy of target and non-target entities types is not essen- tial. For example, when the general topic is a COMPANY, and there is a sentiment expression referring to a PERSON or a PRODUCT, this sentiment expression is still relevant to the com- pany and can be regarded as such. In other situa- tions, SA users may be specifically interested in an interaction between entities of different types. For example, in a medical forum setting, it may be interesting to know the users' sentiments re- garding a given DRUG in the context of a given DISEASE. We will show that such situations are modeled well enough using intersections of re- gions of relevance of the participating entity types, with the relevance region for each type calculated separately.</p><p>We purposefully exclude possible interactions between entities of the same type, because they behave in a different way. The precise analysis of such interactions is a different topic from rele-vance detection, and so it is mostly ignored in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>The task of SA has drawn the attention of many researchers worldwide ( <ref type="bibr" target="#b2">Connor et al., 2010;</ref><ref type="bibr" target="#b7">Liu, 2012;</ref><ref type="bibr" target="#b10">Loughran and Mcdonald, 2010;</ref><ref type="bibr" target="#b13">Pang and Lee, 2004;</ref><ref type="bibr" target="#b17">Turney, 2002</ref>). While most SA re- search is focused on discovering and classifying the expressions, some are also concerned with the targets of the expressions and explicitly iden- tify the syntactic targets of sentiment expressions ( <ref type="bibr" target="#b13">Pang and Lee, 2004</ref>).</p><p>Other related works belong to the Passage Re- trieval field, since the relevance detection prob- lem can be construed as a specific form of pas- sage retrieval problem ( <ref type="bibr" target="#b8">Liu and Croft, 2002;</ref><ref type="bibr" target="#b16">Tiedemann and Mur, 2008)</ref>. Different approach- es were suggested for passage retrieval <ref type="bibr" target="#b0">(Buscaldi et al., 2010;</ref><ref type="bibr" target="#b1">Comas et al., 2012;</ref><ref type="bibr" target="#b4">Hearst, 1997;</ref><ref type="bibr" target="#b5">Lafferty et al., 2001;</ref><ref type="bibr" target="#b6">Lin et al., 2012;</ref><ref type="bibr" target="#b8">Liu and Croft, 2002;</ref><ref type="bibr" target="#b9">Lloret et al., 2012;</ref><ref type="bibr" target="#b11">O'Connor et al., 2013;</ref><ref type="bibr" target="#b12">Otterbacher et al., 2009;</ref><ref type="bibr" target="#b14">Salton et al., 1993;</ref><ref type="bibr" target="#b18">Wachsmuth, 2013)</ref>, some are more sophis- ticated than others.</p><p>The closest approach to ours is the one of <ref type="bibr" target="#b15">Scheible and Schütze (2013)</ref>, but in contrast to them, we strive to discover sentiments' relevance for all entities (of a given type) mentioned in the document, not necessarily topical.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Entity Relevance</head><p>An instance of the sentiment relevance detection problem for a single entity consists of a text doc- ument, a sentiment expression within the docu- ment, and a target entity. The task is a binary decision: 'relevant' vs. 'irrelevant'. To solve this task, we can use any information that can be found by analyzing the document. Thus, we can assume that we know the parse trees of all sen- tences and the locations of all references of all entities in the document, including co-references.</p><p>In addition, we make use of an extra piece of information for each target entity -its "status within the document", or "document type with respect to the entity". We distinguish between several types which are intuitively clearly differ- ent:  'Target' -the entity is the main topic of the document;  'Accidental' -the entity is not the main topic of the document, and is mentioned in passing;</p><p> 'RelationTarget' -the main topic of the doc- ument is a relation between the entity and some other entities of the same type;  'ListTarget' -the entity is one of a few equal- ly important topics, dealt with sequentially.</p><p>In the datasets we use for experiments, each entity is manually annotated with its status with- in the document, which allows us to directly ob- serve the influence of this data on the accuracy of relevance discernment. We also show that this data can be automatically extracted using super- vised classification.</p><p>Since this paper is primarily a study of senti- ment relevance, the actual sentiment expressions are not always labeled in our datasets. Instead, relevance ranges are annotated for each entity, in the style of passage retrieval problems, with the expectation that sentiment expressions relevant to an entity only appear in the parts of the docu- ment that are labeled as "relevant", and converse- ly, that all expressions appearing in parts labeled "irrelevant" are irrelevant. This way of annotat- ing allows the comparing of different relevance detection strategies independently of the main sentiment extraction tool.</p><p>All of the algorithms discussed in this paper use the same document processing methods, thus allowing us to compare the algorithms them- selves independent of the quality and specifics of the underlying NLP.</p><p>The multiple-entity relevance problem is dis- tinguished from the single-entity relevance prob- lem by the requirement for the sentiment expres- sion to be relevant to several entities of different types. The problem is close to Relation Extrac- tion in this sense. The examples we are interested in are in the medical domain and deal with three main entity types: PERSON, DRUG, and DISEASE, where PERSON is restricted to known physicians. While each of the entity types can be the target of a sentiment expression, the more interesting questions in this domain involve multiple entities, specifically, DRUG + DISEASE ("how effective is this drug for this disease?"), and PERSON + DRUG + DISEASE ("what does this physician say about using this drug to cure this disease?").</p><p>We solve the multiple-entity relevance prob- lem by intersecting the relevance ranges of dif- ferent-type entities, thus reducing the problem to the single-entity relevance detection. As such, the experiments regarding the multiple-entity relevance need only check the accuracy of this reduction. In the medical domain, at least, this accuracy appears to be adequate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Relevance Algorithms</head><p>Each algorithm receives, as input, the text of the document, with labeled reference of the target entity and other entities of the same type. The labeled references also include all coreferential references, extracted automatically by an NLP system. The input text also includes labeled can- didate sentiment expressions, either manually labeled or automatically extracted by a rele- vance-ignoring SA system 1 . The task of the algo- rithms is to label each candidate expression as relevant or irrelevant to the target entity. The algorithms are evaluated according to the accura- cy (recall, precision, and F1) of this labeling of individual sentiment expressions.</p><p>This method produces a reasonably well- understandable quality measure (the percentage of expressions that the algorithms get right or wrong), and also allows us to compare algo- rithms focused on individual expressions and algorithms working on text ranges. The algo- rithms we evaluate are as follows:  Baseline -Every expression is declared rele- vant. This is the standard mode of operation of document-level SA tools, although it is usually only applied to the 'Target' entities -the main topic(s) of the document.  Physical-proximity-based -A text-range fo- cused algorithm, which labels pieces of text as relevant or irrelevant according to their place- ment relative to the references of the target en- tity and other entities of the same type, as well as some other contextual clues, such as para- graph boundaries. Generally, the mentioning of an entity starts its relevance range (and stops the relevance range of the previously men- tioned entity). For the first entity reference in a paragraph, the range also extends backward to the beginning of the sentence. There are three flavors of the algorithm, specifically adapted for different document-types-with-respect-to- the-target-entity: o 'Proximity-Accidental' -stops relevance ranges at paragraph boundaries, o 'Proximity-Targeted' -restarts relevance ranges at paragraph boundaries (every para- <ref type="bibr">1</ref> In our experiments, we also use a standalone automatic Financial SA system from <ref type="bibr" target="#b3">Feldman et al. (2010)</ref>, working in the 'ignore relevance' mode, which (1) finds and labels all entities of the target type(s); (2) resolves all corefer- ences for the target entity type(s); (3) finds and labels all sentiment expressions, regardless of their relevance; and (4) provides dependency parses for all sentences in the corpus.</p><p>graph is assumed relevant at the start, unless another entity is mentioned). o 'Proximity-List' -interpolates relevance ranges over intermission paragraphs, unless they are explicitly irrelevant (e.g., contain- ing references of other entities of the same type).  Syntactic-proximity-based -An expression- focused algorithm, which labels expressions as relevant or irrelevant according to their dis- tance to various entity references in the de- pendency parse graph. There are two flavors of the algorithm: direct and reverse. The former considers an expression relevant only if it is closest to the target entity from among all enti- ties of the same type, and the distance is suffi- ciently close. The latter considers an expres- sion irrelevant only if it has the above- described relation to some non-target entity of the same type. The rationale for the two flavors is the distinction between 'Targeted' and 'Acci- dental' document types regarding the target en- tity. For the 'Accidental' entities, a sentiment expression is assumed to be relevant only if it is explicitly connected to the entity. For 'Tar- geted' entities, an expression is irrelevant only if it is explicitly connected to some other entity of the same type.  Classification-based -This algorithm consid- ers each candidate sentiment expression as an instance of a binary classification problem, to be solved using supervised classification. For evaluating this algorithm, some part of the test corpus is used for training, and the other for testing, with N-fold cross-validation. The fea- tures for classification may use any infor- mation present in the input.</p><p>In the current experiments, we use refer- ences of target and non-target entities, appear- ances of paragraph and document boundaries, length of syntactic connections to target and non-target entities, when available, and explicit entity status within documents, when available. The (binary) classification features are built from sequences of up to 5 occurrences of the above-described pieces, with the pieces ap- pearing before and after the sentiment expres- sion tracked separately. For classification, we use a linear classifier with Large Margin train- ing (regularized perceptron, as discussed in <ref type="bibr" target="#b15">Scheible and Schütze, (2013)</ref>).  Sequence-classification-based -The algo- rithm uses exactly the same features as the di- rect classification-based above, but instead of considering each expression separately, it con-siders them as a sequence, one per document. So, instead of a Large Margin binary classifier, a probabilistic sequence classifier is used (CRF, as discussed in <ref type="bibr" target="#b5">Lafferty et al. (2001)</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>For the experiments, we use two manually- annotated corpora 2 , a financial corpus 3 and a medical 4 corpus. In the Financial corpus, COM- PANIEs are used as target entities and in the medical corpus, DISEASEs, DRUGs and PER- SONs are the entity types that are used as target entities. For the purpose of the experiments, we are interested only in single-entity sentiments about DRUGs, and multiple-entity sentiments about DRUGs + DISEASEs, and DRUGs + DISEASEs + PERSONs.</p><p>The evaluation metrics in all of the experi- ments are precision, recall, and F1. For the clas- sification-based algorithms, unless stated other- wise, we use 10-fold cross-validation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experiment: Importance of relevance</head><p>In the first experiment, we demonstrate the im- portance of using relevance when calculating the consolidated sentiment score of an entity within a set of documents. For each entity, we set the 'correct' consolidated sentiment score to the av- erage of polarities of all sentiments in a corpus which are labeled as relevant to the entity. Then, we compare the correct value to the two scores calculated without considering relevance:  'Baseline' -the average of polarities of all sen- timents in all documents where the entity is mentioned, and  'TargetedOnly' -the average of polarities of all sentiments in the documents where the enti- ty is labeled as target (main topic of the docu- ment). This case models the typical state of a relevance-agnostic SA system. For this evaluation, we only compare the sign of the final sentiment scores, without considering their magnitudes (unless it is close to zero, in <ref type="bibr">2</ref> Fully annotating texts for semantic relevance is an arduous task, thus the used annotated corpora are relatively small. Sample can be found at http://goo.gl/6HONHP. <ref type="bibr">3</ref> A corpus of 160 financial news documents on at least one entity of interest, of average size ~5Kb, downloaded from various financial news websites. The dataset mentions 424 different companies. <ref type="bibr">4</ref> A corpus of 160 documents, of average size ~7Kb, down- loaded following Google queries on a set of a few com- mon drugs and diseases. The dataset mentions 722 differ- ent people, 46 diseases, and 175 drugs.</p><p>which it is considered 'neutral'). The errors at this level indicate definite SA errors -miscalculating entity's sentiment into its opposite. The results of the evaluation are as follows: The 'Baseline' scores show a large difference from the correct scores, with 33% and 38% of entities having wrong final polarity in the finan- cial (COMPANY) and medical (DRUG) do- mains, respectively. The 'TargetedOnly' scores are somewhat closer to correct, with 12% and 28% of entities with incorrect final polarities. However, the 'TargetedOnly' method naturally suffers from a very low recall, with only 19% and 38% of entities covered in the financial and medical domains, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experiment: Influence of entity status</head><p>In this experiment, we compare the performance of various algorithms while either providing or withholding the information about the document- type-with-respect-to-the-target-entity.</p><p>The performance of the physical proximity al- gorithms on the financial corpus is shown at the top left hand side of <ref type="table" target="#tab_0">Table 1</ref>. The set of all in- stances of relevance detection problems in the corpus (an instance consists of a sentiment ex- pression within a text, together with a target enti- ty) is divided into three subsets, according to the status of the target entity within the document. As expected, the three flavors of the physical proximity algorithm perform much better on the corpus subsets they are adapted to. At the bottom left hand side of <ref type="table" target="#tab_0">Table 1</ref>, we similarly show the performance of the two flavors of the syntax- proximity-based algorithm on the medical do- main (DRUG entities). Same as above, there is a large difference in the performance of the two flavors of the algorithm on different subsets of the problem set. Finally, at the top of <ref type="table" target="#tab_1">Table 2</ref>, we compare the performance of the two classifica- tion-based algorithms on the two (whole) prob- lem sets, while either keeping or withholding the entity status information from the classifier. The difference in results is less pronounced here, but is still noticeable. The reason for the smaller dif- ference, we hypothesize, is the ability of the clas- sifiers to partially infer the entity status from the various context clues that are used as classifica- tion features (see the experiment 5.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Experiment: Automatic identification of</head><p>entity status using classification.</p><p>In this experiment, we confirm that it is possible to identify the entity status within documents using supervised classification.  The results of direct evaluation show that the accuracies of the Medical and Financial corpora (using 10-fold X-validation) are 87.8% and 82.2% respectively, and the accuracy when using the Medical corpus for training the Financial corpus for testing and vice versa, are 78.2% and 86.1% , respectively.</p><p>The results of relevance detection using the automatically extracted entity status values are shown at the right hand side of <ref type="table" target="#tab_0">Table 1 and in the  middle of Table 2</ref>, which utilize the same da- tasets and algorithms as at the left hand side of <ref type="table" target="#tab_0">Table 1</ref> and at the top of <ref type="table" target="#tab_1">Table 2</ref>. As can be seen from the tables, the drop in performance is small, demonstrating the success of classification-based extraction of entity status information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Experiment: Cross-domain applicability</head><p>In this experiment, we test how well the classifi- ers trained on data from one domain work on input from a different domain.</p><p>The classification results using different types of training data are shown in  <ref type="table" target="#tab_2">Table 3</ref>. Performance of classification-based algorithms using different training data (F1).</p><p>The table confirms general independence of the classification performance on the domain. Comparing the 2-fold and 10-fold cross- validation results (the difference is equivalent to doubling the amount of training data), shows that the amount of training data is sufficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Experiment: Overall performance of algorithms</head><p>In this experiment, we simply compare the over- all accuracy of various algorithms for relevance discernment, operating at their best parameters. The results are shown at the bottom of <ref type="table" target="#tab_1">Table 2</ref>.</p><p>Overall, classification-based algorithms perform better than the deterministic ones, with sequence- classification performing significantly better than direct classification. Syntactic proximity-based is precise, but has relatively low recall, reducing its overall performance. Physical proximity-based is simplest, and produce reasonably high overall results, although worse than the best-performing classification-based methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>The results are mostly intuitively understood and confirm the expectations. We confirmed that relevance detection is essential for producing correct consolidated SA results. We found that the entity status within the document is one of the important clues for solving the relevance detection problem, and showed that this infor- mation can be effectively automatically extracted using supervised classification. We also com- pared several algorithms for relevance detection, with the results that classification-based algo- rithms generally outperform simpler ones based on the same clues, although a very simple prox- imity-based algorithm performs reasonably well if allowed to use the entity status information. <ref type="table" target="#tab_0">Targeted  List  Whole  Accidental  Targeted  List  Whole  Proximity-Accidental  84/43/57  93/76/84  92/74/82  92/72/81  60 (+2.6</ref> </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 .</head><label>1</label><figDesc></figDesc><table>Performance of different algorithms on three subsets of the corpus with a different status of 
the target entity within the document. 

Experiment 
Algorithm 
Financial 
Medical 
Experiment 5.2 
(Prec./ Rec,/F1). 

Classification (with entity 
status info) 

90/86/88 
84/88/86 

Classification (without 
entity status info) 

89/85/87 
87/81/84 

Sequence Classification 
(with entity status info) 

96/84/90 
99/84/91 

Sequence Classification 
(without entity status info) 

96/83/89 
95/85/90 

Experiment 5.3 
(F1, (diff. in F1 
from exp. 5.2)) 

Classification 
86.7 (-0.9) 
83.9 (-2.0) 
Sequence Classification 
89.7 (+0.1) 
90.9 (-0.3) 

Experiment 5.5 
(F1) 

Baseline 
37.2 
28.6 
Physical Proximity 
84.1 
79.5 
Syntactic-Proximity 
43.8 
54.6 
Classification 
87.6 
85.9 
Sequence-Classification 
91.2 
89.6 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 .</head><label>2</label><figDesc></figDesc><table>Performance of different algorithms 
on the different domains. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 3 .</head><label>3</label><figDesc></figDesc><table>Classification 
Sequence classification 
Medical 2-fold/10-fold 
84.6/85.9 
85.7/89.6 
Train on Fin, test on Med 
83.5 
86.8 
Financial 2-fold/10-fold 
86.1/87.6 
90.3/91.2 
Train on Med, test on Fin 
85.4 
91.0 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work is supported by the Israel Ministry of Science and Technology Center of Knowledge in Machine Learning and Artificial Intelligence and the Israel Ministry of Defense.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 5.2 (Precision/Recall/F1) Experiment 5.3 ( F1, (diff. in F1 from exp. 5.2) Accidental</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Answering questions with an n-gram based passage retrieval engine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Buscaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gómez-Soriano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sanchis</surname></persName>
		</author>
		<idno type="doi">doi:10.1007/s10844-009-0082-y</idno>
	</analytic>
	<monogr>
		<title level="j">J. Intell. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="113" to="134" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Sibyl, a factoid question-answering system for spoken documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">R</forename><surname>Comas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Turmo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Màrquez</surname></persName>
		</author>
		<idno type="doi">doi:10.1145/2328967.2328972</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page">40</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">From Tweets to Polls : Linking Text Sentiment to Public Opinion Time Series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">O</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Balasubramanyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>Routledge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth International AAAI Conference on Weblogs and Social Media</title>
		<meeting>the Fourth International AAAI Conference on Weblogs and Social Media</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="122" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The Stock Sonar-Sentiment Analysis of Stocks Based on a Hybrid Approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Rosenfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bar-Haim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fresko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Third Innovative Applications of Artificial Intelligence Conference</title>
		<meeting>the Twenty-Third Innovative Applications of Artificial Intelligence Conference</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1642" to="1647" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">TextTiling: segmenting text into multi-paragraph subtopic passages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Hearst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Linguist</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="33" to="64" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighteenth International Conference on Machine Learning (ICML-2001)</title>
		<meeting>the Eighteenth International Conference on Machine Learning (ICML-2001)</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A concept-based information retrieval approach for engineering domain-specific technical documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-T</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N.-W</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-H</forename><surname>Hsieh</surname></persName>
		</author>
		<idno type="doi">10.1016/j.aei.2011.12.003</idno>
		<ptr target="http://dx.doi.org/10.1016/j.aei.2011.12.003" />
	</analytic>
	<monogr>
		<title level="j">Adv. Eng. Informatics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="349" to="360" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Sentiment Analysis and Opinion Mining Synthesis Lectures on Human Language Technologies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Morgan &amp; Claypool Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Passage retrieval based on language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<idno type="doi">doi:10.1145/584792.584854</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference on Information and Knowledge Management, CIKM &apos;02</title>
		<meeting>the Eleventh International Conference on Information and Knowledge Management, CIKM &apos;02<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="375" to="382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Towards a unified framework for opinion retrieval, mining and summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lloret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Balahur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gómez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Montoyo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Palomar</surname></persName>
		</author>
		<idno type="doi">doi:10.1007/s10844-012-0209-4</idno>
	</analytic>
	<monogr>
		<title level="j">J. Intell. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="711" to="747" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">When is a Liability not a Liability ? Textual Analysis , Dictionaries , and 10-Ks Journal of Finance , forthcoming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">I M</forename><surname>Loughran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Finance</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="35" to="65" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning to Extract International Relations from Political Context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>O&amp;apos;connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1094" to="1104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Biased LexRank: Passage retrieval using random walks with question-based priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Otterbacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Erkan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Radev</surname></persName>
		</author>
		<idno type="doi">10.1016/j.ipm.2008.06.004</idno>
		<ptr target="http://dx.doi.org/10.1016/j.ipm.2008.06.004" />
	</analytic>
	<monogr>
		<title level="j">Inf. Process. Manag</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="42" to="54" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">A Sentimental Education : Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Approaches to passage retrieval in full text information systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
		<idno type="doi">doi:10.1145/160688.160693</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;93</title>
		<meeting>the 16th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;93<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1993" />
			<biblScope unit="page" from="49" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Sentiment Relevance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Scheible</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="954" to="963" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Simple is best: experiments with different document segmentation strategies for passage retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tiedemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Coling 2008: Proceedings of the 2nd Workshop on Information Retrieval for Question Answering, IRQA &apos;08</title>
		<meeting><address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="17" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Thumbs Up or Thumbs Down ? Semantic Orientation Applied to Unsupervised Classification of Reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Turney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Association for Computational Linguistics (ACL)</title>
		<meeting>the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="417" to="424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Information Extraction as a Filtering Task Categories and Subject Descriptors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">To Appear in Proc. of the 22th ACM CIKM</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
