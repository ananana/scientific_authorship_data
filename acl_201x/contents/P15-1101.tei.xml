<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:36+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Sentence-level Emotion Classification with Label and Context Dependence </title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 26-31, 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shoushan</forename><surname>Li</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Collaborative Innovation Center of Novel Software Technology and Industrialization</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">† ‡</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Huang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Wang</surname></persName>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
							<email>gdzhou@suda.edu.cn</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="laboratory">Natural Language Processing Lab</orgName>
								<orgName type="institution">Soochow University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Sentence-level Emotion Classification with Label and Context Dependence </title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1045" to="1053"/>
							<date type="published">July 26-31, 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Predicting emotion categories, such as anger, joy, and anxiety, expressed by a sentence is challenging due to its inherent multi-label classification difficulty and data sparseness. In this paper, we address above two challenges by incorporating the label dependence among the emotion labels and the context dependence among the contextual instances into a factor graph model. Specifically, we recast sentence-level emotion classification as a factor graph inferring problem in which the label and context dependence are modeled as various factor functions. Empirical evaluation demonstrates the great potential and effectiveness of our proposed approach to sentence-level emotion classification. 1</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Predicting emotion categories, such as anger, joy, and anxiety, expressed by a piece of text encom- passes a variety of applications, such as online chatting ( <ref type="bibr" target="#b6">Galik et al., 2012)</ref>, news classification ( <ref type="bibr" target="#b11">Liu et al., 2013</ref>) and stock marketing <ref type="bibr" target="#b3">(Bollen et al., 2011</ref>). Over the past decade, there has been a substantial body of research on emotion classifi- cation, where a considerable amount of work has focused on document-level emotion classification.</p><p>Recently, the research community has become increasingly aware of the need on sentence-level emotion classification due to its wide potential ap- plications, e.g. the massively growing importance of analyzing short text in social media <ref type="bibr" target="#b8">(Kiritchenko et al., 2014;</ref><ref type="bibr" target="#b17">Wen and Wan, 2014</ref>). In general, sentence-level emotion classification ex- hibits two challenges. <ref type="bibr">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>* Corresponding author</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>……</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;S1&gt;她们都睡了，我蹑手蹑脚摸黑上了</head><p>床，凑上去想亲嫣一下，她突然一个转身， 小手'啪'地搭在了我的脸颊上。&lt;/S1&gt; &lt;S2&gt; 现在我终于如愿以偿。&lt;/S2&gt; &lt;S3&gt;感受着小手 的温度，享受着这份她对我的依恋，生怕动 一下，会让她的小手离我而去。&lt;/S3&gt;……</p><p>(English: …… &lt;S1&gt; The girls fall to sleep, so I make my way noiselessly onto the bed, wishing I could get a chance to give a kiss to Yan, suddenly she turn over to me and her little soft hand fall onto my face.&lt;/S1&gt; &lt;S2&gt;Praise the Lord, that is all I want.&lt;/S2&gt; &lt;S3&gt;Feeling the warm of her hand and the attachment she hold to me, I couldn't af- ford to move even a little, fearing I may lost her hand.&lt;/S3&gt;)……) -------------------------------------------------------------------  On one hand, like document-level emotion classification, sentence-level emotion classifica- tion is naturally a multi-label classification prob- lem. That is, each sentence might involve more than one emotion category. For example, as shown in <ref type="figure" target="#fig_1">Figure 1</ref>, in one paragraph, two sen- tences, i.e., S1 and S3, have two and three emotion categories respectively. Automatically classifying instances with multiple possible categories is sometimes much more difficult than classifying instances with a single label.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sentence-level Emotion Classification</head><p>On the other hand, unlike document-level emo- tion classification, sentence-level emotion classi- fication is prone to the data sparseness problem because a sentence normally contains much less content. Given the short text of a sentence, it is often difficult to predict its emotion due to the limited information therein. For example, in S2, only one phrase "如愿以偿(that is all I want)" ex- presses the joy emotion. Once this phrase fails to appear in the training data, it will be hard for the classifier to give a correct prediction according to the limited content in this sentence.</p><p>In this paper, we address above two challenges in sentence-level emotion classification by mod- eling both the label and context dependence. Here, the label dependence indicates that multiple emo- tion labels of an instance are highly correlated to each other. For instance, the two positive emo- tions, joy and love, are more likely to appear at the same time than the two counterpart emotions, joy and hate. The context dependence indicates that two neighboring sentences or two sentences in the same paragraph (or document) might share the same emotion categories. For instance, in <ref type="figure" target="#fig_1">Figure  1</ref>, S1, S2, and S3, from the same paragraph, all share the emotion category joy.</p><p>Specifically, we propose a factor graph, namely Dependence Factor Graph (DFG), to model the la- bel and context dependence in sentence-level emotion classification. In our DFG approach, both the label and context dependence are modeled as various factor functions and the learning task aims to maximize the joint probability of all these fac- tor functions. Empirical evaluation demonstrates the effectiveness of our DFG approach to captur- ing the inherent label and context dependence. To the best of our knowledge, this work is the first attempt to incorporate both the label and context dependence of sentence-level emotion classifica- tion into a unified framework.</p><p>The remainder of this paper is organized as fol- lows. Section 2 overviews related work on emo- tion analysis. Section 3 presents our observations on label and context dependence in the corpus. Section 4 proposes our DFG approach to sen- tence-level emotion classification. Section 5 eval- uates the proposed approach. Finally, Section 6 gives the conclusion and future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Over the last decade, there has been an explosion of work exploring various aspects of emotion analysis, such as emotion resource creation ( <ref type="bibr" target="#b19">Wiebe et al., 2005;</ref><ref type="bibr" target="#b12">Quan and Ren, 2009;</ref><ref type="bibr" target="#b20">Xu et al., 2010</ref>), writer's emotion vs. reader's emotion analysis ( <ref type="bibr" target="#b10">Lin et al., 2008;</ref><ref type="bibr" target="#b11">Liu et al., 2013)</ref>, emo- tion cause event analysis <ref type="bibr" target="#b4">(Chen et al., 2010</ref>), doc- ument-level emotion classification ( <ref type="bibr" target="#b0">Alm et al., 2005;</ref><ref type="bibr" target="#b9">Li et al., 2014</ref>) and sentence-level or short text-level emotion classification ( <ref type="bibr">Tokushisa et al., 2008;</ref><ref type="bibr" target="#b1">Bhowmick et al., 2009;</ref><ref type="bibr" target="#b21">Xu et al., 2012)</ref>. This work focuses on sentence-level emotion clas- sification.</p><p>Among the studies on sentence-level emotion classification, <ref type="bibr">Tokushisa et al. (2008)</ref> propose a data-oriented method for inferring the emotion of an utterance sentence in a dialog system. They leverage a huge collection of emotion-provoking event instances from the Web to deal with the data sparseness problem in sentence-level emotion classification. <ref type="bibr" target="#b1">Bhowmick et al. (2009)</ref> and <ref type="bibr" target="#b2">Bhowmick et al. (2010)</ref> apply KNN-based classi- fication algorithms to classify news sentences into multiple reader emotion categories. Although the multi-label classification difficulty has been no- ticed in their study, the label dependence is not exploited. More recently, <ref type="bibr" target="#b21">Xu et al. (2012)</ref> pro- poses a coarse-to-fine strategy for sentence-level emotion classification. They deal with the data sparseness problem by incorporating the transfer probabilities from the neighboring sentences to refine the emotion categories. To some extent, this can be seen a specific kind of context information. However, they ignore the label dependence by di- rectly applying Binary Relevance to overcome the multi-label classification difficulty.</p><p>Unlike all above studies, this paper emphasizes the importance of the label dependence and ex- ploits it in sentence-level emotion classification via a factor graph model. Moreover, besides the label dependence, our factor graph-based ap- proach incorporates the context dependence in a unified framework to further improve the perfor- mance of sentence-level emotion classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Observations</head><p>To better illustrate our motivation of modeling the label and context dependence, we systematically investigate both dependence phenomena in our evaluation corpus. The corpus contains 100 documents, randomly selected from <ref type="bibr" target="#b12">Quan and Ren (2009)</ref>. There are to- tally 2751 sentences and each of them is manually annotated with one or more emotion labels.   <ref type="table" target="#tab_0">Table 1</ref> shows the sentence distribution of the eight emotion categories. Obviously, the distribu- tion is a bit imbalanced. While about to one quar- ter of sentences express the emotion category love, only ~6% and ~10% express surprise and anger respectively, with the remaining 5 emotion cate- gories distributed rather evenly from ~20% to ~25%. <ref type="table" target="#tab_1">Table 2</ref> shows the numbers of the sen- tences grouped by the emotion labels they contain. From this table, we can see that more than half sentences have two or more emotion labels. This indicates the popularity of the multi-label issue in sentence-level emotion classification.</p><p>To investigate the phenomenon of label de- pendence, we first assume that  <ref type="figure" target="#fig_2">Figure 2</ref> shows the probability distribu- tion of most and least frequently-occurred pairs of emotion categories, with left four most fre- quently-occurred and right four least frequently- occurred, among all 28 pairs. From this figure, we can see that some pairs, e.g., joy and love, are much more likely to be taken by one sentence than some other pairs, e.g. joy and anger. Finally, we investigate the phenomenon of the context dependence by calculating the probabili- ties that two instances k x and l x have at least one identical emotion label, i.e., )   <ref type="figure" target="#fig_5">Figure 3</ref> shows the probabilities that two in- stances have at least one identical emotion label in different settings, where neighbor, paragraph, document and random mean two neighboring in- stances, two instances from the same paragraph, two instances from the same document, and two instances from a random selection, respectively. From this figure, we can see that two instances from the same context are much more likely to take an identical emotion label than two random instances.</p><formula xml:id="formula_0">kl p y y  （ in different settings.</formula><p>From above statistics, we come to two basic ob- servations: 1) Label dependency: One sentence is more likely to take some pair of emotion labels, e.g.,</p><p>hate and angry than some other pair of emo- tion labels, e.g., hate and happy. 2) Context dependency: Two instances from the same context are more likely to share the same emotion label than those from a random selec- tion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Dependence Factor Graph Model</head><p>In this section, we propose a dependence factor graph (DFG) model for learning emotion labels of sentences with both label and context dependence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Preliminary</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Factor Graph</head><p>A factor graph consists of two layers of nodes, i.e., variable nodes and factor nodes, with links be- tween them. The joint distribution over the whole set of variables can be factorized as a product of all factors. <ref type="figure" target="#fig_4">Figure 4</ref> gives an example of our de- pendence factor graph (DFG) when two instances, i.e., sentence-1 and sentence-2 are involved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Binary Relevance</head><p>A popular solution to multi-label classification is called binary relevance which constructs a binary classifier for each label, resulting a set of inde-  pendent binary classification problems <ref type="bibr" target="#b15">(Tsoumakas and Katakis, 2007;</ref><ref type="bibr" target="#b16">Tsoumakas et al., 2009</ref>). In our approach, binary relevance is utilized as a preliminary step so that each original instance is transformed into K pseudo samples, where K is the number of categories. For example, in <ref type="figure" target="#fig_4">Figure  4</ref></p><note type="other">, 1 1 X , 2 1 X , and 3 1 X represent the three pseudo samples, generated from the same original in- stance sentence-1.</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Model Definition</head><p>Formally, let   ,, G V E X  represent an instance network, where V denotes a set of sentence in- stances. E V V  is a set of relationships be- tween sentences. Two kinds of relationship exist in our instance network: One represents the label dependence between each two pseudo instances generated from the same original instance, while the other represents the context dependence when the two instances are from the same context, e.g., the same paragraph. X is the textual feature vec- tor associated with a sentence.</p><p>We model the above network with a factor graph and our objective is to infer the emotion cat- egories of instances by learning the following joint distribution:</p><formula xml:id="formula_1">            , , , k k k k k k i i i i i i ki P Y G f X y g y G y h y H y   (1)</formula><p>where three kinds of factor functions are used. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Textual feature factor function:  </head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Model Learning</head><p>Learning the DFG model is to estimate the best parameter configuration ({ },{ },{ })</p><formula xml:id="formula_2">     to maximize the log-likelihood objective function     log L P Y G    , i.e.,   * arg max L  </formula><p>(5) In this study, we employ the gradient decent method to optimize the objective function. For ex- ample, we can write the gradient of each kj  with regard to the objective function: given by the estimated model. <ref type="figure" target="#fig_7">Figure 5</ref> illustrates the detailed algorithm for learning the parameter  . Note that LBP denotes the Loopy Belief Propagation (LBP) algorithm which is ap- plied to approximately infer the marginal distribu- tion in a factor graph <ref type="bibr" target="#b5">(Frey and MacKay, 1998)</ref>. A similar gradient can be derived for the other pa- rameters.  </p><formula xml:id="formula_3">        | ,, kj kk ij i ij i P Y G kj L E x y E x y                 <label>(6)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Model Prediction</head><p>With the learned parameter configuration  , the prediction task is to find a * U Y which optimizes the objective function, i.e.,</p><formula xml:id="formula_4">  * arg max , , U U L Y P Y Y G  <label>(7)</label></formula><p>Where * U Y are the labels of the instances in the testing data.</p><p>Again, we utilize LBP to calculate the marginal probability of each instance   ,, kL i P y Y G  and predict the label with the largest marginal proba- bility. As all instances in the test data are con- cerned, above prediction is performed in an itera- tion process until the results converge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimentation</head><p>We have systematically evaluated our DFG ap- proach to sentence-level emotion classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Setting</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Corpus</head><p>The corpus contains 100 documents (2751 sen- tences) from the Ren-CECps corpus <ref type="bibr" target="#b12">(Quan and Ren, 2009)</ref>. In our experiments, we use 80 docu- ments as the training data and the remaining 20 documents as the test data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Features</head><p>Each instance is treated as a bag-of-words and transformed into a binary vector encoding the presence or absence of word unigrams.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation Metrics</head><p>In our study, we employ three evaluation metrics to measure the performances of different ap- proaches to sentence-level emotion classification. These metrics have been popularly used in some multi-label classification problems ( <ref type="bibr" target="#b7">Godbole and Sarawagi, 2004;</ref><ref type="bibr" target="#b13">Schapire and Singer, 2000</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Hamming loss: It evaluates how many times</head><p>an instance-label pair is misclassified consid- ering the predicted set of labels and the ground truth set of labels, i.e., Note that smaller Hamming loss corresponds to better classification quality, while larger accuracy and F-measure corresponds to better classifica- tion quality. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experimental Results with Label De- pendence</head><p>In this section, we compare following approaches which only consider the label dependence among pseudo instances:  Baseline: As a baseline, this approach applies a maximum entropy (ME) classifier with only textual features, ignoring both the label and context dependence.  LabelD: As the state-of-the-art approach to handling multi-label classification, this ap- proach incorporates label dependence, as de- scribed in ( <ref type="bibr" target="#b18">Wang et al., 2014</ref>). Specifically, this approach first utilizes a Bayesian network to infer the relationship among the labels and then employ them in the classifier.  DFG-label: Our DFG approach with the label dependence. <ref type="figure" target="#fig_9">Figure 6</ref> compares the performance of different approaches to sentence-level emotion classifica- tion with the label dependence. From this figure, we can see that our DFG approach improves the baseline approach with an impressive improve- ment in all three kinds of evaluation metrics, i.e., 23.5% reduction in Hloss, 25.6% increase in Ac- curacy, and 11.8% increase in F1. This result ver- ifies the effectiveness of incorporating the label dependence in sentence-level emotion classifica- tion. Compared to the state-of-the-art LabelD ap- proach, our DFG approach is much superior. Sig- nificant test show that our DFG approach signifi- cantly outperforms both the baseline approach and LabelD (p-value&lt;0.01). One reason that LabelD performs worse than our approach is possibly due to their separating learning on textual features and label relationships. Also, different from ours, their approach could not capture the information be- tween two conflict emotion labels, such as "happy" and "sad" (they are not possibly appearing to- gether).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Experimental Results with Context De- pendence</head><p>In this section, we compare following approaches which only consider the context dependence among pseudo instances:  Baseline: same as the one in Section 5.2, which applies a maximum entropy (ME) clas- sifier with only textual features, ignoring both the label and context dependence.  Transfer: As the state-of-the-art approach to incorporating contextual information in sen- tence-level emotion classification ( <ref type="bibr" target="#b21">Xu et al., 2012)</ref>, this approach utilizes the label transfor- mation probability to refine the classification results.  DFG-label (Neighbor): Our DFG approach with the context dependence only. Specifically, the neighboring instances are considered as context.  DFG-label (Paragraph): Our DFG approach with the context dependence only. Specifically, the instances in the same paragraph are consid- ered as context.  DFG-label (Document): Our DFG approach with the context dependence only. Specifically, the instances in the same document are consid- ered as context. <ref type="figure">Figure 7</ref> compares the performance of different approaches to sentence-level emotion classifica- tion with the context dependence only. From this figure, we can see that our DFG approach consist- ently improves the state-of-the-art in all three kinds of evaluation metrics, i.e., 6.1% reduction in Hloss, 6.5% increase in Accuracy, and 3.1% in- crease in F1 when the neighboring instances are considered as context. Among the three kinds of context, the neighboring setting performs best. We also find that using the whole document as the context is not helpful and it performs even worse than the baseline approach. Compared to the state- of-the-art Transfer approach, our DFG approach with the neighboring context dependence is much superior. Significant test show that our DFG ap- proach with the neighboring context dependence significantly outperforms the baseline approach and the state-of-the-art LabelD approach (p- value&lt;0.01). <ref type="table" target="#tab_6">Table 3</ref> shows the performance of our DFG ap- proach with both label and context dependence, denoted as DGF-both. From this table, we can see that using both label and context dependence fur- ther improves the performance. <ref type="figure">Figure 8</ref> shows the performance of our DGF- both approach when different sizes of training data are used to train the model. From this figure, we can see that incorporating both the label and context dependence consistently improves the performance with a large margin, irrespective of the amount of training data available.  <ref type="figure">Figure 8</ref>: Performance of our DGF-both ap- proach when different sizes of training data are used</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Experimental Results with Both Label and Context Dependence</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we propose a novel approach to sen- tence-level emotion classification by incorporat- ing both the label dependence among the emotion labels and the context dependence among the con- textual instances into a factor graph, where the la- bel and context dependence is modeled as various factor functions. Empirical evaluation shows that </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F1</head><p>Baseline DFG-both our DFG approach performs significantly better than the state-of-the-art.</p><p>In the future work, we would like to explore bet- ter ways of modeling the label and context de- pendence and apply our DFG approach in more applications, e.g. micro-blogging emotion classi- fication.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Output: S1 : joy, love S2: joy S3: joy, love, anxiety</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example of a paragraph and the sentences therein with their emotion categories from the corpus collected by Quan and Ren (2009)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Probability distribution of most and least frequently-occurred pairs of emotion categories, with left four most frequently-occurred and right four least frequently-occurred, among all 28 pairs</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>be a finite domain of possible emotion labels. Each instance is associated with a subset of Y and this subset is described as an m-dimensional vec- tor 12 { , ,..., } m y y y y  where =1 i y only if in- stance x has label . i l and =0 i y otherwise. Then, we can calculate the probability that an instance takes both emotion labels i l and j l , denoted as ( , ) ij p l l .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: An example of DFG when two instances are involved: sentence-1 with the label vector [1, 0, 1] and sentence-2 with the label vector [1, 1, 0] Note: each multi-label instance is transformed into three pseudo samples, represented as ( 1,2,3) k i Xk  . () f  represents a factor function for modeling textual features. () g  represents a factor function for modeling the label dependence between two pseudo samples. () h  represents a factor function for modeling the context dependence between two instances in the same context.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Probabilities that two instances have an identical emotion label in different settings</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The learning algorithm for DGP model</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>is the number of all test instances and m is the number of all emotion labels. ' j i y is the estimated label while j i y is the true label. 2) Accuracy: It gives an average degree of the similarity between the predicted and the ground truth label sets of all test examples, i.e.,F1-measure: It is the harmonic mean between precision and recall. It can be calculated from true positives, true negatives, false positive and false negatives based on the predictions and the corresponding actual values, i.e.,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Performance comparison of different approaches to sentence-level emotion classification with the label dependence only</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :691 anxiety 567 hate 532 surprise 180 love 1025 anger 287 sorrow 611 expect 603</head><label>1</label><figDesc></figDesc><table>The numbers of the sentences in each 
emotion category 

Emotion #Sentence 
Emotion #Sentence 
joy 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>The numbers of the sentences 
grouped by the emotion labels they contain 

#Sentence 

No Label 
180 
One Label 
1096 
Two Labels 
1081 
Three Labels 
346 
Four or more labels 48 
ALL 
2751 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>, Xl f ( 11 22 , X y ) 3 13 , Xl 3 23 , Xl 3 2 y g( 13 11 , yy ) g( 13 22 , yy ) 3 l 2 l 1 l 3 l 1 l 2 l Sentence-1</head><label></label><figDesc></figDesc><table>Sentence-2 

DFG model 

h( 

22 

12 

, 
yy ) 

h( 

11 

12 

, 
yy ) </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>         (3) Where ikl  is the weight of the function, rep- resenting the influence degree of the two in</head><label></label><figDesc></figDesc><table>, 

kk 
ii 

f X y 

denotes the traditional textual feature factor 
functions associated with each text k 

i 

X . The 
textual feature factor function is instantiated as 
follows: 

 
 
 
 

1 

1 
, 
exp 
, 

k 
k 
k 
k 
i 
i 
kj 
ij 
i 
j 

f X y 
x y 
Z 

 

 
  
 

 

(2) 

Where  
 

, 

kk 
ij 
i 

xy 
 
is a feature function and k 

ij 

x 

represents a textual feature, i.e., a word feature 
in this study. 
2) Label dependence factor function: 

  

 
 

, 

kk 
ii 

g y G y 
denotes the additional label de-

pendence relationship among the pseudo in-

stances, where   

k 
i 

Gy is the label set of the 

instances connected to k 

i 

y .   

k 
i 

Gy and k 

i 

y are 

labels of the pseudo instances generated from 
the same original instance. The label depend-
ence factor function is instantiated as follows: 

 
 
 
 

2 

() 
2 

1 
, ( ) 
exp 

lk 
ii 

k 
k 
k 
l 
i 
i 
ikl 
i 
i 
y G y 

g y G y 
y y 
Z 

-
stances k 

i 

y and l 

i 

y . 
3) Context dependence factor function: 

  

 
 

, 

kk 
ii 

h y H y 
denotes the additional context 

dependence relationship among the instances, 

where   

k 
i 

Hy is the set of the instances con-

nected to k 

i 

y .   

k 
i 

Hy and k 

i 

y are the labels of 

the pseudo instances from the same context but 
generated from different original instances. 
The context dependence factor function is in-
stantiated as follows: 

 
 
 
 

2 

() 
3 

1 
, ( ) 
exp 

kk 
ji 

k 
k 
k 
k 
i 
i 
ijk 
i 
j 
y H y 

h y H y 
y 
y 
Z 

 

 

  
  
  

 

(4) 
Where ijk 

 is the weight of the function, repre-

senting the influence degree of the two in-
stances k 

i 

y and k 

j 

y . 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head></head><label></label><figDesc></figDesc><table>Where 

 
 

, k 

ij 
i 

E 
x y 
  
 

is the expectation of feature 

function  
 

, k 

ij 
i 

xy 
 

given the data distribution. 

  

  

| 

, 

kj 

k 
ij 
i 
P Y G 

E 
x y 

 

  

 is the expectation of feature 

function 

 
 

, k 

ij 
i 

xy 
 

under the distribution 

  

kj 

P Y G 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>:</head><label></label><figDesc></figDesc><table>Learning rate  
Output: Estimated parameters  

Initialize 

0 
  

Repeat 
1) Calculate 

 
 

, k 

ij 
i 

E 
x y 
  
 

using LBP 

2) Calculate 

  

  

| 

, 

kj 

k 
ij 
i 
P Y G 

E 
x y 

 

  

 using LBP 

3) Calculate the gradient of  according to 

Eq. (6) 

4) Update parameter  with the learning 
rate  

  

new 
old 

L  
 
   
 

Until Convergence 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="true"><head>Table 3 : Performance of our DFG approach with both label and context dependence</head><label>3</label><figDesc></figDesc><table>Hloss Accuracy 
F1 
Baseline 
0.447 
0.378 
0.261 
DFG-label 
0.254 
0.621 
0.372 
DFG-context 
0.416 
0.443 
0.292 
DFG-both 
0.242 
0.634 
0.379 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Emotions from Text: Machine Learning for Text-based Emotion Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Alm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sproat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-05</title>
		<meeting>EMNLP-05</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="579" to="586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Multi-label Text Classification Approach for Sentence Level News Emotion Analysis. Pattern Recognition and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bhowmick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Prasad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">5909</biblScope>
			<biblScope unit="page" from="261" to="266" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Sentence Level News Emotion Analysis in Fuzzy Multi-label Classification Framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bhowmick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Prasad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Research in Computing Science. Special Issue: Natural Language Processing and its Applications</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="143" to="154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Twitter Mood Predicts the Stock Market</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bollen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-J</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Science</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Emotion Cause Detection with Linguistic Constructions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING-10</title>
		<meeting>COLING-10</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="179" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A Revolution: Belief Propagation in Graphs with Cycles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Frey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mackay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS-98</title>
		<meeting>NIPS-98</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="479" to="485" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Modelling Emotional Trajectories of Individuals in an Online Chat</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Galik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Springer-Verlag Berlin Heidelberg-12</title>
		<meeting>Springer-Verlag Berlin Heidelberg-12</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="96" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Discriminative Methods for Multi-labeled Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Godbole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sarawagi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in knowledge discovery and data mining</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="22" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Sentiment Analysis of Short Informal Texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kiritchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohammad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="723" to="762" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Emotion Classification of Chinese Miroblog Text via Fusion of BoW and eVector Feature Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NLP&amp;CC-14</title>
		<meeting>NLP&amp;CC-14</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="217" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Emotion Classification of Online News Articles from the Reader&apos;s Perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Web Intelligence and Intelligent Agent Technology-08</title>
		<meeting>the International Conference on Web Intelligence and Intelligent Agent Technology-08</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="220" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Joint Modeling of News Reader&apos;s and Comment Writer&apos;s Emotions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-13</title>
		<meeting>ACL-13</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="511" to="515" />
		</imprint>
	</monogr>
	<note>short paper</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Construction of a Blog Emotion Corpus for Chinese Emotional Expression Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-09</title>
		<meeting>EMNLP-09</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1446" to="1454" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">A Boosting-based System for Text Categorization. Machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="135" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Emotion Classification Using Massive Examples Extracted from the Web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tokuhisa</forename><forename type="middle">R</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Inui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING-2008</title>
		<meeting>COLING-2008</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="881" to="888" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Multi-label Classification: An Overview</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tsoumakas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Katakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Journal of Data Warehousing and Mining</title>
		<meeting>International Journal of Data Warehousing and Mining</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Mining Multi-label Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tsoumakas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Katakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Vlahavas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery Handbook</title>
		<imprint>
			<biblScope unit="page" from="1" to="19" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Emotion Classification in Microblog Texts Using Class Sequential Rules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI-14</title>
		<meeting>AAAI-14</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="187" to="193" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Enhancing Multi-label Classification by Modeling Dependencies among Labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><forename type="middle">S</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="3405" to="3413" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Annotating Expressions of Opinions and Emotions in Language. Language Resources and Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cardie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="65" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Build Chinese Emotion Lexicons Using A Graph-based Algorithm and Multiple Resources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING-10</title>
		<meeting>COLING-10</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1209" to="1217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Coarse-tofine Sentence-level Emotion Classification based on the Intra-sentence Features and Sentential Context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CIKM-12, poster</title>
		<meeting>CIKM-12, poster</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2455" to="2458" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
