<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:22+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Idiom Token Classification using Sentential Distributed Semantics</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giancarlo</forename><forename type="middle">D</forename><surname>Salton</surname></persName>
							<email>giancarlo.salton@mydit.ie {robert.ross,john.d.kelleher}@dit.ie</email>
							<affiliation key="aff0">
								<orgName type="department">Applied Intelligence Research Centre School of Computing Dublin Institute of Technology</orgName>
								<address>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">J</forename><surname>Ross</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Applied Intelligence Research Centre School of Computing Dublin Institute of Technology</orgName>
								<address>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">D</forename><surname>Kelleher</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Applied Intelligence Research Centre School of Computing Dublin Institute of Technology</orgName>
								<address>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Idiom Token Classification using Sentential Distributed Semantics</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="194" to="204"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Idiom token classification is the task of deciding for a set of potentially idiomatic phrases whether each occurrence of a phrase is a literal or idiomatic usage of the phrase. In this work we explore the use of Skip-Thought Vectors to create distributed representations that encode features that are predictive with respect to idiom token classification. We show that classifiers using these representations have competitive performance compared with the state of the art in idiom token classification. Importantly, however, our models use only the sentence containing the target phrase as input and are thus less dependent on a potentially inaccurate or incomplete model of discourse context. We further demonstrate the feasibility of using these representations to train a competitive general idiom token classifier.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Idioms are a class of multiword expressions (MWEs) whose meaning cannot be derived from their individual constituents <ref type="bibr" target="#b26">(Sporleder et al., 2010)</ref>. Idioms often present idiosyncratic be- haviour such as violating selection restrictions or changing the default semantic roles of syntac- tic categories <ref type="bibr" target="#b25">(Sporleder and Li, 2009)</ref>. Conse- quently, they present many challenges for Natu- ral Language Processing (NLP) systems. For ex- ample, in Statistical Machine Translation (SMT) it has been shown that translations of sentences containing idioms receive lower scores than trans- lations of sentences that do not contain idioms <ref type="bibr" target="#b23">(Salton et al., 2014</ref>).</p><p>Idioms are pervasive across almost all lan- guages and text genres and as a result broad cov- erage NLP systems must explicitly handle idioms ( <ref type="bibr">Villavicencio et al., 2005)</ref>. A complicating factor, however, is that many idiomatic expressions can be used both literally or figuratively. In general, idiomatic usages are more frequent, but for some expressions the literal meaning may be more com- mon ( <ref type="bibr" target="#b17">Li and Sporleder, 2010a)</ref>. As a result, there are two fundamental tasks in NLP idiom process- ing: idiom type classification is the task of identi- fying expressions that have possible idiomatic in- terpretations and idiom token classification is the task of distinguishing between idiomatic and lit- eral usages of potentially idiomatic phrases <ref type="bibr" target="#b11">(Fazly et al., 2009)</ref>. In this paper we focus on this second task, idiom token classification.</p><p>Previous work on idiom token classification, such as <ref type="bibr" target="#b25">(Sporleder and Li, 2009)</ref> and <ref type="bibr" target="#b22">(Peng et al., 2014</ref>), often frame the problem in terms of modelling the global lexical context. For exam- ple, these models try to capture the fact that the id- iomatic expression break the ice is likely to have a literal meaning in a context containing words such as cold, frozen or water and an idiomatic meaning in a context containing words such as meet or dis- cuss ( <ref type="bibr" target="#b17">Li and Sporleder, 2010a)</ref>. Frequently these global lexical models create a different idiom to- ken classifier for each phrase. However, a number of papers on idiom type and token classification have pointed to a range of other features that could be useful for idiom token classification; including local syntactic and lexical patterns <ref type="bibr" target="#b11">(Fazly et al., 2009</ref>) and cue words ( <ref type="bibr" target="#b17">Li and Sporleder, 2010a</ref>). However, in most cases these non-global features are specific to a particular phrase. So a key chal- lenge is to identify from a range of features which features are the correct features to use for idiom token classification for a specific expression.</p><p>Meanwhile, in recent years there has been an explosion in the use of neural networks for learn- ing distributed representations for language (e.g., <ref type="bibr" target="#b24">Socher et al. (2013)</ref>, <ref type="bibr" target="#b14">Kalchbrenner et al. (2014)</ref> and <ref type="bibr" target="#b15">Kim (2014)</ref>). These representations are au- tomatically trained from data and can simultane- ously encode multiple linguistics features. For ex- ample, word embeddings can encode gender dis- tinctions and plural-singular distinctions <ref type="bibr" target="#b21">(Mikolov et al., 2013b</ref>) and the representations generated in sequence to sequence mappings have been shown to be sensitive to word order ( <ref type="bibr" target="#b27">Sutskever et al., 2014</ref>). The recent development of Skip-Thought Vectors (or Sent2Vec) ( <ref type="bibr" target="#b16">Kiros et al., 2015</ref>) has pro- vided an approach to learn distributed representa- tions of sentences in an unsupervised manner.</p><p>In this paper we explore whether the repre- sentations generated by Sent2Vec encodes fea- tures that are useful for idiom token classification. This question is particularly interesting because the Sent2Vec based models only use the sentence containing the phrase as input whereas the base- lines systems use full the paragraph surrounding the sentence. We further investigate the construc- tion of a "general" classifier that can predict if a sentence contains literal or idiomatic language (in- dependent of the expression) using just the dis- tributed representation of the sentence. This ap- proach contrasts with previous work that has pri- marily adopted a "per expression" classifier ap- proach and has been based on more elaborate con- text features, such as discourse and lexical cohe- sion between and sentence and the larger context. We show that our method needs less contextual information than the state-of-the-art method and achieves competitive results, making it an impor- tant contribution to a range of applications that do not have access to a full discourse context. We proceed by introducing that previous work in more detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Previous Work</head><p>One of the earliest works on idiom token classi- fication was on Japanese idioms <ref type="bibr" target="#b13">(Hashimoto and Kawahara, 2008)</ref>. This work used a set of features, commonly used in Word Sense Disambiguation (WSD) research, that were defined over the text surrounding a phrase, as well as a number of idiom specific features, which were in turn used to train an SVM classifier based on a corpus of sentences tagged as either containing an idiomatic usage or a literal usage of a phrase. Their results indicated that the WSD features worked well on idiom token classification but that their idioms specific features did not help on the task.</p><p>Focusing on idiom token classification in En- glish, <ref type="bibr" target="#b11">Fazly et al. (2009)</ref> developed the concept of a canonical form (defined in terms of local syn- tactic and lexical patterns) and argued that for each idiom there is a distinct canonical form (or small set of forms) that mark idiomatic usages of a phrase. Meanwhile <ref type="bibr" target="#b25">Sporleder and Li (2009)</ref> proposed a model based on how strongly an ex- pression is linked to the overall cohesive structure of the discourse. Strong links result in a literal classification, otherwise an idiomatic classifica- tion is returned. In related work, <ref type="bibr" target="#b17">Li and Sporleder (2010a)</ref> experimented with a range of features for idiom token classification models, including: global lexical context, discourse cohesion, syntac- tic structures based on dependency parsing, and local lexical features such as cue words, occurring just before or after a phrase. An example of a local lexical feature is when the word between occurs directly after break the ice; here this could mark an idiomatic usage of the phrase: it helped to break the ice between Joe and Olivia. The results of this work indicated that features based on global lex- ical context and discourse cohesion were the best features to use for idiom token classification. The inclusion of syntactic structures in the feature set provided a boost to the performance of the model trained on global lexical context and discourse co- hesion. Interestingly, unlike the majority of pre- vious work on idiom token classification Li and Sporleder (2010a) also investigated building gen- eral models that could work across multiple ex- pressions. Again they found that global lexical context and discourse cohesion were the best fea- tures in their experiments.</p><p>Continuing work on this topic, <ref type="bibr" target="#b18">Li and Sporleder (2010b)</ref> present research based on the assumption that literal and figurative language are generated by two different Gaussians. The model represen- tation is based on semantic relatedness features similar to those used earlier in <ref type="bibr" target="#b25">(Sporleder and Li, 2009)</ref>. A Gaussian Mixture Model was trained us- ing an Expectation Maximization method with the classification of instances performed by choosing the category which maximises the probability of fitting either of the Gaussian components. <ref type="bibr" target="#b18">Li and Sporleder (2010b)</ref>'s results confirmed the findings from previous work that figurative language ex- hibits less cohesion with the surrounding context then literal language.</p><p>More recently, <ref type="bibr" target="#b12">Feldman and Peng (2013)</ref> de- scribes an approach to idiom token identification that frames the problem as one of outlier detec- tion. The intuition behind this work is that be- cause idiomatic usages of phrases have weak co- hesion with the surrounding context they are se- mantically distant from local topics. As a result, phrases that are semantic outliers with respect to the context are likely to be idioms. <ref type="bibr" target="#b12">Feldman and Peng (2013)</ref> explore two different approaches to outlier detection based on principle component analysis (PCA) and linear discriminant analysis (LDA) respectively. Building on this work, <ref type="bibr" target="#b22">Peng et al. (2014)</ref> assume that phrases within a given text segment (e.g., a paragraph) that are seman- tically similar to the main topic of discussion in the segment are likely to be literal usages. They use Latent Dirichlet Allocation (LDA) ( <ref type="bibr" target="#b6">Blei et al., 2003)</ref> to extract a topic representation, defined as a topic term document matrix, of each text segment within a corpus. They then trained a number of models that classify a phrase in a given text seg- ment as a literal or idiomatic usage by using the topic term document matrix to project the phrase into a topic space representation and label outliers within the topic space as idiomatic. To the best of our knowledge, <ref type="bibr" target="#b22">Peng et al. (2014)</ref> is currently the best performing approach to idiom token classifi- cation and we use their models as our baseline 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Skip-Thought Vectors</head><p>While idiom token classification based on long range contexts, such as is explored in a number of the models outlined in the previous section, generally achieve good performance, an NLP sys- tem may not always have access to the surround- ing context, or may indeed find it challenging to construct a reliable interpretation of that context. Moreover, the construction of classifiers for each individual idiom case is resource intensive, and we argue fails to easily scale to under-resourced lan- guages. In light of this, in our work we are ex- ploring the potential of distributed compositional semantic models to produce reliable estimates of idiom token classification.</p><p>Skip-Thought Vectors (Sent2Vec) (Kiros et al.,</p><p>1 However, it is not possible for us to reproduce their re- sults directly as they "apply the (modified) Google stop list before extracting the topics" ( <ref type="bibr" target="#b22">Peng et al., 2014</ref><ref type="bibr">Peng et al., , p. 2023</ref>) and, to date, we do not have access to the modified list. So in our experiments we compare our results with the results they report on the same data. <ref type="bibr" target="#b27">(Sutskever et al., 2014</ref>), a popular architecture for NMT ( <ref type="bibr" target="#b5">Bahdanau et al., 2015</ref>) based on recurrent neural networks (RNN). The encoder takes an in- put sentence and maps it into a distributed repre- sentation (a vector of real numbers). The decoder is a language model that is conditioned on the dis- tributed representation and, in Sent2Vec, is used to "predict" the sentences surrounding the input sen- tence. Consequently, the Sent2Vec encoder learns (among other things) to encode information about the context of an input sentence without the need of explicit access to it. <ref type="figure">Figure 1</ref> presents the archi- tecture of Sent2Vec.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2015) are a recent prominent example of such distributed models. Skip-Thought Vectors are an application of the Encoder/Decoder framework</head><p>More formally, assume a given tuple (s i−1 , s i , s i+1 ) where s i is the input sentence, s i−1 is the previous sentence to s i and s i+1 is the next sen- tence to s i . Let w t i denote the t-th word for s i and x t i denote its word embedding. We follow <ref type="bibr" target="#b16">Kiros et al. (2015)</ref> and describe the model in three parts: encoder, decoder and objective function.</p><p>Encoder. Given the sentence s i of length N , let w 1 i , . . . , w N i denote the words in s i . At each timestep t, the encoder (in this case an RNN with Gated Recurrent Units -GRUs ( <ref type="bibr" target="#b9">Cho et al., 2014)</ref>) produces a hidden state h t i that represents the se- quence w 1 i , . . . , w t i . Therefore, h N i represents the full sentence. Each h N i is produced by iterating the following equations (without the subscript i):</p><formula xml:id="formula_0">r t = σ(W e r x t + U e r h t−1 ) (1) z t = σ(W e z x t + U e z h t−1 ) (2) ˜ h t = tanh(W e x t + U e (r t h t−1 )) (3) h t = (1 − z t ) h t−1 + z t ˜ h t (4)</formula><p>where r t is the reset gate, z t is the update gate, ˜ h t is the proposed update state at time t and denotes a component-wise product.</p><p>Decoder. The decoder is essentially a neural language model conditioned on the input sentence representation h N i . However, two RNNs are used (one for the sentence s i−1 and the other for the sentence s i+1 ) with different parameters except the embedding matrix (E), and a new set of ma- trices (C r , C z and C) are introduced to condition the GRU on h N i . Let h t i+1 denote the hidden state of the decoder of the sentence s i+1 at time t. De- <ref type="figure">Figure 1</ref>: Picture representing the Encoder/Decoder architecture used in the Sent2Vec as shown in <ref type="bibr" target="#b16">Kiros et al. (2015)</ref>. The gray circles represent the Encoder unfolded in time, the red and the green circles represent the Decoder for the previous and the next sentences respectively also unfolded in time. In this example, the input sentence presented to the Encoder is I could see the cat on the steps. The previous sentence is I got back home and the next sentence is This was strange. Unattached arrows are connected to the encoder output (which is the last gray circle).</p><p>coding s i+1 requires iterating the following equa- tions:</p><formula xml:id="formula_1">r t = σ(W d r x t + U d r h t−1 + C r h N i )<label>(5)</label></formula><formula xml:id="formula_2">z t = σ(W d z x t + U d z h t−1 + C z h N i ) (6) ˜ h t = tanh(W d x t + U d (r t h t−1 ) + Ch N i )<label>(7)</label></formula><formula xml:id="formula_3">h t i+1 = (1 − z t ) h t−1 + z t ˜ h t<label>(8)</label></formula><p>where r t is the reset gate, z t is the update gate, ˜ h t is the proposed update state at time t and denotes a component-wise product. An analogous computation is required to decode s i−1 . Given h t i+1 , the probability of the word w t i+1 conditioned on the previous w &lt;t i+1 words and the encoded representation produced by the encoder (h N i ) is:</p><formula xml:id="formula_4">P (w t i+1 |w &lt;t i+1 , h N i ) ∝ exp(E w t i+1 h t i+1 )<label>(9)</label></formula><p>where E w t i+1 denotes the embedding for the word w t i+1 . An analogous computation is performed to find the probability of s i−1 .</p><p>Objective. Given the tuple (s i−1 , s i , s i+1 ), the objective is to optimize the sum of the log- probabilities of the next (s i+1 ) and previous (s i−1 ) sentences given the distributed representa-</p><formula xml:id="formula_5">tion (h N i ) of s i : log P (w t i+1 |w &lt;t i+1 , h N i ) + P (w t i−1 |w &lt;t i−1 , h N i )<label>(10)</label></formula><p>where the total objective is summed over all train- ing tuples (</p><formula xml:id="formula_6">s i−1 , s i , s i+1 ).</formula><p>The utility of Sent2Vec is that it is possible to infer properties of the surrounding context only from the input sentence. Therefore, we can as- sume that the Sent2Vec distributed representation is also carrying information regarding its context (without the need to explicitly access it). Follow- ing that intuition, we can train a supervised clas- sifier only using the labelled sentences containing examples of idiomatic or literal language use with- out modelling long windows of context or using methods to extract topic representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In the following we describe a study that eval- uates the predictiveness of the distributed repre- sentations generated by Sent2Vec for idiom token classifier. We first evaluate these representations using a "per expression" study design (i.e., one classifier per expression) and compare our results to those of <ref type="bibr" target="#b22">Peng et al. (2014)</ref> who applied multi- paragraphs contexts to generate best results. We also experiment with a "general" classifier trained and tested on a set of mixed expressions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset</head><p>In order to make our results comparable with ( <ref type="bibr" target="#b22">Peng et al., 2014</ref>) we used the same VNC-Tokens dataset <ref type="bibr" target="#b10">(Cook et al., 2008</ref>) that they used in their experiments. The dataset used is a collection of sentences containing 53 different Verb Noun Con- structions 2 (VNCs) extracted from the British Na- tional Corpus (BNC) <ref type="bibr" target="#b8">(Burnard, 2007)</ref>. In total, the VNC-Token dataset has 2984 sentences where each sample sentence is labelled with one of three labels: I (idiomatic); L (literal); or Q (unknown).</p><p>Of the 56 VNCs in the dataset 28 of these expres- sions have a reasonably balanced representation (with similar numbers of idiomatic and literal oc- currences in the corpus) and the other 28 expres- sions have a skewed representation (with one class much more common then the other). Following the approach taken by <ref type="bibr" target="#b22">(Peng et al., 2014)</ref>, in this study we use the "balanced" part of the dataset and considered only those sentences labelled as "I" and "L" (1205 sentences -749 labelled as "I" and 456 labelled as "L").</p><p>Peng <ref type="table">Table 1</ref> we present those distribution and the split into training and test sets. The numbers in parentheses denote the number of samples labelled as "I".</p><note type="other">et al. (2014) reported the precision, recall and f1-score of their models on 4 of the expressions from the balanced section of dataset: BlowWhistle; MakeScene; LoseHead; and TakeHeart. So, our first experiment is de- signed to compare our models with these baseline systems on a "per-expression" basis. For this ex- periment we built a training and test set for each of these expressions by randomly sampling expres- sions following the same distributions presented in Peng et al. (2014). In</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Expression</head><p>Samples  <ref type="table">Table 1</ref>: The sizes of the samples for each expres- sion and the split into training and test set. The numbers in parentheses indicates the number of id- iomatic labels within the set. We follow the same split as described in <ref type="bibr" target="#b22">Peng et al. (2014)</ref>.</p><p>While we wish to base our comparison on the work of <ref type="bibr" target="#b22">Peng et al. (2014)</ref> as it is the current state of the art, this is not without its own chal- lenges. In particular we see the choice of these 4 expression as a somewhat random decision as other expressions could also be selected for the evaluation with similar ratios to those described in <ref type="table">Table 1</ref>. Moreover, the choosen expressions are all semi-compositional and do not consider fully non-compositional expressions (although we be- lieve the task of classifying non-compositional ex- pressions would be easier for any method aimed at idiom token classification as these expressions are high-fixed) .A better evaluation would con- sider all the 28 expressions of the balanced part of the VNC-tokens dataset. In addition, we also see this choice of training and test splits as some- what arbitrary. For two of the expressions the test set contain samples in a way that one of the classes outnumber the other by a great amount: for BlowWhistle, the literal class contains roughly 4 times more samples than the idiomatic class; and for TakeHeart the idiomatic class contains roughly 9 times more samples than the literal class. Our concerns with these very skewed test set ratios is that it is very easy when applying a per expres- sion approach (i.e., a separate model for each ex- pression) for a model to achieve good performance (in terms of precision, recall, ad f1) if the positive class is the majority class in the test set. However, despite these concerns, in our first experiment in order to facilitate comparison with the prior art we follow the expression selections and training/test splits described in <ref type="bibr" target="#b22">Peng et al. (2014)</ref>.</p><p>Studies on the characteristics of distributed se- mantic representations of words have shown that similar words tend to be represented by points that are close to each other in the semantic feature space (e.g. <ref type="bibr" target="#b20">Mikolov et al. (2013a)</ref>). Inspired by these results we designed a second experiment to test whether the Sent2Vec representations would cluster idiomatic sentences in one part of the fea- ture space and literal sentences in another part of the space. For this experiment we used the entire "balanced" part of the VNC-tokens dataset to train and test our "general" (multi-expression) models. In this experiment we wanted the data to reflect, as much as possible, the real distribution of the id- iomatic and literal usages of each expression. So, in constructing our training and test set we tried to maintain for each expression the same ratio of idiomatic and literal examples across the training and test set. To create the training and test sets, we split the dataset into roughly 75% for training (917 samples) and 25% for testing (288 samples). We randomly sample the expressions ensuring that the ratio of idiomatic to literal expressions of each ex- pression were maintained across both sets. In <ref type="table">Ta- ble 2</ref> we show the expressions used and their split into training and testing. The numbers in paren- theses are the number of samples labelled as "I".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Sent2Vec Models</head><p>To encode the sentences into their distributed rep- resentations we used the code and models made available <ref type="bibr">3</ref>   <ref type="formula">(11)</ref> 14 <ref type="formula" target="#formula_4">(9)</ref> 4 (2) HitWall 63 <ref type="formula" target="#formula_2">(7)</ref> 50 <ref type="formula">(6)</ref> 13 (1) HoldFire 23 <ref type="formula" target="#formula_2">(7)</ref> 19 <ref type="formula" target="#formula_1">(5)</ref>   <ref type="formula" target="#formula_3">(8)</ref> 18 <ref type="formula">(6)</ref> 7 (2) MakeScene 50 <ref type="formula">(30)</ref> 37 <ref type="formula">(22)</ref> 13 (8) PullLeg 51 <ref type="formula">(11)</ref> 40 <ref type="formula" target="#formula_3">(8)</ref> 11 (3) PullPlug 64 <ref type="formula">(44)</ref> 49 <ref type="formula">(33)</ref> 15 (11) PullPunch 22 <ref type="formula" target="#formula_3">(18)</ref> 18 <ref type="formula" target="#formula_1">(15)</ref> 4 (3) PullWeight 33 <ref type="formula" target="#formula_2">(27)</ref> 24 <ref type="formula">(20)</ref> 9 (7) SeeStar 61 <ref type="formula" target="#formula_1">(5)</ref> 49 <ref type="formula">(3)</ref> 12 (2) TakeHeart 81 <ref type="formula">(61)</ref> 61 <ref type="formula" target="#formula_1">(45)</ref> 20 (16) <ref type="table">Table 2</ref>: The sizes of the samples for each expres- sion and the split into training and test set. The numbers in parentheses indicates the number of idiomatic labels within the set. models it is possible to encode the sentences into three different formats: uni-skip (which uses a regular RNN to encode the sentence into a 2400- dimensional vector); bi-skip (that uses a bidirec- tional RNN to encode the sentence also into a 2400-dimensional vector); and the comb-skip (a concatenation of uni-skip and bi-skip which has 4800 dimensions). Their models were trained us- ing the BookCorpus dataset ( <ref type="bibr" target="#b16">Zhu et al., 2015)</ref> and has been tested in several different NLP tasks as semantic relatedness, paraphrase detection and image-sentence ranking. Although we experi- mented with all the three models, in this paper we only report the results of classifiers trained and tested using the comb-skip features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Classifiers</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">"Per-expression" models</head><p>The idea behind Sent2Vec is similar to those of word embeddings experiments: sentences contain- ing similar meanings should be represented by points close to each other in the feature space. Fol- lowing this intuition we experiment first with a similarity based classifier, the K-Nearest Neigh- bours (k-NN). For the k-NNs we experimented with k = {2, 3, 5, 10}. We also experimented with a more advanced algorithm, namely the Support Vector Machine (SVM) <ref type="bibr">(Vapnik, 1995)</ref>. We trained the SVM un- der three different configurations:</p><p>Linear-SVM-PE 4 . This model used a "linear" kernel with C = 1.0 on all the classification se- tups.</p><p>Grid-SVM-PE. For this model we performed a grid search for the best parameters for each expres- sion. The parameters are: BlowWhiste = { ker- nel: 'rbf', C = 100}; LoseHead = { kernel: 'rbf', C = 1 }; MakeSene = { kernel: 'rbf', C = 100 }; TakeHeart = { kernel: 'rbf', C = 1000 }.</p><p>SGD-SVM-PE. This model is a SVM with lin- ear kernel but trained using stochastic gradient de- scent <ref type="bibr" target="#b7">(Bottou, 2010)</ref>. We set the SGD's learning rates (α) using a grid search: BlowWhiste = {α = 0.001 }; LoseHead = {α = 0.01 }; MakeSene = {α = 0.0001 }; TakeHeart = {α = 0.0001 }; FullDataset = {α = 0.0001 }. We trained these classifiers for 15 epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">"General" models</head><p>We consider the task of creating a "general" clas- sifier that takes an example of any potential idiom and classifying it into idiomatic or literal usage more difficult than the "per-expression" classifi- cation task. Hence we executed this part of the study with the SVM models only. We trained the same three types of SVM models used in the "per- expression" approach but with the following pa- rameters:</p><p>Linear-SVM-GE 5 . This model used a linear kernel with C = 1.0 for all the classification sets.</p><p>Grid-SVM-GE. For this model we also per- formed a grid search and set the kernel to "poly- nomial kernel" of degree = 2 with C = 1000.</p><p>SGD-SVM-GE. We also experimented with a SVM with linear kernel trained using stochastic gradient descent. We set the SGD's learning rate α = 0.0001 after performing a grid search. We trained this classifier for 15 epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and Discussion</head><p>We first present the results for the per expression comparison with <ref type="bibr" target="#b22">Peng et al. (2014)</ref> and then in <ref type="table">Models   BlowWhistle  LoseHead  MakeScene  TakeHeart  P.</ref> R. F1 P. R. F1 P. R. F1 P. R. F1 Peng et. al <ref type="bibr">(2014)</ref> FDA-Topics 0.62 0.60 0.61 0.76 0.97 0.85 0.79 0.95 0.86 0.93 0.99 0.96 FDA-Topics+A 0.47 0.44 0.45 0.74 0.93 0.82 0.82 0.69 0.75 0.92 0.98 0.95 FDA-Text 0.65 0.43 0.52 0.72 0.73 0.72 0.79 0.95 0.86 0.46 0.40 0.43 FDA-Text+A 0.45 0.49 0.47 0.67 0.88 0.76 0.80 0.99 0.88 0.47 0.29 0.36 SVMs-Topics 0.07 0.40 0.12 0.60 0.83 0.70 0.46 0.57 0.51 0.90 1.00 0.95 SVMs-Topics+A 0.21 0.54 0.30 0.66 0.77 0.71 0.42 0.29 0.34 0.91 1.00 0.95 SVMs-Text 0.17 0.90 0.29 0.30 0.50 0.38 0.10 0.01 0.02 0.65 0.21 0.32 SVMs-Text+A 0.24 0.87 0.38 0.66 0.85 0.74 0.07 0.01 0.02 0.74 0.13 0.22 Distributed <ref type="figure">Representations  KNN-2</ref> 0.61 0.41 0.49 0.30 0.64 0.41 0.55 0.89 0.68 0.46 0.96 0. <ref type="figure">62  KNN-3</ref> 0.84 0.32 0.46 0.58 0.65 0.61 0.88 0.88 0.88 0.72 0.94 0.81 KNN-5 0.79 0.28 0.41 0.57 0.65 0.61 0.87 0.83 0.85 0.73 0.94 0.82 KNN-10 0.83 0.30 0.44 0.28 0.68 0.40 0.85 0.83 0.84 0.78 0.94 0.85 Linear SVM 0.77 0.50 0.60 0.72 0.84 0.77 0.81 0.91 0.86 0.73 0.96 0.83 Grid SVM 0.80 0.51 0.62 0.83 0.89 0.85 0.80 0.91 0.85 0.72 0.96 0.82 SGD SVM 0.70 0.40 0.51 0.73 0.79 0.76 0.85 0.91 0.88 0.61 0.95 0.74 <ref type="table">Table 3</ref>: Results in terms of precision (P.), recall (R.) and f1-score (F1) on the four chosen expressions.</p><p>The results of ( <ref type="bibr" target="#b22">Peng et al., 2014</ref>) are those of the multi-paragraphs method. The bold values indicates the best results for that expression in terms of f1-score.</p><p>Section 5.2 we present the results for the "general' classifier approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Per-Expression Classification</head><p>The averaged results over 10 runs in terms of pre- cision, recall and f1-score are presented in <ref type="table">Table  3</ref>. When calculating these metrics, we consid- ered the positive class to be the "I" (idiomatic) la- bel. We used McNemar's test <ref type="bibr" target="#b19">(McNemar, 1947)</ref> to check the statistical significance of our models' results and found all our results to be significant at p &lt; 0.05. We can see in <ref type="table">Table 3</ref> that some of our mod- els outperform the baselines on 1 expression (BlowWhistle) and achieved the same f1-scores on 2 expressions (LoseHead and MakeScene). For theses 3 expressions, our best models generally had higher precision than the baselines, finding more idioms on the test sets. In addition, for MakeScene, 2 of our models achieved the same f1- scores (KNN-3 and SGD-SVM-PE), although they have different precision and recall.</p><p>The only expression on which a baseline model outperformed all our models was TakeHeart where it achieved higher precision, recall and f1-scores. Nevertheless, this expression had the most imbal- anced test set, with roughly 9 times more idioms than literal samples. Therefore, if the baseline la- bel all the test set samples as idiomatic (including the literal examples), it would still have the best re- sults. It is thus worth emphasizing that the choices of distributions for training and test sets in Peng et al's work seems arbitrary and does not reflect the real distribution of the data in a balanced cor- pus. Also, <ref type="bibr" target="#b22">Peng et al. (2014)</ref> did not provide the confusion matrices for their models so we cannot analyse their model behaviour across the classes.</p><p>That aside, while our best models share the same f1-score with the baseline on 2 of the expres- sions, we believe that our method is more powerful if we take into account that we do not explicitly ac- cess the context surrounding our input sentences. We can also consider that our method is cheaper than the baseline in the sense that we do not need to process words other than the words in the input sentence.</p><p>In addition, we note that the SVMs generally outperform the KNNs, although no single model perform best across all expressions. Regardless of the fact that the KNN-3 achieved the same f1- score as SGD-SVM on MakeScene, the SVM con- sistently scored higher than the KNNs on all ex- pressions. This is an interesting finding if we con- sider that our feature vector is 4800-dimensional and the SVMs are projecting these features into a space that has much more than 4800 dimensions and not incurring into the "curse of dimension- ality". Furthermore, other work using Sent2vec have shown the capabilities of the Sent2Vec rep- resentations to capture features that are suited to various NLP tasks where semantics is involved (e.g., paraphrase detection and semantic related- ness ( <ref type="bibr" target="#b16">Kiros et al., 2015)</ref>). These results together with our findings suggests that the factors in- 200 <ref type="table">Table 4</ref>: Precision (P.), recall (R.) and f1-scores (F1) calculated on the expressions of the balanced part of the VNC-Tokens dataset. The expressions marked with * indicate the expressions also evaluated with the "per-expression" classifiers. volved in distinguishing between the semantics of idiomatic and literal language are deeply en- trenched in language generation and only a high- dimensional representation can enable a classifier to make that distinction. This observation also im- plies that the contribution of each feature (gen- erated by the distributed representation) is very small, given the fact that we need that many di- mensions and the space needed to unpack the com- ponents of literal and idiomatic language has many more dimensions than the input space. Therefore, the current manually engineered features (i.e., the features used in previous idiom token classifica- tion) are only capturing a small portion of these dimensions and assigning more weight to these di- mensions while other dimensions (not captured) are not considered (i.e., as they are not considered, the features represented by these dimensions have their weight equal to 0)</p><p>Another point for consideration is the fact that the combination of our model with the work of <ref type="bibr" target="#b22">Peng et al. (2014)</ref> may result in a stronger model on this "per-expression" setting. Nevertheless, as previously highlighted, it was not possible for us to directly re-implement their work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">General Classification</head><p>Moving on to the general classification case, we present the average results (in terms of precision, recall and f1-score) over 10 runs to our "general" classifiers on the balanced part of the VNC-Tokens dataset. Once again, the positive class is assumed to be the "I" (idiomatic) label and we split the out- comes per expression. It should be noted that the "per-expression" evaluation was performed using a balanced set to train the classifiers while in this experiment we maintained the ratio of idiomatic to literal usages for each expression across the train- ing and test sets. Our motivation for maintaining this ratio was to simulate the real distribution of the classes in the corpus.</p><p>We present results for the four individual MWEs used in the per-sentence based evaluation as well as a set of averages made over all 28 ex- pression in the "balanced" portion of the dataset. Referring to the results we first of all note the overall performance of the "general" classifiers is fairly high with 2 classifiers (Linear-SVM-GE and Grid-SVM-GE) sharing the same precision, recall and f1-scores. While averages here are the same across the two classifiers, it is worth noting that deviations occured across individual MWE types, though these deviations balanced out across the data set. Although not displayed in this table due to space limitations, it should be noted that all the 3 classifier had a extremely low performance on SeeStar (f1 = 0.15, 0.15 and 0.17 respectively).</p><p>If we compare the performance of the 4 ex- pressions analysed in the "per-expression" exper- iment we can observe that all the "general" clas- sifiers had a better performance over BlowWhis- tle and the Linear-SVM-GE also performed bet- ter on MakeScene. Nevertheless we should em- phasize that the "general" classifier's evaluation is closer to what we would expect in a real data dis- tribution than the evaluation presented on the "per- expression" section. This does not invalidate the evaluation of the latter but when we have access to a real data distribution it should also be taken into account when performing a ML evaluation.</p><p>In general, the results look promising. It is in- teresting to see how the classifiers trained on a set of mixed expressions ("general" classifiers) had a performance close to the "per-expression" classi- fiers, even though the latter were trained and tested on "artificial" training and test sets that do not re- flect the real data distributions. We believe that these results indicate that the distributed represen- tations generated by Sent2Vec are indeed cluster- ing together sentences within the same class (id- iomatic or literal) in feature space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions and Future Work</head><p>In this paper we have investigated the use of dis- tributed compositional semantics in literal and id- iomatic language classification, more specifically using Skip-Thought Vectors (Sent2Vec). We fol- lowed the intuition that the distributed representa- tions generated by Sent2Vec also include informa- tion regarding the context where the potential id- iomatic expression is inserted and therefore is suf- ficient for distinguishing between idiomatic and literal language use.</p><p>We tested this approach with different Machine Learning (ML) algorithms (K-Nearest Neighbours and Support Vector Machines) and compared our work against a topic model representation that in- clude the full paragraph or the surrounding para- graphs where the potential idiom is inserted. We have shown that using the Sent2Vec representa- tions our classifiers achieve better results in 3 out of 4 expressions tested. We have also shown that our models generally present better precision and/or recall than the baselines.</p><p>We also investigated the capability of Sent2Vec clustering representations of sentences within the same class in feature space. We followed the intuition presented by previous experiments with distributed representations that words with simi- lar meaning are clustered together in feature space and experimented with a "general" classifier that is trained on a dataset of mixed expressions. We have shown that the "general" classifier is feasible but the traditional "per-expression" does achieve better results in some cases.</p><p>In future work we plan to investigate the use of Sent2Vec to encode larger samples of text -not only the sentence containing idioms. We also plan to further analyse the errors made by our "general" model and investigate the "general" approach on the skewed part of the VNC-tokens dataset. We also plan to investigate an end-to-end approach based on deep learning-based representations to classify literal and idiomatic language use.</p><p>In addition, we also plan to compare our work to the method of <ref type="bibr" target="#b26">Sporleder et al. (2010)</ref> as well apply our work on the IDX Corpus ( <ref type="bibr" target="#b26">Sporleder et al., 2010)</ref> and to other languages. The focus of these future experiments will be to test how our ap- proach which is relatively less dependent on NLP resources compares with these other methods for idiom token classification.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>by Kiros et al. (2015). Using their</figDesc><table>Expression 

Samples Train Size Test Size 
BlowTop 
28 (23) 
21 (18) 
7 (5) 
BlowTrumpet 
29 (19) 
21 (14) 
8 (5) 
BlowWhistle 
78 (27) 
59 (20) 
19 (7) 
CutFigure 
43 (36) 
33 (28) 
10 (8) 
FindFoot 
53 (48) 
39 (36) 
14 (12) 
GetNod 
26 (23) 
19 (17) 
7 (6) 
GetSack 
50 (43) 
40 (34) 
10 (9) 
GetWind 
28 (13) 
20 (9) 
8 (4) 
HaveWord 
91 (80) 
69 (61) 
22 (19) 
HitRoad 
32 (25) 
24 (19) 
8 (6) 
HitRoof 
18 </table></figure>

			<note place="foot" n="2"> This verb-noun constructions can be used either idiomatically or literally.</note>

			<note place="foot" n="3"> https://github.com/ryankiros/skip-thoughts</note>

			<note place="foot" n="4"> PE stands for &quot;per-expression&quot; 5 GE stands for &quot;general&quot;.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank the anonymous reviewers for their valuable comments and feedback. Gi-ancarlo D. Salton would like to thank CAPES ("CoordenaçCoordenaç˜Coordenação de Aperfeiçoamento de Pessoal de Nível Superior") for his Science Without Borders scholarship, proc n. 9050-13-2.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Svm-Ge Grid-Svm-Ge Sgd-Svm-Ge P</forename><forename type="middle">R</forename><surname>Linear</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="middle">R</forename><surname>F1 P</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>F1 P. R</surname></persName>
		</author>
		<idno>F1 BlowTop 0.91 0.96 0.94 0.91 0.93 0.94 0.80 0.98 0.88</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Blowwhistle</surname></persName>
		</author>
		<idno>* 0.84 0.67 0.75 0.84 0.68 0.75 0.67 0.59 0.63</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Losehead</surname></persName>
		</author>
		<idno>* 0.78 0.66 0.72 0.75 0.64 0.69 0.75 0.67 0.71</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Makescene</surname></persName>
		</author>
		<idno>* 0.92 0.84 0.88 0.92 0.81 0.86 0.78 0.81 0.79</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Takeheart</surname></persName>
		</author>
		<idno>* 0.94 0.79 0.86 0.94 0.80 0.86 0.86 0.80 0.83</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>References Dzmitry Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Latent dirichlet allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Large-scale machine learning with stochastic gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th International Conference on Computational Statistics (COMPSTAT&apos;2010)</title>
		<meeting>the 19th International Conference on Computational Statistics (COMPSTAT&apos;2010)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="177" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lou</forename><surname>Burnard</surname></persName>
		</author>
		<ptr target="http://www.natcorp.ox.ac.uk/" />
		<title level="m">Reference guide for the british national corpus</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
	<note>xml edition</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1724" to="1734" />
		</imprint>
	</monogr>
	<note>, October. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The VNC-Tokens Dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Afsaneh</forename><surname>Fazly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suzanne</forename><surname>Stevenson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the LREC Workshop: Towards a Shared Task for Multiword Expressions</title>
		<meeting>the LREC Workshop: Towards a Shared Task for Multiword Expressions<address><addrLine>Marrakech, Morocco</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Unsupervised type and token identification of idiomatic expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Afsanesh</forename><surname>Fazly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suzanne</forename><surname>Stevenson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Linguistics</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="61" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Automatic detection of idiomatic clauses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International Conference on Computational Linguistics and Intelligent Text Processing-Volume Part I, CICLing&apos;13</title>
		<meeting>the 14th International Conference on Computational Linguistics and Intelligent Text Processing-Volume Part I, CICLing&apos;13</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="435" to="446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Construction of an idiom corpus and its application to idiom identification based on wsd incorporating idiom-specific features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chikara</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daisuke</forename><surname>Kawahara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the conference on empirical methods in natural language processing</title>
		<meeting>the conference on empirical methods in natural language processing</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="992" to="1001" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">A convolutional neural network for modelling sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-10-25" />
			<biblScope unit="page" from="1746" to="1751" />
		</imprint>
	</monogr>
	<note>A meeting of SIGDAT, a Special Interest Group of the ACL</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Skip-thought vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ruslan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="3276" to="3284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Linguistic cues for distinguishing literal and non-literal usages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linlin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caroline</forename><surname>Sporleder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics: Posters</title>
		<meeting>the 23rd International Conference on Computational Linguistics: Posters</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="683" to="691" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Using gaussian mixture models to detect figurative language in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linlin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caroline</forename><surname>Sporleder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, HLT &apos;10</title>
		<meeting><address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="297" to="300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Note on the sampling error of the difference between correlated proportions or percentages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quinn</forename><surname>Mcnemar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="153" to="157" />
			<date type="published" when="1947" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Linguistic regularities in continuous space word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 2013 Conference of the North Americal Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="746" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Classifying idiomatic and literal expressions using topic models and intensity of emotions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekaterina</forename><surname>Vylomova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014-10" />
			<biblScope unit="page" from="2019" to="2027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">An Empirical Study of the Impact of Idioms on Phrase Based Statistical Machine Translation of English to Brazilian-Portuguese</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giancarlo</forename><forename type="middle">D</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">J</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">D</forename><surname>Kelleher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Third Workshop on Hybrid Approaches to Translation (HyTra) at 14th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Recursive deep models for semantic compositionality over a sentiment treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Perelygin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1631" to="1642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Unsupervised recognition of literal and non-literal use of idiomatic expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caroline</forename><surname>Sporleder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linlin</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 12th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="754" to="762" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Idioms in context: The idix corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caroline</forename><surname>Sporleder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linlin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Gorinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xaver</forename><surname>Koch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC-2010)</title>
		<meeting>the Seventh International Conference on Language Resources and Evaluation (LREC-2010)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="639" to="646" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q. Weinberger</editor>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
