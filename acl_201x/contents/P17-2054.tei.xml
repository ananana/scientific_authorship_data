<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:47+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multi-Task Learning of Keyphrase Boundary Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Augenstein</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
						</author>
						<title level="a" type="main">Multi-Task Learning of Keyphrase Boundary Classification</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</title>
						<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="341" to="346"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-2054</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Keyphrase boundary classification (KBC) is the task of detecting keyphrases in scientific articles and labelling them with respect to predefined types. Although important in practice, this task is so far un-derexplored, partly due to the lack of labelled data. To overcome this, we explore several auxiliary tasks, including semantic super-sense tagging and identification of multi-word expressions, and cast the task as a multi-task learning problem with deep recurrent neural networks. Our multi-task models perform significantly better than previous state of the art approaches on two scientific KBC datasets, particularly for long keyphrases.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The scientific keyphrase boundary classification (KBC) task consists of a) determining keyphrase boundaries, and b) labelling keyphrases with their types according to a predefined schema. KBC is motivated by the need to efficiently search scien- tific literature, which can be summarised by their keyphrases. Several companies are working on keyphrase-based recommender systems for scien- tific literature or search interfaces where scien- tific articles decorate graphs, in which nodes are keyphrases. Such keyphrases must be dynamically retrieved from the articles, because important sci- entific concepts emerge on a daily basis, and the most recent concepts are typically the ones of in- terest to scientists.</p><p>KBC is not a common task in NLP, and there are only few small annotated datasets for inducing supervised KBC models, made available recently ? Both authors contributed equally <ref type="bibr" target="#b19">(QasemiZadeh and Schumann, 2016;</ref><ref type="bibr" target="#b0">Augenstein et al., 2017)</ref>. Typical KBC approaches therefore rely on hand-crafted gazetteers <ref type="bibr" target="#b10">(Hasan and Ng, 2014)</ref> or reduce the task to extracting a list of keyphrases for each document <ref type="bibr" target="#b12">(Kim et al., 2010</ref>) instead of identifying mentions of keyphrases in sentences. For related more common NLP tasks such as named entity recognition and identifica- tion of multi-word expressions, neural sequence labelling methods have been shown to be useful ( <ref type="bibr" target="#b13">Lample et al., 2016)</ref>. In order to overcome the small data problem, we study using more widely available data for tasks related to KBC and exploit their synergies in a deep multi-task learning setup.</p><p>Multi-task learning has become popular within natural language processing and machine learn- ing over the last few years; in particular, hard parameter sharing of hidden layers in deep learn- ing models. This approach to multi-task learning has three advantages: a) It significantly reduces Rademacher complexity <ref type="bibr" target="#b1">(Baxter, 2000;</ref><ref type="bibr" target="#b18">Maurer, 2007)</ref>, i.e., the risk of over-fitting, b) it is space- efficient, reducing the number of parameters, and c) it is easy to implement. This paper shows how hard parameter sharing can be used to improve gazetteer-free keyphrase boundary classification models, by exploiting dif- ferent syntactically and semantically annotated corpora, as well as more readily available data such as hyperlinks.</p><p>Contributions We study the so far widely un- derexplored, though in practice important task of scientific keyphrase boundary classification, for which only a small amount of training data is available. We overcome this by identifying good auxiliary tasks and cast it as a multi-task learn- ing problem. We evaluate our models across two new, manually annotated corpora of scientific arti- cles and outperform single-task approaches by up to 9.64% F1, mostly due to better performance for long keyphrases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Keyphrase Boundary Classification</head><p>Consider the following sentence from a scientific paper:</p><p>(1) We find that simple interpolation methods, like log-linear and linear interpolation, im- prove the performance but fall short of the performance of an oracle.</p><p>This sentence occurs in the ACL RD-TEC 2.0 corpus. Here, interpolation methods and log- linear and linear interpolation are annotated as technical keyphrases, performance as a keyphrase related to measurements, and oracle is a keyphrase labelled as miscellaneous. Below, we are inter- ested in predicting the boundaries and the types of all keyphrases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Multi-Task Learning</head><p>Multi-task learning is an approach to learning, in which generalisation is improved by taking advan- tage of the inductive bias in training signals of re- lated tasks. When abundant labelled data is avail- able for an auxiliary task, but little data for the target task, multi-task learning can act as a form of semi-supervised learning combined with a dis- tant supervision signal. Inducing a model from only the sparse target task data may lead to over- fitting to random noise in the data, but relying on auxiliary data helps the model generalise, making it easier to abstract away from noise, as well as leveraging the marginal distribution of auxiliary input data. From a representation learning per- spective, auxiliary tasks can be used to induce rep- resentations that may be beneficial for the target task. <ref type="bibr" target="#b3">Caruana (1993)</ref> also suggests that the auxil- iary task can help focus attention in the induction of the target task model. Finally, multi-task learn- ing can be cast as a regulariser as studies show re- ductions in Rademacher complexity in multi-task architectures over single-task architectures <ref type="bibr" target="#b1">(Baxter, 2000;</ref><ref type="bibr" target="#b18">Maurer, 2007)</ref>.</p><p>Here, we follow the probably most common ap- proach to multi-task learning, known as hard pa- rameter sharing. This was introduced in <ref type="bibr" target="#b3">Caruana (1993)</ref> in the context of deep neural networks, in which hidden layers can be shared among tasks. We assume T different training set,</p><formula xml:id="formula_0">D 1 , · · · , D T ,</formula><p>where each D t contains pairs of input-output se- quences (w 1:n , y t 1:n ), w i 2 V , y t i 2 L t . The input vocabulary V is shared across tasks, but the out- put vocabularies (tagset) L t are task dependent. At each step in the training process we choose a random task t, followed by a random training in- stance (w 1:n , y t 1:n ) 2 D t . We use the tagger to predict the labelsˆylabelsˆ labelsˆy t i , suffer a loss with respect to the true labels y t i and update the model parame- ters. The parameters are trained jointly for a sen- tence, i.e. cross-entropy loss over each sentence is employed. Each task is associated with an inde- pendent classification function, but all tasks share the hidden layers. Note that for our experiments, we only consider one auxiliary task at a time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>Experimental Setup We perform experiments for both keyphrase boundary identification (un- labelled), and keyphrase boundary identification and classification (labelled). Metrics measured are token-level precision, recall and F1, which are micro-average results across keyphrase types. Types are defined by the two datasets studied.</p><p>Auxiliary tasks We experiment with five aux- iliary tasks: (1) syntactic chunking using anno- tations extracted from the English Penn Tree- bank, following <ref type="bibr" target="#b22">Søgaard and Goldberg (2016)</ref>; (2) frame target annotations from FrameNet 1.5 (cor- responding to the target identification and clas- sification tasks in <ref type="bibr" target="#b6">Das et al. (2014)</ref>); (3) hyper- link prediction using the dataset from <ref type="bibr" target="#b23">Spitkovsky et al. (2010)</ref>, (4) identification of multi-word ex- pressions using the Streusle corpus ( <ref type="bibr" target="#b21">Schneider and Smith, 2015)</ref>; and (5) semantic super-sense tagging using the Semcor dataset, following <ref type="bibr" target="#b11">Johannsen et al. (2014)</ref>. We train our models on the main task with one auxiliary task at a time. Note that the datasets for the auxiliary tasks are not an- notated with keyphrase boundary identification or classification labels.</p><p>Datasets We evaluate on the SemEval 2017 Task 10 dataset ( <ref type="bibr" target="#b0">Augenstein et al., 2017</ref>) and the the ACL RD-TEC 2.0 dataset (QasemiZadeh and <ref type="bibr" target="#b19">Schumann, 2016)</ref>. The SemEval 2017 dataset is annotated with three keyphrase types, the ACL RD-TEC dataset with seven. For the former, we test on the development portion of the dataset, as the test set is not released yet. We randomly split ACL RD-TEC into a training and test set, reserv- Models Our single-and multi-task networks are three-layer, bi-directional LSTMs (Graves and <ref type="bibr" target="#b9">Schmidhuber, 2005</ref>) with pre-trained SENNA em- beddings. 1 For the multi-task networks, we follow the training procedure outlined in Section 3. The dimensionality of the embeddings is 50, and we follow Søgaard and Goldberg (2016) in using the same dimensionality for the hidden layers. We add a dropout of 0.1 to the input and train these archi- tectures with momentum SGD with initial learning rate of 0.001 and momentum of 0.9 for 10 epochs. We use the implementations released by the au- thors and re-train models on our data.</p><note type="other">SemEval 2017 Task 10 ACL RD-TEC Labels Material, Process, Task Technology and Method, Tool and Library, Language Resource, Language Resource Product, Measures and Measurements, Models, Other Topics Computer Science, Physics, Natural Language Processing Material Science Number all keyphrases 5730 2939 Proportion singleton keyphrases 31% 83% Proportion single-word mentions 18% 23% Proportion mentions with word length &gt;= 2 82% 77% Proportion mentions with word length &gt;= 3 51% 33% Proportion mentions with word length &gt;= 5 22% 8%</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and Analysis</head><p>Results for SemEval 2017 Task 10 corpus are pre- sented in <ref type="table" target="#tab_3">Table 2</ref>, and for the ACL RD-TEC cor- pus in belled labelled perform better than the single-task BiLSTM baseline.</p><p>On the SemEval corpus, the F1 error reduc- tion of of the best labelled model over the Stan- ford tagger is 9.64%. The lexicalised <ref type="bibr" target="#b8">Finkel et al. (2005)</ref> model shows a surprisingly competitive performance on the ACL RD-TEC corpus, where it is only 2 points in F1 behind our best per- forming labelled model and on par with our best- performing unlabelled model. Results with <ref type="bibr" target="#b13">Lample et al. (2016)</ref>, on the other hand, are lower than the <ref type="bibr" target="#b8">Finkel et al. (2005)</ref> baseline. This might be due to the model having a large set of parameters to model state transitions which poses a difficulty for small training datasets. Overall, multi-task models show bigger im- provements over baselines for the SemEval cor- pus, and all models achieve better results on ACL RD-TEC. Statistics shown in <ref type="table" target="#tab_0">Table 1</ref> help to explain this. Most noticeably, the SemEval dataset contains a significantly higher proportion of long keyphrases than the ACL dataset. Interest- ingly, ACL RD-TEC contains a large proportion of keyphrases which only appear once in the train- ing set (singletons), significantly fewer keyphrases and more keyphrase type, but that does not seem to impact results as much as a high proportion of long keyphrases.</p><p>All models struggle with semantically vague or broad keyphrases (e.g. 'items', 'scope', 'key') and long keyphrases, especially those containing clauses (e.g. 'complete characterisation of the ox- ide particles', 'earley deduction proof procedure for definite clauses'). The multi-task models gen- erally outperform the BiLSTM baseline for long phrases (e.g. 'language-independent system for    <ref type="table" target="#tab_1">Table 3</ref>: Results for keyphrase boundary classification on the ACL RD-TEC corpus automatic discovery of text in parallel translation', 'honeycomb network of graphite bricks'). Being able to recognise long keyphrases correctly is part of the reason our multi-task models outperform the baselines, especially on the SemEval dataset, which contains many such long keyphrases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Multi-Task Learning Hard sharing of all hid- den layers was introduced in <ref type="bibr" target="#b3">Caruana (1993)</ref>, and popularised in NLP by <ref type="bibr" target="#b4">Collobert et al. (2011a)</ref>. Several variants have been introduced, including hard sharing of selected layers <ref type="bibr" target="#b22">(Søgaard and Goldberg, 2016</ref>) and sharing of parts (subspaces) of layers ( <ref type="bibr" target="#b14">Liu et al., 2015)</ref>. <ref type="bibr" target="#b22">Søgaard and Goldberg (2016)</ref> show that hard parameter sharing is an ef- fective regulariser, also on heterogeneous tasks such as the ones considered here. Hard parameter sharing has been studied for several tasks, includ- ing CCG super tagging <ref type="bibr" target="#b22">(Søgaard and Goldberg, 2016</ref>), text normalisation (Bollman and Søgaard, 2016), neural machine translation ( <ref type="bibr" target="#b7">Dong et al., 2015;</ref><ref type="bibr" target="#b16">Luong et al., 2016)</ref>, and super-sense tag- ging <ref type="bibr" target="#b17">(Martínez Alonso and Plank, 2017</ref>  <ref type="bibr">(2016)</ref>. Other successful methods rely on condi- tional random fields, thereby modelling the proba- bility of each output label conditioned on the label at the previous time step. <ref type="bibr" target="#b13">Lample et al. (2016)</ref>, currently state-of-the-art for NER, stack CRFs on top of recurrent neural networks. We leave explor- ing such models in combination with multi-task learning for future work. Keyphrase detection methods specific to the sci- entific domain often use keyphrase gazetteers as features or exploit citation graphs <ref type="bibr" target="#b10">(Hasan and Ng, 2014</ref>). However, previous methods relied on cor- pora annotated for type-level identification, not for mention-level identification <ref type="bibr" target="#b12">(Kim et al., 2010;</ref><ref type="bibr" target="#b24">Sterckx et al., 2016)</ref>. While most applications rely on extracting keyphrases (as types), this has the unfortunate consequence that previous work ignores acronyms and other short-hand forms re- ferring to methods, metrics, etc. Further, relying on gazetteers makes overfitting likely, obtaining lower scores on out-of-gazetteer keyphrases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions and Future Work</head><p>We present a new state of the art for keyphrase boundary classification, using data from related, auxiliary tasks; in particular, super-sense tag- ging and identification of multi-word expressions. Deep multi-task learning improves significantly on previous approaches to KBC, with error reduc- tions of up to 9.64%, mostly due to better identifi- cation and labelling of long keyphrases.</p><p>In future work, we want to explore alterna- tive multi-task learning regimes to hard parameter sharing and experiment with additional auxiliary tasks. The auxiliary tasks considered here are stan- dard NLP tasks, hyperlink prediction aside. Other tasks may be more directly relevant such as pre- dicting the layout of calls for papers for scientific conferences, or predicting hashtags in tweets by scientists, since both data sources contain scien- tific keyphrases.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Baselines</head><label></label><figDesc>Our baselines are Finkel et al. (2005) 2 and Lample et al. (2016) 3 , in order to compare to a lexicalised and a state-of-the-art neural method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Unlabelled</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Characteristics of SemEval 2017 Task 10 and ACL-RD-TEC corpora, statistics of training sets 

ing 1/3 for testing. Key dataset characteristics are 
summarised in Table 1. One important observa-
tion is that the SemEval 2017 dataset contains a 
significantly higher proportion of long keyphrases 
than the ACL dataset. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 3 .</head><label>3</label><figDesc></figDesc><table>For the SemEval corpus, all five la-
belled multi-task learning models outperform both 
examples of previous work, as well as our single-
task BiLSTM baseline, by some margin. For ACL 
RD-TEC, three of out five multi-task learning la-

1 http://ronan.collobert.com/senna/ 
2 http://nlp.stanford.edu/software/ 
CRF-NER.shtml 
3 https://github.com/clab/ 
stack-lstm-ner 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Results for keyphrase boundary classification on the SemEval 2017 Task 10 corpus 

Unlabelled 
Labelled 

Method 
Precision Recall F1 Precision Recall F1 

Finkel et al. (2005) 
84.16 
80.08 82.07 59.97 
53.86 56.75 
Lample et al. (2016) 
65.60 
86.06 74.45 31.30 
41.07 35.53 

BiLSTM 
83.40 
80.36 81.85 59.62 
57.45 58.51 

BiLSTM + Chunking 
83.36 
79.46 81.37 59.26 
57.24 57.84 
BiLSTM + Framenet 
84.11 
79.39 81.68 60.64 
57.24 58.89 
BiLSTM + Hyperlinks 
83.94 
79.12 81.46 60.18 
56.73 58.40 
BiLSTM + Multi-word 
84.86 
76.92 80.69 59.81 
54.21 56.87 
BiLSTM + Super-sense 84.67 
78.29 81.36 61.35 
56.73 58.95 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank Elsevier for supporting this work.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">SemEval-2017 Task 10 : Extracting Keyphrases and Relations from Scientific Publications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Augenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mrinal</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lakshmi</forename><surname>Vikraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SemEval</title>
		<meeting>SemEval</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A model of inductive bias learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Baxter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="149" to="198" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Improving historical spelling normalization with bi-directional LSTMs and multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcel</forename><surname>Bollman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING</title>
		<meeting>COLING</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multitask Learning: A Knowledge-Based Source of Inductive Bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Caruana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Frame-semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Desai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andre</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="9" to="56" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Multi-Task Learning for Multiple Language Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daxiang</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dianhai</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Incorporating non-local information into information extraction systems by Gibbs sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trond</forename><surname>Grenager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Framewise Phoneme Classification with Bidirectional LSTM and other Neural Network Architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="602" to="610" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Automatic Keyphrase Extraction: A Survey of the State of the Art</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saidul</forename><surname>Kazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">More or less supervised supersense tagging of Twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Johannsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Héctor</forename><surname>Martínez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of *SEM</title>
		<meeting>*SEM</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Barbara Plank, and Anders Søgaard</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">SemEval-2010 Task 5 : Automatic Keyphrase Extraction from Scientific Articles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olena</forename><surname>Su Nam Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min-Yen</forename><surname>Medelyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SemEval</title>
		<meeting>SemEval</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Neural Architectures for Named Entity Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandeep</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuya</forename><surname>Kawakami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="260" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Finegrained Opinion Mining with Recurrent Neural Networks and Word Embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shafiq</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helen</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep Multi-Task Learning with Shared Memory for Text Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Multi-task Sequence to Sequence Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">When is multitask learning effective? Semantic sequence prediction under varying data conditions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alonso</forename><surname>Héctor Martínez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Plank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EACL</title>
		<meeting>EACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Bounds for Linear Multi Task Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Maurer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="117" to="139" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The ACL RD-TEC 2.0: A Language Resource for Evaluating Term Extraction and Entity Recognition Methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Behrang</forename><surname>Qasemizadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anne-Kathrin</forename><surname>Schumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC</title>
		<meeting>LREC</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Semi-supervised Multitask Learning for Sequence Labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marek</forename><surname>Rei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A Corpus and Model Integrating Multiword Expressions and Supersenses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Deep multi-task learning with low level tasks supervised at lower layers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Profiting from Mark-Up: Hyper-Text Annotations for Guided Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valentin</forename><surname>Spitkovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiyan</forename><surname>Alshawi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Supervised Keyphrase Extraction as Positive Unlabeled Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Sterckx</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cornelia</forename><surname>Caragea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Demeester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Develder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Online Segment to Segment Neural Transduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Buys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
