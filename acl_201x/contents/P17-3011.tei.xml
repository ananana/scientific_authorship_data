<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:31+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Blind Phoneme Segmentation With Temporal Prediction Errors</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Michel</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Okko</forename><surname>Räsänen</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Thiollière</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emmanuel</forename><surname>Dupoux</surname></persName>
						</author>
						<title level="a" type="main">Blind Phoneme Segmentation With Temporal Prediction Errors</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of ACL 2017, Student Research Workshop</title>
						<meeting>ACL 2017, Student Research Workshop <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="62" to="68"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-3011</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Phonemic segmentation of speech is a critical step of speech recognition systems. We propose a novel unsupervised algorithm based on sequence prediction models such as Markov chains and recurrent neural networks. Our approach consists in analyzing the error profile of a model trained to predict speech features frame-by-frame. Specifically, we try to learn the dynamics of speech in the MFCC space and hypothesize boundaries from local maxima in the prediction error. We evaluate our system on the TIMIT dataset, with improvements over similar methods.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>One of the main difficulty of speech processing as opposed to text processing is the continuous, time-dependent nature of the signal. As a conse- quence, pre-segmentation of the speech signal into words or sub-words units such as phonemes, syl- lables or words is an essential first step of a variety of speech recognition tasks.</p><p>Segmentation in phonemes is useful for a num- ber of applications (annotation of speech for the purpose of phonetic analysis, computation of speech rate, keyword spotting, etc), and can be done in two ways. Supervised methods are based on an existing phoneme or word recognition sys- tem, which is used to decode the incoming speech into phonemes. Phonemes boundaries can then be extracted as a by-product of the alignment of the phoneme models with the speech. Unsuper- vised methods (also called blind segmentation) consist in finding phonemes boundaries using the acoustic signals only. Supervised methods depend * This work was done when the author was an intern at LSCP / ENS / EHESS / CNRS on the training of acoustic and language models, which requires access to large amounts of linguis- tic resources (annotated speech, phonetic dictio- nary, text). Unsupervised methods do not require these resources and are therefore appropriate for so-called under-resourced languages, such as en- dangered languages, or languages without consis- tent orthographies.</p><p>We propose a blind phoneme segmentation method based on short term statistical properties of the speech signal. We designate peaks in the error curve of a model trained to predict speech frame by frame as potential boundaries. Three dif- ferent models are tested. The first is an approx- imated Markov model of the transition probabili- ties between categorical speech features. We then replace it by a recurrent neural network operating on the same categorical features. Finally, a recur- rent neural network is directly trained to predict the raw speech features. This last model is espe- cially interesting in that it couples our statistical approach with more common spectral transition based methods <ref type="bibr" target="#b4">(Dusan and Rabiner (2006)</ref> for in- stance).</p><p>We first describe the various models used and the pre-and post-processing procedures, before presenting and discussing our results in the light of previous work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>Most previous work on blind phoneme segmenta- tion ( <ref type="bibr" target="#b6">Esposito and Aversano, 2005;</ref><ref type="bibr" target="#b7">Estevan et al., 2007;</ref><ref type="bibr" target="#b0">Almpanidis and Kotropoulos, 2008;</ref><ref type="bibr" target="#b16">Rasanen et al., 2011;</ref><ref type="bibr" target="#b13">Khanagha et al., 2014;</ref><ref type="bibr" target="#b10">Hoang and Wang, 2015)</ref> has focused on the analysis of the rate of change in the spectral domain. The idea is to design robust acoustic features that are supposed to remain stable within a phoneme, and change when transitioning from one phoneme to the next. The algorithm then define a measure of change, which is then used to detect phoneme boundaries.</p><p>Apart from this line of research, three main approaches have been explored. The first idea is to use short term statistical dependencies. In <ref type="bibr">Räsänen (2014)</ref>, the idea was to first discretize the signal using a clustering algorithm and then compute discrete sequence statistics, over which a threshold can be defined. This is the idea that we follow in the current paper. The second approach is to use dynamic programming methods inspired by text segmentation <ref type="bibr" target="#b22">(Wilber, 1988)</ref>, in order to derive optimal segmentation ( <ref type="bibr" target="#b14">Qiao et al., 2008)</ref>. In this line of research, however, the number of seg- ments is assumed to be known in advance, so this cannot count as blind segmentation. The third ap- proach consists in jointly segmenting and learning the acoustic models for phonemes <ref type="bibr" target="#b12">(Kamper et al., 2015;</ref><ref type="bibr" target="#b9">Glass, 2003;</ref><ref type="bibr" target="#b18">Siu et al., 2013</ref>). These mod- els are much more computationally involved than the other methods. Interestingly they all use a sim- pler, blind segmentation as an initialization phase. Therefore, improving on pure blind segmentation could be useful for joint models as well.</p><p>The principal source of inspiration for our work comes from previous work by <ref type="bibr" target="#b5">Elman (1990)</ref> and <ref type="bibr" target="#b2">Christiansen et al. (1998)</ref> published in the 90s. In the former, the author uses recurrent neural net- works to train character-based language models on text and notices that "The error provides a good clue as to what the recurring sequences in the in- put are, and these correlate highly with words." <ref type="bibr" target="#b5">(Elman, 1990)</ref>. More precisely, the error tends to be higher at the beginning of new words than in the middle. In the latter, the author uses El- man recurrent neural networks to predict bound- aries between words given the character sequence and phonological cues.</p><p>Our work uses the same idea, using prediction error as a cue for segmentation, but with two im- portant changes: we apply it to speech instead of text, and we use it to segment in terms of phoneme units instead of word units.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">System</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Pre-processing</head><p>We used two kinds of speech features : 13 di- mensional MFCCs ( <ref type="bibr" target="#b3">Davis and Mermelstein, 1980)</ref> (with 12 mel-cepstrum coefficients and 1 energy coefficient) and categorical one-hot vectors de- rived from MFCCs inspired by <ref type="bibr">Räsänen (2014)</ref>. The latter are computed according to <ref type="bibr">Räsänen (2014)</ref> : K-means clustering 1 is performed on a random subset of the MFCCs (10,000 frames were selected at random), with a target number of clus- ters of 8, then each MFCC is identified to the clos- est centroid. Each frame is then represented by a cluster number c ∈ {1, . . . , 8}, or alternatively by the corresponding one-hot vector of dimension 8. These hyper-parameters were chosen according to <ref type="bibr">Räsänen (2014)</ref>. <ref type="figure" target="#fig_0">Figure 1</ref> allows for a visual comparison of the three signals (waveform, MFCC, categorical).</p><p>The entire dataset is split between a training and a testing subset. A randomly selected subset of the training part is used as validation data to prevent overfitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Training phase</head><p>A frame-by-frame prediction model is then learned on the training set. The three different models used are described below :</p><p>Pseudo-markov model When trying to pre- dict the frame x t given the previous frames x t−1 0 := x t−1 , . . . , x 0 , a simplifying assumption is to model the transition probabilities with a Markov chain of higher order K, i.e. p(x t |x t−1 0 ) = p(x t | x t−1 t−K ). Provided each frame is part of a finite al- phabet, a finite (albeit exponential in K) number of transition probabilities must be learned.</p><p>However, as the order rises, the ratio between the size of the data and the number of transition probability being learned makes the exact calcula- tion more difficult and less relevant.</p><p>In order to circumvent this issue, we approxi- mate the K-order Markov chain with the mean of 1-order markov chain of the lag-transition proba- bilities p(x t |x t−i ) for 1 i K, so that</p><formula xml:id="formula_0">p(x t |x t−1 0 ) = 1 K K i=1 p(x t |x t−i )<label>(1)</label></formula><formula xml:id="formula_1">with p(x t |x t−i ) = f (xt,x t−i ) f (x t−i )</formula><p>. In practice, we chose K = 6, thus ensuring that the markov model's attention is of the same order of magnitude than the length of a phoneme.</p><p>Compared to <ref type="bibr">Räsänen (2014)</ref>, this model only uses information from previous frames and as such is completely online.</p><p>Recurrent neural network on categorical fea- tures Alternatively to Markov chains, the tran- sition probability p(x t |x t−1 0 ) can be modeled by a recurrent neural network (RNN). RNN can the- oretically model indefinite order temporal de- pendencies, hence their advantage over Markov chains for long sequence modeling.</p><p>Given a set of examples {(x t , (x t−1 0 )) | t ∈ {0, . . . , t max }}, the networks parameters are learned so that the error E(x t , RNN(x t−1 0 )) is minimized using back propagation through time <ref type="bibr" target="#b21">(Werbos, 1990</ref>) and stochastic gradient descent or a variant thereof (we have found RMSProp (Tiele- man and Hinton, 2012) to give the best results).</p><p>In our case, the network itself consists of two LSTM layers (Hochreiter and Schmidhuber, 1997) stacked on one another followed by a linear layer and a softmax. The input and output units have both dimension 8, whereas all other layers have the same hidden dimension 40. Dropout (Srivas- tava et al., 2014) with probability 0.2 was used af- ter each LSTM layer to prevent overfitting.</p><p>A pitfall of this method is the tendency of the network to predict the last frame it is fed. This is due to the fact that the sequences of categori- cal features extracted from speech contain a lot of constant sub-sequences length 2.</p><p>As a consequence, around 80% of the data fed to the network consists of sub-sequences where x t = x t−1 . Despite the fact that phone bound- aries are somewhat correlated with changes of cat- egories (around 65% of the time), this leads the network to a local minimum where it only tries to predict the same characters.</p><p>To mitigate this effect, examples where x t = x t−1 were removed with probability 0.8, so that the number of transitions was slightly skewed to- wards category transitions. The model still passed over all frames during training but the error was back-propagated for only 46% of them. This change lead to substantial improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recurrent neural network on raw MFCCs</head><p>The recurrent neural network model can be adapted to raw speech features simply by changing the loss function from categorical cross-entropy to mean squared error, which is the direct translation from a categorical distribution to a Gaussian den- sity (2x − y 2 2 + d is the Kullback-Leibler diver- gence of two d-dimensional normal distributions centered in x and y with the same scalar covari- ance matrix).</p><p>We used the same architecture than in the cat- egorical case, simply removing the softmax layer and decreasing the hidden dimension size to 20. In this case, no selection of the samples is needed since the sequences vary continuously.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Test phase</head><p>Each model is run on the test set and the prediction error is calculated at each time step according to the formula :</p><formula xml:id="formula_2">E markov (t) = − log K i=1 p(x t |x t−i ) E RNN-cat (t) = − d i=1 1 xt=i log(RNN(x t−1 0 )) E RNN-MFCC (t) = 1 d x t − RNN(x t−1 0 ) 2 2<label>(2)</label></formula><p>In each case this corresponds, up to a scaling factor constant across the dataset, to the Kullback- Leibler divergence between the predicted and ac- tual probability distribution for x t in the feature space.</p><p>Since all three systems predict probabilities conditioned by the preceding frames, they cannot be expected to give meaningful results for the first Algorithm P R F R-val Periodic 57.5 91.0 70.5 46.9 Rasanen (2014) 68.4 70.6 69.5 73.7 Markov 70.7 77.3 73.9 76.4 RNN (Cat.) 68.7 77.1 72.7 74.6 RNN (Cont.) 70.3 72.4 71.3 75.3 <ref type="table">Table 1</ref>: Final results (in%) evaluated with cropped tolerance windows frames of each utterance. To be consistent, the first 7 frames (70 ms) of the error signal for each utter- ance were set to 0. A peak detection procedure is then applied to the resulting error. As we are looking for sudden bursts in the prediction error, a local maximum is labeled as a potential boundary if and only if the difference between its value and the one of the pre- vious minimum is superior to a certain threshold δ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset</head><p>We evaluated our methods on the TIMIT dataset <ref type="bibr" target="#b8">Fischer et al. (1986)</ref>. The TIMIT dataset consists of 6300 utterances (∼ 5.4 hours) from 630 speak- ers spanning 8 dialects of the English language. The corpus was divided into a training and test set according to the standard split. The training set contains 4620 utterances (172,460 boundaries) and the test set 1680 (65,825 boundaries).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation</head><p>The performance evaluation of our system is based on precision (P ), recall (R) and F -score, defined as the harmonic mean of precision and recall. A drawback of this metric is that high recall, low precision results, such as the ones produces by hy- pothesizing a boundary every 5 ms (P : 58%, R : 91%) yield high F -score (70%).</p><p>Other metrics have been designed to tackle this issue. One such example is the R-value <ref type="bibr">(Räsänen et al., 2009)</ref> :</p><formula xml:id="formula_3">R-val = 1 − (1 − R) 2 + OS 2 + | R+1−OS √ 2 | 2<label>(3)</label></formula><p>Where OS = R P − 1 is the over-segmentation measure. The R value represents how close the segmentation is from the ideal 0 OS, 1 R point and the P=1 line in the R, OS space. Further details can be found in <ref type="bibr">Räsänen et al. (2009)</ref>.</p><formula xml:id="formula_4">Algorithm P R F R-val Periodic</formula><p>62.2 98.3 76.2 49.8 Rasanen (2014) 74.0 70.0 73.0 76.0 Markov 74.8 81.9 78.2 80.1 RNN (Cat.) 72.5 81.4 76.7 78.0 RNN <ref type="table">(Cont.)</ref> 77.6 72.7 75.0 78.6 <ref type="table">Table 2</ref>: Final results (in%) evaluated with over- lapping tolerance windows. The scores reported for Rasanen (2014) are the paper results.</p><p>Determining whether gold boundary is detected or not is a crucial part of the evaluation proce- dure. On our test set for instance, which contains 65,825 gold boundaries partitioned into 1,680 files, adding or removing one correctly detected boundary per utterance leads to a change of ± 2.5% in precision. This means that minor changes in the evaluation process (such as removing the trailing silence parts of each file, removing the opening and closing boundary) yield non-trivial variations in the end result.</p><p>A common condition for a gold boundary to be considered as 'correctly detected' is to have a pro- posed boundary within a 20 ms distance on either side. Without any other specification, this means that a proposed boundary may be matched to sev- eral gold boundaries, provided these are within 40 ms from each other, leading to an increase of up to 4% F-score in some of our results (74%-78%). Unfortunately this point is seldom detailed in the literature.</p><p>We decided to use the procedure described in <ref type="bibr">Räsänen et al. (2009)</ref> to match gold boundaries and hypothesized boundaries : overlapping toler- ance windows are cropped in the middle of the two boundaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results</head><p>The current state of the art in blind phoneme seg- mentation on the TIMIT corpus is provided by <ref type="bibr" target="#b10">Hoang and Wang (2015)</ref>. It evaluates to 78.16% F-score and 81.11 R-value on the training part of the dataset, using an evaluation method similar to our own.</p><p>In <ref type="table">Tables 1 and 2</ref> we compare our best re- sults to the previous statistical approach evoked in <ref type="bibr">Räsänen (2014)</ref> and the naive periodic boundaries segmentation (one boundary each 5 ms). Since <ref type="bibr">Räsänen (2014)</ref> used an evaluation method allow- ing for tolerance windows to overlap, we provide our results with both evaluation methods (full win- dows and cropped windows) for the sake of con- sistency.</p><p>Another main difference with Räsänen (2014) is that its results are given on the core test set of TIMIT, whereas our results are given on the full test set. <ref type="figure">Figure 2</ref>: Precision/recall curves for our various models when varying the peak detection threshold δ <ref type="figure">Figure 2</ref> provides an overview of the preci- sion/recall scores when varying the peak detec- tion threshold (and, in case of periodic boundaries, the period). This gives some insight about the ac- tual behavior of the various algorithms, especially in the high precision, low recall region where the RNN on actual MFCCs seems to outperform the methods based on discrete features.</p><p>We provide <ref type="figure" target="#fig_1">Figure 3</ref> as a qualitative assessment of the error profiles of all three algorithms on one specific utterance. Notably, the error profile of the markov model contains distinct isolated peaks of similar height. As expected, the error curve is much more noisy in the case of the RNN on MFCCs, due to the greater variability in the fea- ture space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>In terms of optimal F-score and R values, the sim- ple Markov model outperformed the previously published paper using short term sequential statis- tics <ref type="bibr">(Räsänen, 2014)</ref>, as well as the recurrent neu- ral networks. However, these optimal values may mask the differential behavior of these algorithms in different sections of the precision/recall curve.</p><p>In particular, it is interesting to notice that the neural network based model trained on the raw MFCCs gave very good results in the low recall, high precision domain. Indeed, the precision can reach 90% with a recall of 40%. Such a regime could be useful, for instance, if blind phoneme segmentation is used to help with word segmen- tation.</p><p>The reason of the higher precision of neural networks may be that it combines the sensitivity of this model to sequential statistical regularities of the signal, but also to the spectral variations, i.e. the error is also correlated to the spectral changes, meaning that some peaks are associated with a high error because the euclidean distance x t+1 − x t 2 itself is big. This is why the height difference is much more significant in this case. Although we only reported the best results, we also tested our model on two other neural network architectures : a single vanilla RNN and a single LSTM cell. Both architecture did not yield signifi- cantly different results (∼ 1-2% F-score, mainly dropping precision). Similarly, different hidden dimension were tested. In the extreme cases (very low -8 -or high -128 -dimension), the output signal proved too noisy to be of any significance, yielding results comparable to naive periodic seg- mentation.</p><p>It is worth mentioning that our approach doesn't make any language specific assumption, and as such similar results are to be expected on other languages. We leave the confirmation of this as- sumption to future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>66</head><p>We have presented a lightweight blind phoneme segmentation method predicting boundaries at peaks of the prediction loss of transition probabil- ities models. The different models we tested pro- duced satisfying results while remaining computa- tionally tractable, requiring only one pass over the data at test time.</p><p>Our recurrent neural network trained on speech features in particular hints at a way of combining both the statistical and spectral information into a single model.</p><p>On a machine learning point of view, we high- lighted the use that can be made of side channel information (in this case the test error) in order to extract structure from raw data in an unsupervised setting.</p><p>Future work may involve exploring different RNN models, assessing the stability of these meth- ods on simpler features such as raw spectrograms or waveforms, or exploring the representation of each frame in the hidden layers of the networks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Visual representation of the various features on 100 frames from the TIMIT corpus. From top to bottom are the waveform, the 13dimensional MFCCs and the 8-dimensional one hot encoded categorical features.</figDesc><graphic url="image-1.png" coords="2,307.28,88.76,218.27,194.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Comparison of error signals (gold boundaries are indicated in red)</figDesc><graphic url="image-3.png" coords="5,307.28,307.94,218.26,186.58" type="bitmap" /></figure>

			<note place="foot" n="1"> In particular, we use the K-means++ (Arthur and Vassilvitskii, 2007) algorithm, and pick the best outcome of 10 random initializations</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Acknowledgements</head><p>The authors would like to thank the anonymous re-viewers for their insightful and constructive com-ments which helped shape the final version of this paper.</p><p>This project is supported by the Euro-pean Research Council (ERC-2011-AdG-295810 BOOTPHON), the Agence Nationale pour la Recherche (ANR-10-LABX-0087 IEC, ANR-10-IDEX-0001-02 PSL*), the Fondation de France, the Ecole de Neurosciences de Paris, the Region Ile de France (DIM cerveau et pensée), and an AWS in Education Research Grant award.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Phonemic segmentation using the generalised gamma distribution and small sample bayesian information criterion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Almpanidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Constantine</forename><surname>Kotropoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Speech Communication</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="38" to="55" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">2007. kmeans++: The advantages of careful seeding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Arthur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergei</forename><surname>Vassilvitskii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms. Society for Industrial and Applied Mathematics</title>
		<meeting>the eighteenth annual ACM-SIAM symposium on Discrete algorithms. Society for Industrial and Applied Mathematics</meeting>
		<imprint>
			<biblScope unit="page" from="1027" to="1035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning to segment speech using multiple cues: A connectionist model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Morten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Christiansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Seidenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language and cognitive processes</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="221" to="268" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Comparison of parametric representations for monosyllabic word recognition in continuously spoken sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Mermelstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on acoustics, speech, and signal processing</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="357" to="366" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">On the relation between maximum spectral transition positions and phone boundaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sorin</forename><surname>Dusan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lawrence R Rabiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Finding structure in time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jeffrey L Elman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="211" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Text independent methods for speech segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Esposito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guido</forename><surname>Aversano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Nonlinear Speech Modeling and Applications</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="261" to="290" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Finding maximum margin segments in speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yago</forename><surname>Pereiro Estevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Odette</forename><surname>Scharenborg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2007 IEEE International Conference on Acoustics, Speech and Signal ProcessingICASSP&apos;07. IEEE</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">937</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The darpa speech recognition research database: Specifications and status</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">M</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">R</forename><surname>Doddington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen M Goudie-Marshall</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of DARPA Workshop on Speech Recognition</title>
		<meeting>DARPA Workshop on Speech Recognition</meeting>
		<imprint>
			<date type="published" when="1986" />
			<biblScope unit="page" from="93" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A probabilistic framework for segment-based speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>James R Glass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="137" to="152" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Blind phone segmentation based on spectral change detection using legendre polynomial approximation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dac-Thang</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsiao-Chuan</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">137</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="797" to="805" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Fully unsupervised small-vocabulary speech recognition using a segmental bayesian model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herman</forename><surname>Kamper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aren</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Goldwater</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Phonetic segmentation of speech signal using local singularity analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vahid</forename><surname>Khanagha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khalid</forename><surname>Daoudi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Digital Signal Processing</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="86" to="94" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Oriol Pont, and Hussein Yahia</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Unsupervised optimal phoneme segmentation: Objectives, algorithm and comparisons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naoya</forename><surname>Shimomura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nobuaki</forename><surname>Minematsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2008 IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="3989" to="3992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Basic cuts revisited: Temporal segmentation of speech into phone-like units with statistical learning at a pre-linguistic level</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Okko Räsänen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th Annual Conference of the Cognitive Science Society</title>
		<meeting>the 36th Annual Conference of the Cognitive Science Society<address><addrLine>Quebec, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Blind segmentation of speech using nonlinear filtering methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toomas</forename><surname>Okko Rasanen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Unto</forename><surname>Altosaar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Laine</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>INTECH Open Access Publisher</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">An improved speech segmentation quality measure: the r-value</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Okko Räsänen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toomas</forename><surname>Unto Kalervo Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Altosaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Unsupervized training of an HMM-based self-organizing recognizer with applications to topic classification and keyword discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Man-Hung</forename><surname>Siu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herbert</forename><surname>Gish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Belfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language preprint</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude. COURSERA: Neural Networks for</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tijmen</forename><surname>Tieleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Backpropagation through time: what it does and how to do it</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Paul J Werbos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1550" to="1560" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The concave least-weight subsequence problem revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Wilber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Algorithms</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="418" to="425" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
