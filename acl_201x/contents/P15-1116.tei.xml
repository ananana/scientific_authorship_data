<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:48+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Discontinuous Incremental Shift-Reduce Parsing</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Maier</surname></persName>
							<email>maierw@hhu.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Universität Düsseldorf Institut für Sprache und Information Universitätsstr. 1</orgName>
								<address>
									<postCode>40225</postCode>
									<settlement>Düsseldorf</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Discontinuous Incremental Shift-Reduce Parsing</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1202" to="1212"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present an extension to incremental shift-reduce parsing that handles discon-tinuous constituents, using a linear clas-sifier and beam search. We achieve very high parsing speeds (up to 640 sent./sec.) and accurate results (up to 79.52 F 1 on TiGer).</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Discontinuous constituents consist of more than one continuous block of tokens. They arise through phenomena which traditionally in linguis- tics would be analyzed as being the result of some kind of "movement", such as extraposition or top- icalization. The occurrence of discontinuous con- stituents does not necessarily depend on the de- gree of freedom in word order that a language al- lows for. They can be found, e.g., in almost equal proportions in English and German treebank data ( <ref type="bibr" target="#b9">Evang and Kallmeyer, 2011</ref>).</p><p>Generally, discontinuous constituents are ac- counted for in treebank annotation. One annota- tion method consists of using trace nodes that de- note the source of a movement and are co-indexed with the moved constituent. Another method is to annotate discontinuities directly by allowing for crossing branches. <ref type="figure">Fig. 1</ref> shows an example for the latter approach with which we are concerned in this paper, namely, the annotation of (1). The tree contains a discontinuous VP due to the fact that the fronted pronoun is directly attached. framed as a separate pre-, post-or in-processing task to PCFG parsing <ref type="bibr" target="#b16">(Johnson, 2002;</ref><ref type="bibr" target="#b7">Dienes and Dubey, 2003;</ref><ref type="bibr" target="#b15">Jijkoun, 2003;</ref><ref type="bibr" target="#b18">Levy and Manning, 2004;</ref><ref type="bibr" target="#b29">Schmid, 2006;</ref><ref type="bibr">Cai et al., 2011, among others)</ref>; see particularly <ref type="bibr" target="#b29">Schmid (2006)</ref> for more details. Directly annotated discontinuous con- stituents can be parsed with a dependency parser, given a reversible transformation from discontin- uous constituency trees to non-projective depen- dency structures. Transformations have been pro- posed by <ref type="bibr" target="#b14">Hall and Nivre (2008)</ref>, who use com- plex edge labels that encode paths between lexical heads, and recently by <ref type="bibr" target="#b11">Fernández-González and Martins (2015)</ref>, who use edge labels to encode the attachment order of modifiers to heads.</p><p>Direct parsing of discontinuous constituents can be done with Linear Context-Free Rewriting Sys- tem (LCFRS), an extension of CFG which allows its non-terminals to cover more than one contin- uous block <ref type="bibr" target="#b35">(Vijay-Shanker et al., 1987)</ref>. LCFRS parsing is expensive: CYK chart parsing with a binarized grammar can be done in O(n 3k ) where k is the block degree, the maximal number of con- tinuous blocks a non-terminal can cover ( <ref type="bibr" target="#b31">Seki et al., 1991)</ref>. For a typical treebank LCFRS <ref type="bibr" target="#b21">(Maier and Søgaard, 2008)</ref>, k ≈ 3, instead of k = 1 for PCFG. In order to improve on otherwise imprac- tical parsing times, LCFRS chart parsers employ different strategies to speed up search: <ref type="bibr" target="#b17">Kallmeyer and Maier (2013)</ref> use A * search; van Cranenburgh (2012) and van <ref type="bibr" target="#b32">Cranenburgh and Bod (2013)</ref> use a coarse-to-fine strategy in combination with Data- Oriented Parsing; <ref type="bibr" target="#b0">Angelov and Ljunglöf (2014)</ref> use a novel cost estimation to rank parser items. <ref type="bibr" target="#b22">Maier et al. (2012)</ref> apply a treebank transforma- tion which limits the block degree and therewith also the parsing complexity.</p><p>Recently Versley (2014) achieved a break- through with a EaFi, a classifier-based parser that uses an "easy-first" approach in the style of <ref type="bibr" target="#b12">Goldberg and Elhadad (2010)</ref>. In order to obtain dis- continuous constituents, the parser uses a strat- egy known from non-projective dependency pars- ing <ref type="bibr" target="#b25">(Nivre, 2009;</ref>): For every non-projective dependency tree, there is a projec- tive dependency tree which can be obtained by reordering the input words. Non-projective de- pendency parsing can therefore be viewed as pro- jective dependency parsing with an additional re- ordering of the input words. The reordering can be done online during parsing with a "swap" op- eration that allows to process input words out of order. This idea can be transferred, because also for every discontinuous constituency tree, one can find a continuous tree by reordering the terminals. <ref type="bibr" target="#b34">Versley (2014)</ref> uses an adaptive gradient method to train his parser. He reports a parsing speed of 40-55 sent./sec. and results that surpass those re- ported for the above mentioned chart parsers.</p><p>In (continuous) constituency parsing, incremen- tal shift-reduce parsing using the structured per- ceptron is an established technique. While the structured perceptron for parsing has first been used by <ref type="bibr" target="#b5">Collins and Roark (2004)</ref>, classifier-based incremental shift-reduce parsing has been taken up by <ref type="bibr" target="#b27">Sagae and Lavie (2005)</ref>. A general formula- tion for the application of the perceptron algorithm to various problems, including shift-reduce con- stituency parsing, has been introduced by <ref type="bibr" target="#b38">Zhang and Clark (2011b)</ref>. Improvements have followed ( <ref type="bibr" target="#b39">Zhu et al., 2012;</ref><ref type="bibr" target="#b40">Zhu et al., 2013)</ref>. A similar strat- egy has been shown to work well for CCG parsing <ref type="bibr" target="#b37">(Zhang and Clark, 2011a)</ref>, too.</p><p>In this paper, we contribute a perceptron-based shift-reduce parsing architecture with beam search (following <ref type="bibr" target="#b40">Zhu et al. (2013)</ref> and <ref type="bibr" target="#b1">Bauer (2014)</ref>) and extend it such that it can create trees with crossing branches (following <ref type="bibr" target="#b34">Versley (2014)</ref>). We present strategies to improve performance on dis- continuous structures, such as a new feature set.</p><p>Our parser is very fast (up to 640 sent./sec.), and produces accurate results. In our evaluation, where we pay particular attention to the parser performance on discontinuous structures, we show among other things that surprisingly, a grammar- based parser has an edge over a shift-reduce ap- proach concerning the reconstruction of discontin- uous constituents.</p><p>The remainder of the paper is structured as fol- lows. In subsection 2.1, we introduce the gen- eral parser architecture; the subsections 2.2 and 2.3 introduce the features we use and our strat- egy for handling discontinuous structures. Section 3 presents and discusses the experimental results, section 4 concludes the article.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Discontinuous Shift-Reduce Parsing</head><p>Our parser architecture follows previous work, particularly <ref type="bibr" target="#b40">Zhu et al. (2013)</ref> and Bauer (2014).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Shift-reduce parsing with perceptron training</head><p>An item in our parser consists of a queue q of token/POS-pairs to be processed, and a stack s, which holds completed constituents. <ref type="bibr">1</ref> The parser uses different transitions: SHIFT shifts a termi- nal from the queue on to the stack. UNARY-X reduces the first element on the stack to a new constituent labeled X. BINARY-X-L and BINARY- X-R reduce the first two elements on the stack to a new X constituent, with the lexical head com- ing from the left or the right child, respectively. FINISH removes the last element from the stack. We additionally use an IDLE transition, which can be applied any number of times after FINISH, to improve the comparability of analyses of different lengths ( <ref type="bibr" target="#b40">Zhu et al., 2013)</ref>. The application of a transition is subject to re- strictions. UNARY-X, e.g., can only be applied when there is at least a single item on the stack. We implement all restrictions listed in the ap- pendix of <ref type="bibr" target="#b36">Zhang and Clark (2009)</ref>, and add addi- tional restrictions that block transitions involving the root label when not having arrived at the end of a derivation. We do not use an underlying gram- mar to filter out transitions which have not been seen during training.</p><p>For decoding, we use beam search <ref type="bibr" target="#b38">(Zhang and Clark, 2011b</ref>). Decoding is started by putting the Then, repeatedly, a candidate list is filled with all items that result from applying legal transitions to the items on the beam, followed by putting the highest scoring n of them back on the beam (given a beam size of n). Parsing is finished if the high- est scoring item on the beam is a final item (stack holds one item labeled with the root label, queue is empty), which can be popped. Item scores are computed as in <ref type="bibr" target="#b38">Zhang and Clark (2011b)</ref>: The score of the i + 1th item is computed as the sum of the score of the ith item and the dot product of a global feature weight vector and the local weight vector resulting from the changes induced by the corresponding transition to the i + 1th item. The start item has score 0. We train the global weight vector with an averaged Perceptron with early up- date ( <ref type="bibr" target="#b5">Collins and Roark, 2004</ref>).</p><p>Parsing relies on binary trees. As in previ- ous work, we binarize the incoming trees head- outward with binary top and bottom productions. Given a constituent X which is to be binarized, all intermediate nodes which are introduced will be labeled @X. Lexical heads are marked with Collins-style head rules. As an example, <ref type="figure" target="#fig_1">Fig. 2</ref> shows the binarized version of the tree of <ref type="figure">Fig. 1</ref>.</p><p>Finally, since we are learning a sparse model, we also exploit the work of Goldberg and Elhadad (2011) who propose to include a feature in the cal- culation of a score only if it has been observed ≥ MINUPDATE times.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Features</head><p>Features are generated by applying templates to parser items. They reflect different configurations of stack and queue. As BASELINE features, we use the feature set from <ref type="bibr" target="#b36">Zhang and Clark (2009)</ref> without the bracketing features (as used in <ref type="bibr" target="#b40">Zhu et al. (2013)</ref>). We furthermore experiment with fea- tures that reflect the presence of separating punctu- ation ",", ":", ";" (SEPARATOR) ( <ref type="bibr" target="#b36">Zhang and Clark, 2009)</ref>, and with the EXTENDED features of Zhu et unigrams s0tc, s0wc, s1tc, s1wc, s2tc, s2wc, s3tc, s3wc, q0wt, q1wt, q2wt, q3wt, s0lwc, s0rwc, s0uwc, s1lwc, s1rwc, s1uwc bigrams s0ws1w, s0ws1c, s0cs1w, s0cs1c, s0wq0w, s0wq0t, s0cq0w, s0cq0t, s1wq0w, s1wq0t, s1cq0w, s1cq0t, q0wq1w, q0wq1t, q0tq1w, q0tq1t trigrams s0cs1cs2w, s0cs1cs2c, s0cs1cq0w, s0cs1cq0t, s0cs1wq0w, s0cs1wq0t, s0ws1cs2c, s0ws1cq0t extended s0llwc, s0lrwc, s0luwc, s0rlwc, s0rrwc, s0ruwc, s0ulwc, s0urwc, s0uuwc, s1llwc, s1lrwc, s1luwc, s1rlwc, s1rrwc, s1ruwc separator s0wp, s0wcp, s0wq, s0wcq, s0cs1cp, s0cs1cq s1wp, s1wcp, s1wq, s1wcq  <ref type="formula">(2013)</ref>, which look deeper into the trees on the stack, i.e., up to the grand-children instead of only to children. <ref type="figure" target="#fig_2">Fig. 3</ref> shows all the feature templates. Note that s i and q i stands for the ith stack and queue item, w stands for the head word, t for the head tag and c for the constituent label (w, t and c are identi- cal on POS-level). l and r (ll and rr) represent the left and right children (grand-children) of the element on the stack; u handles the unary case. Concerning the separator features, p is a unique separator punctuation between the head words of s 0 and s 1 , q is the count of any separator punctua- tion between s 0 and s 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Handling Discontinuities</head><p>In order to handle discontinuities, we use two variants of a swap transition which are similar to swap-eager and swap-lazy from Nivre <ref type="formula">(2009)</ref>  3. all elements to be swapped are pre-terminals, and 4. if the first item of the stack has a lower index than the second (this inhibits swap loops).</p><p>SINGLESWAP can only been applied if there are at least two items on the stack. For COM- POUNDSWAP i , there must be at least i + 1 items.</p><p>Transition sequences are extracted from tree- bank trees with an algorithm that traverses the tree bottom-up and collects the transitions. For a given tree τ , intuitively, the algorithm works as follows. We start out with a queue t containing the pre- terminals of τ , a stack σ that receives finished con- stituents, a counter s that keeps track of the num- ber of terminals to be swapped, and an empty se- quence r that holds the result. First, the first ele- ment of t is pushed on σ and removed from t.</p><p>While |σ| &gt; 0 or |t| &gt; 0, we repeat the follow- ing two steps.</p><p>1. Repeat while transitions can be added:</p><p>(a) if the top two elements on σ, l and r, have the same parent p labeled X and l/r is the head of p, add BINARY-X-l/r to r, pop two elements from σ and push p; (b) if the top element on σ is the only child of its parent p labeled X, add UNARY- X, pop an element of σ and push p.</p><p>2. If |t| &gt; 0, while the first element of t is not equal to the leftmost pre-terminal dominated by the right child of the parent of the top el- ement on σ (i.e., while there are terminals that must be swapped), add SHIFT to r, in- crement s, push the first element of t on σ and remove it from t. Finally, add another SHIFT to r, push first element of t to σ and remove it from t (this will contribute to the next reduction). If s &gt; 0, we must swap. Ei- ther we add s many SWAP transitions or one COMPOUNDSWAP s to r. Then we move s many elements from σ to the front of t, start- ing with the second element of σ. Finally we set s = 0.</p><p>As an example, consider the transition sequence we would extract from the tree in <ref type="figure" target="#fig_1">Fig. 2</ref>. Using SINGLESWAP, we would obtain SHIFT, SHIFT, SHIFT, SHIFT, SINGLESWAP, SINGLESWAP, BINARY-VP-R, SHIFT, BINARY-@S-R, SHIFT, BINARY-S-L, FINISH. Using COMPOUNDSWAP i , instead of two SINGLESWAPs, we would just ob- tain a single COMPOUNDSWAP 2 . unigrams s0xwc, s1xwc, s2xwc, s3xwc, s0xtc, s1xwc, s2xtc, s3xwc, s0xy, s1xy, s2xy, s3xy bigrams s0xs1c, <ref type="bibr">s0xs1w, s0xs1x, s0ws1x, s0cs1x, s0xs2c, s0xs2w, s0xs2x, s0ws2x, s0cs2x</ref>, s0ys1y, s0ys2y, s0xq0t, s0xq0w</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 4: Features for discontinuous structures</head><p>We explore two methods which improve the performance on discontinuous structures. Even though almost a third of all sentences in the Ger- man NeGra and TiGer treebanks contains at least one discontinuous constituent, among all con- stituents, the discontinuous ones are rare, making up only around 2%. The first, simple method ad- dresses this sparseness by raising the importance of the features that model the actual discontinu- ities by counting all feature occurrences at a gold swap transition twice (IMPORTANCE).</p><p>Secondly, we use a new feature set (DISCO) with bigram and unigram features that conveys in- formation about discontinuities. The features con- dition the possible occurrence of a gap on previ- ous gaps and their properties. <ref type="bibr">2</ref> The feature tem- plates are shown in <ref type="figure">Fig. 4</ref>. x denotes the gap type of a tree on the stack. There are three possi- ble values, either "none" (tree is fully continuous), "pass" (there is a gap at the root, i.e., this gap must be filled later further up in the tree), or "gap" (the root of this tree fills a gap, i.e., its children have gaps, but the root does not). Finally, y is the sum of all gap lengths.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data</head><p>We use the TiGer treebank release 2.2 (TIGER), and the NeGra treebank (NEGRA). For TIGER, we use the first half of the last 10,000 sentences for development and the second half for testing. <ref type="bibr">3</ref> We also recreate the split of Hall and Nivre (2008) (TIGERHN), for which we split TiGer in 10 parts, assigning sentence i to part imod 10. The first of those parts is used for testing, the concatenation of the rest for training.</p><p>From NeGra, we exclude all sentences longer than 30 words (in order to make a comparison with rparse possible, see below), and split off the last 10% of the treebank for testing, as well as the previous 10% for development. As a pre- processing step, in both treebanks we remove spu- rious discontinuities that are caused by material which is attached to the virtual root node (mainly punctuation). All such elements are attached to the least common ancestor node of their left and right terminal neighbors (as proposed by <ref type="bibr" target="#b19">Levy (2005)</ref>, p. 163). We furthermore create a continuous vari- ant NEGRACF of NEGRA with the method usu- ally used for PCFG parsing: For all maximal con- tinuous parts of a discontinuous constituent, a sep- arate node is introduced <ref type="bibr" target="#b2">(Boyd, 2007)</ref>. Subse- quently, all nodes that do not cover the head child of the discontinuous constituent are removed.</p><p>No further preprocessing or cleanup is applied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experimental Setup</head><p>Our parser is implemented in Java. We run all our experiments with Java 8 on an Intel Core i5, al- locating 15 GB per experiment. All experiments are carried out with gold POS tags, as in previous work on shift-reduce constituency parsing ( <ref type="bibr" target="#b36">Zhang and Clark, 2009)</ref>. Grammatical function labels are discarded.</p><p>For the evaluation, we use the corresponding module of discodop. <ref type="bibr">4</ref> We report several metrics (as implemented in discodop):</p><p>• Extended labeled bracketing, in which a bracket for a single node consists of its la- bel and a set of pairs of indices, delimiting the continuous blocks it covers. We do not include the root node in the evaluation and ignore punctuation. We report labeled preci- sion, recall and F 1 , as well as exact match (all brackets correct).</p><p>• Leaf-ancestor ( <ref type="bibr" target="#b28">Sampson and Babarczy, 2003)</ref>, for which we consider all paths from leaves to the root.</p><p>• Tree edit distance <ref type="bibr" target="#b8">(Emms, 2008)</ref>, which con- sists of the minimum edit distance between gold tree and parser output.</p><p>Aside from a full evaluation, we also evaluate only the constituents that are discontinuous.  <ref type="formula">(2006)</ref>).</p><p>We run further experiments with rparse 5 ( <ref type="bibr" target="#b17">Kallmeyer and Maier, 2013)</ref> to facilitate a com- parison with a grammar-based parser.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results</head><p>We start with discontinuous parsing experiments on NEGRA and TIGER, followed by continu- ous parsing experiments, and a comparison to grammar-based parsing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Discontinuous Parsing</head><p>NeGra The first goal is to determine the effect of different beam sizes with BASELINE features and the COMPOUNDSWAP i operation. We run ex- periments with beam sizes 1, 2, 4 and 8; <ref type="figure">Fig. 5</ref> shows the results obtained on the dev set after each iteration. <ref type="figure">Fig. 6</ref> shows the average decod- ing speed during each iteration for each beam size (both smoothed).</p><p>Tracking two items instead of one results in a large improvement. Raising the beam size from 2 to 4 results in a smaller improvement. The im- provement obtained by augmenting the beam size from 4 to 8 is even smaller. This behavior is mir- rored by the parsing speeds during training: The differences in parsing speed roughly align with the result differences. Note that fast parsing during training means that the parser does not perform well (yet) and that therefore, early update is done more often. Note finally that the average parsing speeds on the test set after the last training iteration   In the second block, we run the BASELINE features with COMPOUNDSWAP i combined with SEPARATOR, EXTENDED and DISCO. The SEP- ARATOR features were not as successful as they were for <ref type="bibr" target="#b36">Zhang and Clark (2009)</ref>. All scores for discontinuous constituents drop (compared to the baseline). The EXTENDED features are more ef- fective and give an improvement of about half a point F 1 on all constituents, as well as the highest exact match among all experiments. On discontin- uous constituents, precision raises slightly but we loose about 1.4% in recall (compared to the base- line). The latter seems to be due to the fact that in comparison to the baseline, with EXTENDED, more sentences get erroneously analyzed as not containing any crossing branches. This effect can be explained with data sparseness and is less pro- nounced when more training data is available (see below). Similarly to EXTENDED, the new DISCO features lead to a slight gain over the baseline (on all constituents). As with EXTENDED, on discon- tinuous constituents, we again gain precision (3%) but loose recall (0.5%), because more sentences wrongly analyzed as not having discontinuities than in the BASELINE. A category-based evalua- tion of discontinuous constituents reveals that EX- TENDED has an advantage over DISCO when con- sidering all constituents. However, we can also see that the DISCO features yield better results than EXTENDED particularly on the frequent discontin- uous categories (NP, VP, AP, PP), which indicates that the information about gap type and gap length is useful for the recovery of discontinuities. IM- PORTANCE (see Sec. 2.3) is not very successful, yielding results which lie in the vicinity of those of the BASELINE.</p><p>In the third block of the tables, we test the per- formance of the DISCO features in combination with other techniques, i.e., we use the BASELINE and DISCO features with COMPOUNDSWAP i and combine it with EXTENDED and SEPARATOR fea- tures as well as with the IMPORTANCE strategy. All experiments beat the BASELINE/DISCO com- bination in terms of F 1 . EXTENDED and DISCO give a cumulative advantage, resulting in an in- crease of precision of almost 4%, resp. over 6% on discontinuous constituents, compared to the use of DISCO, resp. EXTENDED alone. Adding the SEPARATOR features to this combination does not bring an advantage. The IMPORTANCE strategy is the most successful one in combination with DISCO, causing a boost of almost 10% on preci- sion of discontinuous constituents, leading to the highest overall discontinuous F 1 of 29.41 (notably more than 12 points higher than the baseline); also on all constituents we obtain the third-highest F 1 . Combining DISCO with IMPORTANCE and EX- TENDED leads to the highest overall F 1 on all con- stituents of 76.95, however, the results on discon- tinuous constituents are slightly lower than for IM- PORTANCE alone. This confirms the previously observed behavior: The EXTENDED features help when considering all constituents, but they do not seem to be effective for the recovery of disconti- nuities in particular.</p><p>In the TED and LA scores (Tab. 2), we see much less variation than in the bracketing scores. As re- ported in the literature (e.g., <ref type="bibr" target="#b26">Rehbein and van Genabith (2007)</ref>), this is because of the fact that with bracketing evaluation, a single wrong attachment can "break" brackets which otherwise would be counted as correct. Nevertheless, the trends from bracketing evaluation repeat.</p><p>To sum up, the COMPOUNDSWAP i operation works better than SWAP because the latter misses long gaps. The most useful feature sets were EX- TENDED and DISCO, both when used indepen- dently and when used together. DISCO was partic- ularly useful for discontinuous constituents. SEP- ARATOR yielded no usable improvements. IM- PORTANCE has also proven to be effective, yield- ing the best results on discontinuous constituents (in combination with DISCO). Over almost all ex- periments, a common error is that on root level, CS and S get confused, indicating that the present features do not provide sufficient information for disambiguation of those categories. We can also confirm the tendency that discontinuous VPs in relatively short sentences are recognized correctly, as reported by <ref type="bibr" target="#b34">Versley (2014)</ref>.</p><p>TiGer We now repeat the most successful exper- iments on TIGER. Tab. 3 shows the parsing results for the test set.</p><p>Some of the trends seen on the experiments with NEGRA are repeated. EXTENDED and DISCO yields an improvement on all constituents. How- ever, now not only DISCO, but also EXTENDED lead to improved scores on discontinuous con- stituents. As mentioned above, this can be ex- plained with the fact that for the EXTENDED fea- tures to be effective, the amount of training data available in NEGRA was not enough. Other than in NEGRA, the DISCO features are now more ef- fective when used alone, leading to the highest overall F 1 on discontinuous constituents of 19.45. They are, however, less effective in combination with EXTENDED. This is partially remedied by giving the swap transitions more IMPORTANCE, which leads to the highest overall F 1 on all con- stituents of 74.71.</p><p>The models we learn are sparse, therefore, as mentioned above, we can exploit the work of <ref type="bibr" target="#b13">Goldberg and Elhadad (2011)</ref>. They propose to only include the weight of a feature in the compu- tation of a score if it has been seen more than MIN- UPDATE times. We repeat the BASELINE experi- ment with two different MINUPDATE settings (see <ref type="table">Tab.</ref> 3). As expected, the MINUPDATE models are much smaller. The final model with the baseline experiment uses 8.3m features (parsing speed on test set 73 sent./sec.), with MINUPDATE 5 3.3m features (121 sent./sec.) and with MINUPDATE 10 1.8m features (124 sent./sec.). With MINUP- DATE 10, the results do degrade. However, with MINUPDATE 5 in addition to the faster parsing we consistently improve over the baseline.</p><p>Finally, in order to check the convergence, we run a further experiment in which we limit train- ing iterations to 40 instead of 20, together with beam size 4. We use the BASELINE features with COMPOUNDSWAP i combined with DISCO, EX-    <ref type="figure">Fig. 5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Continuous Parsing</head><p>We investigate the impact of the swap transitions on both speed and parsing results by running an experiment with NEGRACF using the BASELINE and EXTENDED features. The corresponding re- sults are shown in Tab. 4.</p><p>Particularly high frequency categories (NP, VP, S) are much easier to find in the continuous case and show large improvements. This explains why without the swap transition, F 1 with BASELINE features is 6.9 points higher than the F 1 on discon- tinuous constituents (with COMPOUNDSWAP i ). With the EXTENDED features, we obtain a small improvement.</p><p>Note that with the shift-reduce approach, the difference between the computational cost of pro- ducing discontinuous constituents vs. the cost of producing continuous constituents is much lower than for a grammar-based approach. When pro- ducing continuous constituents, parsing is only 20% faster than with the swap transition, namely 97 instead of 81 sentences per second.</p><p>In order to give a different perspective on the role of discontinuous constituents, we perform two further evaluations. First, we remove the dis- continuities from the output of the discontinuous baseline parser using the procedure described in Sec. 3.1 and evaluate the result against the con- tinuous gold data. We obtain an F 1 of 76.70, 5.5 points lower than the continuous baseline.  Secondly, we evaluate the output of the continu- ous baseline parser against the discontinuous gold data. This leads to an F 1 78.89, 2.9 point more than the discontinuous baseline. Both evaluations confirm the intuition that parsing is much easier when discontinuities (i.e., in our case the swap transition) do not have to be considered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Comparison with other Parsers</head><p>rparse In order to compare our parser with a grammar-based approach, we now parse NEGRA with rparse, with the same training and test sets as before (i.e., we do not use the development set). We employ markovization with v = 1, h = 2 and head driven binarization with binary top and bot- tom productions. The first thing to notice is that rparse is much slower than our parser. The average parsing speed is about 0.3 sent./sec.; very long sentences require over a minute to be parsed. The parsing results are shown in Tab. 5. They are about 5 points worse than those reported by <ref type="bibr" target="#b17">Kallmeyer and Maier (2013)</ref>. This is due to the fact that they train on the first 90% of the treebank, and not on the first 80% as we do, which leads to an increased number of unparsed sentences. In comparison to the baseline setting of the shift-reduce parser with beam size 8, the results are around 10 points worse. How- ever, rparse reaches an F 1 of 26.61 on discontinu- ous constituents, which is 5.9 points more than we achieved with the best setting with our parser.</p><p>In order to investigate why the grammar-based approach outperforms our parser on discontinuous constituents, we count the frequency of LCFRS productions of a certain gap degree in the bina- rized grammar used in the rparse experiment. The  <ref type="bibr" target="#b34">Versley (2014</ref><ref type="bibr">Versley ( ) 74.23 37.32 this work 79.52 44.32 H&amp;N (2008</ref> 79.93 <ref type="bibr">37.78 F&amp;M (2015)</ref> 85.53 51.21 average occurrence count of rules with gap degree 0 is 12.18. Discontinuous rules have a much lower frequency, the average count of productions with one, two and three gaps being 3.09, 2.09, and 1.06, respectively. In PCFG parsing, excluding low fre- quency productions does not have a large effect <ref type="bibr" target="#b4">(Charniak, 1996)</ref>; however, this does not hold for LCFRS parsing, where they have a major influ- ence (cf. Maier <ref type="bibr">(2013, p. 205)</ref>): This means that removing low frequency productions has a nega- tive impact on the parser performance particularly concerning discontinuous structures; however, it also means that low frequency discontinuous pro- ductions get triggered reliably. This hypothesis is confirmed by the fact that the our parser per- forms much worse on discontinuous constituents with a very low frequency (such as CS, making up only 0.62% of all discontinuous constituents) than it performs on those with a high frequency (such as VP, making up 60.65% of all discontin- uous constituents), while rparse performs well on the low frequency constituents. Our results exceed those of EaFi 6 and the ex- act match score of H&amp;N. We are outperformed by the F&amp;M parser. Note, that particularly the com- parison to EaFi must be handled with care, since Versley (2014) uses additional preprocessing: PP- internal NPs are annotated explicitly, and the par- enthetical sentences are changed to be embedded by their enclosing sentence (instead of vice versa).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EaFi and Dependency Parsers</head><p>We postpone a thorough comparison with both EaFi and the dependency parsers to future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Discussion</head><p>To our knowledge, surprisingly, numerical scores for discontinuous constituents have not been re- ported anywhere in previous work. The relatively low overall performance with both grammar-based and shift-reduce based parsing, along with the fact that the grammar-based approach outperforms the shift-reduce approach, is striking. We have shown that it is possible to push the precision on discon- tinuous constituents, but not the recall, to the level of what can be achieved with a grammar-based ap- proach.</p><p>Particularly the outcome of the experiments involving the EXTENDED features and IMPOR- TANCE drives us to the conclusion that the major problem when parsing discontinuous constituents is data sparseness. More features cannot be the only solution: A more reliable recognition of dis- continuous constituents requires a more robust learning from larger amounts of data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>We have presented a shift-reduce parser for dis- continuous constituents which combines previous work in shift-reduce parsing for continuous con- stituents with recent work in easy-first parsing of discontinuous constituents. Our experiments con- firm that an incremental shift-reduce architecture with a swap transition can indeed be used to parse discontinuous constituents. The swap transition is associated with a low computational cost. We have obtained a speed-up of up to 2,000% in compar- ison to the grammar-based rparse, and we have shown that we obtain better results than with the grammar-based parser, even though the grammar- based strategy does better at the reconstruction of discontinuous constituents.</p><p>In future work, we will concentrate on methods that could remedy the data sparseness concerning discontinuous constituents, such as self-training. Furthermore, we will experiment with larger fea- ture sets that add lexical information. An for- mal investigation of the expressivity of our parsing model is currently under way.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Figure 1: Example annotation with discontinuous constituents from TiGer</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Binarization example</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Feature templates</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>and Nivre et al. (2009). The first variant, SIN- GLESWAP, swaps the second item of the stack back on the queue. The second variant COM- POUNDSWAP i bundles a maximal number of ad- jacent swaps. It swaps i items starting from the second item on the stack, with 1 ≤ i &lt; |s|. Both swap operations can only be applied if 1. the item has not yet been FINISHed and the last transition has not been a transition with the root category, 2. the queue is not empty,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>All</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>We run an ex- periment with 40 iterations on TIGERHN, using DISCO, EXTENDED and IMPORTANCE. Tab. 6 lists the results, together with the correspond- ing results of Versley (2014), Hall and Nivre (2008) (H&amp;N) and Fernández-González and Mar- tins (2015) (F&amp;M).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 2 : Results NEGRA TED and Leaf-Ancestor</head><label>2</label><figDesc></figDesc><table>constituents, the latter beats the former by 0.8 
(F 1 ). On discontinuous constituents, using COM-
POUNDSWAP i gives an improvement of more than 
four points in precision and of about 0.8 points 
in recall. A manual analysis confirms that as 
expected, particularly discontinuous constituents 
with large gaps profit from bundling swap transi-
tions. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Results TIGER, beam size 4 

LR 
LP 
LF1 
E 
BASELINE 
81.89 82.49 82.19 49.05 
EXTENDED 82.20 82.70 82.45 49.54 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><head>Table 4 : Results NEGRACF</head><label>4</label><figDesc></figDesc><table>TENDED, and IMPORTANCE. The parsing speed 
on the test set drops to around 39 sentences per 
second. However, we achieve 75.10 F 1 , i.e., a 
slight improvement over the experiments in Tab. 3 
that confirms the tendencies visible in </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 5 : Results NEGRA rparse</head><label>5</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 6 : Results TIGERHN, sentence length ≤ 40</head><label>6</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="1"> As in other shift-reduce approaches, we assume that POS tagging is done outside of the parser.</note>

			<note place="foot" n="2"> See Maier and Lichte (2011) for a formal account on gaps in treebanks. 3 This split, which corresponds to the split used in the SPMRL 2013 shared task (Seddah et al., 2013), was proposed in Farkas and Schmid (2012). We exclude sentences 46,234 and 50,224, because of annotation errors. Both contain nodes with more than one parent node.</note>

			<note place="foot" n="5"> http://github.com/wmaier/rparse</note>

			<note place="foot" n="6"> Note that Versley (2014) reports a parsing speed of 4055 sent./sec.; depending on the beam size and the training set size, per second, our parser parses 39-640 sentences.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>I wish to thank Miriam Kaeshammer for enlight-ening discussions and the three anonymous re-viewers for helpful comments and suggestions. This work was partially funded by Deutsche Forschungsgemeinschaft (DFG).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Fast statistical parsing with parallel multiple context-free grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krasimir</forename><surname>Angelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Ljunglöf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 14th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Gothenburg, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="368" to="376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Stanford shift-reduce parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<ptr target="http://nlp.stanford.edu/software/srparser.shtml" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Discontinuity revisited: An improved conversion to context-free representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriane</forename><surname>Boyd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The Linguistic Annotation Workshop (LAW) at ACL 2007</title>
		<meeting>The Linguistic Annotation Workshop (LAW) at ACL 2007<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="41" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Language-independent parsing with empty elements</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Portland, OR</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="212" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Tree-bank grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
		<idno>CS-96-02</idno>
		<imprint>
			<date type="published" when="1996" />
			<pubPlace>Providence, RI</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, Brown University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Incremental parsing with the perceptron algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Roark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL&apos;04), Main Volume</title>
		<meeting>the 42nd Meeting of the Association for Computational Linguistics (ACL&apos;04), Main Volume<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="111" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Practical Structured Learning Techniques for Natural Language Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
		<respStmt>
			<orgName>University of Southern California, Los Angeles, CA</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Antecedent recovery: Experiments with a trace tagger</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Péter</forename><surname>Dienes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Dubey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2003 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Sapporo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="33" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Tree distance and some other variants of Evalb</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Emms</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth International Language Resources and Evaluation (LREC&apos;08)</title>
		<meeting>the Sixth International Language Resources and Evaluation (LREC&apos;08)<address><addrLine>Marrakech, Morocco</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1373" to="1379" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">PLCFRS parsing of English discontinuous constituents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian</forename><surname>Evang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Kallmeyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th International Conference on Parsing Technologies (IWPT 2011)</title>
		<meeting>the 12th International Conference on Parsing Technologies (IWPT 2011)<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="104" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Forest reranking through subtree ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Farkas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helmut</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1038" to="1047" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Parsing as reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Fernández</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-González</forename><surname>André</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">T</forename><surname>Martins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and Teh 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and Teh 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>To appear</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">An efficient algorithm for easy-first non-directional dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">Elhadad</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting><address><addrLine>Los Angeles, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="742" to="750" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Learning sparser perceptron models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Elhadad</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
		<respStmt>
			<orgName>Ben Gurion University of the Negev</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Parsing discontinuous phrase structure with grammatical functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Natural Language Processing</title>
		<editor>Bengt Nordström and Aarne Ranta</editor>
		<meeting><address><addrLine>Gothenburg, Sweden</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="volume">5221</biblScope>
			<biblScope unit="page" from="169" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Finding non-local dependencies: Beyond pattern matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Valentin Jijkoun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Companion Volume to the Proceedings of 41st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting><address><addrLine>Sapporo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="37" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A simple pattern-matching algorithm for recovering empty nodes and their antecedents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 40th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Philadelphia, PA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="136" to="143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Datadriven parsing using probabilistic linear contextfree rewriting systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Kallmeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Maier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="87" to="119" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep dependencies from context-free statistical parsers: Correcting the surface dependency approximation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL&apos;04), Main Volume</title>
		<meeting>the 42nd Meeting of the Association for Computational Linguistics (ACL&apos;04), Main Volume<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="327" to="334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Probabilistic Models of Word Order and Syntactic Discontinuity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Levy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
		<respStmt>
			<orgName>Stanford University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Characterizing discontinuity in constituent treebanks. In Formal Grammar</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Maier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timm</forename><surname>Lichte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">14th International Conference</title>
		<meeting><address><addrLine>Bordeaux, France</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2009-07-25" />
			<biblScope unit="volume">5591</biblScope>
			<biblScope unit="page" from="167" to="182" />
		</imprint>
	</monogr>
	<note>Revised Selected Papers</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Treebanks and mild context-sensitivity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Maier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Conference on Formal Grammar (FG-2008)</title>
		<editor>Philippe de Groote</editor>
		<meeting>the 13th Conference on Formal Grammar (FG-2008)<address><addrLine>Hamburg, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>CSLI Publications</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="61" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Data-driven PLCFRS parsing revisited: Restricting the fan-out to two</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Maier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miriam</forename><surname>Kaeshammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Kallmeyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference on Tree Adjoining Grammars and Related Formalisms (TAG+11)</title>
		<meeting>the Eleventh International Conference on Tree Adjoining Grammars and Related Formalisms (TAG+11)<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="126" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Parsing Discontinuous Structures. Dissertation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Maier</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
		<respStmt>
			<orgName>University of Tübingen</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">An improved oracle for dependency parsing with online reordering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Kuhlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Hall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Conference on Parsing Technologies (IWPT&apos;09)</title>
		<meeting>the 11th International Conference on Parsing Technologies (IWPT&apos;09)<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="73" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Non-projective dependency parsing in expected linear time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="351" to="359" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Evaluating evaluation measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ines</forename><surname>Rehbein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Van Genabith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Nordic Conference of Computational Linguistics NODALIDA-2007</title>
		<meeting>the 16th Nordic Conference of Computational Linguistics NODALIDA-2007<address><addrLine>Tartu, Estonia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="372" to="379" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A classifier-based parser with linear run-time complexity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Sagae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International Workshop on Parsing Technology</title>
		<meeting>the Ninth International Workshop on Parsing Technology<address><addrLine>Vancouver, BC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="125" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A test of the leaf-ancestor metric for parse accuracy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Sampson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Babarczy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="365" to="380" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Trace prediction and recovery with unlexicalized PCFGs and slash features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helmut</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="177" to="184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Overview of the SPMRL 2013 shared task: A cross-framework evaluation of parsing morphologically rich languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Djamé</forename><surname>Seddah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reut</forename><surname>Tsarfaty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandra</forename><surname>Kübler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie</forename><surname>Candito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinho</forename><forename type="middle">D</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richárd</forename><surname>Farkas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iakes</forename><surname>Goenaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koldo</forename><forename type="middle">Gojenola</forename><surname>Galletebeitia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spence</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nizar</forename><surname>Habash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Kuhlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Maier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuval</forename><surname>Marton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Przepiórkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Seeker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannick</forename><surname>Versley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veronika</forename><surname>Vincze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Woli´nskiwoli´nski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alina</forename><surname>Wróblewska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages</title>
		<meeting>the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages<address><addrLine>Seattle, WA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="146" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">On Multiple ContextFree Grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroyuki</forename><surname>Seki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takashi</forename><surname>Matsumura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mamoru</forename><surname>Fujii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tadao</forename><surname>Kasami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="191" to="229" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Discontinuous parsing with an efficient and accurate DOP model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Van Cranenburgh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rens</forename><surname>Bod</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 13th International Conference on Parsing Technologies</title>
		<meeting>The 13th International Conference on Parsing Technologies<address><addrLine>Nara, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Efficient parsing with linear context-free rewriting systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Van Cranenburgh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 13th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Avignon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="460" to="470" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Experiments with easy-first nonprojective constituent parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannick</forename><surname>Versley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Joint Workshop on Statistical Parsing of Morphologically Rich Languages and Syntactic Analysis of Non-Canonical Languages</title>
		<meeting>the First Joint Workshop on Statistical Parsing of Morphologically Rich Languages and Syntactic Analysis of Non-Canonical Languages<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="39" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Characterising structural descriptions used by various formalisms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Vijay-Shanker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Weir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><forename type="middle">K</forename><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 25th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Stanford, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1987" />
			<biblScope unit="page" from="104" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Transitionbased parsing of the Chinese treebank using a global discriminative model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Conference on Parsing Technologies (IWPT&apos;09)</title>
		<meeting>the 11th International Conference on Parsing Technologies (IWPT&apos;09)<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="162" to="171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Shift-reduce CCG parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Portland, OR</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="683" to="692" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Syntactic processing using the generalized perceptron and beam search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="105" to="151" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Exploiting lexical dependencies from large-scale data for better shift-reduce constituency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhua</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingbo</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huizhen</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2012</title>
		<meeting>COLING 2012<address><addrLine>Mumbai, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="3171" to="3186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Fast and accurate shiftreduce constituent parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhua</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenliang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingbo</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="434" to="443" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
