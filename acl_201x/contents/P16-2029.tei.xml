<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:24+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Unsupervised morph segmentation and statistical language models for vocabulary expansion</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matti</forename><surname>Varjokallio</surname></persName>
							<email>matti.varjokallio@aalto.fi</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Signal Processing and Acoustics</orgName>
								<orgName type="laboratory">Spoken Language Systems Saarland University Saarbrücken</orgName>
								<orgName type="institution">Aalto University Espoo</orgName>
								<address>
									<country>Finland, Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dietrich</forename><surname>Klakow</surname></persName>
							<email>dietrich.klakow@lsv.uni-saarland.de</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Signal Processing and Acoustics</orgName>
								<orgName type="laboratory">Spoken Language Systems Saarland University Saarbrücken</orgName>
								<orgName type="institution">Aalto University Espoo</orgName>
								<address>
									<country>Finland, Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Unsupervised morph segmentation and statistical language models for vocabulary expansion</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="175" to="180"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This work explores the use of unsu-pervised morph segmentation along with statistical language models for the task of vocabulary expansion. Unsupervised vocabulary expansion has large potential for improving vocabulary coverage and performance in different natural language processing tasks, especially in less-resourced settings on morphologically rich languages. We propose a combination of unsupervised morph segmentation and statistical language models and evaluate on languages from the Babel corpus. The method is shown to perform well for all the evaluated languages when compared to the previous work on the task.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Language modelling for different natural language processing tasks like speech recognition, machine translation or optical character recognition require large training corpora to achieve good language model estimates and high enough vocabulary cov- erage. Sometimes such resources are not readily available or easily acquirable. This is especially the case for the many less-resourced languages. In the case of morphologically rich languages, these issues are emphasized, as words appear in many forms, thus increasing the required vocabu- lary size and the data sparsity. Automatic speech recognition of spontaneous speech is a task with some special characteristics, as speech transcrip- tions are expensive to acquire. Taking all these factors into account, the importance of making the most out of the available resources becomes evi- dent.</p><p>This work was done while the author was visiting the Saarland University Spoken Language Systems group Previous work on handling out-of-vocabulary (OOV) words in automatic speech recognition have included explicit OOV word modelling and confidence measures <ref type="bibr" target="#b6">(Hazen and Bazzi, 2001</ref>) and hybrid word-subword language modelling for OOV word detection ( <ref type="bibr" target="#b18">Yazgan and Saraçlar, 2004)</ref>. Speech recognition by directly using optimized subword units has also <ref type="bibr" target="#b8">(Kneissler and Klakow, 2001</ref>) proven a good approach for speech recog- nition of a morphologically rich language.</p><p>In this work, we study unsupervised vocabu- lary expansion for conversational speech recogni- tion of morphologically rich languages in a less- resourced setting. We expand the recognition vo- cabulary, and thus lower the OOV rate, by generat- ing new word forms. Two recent works also target the unsupervised vocabulary expansion.</p><p>In ( <ref type="bibr" target="#b12">Rasooli et al., 2014</ref>), an unsupervised mor- phological segmentation was inferred from the training corpus using the Morfessor Categories- MAP ( <ref type="bibr" target="#b1">Creutz and Lagus, 2007)</ref> method. The prefix-stem-suffix structure estimated by the model was then represented as a finite-state- transducer for sampling new word forms. Differ- ent reranking schemes using a bigram language model and a letter trigraph language model were evaluated.</p><p>The Kaldi speech recognition package <ref type="bibr" target="#b11">(Povey et al., 2011</ref>) includes an approach ( <ref type="bibr" target="#b15">Trmal et al., 2014</ref>) for vocabulary expansion. In this approach, the provided syllable segmented pronunciation lexicon is used as the basis for the expansion. An n-gram model is trained over the syllable segmen- tation and syllabic words are generated from the model. Finally a phoneme-to-grapheme mapping is performed to obtain the grapheme form for the words.</p><p>In our approach, statistical language models are trained over a morph segmentation, which is learned unsupervisedly from the data. Words are sampled from the language models and ordered according to the probabilities given by the lan- guage models. We evaluate the method on seven morphologically rich languages from the Babel <ref type="bibr" target="#b5">(Harper, 2013)</ref> corpus and compare to the previ- ously suggested approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Suggested method</head><p>We present a combination of unsupervised morph segmentation and statistical language models for unsupervised vocabulary expansion. The sug- gested approach operates in four steps: unsu- pervised morph segmentation, statistical language model training, sampling of new word types and reranking of the sampled words. The phases are described in more detail in the corresponding sub- sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Unsupervised morph segmentation</head><p>Morfessor Baseline ( <ref type="bibr" target="#b0">Creutz and Lagus, 2002</ref>) is a method for unsupervised morphological segmen- tation. The algorithm optimizes a two-part min- imum description length code, finding a balance between the cost of encoding the training corpus and the lexicon, as in Formula 1.</p><formula xml:id="formula_0">arg min θ L(x, θ) = arg min L(x|θ) + L(θ) (1)</formula><p>The corpus encoding is based on a unigram model. A so-called α-term may be used for fine- tuning the corpus encoding cost. For the experi- ments in this work, a recent Python implementa- tion Morfessor 2.0 ( <ref type="bibr" target="#b14">Smit et al., 2014</ref>) was used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Statistical language models over morphs</head><p>As statistical language models, two state-of-the- art models were selected. These language models were trained on a corpus, where one segmented word was treated as what would in normal lan- guage model training be a sentence. The train- ing was done using log-weighted word frequen- cies, thus some words appearing multiple times in the training corpus. The rationale of the log- weighting was to slightly emphasize the most common words. As a last step, the order of the training words was randomized.</p><p>The first model was a trigram model trained with the modified Kneser-Ney smoothing <ref type="bibr" target="#b9">(Kneser and Ney, 1995</ref>) using three discounts per order. The discount parameters could normally be op- timized on a held-out-set, but here leave-one-out estimates were used, as it is not clear what would in this case constitute a reasonable held-out set. The model was trained using the VariKN software package ( .</p><p>It has recently been shown, that the recurrent neural network language models may efficiently be trained using the backpropagation algorithm ( <ref type="bibr" target="#b10">Mikolov et al., 2010)</ref>, making it also an appealing choice for language modelling. As the second lan- guage model, a recurrent neural network language model was trained using the RNNLM toolkit. The words were treated as independent of the preceed- ing words in both the model training and the word sampling phases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Sampling and reranking</head><p>The initial set of candidate words was obtained by sampling separately from both the n-gram model and the recurrent neural network language model. These word lists were then merged. It is very im- portant to rerank the obtained word list, as the goal is to improve the OOV rate as much as possible with introducing as little incorrect words as possi- ble to the vocabulary. As the final estimate on the word likelihood, the linear interpolation of these two model scores was used. The linear interpola- tion was applied morph-wise. The list of the sam- pled words was sorted in descending order with the linearly interpolated likelihood as the score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Training corpus</head><p>The vocabulary expansion experiments were con- ducted on the Babel corpus <ref type="bibr">(DARPA, 2013)</ref>. The experiments were run on the following set of languages: Assamese, Bengali, Pashto, Tagalog, Tamil, Turkish and Zulu. The training corpora consist mainly of conversation transcriptions, but also additional scripted data is provided. Including the scripted training data in general helps to lower the OOV rate. The OOV reduction rate reachable by the vocabulary expansion then becomes, with some exceptions, slightly slower. Statistics of the datasets are in the <ref type="table">Table 1</ref>.</p><p>As preprocessing, all special symbols were re- moved from the texts. Asterisk symbols are used to denote misspellings in cases where the real word was identifiable. Asterisk symbols were re- moved and the words included in the training cor- pus. Dash symbols in the beginning and end of Only proper names were written in uppercase in the transcriptions, so these words were kept intact.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Expansion model</head><p>As statistical language models, we evaluated a tri- gram language model, a recurrent neural network language model, and the linear interpolation of these models. 10 million new distinct word types were sampled from both the models separately. These lists were then merged and reranked as ex- plained in the Section 2.3. The model parameters were optimized on se- lected languages and these parameters were used in all the experiments. For the recurrent neural net- work language model, the number of classes was set to 50 and the hidden layer size to 20. These values were reasonably close to optimum for all the languages.</p><p>The suitable α-value for the Morfessor Baseline segmentation was studied. With the default value of 1.0, the method seemed to suffer from a slight undersegmentation. To encourage the method to segment more, the α value was set to 0.8. This setting was equal or better for all the evaluated lan- guages.</p><p>When evaluating the language models as stan- dalone models, the trigram model provided bet- ter generation accuracy for 4 of the in total 7 lan- guages and the recurrent neural network language model for 3 of the languages. Linear interpolation of the models was without exceptions the most ac- curate model. The linear interpolation weight was set to 0.5. <ref type="figure" target="#fig_0">Figure 1</ref> shows an example of the OOV rate de- velopment as a function of the extended vocabu- lary size for Turkish. The rapid improvement of the OOV rate for small extensions and the superi- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Comparison to the previous work</head><p>We compared the approach to the previous results in ( <ref type="bibr" target="#b12">Rasooli et al., 2014</ref>). They reported the results for a vocabulary expansion of 50k best words. Ta- ble 2 compares the type-based expansion results and     We ran the Kaldi vocabulary expansion in the limited language pack setting as in ( <ref type="bibr" target="#b15">Trmal et al., 2014</ref>). In the default setting, around 1M dis- tinct syllabic words are generated and converted by a phoneme-to-grapheme mapping to obtain the graphemic word form. <ref type="table" target="#tab_4">Table 4</ref> compares the type- based expansion results and <ref type="table" target="#tab_5">Table 5</ref> the token- based expansion results for a vocabulary expan- sion of similar size (in graphemic words). The scripted data was not used in training the models for these comparisons.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">OOV reduction and type to token ratio</head><p>The OOV reduction was evaluated as a function of the type/token ratio. This analysis may provide information about the properties of the evaluated languages. The token-based analysis is in the <ref type="figure">Fig- ure 2</ref> and the type-based analysis in the <ref type="figure">Figure 3</ref>. As the type/token ratio is dependent on the number of tokens, these values are computed on a matched number of tokens (65821) from the training cor- pus. The plots show that there are similarities, but also big differences between the languages. Most notable exceptions seem to be Tamil and Tagalog. For Tamil, the number of the most frequent words was lower with a slightly more even tail of less frequent words. For Tagalog, the average number of morphs per word as estimated by the Morfessor Baseline algorithm was 2.8, which was the highest value among all the languages. Still, the number of distinct word types in the training set was the lowest. These properties seem to play a role in the different vocabulary expansion characteristics. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion</head><p>This work concerned the use of unsupervised mor- phological segmentation and statistical language models for the task of vocabulary expansion. Un- supervised vocabulary expansion has large poten- tial for reducing OOV-rates and improving results in NLP tasks especially in less-resourced settings for morphologically rich languages.</p><p>The suggested method was evaluated on some of the morphologically rich languages of the Ba- bel corpus in the limited language pack condition. The performance of the method was evaluated in terms of the improvement of the OOV-rate on the development set. The suggested combination of segmentation and interpolation of statistical lan- guage models provided to our understanding the best results on the task so far. Compared to <ref type="bibr" target="#b12">(Rasooli et al., 2014)</ref>, our approach differed in that the statistical language models were used directly in the word generation phase. As opposed to <ref type="bibr" target="#b15">(Trmal et al., 2014</ref>), our approach operated purely on the grapheme level.</p><p>It is perhaps noteworthy, that the methods are not that different from what one would use in a normal language modelling scenario for automatic speech recognition. Morfessor Baseline ( <ref type="bibr" target="#b0">Creutz and Lagus, 2002</ref>) has been seen to give good re- sults in morph-based speech recognition ( ) when used along with standard n-gram models. If a larger training corpus is available, op- timizing unigram likelihood more directly may be a good choice ( <ref type="bibr" target="#b17">Varjokallio et al., 2013</ref>).</p><p>Morph segmentations provided by the Morfes- sor Flatcat ) -method were also evaluated for this work, but Morfessor Baseline was found to perform better. It is pos- sible, that the tradeoff between the lexicon cost and the corpus encoding cost, as given by the Minimum Description Length -principle, is impor- tant for the modelling accuracy in this type of a less-resourced scenario. Morfessor Flatcat will in most cases segment more accurately according to the grammatical morph boundaries. This is likely a more valuable property for statistical machine translation than for the present task.</p><p>The linear interpolation of an n-gram model and a recurrent neural network language model provides at the moment state-of-the-art modelling accuracy in many statistical language modelling tasks. Some forms of class n-grams were also evaluated for this work. Sampling from a class n- gram provided many complementary word forms, not easily generated by the other models. How- ever, it became successively harder to improve the OOV reduction rates by a combination of three models.</p><p>This work concentrated only on methods for expanding the vocabulary. Naturally some lan- guage modelling methods are required to utilize these generated words in speech recognition or some other task. One possibility is to extend the unknown symbol and improve the obtained estimates via class n-gram models ( <ref type="bibr" target="#b15">Trmal et al., 2014</ref>). Morph-based language models may be uti- lized using a constrained vocabulary as suggested in <ref type="bibr" target="#b16">(Varjokallio and Kurimo, 2014)</ref>. In this case word-level pronunciation variants may be applied. Performing the vocabulary expansion may also provide insights into unlimited vocabulary speech recognition <ref type="bibr" target="#b8">(Kneissler and Klakow, 2001;</ref><ref type="bibr" target="#b7">Hirsimäki et al., 2006</ref>) with morph language mod- els. Finding units with consistent grapheme-to- phoneme mapping may, however, be challenging for some of the Babel languages.</p><p>Regarding the type of approaches considered in this work, it is possible that advances in either un- supervised morph segmentation or statistical lan- guage models could bring about further improve- ments in the expansion accuracy. Unsupervised learning of morphological paradigms is also a po- tential direction when seeking for improvements in the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>Unsupervised vocabulary expansion has great po- tential for reducing out-of-vocabulary rates and improving results in different natural language processing tasks, including ASR. In this work, an approach comprising of unsupervised morph segmentation and statistical language models was suggested. The model was evaluated on the Babel languages and was shown to give large improve- ments compared to the previous work on the task.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Token-based OOV rate as a function of the extended vocabulary size for Turkish</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>Figure 2: Token-based OOV reduction rate for 50k word expansion as a function of type/token ratio</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 3 the</head><label>3</label><figDesc>token-based expansion results. Models for these comparisons were trained with the scripted data included.</figDesc><table>Language Rasooli et al. Suggested method 
Assamese 
28.46 
31.93 
Bengali 
24.75 
33.20 
Pashto 
19.43 
32.95 
Tagalog 
16.81 
21.27 
Tamil 
-
16.27 
Turkish 
14.79 
28.32 
Zulu 
13.87 
21.18 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Type-based OOV reduction rates for the 
50k best words </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Token-based OOV reduction rates for the 
50k best words 

Language Vocabulary size Kaldi Suggested 
Assamese 
845k 
26.4 
21.2 
Bengali 
834k 
27.4 
22.0 
Pashto 
494k 
26.7 
20.3 
Tagalog 
581k 
37.5 
33.2 
Tamil 
896k 
45.2 
38.0 
Turkish 
704k 
37.1 
28.4 
Zulu 
818k 
40.7 
37.0 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><head>Table 4 : Type-based OOV rate comparison to Kaldi</head><label>4</label><figDesc></figDesc><table>Language Vocabulary size Kaldi Suggested 
Assamese 
845k 
4.3 
3.5 
Bengali 
834k 
4.6 
3.6 
Pashto 
494k 
2.4 
1.9 
Tagalog 
581k 
5.3 
4.6 
Tamil 
896k 
11.2 
9.1 
Turkish 
704k 
7.9 
6.0 
Zulu 
818k 
12.5 
11.4 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 5 : Token-based OOV rate comparison to Kaldi</head><label>5</label><figDesc></figDesc><table></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research was conducted while the first au-thor was visiting the Saarland University Spoken Language Systems group. The work was partially funded by the Saarland University SFB1102 Col-laborative Research Center for Information Den-sity and Linguistic Encoding.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Unsupervised Discovery of Morphemes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathias</forename><surname>Creutz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krista</forename><surname>Lagus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL-02 Workshop on Morphological and Phonological Learning</title>
		<meeting>the ACL-02 Workshop on Morphological and Phonological Learning</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="21" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Unsupervised Models for Morpheme Segmentation and Morphology Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathias</forename><surname>Creutz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krista</forename><surname>Lagus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Speech and Language Processing</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2007-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Morph-based Speech Recognition and Modeling of Out-of-vocabulary Words Across Languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathias</forename><surname>Creutz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teemu</forename><surname>Hirsimäki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikko</forename><surname>Kurimo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antti</forename><surname>Puurula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janne</forename><surname>Pylkkönen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vesa</forename><surname>Siivola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matti</forename><surname>Varjokallio</surname></persName>
		</author>
		<idno>3:1-3:29</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Speech and Language Processing</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
<note type="report_type">December</note>
	<note>Ebru Arisoy, Murat Saraçlar, and Andreas Stolcke</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">IARPA Babel Data Specifications for Performers</title>
	</analytic>
	<monogr>
		<title level="j">DARPA</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Morfessor FlatCat: An HMM-Based Method for Unsupervised and Semi-Supervised Learning of Morphology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stig-</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arne</forename><surname>Grönroos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sami</forename><surname>Virpioja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on Computational Linguistics</title>
		<meeting>the 25th International Conference on Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-08" />
			<biblScope unit="page" from="1177" to="1185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">The Babel Program and Low Resource Speech Technology. Automatic Speech Recognition and Understanding Workshop (ASRU)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><surname>Harper</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Invited talk</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A Comparison and Combination of Methods for OOV Word Detection and Word Confidence Scoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">J</forename><surname>Hazen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Issam</forename><surname>Bazzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2001 IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<meeting>the 2001 IEEE International Conference on Acoustics, Speech and Signal Processing</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="397" to="400" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Unlimited Vocabulary Speech Recognition with Morph Language Models Applied to Finnish</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teemu</forename><surname>Hirsimäki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathias</forename><surname>Creutz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vesa</forename><surname>Siivola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikko</forename><surname>Kurimo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sami</forename><surname>Virpioja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janne</forename><surname>Pylkkönen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech and Language</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="515" to="541" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Speech Recognition for Huge Vocabularies by Using Optimized Sub-word Units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Kneissler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dietrich</forename><surname>Klakow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Annual Conference of the International Speech Communication Association (INTERSPEECH 2001)</title>
		<meeting>the 2nd Annual Conference of the International Speech Communication Association (INTERSPEECH 2001)</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="69" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Improved Backing-off for M-gram Language Modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reinhard</forename><surname>Kneser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1995 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<meeting>the 1995 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</meeting>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="181" to="184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Recurrent Neural Network Based Language Model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomáš</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Karafiát</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukáš</forename><surname>Burget</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaňjaň</forename><surname>Cernock´ycernock´y</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Khudanpur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th Annual Conference of the International Speech Communication Association (INTERSPEECH 2010)</title>
		<meeting>the 11th Annual Conference of the International Speech Communication Association (INTERSPEECH 2010)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1045" to="1048" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The Kaldi Speech Recognition Toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Povey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnab</forename><surname>Ghoshal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gilles</forename><surname>Boulianne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Burget</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Glembek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nagendra</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirko</forename><surname>Hannemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petr</forename><surname>Motlicek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanmin</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petr</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Silovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Stemmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karel</forename><surname>Vesely</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE 2011 Workshop on Automatic Speech Recognition and Understanding</title>
		<meeting>the IEEE 2011 Workshop on Automatic Speech Recognition and Understanding</meeting>
		<imprint>
			<date type="published" when="2011-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Unsupervised Morphology-Based Vocabulary Expansion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Sadegh Rasooli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Lippincott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nizar</forename><surname>Habash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Owen</forename><surname>Rambow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1349" to="1359" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">On Growing and Pruning KneserNey Smoothed N-gram Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vesa</forename><surname>Siivola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teemu</forename><surname>Hirsimäki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sami</forename><surname>Virpioja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Audio, Speech and Language Processing</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1617" to="1624" />
			<date type="published" when="2007-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Morfessor 2.0: Toolkit for Statistical Morphological Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Smit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sami</forename><surname>Virpioja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stig-Arne</forename><surname>Grönroos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikko</forename><surname>Kurimo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics (EACL)</title>
		<meeting>the 14th Conference of the European Chapter of the Association for Computational Linguistics (EACL)<address><addrLine>Gothenburg, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-04" />
			<biblScope unit="page" from="21" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A Keyword Search System Using Open Source Software</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Trmal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoguo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Povey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Khudanpur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pegah</forename><surname>Ghahremani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vimal</forename><surname>Manohar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunxi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aren</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dietrich</forename><surname>Klakow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Metze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE 2014 Workshop on Spoken Language Technology</title>
		<meeting>the IEEE 2014 Workshop on Spoken Language Technology<address><addrLine>South Lake Tahoe, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A WordLevel Token-Passing Decoder for Subword n-gram LVCSR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matti</forename><surname>Varjokallio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikko</forename><surname>Kurimo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE 2014 Workshop on Spoken Language Technology</title>
		<meeting>the IEEE 2014 Workshop on Spoken Language Technology<address><addrLine>South Lake Tahoe, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning a Subword Vocabulary Based on Unigram Likelihood</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matti</forename><surname>Varjokallio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikko</forename><surname>Kurimo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sami</forename><surname>Virpioja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE 2013 Workshop on Automatic Speech Recognition and Understanding</title>
		<meeting>the IEEE 2013 Workshop on Automatic Speech Recognition and Understanding<address><addrLine>Olomouc, Czech Republic, December</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Hybrid Language Models for Out of Vocabulary Word Detection in Large Vocabulary Conversational Speech Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Yazgan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Murat</forename><surname>Saraçlar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<meeting>the 2004 IEEE International Conference on Acoustics, Speech and Signal Processing</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="745" to="753" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
