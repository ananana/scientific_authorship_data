<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:03+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Encoding Relation Requirements for Relation Extraction via Joint Inference</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>June 23-25 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liwei</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">ICST</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yansong</forename><surname>Feng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">ICST</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songfang</forename><surname>Huang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">IBM China Research Lab</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Qin</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">IBM China Research Lab</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">ICST</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Encoding Relation Requirements for Relation Extraction via Joint Inference</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="818" to="827"/>
							<date type="published">June 23-25 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Most existing relation extraction models make predictions for each entity pair locally and individually, while ignoring implicit global clues available in the knowledge base, sometimes leading to conflicts among local predictions from different entity pairs. In this paper, we propose a joint inference framework that utilizes these global clues to resolve disagreements among local predictions. We exploit two kinds of clues to generate constraints which can capture the implicit type and cardinality requirements of a relation. Experimental results on three datasets, in both English and Chinese, show that our framework outperforms the state-of-the-art relation extraction models when such clues are applicable to the datasets. And, we find that the clues learnt automatically from existing knowledge bases perform comparably to those refined by human.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Identifying predefined kinds of relationship be- tween pairs of entities is crucial for many knowl- edge base related applications <ref type="bibr" target="#b12">(Suchanek et al., 2013</ref>). In the literature, relation extraction (RE) is usually investigated in a classification style, where relations are simply treated as isolated class labels, while their definitions or background information are sometimes ignored. Take the relation Capital as an example, we can imagine that this relation will expect a country as its subject and a city as object, and in most cases, a city can be the capital of only one country. All these clues are no doubt helpful, for instance,  explicitly modeled the expected types of a relation's argu- ments with the help of Freebase's type taxonomy and obtained promising results for RE. * Yansong Feng is the corresponding author.</p><p>However, properly capturing and utilizing such typing clues are not trivial. One of the hurdles here is the lack of off-the-shelf resources and such clues often have to be coded by human experts. Many knowledge bases do not have a well-defined typing system, let alone fine-grained typing taxonomies with corresponding type recognizers, which are crucial to explicitly model the typing requirements for arguments of a relation, but rather expensive and time-consuming to collect. Similarly, the car- dinality requirements of arguments, e.g., a person can have only one birthdate and a city can only be labeled as capital of one country, should be con- sidered as a strong indicator to eliminate wrong predictions, but has to be coded manually as well.</p><p>On the other hand, most previous relation ex- tractors process each entity pair (we will use en- tity pair and entity tuple exchangeably in the rest of the paper) locally and individually, i.e., the ex- tractor makes decisions solely based on the sen- tences containing the current entity pair and ig- nores other related pairs, therefore has difficulties to capture possible disagreements among different entity pairs. However, when looking at the output of a multi-class relation predictor globally, we can easily find possible incorrect predictions such as a university locates in two different cities, two dif- ferent cities have been labeled as capital for one country, a country locates in a city and so on.</p><p>In this paper, we will address how to derive and exploit two categories of these clues: the expected types and the cardinality requirements of a rela- tion's arguments, in the scenario of relation extrac- tion. We propose to perform joint inference upon multiple local predictions by leveraging implicit clues that are encoded with relation specific re- quirements and can be learnt from existing knowl- edge bases. Specifically, the joint inference frame- work operates on the output of a sentence level re- lation extractor as input, derives 5 types of con- straints from an existing KB to implicitly capture the expected type and cardinality requirements for a relation's arguments, and jointly resolve the dis- agreements among candidate predictions. We for- malize this procedure as a constrained optimiza- tion problem, which can be solved by many opti- mization frameworks. We use integer linear pro- gramming (ILP) as the solver and evaluate our framework on English and Chinese datasets. The experimental results show that our framework per- forms better than the state-of-the-art approaches when such clues are applicable to the datasets. We also show that the automatically learnt clues per- form comparably to those refined manually.</p><p>In the rest of the paper, we first review related work in Section 2, and in Section 3, we describe our framework in detail. Experimental setup and results are discussed in Section 4. We conclude this paper in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Since traditional supervised relation extraction methods <ref type="bibr" target="#b11">(Soderland et al., 1995;</ref><ref type="bibr" target="#b19">Zhao and Grishman, 2005</ref>) require manual annotations and are often domain-specific, nowadays many efforts fo- cus on semi-supervised or unsupervised methods ( <ref type="bibr" target="#b0">Banko et al., 2007;</ref><ref type="bibr" target="#b4">Fader et al., 2011</ref>). Distant supervision (DS) is a semi-supervised RE frame- work and has attracted many attentions <ref type="bibr" target="#b2">(Bunescu, 2007;</ref><ref type="bibr" target="#b8">Mintz et al., 2009;</ref><ref type="bibr" target="#b13">Surdeanu et al., 2010;</ref><ref type="bibr" target="#b5">Hoffmann et al., 2011;</ref><ref type="bibr" target="#b14">Surdeanu et al., 2012)</ref>. DS approaches can predict canonicalized (predefined in KBs) relations for large amount of data and do not need much hu- man involvement. Since the automatically gener- ated training datasets in DS often contain noises, there are also research efforts focusing on reduc- ing the noisy labels in the training data ( <ref type="bibr" target="#b15">Takamatsu et al., 2012)</ref>. To bridge the gaps between the rela- tions extracted from open information extraction and the canonicalized relations in KBs, <ref type="bibr" target="#b17">Yao et al. (2012)</ref> and  propose a universal schema which is a union of KB schemas and nat- ural language patterns, making it possible to in- tegrate the unlimited set of uncanonicalized rela- tions in open settings with the relations in existing KBs.</p><p>As far as we know, few works have managed to take the relation specific requirements for ar- guments into account, and most existing works make predictions locally and individually. The MultiR system allows entity tuples to have more than one relations, but still predicts each entity tuple locally <ref type="bibr" target="#b5">(Hoffmann et al., 2011</ref>). <ref type="bibr" target="#b14">Surdeanu et al. (2012)</ref> propose a two-layer multi-instance multi-label (MIML) framework to capture the de- pendencies among relations. The first layer is a multi-class classifier making local predictions for single sentences, the output of which are aggre- gated by the second layer into the entity pair level. Their approach only captures relation dependen- cies, while we learn implicit relation backgrounds from knowledge bases, including argument type and cardinality requirements.  propose to use latent vectors to estimate the pref- erences between relations and entities. These can be considered as the latent type information of the relations' arguments, which is learnt from various data sources. In contrast, our approach learn im- plicit clues from existing KBs, and jointly opti- mize local predictions among different entity tu- ples to capture both relation argument type clues and cardinality clues. <ref type="bibr" target="#b6">Li et al. (2011)</ref> and <ref type="bibr" target="#b7">Li et al. (2013)</ref> use co-occurring statistics among relations or events to jointly improve information extrac- tion performances in ACE tasks, while we mine existing KBs to collect global clues to solve lo- cal conflicts and find the optimal aggregation as- signments, regarding existing knowledge facts. de <ref type="bibr" target="#b3">Lacalle and Lapata (2013)</ref> encode general domain knowledge as FOL rules in a topic model while our instantiated constraints are directly operated in an ILP model. <ref type="bibr" target="#b18">Zhang et al. (2013)</ref> utilize relation cardinality to create negative samples for distant supervision while we use both implicit type clues and relation cardinality expectations to discover possible inconsistencies among local predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The Framework</head><p>Our framework takes a set of entity pairs and their supporting sentences as its input. We first train a preliminary sentence level extractor which can output confidence scores for its predictions, e.g., a maximum entropy or logistic regression model, and use this local extractor to produce local predic- tions. In order to implicitly capture the expected type and cardinality requirements for a relation's arguments, we derive two kinds of clues from an existing KB, which are further utilized to discover the disagreements among local candidate predic- tions. Our objective is to maximize the overall confidence of all the selected predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Generating Candidate Relations</head><p>Since we will focus on the open domain relation extraction, we still follow the distant supervision paradigm to collect our training data guided by a KB, and train the local extractor accordingly. Specifically, we train a sentence level extractor us- ing the maximum entropy model. Given a sen- tence containing an entity pair, the model will output the confidence of this sentence represent- ing certain relationship (from a predefined relation set) between the entity pair. Formally R repre- sents the relation set we are working on, T is the set of entity tuples that we will predict in the test set.</p><p>Keep in mind that our local extractor is trained on noisy training data, which, we admit, is not fully reliable. As we observed in a pilot experi- ment that there is a good chance that the predic- tions ranked in the second or third may still be correct, we select top three predictions as the can- didate relations for each mention in order to intro- duce more potentially correct output.</p><p>On the other hand, we should discard the pre- dictions whose confidences are too low to be true, where we set up a threshold of 0.1. For a tuple t, we obtain its candidate relation set by combining the candidate relations of all its mentions, and rep- resent it as R t . For a candidate relation r ∈ R t and a tuple t, we define M r t as all t's mentions whose candidate relations contain r. Now the confidence score of a relation r ∈ R t being assigned to tuple t can be calculated as:</p><formula xml:id="formula_0">conf (t, r) = m∈M r t MEscore(m, r)<label>(1)</label></formula><p>where MEscore(m, r) is the confidence of mention m representing relation r output by our prelimi- nary extractor. Traditionally, both lexical features and syntac- tic features are used in relation extraction. Lexi- cal features are the word chains between the sub- jects and objects in the sentences, while syntactic features are the dependency paths from the sub- jects to the objects on the dependency graphs of the supporting sentences. However, lexical fea- tures are usually too specific to frequently appear in the test data, while the reliability of syntactic features depends heavily on the quality of depen- dency parsing tools. Generally, we expect more potentially correct relations to be put into the can- didate relation set for further consideration. So in conflict conflict conflict conflict Capital: 0.5 LargestCity: 0.4</p><p>LocationCity: 0.05 <ref type="figure">Figure 1</ref>: The different types of disagreements we will investigate in the candidate relations. The clues of detecting these inconsistencies can be learnt from a knowledge base.</p><p>addition to lexical and syntactic features, we also use n-gram features to train our preliminary rela- tion extraction model. N-gram features are consid- ered as more ambiguous compared to traditional lexical and syntactic features, and may introduce incorrect predictions, thus improving the recall at the cost of precision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Disagreements among the Candidates</head><p>The candidate relations we obtained in the pre- vious subsection inevitably include many incor- rect predictions. Ideally we should discard those wrong predictions to produce more accurate re- sults.</p><p>As discussed earlier, we will exploit from the knowledge base two categories of clues that im- plicitly capture relations' backgrounds: their ex- pected argument types and argument cardinalities, based on which we can discover two categories of disagreements among the candidate predictions, summarized as argument type inconsistencies and violations of arguments' uniqueness, which have been rarely considered before. We will discuss them in detail, and describe how to learn the clues from a KB afterwards.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implicit Argument Types Inconsistencies:</head><p>Generally, the argument types of the correct predictions should be consistent with each other. Given a relation, its arguments sometimes are required to be certain types of entities. For example, in <ref type="figure">Figure 1</ref>, the relation LargestCity restricts its subject to be either countries or states, and its object to be cities. If the predictions among different entity tuples require the same entity to belong to different types, we call this an argument type inconsistency. Take &lt;USA, New York&gt; and &lt;USA, Washington D.C.&gt; as an example. In <ref type="figure">Figure 1</ref>, &lt;USA, New York&gt; has a candidate relation LargestCity which restricts USA to be either countries or states, while &lt;USA, Washington D.C.&gt; has a prediction LocationCity which indicates a disagreement in terms of USA's type because the latter prediction expects USA to be an organization located in a city. This warns that at least one of the two candidate relations is incorrect.</p><p>The previous scenario shows that the subjects of two candidate relations may disagree with each other. From <ref type="figure">Figure 1</ref>, we can observe two more situations: the first one is that the objects of the two candidate relations are inconsistent with each other, for example &lt;New York University, New York&gt; with the prediction LocationCity and &lt;Columbia University, New York&gt; with the pre- diction LocationCountry. The second one is that the subject of one candidate relation do not agree with another prediction's object, for exam- ple &lt;Richard Fuld, USA&gt; with the prediction Na- tionality and &lt;USA, New York&gt; with the pre- diction LocationCity. Although we have not as- signed explicit types to these entities, we can still exploit the inconsistencies implicitly with the help of shared entities. Note that the implicit argument typing clues here mean whether two relations can share arguments, but NOT enumate what types ex- plicitly their arguments should have.</p><p>We formalize all the relation pairs that disagree with each other as follows. These relation pairs can be divided into three subcategories. We repre- sent the relation pairs (r i , r j ) that are inconsistent in terms of subjects as C sr , the relations pairs that are inconsistent in terms of objects as C ro , the re- lation pairs that are inconsistent in terms of one's subject and the other one's object as C rer .</p><p>It is worth mentioning that disagreements in- side a tuple are also included here. For instance, an entity tuple &lt;USA, Washington D.C.&gt; in <ref type="figure">Fig- ure 1</ref> has two candidate relations, Capital and Lo- cationCity. These two predictions are inconsistent with each other with respect to the type of USA. They implicitly consider USA as "country" and "organization", respectively.</p><p>Violations of Arguments' Uniqueness: The previous categories of disagreements are all based on the implicit type information of the relations' arguments, Now we make use of the clues of ar- gument cardinality requirements. Given a subject, some relations should have unique objects. For example, in <ref type="figure">Figure 1</ref>, given USA as the subject of the relation Capital, we can only accept one pos- sible object, because there is great chance that a country only have one capital. On the other hand, given Washington D.C. as the object of the relation Capital, we can only accept one subject, since usu- ally a city can only be the capital of one country or state. If these are violating in the candidates, we could know that there may be some incorrect predictions. We represent the relations expecting unique objects as C ou , and the relations expecting unique subjects as C su .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Obtaining the Global Clues</head><p>Now, the issue is how to obtain the clues used in the previous subsection. That is, how we de- termine which relations expect certain types of subjects, which relations expect certain types of objects, etc. These knowledge can be definitely coded by human, or learnt from a KB.</p><p>Most existing knowledge bases represent their knowledge facts in the form of (&lt;subject, rela- tion, object&gt;) triple, which can be seen as re- lational facts between entity tuples. Usually the triples in a KB are carefully defined by experts. It is rare to find inconsistencies among the triples in the knowledge base. The clues are therefore learnt from KBs, and further refined manually if needed.</p><p>Given two relations r 1 and r 2 , we query the KB for all tuples bearing the relation r 1 or r 2 . We use S i and O i to represent r i 's (i ∈ {1, 2}) subject set and object set, respectively. We adopt the point- wise mutual information (PMI) to estimate the de- pendency between the argument sets of two rela- tions:</p><formula xml:id="formula_1">PMI(A, B) = log p(A, B) p(A)p(B)<label>(2)</label></formula><p>where p(A, B) is number of the entities both in A and B, p(A) and p(B) are the numbers of the entities in A and B, respectively. For any pair of relations from R × R, we calculate four scores: PMI(S 1 , S 2 ), PMI(O 1 , O 2 ), PMI(S 1 , O 2 ) and PMI(S 2 , O 1 ). To make more stable esti- mations, we set up a threshold for the PMI. If PMI(S 1 , S 2 ) is lower than the threshold, we will consider that r 1 and r 2 cannot share a subject. Things are similar for the other three scores. The threshold is set to -3 in this paper.</p><p>We can also learn the uniqueness of arguments for relations. For each pre-defined relation in R, we collect all the triples containing this relation, and count the portion of the triples which only have one object for each subject, and the por- tion of the triples which only have one subject for each object. The relations whose portions are higher than the threshold will be considered to have unique argument values. This threshold is set to 0.8 in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Integer Linear Program Formulation</head><p>As discussed above, given a set of entity pairs and their candidate relations output by a preliminary extractor, our goal is to find an optimal configura- tion for all those entities pairs jointly, solving the disagreements among those candidate predictions and maximizing the overall confidence of the se- lected predictions. This is an NP-hard optimiza- tion problem. Many optimization models can be used to obtain the approximate solutions.</p><p>In this paper, we propose to solve the problem by using an ILP tool, IBM ILOG Cplex 1 . Firstly, for each tuple t and one of its candidate relations r, we define a binary decision variable d r t indicat- ing whether the candidate relation r is selected by the solver. Our objective is to maximize the total confidence of all the selected candidates, and the objective function can be written as: where conf (t, r) is the confidence of the tuple t bearing the candidate relation r. The first compo- nent is the sum of the original confidence scores of all the selected candidates, and the second one is the sum of the maximal mention-level confidence scores of all the selected candidates. The latter is designed to encourage the model to select the can- didates with higher individual mention-level con- fidence scores.</p><p>We add the constraints with respect to the dis- agreements described in Section 3.2. For the sake of clarity, we describe the constraints derived from each scenario of the two categories of disagree- ments separately.</p><p>The subject-relation constraints avoid the dis- agreements between the predictions of two tuples 1 www.cplex.com sharing a subject. These constraints can be repre- sented as:</p><formula xml:id="formula_2">d r t i t i + d r t j t j ≤ 1 (3) ∀t i , t j : subj(t i ) = subj(t j ) ∧ (r t i , r t j ) ∈ C sr</formula><p>where t i and t j are two tuples in T , subj(t i ) is the subject of t i , r t i is a candidate relation of t i , r t j is a candidate relation of t j .</p><p>The object-relation constraints avoid the incon- sistencies between the predictions of two tuples sharing an object. Formally we add the following constraints:</p><formula xml:id="formula_3">d r t i t i + d r t j t j ≤ 1 (4) ∀t i , t j : obj(t i ) = obj(t j ) ∧ (r t i , r t j ) ∈ C ro</formula><p>where t i ∈ T and t j ∈ T are two tuples, obj(t i ) is the object of t i .</p><p>The relation-entity-relation constraints ensure that if an entity works as subject and object in two tuples t i and t j respectively, their relations agree with each other. The constraints we add are:</p><formula xml:id="formula_4">d r t i t i + d r t j t j ≤ 1 (5) ∀t i , t j : obj(t i ) = subj(t j ) ∧ (r t i , r t j ) ∈ C rer</formula><p>The object uniqueness constraints ensure that the relations requiring unique objects do not bear more than one object given a subject.</p><p>t∈T uple(r),subj(t)=e</p><formula xml:id="formula_5">d r t ≤ 1 (6) ∀e ∧ r ∈ C ou</formula><p>where e is an entity, T uple(r) are the tuples whose candidate relations contain r. The subject uniqueness constraints ensure that given an object, the relations expecting unique subjects do not bear more than one subject.</p><p>t∈T uple(r),obj(t)=e</p><formula xml:id="formula_6">d r t ≤ 1<label>(7)</label></formula><p>∀e ∧ r ∈ C su By adopting ILP, we can combine the local information including MaxEnt confidence scores and the implicit relation backgrounds that are em- bedded into global consistencies of the entity tu- ples together. After the optimization problem is solved, we will obtain a list of selected candidate relations for each tuple, which will be our final output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>822</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>We evaluate our approach on three datasets, in- cluding two English datasets and one Chinese dataset.</p><p>The first English dataset, Riedel's dataset, is the one used in ( <ref type="bibr" target="#b5">Hoffmann et al., 2011;</ref><ref type="bibr" target="#b14">Surdeanu et al., 2012)</ref>, with the same split. It uses Freebase as the knowledge base and New York Time corpus as the text corpus, including about 60,000 entity tuples in the training set, and about 90,000 entity tuples in the testing set.</p><p>We generate the second English dataset, DB- pedia dataset, by mapping the triples in DBpedia ( <ref type="bibr" target="#b1">Bizer et al., 2009</ref>) to the sentences in New York Time corpus. We map 51 different relations to the corpus and result in about 50,000 entity tuples, 134,000 sentences for training and 30,000 entity tuples, 53,000 sentences for testing.</p><p>For the Chinese dataset, we derive knowledge facts and construct a Chinese KB from the In- foboxes of HudongBaike, one of the largest Chi- nese online encyclopedias. We collect four na- tional economic newspapers in 2009 as our corpus. 28 different relations are mapped to the corpus and this results in 60,000 entity tuples, 120,000 sen- tences for training and 40,000 tuples, 83,000 sen- tences for testing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Baselines and Competitors</head><p>The baseline we use in this paper is Mintz++, which is described in ( <ref type="bibr" target="#b14">Surdeanu et al., 2012)</ref>. It is a modification of the model proposed by <ref type="bibr" target="#b8">Mintz et al. (2009)</ref>. The model predicts for each mention separately, and allows multi-label outputs for an entity tuple by OR-ing the outputs of its mentions.</p><p>As we described in Section 3.1, originally we select the top three predicted relations as the can- didates for each mention. In order to investigate whether it is necessary to use up to three candi- dates, we implement two variants of our approach, which select the top one and top two relations as candidates for each mention, and represented as ILP-1cand and ILP-2cand, respectively.</p><p>We also use two distant supervision approaches for the comparison. The first one is MultiR <ref type="bibr" target="#b5">(Hoffmann et al., 2011)</ref>, a novel joint model that can deal with the relation overlap issue. The second one, MIML-RE ( <ref type="bibr" target="#b14">Surdeanu et al., 2012)</ref>, is one of the state-of-the-art MIML relation extraction sys- tems. We tune the models of MultiR and MIML- RE so that they fit our datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Overall Performance</head><p>First we compare our framework and its vari- ants with the baseline and the state-of-the-art RE models. Following previous works, we use the Precision-Recall curve as the evaluation criterion in our experiment. The results are summarized in <ref type="figure" target="#fig_1">Figure 2</ref>. For the constraints, we first manu- ally select an average of 20 relation pairs for each subcategory of the first kind of clues, and all the relations with unique argument values in R. We also show how automatically learnt clues perform in Section 4.5. <ref type="figure" target="#fig_1">Figure 2</ref> shows that compared with the baseline, our framework performs consistently better in the DBpedia dataset and the Chinese dataset. Mintz++ proves to be a strong baseline on both datasets. It tends to result in a high recall, and its weakness of low precision is perfectly fixed by the ILP model. Our ILP model and its variants all outperform Mintz++ in precision in both datasets, indicating that our approach helps filter out incorrect predic- tions from the output of MaxEnt model. Com- pared with MultiR, our framework obtains better results in both datasets. Especially in the Chinese dataset, the improvement in precision reaches as high as 10-16% at the same recall points. Our framework performs better compared to MIML- RE in the English dataset. On the Chinese dataset, our framework outperforms MIML-RE except in the low-recall portion (&lt;10%) of the P-R curve. All these results show that embedding the relation background information into RE can help elim- inate the wrong predictions and improve the re- sults.</p><p>However, in the Riedel's dataset, Mintz++, the MaxEnt relation extractor, does not perform well, and our framework cannot improve its perfor- mance. In order to find out the reasons, we manu- ally investigate the dataset. The top three relations of this dataset are /location/location/contains, /people/person/nationality and /people/person/place lived. About two-thirds of the entity tuples belongs to these three relations, and the outputs of the local extractor usually bias even more to the large relations. What is worse, we cannot find any clues from the top three relations because their arguments' types are too general. Things are similar for many other relations in this dataset. Although we may find some clues any way, they are too few to make any improvement. Hence, our framework does not perform well due to the poor performance of MaxEnt extractor and the lack of clues. To solve this problem, we think of addressing the selection preferences between relations and entities pro- posed in ( , which should be our future work.</p><p>We notice that in all three datasets our variant ILP-1cand is shorter than Mintz++ in recall, in- dicating we may incorrectly discard some predic- tions. Compared to ILP-2cand and original ILP, ILP-1cand leads to slightly lower precision but much lower recall, showing that selecting more candidates may help us collect more potentially correct predictions. Comparing ILP-2cand and original ILP, the latter hardly makes any improve- ment in precision, but is slightly longer in re- call, indicating using three candidates can still col- lect some more potentially correct predictions, al- though the number may be limited.</p><p>In order to study how our framework improves the performances on the DBpedia dataset and the Chinese dataset, we further investigate the num- ber of incorrect predictions eliminated by ILP and the number of incorrect predictions corrected by ILP. We also examine the number of correct pre- dictions newly introduce by ILP, which were NA in Mintz++. We summarize the results in <ref type="table" target="#tab_0">Table 1</ref>.</p><p>The results show that our framework can reduce the incorrect predictions and introduce more cor- rect predictions at the same time. We also find an interesting results: in the DBpedia dataset, ILP is more likely to introduce correct predictions to the results, while in the Chinese dataset it tends to reduce more incorrect predictions, which may be caused by the differences between performances of Mintz++ on the two datasets, where it gets a higher recall on the Chinese dataset.</p><p>Following <ref type="bibr" target="#b14">Surdeanu et al. (2012)</ref>, we also list the peak F1 score (highest F1 score) for each model in <ref type="table">Table 2</ref>. Different from ( <ref type="bibr" target="#b14">Surdeanu et al., 2012)</ref>, we use all the entity pairs instead of the ones with more than 10 mentions. We can observe that our model obtains the best performance in the DBpedia dataset and the Chinese dataset. In the DBpedia dataset, it is 3.6% higher than Mintz++, 7.9% higher than MIML-RE and 13.9% higher than MultiR. In the Chinese dataset, Mintz++, MultiR and MIML-RE performs similarly in terms of the highest F1 score, while our model gains about 8% improvement. In the Riedel's dataset, our framework hardly obtains any improvement compared with Mintz++.</p><p>We also investigate the impacts of the con- straints used in ILP, which are derived based on the two kinds of clues and can encode relation defini- tion information into our framework. Experimen- tal results in <ref type="table">Table 2</ref> shows that in the DBpedia dataset, the highest F1 score increases from 35.2% to 38.3% with the help of both kinds of clues, while in the Chinese dataset the improvement is from 44.4% to 52.8%. In the Riedel's dataset we do not see any improvements since there are al- most no clues. Furthermore, using constraints de- rived from only one kind of clues can also improve the performance, but not as well as using both of them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Adapting MultiR Sentence Level Extractor to Our Framework</head><p>The preliminary relation extractor of our optimiza- tion framework is not limited to the MaxEnt ex- tractor, and can take any sentence level relation extractor with confidence scores. We also fit Mul- tiR's mention level extractor into our framework.</p><p>As shown in <ref type="figure" target="#fig_4">Figure 3</ref>, in the DBpedia dataset and the Chinese dataset, in most parts of the curve, ILP optimized MultiR outperforms original Mul- tiR. We think the reason is that our framework make use of global clues to discard the incorrect predictions. The results are not as high as when we use MaxEnt as the preliminary extractor. We think one reason is that MultiR does not perform well in these two datasets. Furthermore, the confi- dence scores which MultiR outputs are not nor- malized to the same scale, which brings us dif- ficulties in setting up a confidence threshold to select the candidates. As a result, we only use the top one result as the candidate since including top two predictions without thresholding the confi- dences performs bad, indicating that a probabilis- tic sentence-level extractor is more suitable for our framework. We also notice that in the Riedel's dataset our framework does not improve the per- formance significantly, and we have discussed the reasons in Section 4.3.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Examining the Automatically Learnt Clues</head><p>Now we evaluate the performance of automati- cally collected clues used in our model. Since there are almost no clues in the Riedel's dataset, we only investigate the other two datasets. We add clues according to their related relations' propor- tions in the local predictions. For example, Coun- try and birthPlace take up about 30% in the local predictions, we thus add clues that are related to these two relations, and then move on with new clues related to other relations according to those relations' proportions in the local predictions. As is shown in <ref type="figure" target="#fig_2">Figure 4</ref>, in both datasets, the clues related to more local predictions will solve more inconsistencies, thus are more effective. Adding the first two relations improves the model significantly, and as more relations are added, the <ref type="table">Table 2</ref>: Results of the highest F1 score on all three datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DBpedia Riedel Chinese</head><p>Method P(%) R(%) F1(%) P(%) R(%) F1(%) P(%) R(%) F1(%)  performances keep increasing until approaching the still state. It is worth mentioning that when sufficient learnt clues are added into the model, the results are comparable to those based on the clues refined manually, as shown in <ref type="figure" target="#fig_3">Figure 5</ref>. This indi- cates that the clues can be collected automatically, and further used to examine whether predicted re- lations are consistent with the existing ones in the KB, which can be considered as a form of quality control.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In this paper, we make use of the global clues de- rived from KB to help resolve the disagreements among local relation predictions, thus reduce the incorrect predictions and improve the performance of relation extraction. Two kinds of clues, includ- ing implicit argument type information and argu- ment cardinality information of relations are in- vestigated. Our framework outperforms the state- of-the-art models if we can find such clues in the KB. Furthermore, our framework is scalable for other local sentence level extractors in addition to the MaxEnt model. Finally, we show that the clues can be learnt automatically from the KB, and lead to comparable performance to manually refined ones.</p><p>For future work, we will investigate other kinds of clues and attempt a joint optimization frame- work that could host entity disambiguation, rela- tion extraction and entity linking together. We will also adopt selection preference between en- tities and relations since sometimes we may not find useful clues.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>max t∈T ,r∈R t conf (t, r)d r t + ∀t,r∈R t ,m∈M r t max MEscore(m, r)d r t</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Overall performances of our framework and its variants, the baselines and the state-of-the-art approaches on the three datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: F1 score v.s. number of relations (used to introduce the related learnt clues into the ILP framework) on the DBpedia dataset (a) and the Chinese dataset (b).</figDesc><graphic url="image-2.png" coords="8,312.64,173.89,206.45,95.77" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Performances of manually selected clues and automatically learnt clues on two datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The results of original MultiR and ILP optimized MultiR on the three datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 :</head><label>1</label><figDesc>Details of the improvements made by ILP in the DBpedia and Chinese datasets.</figDesc><table>Datasets Incorrect Predictions Wrong Predictioins Correct Predictions 

Eliminated 
Corrected 
Newly Introduced 

DBpedia 
268 
61 
1426 

Chinese 
1506 
14 
283 

</table></figure>

			<note place="foot" n="1"> 1-&gt;0 1 USA, New York LocationCity: 0.8 FoundationPlace: 0.15 1 1 New York University, New York Capital: 0.95 LocationCity: 0.03 1 1-&gt;0 USA, Washington D.C. Nationality: 0.7 BirthPlace: 0.2 1 1 Richard Fuld,USA Capital: 0.3 1-&gt;0 Germany, Washington D.C. conflict LocationCountry: 0.5 LocationCity: 0.3 1-&gt;0 1 Columbia University, New York conflict</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank Heng Ji, Dong Wang and Kun Xu for their useful discussions and the anony-mous reviewers for their helpful comments which greatly improved the work. This work was sup-</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Open information extraction from the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michele</forename><surname>Banko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Cafarella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Broadhead</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI, IJCAI&apos;07</title>
		<meeting>IJCAI, IJCAI&apos;07</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="2670" to="2676" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Dbpedia-a crystallization point for the web of data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Bizer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgi</forename><surname>Kobilarov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sören</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Cyganiak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Hellmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Web Semant</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="154" to="165" />
			<date type="published" when="2009-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning to extract relations from the web using minimal supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Razvan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bunescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 45th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Unsupervised relation extraction with general domain knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Oier Lopez De Lacalle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="415" to="425" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Identifying relations for open information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;11</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;11<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1535" to="1545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Knowledge-based weak supervision for information extraction of overlapping relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Congle</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th ACL-HLT</title>
		<meeting>the 49th ACL-HLT<address><addrLine>Stroudsburg, PA, USA. ACL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="541" to="550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Joint inference for cross-document information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Anzaroot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Pin</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM International Conference on Information and Knowledge Management, CIKM &apos;11</title>
		<meeting>the 20th ACM International Conference on Information and Knowledge Management, CIKM &apos;11<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2225" to="2228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Joint event extraction via structured prediction with global features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Association for Computer Linguistics</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="73" to="82" />
		</imprint>
	</monogr>
	<note>ACL</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction without labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Mintz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bills</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rion</forename><surname>Snow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<idno>ACL &apos;09</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1003" to="1011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Modeling relations and their mentions without labeled text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning and Knowledge Discovery in Databases</title>
		<meeting><address><addrLine>Berlin / Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="volume">6323</biblScope>
			<biblScope unit="page" from="148" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Relation extraction with matrix factorization and universal schemas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><forename type="middle">M</forename><surname>Marlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint Human Language Technology Conference/Annual Meeting of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL &apos;13)</title>
		<imprint>
			<date type="published" when="2013-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Crystal inducing a conceptual dictionary</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Aseltine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wendy</forename><surname>Lehnert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th IJCAI</title>
		<meeting>the 14th IJCAI<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1995" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1314" to="1319" />
		</imprint>
	</monogr>
	<note>IJCAI&apos;95</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Advances in automated knowledge base construction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Suchanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><forename type="middle">Pratim</forename><surname>Talukdar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD Records journal</title>
		<imprint>
			<date type="published" when="2013-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A simple distant supervision approach for the TAC-KBP slot filling task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julie</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angel</forename><forename type="middle">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valentin</forename><forename type="middle">I</forename><surname>Spitkovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Text Analysis Conference</title>
		<meeting>the Third Text Analysis Conference<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Multiinstance multi-label learning for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julie</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-CoNLL</title>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="455" to="465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Reducing wrong labels in distant supervision for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shingo</forename><surname>Takamatsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Issei</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroshi</forename><surname>Nakagawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="721" to="729" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Collective cross-document relation extraction without labelled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP, EMNLP &apos;10</title>
		<meeting>EMNLP, EMNLP &apos;10<address><addrLine>Stroudsburg, PA, USA. ACL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1013" to="1023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Probabilistic databases of universal schema</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Workshop on Automatic Knowledge Base Construction and Webscale Knowledge Extraction, AKBC-WEKEX &apos;12</title>
		<meeting>the Joint Workshop on Automatic Knowledge Base Construction and Webscale Knowledge Extraction, AKBC-WEKEX &apos;12<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="116" to="121" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Towards accurate distant supervision for relational facts extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingxing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyu</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifang</forename><surname>Sui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-08" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="810" to="815" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Extracting relations with integrated information using kernel methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shubin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, ACL &apos;05</title>
		<meeting>the 43rd Annual Meeting on Association for Computational Linguistics, ACL &apos;05<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="419" to="426" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
