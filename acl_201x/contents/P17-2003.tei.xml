<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:06+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Lexical Features in Coreference Resolution: To be Used With Caution</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nafise</forename><forename type="middle">Sadat</forename><surname>Moosavi</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Strube</surname></persName>
						</author>
						<title level="a" type="main">Lexical Features in Coreference Resolution: To be Used With Caution</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</title>
						<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="14" to="19"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-2003</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Lexical features are a major source of information in state-of-the-art coreference resolvers. Lexical features implicitly model some of the linguistic phenomena at a fine granularity level. They are especially useful for representing the context of mentions. In this paper we investigate a drawback of using many lexical features in state-of-the-art coreference resolvers. We show that if coreference resolvers mainly rely on lexical features, they can hardly generalize to unseen domains. Furthermore, we show that the current coreference resolution evaluation is clearly flawed by only evaluating on a specific split of a specific dataset in which there is a notable overlap between the training, development and test sets.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Similar to many other tasks, lexical features are a major source of information in current corefer- ence resolvers. Coreference resolution is a set par- titioning problem in which each resulting partition refers to an entity. As shown by <ref type="bibr" target="#b3">Durrett and Klein (2013)</ref>, lexical features implicitly model some lin- guistic phenomena, which were previously mod- eled by heuristic features, but at a finer level of granularity. However, we question whether the knowledge that is mainly captured by lexical fea- tures can be generalized to other domains.</p><p>The introduction of the CoNLL dataset en- abled a significant boost in the performance of coreference resolvers, i.e. about 10 percent differ- ence between the CoNLL score of the currently best coreference resolver, deep-coref by <ref type="bibr" target="#b2">Clark and Manning (2016b)</ref>, and the winner of the CoNLL 2011 shared task, the Stanford rule-based system by <ref type="bibr" target="#b6">Lee et al. (2013)</ref>. However, this substantial im- provement does not seem to be visible in down- stream tasks. Worse, the difference between state- of-the-art coreference resolvers and the rule-based system drops significantly when they are applied on a new dataset, even with consistent definitions of mentions and coreference relations <ref type="bibr" target="#b4">(Ghaddar and Langlais, 2016a)</ref>.</p><p>In this paper, we show that if we mainly rely on lexical features, as it is the case in state-of-the- art coreference resolvers, overfitting become more sever. Overfitting to the training dataset is a prob- lem that cannot be completely avoided. However, there is a notable overlap between the CoNLL training, development and test sets that encour- ages overfitting. Therefore, the current corefer- ence evaluation scheme is flawed by only evalu- ating on this overlapped validation set. To ensure meaningful improvements in coreference resolu- tion, we believe an out-of-domain evaluation is a must in the coreference literature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Lexical Features</head><p>The large difference in performance between coreference resolvers that use lexical features and ones which do not, implies the importance of lex- ical features. <ref type="bibr" target="#b3">Durrett and Klein (2013)</ref> show that lexical features implicitly capture some phenom- ena, e.g. definiteness and syntactic roles, which were previously modeled by heuristic features. <ref type="bibr" target="#b3">Durrett and Klein (2013)</ref> use exact surface forms as lexical features. However, when word embed- dings are used instead of surface forms, the use of lexical features is even more beneficial. Word embeddings are an efficient way of capturing se- mantic relatedness. Especially, they provide an ef- ficient way for describing the context of mentions. <ref type="bibr" target="#b3">Durrett and Klein (2013)</ref> show that the addi- tion of some heuristic features like gender, num-</p><formula xml:id="formula_0">14 MUC B 3</formula><p>CEAFe <ref type="table" target="#tab_1">CoNLL  LEA  R  P  F1  R  P  F1  R  P  F1 Avg. F1  R  P  F1  CoNLL test set  rule-</ref>  ber, person and animacy agreements and syntactic roles on top of their lexical features does not result in a significant improvement. deep-coref, the state-of-the-art coreference re- solver, follows the same approach. <ref type="bibr" target="#b2">Clark and Manning (2016b)</ref> capture the required information for resolving coreference relations by using a large number of lexical features and a small set of non- lexical features including string match, distance, mention type, speaker and genre features. The main difference is that <ref type="bibr" target="#b2">Clark and Manning (2016b)</ref> use word embeddings instead of the exact surface forms that are used by <ref type="bibr" target="#b3">Durrett and Klein (2013)</ref>.</p><p>Based on the error analysis by cort <ref type="bibr" target="#b10">(Martschat and Strube, 2014)</ref>, in comparison to systems that do not use word embeddings, deep-coref has fewer recall and precision errors especially for pro- nouns. For example, deep-coref correctly recog- nizes around 83 percent of non-anaphoric "it" in the CoNLL development set. This could be a di- rect result of a better context representation by word embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Out-of-Domain Evaluation</head><p>Aside from the evident success of lexical features, it is debatable how well the knowledge that is mainly captured by the lexical information of the training data can be generalized to other domains. As reported by <ref type="bibr" target="#b5">Ghaddar and Langlais (2016b)</ref>, state-of-the-art coreference resolvers trained on the CoNLL dataset perform poorly, i.e. worse than the rule-based system ( <ref type="bibr" target="#b6">Lee et al., 2013</ref>), on the new dataset, WikiCoref (Ghaddar and Langlais, 2016b), even though WikiCoref is annotated with the same annotation guidelines as the CoNLL dataset. The results of some of recent coreference resolvers on this dataset are listed in <ref type="table" target="#tab_1">Table 1</ref>.</p><p>The results are reported using MUC <ref type="formula">(</ref>  <ref type="bibr" target="#b12">Moosavi and Strube, 2016)</ref>. berkeley is the mention-ranking model of Dur- rett and Klein (2013) with the FINAL feature set including the head, first, last, preceding and fol- lowing words of a mention, the ancestry, length, gender and number of a mention, distance of two mentions, whether the anaphor and antecedent are nested, same speaker and a small set of string match features.</p><p>cort is the mention-ranking model of <ref type="bibr" target="#b11">Martschat and Strube (2015)</ref>. cort uses the following set of features: the head, first, last, preceding and fol- lowing words of a mention, the ancestry, length, gender, number, type, semantic class, dependency relation and dependency governor of a mention, the named entity type of the head word, distance of two mentions, same speaker, whether the anaphor and antecedent are nested, and a set of string match features. berkeley and cort scores in <ref type="table" target="#tab_1">Table 1</ref> are taken from <ref type="bibr" target="#b4">Ghaddar and Langlais (2016a)</ref>. deep-coref is the mention-ranking model of <ref type="bibr" target="#b2">Clark and Manning (2016b)</ref>. deep-coref incorpo- rates a large set of embeddings, i.e. embeddings of the head, first, last, two previous/following words, and the dependency governor of a mention in ad- dition to the averaged embeddings of the five pre- vious/following words, all words of the mention, sentence words, and document words. deep-coref also incorporates type, length, and position of a mention, whether the mention is nested in any other mention, distance of two mentions, speaker features and a small set of string match features.</p><p>For deep-coref [conll] the averaged CoNLL score is used to select the best trained model on the development set. deep-coref <ref type="bibr">[lea]</ref> uses the LEA genre bc bn mz nw pt tc wb train+dev 43% 50% 51% 45% 77% 38% 39% train 41% 49% 39% 44% 76% 37% 38% <ref type="table">Table 2</ref>: Ratio of non-pronominal coreferent men- tions in the test set that are seen as coreferent in the training data.</p><p>metric <ref type="bibr" target="#b12">(Moosavi and Strube, 2016)</ref> for choosing the best model. It is worth noting that the results of deep-coref 's ranking model may be slightly dif- ferent at various experiments. However, the per- formance of deep-coref <ref type="bibr">[lea]</ref> is always higher than that of deep-coref <ref type="bibr">[conll]</ref>.</p><p>We add WikiCoref's words to deep-coref 's dic- tionary for both deep-coref <ref type="bibr">[conll]</ref> and deep-coref <ref type="bibr">[lea]</ref>. deep-coref − reports the performance of deep-coref <ref type="bibr">[lea]</ref> in which WikiCoref's words are not incorporated into the dictionary. Therefore, for deep-coref − , WikiCoref's words that do not exist in CoNLL will be initialized randomly in- stead of using pre-trained word2vec word embed- dings. The performance gain of deep-coref <ref type="bibr">[lea]</ref> in comparison to deep-coref − indicates the bene- fit of using pre-trained word embeddings and word embeddings in general. Henceforth, we refer to deep-coref <ref type="bibr">[lea]</ref> as deep-coref.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Why do Improvements Fade Away?</head><p>In this section, we investigate how much lexical features contribute to the fact that current improve- ments in coreference resolution do not properly apply to a new domain. <ref type="table">Table 2</ref> shows the ratio of non-pronominal coreferent mentions in the CoNLL test set that also appear as coreferent mentions in the training data. These high ratios indicate a high degree of overlap between the mentions of the CoNLL datasets.</p><p>The highest overlap between the training and test sets exists in genre pt (Bible). The tc (tele- phone conversation) genre has the lowest over- lap for non-pronominal mentions. However, this genre includes a large number of pronouns. We choose wb (weblog) and pt for our analysis as two genres with low and high degree of overlap. <ref type="table" target="#tab_4">Table 3</ref> shows the results of the examined coref- erence resolvers when the test set only includes one genre, i.e. pt or wb, in two different settings: (1) the training set includes all genres (in-domain evaluation), and (2) the corresponding genre of the test set is excluded from the training and develop- ment sets (out-of-domain evaluation).</p><p>berkeley-final is the coreference resolver of <ref type="bibr" target="#b3">Durrett and Klein (2013)</ref> with the FINAL feature set explained in Section 3. berkeley-surface is the same coreference resolver with only surface fea- tures, i.e. ancestry, gender, number, same speaker and nested features are excluded from the FINAL feature set.</p><p>cort−lexical is a version of cort in which no lexical feature is used, i.e. the head, first, last, gov- ernor, preceding and following words of a mention are excluded.</p><p>For in-domain evaluations we train deep-coref 's ranking model for 100 iterations, i.e. the setting used by <ref type="bibr" target="#b1">Clark and Manning (2016a)</ref>. However, based on the performance on the development set, we only train the model for 50 iterations in out-of- domain evaluations.</p><p>The results of the pt genre show that when there is a high overlap between the training and test datasets, the performance of all learning-based classifiers significantly improves. deep-coref has the largest gain from including pt in the training data that is more than 13% based on the LEA score. cort uses both lexical and a relatively large num- ber of non-lexical features while berkeley-surface is a pure lexicalized system. However, the differ- ence between the berkeley-surface's performances when pt is included or excluded from the train- ing data is lower than that of cort. berkeley uses feature-value pruning so lexical features that occur fewer than 20 times are pruned from the training data. Maybe, this is the reason that berkeley's per- formance difference is less than other lexicalized systems in highly overlapping datasets.</p><p>For a less overlapping genre, i.e. wb, the perfor- mance gain of including the genre in the training data is significantly lower for all lexicalized sys- tems. Interestingly, the performance of berkeley- final, cort and cort−lexical increases for the wb genre when this genre is excluded from the train- ing set. deep-coref, which uses a complex deep neural network and mainly lexical features, has the highest gain from the redundancy in the training and test datasets. As we use more complex neu- ral networks, there is more capacity for brute-force memorization of the training dataset.</p><p>It is also worth noting that the performance gains and drops in out-of-domain evaluations are    We further analyze the output of deep-coref on the development set. The all rows in <ref type="table" target="#tab_5">Table 4</ref> show the number of pairwise links that are created by deep-coref on the development set for different mention types. The seen rows show the ratio of each category of links for which the (antecedent head, anaphor head) pair is seen in the training set. All ratios are surprisingly high. The most worri- some cases are those in which both mentions are either a proper name or a common noun. <ref type="table" target="#tab_7">Table 5</ref> further divides the links of <ref type="table" target="#tab_5">Table 4</ref> based on whether they are correct coreferent links. The results of <ref type="table" target="#tab_7">Table 5</ref> show that most of the incorrect links are also made between the mentions that are both seen in the training data.</p><p>The high ratios indicate that <ref type="formula">(1)</ref>   overlap between the mention pairs of the training and development sets, and (2) even though that deep-coref uses generalized word embeddings in- stead of exact surface forms, it is strongly biased towards the seen mentions. We analyze the links that are created by Stan- ford's rule-based system and compute the ratio of the links that exist in the training set. All corre- sponding ratios are lower than those of deep-coref in <ref type="table" target="#tab_7">Table 5</ref>. However, the ratios are surprisingly high for a system that does not use the training data. This analysis emphasizes the overlap in the CoNLL datasets. Because of this high overlap, it is not easy to assess the generalizability of a coref- erence resolver to unseen mentions on the CoNLL dataset given its official split.</p><p>We also compute the ratios of <ref type="table" target="#tab_7">Table 5</ref> for the missing links that are associated with the recall er-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Anaphor</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Antecedent</head><p>Proper <ref type="table" target="#tab_1">Nominal Pronominal   Proper  seen  63%  51%  75%  all  818  418  278   Nominal  seen  44%  73%  90%  all  168  892  538   Pronominal  seen  82%  90%  100%  all  49  59  444   Table 6</ref>: Ratio of deep-coref's recall errors for which the head-pair exists in the training data.</p><p>rors of deep-coref. We compute the recall errors by cort error analysis tool <ref type="bibr" target="#b10">(Martschat and Strube, 2014)</ref>. <ref type="table">Table 6</ref> shows the corresponding ratios for recall errors. The lower ratios of <ref type="table">Table 6</ref> in com- parison to those of <ref type="table" target="#tab_5">Table 4</ref> emphasize the bias of deep-coref towards the seen mentions. For example, the deep-coref links include 31 cases in which both mentions are either proper names or common nouns and the head of one of the mentions is "country". For all these links, "country" is linked to a mention that is seen in the training data. Therefore, this raises the question how the classifier would perform on a text about countries not mentioned in the training data.</p><p>Memorizing the pairs in which one of them is a common noun could help the classifier to capture world knowledge to some extent. From the seen pairs like <ref type="bibr">(Haiti, his country)</ref>, and (Guangzhou, the city) the classifier could learn that "Haiti" is a country and "Guangzhou" is a city. However, it is questionable how useful word knowledge is if it is mainly based on the training data.</p><p>The coreference relation of two nominal noun phrases with no head match can be very hard to resolve. The resolution of such pairs has been re- ferred to as capturing semantic similarity <ref type="bibr" target="#b2">(Clark and Manning, 2016b)</ref>. deep-coref links 49 such pairs on the development set. Among all these links, only 5 pairs are unseen on the training set and all of them are incorrect links.</p><p>The effect of lexical features is also analyzed by <ref type="bibr" target="#b7">Levy et al. (2015)</ref> for tasks like hypernymy and entailment. They show that state-of-the-art classi- fiers memorize words from the training data. The classifiers benefit from this lexical memorization when there are common words between the train- ing and test sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>We show the extensive use of lexical features bi- ases coreference resolvers towards seen mentions. This bias holds us back from developing more ro- bust and generalizable coreference resolvers. Af- ter all, while coreference resolution is an impor- tant step for text understanding, it is not an end- task. Coreference resolvers are going to be used in tasks and domains for which coreference an- notated corpora may not be available. Therefore, generalizability should be brought into attention in developing coreference resolvers.</p><p>Moreover, we show that there is a significant overlap between the training and validation sets in the CoNLL dataset. The LEA metric <ref type="bibr" target="#b12">(Moosavi and Strube, 2016</ref>) is introduced as an attempt to make coreference evaluations more reliable. However, in order to ensure valid developments on corefer- ence resolution, it is not enough to have reliable evaluation metrics. The validation set on which the evaluations are performed also needs to be re- liable. A dataset is reliable for evaluations if a con- siderable improvement on this dataset indicates a better solution for the coreference problem instead of a better exploitation of the dataset itself.</p><p>This paper is not intended to argue against the use of lexical features. Especially, when word em- beddings are used as lexical features. The incorpo- ration of word embeddings is an efficient way for capturing semantic relatedness. Maybe we should use them more for describing the context and less for describing the mentions themselves. Pruning rare lexical features plus incorporating more gen- eralizable features could also help to prevent over- fitting.</p><p>To ensure more meaningful improvements, we ask to incorporate out-of-domain evaluations in the current coreference evaluation scheme. Out- of-domain evaluations could be performed by us- ing either the existing genres of the CoNLL dataset or by using other existing coreference annotated datasets like WikiCoref, MUC or ACE.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>not entirely because of lexical features, as the per- formance of cort−lexical also drops significantly in pt out-of-domain evaluation. The classifier may also memorize other properties of the seen men- tions in the training data. However, in compari- son to features like gender and number agreement or syntactic roles, lexical features have the highest potential for overfitting.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Comparison of the results on the CoNLL test set and WikiCoref. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><head>Table 3 : In-domain and out-of-domain evaluations for a high and a low overlapped genres.</head><label>3</label><figDesc></figDesc><table>Anaphor 
Antecedent 
Proper Nominal Pronominal 

Proper 
seen 
80% 
85% 
77% 
all 
3221 
261 
1200 

Nominal 
seen 
75% 
93% 
95% 
all 
69 
1673 
1315 

Pronominal 
seen 
58% 
99% 
100% 
all 
85 
74 
4737 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 :</head><label>4</label><figDesc>Ratio of links created by deep-coref for which the head-pair is seen in the training data.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Ratio of links created by deep-coref for 
which the head-pair is seen in the training data. 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors would like to thank Kevin Clark for answering all of our questions regarding deep-coref. We would also like to thank the three anony-mous reviewers for their thoughtful comments. This work has been funded by the Klaus Tschira Foundation, Heidelberg, Germany. The first au-thor has been supported by a Heidelberg Institute for Theoretical Studies PhD. scholarship.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Algorithms for scoring coreference chains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Bagga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Breck</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st International Conference on Language Resources and Evaluation</title>
		<meeting>the 1st International Conference on Language Resources and Evaluation<address><addrLine>Granada, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-05-30" />
			<biblScope unit="page" from="563" to="566" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning for mentionranking coreference models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Tex</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-11" />
			<biblScope unit="page" from="2256" to="2262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Improving coreference resolution by learning entitylevel distributed representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P16-1061.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2016-08" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="7" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Easy victories and uphill battles in coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Durrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/D13-1203.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013-10" />
			<biblScope unit="page" from="1971" to="1982" />
		</imprint>
	</monogr>
	<note>Seattle, Wash.</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Coreference in Wikipedia: Main concept resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abbas</forename><surname>Ghaddar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Langlais</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/K16-1023.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th Conference on Computational Natural Language Learning</title>
		<meeting>the 20th Conference on Computational Natural Language Learning<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-08" />
			<biblScope unit="page" from="229" to="238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">WikiCoref: An English coreference-annotated corpus of Wikipedia articles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abbas</forename><surname>Ghaddar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Langlais</surname></persName>
		</author>
		<ptr target="http://www.lrec-conf.org/proceedings/lrec2016/pdf/192Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Conference on Language Resources and Evaluation</title>
		<meeting>the 10th International Conference on Language Resources and Evaluation<address><addrLine>Portorož, Slovenia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-05" />
			<biblScope unit="page" from="23" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Deterministic coreference resolution based on entity-centric, precision-ranked rules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heeyoung</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angel</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yves</forename><surname>Peirsman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/J13-4004.pdf" />
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="885" to="916" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Do supervised distributional methods really learn lexical inference relations?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steffen</forename><surname>Remus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/N15-1098" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Denver</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Denver</meeting>
		<imprint>
			<date type="published" when="2015-05-31" />
			<biblScope unit="page" from="970" to="976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">On coreference resolution performance metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoqiang</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Human Language Technology Conference and the</title>
		<meeting>the Human Language Technology Conference and the</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<title level="m">Conference on Empirical Methods in Natural Language Processing</title>
		<meeting><address><addrLine>Vancouver, B.C., Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-10" />
			<biblScope unit="page" from="25" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Recall error analysis for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Martschat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Strube</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/D14-1221.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-10" />
			<biblScope unit="page" from="2070" to="2081" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Latent structures for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Martschat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Strube</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/Q15-1029.pdf" />
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="405" to="418" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Which coreference evaluation metric do you trust? A proposal for a link-based entity aware metric</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadat</forename><surname>Nafise</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Moosavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Strube</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2016-08" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="632" to="642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Scoring coreference partitions of predicted mentions: A reference implementation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoqiang</forename><surname>Sameer Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Recasens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Strube</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P14-" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Baltimore, Md</addrLine></address></meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2014-06" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="30" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Dennis Connolly, and Lynette Hirschman. 1995. A modeltheoretic coreference scoring scheme</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Vilain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Aberdeen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th Message Understanding Conference (MUC-6)</title>
		<meeting>the 6th Message Understanding Conference (MUC-6)<address><addrLine>San Mateo, Cal</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<biblScope unit="page" from="45" to="52" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
