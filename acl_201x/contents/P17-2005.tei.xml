<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:46+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Principled Framework for Evaluating Summarizers: Comparing Models of Summary Quality against Human Judgments</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxime</forename><surname>Peyrard</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judith</forename><surname>Eckle-Kohler</surname></persName>
						</author>
						<title level="a" type="main">A Principled Framework for Evaluating Summarizers: Comparing Models of Summary Quality against Human Judgments</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</title>
						<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="26" to="31"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-2005</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present a new framework for evaluating extractive summarizers, which is based on a principled representation as optimization problem. We prove that every ex-tractive summarizer can be decomposed into an objective function and an optimization technique. We perform a comparative analysis and evaluation of several objective functions embedded in well-known summarizers regarding their correlation with human judgments. Our comparison of these correlations across two datasets yields surprising insights into the role and performance of objective functions in the different summarizers.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The task of extractive summarization (ES) can nat- urally be cast as a discrete optimization problem where the text source is considered as a set of sen- tences and the summary is created by selecting an optimal subset of the sentences under a length con- straint <ref type="bibr" target="#b12">(McDonald, 2007;</ref><ref type="bibr" target="#b9">Lin and Bilmes, 2011)</ref>.</p><p>In this work, we go one step further and mathe- matically prove that ES is equivalent to the prob- lem of choosing (i) an objective function θ for scoring system summaries, and (ii) an optimizer O. We use (θ, O) to denote the resulting decompo- sition of any extractive summarizer. Our proposed decomposition enables a principled analysis and evaluation of existing summarizers, and addresses a major issue in the current evaluation of ES.</p><p>This issue concerns the traditional "intrinsic" evaluation comparing system summaries against human reference summaries. This kind of evalu- ation is actually an end-to-end evaluation of sum- marization systems which is performed after θ has been optimized by O. This is highly problematic from an evaluation point of view, because first, θ is typically not optimized exactly, and second, there might be side-effects caused by the particu- lar optimization technique O, e.g., a sentence ex- tracted to maximize θ might be suitable because of other properties not included in θ. Moreover, the commonly used evaluation metric ROUGE yields a noisy surrogate evaluation (despite its good cor- relation with human judgments) compared to the much more meaningful evaluation based on hu- man judgments. As a result, the current end-to- end evaluation does not provide any insights into the task of automatic summarization.</p><p>The (θ, O) decomposition we propose addresses this issue: it enables a well-defined and principled evaluation of extractive summarizers on the level of their components θ and O. In this work, we fo- cus on the analysis and evaluation of θ, because θ is a model of the quality indicators of a sum- mary, and thus crucial in order to understand the properties of "good" summaries. Specifically, we compare θ functions of different summarizers by measuring the correlation of their θ functions with human judgments.</p><p>Our goal is to provide an evaluation framework which the research community could build upon in future research to identify the best possible θ and use it in optimization-based systems. We be- lieve that the identification of such a θ is the cen- tral question of summarization, because this op- timal θ would represent an optimal definition of summary quality both from an algorithmic point of view and from the human perspective.</p><p>In summary, our contribution is twofold: (i) We present a novel and principled evaluation frame- work for ES which allows evaluating the objec- tive function and the optimization technique sep- arately and independently. (ii) We compare well- known summarization systems regarding their im- plicit choices of θ by measuring the correlation of their θ functions with human judgments on two datasets from the Text Analysis Conference (TAC). Our comparative evaluation yields surpris- ing results and shows that extractive summariza- tion is not solved yet.</p><p>The code used in our experiments, includ- ing a general evaluation tool is available at github.com/UKPLab/acl2017-theta_ evaluation_summarization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Evaluation Framework</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">(θ, O) decomposition</head><p>Let D = {s i } be a document collection consid- ered as a set of sentences. A summary S is then a subset of D, or we can say that S is an element of P(D), the power set of D. Objective function We define an objective func- tion to be a function that takes a summary of the document collection D and outputs a score:</p><formula xml:id="formula_0">θ : P(D) → R S → θ D (S)<label>(1)</label></formula><p>Optimizer Then the task of ES is to select the set of sentences S * with maximal θ(S * ) under a length constraint:</p><formula xml:id="formula_1">S * = argmax S θ(S) len(S) = s∈S len(s) ≤ c<label>(2)</label></formula><p>We use O to denote the technique which solves this optimization problem. O is an operator which takes an objective function θ from the set of all objective functions Θ and a document collection D from the set of all document collections D, and outputs a summary S * :</p><formula xml:id="formula_2">O : Θ × D → S (θ, D) → S * (3)</formula><p>Decomposition Theorem Now we show that the problem of ES is equivalent to the problem of choosing a decomposition (θ, O).</p><p>We formalize an extractive summarizer σ as a set function which takes a document collection D ∈ D and outputs a summary S D,σ ∈ P(D). With this formalism, it is clear that every (θ, O) tu- ple forms a summarizer because O(θ, ·) produces a summary from a document collection.</p><p>But the other direction is also true: for every ex- tractive summarizer there exists at least one tuple (θ, O) which perfectly describes the summarizer:</p><formula xml:id="formula_3">Theorem 1 ∀σ, ∃(θ, O) such that: ∀D ∈ D, σ(D) = O(θ, D)</formula><p>This theorem is quite intuitive, especially since it is common to use a similar decomposition in optimization-based summarization systems. In the next section we illustrate the theorem by way of several examples, and provide a rigorous proof of the existence in the supplemental material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Examples of θ</head><p>We analyze a range of different summarizers re- garding their (mostly implicit) θ. ICSI ( <ref type="bibr" target="#b4">Gillick and Favre, 2009</ref>) is a global linear optimization that extracts a summary by solving a maximum coverage problem considering the most frequent bigrams in the source documents. ICSI has been among the best systems in a classical ROUGE evaluation ( <ref type="bibr" target="#b6">Hong et al., 2014</ref>). For ICSI, the identification of θ is trivial because it was for- mulated as an optimization task. If c i is the i-th bigram selected in the summary and w i its weight computed from D, then:</p><formula xml:id="formula_4">θ ICSI (S) = c i ∈S c i * w i<label>(4)</label></formula><p>LexRank ( <ref type="bibr" target="#b2">Erkan and Radev, 2004</ref>) is a well- known graph-based approach. A similarity graph G(V, E) is constructed where V is the set of sen- tences and an edge e ij is drawn between sentences v i and v j if and only if the cosine similarity be- tween them is above a given threshold. Sentences are scored according to their PageRank score in G. We observe that θ LexRank is given by:</p><formula xml:id="formula_5">θ LexRank (S) = s∈S P R G (s)<label>(5)</label></formula><p>where P R is the PageRank score of sentence s.  <ref type="bibr" target="#b19">and Jezek, 2004</ref>) is an approach involving a dimensionality reduction of the term- document matrix via Singular Value Decomposi- tion (SVD). The sentences extracted should cover the most important latent topics:</p><formula xml:id="formula_6">θ LSA = t∈S λ t (6)</formula><p>where t is a latent topic identified by SVD on the term-document matrix and λ t the associated sin- gular value.</p><p>Edmundson <ref type="bibr" target="#b1">(Edmundson, 1969</ref>) is an older heuristic method which scores sentences accord- ing to cue-phrases, overlap with title, term fre- quency and sentence position. θ Edmundson is sim- ply a weighted sum of these heuristics. TFIDF (Luhn, 1958) scores sentences with the TF*IDF of their terms. The best sentences are then greedily extracted. We use both the unigram and bigram versions in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>Now we compare the summarizers analyzed above by measuring the correlation of their θ functions with human judgments.</p><p>Datasets We use two multi-document summa- rization datasets from the Text Analysis Confer- ence (TAC) shared task: TAC-2008 and TAC- 2009. 1 TAC-2008 and TAC-2009 contain 48 and 44 topics, respectively. Each topic consists of 10 news articles to be summarized in a maximum of 100 words. We use only the so-called initial sum- maries (A summaries), but not the update part.</p><p>For each topic, there are 4 human reference summaries along with a manually created Pyramid set. In both editions, all system summaries and the 4 reference summaries were manually evalu- ated by NIST assessors for readability, content se- lection (with Pyramid) and overall responsiveness. At the time of the shared tasks, 57 systems were submitted to <ref type="bibr">TAC-2008 and</ref><ref type="bibr">55 to TAC-2009.</ref> For our experiments, we use the Pyramid and the re- sponsiveness annotations.</p><p>System Comparison For each θ, we compute the scores of all system and all manual summaries for any given topic. These scores are compared with the human scores. We include the manual summaries in our computation because this yields a more diverse set of summaries with a wider range of scores. Since an ideal summarizer would create summaries as well as humans, an ideal θ would also be able to correctly score human sum- maries with high scores.</p><p>For comparison, we also report the correlation between pyramid and responsiveness.</p><p>Correlations are measured with 3 metrics: Pear-son's r, Spearman's ρ and Normalized Discounted Cumulative Gain (Ndcg). Pearson's r is a value correlation metric which depicts linear relation- ships between the scores produced by θ and the human judgments. Spearman's ρ is a rank correla- tion metric which compares the ordering of sys- tems induced by θ and the ordering of systems induced by human judgments. Ndcg is a metric that compares ranked lists and puts more emphasis on the top elements by logarithmic decay weight- ing. Intuitively, it captures how well θ can rec- ognize the best summaries. The optimization sce- nario benefits from high Ndcg scores because only summaries with high θ scores are extracted.</p><p>Previous work on correlation analysis averaged scores over topics for each system and then com- puted the correlation between averaged scores ( <ref type="bibr" target="#b10">Louis and Nenkova, 2013;</ref><ref type="bibr" target="#b14">Nenkova et al., 2007</ref>). An alternative and more natural option which we use here is to compute the correlation for each topic and average these correlations over topics (CORRELATION-AVERAGE). Since we want to estimate how well θ functions measure the quality of summaries, we find the summary level averag- ing more meaningful.</p><p>Analysis The results of our correlation analysis are presented in <ref type="table">Table 1</ref>.</p><p>In our (θ, O) formulation, the end-to-end ap- proach maps a set of documents to exactly one summary selected by the system. We call the (clas- sical and well known) evaluation of this single summary end-to-end evaluation because it mea- sures the end product of the system. This is in con- trast to our proposed evaluation of the assumption made by individual summarizers shown in <ref type="table">Table 1</ref>. A system summary was extracted by a given sys- tem because it was high scoring using its θ, but we ask the question whether optimizing this θ made sense in the first place.</p><p>We first observe that scores are relatively low. Summarization is not a solved problem and the systems we investigated can not identify correctly what makes a good summary. This is in contrast to the picture in the classical end-to-end evaluation with ROUGE where state-of-the-art systems score relatively high. Some Ndcg scores are higher (for TAC-2008) which explains why these systems can extract relatively good summaries in the end-to- end evaluation. In this classical evaluation, only the single best summary is evaluated, which means that a system does not need to be able to rank all  <ref type="table">Table 1</ref>: Correlation of θ functions with human judgments across various systems.</p><note type="other">TAC-2008 TAC-2009 responsiveness Pyramid responsiveness Pyramid θ r ρ Ndcg r ρ Ndcg r ρ Ndcg r ρ</note><p>possible summaries correctly. We see that systems with high end-to-end ROUGE scores (according to <ref type="bibr" target="#b6">Hong et al. (2014)</ref>) do not necessarily have a good model of summary quality. Indeed, the best performing θ functions are not part of the systems performing best with ROUGE. For example, ICSI is the best system ac- cording to ROUGE, but it is not clear that it has the best model of summary quality. In TAC-2009, LexRank, LSA and the heuristic Edmundson have better correlations with human judgments. The difference with end-to-end evaluation might stem from the fact that ICSI solves the optimization problem exactly, while LexRank and Edmundson use greedy optimizers. There might also be some side-effects from which ICSI profits: extracting sentences to improve θ might lead to accidentally selecting suitable sentences, because θ can merely correlate well with properties of good summaries, while not modeling these properties itself.</p><p>It is worth noting that systems perform differ- ently on TAC2009 and TAC2008. There are sev- eral differences between TAC2008 and TAC2009 like redundancy level or guidelines for annota- tions; for example, responsiveness is scored out of 5 in 2008 and out of 10 in 2009. The LSA sum- marizer ranks among the best systems in TAC2009 with pearson's r but is closer to the worst sys- tems in TAC2008. While this is difficult to ex- plain we hypothesize that the model of summary quality from LSA is sensitive to the slight vari- ations and therefore not robust. In general, any system which claims to have a better θ than previ- ous works should indeed report results on several datasets to ensure robustness and generality.</p><p>Interestingly, we observe that the correlation be- tween Pyramid and responsiveness is better than in any system, but still not particularly high. Respon- siveness is an overall annotation while Pyramid is a manual measure of content only. These results confirm the intuition that humans take into account much more aspects when evaluating summaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related Work and Discussion</head><p>While correlation analyses on human judgment data have been performed in the context of validat- ing automatic summary evaluation metrics <ref type="bibr" target="#b10">(Louis and Nenkova, 2013;</ref><ref type="bibr" target="#b14">Nenkova et al., 2007;</ref><ref type="bibr" target="#b7">Lin, 2004</ref>), there is no prior work which uses these data for a principled comparison of summarizers.</p><p>Much previous work focused on efficient opti- mizers O, such as ILP, which impose constraints on the θ function. <ref type="bibr">Linear (Gillick and Favre, 2009)</ref> and submodular (Lin and Bilmes, 2011) θ func- tions are widespread in the summarization com- munity because they can be optimized efficiently and effectively via ILP <ref type="bibr" target="#b16">(Schrijver, 1986)</ref> and the greedy algorithm for submodularity <ref type="bibr" target="#b3">(Fujishige, 2005)</ref>. A greedy approach is often used when θ does not have convenient properties that can be leveraged by a classical optimizer <ref type="bibr" target="#b5">(Haghighi and Vanderwende, 2009)</ref>.</p><p>Such interdependencies of O and θ limit the ex- pressiveness of θ. However, realistic θ functions are unlikely to be linear or submodular, and in the well-studied field of optimization there exist a range of different techniques developed to tackle difficult combinatorial problems <ref type="bibr" target="#b17">(Schrijver, 2003;</ref><ref type="bibr" target="#b0">Blum and Roli, 2003)</ref>.</p><p>A recent example of such a technique adapted to extractive summarization are meta-heuristics used to optimize non-linear, non-submodular objec- tive functions <ref type="bibr" target="#b15">(Peyrard and Eckle-Kohler, 2016</ref>).</p><p>Other methods like Markov Chain Monte Carlo ( <ref type="bibr" target="#b13">Metropolis et al., 1953)</ref> or Monte-Carlo Tree Search <ref type="bibr" target="#b20">(Suttner and Ertel, 1991;</ref><ref type="bibr" target="#b18">Silver et al., 2016</ref>) could also be adapted to summarization and thus become realistic choices for O. General pur- pose optimization techniques are especially ap- pealing, because they offer a decoupling of θ and O and allow investigating complex θ functions without making any assumption on their mathe- matical properties. In particular, this supports fu- ture work on identifying an "optimal" θ as a model of relevant quality aspects of a summary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We presented a novel evaluation framework for ES which is based on the proof that ES is equivalent to the problem of choosing an objective function θ and an optimizer O. This principled and well- defined framework allows evaluating θ and O of any extractive summarizer -separately and inde- pendently. We believe that our framework can serve as a basis for future work on identifying an "optimal" θ function, which would provide an an- swer to the central question of what are the prop- erties of a "good" summary.</p></div>
			<note place="foot" n="1"> http://tac.nist.gov/2009/ Summarization/, http://tac.nist.gov/2008/ Summarization/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work has been supported by the German Re-search Foundation (DFG) as part of the Research Training Group "Adaptive Preparation of Informa-tion from Heterogeneous Sources" (AIPHES) un-der grant No. GRK 1994/1, and via the German-Israeli Project Cooperation (DIP, grant No. GU 798/17-1).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Metaheuristics in Combinatorial Optimization: Overview and Conceptual Comparison</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Roli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="268" to="308" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">New Methods in Automatic Extracting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">P</forename><surname>Edmundson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Association for Computing Machinery</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="264" to="285" />
			<date type="published" when="1969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">LexRank: Graph-based Lexical Centrality As Salience in Text Summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Günes</forename><surname>Erkan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><forename type="middle">R</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="page" from="457" to="479" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Annals of discrete mathematics. Elsevier</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Satoru Fujishige</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<pubPlace>Amsterdam, Boston, Paris</pubPlace>
		</imprint>
	</monogr>
	<note>Submodular functions and optimization</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A Scalable Global Model for Summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Gillick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoit</forename><surname>Favre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Integer Linear Programming for Natural Language Processing. Association for Computational Linguistics</title>
		<meeting>the Workshop on Integer Linear Programming for Natural Language Processing. Association for Computational Linguistics<address><addrLine>Boulder, Colorado</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="10" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Exploring Content Models for Multi-document Summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aria</forename><surname>Haghighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucy</forename><surname>Vanderwende</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics<address><addrLine>Boulder, Colorado</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="362" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A Repository of State of the Art and Competitive Baseline Summaries for Generic News Summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Conroy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Benoit Favre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nenkova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC&apos;14)</title>
		<meeting>the Ninth International Conference on Language Resources and Evaluation (LREC&apos;14)<address><addrLine>Reykjavik, Iceland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1608" to="1616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">ROUGE: A Package for Automatic Evaluation of Summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text Summarization Branches Out: Proceedings of the ACL-04</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Association for Computational Linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Workshop</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="74" to="81" />
			<pubPlace>Barcelona, Spain</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A Class of Submodular Functions for Document Summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><forename type="middle">A</forename><surname>Bilmes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics<address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="510" to="520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Automatically Assessing Machine Summary Content Without a Gold Standard</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Annie</forename><surname>Louis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="267" to="300" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The Automatic Creation of Literature Abstracts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans</forename><surname>Peter Luhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Journal of Research Development</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="159" to="165" />
			<date type="published" when="1958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A Study of Global Inference Algorithms in Multi-document Summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th European Conference on IR Research</title>
		<meeting>the 29th European Conference on IR Research<address><addrLine>Rome, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="557" to="564" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Equation of State Calculations by Fast Computing Machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Metropolis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arianna</forename><surname>Rosenbluth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marshall</forename><surname>Rosenbluth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Augusta</forename><surname>Teller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Teller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Chemical Physics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1087" to="1092" />
			<date type="published" when="1953" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The Pyramid Method: Incorporating Human Content Selection Variation in Summarization Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Passonneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><surname>Mckeown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Speech and Language Processing</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>TSLP)</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A General Optimization Framework for MultiDocument Summarization Using Genetic Algorithms and Swarm Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxime</forename><surname>Peyrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judith</forename><surname>Eckle-Kohler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on Computational Linguistics</title>
		<meeting>the 26th International Conference on Computational Linguistics<address><addrLine>Osaka, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="247" to="257" />
		</imprint>
	</monogr>
	<note>The COLING 2016 Organizing Committee</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Theory of Linear and Integer Programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Schrijver</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
			<publisher>John Wiley &amp; Sons, Inc</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Combinatorial Optimization-Polyhedra and Efficiency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Schrijver</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<publisher>Springer</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Mastering the game of Go with deep neural networks and tree search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aja</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Guez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Sifre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Van Den Driessche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Schrittwieser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veda</forename><surname>Panneershelvam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Lanctot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sander</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dominik</forename><surname>Grewe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Nham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Madeleine</forename><surname>Leach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thore Graepel, and Demis Hassabis</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">529</biblScope>
			<biblScope unit="page" from="484" to="489" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Using latent semantic analysis in text summarization and summary evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Steinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karel</forename><surname>Jezek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Conference on Information Systems Implementation and Modelling (ISIM &apos;04)</title>
		<meeting>the 7th International Conference on Information Systems Implementation and Modelling (ISIM &apos;04)<address><addrLine>Rožnov pod Radhoštěm, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="93" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Using Back-Propagation Networks for Guiding the Search of a Theorem Prover</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Suttner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Ertel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Neural Networks Research &amp; Applications</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="16" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
