<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:02+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Topic Modeling based Sentiment Analysis on Social Media for Stock Market Prediction</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Thien</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information Science</orgName>
								<orgName type="institution">Japan Advanced Institute of Science and Technology</orgName>
								<address>
									<addrLine>1-1 Asahidai</addrLine>
									<postCode>923-1292</postCode>
									<settlement>Nomi</settlement>
									<region>Ishikawa</region>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiyoaki</forename><surname>Nguyen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information Science</orgName>
								<orgName type="institution">Japan Advanced Institute of Science and Technology</orgName>
								<address>
									<addrLine>1-1 Asahidai</addrLine>
									<postCode>923-1292</postCode>
									<settlement>Nomi</settlement>
									<region>Ishikawa</region>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shirai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information Science</orgName>
								<orgName type="institution">Japan Advanced Institute of Science and Technology</orgName>
								<address>
									<addrLine>1-1 Asahidai</addrLine>
									<postCode>923-1292</postCode>
									<settlement>Nomi</settlement>
									<region>Ishikawa</region>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Topic Modeling based Sentiment Analysis on Social Media for Stock Market Prediction</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1354" to="1364"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The goal of this research is to build a model to predict stock price movement using sentiments on social media. A new feature which captures topics and their sentiments simultaneously is introduced in the prediction model. In addition, a new topic model TSLDA is proposed to obtain this feature. Our method outperformed a model using only historical prices by about 6.07% in accuracy. Furthermore, when comparing to other sentiment analysis methods, the accuracy of our method was also better than LDA and JST based methods by 6.43% and 6.07%. The results show that incorporation of the sentiment information from social media can help to improve the stock prediction.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Stock price forecasting is very important in the planning of business activity. However, building an accurate stock prediction model is still a chal- lenging problem. In addition to historical prices, the current stock market is affected by the mood of society. The overall social mood with respect to a given company might be one of the important variables which affect the stock price of that com- pany. Nowadays, the emergence of online social networks makes large amounts of mood data avail- able. Therefore, incorporating information from social media with the historical prices can improve the predictive ability of the models.</p><p>The goal of our research is to develop a model to predict a stock price movement using information from social media (Message Board). In our pro- posed method, the model predicts the movement of the stock value at t using features derived from information at t − 1 and t − 2, where t stands for a transaction date. It will be trained by supervised machine learning. Apart from the mood informa- tion, the stock prices are affected by many factors such as microeconomic and macroeconomic fac- tors. However, this research only focuses on how the mood information from social media can be used to predict the stock price movement. That is, the mood of topics in social media is extracted by sentiment analysis. Then, the topics and their sentiments are integrated into the model to pre- dict the stocks. To achieve this goal, discover- ing the topics and sentiments in a large amount of social media is important to get opinions of investors as well as events of companies. How- ever, sentiment analysis on social media is diffi- cult. The text is usually short, contains many mis- spellings, uncommon grammar constructions and so on. In addition, the literature shows conflict- ing results in sentiment analysis for stock market prediction. Some researchers report that the senti- ments from social media have no predictive capa- bilities ( <ref type="bibr" target="#b0">Antweiler and Frank, 2004;</ref><ref type="bibr" target="#b22">Tumarkin and Whitelaw, 2001</ref>), while other researchers have re- ported either weak or strong predictive capabilities <ref type="bibr" target="#b3">(Bollen et al., 2011)</ref>. Therefore, how to use opin- ions in social media for stock price predictions is still an open problem.</p><p>Our contributions are summarized as follows:</p><p>1. We propose a new feature "topic-sentiment" for the stock market prediction model.</p><p>2. We propose a new topic model, Topic Sen- timent Latent Dirichlet Allocation (TSLDA), which can capture the topic and sentiment si- multaneously.</p><p>3. Large scale evaluation. Most of the previous researches are limited on predicting for one stock <ref type="bibr" target="#b3">(Bollen et al., 2011;</ref><ref type="bibr" target="#b16">Qian and Rasheed, 2007;</ref><ref type="bibr" target="#b20">Si et al., 2013)</ref>, and the number of instances (transaction dates) in a test set is rather low such as 14 or 15 instances <ref type="bibr" target="#b3">(Bollen et al., 2011;</ref><ref type="bibr" target="#b23">Vu et al., 2012</ref>). With only a few instances in the test set, the conclusion might be insufficient. This is the first research that shows good prediction results on evaluation of many stocks using a test set consisting of many transaction dates.</p><p>The rest of the paper is organized as follows. Section 2 introduces some previous approaches on sentiment analysis for stock prediction. Section 3 explains our model for sentiment analysis by si- multaneously inferring the topic and sentiment in the text. Section 4 describes two kinds of datasets required for stock prediction. Section 5 describes our prediction models and also proposes a novel feature based on the topics and sentiments. Sec- tion 6 assesses the results of the experiments. Fi- nally, Section 7 concludes our research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Stock market prediction is one of the most at- tracted topics in academic as well as real life busi- ness. Many researches have tried to address the question whether the stock market can be pre- dicted. Some of the researches were based on the random walk theory and the Efficient Market Hypothesis (EMH). According to the EMH ( <ref type="bibr" target="#b4">Fama et al., 1969;</ref><ref type="bibr" target="#b5">Fama, 1991)</ref>, the current stock mar- ket fully reflects all available information. Hence, price changes are merely due to new information or news. Because news in nature happens ran- domly and is unknowable in the present, stock prices should follow a random walk pattern and the best bet for the next price is the current price. Therefore, they are not predictable with more than about 50% accuracy <ref type="bibr" target="#b24">(Walczak, 2001</ref>). On the other hand, various researches specify that the stock market prices do not follow a random walk, and can be predicted in some degree <ref type="bibr" target="#b3">(Bollen et al., 2011;</ref><ref type="bibr" target="#b16">Qian and Rasheed, 2007;</ref><ref type="bibr" target="#b23">Vu et al., 2012</ref>). Degrees of accuracy at 56% hit rate in the pre- dictions are often reported as satisfying results for stock predictions <ref type="bibr" target="#b19">(Schumaker and Chen, 2009b;</ref><ref type="bibr" target="#b20">Si et al., 2013;</ref><ref type="bibr" target="#b21">Tsibouris and Zeidenberg, 1995)</ref>.</p><p>Besides the efficient market hypothesis and the random walk theories, there are two distinct trad- ing philosophies for stock market prediction: fun- damental analysis and technical analysis. The fun- damental analysis studies the company's financial conditions, operations, macroeconomic indicators to predict the stock price. On the other hand, the technical analysis depends on historical and time- series prices. Price moves in trends, and history tends to repeat itself. Some researches have tried to use only historical prices to predict the stock price ( <ref type="bibr" target="#b28">Zuo and Kita, 2012a;</ref><ref type="bibr" target="#b29">Zuo and Kita, 2012b)</ref>. To discover the pattern in the data, they used Bayesian network ( <ref type="bibr" target="#b28">Zuo and Kita, 2012a;</ref><ref type="bibr" target="#b29">Zuo and Kita, 2012b)</ref>, time-series method such as Auto Re- gressive, Moving Average, Auto Regressive Mov- ing Average model ( <ref type="bibr" target="#b28">Zuo and Kita, 2012a</ref>) and so on.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Extracting Opinions from Text</head><p>Sentiment analysis has been found to play a sig- nificant role in many applications such as prod- uct and restaurant reviews ( <ref type="bibr" target="#b10">Liu and Zhang, 2012;</ref><ref type="bibr" target="#b15">Pang and Lee, 2008)</ref>. There are some researches trying to apply sentiment analysis on information sources to improve the stock prediction model. There are two main such sources. In the past, the main source was the news ( <ref type="bibr" target="#b18">Schumaker and Chen, 2009a;</ref><ref type="bibr" target="#b19">Schumaker and Chen, 2009b)</ref>, and in re- cent years, social media sources. A simple ap- proach is combining the sentiments in the textual content with the historical prices through the lin- ear regression model. Most of the previous work primarily used the bag-of-words as text representation that are incor- porated into the prediction model. Schumaker and Chen tried to use different textual representations such as bag-of-words, noun phrases and named entities for financial news <ref type="bibr" target="#b19">(Schumaker and Chen, 2009b)</ref>. However, the textual representations are just the words or named entity tags, not exploit- ing the mood information so much. A novel tree representation based on semantic frame parsers is proposed ( <ref type="bibr" target="#b25">Xie et al., 2013)</ref>. By using stock prices from Yahoo Finance, they annotated all the news in a transaction date with going up or down cate- gories. However, the weakness of this assumption is that all the news in one day will have the same category. In addition, this is a task of text classifi- cation, not stock prediction.</p><p>Naive Bayes was used to classify messages from message boards into three classes: buy, hold and sell <ref type="bibr" target="#b0">(Antweiler and Frank, 2004</ref>). They were integrated into the regression model. However, they concluded that their model does not success- fully predict stock returns.</p><p>A method to measure collective hope and fear on each day and analyze the correlation between these indices and the stock market indicators was proposed <ref type="bibr" target="#b26">(Zhang et al., 2011</ref>). They used the mood words to tag each tweet as fear, worry, hope and so on. They concluded that the ratio of the emotional tweets significantly negatively corre- lated with Down Jones, NASDAQ and S&amp;P 500, but positively with VIX. However, they did not use their model to predict the stock price values.</p><p>Two mood tracking tools, OpinionFinder and Google Profile of Mood States, were used to an- alyze the text content of daily Twitter <ref type="bibr" target="#b3">(Bollen et al., 2011</ref>). The former measures the positive and negative mood. The latter measures the mood in terms of six dimensions (Calm, Alert, Sure, Vital, Kind, and Happy). They used the Self Organizing Fuzzy Neural Network model to predict DJIA val- ues. The results showed 86.7% direction accuracy (up or down) and 1.79% Mean Absolute Percent- age Error. Although they achieved the high accu- racy, there were only 15 transaction dates (from December 1 to <ref type="bibr">19,</ref><ref type="bibr">2008</ref>) in their test set. With such a short period, it might not be sufficient to conclude the effectiveness of their method.</p><p>A keyword-based algorithm was proposed to identify the sentiment of tweets as positive, neu- tral and negative for stock prediction ( <ref type="bibr" target="#b23">Vu et al., 2012)</ref>. Their model achieved around 75% accu- racy. However, their test period was short, from 8 th to 26 th in September 2012, containing only 14 transaction dates.</p><p>Continuous Dirichlet Process Mixture (cDPM) model was used to learn the daily topic set of Twit- ter messages to predict the stock market ( <ref type="bibr" target="#b20">Si et al., 2013)</ref>. A sentiment time series was built based on these topics. However, the time period of their whole dataset is rather short, only three months.</p><p>Most of the researches tried to extract only the opinions or sentiments. However, one important missing thing is that opinions or sentiments are ex- pressed on topics or aspects of companies. There- fore, understanding on which topics of a given stock people are expressing their opinion is very important. Although the models for inferring the topics and sentiments simultaneously have already proposed as discussed in Subsection 2.2, to the best of our knowledge, such models have never applied for stock market prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Aspect based Sentiment Analysis</head><p>Some researches tried to identify the sentiment ex- pressed toward an aspect in a sentence rather than a whole sentence or document. The simple ap- proach is to define a sentiment score of a given as- pect by the weighted sum of opinion scores of all words in the sentence, where the weight is defined by the distance from the aspect ( <ref type="bibr" target="#b10">Liu and Zhang, 2012;</ref><ref type="bibr" target="#b15">Pang and Lee, 2008)</ref>. This method is further improved by identifying the aspect-opinion rela- tions using tree kernel method <ref type="bibr">(Nguyen and Shirai, 2015)</ref>.</p><p>Other researches trying to extract both the topic and sentiment for some domains such as on- line product, restaurant and movie review dataset. ASUM is a model for extracting both the aspect and sentiment for online product review dataset ( <ref type="bibr" target="#b6">Jo and Oh, 2011)</ref>. Joint sentiment/topic model (JST) is another model to detect the sentiment and topic simultaneously, which was applied for movie review dataset ( <ref type="bibr" target="#b9">Lin and He, 2009</ref>). These models assume that each word is generated from a joint topic and sentiment distribution. It means that these models do not distinguish the topic word and opinion word distributions.</p><p>Besides the general opinion words, topic mod- els considering aspect-specific opinion words were also proposed. MaxEnt-LDA hybrid model can jointly discover both aspects and aspect- specific opinion words on a restaurant review dataset ( <ref type="bibr" target="#b27">Zhao et al., 2010)</ref>, while FACTS, CFACTS, FACTS-R, and CFACTS-R model were proposed for sentiment analysis on a product re- view data ( <ref type="bibr" target="#b8">Lakkaraju et al., 2011</ref>). However, one of the weaknesses of these methods is that there is only one opinion word distribution corresponding to one topic (aspect). It makes difficult to know which sentiment (e.g. positive or negative) is ex- pressed by the opinion words on that topic.</p><p>To overcome this drawback, we propose a new topic model called Topic Sentiment Latent Dirich- let Allocation (TSLDA), which estimates differ- ent opinion word distributions for individual sen- timent categories for each topic. To the best of our knowledge, such a model has not been proposed. TSLDA is suitable for not only sentiment analy- sis for stock prediction but also general sentiment analysis of the document, sentence and aspect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">TSLDA: Topic Sentiment Latent Dirichlet Allocation</head><p>The proposed model TSLDA infers the topics and their sentiments simultaneously. It is an extended model of Latent Dirichlet Allocation (LDA) ( <ref type="bibr" target="#b2">Blei et al., 2003)</ref>. We assume that one sentence ex- <ref type="figure">Figure 1</ref>: Graphical Model Representation of TSLDA presses only one topic and one opinion on that topic. The topics are usually nouns, whereas the opinion words are adjectives or adverbs. The words in the document are classified into three cat- egories, the topic word (category c = 1), opinion word (c = 2) and others (c = 0). Then, we sup- pose the different opinion words are used for the different topics. Depending on the topic, an opin- ion word may express different sentiment mean- ing. For example, the opinion word "low" in "low cost" and "low salary" have opposite polarity. In our model, different topics, which are also repre- sented by word distributions, will have different opinion word distributions. Finally, to capture the sentiment meanings such as positive, negative or neutral of the opinion words for each topic, we distinguish opinion word distributions for differ- ent sentiment meanings. <ref type="figure">Figure 1</ref> shows the graphical model representa- tion of TSLDA. Observed and hidden variables are indicated by shaded and clear circles, respectively. <ref type="table" target="#tab_0">Table 1</ref> shows the notations in <ref type="figure">Figure 1</ref>. The gen- eration process in TSLDA is as follows:</p><p>1. Choose a distribution of background words</p><formula xml:id="formula_0">Φ b ∼ Dirichlet(α)</formula><p>2. For each topic k:</p><p>• Choose a distribution of topic words </p><formula xml:id="formula_1">Φ t k ∼ Dirichlet(α) • For each sentiment s of topic k: -Choose a distribution of sentiment words Φ o k,s ∼ Dirichlet(λ)</formula><formula xml:id="formula_2">Φ o distribution over sentiment words D # of documents M d # of sentences in document d N d,m # of words in sentence m in document d θ t d topic distribution for document d θ o d sentiment distribution for document d z t d,m topic assignment for sentence m in document d z o d,m sentiment assignment for sentence m in document d w d,m,n n th word in sentence m in document d c d,m,n</formula><p>n th word's category (background, topic or sentiment) in sentence m in document d</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">For each document d:</head><p>• Choose a topic distribution</p><formula xml:id="formula_3">θ t d ∼ Dirichlet(β) • Choose a sentiment distribution θ o d ∼ Dirichlet(γ) • For each sentence m:</formula><p>-Choose a topic assignment</p><formula xml:id="formula_4">z t d,m ∼ M ultinomial(θ t d ) -Choose a sentiment assignment z o d,m ∼ M ultinomial(θ o d ) -For each word in the sentence:</formula><p>* Choose a word w d,m,n as in Equa- tion (1).</p><formula xml:id="formula_5">w d,m,n ∼      M ultinomial(Φ b ) if c d,m,n = 0 M ultinomial(Φ t z t d,m ) if c d,m,n = 1 M ultinomial(Φ o z t d,m ,z o d,m ) if c d,m,n = 2<label>(1)</label></formula><p>We will define some notations for explanation of our method. W k,s d,m,v,c is the number of times the word v with the category c appears in the sentence m in the document d, where m discusses the topic k and the sentiment s. Let Z k,s d be the number of times the document d has the topic k and the sen- timent s. If any of these dimensions is not limited to a specific value, we used an asterisk * to denote it. For example, W k,s * , * ,v,c is the number of appear- ance of combination (v, c, k, s) in any sentences in any documents. Similarly, Z k, * d is the number of times the document d has the topic k with any sentiments.</p><p>A bold-font variable denotes the list of the vari- ables. For instance, z t and w denote all of topic assignments and words in all documents, respec- tively.</p><p>− , w, c) is calculated by marginalizing out random vari- ables Φ b , Φ t , Φ o , θ t and θ o . Because of the limit of spaces, we only show the final formula of this conditional probability as in Equation (2). Let V d,m be a set of words in the sentence m in the document d. V is a set of all of the words in all documents.</p><note type="other">(d, m) stands for exclusion of the value in the sentence m in the document d. For example, z t −(d,m) denotes all of topic assignment variables z t but z t d,m . Z</note><formula xml:id="formula_6">P (z t d,m = a, z o d,m = b|z t −(d,m) , z o −(d,m) , w, c, ) ∝ (Z a, * −(d,m) d + β[a])(Z * ,b−(d,m) d + γ[b]) × V d,m v=1 W * , * d,m,v,1 j=1 (W a, * −(d,m) * , * ,v,1 + α[v] + j − 1) W * , * d,m, * ,1 j=1 ( V v=1 W a, * −(d,m) * , * ,v,1 + α[v] + j − 1) × V d,m v=1 W * , * d,m,v,2 j=1 (W a,b−(d,m) * , * ,v,2 + λ[v] + j − 1) W * , * d,m, * ,2 j=1 ( V v=1 W a,b−(d,m) * , * ,v,2 + λ[v] + j − 1)<label>(2)</label></formula><p>Multinomial parameters: Finally, samples ob- tained from Collapsed Gibbs Sampling can be used to approximate the multinomial parameter sets. The distributions of topics and sentiments in the document d are estimated as in Equation (3).</p><formula xml:id="formula_7">θ t d [a] = Z a, * d + β[a] K k=1 Z k, * d + β[k] ; θ o d [b] = Z * ,b d + γ[b] S s=1 Z * ,s d + γ[s]<label>(3)</label></formula><p>The background word distribution, topic word distribution of the topic k and sentiment word dis- tribution of the sentiment s for k are estimated in Equation <ref type="formula" target="#formula_8">(4)</ref>, <ref type="formula" target="#formula_9">(5)</ref> and <ref type="formula" target="#formula_10">(6)</ref>, respectively.</p><formula xml:id="formula_8">Φ b [r] = W * , * * , * ,r,0 + α[r] V v=1 W * , * * , * ,v,0 + α[v]<label>(4)</label></formula><formula xml:id="formula_9">Φ t k [r] = W k, * * , * ,v,1 + α[r] V v=1 W k, * * , * ,v,1 + α[v]<label>(5)</label></formula><formula xml:id="formula_10">Φ o k,s [r] = W k,s * , * ,v,2 + λ[r] V v=1 W k,s * , * ,v,2 + λ[v]<label>(6)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Dataset</head><p>Two datasets are used for the development of our stock prediction model. One is the historical price dataset, and the other is the message board dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Historical Price Dataset</head><p>Historical prices are extracted from Yahoo Fi- nance for 5 stocks. The list of the stock quotes and company names is shown in <ref type="table" target="#tab_1">Table 2</ref>. For each transaction date, there are open, high, low, close and adjusted close prices. The adjusted close prices are the close prices which are adjusted for dividends and splits. They are often used for stock market prediction as in other researches <ref type="bibr" target="#b17">(Rechenthin et al., 2013</ref>). Therefore, we chose it as the stock price value for each transaction date.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Message Board Dataset</head><p>To get the mood information of the stocks, we col- lected 5 message boards of the 5 stocks from Ya- hoo Finance Message Board for a period of one year (from July 23, 2012 to July <ref type="bibr">19,</ref><ref type="bibr">2013</ref>). On the message boards, users usually discuss company news, prediction about stock going up or down, facts, comments (usually negative) about specific company executives or company events. The stock market is not opened at the weekend and holiday. To assign the messages to the transaction dates, the messages which were posted from 4 pm of the pre- vious transaction date to 4 pm of the current trans- action date will belong to the current transaction. We choose 4 pm because it is the time of closing transaction. There are 249 transaction dates in the one year period in our dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Stock Prediction Models with Sentiment Analysis</head><p>This paper focuses on prediction of not the stock price but movement of it. That is, our goal is to develop a model that predicts if the stock price goes up or down. Support Vector Machine (SVM) has long been recognized as being able to effi- ciently handle high dimensional data and has been shown to perform well on many tasks such as text classification <ref type="bibr" target="#b7">(Joachims, 1998;</ref><ref type="bibr">Nguyen and Shirai, 2013</ref>). Therefore, we chose SVM with the lin- ear kernel as the prediction model.  <ref type="table" target="#tab_2">Ta- ble 3</ref> summarizes our features used in the model to predict the price movement at the transaction date t. The details of each feature will be explained in the next subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Price Only</head><p>In this method, only historical prices are used to predict the stock movement. The purpose of this method is to investigate whether there are patterns of the price movement in the history of the stock. In addition, it is a baseline for evaluation of the price t−1 , price t−2 LDA-based Method price t−1 , price t−2 , lda i,t , lda i,t−1 JST-based Method price t−1 , price t−2 , jst i,j,t , jst i,j,t−1 TSLDA-based Method price t−1 , price t−2 , tslda i,j,t , tslda i,j,t−1 effectiveness of the sentiment features. Features used for training SVM are price t−1 and price t−2 which are the price movements (up, down) at the transaction dates t − 1, t − 2, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">LDA-based Method</head><p>In this model, we consider each message as a mix- ture of hidden topics. LDA is a generative prob- abilistic model of a corpus 1 . The basic idea is that documents are represented as random mix- tures over latent topics, where each topic is charac- terized by a distribution over words. Hidden topics of LDA are incorporated into the prediction model as follows. First, stop words are removed from the messages, and all the words are lemmatized by Stanford CoreNLP ( <ref type="bibr" target="#b11">Manning et al., 2014</ref>). Topics are inferred by Gibbs Sampling with 1000 itera- tions. Next, the probability of each topic for each message is calculated. For each transaction date t, the probability of each topic is defined as the aver- age of the probabilities of the topic in all messages posted on that transaction date. Features used for training SVM are price t−1 , price t−2 , lda i,t and lda i,t−1 . lda i,t and lda i,t−1 are the probabilities of the topic i (i ∈ {1, · · · , K}) for the transaction dates t and t − 1. The number of the topics K is empirically deter- mined as explained in Subsection 6.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">JST-based Method</head><p>When people post the message on social media to express their opinion for a given stock, they tend to talk their opinions for a given topic or aspect such as profit and dividend. They would think that the future price of the stock goes up or down by seeing pairs of topic-sentiment written by oth- ers. Following the above intuition, we propose a new feature topic-sentiment for the stock predic-   <ref type="bibr" target="#b9">and He, 2009</ref>). The other is TSLDA discussed in Section 3. This subsection introduces the method using the former. We consider each message as a mixture of hid- den topics and sentiments. JST model is used to extract topics and sentiments simultaneously. <ref type="figure" target="#fig_2">Fig- ure 2</ref> shows the graphical model representation of JST. Notations in <ref type="figure" target="#fig_2">Figure 2</ref> are shown in <ref type="table" target="#tab_3">Table 4</ref>. In LDA model, there is only one document specific topic distribution. In contrast, each document in JST is associated with multiple sentiment labels. Each sentiment label is associated with a docu- ment specific topic distribution. A word in the document is drawn from a distribution over words defined by the topic and sentiment label.</p><p>After removal of stop words and lemmatiza- tion, JST model is trained by Gibbs Sampling with 1000 iterations. We chose 3 as the number of sentiments which might represent negative, neu- tral and positive. The number of the topics K is empirically determined as explained in Subsec- tion 6.1. Next, the joint probability of each pair of topic and sentiment is calculated for each mes- sage. For each transaction date t, the joint proba- bility of each topic-sentiment pair is defined as the average of the joint probabilities in the messages on that transaction date. Then we integrate these probabilities into the prediction model.</p><p>Features used for training SVM are price t−1 , price t−2 , jst i,j,t and jst i,j,t−1 . jst i,j,t and jst i,j,t−1 are the joint probabilities of the sen- timent i (i ∈ {1, 2, 3}) and topic j (j ∈ {1, · · · , K}) for the transaction dates t and t − 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">TSLDA-based Method</head><p>We use our TSLDA model to capture the topics and sentiments simultaneously. First, a rule-based algorithm is applied to identify the category of each word in the documents. Consecutive nouns are considered as topic words. If a word is not a noun and in a list of opinion words in SentiWord- Net ( <ref type="bibr" target="#b1">Baccianella et al., 2010)</ref>, it is considered as an opinion word. The rest of words are classified as background words.</p><p>After lemmatization, TSLDA model is trained by Collapsed Gibbs Sampling with 1000 itera- tions. We chose 3 as the number of sentiments which might represent for negative, neutral and positive. K (number of topics) is determined as explained in Subsection 6.1. The topic and its sen- timent in each sentence are gotten from the topic assignment and sentiment assignment in TSLDA. If there is a sentence expressing the sentiment j on the topic i, we represent the tuple (i, j) = 1, and 0 otherwise. The proportion of (i, j) over all sentences are calculated for each message. For each transaction date, a weight of the tuple (i, j) is defined as the average of the proportions over all messages. Then we integrated the weights of the topics and their sentiments into the prediction model.</p><p>Features used for training SVM are price t−1 , price t−2 , tslda i,j,t and tslda i,j,t−1 . tslda i,j,t and tslda i,j,t−1 are the weights of the topic i (i ∈ {1, · · · , K}) with the sentiment j (j ∈ {1, 2, 3}) for the transaction dates t and t − 1. To optimize the number of topics K for each stock, we run the models with four values of K: 10, 20, 50 and 100. The best K is chosen for each stock on the development set, and the systems with the chosen K is evaluated on the test data. The performance of the prediction is measured by ac- curacy.</p><p>For the hyperparameters of LDA, JST and TSLDA, we simply selected symmetric Dirich- let prior vectors, that is all possible distributions are likely equal. We used the default values of these hyperparameters for LDA and JST. Con- cretely speaking, α = 0.5, β = 0.01 in LDA and α = 50 #topics , β = 0.01, γ = 0.3 were used in JST. For TSLDA, we set α = 0.1, λ = 0.1, β = 0.01 and γ = 0.01.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Results</head><p>The result of each stock is shown in <ref type="table" target="#tab_4">Table 5</ref>. In addition, the average of 5 stocks for each model is revealed in the last row of this table for easy com- parison. Our model TSLDA-based method out- performed the other methods on the average of the stocks. <ref type="table" target="#tab_5">Table 6</ref> shows the number of true posi- tive (TP), true negative (TN), false positive (FP) and false negative (FN) of models for the stocks. For easy comparison, the summation for these five stocks are calculated in the last row.</p><p>To assess the effectiveness of integrating mood information, we compare our TSLDA-based method with Price Only method. The results showed that the model using mood information outperformed the model without mood by 3.57%, 3.58%, 14.29% and 12.5% accuracy for XOM, EBAY, IBM and KO stock, respectively. On the other hand, the performance on DELL stock was not improved. It means that the use of the mood does not always make the performance better. The mood from social media could lead to a wrong pre- diction because of wrong prediction of message writers, fault information and so on. However, TSLDA was better than Price Only method on av- erage of these stocks. In addition, TSLDA can re- duce the number of FN, especially for IBM, al- though FP was not changed in the sum of 5 stocks. Thus, we can conclude that integrating the mood information from social media can help to predict stock price movement more precisely. Next, let us compare the models for inferring la- tent topics only (LDA) and topics and sentiments (JST and TSLDA) in the stock movement predic- tion. The accuracy of JST-based method was bet- ter than LDA for two stocks (XOM and IBM), worse for three stocks and comparable in the aver- age of five stocks. While, TSLDA-based method outperformed LDA and JST by 2 to 17% in the accuracy for five stocks. TSLDA was also better  <ref type="table" target="#tab_0">Topic1  Topic2  Topic3  Topic4  Topic5  Topic6  ko  split  drink  customer  company  country  ceo  stock  coke  budget  competitor  tax  company  share  water  campaign  buy  governor  report  price  produce promotion  sell  obama  earning  dividend product  growth  hold  rommey  analyst  year  health  sale  problem  mitt  share  date  juice  volumn  soda  president  news  market  make  come  product  bill  downgrade  time  p.o.s  revenue  people  christian</ref> than LDA and JST on average as shown in <ref type="table" target="#tab_4">Table  5</ref>. The improvement of the accuracy was derived by increase of TP and decrease of FN. These re- sults indicate that (1) our idea to use both latent topics and sentiments as the features is effective, (2) TSLDA is more appropriate model than JST in stock movement prediction. <ref type="table" target="#tab_6">Table 7</ref> shows examples of highly associated words of some topics for stock KO (Coca-Cola Company) in TSLDA. For example, 'split', 'stock' and 'share' are words highly associated with the hidden topic 2, and 'drink', 'coke' and 'water' are highly associated with the topic 3. The first five hidden topics in <ref type="table" target="#tab_6">Table 7</ref> may represent the man- agement, stock market trading, product, customer care service, competitors of the company, while the last one indicates macroeconomic factors. Ta- ble 8 shows examples of highly associated words of three sentiments of the hidden topic 1 and 2. For the hidden topic 1, 'growth', 'strong', 'solid' etc. are the words highly associated with the hidden sentiment 3 (which may corresponds to positive class), while 'old', 'tired', 'unreal' etc. with the hidden sentiment 1 (may be negative). In general, however, it is rather difficult to interpret the mean- ing of the hidden sentiment because the sentiments have many dimensions such as happy, anger, sad, vital and so on. We also found that the words with high probabilities in the background distribu- tion were the stop words, punctuations, function words, messy characters written in social media, e.g. '.', 'the', 'and', 'you', '$', 'for' and '?'. <ref type="table" target="#tab_8">Table 9</ref> shows top words in some joint senti- ment topic distributions of JST model for stock KO. For example, 'yahoo', 'ko' and 'finance' are highly associated with the distribution defined by hidden sentiment 1 and hidden topic 1. However, it is rather difficult to guess which sentiment or topic in this joint distribution actually means.  <ref type="table" target="#tab_0">Topic1  Topic2  S1  S2  S3  S1  S2  S3  old  value  grow  down  straight  good  tired  even  strong  tough  warm  long  unreal  difference  solid  troll  informative more  much  list  gain  breakthrough interesting  high  obviously together  full  ex  later  still  much  serve  continue  sugary  responsible right  not  americans growth  ep  yeah  sure  helpful  operation  value  richly  used  same  here</ref> get quarter major though many </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>This paper presents the method to infer the top- ics and their sentiments on the documents and use them for prediction of the stock movement. The results of the experiments show the effectiveness of our proposed TSLDA-based method. Although 56% accuracy of our method is not so high, it can be satisfying results as regarded in the previous pa- pers. Another advantage of the paper is the eval- uation by the large scale experiment (five stocks, three month transaction dates in the test set). The drawback of TSLDA is that we have to specify the number of topics and sentiment be- forehand. To overcome it, TSLDA should be ex- tended as a non-parametric topic model estimating the number of topics inherent in the data. This will be done in our future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>denotes the value of Z a, * d not counting times at the sentence m in the docu- ment d. We used square brackets for specifying the value at the index of a vector or distribution. For instance, α[v] denotes the value of α at index v. Collapsed Gibbs Sampling was implemented for inference in TSLDA. It will sequentially sam- ple hidden variables z t d,m and z o d,m from the dis- tribution over these variables given the current values of all other hidden and observed vari- ables. In other words, in order to perform Col- lapsed Gibbs Sampling, conditional probability P (z t d,m = a, z o d,m = b|z t −(d,m) , z o −(d,m)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Furthermore, features derived by sentiment analysis on the mes- sage board are incorporated in it. To assess the ef- fectiveness of sentiment analysis, four sets of fea- tures are designed. The first one uses only the his- torical prices. The other sets include topic and sen- timent features obtained by different methods. All the feature values are scaled into [−1, 1] value.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Graphical Model Representation of JST</figDesc><graphic url="image-2.png" coords="7,72.00,62.81,218.40,159.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 : Notations in TSLDA</head><label>1</label><figDesc></figDesc><table>Notation Definition 
α, β, γ, λ Dirichlet prior vectors 
K 
# of topics 
S 
# of sentiments 
Φ b 
distribution over background words 
Φ t 
distribution over topic words 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 : Statistics of Our Dataset</head><label>2</label><figDesc></figDesc><table>Stocks 
Company Names #Documents 
XOM Exxon Mobil Corporation 
11027 
DELL 
Dell Inc. 
10339 
EBAY 
eBay Inc. 
7168 

IBM 
International Business 
5008 
Machines Corporation 
KO The Coca-Cola Company 
2024 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 : Features of the Prediction Model Method Features Price Only</head><label>3</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 4 : Notations in JST</head><label>4</label><figDesc></figDesc><table>Notation Definition 
α, β, γ 
Dirichlet prior vectors 
ϕ 
distribution over words 
T 
# of topics 
S 
# of sentiments 
θ 
message and sentiment specific topic 
distribution 
z 
topic 
w 
word in the message d 
l 
sentiment label 
π 
message specific sentiment distribution 
N d 
# of words in the message d 
D 
# of messages 

tion model. Two methods are used to extract the 
pairs of topic-sentiment from the message board. 
One is a latent topic based model called JST (Lin 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 5 : Accuracies of Stock Movement Predic- tion</head><label>5</label><figDesc></figDesc><table>Stocks Price Only 
LDA 
JST TSLDA 
XOM 
0.5000 0.4464 0.5179 
0.5357 
DELL 
0.5893 0.5357 0.5000 
0.5536 
EBAY 
0.6071 0.6071 0.5000 
0.6429 
IBM 
0.4107 0.3929 0.5357 
0.5536 
KO 
0.4107 0.5179 0.4643 
0.5357 
Average 
0.5036 0.5000 0.5036 
0.5643 

6 Evaluation 

6.1 Experiment Setup 

We divided the dataset described in Section 4 into 
three parts: training set from July 23, 2012 to 
March 31, 2013, development set from April 01, 
2013 to April 30, 2013, and test set from May 
01, 2013 to July 19, 2013. The label of 'up' 
and 'down' is assigned to each transaction date by 
comparing the price of the current and previous 
dates. 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 6 : TP, TN, FP, FN of Stock Movement Pre- diction Stocks Metrics Price Only LDA JST TSLDA</head><label>6</label><figDesc></figDesc><table>XOM 

TP 
14 
13 
15 
18 
TN 
14 
12 
14 
12 
FP 
8 
10 
8 
10 
FN 
20 
21 
19 
16 

DELL 

TP 
17 
13 
5 
13 
TN 
16 
17 
23 
18 
FP 
17 
16 
10 
15 
FN 
6 
10 
18 
10 

EBAY 

TP 
17 
18 
20 
20 
TN 
17 
16 
8 
16 
FP 
9 
10 
18 
10 
FN 
13 
12 
10 
10 

IBM 

TP 
15 
15 
7 
31 
TN 
8 
7 
23 
0 
FP 
17 
18 
2 
25 
FN 
16 
16 
24 
0 

KO 

TP 
12 
14 
16 
10 
TN 
11 
15 
10 
20 
FP 
17 
13 
18 
8 
FN 
16 
14 
12 
18 

Sum 

TP 
75 
73 
63 
92 
TN 
66 
67 
78 
66 
FP 
68 
67 
56 
68 
FN 
71 
73 
83 
54 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 7 : Top Words in Topics of TSLDA</head><label>7</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 8 : Top Words in Sentiments of Topics of TSLDA</head><label>8</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 9 :</head><label>9</label><figDesc></figDesc><table>Top Words in Distributions Defined by 
Sentiments and Topics of JST 

S1 
S2 
S3 
Topic1 
Topic2 Topic1 
Topic2 
Topic1 Topic2 
yahoo 
juice 
ko 
new 
spam 
split 
ko 
minute 
buy 
american 
board 
share 
finance 
maid 
get 
country 
post 
date 
chart 
orange 
sell 
obama 
ignore 
stock 
free 
apple 
go 
top 
idiot 
record 
fire 
drink 
make 
fall 
get 
price 
website 
fruit 
money 
health 
read 
august 
aone 
edit 
much government another receive 
download punch 
next 
place 
report 
get 

</table></figure>

			<note place="foot" n="1"> We used the LDA implementation from the Mallet library.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Is all that talk just noise? the information content of internet stock message boards</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Werner</forename><surname>Antweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Finance</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1259" to="1294" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Sentiwordnet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Baccianella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Esuli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabrizio</forename><surname>Sebastiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Conference on International Language Resources and Evaluation (LREC&apos;10)</title>
		<meeting>the Seventh Conference on International Language Resources and Evaluation (LREC&apos;10)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="2200" to="2204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Latent dirichlet allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Twitter mood predicts the stock market</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Bollen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huina</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Science</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The adjustment of stock prices to new information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Eugene F Fama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Michael C Jensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Roll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International economic review</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="1969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Efficient capital markets: Ii. The journal of finance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Eugene F Fama</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="1575" to="1617" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Aspect and sentiment unification model for online review analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yohan</forename><surname>Jo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alice</forename><forename type="middle">H</forename><surname>Oh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fourth ACM international conference on Web search and data mining</title>
		<meeting>the fourth ACM international conference on Web search and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="815" to="824" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Text categorization with support vector machines: Learning with many relevant features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><forename type="middle">Joachims</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Exploiting coherence for the simultaneous discovery of latent facets and associated sentiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Himabindu</forename><surname>Lakkaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiranjib</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Indrajit</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srujana</forename><surname>Merugu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh SIAM International Conference on Data Mining, SDM 2011</title>
		<meeting>the Eleventh SIAM International Conference on Data Mining, SDM 2011<address><addrLine>Mesa, Arizona, USA</addrLine></address></meeting>
		<imprint>
			<publisher>SIAM / Omnipress</publisher>
			<date type="published" when="2011-04-28" />
			<biblScope unit="page" from="498" to="509" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Joint sentiment/topic model for sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenghua</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th ACM conference on Information and knowledge management</title>
		<meeting>the 18th ACM conference on Information and knowledge management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="375" to="384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A survey of opinion mining and sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mining Text Data</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="415" to="463" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 52nd</title>
		<meeting>52nd</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<title level="m">Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<imprint>
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Text classification of technical papers based on text segmentation</title>
	</analytic>
	<monogr>
		<title level="m">Elisabeth Mtais, Farid Meziane, Mohamad Saraee, Vijayan Sugumaran, and Sunil Vadera</title>
		<editor>Thien Hai Nguyen and Kiyoaki Shirai</editor>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">7934</biblScope>
			<biblScope unit="page" from="278" to="284" />
		</imprint>
	</monogr>
	<note>Natural Language Processing and Information Systems</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Aspectbased sentiment analysis using tree kernel based relation extraction</title>
	</analytic>
	<monogr>
		<title level="m">Computational Linguistics and Intelligent Text Processing</title>
		<editor>Alexander Gelbukh</editor>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">9042</biblScope>
			<biblScope unit="page" from="114" to="125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Opinion mining and sentiment analysis. Foundations and trends in information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Stock market prediction with multiple classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khaled</forename><surname>Rasheed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Intelligence</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="25" to="33" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Stock chatter: Using stock sentiment to predict price direction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">, W Nick</forename><surname>Michael Rechenthin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Padmini</forename><surname>Street</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Srinivasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Algorithmic Finance</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="169" to="196" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A quantitative stock prediction system based on financial news</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsinchun</forename><surname>Schumaker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="571" to="583" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Textual analysis of stock market prediction using breaking financial news: The azfin text system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsinchun</forename><surname>Schumaker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
		<idno>12:1-12:19</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2009-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Exploiting topic based twitter sentiment for stock prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huayi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaotie</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, ACL</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics, ACL<address><addrLine>Sofia, Bulgaria; Short Papers</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-08-09" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="24" to="29" />
		</imprint>
		<respStmt>
			<orgName>The Association for Computer Linguistics</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Testing the efficient markets hypothesis with gradient descent algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Tsibouris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Zeidenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Networks in the Capital Markets</title>
		<imprint>
			<publisher>Chichester</publisher>
			<date type="published" when="1995" />
			<biblScope unit="page" from="127" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">News or noise? internet postings and stock prices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Tumarkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Robert F Whitelaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Financial Analysts Journal</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="41" to="51" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">An experiment in integrating sentiment features for tech stock prediction in twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tien</forename><forename type="middle">Thanh</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quang</forename><forename type="middle">Thuy</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nigel</forename><surname>Collier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">24th International Conference on Computational Linguistics</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="23" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">An empirical analysis of data requirements for financial forecasting with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Walczak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of management information systems</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="203" to="222" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Semantic frames to predict stock price movement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><forename type="middle">J</forename><surname>Passonneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Germán</forename><surname>Creamer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="873" to="883" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Predicting stock market indicators through twitter &quot;I hope it is not as bad as I fear</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hauke</forename><surname>Fuehres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter A</forename><surname>Gloor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Procedia-Social and Behavioral Sciences</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">0</biblScope>
			<biblScope unit="page" from="55" to="62" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Jointly modeling aspects and opinions with a maxent-lda hybrid</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Wayne Xin Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongfei</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2010 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="56" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Stock price forecast using bayesian network. Expert Systems with Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eisuke</forename><surname>Kita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">An International Journal</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="6729" to="6737" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Up/down analysis of stock index by using bayesian network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eisuke</forename><surname>Kita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Engineering Management Research</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="46" to="52" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
