<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:03+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Cross-Lingual Lexico-Semantic Transfer in Language Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekaterina</forename><surname>Kochmar</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Laboratory</orgName>
								<orgName type="institution" key="instit1">The ALTA Institute University of Cambridge</orgName>
								<orgName type="institution" key="instit2">University of Cambridge</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekaterina</forename><surname>Shutova</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Laboratory</orgName>
								<orgName type="institution" key="instit1">The ALTA Institute University of Cambridge</orgName>
								<orgName type="institution" key="instit2">University of Cambridge</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Cross-Lingual Lexico-Semantic Transfer in Language Learning</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="974" to="983"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Lexico-semantic knowledge of our native language provides an initial foundation for second language learning. In this paper, we investigate whether and to what extent the lexico-semantic models of the native language (L1) are transferred to the second language (L2). Specifically, we focus on the problem of lexical choice and investigate it in the context of three typolog-ically diverse languages: Russian, Span-ish and English. We show that a statistical semantic model learned from L1 data improves automatic error detection in L2 for the speakers of the respective L1. Finally, we investigate whether the semantic model learned from a particular L1 is portable to other, typologically related languages.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Lexico-semantic knowledge of our native lan- guage is one of the factors that underlie our ability to communicate and reason about the world. It is also the knowledge that guides us in the process of second language learning. Lexico-semantic vari- ation across languages ( <ref type="bibr" target="#b0">Bach and Chao, 2008)</ref> makes lexical choice a challenging task for sec- ond language learners <ref type="bibr" target="#b26">(Odlin, 1989)</ref>. For instance, the meaning of the English expression pull the trigger is realised as *push the trigger in Russian and Spanish, possibly leading to errors of lexical choice by Russian and Spanish speakers learning English. Our native language (L1) plays an essen- tial role in the process of lexical choice. When choosing between several linguistic realisations in L2, non-native speakers may rely on the lexico- semantic information from L1 and select a trans- lational equivalent that they deem to match their communicative intent best. For example, Russian speakers *do exceptions and offers instead of mak- ing them, and *find decisions instead of finding so- lutions, since in Russian do and make have a sin- gle translational equivalent (delat'), and so do de- cision and solution (resheniye). As a result, non- native speakers who tend to fall back to their L1 translate phrases word-for-word, violating English lexico-semantic conventions.</p><p>The effect of L1 interference on lexical choice in L2 has been pointed out in a number of stud- ies ( <ref type="bibr">Chang et al., 2008;</ref><ref type="bibr" target="#b29">Rozovskaya, 2010;</ref><ref type="bibr" target="#b30">Rozovskaya, 2011;</ref><ref type="bibr" target="#b7">Dahlmeier and Ng, 2011</ref>). Some of these studies also demonstrated that using L1- specific properties, such as the error patterns of speakers of a given L1 or L1-induced paraphrases, improves the performance of automatic error cor- rection in non-native writing. However, neither of the approaches has constructed a semantic model from L1 data and systematically studied the effects of its transfer onto L2. In addition, most previous work has focused on error correction, bypassing the task of error detection for lexical choice. Lex- ical choice is one of the most challenging tasks for both non-native speakers and automated error detection and correction (EDC) systems. The re- sults of the most recent shared task on EDC, which spanned all error types including lexical choice, show that most teams either did not propose any algorithms for this type of errors or did not per- form well on them <ref type="bibr" target="#b22">(Ng, 2014)</ref>.</p><p>In this paper, we experimentally investigate the influence of L1 on lexical choice in L2 and whether lexico-semantic models from L1 are transferred to L2 during language learning. For this purpose, we induce L1 and L2 semantic mod- els from corpus statistics in each language in- dependently, and then use the discrepancies be- tween the two models to identify errors of lexi- cal choice. We focus on two types of verb-noun combinations, VERB-DIRECT OBJECT (dobj) and SUBJECT-VERB (subj), and consider two widely spoken L1s from different language families - Russian and Spanish. We conduct our experiments using the Cambridge Learner Corpus <ref type="bibr" target="#b24">(Nicholls, 2003)</ref>, containing writing samples of non-native speakers of English. Spanish speakers account for around 24.6% of the non-native speakers repre- sented in this corpus and Russian speakers for 4%.</p><p>Our experiments test two hypotheses: (1) that L1 effects in the lexical choice in L2 reveal them- selves in the difference of the word association strength in the L1 and L2; and (2) that L1 lexico- semantic models are portable to other, typologi- cally related languages. To the best of our knowl- edge, our paper is the first one to experimentally investigate these questions. Our results demon- strate that L1-induced information improves auto- matic error detection for lexical choice, confirm- ing the hypothesis that L1 speakers rely on se- mantic knowledge from their native language dur- ing L2 learning. We test the second hypothesis by verifying that Russian speakers exhibit similar trends in errors with the speakers of other Slavic languages, and Spanish speakers with the speakers of other Romance languages. We find that the L1- induced information from Russian and Spanish is effective in assessing lexical choice of the speak- ers of other languages for both language groups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work 2.1 Error detection in content words</head><p>Early approaches to collocation error detection re- lied on manually created databases of correct and incorrect word combinations <ref type="bibr" target="#b33">(Shei and Pain, 2000;</ref><ref type="bibr" target="#b35">Wible et al., 2003;</ref><ref type="bibr">Chang et al., 2008)</ref>. Con- structing such databases is expensive and time- consuming, and therefore, more recent research turned to the use of machine learning techniques. <ref type="bibr" target="#b12">Leacock et al. (2014)</ref> note that most approaches to detection and correction of collocation errors compare the writer's word choice to the set of al- ternatives using association strength measures and choose the combination with the highest score, re- porting an error if this combination does not coin- cide with the original choice ( <ref type="bibr">Futagi et al., 2008;</ref><ref type="bibr" target="#b27">Â¨ Ostling and Knutsson, 2009;</ref><ref type="bibr" target="#b13">Liu et al., 2009)</ref>. This strategy is expensive as it relies on compar- ison with a set of alternatives, limited in capac- ity as it depends on the quality of the alternatives generated and circular as the detection cannot be performed independently of the correction. Our approach alleviates these problems, since error de- tection depends on the original combination only.</p><p>Some previous approaches focused on correc- tion only <ref type="bibr" target="#b7">(Dahlmeier and Ng, 2011;</ref><ref type="bibr" target="#b11">Kochmar and Briscoe, 2015)</ref>, and although they show promising results, they have not attempted to per- form error detection in lexical choice. <ref type="bibr" target="#b10">Kochmar and Briscoe (2014)</ref> focus on error detection, but their system addresses adjective-noun combina- tions and does not use L1-induced information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">L1 factors in L2 writing</head><p>The influence of an L1 on lexical choice in L2 and the resulting errors have been previously stud- ied ( <ref type="bibr">Chang et al., 2008;</ref><ref type="bibr" target="#b27">Â¨ Ostling and Knutsson, 2009;</ref><ref type="bibr" target="#b7">Dahlmeier and Ng, 2011</ref>). These works fo- cus on errors in particular L1s and use the trans- lational equivalents directly to improve candidate selection and quality of corrections. <ref type="bibr" target="#b7">Dahlmeier and Ng (2011)</ref> show that L1-induced paraphrases outperform approaches based on edit distance, ho- mophones, and WordNet synonyms in selecting the appropriate corrections. <ref type="bibr" target="#b29">Rozovskaya and Roth (2010)</ref> show that an error correction system for prepositions benefits from restricting the set of possible corrections to those observed in the non-native data. <ref type="bibr" target="#b30">Rozovskaya and Roth (2011)</ref> further demonstrate that the models perform better when they use knowledge about er- ror patterns of the non-native writers. According to their results, an error correction algorithm that relies on a set of priors dependent on the writer's preposition and the writer's L1 outperforms other methods. <ref type="bibr">Madnani et al. (2008)</ref> show promising results in whole-sentence grammatical error cor- rection using round-trip translations from Google Translate via 8 different pivot languages.</p><p>The results of these studies suggest that L1 is a valuable source of information in EDC. However, all these works use isolated translational equiva- lents and focus on error correction only. In con- trast, we construct holistic semantic models of L1 from L1 corpora and use these models to perform the more challenging task of error detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">L1 Data</head><p>Spanish data The Spanish data was extracted from the Spanish Gigaword corpus <ref type="bibr" target="#b15">(Mendonca et al., 2011</ref>), a one billion-word collection of news articles in Spanish. The corpus was parsed using the Spanish Malt parser ( <ref type="bibr" target="#b25">Nivre et al., 2007;</ref><ref type="bibr" target="#b2">Ballesteros et al., 2010)</ref>. We extracted VERB-SUBJECT and VERB-DIRECT OBJECT relations from the output of the parser, which we then used to build an L1 word association model for Spanish.</p><p>Russian data The Russian data was extracted from the RU-WaC corpus <ref type="bibr" target="#b31">(Sharoff, 2006</ref>), a two billion-word representative collection of texts from the Russian Web. The corpus was parsed us- ing Malt dependency parser for Russian ( <ref type="bibr" target="#b32">Sharoff and Nivre, 2011)</ref>, and the VERB-SUBJECT and VERB-DIRECT OBJECT relations were extracted from the parser output to create an L1 word as- sociation model for Russian.</p><p>Dictionaries and translation Once the L1 word associations have been computed for the verb- noun pairs, we identify possible translations for verbs and nouns (in each pair) in isolation, as a language learner might do. To create the trans- lation dictionaries, we extracted translations from the English-Spanish and English-Russian edi- tions of Wiktionary, both from the translation sec- tions and the gloss sections if the latter contained single words as glosses. We focus on verb-noun pairs, therefore multi-word expressions were uni- versally removed. We added inverse translations for every original translation. We then created separate translation dictionaries for each language and part-of-speech tag combination from the re- sulting collection of translations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">L2 data</head><p>To build the English word association model, we have used a combination of the British National Corpus <ref type="bibr" target="#b5">(Burnard, 2007)</ref> and the UKWaC ( <ref type="bibr" target="#b3">Baroni et al., 2009</ref>). The corpora were parsed by the RASP parser ( <ref type="bibr" target="#b4">Briscoe et al., 2006</ref>) and VERB- SUBJECT and VERB-DIRECT OBJECT relations were extracted from the parser output. Since the UKWaC is a Web corpus, we assume that the data contains a certain amount of noise, e.g. typograph- ical errors, slang and non-words. We filter these out by checking that the verbs and nouns in the ex- tracted relations are included in WordNet <ref type="bibr" target="#b18">(Miller, 1995)</ref> with the appropriate part of speech.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Learner data</head><p>To extract the verb-noun combinations that have been used by non-native speakers in practice, we use the Cambridge Learner Corpus (CLC), which is a 52.5 million-word corpus of learner En- glish collected by Cambridge University Press and Cambridge English Language Assessment since 1993 <ref type="bibr" target="#b24">(Nicholls, 2003)</ref>. It comprises English ex- amination scripts written by learners of English with 148 different L1s, ranging across multiple examinations and covering all levels of language proficiency. A 25.5 million-word component of the CLC has been manually error-annotated.</p><p>We have preprocessed the CLC with the RASP parser ( <ref type="bibr" target="#b4">Briscoe et al., 2006</ref>), as it is robust when applied to ungrammatical sentences. We have then extracted all dobj and subj combinations: in total, we have extracted 187, 109 dobj and 225, 716 subj combinations. We have used the CLC error anno- tation to split the data into correct combinations and errors. We note that some verb-noun com- binations are annotated both as being correct and as errors, depending on their wider context of use. To ensure that the annotation we use in our exper- iments is reliable and not context-dependent, we have empirically set a threshold to filter out am- biguously annotated instances. The set of correct word combinations includes only those word pairs that are used correctly in at least 70% of the cases they occur in the CLC; the set of errors includes only those that are used incorrectly at least 70% of the time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Experimental datasets</head><p>We split the annotated CLC data by language and relation type. <ref type="table" target="#tab_1">Table 1</ref> presents the statistics on the datasets collected. <ref type="bibr">1</ref> We extract the verb-noun combinations from the CLC texts written by native speakers of Russian (RU) and Spanish (ES) to test our first hypothesis, as well as by speakers of ALL L1s in the CLC to test our second hypothesis. We then filter the extracted relations using the trans- lated verb-noun pairs from Russian and Spanish corpora.</p><p>We note that Russian and Spanish have compa- rable number of word combinations in L1-specific subsets -10K-12K for dobj and subj combina- tions -and comparable error rates (ERR). We also note that the error rates in the dobj sub-  sets are higher than in subj subsets, presumably, because VERB-SUBJECT combinations allow for more flexibility in lexical choice. We find a large number of translated word combinations in other L1s, and it is interesting to note that the error rates are higher across multiple languages than in the same L1s, which corroborates our second hy- pothesis that the lexico-semantic models from L1s transfer to L2. The last two columns of <ref type="table" target="#tab_1">Table  1</ref> show how diverse our datasets are in terms of verbs and nouns used in the constructions: for ex- ample, RU dobj subset contains combinations with 786 different verbs and 1, 918 different nouns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Methods</head><p>Our approach to detecting lexico-semantic trans- fer errors relies on the intuition that a mismatch between the lexico-semantic models in two lan- guages reveals itself in the difference in word as- sociation scores. We argue that a high association score of a verb-noun combination in L1 shows that it is a collocation in L1, but low association score of its translational equivalent in L2 signals an error in L2 stemming from the lexico-semantic transfer. Following previous research <ref type="bibr" target="#b1">(Baldwin and Kim, 2010)</ref>, we measure the strength of verb- noun association using pointwise mutual informa- tion (PMI). <ref type="figure" target="#fig_0">Figure 1</ref> illustrates this intuition. In Russian, both *find decision vs. find solution have a high PMI score. However, in English the latter has a high PMI while the former has a negative PMI. We expect such a discrepancy in word asso- ciation to be an indicator of error of lexical choice, driven by the L1 semantics.</p><p>We treat the task of lexico-semantic transfer er- ror detection as a binary classification problem and train a classifier for this task. The classifier uses a combination of L1 and L2 semantic features. If our hypothesis holds, we expect to see an improve- ment in the classifier's performance when adding L1 semantic features. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">L2 lexico-semantic features</head><p>We experiment with two types of L2 features: lexico-semantic features and semantic vector space features.</p><p>Lexico-semantic features include:</p><p>â¢ pmi in L2: we estimate the association strength between the noun and verb using the combined BNC and UKWaC corpus;</p><p>â¢ verb and noun: the identity of the verb and the noun in the pair, encoded in a numerical form in the range of (0, 1). The motivation behind that step is that certain words are more error-prone than others and converting them into numerical features helps the classifier to use this information.</p><p>Semantic vector space features <ref type="bibr" target="#b10">Kochmar and Briscoe (2014)</ref> obtained state-of-the-art results in error detection by using the semantic component of the content word combinations. We reimple- ment these features and test their impact on our task. We extracted the noun and verb vectors from the publicly available word2vec dataset of word embeddings for 3 million words and phrases. <ref type="bibr">2</ref> The 300-dimensional vectors have been trained on a part of Google News dataset (about 100 billion words) using word2vec ( ). The dobj and subj vectors are then built using element-wise addition on the vectors ( <ref type="bibr" target="#b19">Mitchell and Lapata, 2008;</ref><ref type="bibr" target="#b10">Kochmar and Briscoe, 2014</ref>).</p><p>Once the compositional vectors are created, the method relies on the idea that correct combina- tions can be distinguished from the erroneous ones by certain vector properties <ref type="bibr" target="#b34">(Vecchi et al., 2011;</ref><ref type="bibr" target="#b10">Kochmar and Briscoe, 2014</ref>). We implement a set of numerical features based on the following prop- erties of the vectors:</p><p>â¢ length of the additive (vn) vector</p><p>â¢ cos vnâ§n -cosine between the vn vector and the noun vector</p><p>â¢ cos vnâ§v -cosine between the vn vector and the verb vector</p><p>â¢ dist 10 -distance to the 10 nearest neigh- bours of the vn vector</p><p>â¢ lex-overlap -proportion of the 10 near- est neighbours of the vn vector containing the verb/noun</p><p>â¢ comp-overlap -overlap between the 10 neighbours of the vn vector and 10 neigh- bours of the verb/noun vector</p><p>â¢ cos vâ§n -cosine between the verb and the noun vectors.</p><p>The 10 nearest neighbours are retrieved in the combined semantic space containing word embed- dings and additive phrase vectors. All features, ex- cept for the last one, have been introduced in pre- vious work and showed promising results <ref type="bibr" target="#b34">(Vecchi et al., 2011;</ref><ref type="bibr" target="#b10">Kochmar and Briscoe, 2014</ref>). For ex- ample, it has been shown that the distance from the constructed word combination vector to its nearest neighbours is one of the discriminative features of the error detection classifier. Manual inspection of the vectors and nearest neighbours shows that the closest neighbour to *find decision is see decision with the similarity of 0.8735 while the closest one to find solution is discover solution with the simi- larity of 0.9048.</p><p>We implement an additional cos vâ§n feature based on the intuition that the distance between the verb and noun vectors themselves may indicate a semantic mismatch and thus help in detecting lex- ical choice errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">L1 lexico-semantic features</head><p>We first quantified the strength of association be- tween the L1 verbs and nouns in the original L1 data, using PMI. We then generated a set of possi- ble translations for each verb-noun pair in L1 us- ing the translation dictionaries. Each verb-noun pair in the CLC was then mapped to one of the translated L1 pairs and its L1 features. We used the following L1 features in classification:</p><p>â¢ pmi in L1: we estimate the strength of asso- ciation on the original L1 corpora;</p><p>â¢ difference between the PMI of the verb- noun pair in L1 and in L2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Classification</head><p>Classifier settings We treat the task as a binary classification problem and apply a linear SVM classifier using scikit-learn LinearSVC implementation. <ref type="bibr">3</ref> The error rates in <ref type="table" target="#tab_1">Table 1</ref> show that we are dealing with a two-class problem where one class (correct word combinations) sig- nificantly outnumbers the other class (errors) by up to 11:1 (on RU subj ). To address the problem of class imbalance, we use subsampling: we ran- domly split the set of correct word combinations in n samples keeping the majority class baseline under 0.60, and run n experiments over the sam- ples. We apply 10-fold cross-validation within each sample. The results reported in the follow- ing sections are averaged across the samples for each dataset.</p><p>Evaluation The goal of the classifier is to detect errors, therefore we primarily focus on its perfor- mance on the error class and, in addition to ac- curacy, report precision (P), recall (R) and F 1 on this class. Previous studies <ref type="bibr" target="#b21">(Nagata and Nakatani, 2010)</ref> suggest that systems with high precision in detecting errors are more helpful for L2 learning than systems with high recall as non-native speak- ers find misidentified errors very misleading. In line with this research, we focus on maximising precision on the error class.</p><p>Baseline We compare the performance of our different feature sets to the baseline classifier which uses L2 co-occurrence frequency of the verb and noun in the pair as a single feature. Fre- quency sets a competitive baseline as it is often judged to be the measure of acceptability of an ex- pression and many previous works relied on the frequency of occurrence as an evidence of accept- ability <ref type="bibr" target="#b33">(Shei and Pain, 2000;</ref><ref type="bibr">Futagi et al., 2008</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Results</head><p>To test our hypothesis that lexico-semantic mod- els are transferred from L1 to L2, we first run the set of experiments on the L1 subsets of the CLC data, that is RU â RU CLC and ES â ES CLC , where the left-hand side of the notation denotes the lexico-semantic model and the right-hand side the L1 of the speakers that produced the word pairs extracted from the CLC. We incrementally add the features, starting with the set of lexico-semantic  features in L2 that are readily available without reference to the L1, and later adding L1 semantic features, and measure their contribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">L2 lexico-semantic features</head><p>The first system configuration we experiment with uses the set of lexico-semantic features from L2. <ref type="table" target="#tab_3">Table 2</ref> reports the results. Our experiments show that a classifier that uses L2 PMI (pmi En ) as a single feature performs with relatively high accu- racy: on all four datasets it outperforms the base- line classifier achieving an increase from 7.54% (on ES dobj ) up to 14.77% (on ES subj ) in accuracy.</p><p>Adding the noun as a feature decreases perfor- mance of the classifier and we do not further use this feature. The verb used as an additional fea- ture consistently improves classifier performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">L2 semantic vector space features</head><p>Next, we test the combination of the semantic vec- tor space features (sem) and combine them with two L2 lexico-semantic features including pmi En and verb (denoted as ft En hereafter for brevity). <ref type="table" target="#tab_5">Table 3</ref> reports the results.</p><p>We note that the semantic vector space features on their own yield precision of 50% â 52% on the error class in dobj combinations and lower than 50% on subj combinations. This suggests that the classifier misidentifies correct combinations as er- rors more frequently than it correctly detects er- rors. Moreover, recall of this system configura- tion is also low on all datasets. Adding the seman- tic vector space features to the other L2 semantic features, however, improves the performance, as shown in <ref type="table" target="#tab_5">Table 3</ref>. As both groups of features refer to the phenomena in L2, the results suggest that they complement each other.    <ref type="table">Table 4</ref>: System performance (in %) using L1 and L2 lexico-semantic features, L1 â L1 CLC .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">L1 lexico-semantic features</head><p>Finally, we add the L1 lexico-semantic features to the well-performing L2 features (pmi and verb).</p><p>The combination of L1 lexico-semantic features with the L2 lexico-semantic and semantic vec- tor space features achieves lower results, there- fore we do not report them here. The use of L1 pmi improves both the accuracy and the F-score of the error class (see <ref type="table">Table 4</ref>). For the ease of comparison, we also include the results obtained using a combination of L1 lexico-semantic fea- tures (denoted ft En ). The addition of the explicit difference feature between the two PMIs has not yielded further improvement. This is likely to be due to the fact that the classifier already implic- itly captures the knowledge of this difference in the form of individual L1 and L2 PMIs. We note that the system using a combination of L1 and L2 lexico-semantic features gains an ab- solute improvement in accuracy from 1.04% for RU subj to 2.55% on ES dobj . The performance on the error class improves in all but one case (P e on RU dobj ), with an absolute increase in F 1 up to 7.66%. The system has both a higher coverage in error detection (a rise in recall) and a higher pre- cision. The improvement in performance across all four datasets is statistically significant at 0.05 level. These results demonstrate the effect of lexico-semantic model transfer from L1 to L2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Effect on different L1s</head><p>Next, we test our second hypothesis that a lexico- semantic model from one L1 is portable across several L1s, in particular, typologically related ones. We first experiment with the data repre- senting all L1s in the CLC and then with the data representing a specific language group. We com- pare the performance of the baseline system us- ing verb-noun co-occurrence frequency as a single feature, the system that uses L2 semantic features only and the system that combines both L2 and L1 semantic features. <ref type="table" target="#tab_1">Table 1</ref> shows that using the translated verb-noun combinations from our L1s (RU and ES) we are able to find a large amount of both correct and er- roneous combinations in different L1s in the CLC including RU and ES (see ALL). This gives us an initial confirmation that the lexico-semantic mod- els may be shared across multiple languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Experiments on all L1s</head><p>We then experiment with error detection across all L1s represented in the CLC. The results are shown in <ref type="table">Table 5</ref>. The baseline system achieves similar performance on RU â ALL CLC as on RU â RU CLC , and better performance on ES â ALL CLC than on ES â ES CLC . The results ob- tained with the L2 lexico-semantic features are also comparable: the system achieves an absolute increase in accuracy of up to 9.86% for the model transferred from RU subj , reaching an accuracy of around 65 â 66% with balanced performance in terms of precision and recall on errors.</p><p>When the L1 lexico-semantic features are added to the model, we observe an absolute increase in the accuracy ranging from 0.57% (for RU subj ) to 1.43% (for ES dobj ). The Spanish lexico-semantic model has a higher positive effect on all measures, including precision on the error class. Although the addition of the L1 lexico-semantic features does not have a significant effect on the accuracy and precision, the system achieves an absolute im- provement in recall of up to 12.71% (on RU dobj ). That is, the system that uses L1 lexico-semantic features is able to find more errors in the data orig- inating with a set of different L1s. Generally, the results of the Spanish model are more stable and comparable to the results in the previous Section, which may be explained by the fact that Spanish is more well-represented in the CLC.   <ref type="table">Table 5</ref>: System performance (in %) using L1 and L2 lexico-semantic features, L1 â all L1s.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Experiments on related L1s</head><p>The results on ALL L1s confirm our expectations: since we have extracted verb-noun combinations that originate with two particular L1s from the set of all different L1s in the CLC, and then used the L1 lexico-semantic features, the system is able to identify more errors thus we observe an improve- ment in recall. The precision, however, does not improve, possibly because the set of errors in ALL L1s is different from that in the two L1s we rely on to build the lexico-semantic models. The final question that we investigate is whether the lexico- semantic models of our L1s are directly portable to typologically related languages. If this is the case, we expect to see an effect on the precision of the classifier as well as on the recall. We experiment with the following groups of re- lated languages ordered by the number of verb- noun pairs we found in the CLC data:</p><p>â¢ RU group: Russian, Polish, Czech, Slovak, Serbian, Croatian, Bulgarian, Slovene;</p><p>â¢ ES group: Spanish, Italian, Portuguese, French, Catalan, Romanian, Romansch.</p><p>In addition to investigating the effect of the L1 lexico-semantic model on the whole language group, we also consider its effects on individual languages. We chose Polish for the RU model, and Italian for the ES model as these two languages have the most data representing their native speak- ers in the CLC. <ref type="table" target="#tab_8">Table 6</ref> shows the number of verb- noun combinations and error rates for the language groups and these individual languages.</p><p>The results are presented in <ref type="table" target="#tab_9">Tables 7 and 8</ref>. They exhibit similar trends in the change of the system performance on L1 â L1 GROUP as we   see for L1 â ALL L1s. Adding the L1 lexico- semantic features has only a minor effect on accu- racy and precision, and a more pronounced effect on recall. On the contrary, when we test the system on one particular related L1 <ref type="table" target="#tab_11">(Table 8)</ref> we observe the opposite effect: with the exception of ES subj data, precision and accuracy improve, suggesting that the error detection system using L1-induced information identifies errors more precisely. Overall, the observed gains in performance in- dicate that L1 semantic models contribute infor- mation to lexical choice error detection in L2 for the speakers of typologically related languages. This in turn suggests that there may be less seman- tic variation within a language group than across different language groups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Discussion and data analysis</head><p>The best accuracy achieved in our experiments is 71.19% on ES subj combinations. However, previous research suggests that error detection in lexical choice is a difficult task. For instance, <ref type="bibr" target="#b10">Kochmar and Briscoe (2014)</ref> report that the agree- ment between human annotators on error detection in adjective-noun combinations is 86.50%.</p><p>We then qualitatively assessed the performance of our systems by analysing what types of errors  the classifiers reliably detect and what types of er- rors the classifiers miss across all runs over the samples. Some of the most reliably identified er- rors in both RU and ES datasets include:</p><p>â¢ verbs offer, propose and suggest which are often confused with each other. Correctly identified errors include *offer plan vs. sug- gest plan, *propose work vs. offer work and *suggest cost vs. offer cost;</p><p>â¢ verbs demonstrate and show where demon- strate is often used instead of show as in *chart demonstrates;</p><p>â¢ verbs say and tell particularly well identified with the ES model. Examples include *say idea instead of tell idea and *tell goodbye in- stead of say goodbye.</p><p>These examples represent lexical choice errors when selecting among near-synonyms, and viola- tions of verb subcategorization frames. The error in *find solution discussed throughout the paper is also reliably identified by the classifier across all runs. It is interesting to note that in the pair of verbs do and make, which are often confused with each other by both Russian and Spanish L1 speak- ers, errors involving make are identified more reli- ably than errors involving do: for example, *make business is correctly identified as an error, while *do joke is missed by the classifier. Many of the errors missed by the classifier are context-dependent. Some of the most problematic errors involve errors in combinations with verbs like be and become. Such errors do not result from an L1 lexico-semantic transfer and it is not surpris- ing that the classifiers miss them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>We have investigated whether lexico-semantic models from the native language are transferred to the second language, and what effect this trans- fer has on lexical choice in L2. We focused on two typologically different L1s -Russian and Spanish, and experimentally confirmed the hypothesis that statistical semantic models learned from these L1s significantly improve automatic error detection in L2 data produced by the speakers of the respec- tive L1s. We also investigated whether the seman- tic models learned from particular L1s are portable to other languages, and in particular to languages that are typologically close to the investigated L1s. Our results demonstrate that L1 models improve the coverage of the error detection system on a range of other L1s.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Russian to English interface for *find decision.</figDesc><graphic url="image-1.png" coords="4,310.66,66.19,216.00,92.19" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Statistics on the datasets collected. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>System performance (in %) using L2 
lexico-semantic features, L1 â L1 CLC . 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>System performance (in %) using a com-
bination of L2 semantic features, L1 â L1 CLC . 

L1 
Features Acc 
Pe 
Re 
F1 e 

RU dobj 
ftEn 
64.79 59.87 47.56 53.01 
+pmiL1 
66.05 58.74 62.72 60.67 

RU subj 
ftEn 
67.64 59.88 62.17 60.98 
+pmiL1 
68.68 62.10 69.61 64.38 

ES dobj 
ftEn 
64.34 61.80 59.67 60.71 
+pmiL1 
66.89 63.01 68.61 65.68 

ES subj 
ftEn 
69.51 61.79 68.58 65.00 
+pmiL1 
71.19 62.10 77.66 69.00 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Statistics on the L1 groups and related 
languages. 

L1 
Features Acc 
Pe 
Re 
F1 e 

RU dobj 
baseline 
57.08 51.80 71.58 59.78 
ftEn 
64.20 60.99 55.36 58.04 
+pmiL1 
65.77 61.06 64.78 62.86 

RU subj 
baseline 
56.43 49.52 62.04 54.24 
ftEn 
62.26 55.84 50.02 52.76 
+pmiL1 
62.78 56.02 54.48 55.21 

ES dobj 
baseline 
59.18 51.44 72.31 59.97 
ftEn 
65.14 59.82 53.83 56.66 
+pmiL1 
66.24 58.92 67.00 62.70 

ES subj 
baseline 
58.10 52.95 77.43 62.45 
ftEn 
66.29 61.24 68.45 64.64 
+pmiL1 
67.00 61.68 70.50 65.78 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table>System performance (in %) using L1 and 
L2 lexico-semantic features, L1 â L1 GROUP. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11" validated="false"><head>Table 8 :</head><label>8</label><figDesc></figDesc><table>System performance (in %) using L1 and 
L2 lexico-semantic features, L1 â REL L1. 

</table></figure>

			<note place="foot" n="3"> Data We first use large monolingual corpora in Spanish, Russian and English to build word association models for each of the languages. We then apply the resulting models for error detection in the English learner data.</note>

			<note place="foot" n="1"> The data is available at http://www.cl.cam.ac. uk/ Ë ek358/cross-ling-data.html</note>

			<note place="foot" n="2"> code.google.com/archive/p/word2vec/</note>

			<note place="foot" n="3"> scikit-learn.org/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We are grateful to the ACL reviewers for their helpful feedback. Ekaterina Kochmar's research is supported by Cambridge English Language Assessment via the ALTA Institute. Ekaterina Shutova's research is supported by the Leverhulme Trust Early Career Fellowship.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Semantic universals and typology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Language Universals</title>
		<editor>Chris Collins, Morten Christiansen and Shimon Edelman</editor>
		<meeting><address><addrLine>Oxford</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Multiword Expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Baldwin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">N</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Natural Language Processing</title>
		<editor>Indurkhya and F. J. Damerau</editor>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="267" to="292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A Feasibility Study on Low Level Techniques for Improving Parsing Accuracy for Spanish Using Maltparser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Herrera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Francisco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">GervÃ¡s</forename><forename type="middle">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th Hellenic Conference on Artificial Intelligence: Theories, Models and Applications</title>
		<meeting>the 6th Hellenic Conference on Artificial Intelligence: Theories, Models and Applications</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="39" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The WaCky Wide Web: A Collection of Very Large Linguistically Processed Web-Crawled Corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bernardini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ferraresi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zanchetta</forename><forename type="middle">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language Resources and Evaluation</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="209" to="226" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The Second Release of the RASP System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Briscoe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carroll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Watson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the COLING/ACL-2006 Interactive Presentation Sessions</title>
		<meeting>the COLING/ACL-2006 Interactive Presentation Sessions</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="59" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The British National Corpus, version 3 (BNC XML Edition)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Burnard</surname></persName>
		</author>
		<ptr target="http://www.natcorp.ox.ac.uk/" />
	</analytic>
	<monogr>
		<title level="m">Distributed by Oxford University Computing Services on behalf of the BNC Consortium</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">An automatic collocation writing assistant for Taiwanese EFL learners: A case of corpusbased NLP technology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">C</forename><surname>Liou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="283" to="299" />
		</imprint>
		<respStmt>
			<orgName>Computer Assisted Language Learning</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Correcting Semantic Collocation Errors with L1-induced Paraphrases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dahlmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">T</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the EMNLP-2011</title>
		<meeting>the EMNLP-2011</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="107" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A computational approach to detecting collocation errors in the writing of non-native speakers of English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Futagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Deane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chodorow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tetreault</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Assisted Language Learning</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="353" to="367" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Making Large-Scale SVM Learning Practical</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Kernel Methods-Support Vector Learning. B. SchÃ¶lkopf and C. Burges and A. Smola</title>
		<imprint>
			<publisher>MIT-Press</publisher>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Detecting Learner Errors in the Choice of Content Words Using Compositional Distributional Semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kochmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Briscoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on Computational Linguistics: Technical Papers</title>
		<meeting>the 25th International Conference on Computational Linguistics: Technical Papers</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1740" to="1751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Using Learner Data to Improve Error Correction in AdjectiveNoun Combinations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kochmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Briscoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth Workshop on Innovative Use of NLP for Building Educational Applications</title>
		<meeting>the Tenth Workshop on Innovative Use of NLP for Building Educational Applications</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="233" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Automated Grammatical Error Detection for Language Learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Leacock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chodorow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gamon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tetreault</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>Morgan and Claypool Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Automated suggestions for miscollocations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-E</forename><surname>Wible</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsao N.-L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Workshop on Innovative Use of NLP for Building Educational Applications</title>
		<meeting>the 4th Workshop on Innovative Use of NLP for Building Educational Applications</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="47" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Exploring Grammatical Error Correction with Not-SoCrummy Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Madnani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tetreault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chodorow</forename><forename type="middle">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Workshop on the Innovative Use of NLP for Building Educational Applications</title>
		<meeting>the 7th Workshop on the Innovative Use of NLP for Building Educational Applications</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="44" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mendonca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jaquette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Graff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipersio</forename><forename type="middle">D</forename></persName>
		</author>
		<title level="m">Spanish Gigaword Third Edition. Linguistic Data Consortium</title>
		<meeting><address><addrLine>Philadelphia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Distributed Representations of Words and Phrases and their Compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dean</forename><forename type="middle">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Linguistic Regularities in Continuous Space Word Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-T</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zweig</forename><forename type="middle">G</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL HLT</title>
		<meeting>NAACL HLT</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">WordNet: A Lexical Database for English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Vector-based models of semantic composition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="236" to="244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Composition in distributional models of semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1388" to="1429" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Evaluating Performance of Grammatical Error Detection to Maximize Learning Effect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nagata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nakatani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING (Posters)</title>
		<meeting>COLING (Posters)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="894" to="900" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">T</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Briscoe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hadiwinoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Susanto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bryant</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Shared Task on Grammatical Error Correction</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighteenth Conference on Computational Natural Language Learning: Shared Task</title>
		<meeting>the Eighteenth Conference on Computational Natural Language Learning: Shared Task</meeting>
		<imprint>
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The Cambridge Learner Corpus: Error coding and analysis for lexicography and ELT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Nicholls</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Corpus Linguistics conference</title>
		<meeting>the Corpus Linguistics conference</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="572" to="581" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">MaltParser: A language-independent system for datadriven dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nilsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chanev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Eryigit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>KÃ¼bler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Marinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marsi</forename><forename type="middle">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="95" to="135" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Language transfer: Cross-linguistic influence in language learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Odlin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A corpus-based tool for helping writers with Swedish collocations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Â¨</forename><surname>Ostling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Knutsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Extracting and Using Constructions in NLP, NODALIDA</title>
		<meeting>the Workshop on Extracting and Using Constructions in NLP, NODALIDA</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="28" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Is the sky pure today? AwkChecker: an assistive tool for detecting and correcting collocation errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Poupart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><forename type="middle">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st annual ACM symposium on User interface software and technology</title>
		<meeting>the 21st annual ACM symposium on User interface software and technology</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="121" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Generating Confusion Sets for Context-Sensitive Error Correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rozovskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2010 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="961" to="970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Algorithm Selection and Model Adaptation for ESL Correction Tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rozovskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="924" to="933" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Creating General-Purpose Corpora Using Automated Search Engine Queries. WaCky! Working papers on the Web as Corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sharoff</surname></persName>
		</author>
		<editor>Marco Baroni and Silvia Bernardini</editor>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">The proper place of men and machines in language technology Processing Russian without any linguistic knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sharoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nivre</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note>Russian Conference on Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">An ESL Writer&apos;s Collocation Aid</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Shei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Assisted Language Learning</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="167" to="182" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Linear) maps of the impossible: Capturing semantic anomalies in distributional space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Vecchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zamparelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the DISCO Workshop at ACL-2011</title>
		<meeting>the DISCO Workshop at ACL-2011</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Bootstrapping in a language-learning environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wible</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-H</forename><surname>Kwo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N.-L</forename><surname>Tsao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">L</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer Assisted Learning</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="90" to="102" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
