<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T13:02+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">QA-It: Classifying Non-Referential It for Question Answer Pairs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Math &amp; Computer Science</orgName>
								<orgName type="department" key="dep2">Math &amp; Computer Science</orgName>
								<orgName type="institution">Emory University Atlanta</orgName>
								<address>
									<postCode>30322</postCode>
									<region>GA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Lutz</surname></persName>
							<email>ajlutz@emory.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Math &amp; Computer Science</orgName>
								<orgName type="institution">Emory University Atlanta</orgName>
								<address>
									<postCode>30322</postCode>
									<region>GA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinho</forename><forename type="middle">D</forename><surname>Choi</surname></persName>
							<email>jinho.choi@emory.edu</email>
							<affiliation key="aff2">
								<orgName type="institution">Emory University Atlanta</orgName>
								<address>
									<postCode>30322</postCode>
									<region>GA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">QA-It: Classifying Non-Referential It for Question Answer Pairs</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics-Student Research Workshop</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics-Student Research Workshop <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="132" to="137"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper introduces a new corpus, QA-It, for the classification of non-referential it. Our dataset is unique in a sense that it is annotated on question answer pairs collected from multiple genres, useful for developing advanced QA systems. Our annotation scheme makes clear distinctions between 4 types of it, providing guidelines for many erroneous cases. Several statistical models are built for the classification of it, showing encouraging results. To the best of our knowledge, this is the first time that such a corpus is created for question answering.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>One important factor in processing document-level text is to resolve coreference resolution; one of the least developed tasks left in natural language pro- cessing. Coreference resolution can be processed in two steps, mention detection and antecedent resolu- tion. For mention detection, the classification of the pronoun it as either referential or non-referential is of critical importance because the identification of non-referential instances of it is essential to remove from the total list of possible mentions <ref type="bibr" target="#b2">(Branco et al., 2005;</ref><ref type="bibr" target="#b12">Wiseman et al., 2015)</ref>.</p><p>Although previous work has demonstrated a lot of promise for classifying all instances of it ( <ref type="bibr" target="#b1">Boyd et al., 2005;</ref><ref type="bibr" target="#b11">Müller, 2006;</ref><ref type="bibr" target="#b0">Bergsma et al., 2008;</ref><ref type="bibr" target="#b9">Li et al., 2009)</ref>, it is still a difficult task, especially when performed on social networks data containing grammatical errors, ambiguity, and colloquial lan- guage. In specific, we found that the incorrect clas- sification of non-referential it was one of the major reasons for the failure of a question answering sys- tem handling social networks data. In this paper, we first introduce our new corpus, QA-It, sampled from the Yahoo! Answers corpus and manually an- notated with 4 categories of it, referential-nominal, referential-others, non-referential, and errors. We also present statistical models for the classification of these four categories, each showing incremental improvements from one another.</p><p>The manual annotation of this corpus is challeng- ing because the rhetoric used in this dataset is often ambiguous; consequently, the automatic classifica- tion becomes undoubtedly more challenging. Our best model shows an accuracy of ≈78%, which is lower than some of the results achieved by previ- ous work, but expected because our dataset is much harder to comprehend even for humans, showing an inter-annotation agreement of ≈65%. However, we believe that this corpus provides an initiative to development a better coreference resolution system for the setting of question answering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>The identification of non-referential it, also known as pleonastic it, has been studied for many years, starting with <ref type="bibr" target="#b8">Hobbs (1978)</ref>. Although most of these earlier approaches are not used any more, the rules they discovered have helped for finding useful fea- tures for later machine learning approaches. <ref type="bibr" target="#b7">Evans (2001)</ref> used 35 features and memory-based learn- ing to classify 7 categories of it using data sampled from the SUSANNE and BNC corpora. <ref type="bibr" target="#b1">Boyd et al. (2005)</ref> took this approach and added 25 more features to identify 5 categories of it.</p><p>Müller (2006) classified 6 categories of it using spoken dialogues from the ICSI Meeting corpus. <ref type="bibr" target="#b0">Bergsma et al. (2008)</ref> used n-gram models to iden- tify it as either referential or non-referential. <ref type="bibr" target="#b9">Li et al. (2009)</ref> used search queries to help classify 7 categories of it. <ref type="figure" target="#fig_1">Figure 2</ref> shows how the annotation scheme for non-referential it has changed over time. Our approach differs from the recent work because we not only identify instances of it as either refer- ential or not, but also categorize whether referential it refers to a nominal or others, providing corefer- ence resolution systems more valuable information. Furthermore, our corpus includes more colloquial language, which makes it harder to disambiguate different categories of it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data Collection</head><p>We inspected several corpora (e.g., Amazon prod- uct reviews, Wikipedia, New York Times, Yahoo! Answers), and estimated the maximum likelihood of non-referential it in each corpus. After thorough inspection, the Yahoo! Answers and the Amazon product reviews were found to contain the highest numbers of it; however, an overwhelming percent- age of it in the Amazon product reviews was ref- erential. On the other hand, the Yahoo! Answers showed great promise with over 35% instances of non-referential and referential-others it. Thus, ques- tion answer pairs were uniformly sampled from 9 genres in the Yahoo! Answers corpus:</p><p>These genres contained the highest numbers of it. Each question answer pair was then ranked by the number of tokens it contained, ranging from 0 to 20, 20 to 40, all the way from 200 to 220, to see the impact of the document size on the classification of it. It is worth mentioning that our annotation was done on the document-level whereas annotations from most of the previous work were done on the sentence-level. While training our annotators, we confirmed that the contextual information was vital in classifying different categories of it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Annotation Scheme</head><p>Instances of it are grouped into 4 categories in our annotation scheme; referential-nominal, referential- others, non-referential, and errors ( <ref type="figure" target="#fig_1">Figure 2</ref>). Some of these categories are adapted from Evans (2001) who classified it into 7 categories; their categories captured almost every form of it, thus linguistically valuable, but a simpler scheme could enhance the annotation quality, potentially leading to more ro- bust coreference resolution. <ref type="bibr" target="#b1">Boyd et al. (2005)</ref> focused on the detection of non-referential it, and although their scheme was ef- fective, they did not distinguish referents that were nominals from the others (e.g., proaction, clause, discourse topic), which was not as suited for coref- erence resolution. <ref type="bibr" target="#b0">Bergsma et al. (2008)</ref> attempted to solve this issue by defining that only instances of it referent to nominals were referential. <ref type="bibr" target="#b9">Li et al. (2009)</ref> further elaborated above rules by adding referential-clause; their annotation scheme is simi- lar to ours such that we both make the distinction between whether it refers to a nominal or a clause; however, we include proaction and discourse topic to referential-others as well as cataphoric instances to non-referential.</p><p>Our aim is to generate a dataset that is useful for a coreference system to handle both nominal and non-nominal referents. With our proposed scheme, it is up to a coreference resolution system whether or not to handle the referential-others category, in- cluding clause, proaction, and discourse topic, dur- ing the process of mention detection. Furthermore, the errors category is added to handle non-pronoun cases of it. Note that we only consider referential as those that do have antecedents. If the pronoun is cataphoric, it is categorized as non-referential. <ref type="table" target="#tab_3">Computers and Internet  100  918  11,586  222  31  24  3  280  2. Science and Mathematics 100  801  11,589  164  35  18  3  220  3. Yahoo! Products  100 1,027  11,803  176  36  25  3  240  4. Education and Reference  100  831  11,520  148  55  36  2  241  5. Business and Finance  100  817  11,267  139  57  37  0</ref>  </p><formula xml:id="formula_0">Genre Doc Sen Tok C 1 C 2 C 3 C 4 C * 1.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Referential -Nominal</head><p>This category is for anaphoric instances of it that clearly refer to nouns, noun phrases, or gerunds. This is the standard use of it that is already being referenced by coreference resolution models today.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Referential -Others</head><p>This category is for any anaphoric instances of it that do not refer to nominals. Some anaphora referents could be in the form of proaction, clause anaphoras, or discourse topic <ref type="bibr" target="#b7">(Evans, 2001</ref>). Most coreference resolution models do not handle these cases, but as they still have anaphora referents, it would be valuable to indicate such category for the future advance of a coreference resolution system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Non-Referential</head><p>This category is for any extraposition, clefts, and pronouns that do not have referent. This also in- cludes cataphora <ref type="bibr" target="#b7">(Evans, 2001)</ref>. Our distinction of non-referential it is similar to the one made by <ref type="bibr" target="#b1">Boyd et al. (2005)</ref>, except that we do not include weather, condition, time, or place in this category because it would often be helpful to have those instances of it be referential:</p><p>What time is it now in Delaware US? It would be approximately 9:00 am.</p><p>Many could argue that the second instance of it is non-referential for the above example. But when context is provided, it would be more informative to have it refer to "the time now in Delaware US" for coreference resolution. If it is simply marked as non-referential, we would essentially be los- ing the context that the time in Delaware is 9:00 am. Although this does not appear many times in our corpus, it is important to make this distinction based on the context because without the context, this instance of it would be simply marked as non- referential.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Errors</head><p>This category includes any uses of a non-pronoun form of it including IT (Information Technology), disfluencies, and ambiguous it in book/song titles.</p><p>When you leave a glass of water sitting around for a couple hours or so , do bubbles form it it</p><p>In the example above, the two instances of it serves no purpose and cannot be identified as a potential misspelling of another word. This category is not present in any of the previous work, but due to the nature of our corpus as mentioned in difficulties, it is included in our annotation scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Corpus Analytics</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Annotation Difficulties</head><p>The Yahoo! Answers contains numerous grammat- ical errors, ambiguous references, disfluency, frag- ments, and unintelligible question and answer pairs, all of which contributes to difficulties in annota- tion. Ambiguous referencing had been problematic throughout the annotation and sometimes an agree- ment was hard to reach between annotators:</p><p>After selling mobile phones, I got post dated cheques ($170,000). But he closed office and bank account. help me?... That's a lot of money to just let go. If it were $1,700.00 then I might just whoop his a** and let it go but for $170,000... are you kidding?...</p><p>Here, it can be either idiomatic, or refer to the "post dated cheque" or the "process of receiving the post dated cheque" such that disambiguating its cate- gory is difficult even with the context. There were more of such cases where we were not certain if the referent was referential-nominal, referential-others, or idiomatic; in which case, the annotators were instructed to use their best intuition to categorize.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Inter-Annotation Agreement</head><p>All instances of it were double annotated by stu- dents trained in both linguistics and computer sci- ence. Adjudication was performed by the authors of this paper. For the inter-annotator agreement, our annotation gave the Cohans Kappa score of 65.25% and the observed proportionate agreement score of 81.81%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Analysis By Genre</head><p>The genre has a noticeable influence on the rela- tive number of either referential or non-referential instances of it. The genres with the lowest percent- age of referential-nominal are "Society and Culture" and "Politics and Government". These genres also contain the most abstract ideas and thoughts within the question and answer pairs. The genres which contain the most number of referential-nominal are "Computers and Internet", "Science and Mathemat- ics", and "Yahoo! Products". This makes sense because in each of these categories, the questions and answers deal with specific, tangible objects such as "pressing a button on the computer to unin- stall software". Overall, the more abstract the ques- tions and answers get, the more likely it is to use non-referential it or referential-others.  <ref type="table">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Analysis By Document Size</head><p>The document size shows a small influence on the categorization of it. The document group with the most instances of non-referential it is the smallest in size with a total number of tokens between 0 and 20. The rest of the document groups contains fewer instances of non-referential it although the differences are not as large as expected.  <ref type="table">Table 2</ref>: Distributions of our data for each docu- ment size.</p><formula xml:id="formula_1">Document Size C 1 C 2 C 3 C 4 C * 0</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Importance of Contextual Information</head><p>In certain cases, context is mandatory in determin- ing the category of it:</p><formula xml:id="formula_2">Q:</formula><p>Regarding IT, what are the fastest ways of getting superich? A: Find something everyone will need and then patent it. It could be anything that would do with or about computers. Look at RIM and the struggle it is now facing. With good maket- ing ANY enhancement or a new design could be worth millions. However, the biggest path to being rich is with maintenece or service of systems or with old programming languages.</p><p>For the first instance of it, if the annotators are only given the question, they possibly categorize it as referential-nominal or referential-others. However, we can confirm from further reading the context that it refers to the IT, "Information Technology". <ref type="table">Table 4</ref> shows the distributions of our corpus, split into training (70%), development (10%), and eval- uation (20%) sets. A total of 1,500, 209, and 474 instances of it is found in each set, respectively.   <ref type="table">Table 4</ref>: Distributions of our data splits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Corpus</head><formula xml:id="formula_3">Model Development Set Evaluation Set ACC C 1 C 2 C 3 C 4 ACC C 1 C 2 C 3 C 4 M 0 72.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Feature Template</head><p>For each token w i whose lemma is either it or its, features are extracted from the template in <ref type="table" target="#tab_4">Table 5</ref>. Three additional features are used, the relative posi- tion of w i within the sentence S k (rpw; w i ∈ S k ), the relative distance of w i from the nearest preced- ing noun w j (rdw; w j ∈ S k ), and the relative posi- tion of S k within the document D (rps; S k ∈ D): It is worth mentioning that we experimented with features extracted from brown clusters <ref type="bibr" target="#b3">(Brown et al., 1992</ref>) and word embeddings ( <ref type="bibr" target="#b10">Mikolov et al., 2013</ref>) trained on the Wikipedia articles, which did not lead to a more accurate result. It may be due to the different nature of our source data, Yahoo! An- swers. We will explore the possibility of improving our model by facilitating distributional semantics trained on the social networks data.</p><formula xml:id="formula_4">rpw = i /t , t = # of tokens in S k . rdw = |i−j| /t , t = # of tokens in S k . rps = k /d , d = # of sentences in D. w i .p, w i±1 .p, w i±2 .p, h(w i ).p, w i±1 .m, h(w i ).m w i+1 .p + w i+2 .m, w i+1 .p + w i+2 .p + w i+3 .m w i .d , h(w i ).dm</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Machine Learning</head><p>A stochastic adaptive gradient algorithm is used for statistical learning, which adapts per-coordinate learning rates to exploit rarely seen features while remaining scalable <ref type="bibr" target="#b6">(Duchi et al., 2011</ref>). Regular- ized dual averaging is applied for 1 regularization, shown to work well with ADAGRAD <ref type="bibr" target="#b13">(Xiao, 2010)</ref>. In addition, mini-batch is applied, where each batch consists of instances from k-number of documents. The following hyperparameters are found during the development and used for all our experiments: the learning rate η = 0.1, the mini-batch boundary k = 5, the regularization parameter λ = 0.001. <ref type="table" target="#tab_3">Table 3</ref> shows the accuracies achieved by our mod- els. M 0 is the baseline model using only the fea- tures extracted from <ref type="table">Table.</ref> M 1 uses the additional features of rpw, rdw, and rps in Section 6.2. The additional features show robust improvements on both the development and the evaluation sets. No- tice that the F1 score for C 4 (errors) is consistently 0; this is not surprising given the tiny amount of training instances C 4 has. M 2 is experimented on datasets where annotations for C 4 are discarded. A small improvement is shown for M 2 on the evalua- tion set but not on the development set, where only 1 instance of C 4 is found. M 3 and M 4 aim to classify instances of it into 2 classes by merging C 2 and C 3 during either train-ing (M 3 ) or evaluation (M 4 ). Training with 3 cat- egories and merging the predicted output into 2 categories during evaluation (M 4 ) gives higher ac- curacies than merging the gold labels and training with 2 categories (M 3 ) in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>This paper introduces a new corpus called, QA-It, sampled from nine different genres in the Yahoo! Answers corpus and manually annotated with four categories of it. 2 Unlike many previous work, our annotation is done on the document-level, which is useful for both human annotators and machine learning algorithms to disambiguate different types of it. Our dataset is challenging because it includes many grammatical errors, ambiguous references, disfluency, and fragments. Thorough corpus ana- lysts are provided for a better understanding of our corpus. Our corpus is experimented with several statistical models. Our best model shows an accu- racy of 78%; considering the challenging nature of our corpus, this is quite encouraging. Our work can be useful for those who need to perform coref- erence resolution for question answering systems.</p><p>In the future, we will double the size of our an- notation so we can train a better model and have a more meaningful evaluation. We are also planning on developing a recurrent neural network model for the classification of it.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The chronicles of non-referential it annotation schemes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The proportion of referential-nominal for each genre. C1..3: the first 3 categories in Section 4, G1..9: the 9 genres in Table 1.</figDesc><graphic url="image-1.png" coords="4,75.38,547.04,211.51,172.77" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>w i−k and w i+k are the k'th preceding and succeed- ing tokens of w i , respectively. h(w i ) is the depen- dency head of w i . The joint features in line 2 are motivated by the rules in Boyd et al. (2005). For instance, with a sufficient amount of training data, features extracted from [w i+1 .p + w i+2 .m] should cover all rules such as [it + verb + to/that/what/etc].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Accuracies achieved by each model (in %). ACC: overall accuracy, C 1..4 : F1 scores for 4 
categories in Section 4. The highest accuracies are highlighted in bold. 

All data are tokenized, sentence segmented, part-of-
speech tagged, lemmatized, and dependency parsed 
by the open-source NLP toolkit, NLP4J (Choi and 
Palmer, 2012; Choi and McCallum, 2013). 1 

Set 
Doc Sen 
Tok 
C 1 C 2 C 3 C 4 
TRN 630 5,650 72,824 927 353 209 11 
DEV 
90 
787 10,348 139 
42 
27 
1 
TST 180 1,549 20,625 282 122 
64 
6 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Feature template used for our experiments. 
p: part-of-speech tag, m: lemma, d: dependency 
label, dm: set of dependents' lemmas. 

1 https://github.com/emorynlp/nlp4j 

</table></figure>

			<note place="foot" n="1"> Computers and Internet, 2 Science and Mathematics, 3 Yahoo! Products, 4 Education and Reference, 5 Business and Finance, 6 Entertainment and Music, 7 Society and Culture, 8 Health, 9 Politics and Government</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Distributional Identification of Non-Referential Pronouns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shane</forename><surname>Bergsma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Randy</forename><surname>Goebel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Conference of the Association for Computational Linguistics, ACL&apos;08</title>
		<meeting>the Annual Conference of the Association for Computational Linguistics, ACL&apos;08</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="10" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Identifying Non-Referential it: A Machine Learning Approach Incorporating Linguistically Motivated Patterns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriane</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Whitney</forename><surname>Gegg-Harrison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donna</forename><surname>Byron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL Workshop on Feature Engineering for Machine Learning in Natural Language Processing</title>
		<meeting>the ACL Workshop on Feature Engineering for Machine Learning in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="40" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">António</forename><surname>Branco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tony</forename><surname>Mcenery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Mitkov</surname></persName>
		</author>
		<title level="m">Anaphora Processing: Linguistic, Cognitive and Computational Modelling</title>
		<imprint>
			<publisher>John Benjamins Publishing Company</publisher>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Class-based n-gram Models of Natural Language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">V</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">L</forename><surname>Desouza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><forename type="middle">J</forename><surname>Mercer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenifer</forename><forename type="middle">C</forename><surname>Della Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="467" to="480" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Transition-based Dependency Parsing with Selectional Branching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jinho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, ACL&apos;13</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics, ACL&apos;13</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1052" to="1062" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Fast and Robust Part-of-Speech Tagging Using Dynamic Model Selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jinho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, ACL&apos;12</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics, ACL&apos;12</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="363" to="367" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Adaptive Subgradient Methods for Online Learning and Stochastic Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">39</biblScope>
			<biblScope unit="page" from="2121" to="2159" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Applying Machine Learning Toward an Automatic Classification of It. Literary and Linguistic Computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Evans</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="45" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerry</forename><forename type="middle">R</forename><surname>Hobbs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Resolving Pronoun References. Lingua</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="331" to="338" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Identification of Pleonastic It Using the Web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petr</forename><surname>Musílek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marek</forename><surname>Reformat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Loren Wyard-Scott</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal Of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="339" to="389" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Distributed Representations of Words and Phrases and their Compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Advances in Neural Information Processing Systems 26, NIPS&apos;13</title>
		<meeting>Advances in Neural Information Processing Systems 26, NIPS&apos;13</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Automatic detection of nonreferential it in spoken multi-party dialog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">11th Conference of the European Chapter of the Association for Computational Linguistics, EACL&apos;06</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="49" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning Anaphoricity and Antecedent Ranking Features for Coreference Resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Wiseman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stuart</forename><surname>Shieber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1416" to="1426" />
		</imprint>
	</monogr>
	<note>Long Papers), ACL&apos;15</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Dual Averaging Methods for Regularized Stochastic Learning and Online Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="2543" to="2596" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
