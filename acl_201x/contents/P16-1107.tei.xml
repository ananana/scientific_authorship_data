<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:31+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Context-aware Argumentative Relation Mining</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huy</forename><forename type="middle">V</forename><surname>Nguyen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computer Science Department</orgName>
								<orgName type="department" key="dep2">Computer Science Department and Learning Research and Development Center</orgName>
								<orgName type="institution" key="instit1">University of Pittsburgh Pittsburgh</orgName>
								<orgName type="institution" key="instit2">University of Pittsburgh Pittsburgh</orgName>
								<address>
									<postCode>15260, 15260</postCode>
									<region>PA, PA</region>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><forename type="middle">J</forename><surname>Litman</surname></persName>
							<email>dlitman@pitt.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computer Science Department</orgName>
								<orgName type="department" key="dep2">Computer Science Department and Learning Research and Development Center</orgName>
								<orgName type="institution" key="instit1">University of Pittsburgh Pittsburgh</orgName>
								<orgName type="institution" key="instit2">University of Pittsburgh Pittsburgh</orgName>
								<address>
									<postCode>15260, 15260</postCode>
									<region>PA, PA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Context-aware Argumentative Relation Mining</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1127" to="1137"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Context is crucial for identifying argumentative relations in text, but many argument mining methods make little use of contex-tual features. This paper presents context-aware argumentative relation mining that uses features extracted from writing topics as well as from windows of context sentences. Experiments on student essays demonstrate that the proposed features improve predictive performance in two argumentative relation classification tasks.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>By supporting tasks such as automatically iden- tifying argument components 1 (e.g., premises, claims) in text, and the argumentative relations (e.g., support, attack) between components, ar- gument (argumentation) mining has been studied for applications in different research fields such as document summarization <ref type="bibr" target="#b32">(Teufel and Moens, 2002</ref>), opinion mining <ref type="bibr">(Boltuži´Boltuži´c andŠnajderandˇandŠnajder, 2014)</ref>, automated essay evaluation ( <ref type="bibr" target="#b3">Burstein et al., 2003)</ref>, legal information systems ( <ref type="bibr" target="#b19">Palau and Moens, 2009)</ref>, and policy modeling platforms ( <ref type="bibr" target="#b9">Florou et al., 2013)</ref>.</p><p>Given a pair of argument components with one component as the source and the other as the tar- get, argumentative relation mining involves deter- mining whether a relation holds from the source to the target, and classifying the argumentative func- tion of the relation (e.g., support vs. attack). Ar- 1 There is no consensus yet on an annotation scheme for argument components, or on the minimal textual units to be annotated. We follow <ref type="bibr" target="#b21">Peldszus and Stede (2013)</ref> and con- sider "argument mining as the automatic discovery of an ar- gumentative text portion, and the identification of the relevant components of the argument presented there." We also bor- row their term "argumentative discourse unit" to refer to the textual units (e.g., text segment, sentence, clause) which are considered as argument components.</p><p>Essay 73. Topic: Is image more powerful than the written word?</p><p>... (1) Hence, I agree only to certain de- gree that in today's world, image serves as a more effective means of communica- tion <ref type="bibr">[M ajorClaim]</ref> .</p><p>(2) Firstly, pictures can influence the way people think <ref type="bibr">[Claim]</ref> . <ref type="formula">(3)</ref> For example, nowa- days horrendous images are displayed on the cigarette boxes to illustrate the con- sequences of smoking <ref type="bibr">[P remise]</ref> . <ref type="formula">(4)</ref> As a result, statistics show a slight reduction in the number of smokers, indicating that they realize the effects of the negative habit <ref type="bibr">[P remise]</ref> ... gumentative relation mining -beyond argument component mining -is perceived as an essential step towards more fully identifying the argumenta- tive structure of a text <ref type="bibr" target="#b21">(Peldszus and Stede, 2013;</ref><ref type="bibr" target="#b28">Sergeant, 2013;</ref><ref type="bibr" target="#b31">Stab et al., 2014</ref>). Consider the second paragraph shown in <ref type="figure" target="#fig_0">Figure 1</ref>. Only detect- ing the argument components (a claim in sentence 2 and two premises in sentences 3 and 4) does not give a complete picture of the argumentation. By looking for relations between these components, one can also see that the two premises together jus- tify the claim. The argumentation structure of the text in <ref type="figure" target="#fig_0">Figure 1</ref> is illustrated in <ref type="figure" target="#fig_1">Figure 2</ref>.</p><p>Our current study proposes a novel approach for argumentative relation mining that makes use of contextual features extracted from surround- ing sentences of source and target components as well as from topic information of the writings.</p><p>Prior argumentative relation mining studies have often used features extracted from argument com- ponents to model different aspects of the relations between the components, e.g., relative distance, word pairs, semantic similarity, textual entailment <ref type="bibr" target="#b4">(Cabrio and Villata, 2012;</ref><ref type="bibr" target="#b30">Stab and Gurevych, 2014b;</ref><ref type="bibr">Boltuži´Boltuži´c andŠnajderandˇandŠnajder, 2014;</ref><ref type="bibr" target="#b23">Peldszus and Stede, 2015b)</ref>. Features extracted from the text surrounding the components have been less ex- plored, e.g., using words and their part-of-speech from adjacent sentences <ref type="bibr" target="#b24">(Peldszus, 2014</ref>). The first hypothesis investigated in this paper is that the discourse relations of argument components with adjacent sentences (called context windows in this study, a formal definition is given in §5.3) can help characterize the argumentative relations that con- nect pairs of argument components. Reconsider- ing the example in <ref type="figure" target="#fig_0">Figure 1</ref>, without knowing the content "horrendous images are displayed on the cigarette boxes" in sentence 3, one cannot easily tell that "reduction in the number of smokers" in sentence 4 supports the "pictures can influence" claim in sentence 2. We expect that such content relatedness can be revealed from a discourse anal- ysis, e.g., the appearance of a discourse connective "As a result".</p><p>While topic information in many writing gen- res (e.g., scientific publications, Wikipedia arti- cles, student essays) has been used to create fea- tures for argument component mining ( <ref type="bibr" target="#b32">Teufel and Moens, 2002;</ref><ref type="bibr" target="#b13">Levy et al., 2014;</ref><ref type="bibr" target="#b17">Nguyen and Litman, 2015)</ref>, topic-based features have been less explored for argumentative relation mining. The second hypothesis investigated in this paper is that features based on topic context also provide useful information for improving argumentative relation mining. In the excerpt below, knowing that 'online game' and 'computer' are topically related might help a model decide that the claim in sentence 1 supports the claim in sentence 2:</p><p>(1) People who are addicted to games, especially online games, can eventually bear dangerous consequences <ref type="bibr">[Claim]</ref> .</p><p>(2) Although it is undeniable that computer is a crucial part of human life <ref type="bibr">[P remise]</ref> , it still has its bad side <ref type="bibr">[M ajorClaim]</ref> . <ref type="bibr">2</ref> Motivated by the discussion above, we propose context-aware argumentative relation mining -a novel approach that makes use of contextual fea-</p><formula xml:id="formula_0">MajorClaim (1)</formula><p>Claim <ref type="bibr">(2)</ref> Premise <ref type="formula">(</ref> tures that are extracted by exploiting context sen- tence windows and writing topic to improve rela- tion prediction. In particular, we derive features using discourse relations between argument com- ponents and windows of their surrounding sen- tences. We also derive features using an argument and domain word lexicon automatically created by post-processing an essay's topic model. Experi- mental results show that our proposed contextual features help significantly improve performance in two argumentative relation classification tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Unlike argument component identification where textual inputs are typically sentences or clauses ( <ref type="bibr" target="#b16">Moens et al., 2007;</ref><ref type="bibr" target="#b30">Stab and Gurevych, 2014b;</ref><ref type="bibr" target="#b13">Levy et al., 2014;</ref><ref type="bibr" target="#b14">Lippi and Torroni, 2015)</ref>, tex- tual inputs of argumentative relation mining vary from clauses ( <ref type="bibr" target="#b30">Stab and Gurevych, 2014b;</ref><ref type="bibr" target="#b24">Peldszus, 2014</ref>) to multiple-sentences <ref type="bibr" target="#b0">(Biran and Rambow, 2011;</ref><ref type="bibr" target="#b4">Cabrio and Villata, 2012;</ref><ref type="bibr">Boltuži´Boltuži´c andŠnajder andˇandŠnajder, 2014</ref>). Studying claim justification be- tween user comments, <ref type="bibr" target="#b0">Biran and Rambow (2011)</ref> proposed that the argumentation in justification of a claim can be characterized with discourse struc- ture in the justification. They however only con- sidered discourse markers but not discourse re- lations. <ref type="bibr" target="#b5">Cabrio et al. (2013)</ref> conducted a cor- pus analysis and found certain similarity between Penn Discourse TreeBank relations ( <ref type="bibr" target="#b25">Prasad et al., 2008</ref>) and argumentation schemes ( <ref type="bibr" target="#b33">Walton et al., 2008</ref>). However they did not discuss how such similarity could be applied to argument mining. Motivated by these findings, we propose to use features extracted from discourse relations be-tween sentences for argumentative relation min- ing. Moreover, to enable discourse relation features when the textual inputs are only sen- tences/clauses, we group the inputs with their con- text sentences. <ref type="bibr" target="#b26">Qazvinian and Radev (2010)</ref> used the term "context sentence" to refer to sentences surrounding a citation that contained information about the cited source but did not explicitly cite it. In our study, we only require that the context sen- tences of an argument component must be in the same paragraph and adjacent to the component.</p><p>Prior work in argumentative relation mining has used argument component labels to provide con- straints during relation identification. For exam- ple, when an annotation scheme (e.g., <ref type="bibr" target="#b21">(Peldszus and Stede, 2013;</ref><ref type="bibr" target="#b29">Stab and Gurevych, 2014a)</ref>) does not allow relations from claim to premise, no rela- tions are inferred during relation mining for any argument component pair where the source is a claim and the target is a premise. In our work, we follow <ref type="bibr" target="#b30">Stab and Gurevych (2014b)</ref> and use the predicted labels of argument components as fea- tures during argumentative relation mining. We, however, take advantage of an enhanced argument component model <ref type="bibr" target="#b18">(Nguyen and Litman, 2016)</ref> to obtain more reliable argument component labels than in <ref type="bibr" target="#b30">(Stab and Gurevych, 2014b</ref>).</p><p>Argument mining research has studied differ- ent data-driven approaches for separating orga- nizational content (shell) from topical content to improve argument component identification, e.g., supervised sequence model ( <ref type="bibr" target="#b15">Madnani et al., 2012)</ref>, unsupervised probabilistic topic models <ref type="bibr" target="#b27">(Séaghdha and Teufel, 2014;</ref><ref type="bibr" target="#b7">Du et al., 2014</ref>). Nguyen and Litman (2015) post-processed LDA ( <ref type="bibr" target="#b1">Blei et al., 2003</ref>) output to extract a lexicon of ar- gument and domain words from development data. Their semi-supervised approach exploits the topic context through essay titles to guide the extraction.</p><p>Finally, prior research has explored predict- ing different argumentative relationship labels be- tween pairs of argument components, e.g., attach- ment (Peldszus and Stede, 2015a), support vs. non-support ( <ref type="bibr" target="#b0">Biran and Rambow, 2011;</ref><ref type="bibr" target="#b4">Cabrio and Villata, 2012;</ref><ref type="bibr" target="#b30">Stab and Gurevych, 2014b)</ref>, {implicit, explicit}×{support, attack} (Boltuži´Boltuži´c andŠnajderandˇandŠnajder, 2014), verifiability of support <ref type="bibr" target="#b20">(Park and Cardie, 2014)</ref>. Our experiments use two such argumentative relation classification tasks (Sup- port vs. Non-support, Support vs. Attack) to eval- uate the effectiveness of our proposed features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Persuasive Essay Corpus</head><p>Stab and Gurevych (2014a) compiled the Persua- sive Essay Corpus consisting of 90 student argu- mentative essays and made it publicly available. <ref type="bibr">3</ref> Because the corpus has been utilized for differ- ent argument mining tasks <ref type="bibr" target="#b30">(Stab and Gurevych, 2014b;</ref><ref type="bibr" target="#b17">Nguyen and Litman, 2015;</ref><ref type="bibr" target="#b18">Nguyen and Litman, 2016)</ref>, we use this corpus to demonstrate our context-aware argumentative relation mining approach, and adapt the model developed by <ref type="bibr" target="#b30">Stab and Gurevych (2014b)</ref> to serve as the baseline for evaluating our proposed approach.</p><p>Three experts identified possible argument components of three types within each sentence in the corpus (MajorClaim -writer's stance toward the writing topic, Claim -controversial statements that support or attack MajorClaim, and Premise - evidence used to underpin the validity of Claim), and also connected the argument components us- ing two argumentative relations <ref type="bibr">(Support and Attack)</ref>. According to the annotation manual, each essay has exactly one MajorClaim. A sentence can have one or more argument components (Ar- gumentative sentences). Sentences that do not contain any argument component are labeled Non- argumentative. <ref type="figure" target="#fig_0">Figure 1</ref> shows an example essay with components annotated, and <ref type="figure" target="#fig_1">Figure 2</ref> illus- trates relations between those components. Argu- mentative relations are directed and can hold be- tween a Premise and another Premise, a Premise and a (Major-) Claim, or a Claim and a Major- Claim. Except for the relation from Claim to MajorClaim, an argumentative relation does not cross paragraph boundaries. The three experts achieved inter-rater accuracy 0.88 for component labels and Krippendorff's α U 0.72 for component boundaries. Given the annotated argument com- ponents, the three experts obtained Krippendorff's α 0.81 for relation labels. The number of relations are shown in <ref type="table">Table 1</ref> Stab and Gurevych (2014b) split the corpus into an 80% training set and a 20% test set which have similar label distributions. We use this split to train and test our proposed models, and directly com- pare our models' performance to the reported per- formance in (Stab and Gurevych, 2014b).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Task 2: Support vs. Attack</head><p>To further evaluate the effectiveness of our ap- proach, we conduct an additional task that clas- sifies an argumentative relation as Support or At- tack. For this task, we assume that the relation (i.e., attachment <ref type="bibr" target="#b24">(Peldszus, 2014)</ref>) between two components is given, and aim at identifying the argumentative function of the relation. Because we remove the paragraph constraint in this task, we obtain more Support relations than in Task 1. As shown in <ref type="table">Table 1</ref>, of the total 1473 relations, we have 1312 (89%) Support and 161 (11%) At- tack relations. Because this task was not studied in <ref type="bibr" target="#b30">(Stab and Gurevych, 2014b)</ref>, we adapt Stab and Gurevych's model to use as the baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Argumentative Relation Models</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Baseline</head><p>We adapt <ref type="bibr" target="#b30">(Stab and Gurevych, 2014b</ref>) to use as a baseline for evaluating our approach. Given a pair of argument components, we follow (Stab and Gurevych, 2014b) by first extracting 3 feature sets: structural (e.g., word counts, sentence position), lexical (e.g., word pairs, first words), and gram- matical production rules (e.g., S→NP,VP).</p><p>Because a sentence may have more than one ar- gument component, the relative component posi- tions might provide useful information <ref type="bibr" target="#b24">(Peldszus, 2014</ref>). Thus, we also include 8 new component position features: whether the source and target components are the whole sentences or the be- ginning/end components of the sentences; if the source is before or after the target component; and the absolute difference of their positions.</p><p>Stab and Gurevych (2014b) used a 55-discourse marker set to extract indicator features. We ex- pand their discourse maker set by combining them with a 298-discourse marker set developed in <ref type="bibr" target="#b0">(Biran and Rambow, 2011</ref>). We expect the expanded set of discourse markers will represent better pos- sible discourse relations in the texts.</p><p>Stab and Gurevych (2014b) used predicted label of argument components as features for both train- ing and testing their argumentation structure iden- tification model. <ref type="bibr">5</ref> As their predicted labels are not available to us, we adapt this feature set by using the argument component model in <ref type="bibr" target="#b18">(Nguyen and Litman, 2016)</ref> which was shown to outperform the corresponding model of Stab and Gurevych.</p><p>For later presentation purposes, we name the set of all features from this section except word pairs and production rules as the common fea- tures. While word pairs and grammatical pro- duction rules were the most predictive features in <ref type="bibr" target="#b30">(Stab and Gurevych, 2014b)</ref>, we hypothesize that this large and sparse feature space may have nega- tive impact on model robustness <ref type="bibr" target="#b17">(Nguyen and Litman, 2015</ref>). Most of our proposed models re- place word pairs and production rules with differ- ent combinations of new contextual features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Topic-context Model</head><p>Our first proposed model (TOPIC) makes use of Topic-context features derived from a lexicon of argument and domain words for persuasive essays <ref type="bibr" target="#b17">(Nguyen and Litman, 2015)</ref>. Argument words (e.g., 'believe', 'opinion') signal the argumenta- tive content and are commonly used across differ- ent topics. In contrast, domain words are specific terminologies commonly used within the topic (e.g., 'art', 'education'). The authors first use topic prompts in development data of unannotated persuasive essays to semi-automatically collect ar- gument and domain seed words. In particular, they used 10 argument seed words: agree, disagree, reason, support, advantage, disadvantage, think, conclusion, result, opinion. Domain seed words are those in the topic prompts but not argument seed words or stop words. The seeds words are then used to supervise an automated extraction of argument and domain words from output of LDA topic model ( <ref type="bibr" target="#b1">Blei et al., 2003</ref></p><note type="other">) on the develop- ment data. The extracted lexicon consists of 263 (stemmed) argument words and 1806 (stemmed) domain words mapped to 36 LDA topics. 6 All ar- gument words are from a single LDA topic while a domain word can map to multiple LDA topics (ex- cept the topic of argument words). Using the lex- icon, we extract the following Topic-context fea- tures:</note><p>Argument word: from all word pairs extracted from the source and target components, we re- move those that have at least one word not in the argument word list. Each argument word pair de- fines a boolean feature indicating its presence in the argument component pair. We also include each argument word of the source and target com- ponents as a boolean feature which is true if the word is present in the corresponding component. We count number of common argument words, the absolute difference in number of argument words between source and target components.</p><p>Domain word count: to measure the topic sim- ilarity between the source and target components, we calculate number of common domain words, number of pairs of two domain words that share an LDA topic, number of pairs that share no LDA topic, and the absolute difference in number of do- main words between the two components.</p><p>Non-domain MainVerb-Subject dependency: we extract MainVerb-Subject dependency triples, e.g., nsubj(belive, I), from the source and target components, and filter out triples that involve do- main words. We model each extracted triple as a boolean feature which is true if the corresponding argument component has the triple.</p><p>Finally, we include the common feature set.</p><p>To illustrate the Topic-context features, con- sider the following source and target components. Argument words are in boldface, and domain words are in italic.</p><p>Essay 54. Topic: museum and art gallery will disappear soon?</p><p>Source: more and more people can watch exhibitions through television or internet at home due to modern technology <ref type="bibr">[P remise]</ref> Target: some people think museums and art galleries will disappear soon <ref type="bibr">[Claim]</ref> An argument word pair is people-think. There are 35 pairs of domain words. A pair of two do- main words that share an LDA topic is exhibitions- art. A pair of two domain words that do not share any LDA topic is internet-galleries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Window-context Model</head><p>Our second proposed model (WINDOW) extracts features from discourse relations and common words between context sentences in the context windows of the source and target components.</p><p>Definition. Context window of an argument com- ponent is a text segment formed by neighboring sentences and the covering sentence of the com- ponent. The neighboring sentences are called con- text sentences, and must be in the same paragraph with the component.</p><p>In this study, context windows are determined using window-size heuristics. <ref type="bibr">7</ref> Given a window- size n, we form a context window by grouping the covering sentence with at most n adjacently pre- ceding and n adjacently following sentences that must be in the same paragraph.</p><p>To minimize noise in feature space, we re- quire that context windows of the source and tar- get components must be mutually exclusive. Bi- ran and Rambow (2011) observed that the re- lation between a source argument and a target argument is usually instantiated by some elabo- ration/justification provided in a support of the source argument. Therefore we prioritize the con- text window of source component when it overlaps with the target context window. Particularly, we keep overlapping context sentences in the source window, and remove them from the target win- dow. For example, with window-size 1, context windows of the Claim in sentence 2 in <ref type="figure" target="#fig_0">Figure 1</ref> and the Premise in sentence 4 overlap at sentence 3. When the Claim is set as source component, its  context window includes sentences {2, 3}, and the Premise as a target has context window with only sentence 4. We extract three Window-context feature sets from the context windows:</p><p>Common word: as common word counts be- tween adjacent sentences were shown useful for argument mining <ref type="bibr" target="#b18">(Nguyen and Litman, 2016)</ref>, we count common words between the covering sen- tence with preceding context sentences, and with following context sentences, for source and target components.</p><p>Discourse relation: for both source and tar- get components, we extract discourse relations between context sentences, and within the cov- ering sentence. We also extract discourse rela- tions between each pair of source context sen- tence and target context sentence. Each relation defines a boolean feature. We extract both Penn Discourse Treebank (PDTB) relations <ref type="bibr" target="#b25">(Prasad et al., 2008)</ref> and Rhetorical Structure Theory Dis- course Treebank (RST-DTB) relations <ref type="bibr" target="#b6">(Carlson et al., 2001</ref>) using publicly available discourse parsers <ref type="bibr" target="#b11">(Ji and Eisenstein, 2014;</ref><ref type="bibr" target="#b34">Wang and Lan, 2015)</ref>. Each PDTB relation has sense label de- fined in a 3-layered (class, type, subtype), e.g., CONTINGENCY.Cause.result. While there are only four semantic class labels at the class-level which may not cover well different aspects of ar- gumentative relation, subtype-level output is not available given the discourse parser we use. Thus, we use relations at type-level as features. For RST- DTB relations, we use only relation labels, but ig- nore the nucleus and satellite labels of components as they do not provide more information given the component order in the pair. Because tempo- ral relations were shown not helpful for argument mining tasks ( <ref type="bibr" target="#b0">Biran and Rambow, 2011;</ref><ref type="bibr" target="#b30">Stab and Gurevych, 2014b)</ref>, we exclude them here.</p><p>Discourse marker: while the baseline model only considers discourse markers within the ar- gument components, we define a boolean feature for each discourse marker classifying whether the marker is present before the covering sentence of the source and target components or not. This im- plementation aims to characterize the discourse of the preceding and following text segments of each argument component separately.</p><p>Finally, we include the common feature set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Combined Model</head><p>While Window-context features are extracted from surrounding text of the argument com- ponents, which exploits the local context, the Topic-context features are an abstraction of topic- dependent information, e.g., domain words are de- fined within the context of topic domain (Nguyen and Litman, 2015), and thus make use of the global context of the topic domain. We believe that local and global context information repre- sent complementary aspects of the relation be- tween argument components. Thus, we expect to achieve the best performance by combining Window-context and Topic-context models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Full Model</head><p>Finally, the FULL model includes all features in BASELINE and COMBINED models. That is, the FULL model is the COMBINED model plus word pairs and production rules. A summary of all mod- els is shown in <ref type="figure" target="#fig_2">Figure 3</ref>.   window-size in range <ref type="bibr">[0,</ref><ref type="bibr">8]</ref> 8 that yields the best F1 score in 10-fold cross validation. We use the training set as determined in <ref type="bibr" target="#b30">(Stab and Gurevych, 2014b</ref>) to train/test 9 the models using LibLINEAR algorithm <ref type="bibr" target="#b8">(Fan et al., 2008</ref>) without parameter or feature optimization. Cross-validations are con- ducted using Weka ( <ref type="bibr" target="#b10">Hall et al., 2009</ref>). We use Stanford parser <ref type="bibr" target="#b12">(Klein and Manning, 2003)</ref> to per- form text processing. As shown in <ref type="figure" target="#fig_3">Figure 4</ref>, while increasing the window-size from 2 to 3 improves performance (significantly), using window-sizes greater than 3 does not gain further improvement. We hypothesize that after a certain limit, larger context windows will produce more noise than helpful information for the prediction. Therefore, we set the window-size to 3 in all of our experi- ments involving Window-context model (all with a separate test set).</p><note type="other">F1:Support 0.519 0.519 0.488 0.533 0.583* 0.550 F1:Non-support 0.920 0.925 0.917 0.916* 0.923 0.929</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Performance on Test Set</head><p>We train all models using the training set and re- port their performances on the test set in <ref type="table" target="#tab_3">Table 2</ref>.</p><p>We also compare our baseline to the reported per- formance (REPORT) for Support vs. Non-support classification in <ref type="bibr" target="#b30">(Stab and Gurevych, 2014b</ref>). The learning algorithm with parameters are kept the same as in the window-size tuning experiment. Given the skewed class distribution of this data, Accuracy and F1 of Non-support (the major class) are less important than Kappa, F1, and F1 of Sup- port (the minor class). To conduct T-tests for per- formance significance, we split the test data into subsets by essays' ID, and record prediction per- formance for individual essays. We first notice that the performances of our baseline model are better than (or equal to) RE- PORTED, except the Macro Recall. We reason that these performance disparities may be due to the differences in feature extractions between our im- plementation and Stab and Gurevych's, and also due to the minor set of new features (e.g., new predicted labels, expanded marker set, component position) that we added in our baseline.</p><p>Comparing proposed models with BASELINE, we see that WINDOW, COMBINED, and FULL models outperform BASELINE in important met- rics: Kappa, F1, Recall, but TOPIC yields worse performances than BASELINE. However, the fact that COMBINED outperforms BASELINE, espe- cially with significantly higher Kappa, F1, Recall, and F1:Support, has shown the value of Topic- context features. While Topic-context features alone are not effective, they help improve WIN- DOW model which supports our hypothesis that Topic-context and Window-context features are complementary aspects of context, and they to- gether obtain better performance.</p><p>Comparing our proposed TOPIC, WINDOW,  COMBINED models with each other shows that COMBINED obtains the best performance while TOPIC performs the worst, which reveals that Topic-context feature set is less effective than Window-context set. While FULL model achieves the best Accuracy, Precision, and F1:Non-support, it has lower performance than COMBINED model in important metrics: Kappa, F1, F1:Support. We reason that the noise caused by word pairs and production rules even dominate the effectiveness of Topic-context and Window-context features, which degrades the overall performance. Overall, by combining TOPIC and WINDOW models, we obtain the best performance. Most notably, we obtain the highest improvement in F1:Support, and have the best balance between Precision and Recall values among all models. These reveal that our contextual features not only dominate generic features like word pairs and pro- duction rules, but also are effective to predict mi- nor positive class (i.e., Support).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Task 2: Support vs. Attack</head><p>To evaluate the robustness of our proposed mod- els, we conduct an argumentative relation classifi- cation experiment that classifies a relation as Sup- port or Attack. Because this task was not stud- ied in <ref type="bibr" target="#b30">(Stab and Gurevych, 2014b</ref>) and the train- ing/test split for Support vs. Not task is not ap- plicable here, we conduct 5×10-fold cross valida- tion. We do not optimize the window-size param- eter of the WINDOW model, and use the value 3 as set up before. Average prediction performance of all models are reported in <ref type="table" target="#tab_5">Table 3</ref>.</p><p>Comparing our proposed models with the base- line shows that all of our proposed models sig- nificantly outperform the baseline in important metrics: Kappa, F1, F1:Attack. More notably than in the Support vs. Non-support classifica- tion, all of our proposed models predict the minor class (Attack) significantly more effectively than the baseline. The baseline achieves significantly higher F1:Support than WINDOW model. How- ever, F1:Support of the baseline is in a tie with TOPIC, COMBINED, and FULL.</p><p>Comparing our proposed models, we see that TOPIC and WINDOW models reveal different be- haviors. TOPIC model has significantly higher Precision and F1:Support, and significantly lower Recall and F1:Attack than WINDOW. Moreover, WINDOW model has slightly higher Kappa, F1, but significantly lower Accuracy. These com- parisons indicate that Topic-context and Window- context features are equally effective but impact differently to the prediction. The different nature between these two feature sets is clearer than in the prior experiment, as now the classification in- volves classes that are more semantically differ- ent, i.e., Support vs. Attack. We recall that TOPIC model performs worse than WINDOW model in Support vs. Non-support task.</p><p>Our FULL model performs significantly worse than all of TOPIC, WINDOW, and COMBINED in Kappa, F1, Recall, and F1:Attack. Along with re- sults from Support vs. Non-support task, this fur- ther suggests that word pairs and production rules are less effective and cannot be combined well with our contextual features.</p><p>Despite the fact that the Support vs. Attack task (Task 2) has smaller and more imbalanced data than the Support vs. Non-support (Task 1), our proposed contextual features seem to add even more value in Task 2 compared to Task 1. Us- ing Kappa to roughly compare prediction perfor- mance across the two tasks, we observe a greater performance improvement from Baseline to Com- bined model in Task 2 than in Task 1. This is an evidence that our proposed context-aware features work well even in a more imbalanced with smaller data classification task. The lower performance values of all models in Support vs. Attack than in Support vs. Non-support indirectly suggest that Support vs. Attack classification is a more difficult task. We hypothesize that the difference between support and attack exposes a deeper semantic re- lation than that between support and no-relation. We plan to extract textual text similarity and tex- tual entailment features <ref type="bibr" target="#b4">(Cabrio and Villata, 2012;</ref><ref type="bibr">Boltuži´Boltuži´c andŠnajderandˇandŠnajder, 2014)</ref> to investigate this hy- pothesis in our future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions and Future Work</head><p>In this paper, we have presented context-aware argumentative relation mining that makes use of contextual features by exploiting information from topic context and context sentences. We have explored different ways to incorporate our pro- posed features with baseline features used in a prior study, and obtained insightful results about feature effectiveness. Experimental results show that Topic-context and Window-context features are both effective but impact predictive perfor- mance measures differently. In addition, predict- ing an argumentative relation will benefit most from combining these two set of features as they capture complementary aspects of context to bet- ter characterize the argumentation in justification.</p><p>The results obtained in this preliminary study are promising and encourage us to explore more directions to enable contextual features. Our next step will investigate uses of topic segmentation to identify context sentences and compare this linguistically-motivated approach to our current window-size heuristic. We plan to follow prior research on graph optimization to refine the argu- mentation structure and improve argumentative re- lation prediction. Also, we will apply our context- aware argumentative relation mining to different argument mining corpora to further evaluate its generality.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Excerpt from a student persuasive essay (Stab and Gurevych, 2014a). Sentences are numbered and argument components are tagged.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Structure of the argumentation in the excerpt. Relations are illustrated accordingly to the annotation provided in the corpus. Premises 3 and 4 were annotated for separate relations to Claim 2. Our visualization should not mislead that the two premises are linked or convergent.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Features used in different models. Feature change across models are denoted by connectors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Performance of Window-context feature set by window-size.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>.</head><label></label><figDesc></figDesc><table>Label 

#instances 
Within-paragraph constraint 
Support 
989 
Attack 
103 
No paragraph constraint 
Support 
1312 
Attack 
161 

Table 1: Data statistics of the corpus. 

nent. For each of two argument components in 
the same paragraph 4 , we form two pairs (i.e., re-
versing source and target). In total we obtain 6330 
pairs, in which 989 (15.6%) have Support relation. 
Among 5341 Non-support pairs, 103 have Attack 
relation and 5238 are no-relation pairs. 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Support vs. Non-support classification performances on test set. Best values are in bold. Values 
smaller than baseline are underlined. * indicates significantly different from the baseline (p &lt; 0.05). 

0.62 

0.63 

0.64 

0.65 

0.66 

0.67 

0.68 

0.69 

0.7 

0 
1 
2 
3 
4 
5 
6 
7 
8 

Window-size 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>5×10-fold cross validation performance of Support vs. Attack classification. * indicates signif-
icantly different from the baseline (p &lt; 0.01). 

</table></figure>

			<note place="foot" n="2"> In this excerpt, the Premise was annotated as an attack to the MajorClaim in sentence 2.</note>

			<note place="foot" n="4"> Argumentative Relation Tasks 4.1 Task 1: Support vs. Non-support Our first task follows (Stab and Gurevych, 2014b): given a pair of source and target argument components, identify whether the source argumentatively supports the target or not. Note that when a support relation does not hold, the source may attack or has no relation with the target compo3 www.ukp.tu-darmstadt.de/data/argumentation-mining</note>

			<note place="foot" n="4"> Allowing cross-paragraph relations exponentially increases the number of no-relation pairs, which makes the prediction data extremely skewed (Stab and Gurevych, 2014b).</note>

			<note place="foot" n="5"> Stab and Gurevych (2014b) reported that including goldstandard labels of argument component in both training and testing phases yielded results close to human performance. Our preliminary experiment showed that including goldstandard argument component labels in training did not help when predicted labels were used in the test set.</note>

			<note place="foot" n="6"> An LDA topic is simply represented by a number, and should not be misunderstood with essay topics.</note>

			<note place="foot" n="7"> Due to the paragraph constraint and window overlapping, window-size does not indicate the actual context window size. However, window-size tells what the maximum size a window can have.</note>

			<note place="foot" n="8"> Windows-size 0 means covering sentence is the only context sentence. We experimented with not using context sentence at all and obtained worse performance. Our data does not have context window with window-size 9 or larger. 9 Note that via cross validation, in each fold some of our training set serves as a development set.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research is supported by NSF Grant 1122504. We thank the reviewers for their helpful feedback. We also thank Christian Stab for providing us the data split for the first experiment.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Identifying Justifications in Written Dialogs by Classifying Text as Argumentative</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Or</forename><surname>Biran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Owen</forename><surname>Rambow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Semantic Computing</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="363" to="381" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Latent Dirichlet allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Back up your Stance: Recognizing Arguments in Online Discussions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Boltuži´boltuži´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaň</forename><surname>Snajder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Argumentation Mining</title>
		<meeting>the First Workshop on Argumentation Mining<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06" />
			<biblScope unit="page" from="49" to="58" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Finding the WRITE Stuff: Automatic Identification of Discourse Structure in Student Essays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jill</forename><surname>Burstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="32" to="39" />
			<date type="published" when="2003-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Combining Textual Entailment and Argumentation Theory for Supporting Online Debates Interactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Cabrio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serena</forename><surname>Villata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="208" to="212" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">From Discourse Analysis to Argumentation Schemes and Back: Relations and Differences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Cabrio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Tonelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serena</forename><surname>Villata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Logic in Multi-Agent Systems</title>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Building a Discourse-tagged Corpus in the Framework of Rhetorical Structure Theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lynn</forename><surname>Carlson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><forename type="middle">Ellen</forename><surname>Okurowski</surname></persName>
		</author>
		<idno>SIG- DIAL &apos;01</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second SIGdial Workshop on Discourse</title>
		<meeting>the Second SIGdial Workshop on Discourse<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Shell Miner: Mining Organizational Phrases in Argumentative Texts in Social Media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianguang</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dandan</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lejian</forename><surname>Liao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 IEEE International Conference on Data Mining, ICDM &apos;14</title>
		<meeting>the 2014 IEEE International Conference on Data Mining, ICDM &apos;14<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="797" to="802" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">LIBLINEAR: A Library for Large Linear Classification. The Journal of</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Wei</forename><surname>Rong-En Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho-Jui</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangrui</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Jen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1871" to="1874" />
			<date type="published" when="2008-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Argument extraction for supporting public policy formulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eirini</forename><surname>Florou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities</title>
		<meeting>the 7th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-08" />
			<biblScope unit="page" from="49" to="54" />
		</imprint>
	</monogr>
	<note>Stasinos Konstantopoulos, Antonis Koukourikos, and Pythagoras Karampiperis. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The WEKA Data Mining Software: An Update</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eibe</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Pfahringer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Reutemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGKDD Explorations Newsletter</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="10" to="18" />
			<date type="published" when="2009-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Representation Learning for Text-level Discourse Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014-06" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="13" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Accurate unlexicalized parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 41st Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="423" to="430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Context Dependent Claim Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ran</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Bilu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Hershcovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehud</forename><surname>Aharoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Slonim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers</title>
		<meeting>COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-08" />
			<biblScope unit="page" from="1489" to="1500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Contextindependent Claim Detection for Argument Mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Lippi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Torroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on Artificial Intelligence, IJCAI&apos;15</title>
		<meeting>the 24th International Conference on Artificial Intelligence, IJCAI&apos;15<address><addrLine>Buenos Aires, Argentina</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="185" to="191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Identifying HighLevel Organizational Elements in Argumentative Discourse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitin</forename><surname>Madnani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Heilman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Tetreault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Chodorow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="20" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Automatic Detection of Arguments in Legal Texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Boiy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Conference on Artificial Intelligence and Law, ICAIL &apos;07</title>
		<meeting>the 11th International Conference on Artificial Intelligence and Law, ICAIL &apos;07<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="225" to="230" />
		</imprint>
	</monogr>
	<note>Raquel Mochales Palau, and Chris Reed</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Extracting Argument and Domain Words for Identifying Argument Components in Texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huy</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><surname>Litman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Argumentation Mining</title>
		<meeting>the 2nd Workshop on Argumentation Mining<address><addrLine>Denver, CO, June</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="22" to="28" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Improving argument mining in student essays by learning and exploiting argument indicators versus essay topics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huy</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><surname>Litman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 29th International FLAIRS Conference</title>
		<meeting>29th International FLAIRS Conference<address><addrLine>Key Largo, FL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Argumentation Mining: The Detection, Classification and Structure of Arguments in Text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><forename type="middle">Mochales</forename><surname>Palau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th International Conference on Artificial Intelligence and Law, ICAIL &apos;09</title>
		<meeting>the 12th International Conference on Artificial Intelligence and Law, ICAIL &apos;09<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="98" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Identifying Appropriate Support for Propositions in Online User Comments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joonsuk</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Argumentation Mining</title>
		<meeting>the First Workshop on Argumentation Mining<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06" />
			<biblScope unit="page" from="29" to="38" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">From Argument Diagrams to Argumentation Mining in Texts: A Survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Peldszus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><surname>Stede</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Cognitive Informatics and Natural Intelligence (IJCINI)</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="31" />
			<date type="published" when="2013-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Joint prediction in MST-style discourse parsing for argumentation mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Peldszus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><surname>Stede</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-09" />
			<biblScope unit="page" from="938" to="948" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Towards Detecting Counter-considerations in Text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Peldszus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><surname>Stede</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Argumentation Mining</title>
		<meeting>the 2nd Workshop on Argumentation Mining<address><addrLine>Denver, CO</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015-06" />
			<biblScope unit="page" from="104" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Towards segment-based recognition of argumentation structure in short texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Peldszus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Argumentation Mining</title>
		<meeting>the First Workshop on Argumentation Mining<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014-06" />
			<biblScope unit="page" from="88" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The Penn Discourse TreeBank 2.0</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rashmi</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhil</forename><surname>Dinesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleni</forename><surname>Miltsakaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Livio</forename><surname>Robaldo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Webber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC-08)</title>
		<meeting>the Sixth International Conference on Language Resources and Evaluation (LREC-08)<address><addrLine>Marrakech, Morocco, May</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="8" to="1093" />
		</imprint>
	</monogr>
	<note>European Language Resources Association (ELRA). ACL Anthology Identifier</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Identifying Non-explicit Citing Sentences for Citationbased Summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vahed</forename><surname>Qazvinian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dragomir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL &apos;10</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics, ACL &apos;10<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="555" to="564" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Unsupervised learning of rhetorical structure with untopic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diarmuid´o</forename><surname>Diarmuid´odiarmuid´</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Séaghdha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Teufel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on Computational Linguistics (COLING-14)</title>
		<meeting>the 25th International Conference on Computational Linguistics (COLING-14)<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Automatic argumentation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Sergeant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 10th European Semantic Web Conference</title>
		<meeting><address><addrLine>Montpellier, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="656" to="660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Annotating Argument Components and Relations in Persuasive Essays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Stab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers</title>
		<meeting>COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1501" to="1510" />
		</imprint>
		<respStmt>
			<orgName>Dublin City University and Association for Computational Linguistics</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Identifying Argumentative Discourse Structures in Persuasive Essays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Stab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="46" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Argumentation Mining in Persuasive Essays and Scientific Articles from the Discourse Structure Perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Stab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Kirschner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judith</forename><surname>Ecklekohler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Frontiers and Connections between Argumentation Theory and Natural Language Processing</title>
		<editor>Elena Cabrio, Serena Villata, and Adam Wyner</editor>
		<meeting>the Workshop on Frontiers and Connections between Argumentation Theory and Natural Language Processing<address><addrLine>Bertinoro, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2014-07" />
			<biblScope unit="page" from="40" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Summarizing Scientific Articles: Experiments with Relevance and Rhetorical Status</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Teufel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Moens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2002-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><surname>Walton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabrizio</forename><surname>Macagno</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Argumentation Schemes. Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A Refined End-to-End Discourse Parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Man</forename><surname>Lan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Nineteenth Conference on Computational Natural Language Learning-Shared Task</title>
		<meeting>the Nineteenth Conference on Computational Natural Language Learning-Shared Task<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015-07" />
			<biblScope unit="page" from="17" to="24" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
