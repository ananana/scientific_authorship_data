<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:27+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Generative Event Schema Induction with Entity Disambiguation</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiem-Hieu</forename><surname>Nguyen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">LIMSI-CNRS</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Laboratoire Vision et Ingnierie des Contenus</orgName>
								<orgName type="institution" key="instit1">CEA</orgName>
								<orgName type="institution" key="instit2">LIST</orgName>
								<address>
									<postCode>F-91191</postCode>
									<settlement>Gif-sur-Yvette</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Tannier</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">LIMSI-CNRS</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Univ. Paris-Sud</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Ferret</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Laboratoire Vision et Ingnierie des Contenus</orgName>
								<orgName type="institution" key="instit1">CEA</orgName>
								<orgName type="institution" key="instit2">LIST</orgName>
								<address>
									<postCode>F-91191</postCode>
									<settlement>Gif-sur-Yvette</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Romaric</forename><surname>Besan√ßon</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Laboratoire Vision et Ingnierie des Contenus</orgName>
								<orgName type="institution" key="instit1">CEA</orgName>
								<orgName type="institution" key="instit2">LIST</orgName>
								<address>
									<postCode>F-91191</postCode>
									<settlement>Gif-sur-Yvette</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Generative Event Schema Induction with Entity Disambiguation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="188" to="197"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper presents a generative model to event schema induction. Previous methods in the literature only use head words to represent entities. However, elements other than head words contain useful information. For instance, an armed man is more discriminative than man. Our model takes into account this information and precisely represents it using proba-bilistic topic distributions. We illustrate that such information plays an important role in parameter estimation. Mostly, it makes topic distributions more coherent and more discriminative. Experimental results on benchmark dataset empirically confirm this enhancement.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Information Extraction was initially defined (and is still defined) by the MUC evaluations <ref type="bibr" target="#b19">(Grishman and Sundheim, 1996)</ref> and more specifically by the task of template filling. The objective of this task is to assign event roles to individual tex- tual mentions. A template defines a specific type of events (e.g. earthquakes), associated with se- mantic roles (or slots) hold by entities (for earth- quakes, their location, date, magnitude and the damages they caused <ref type="bibr" target="#b22">(Jean-Louis et al., 2011)</ref>).</p><p>Schema induction is the task of learning these templates with no supervision from unlabeled text. We focus here on event schema induction and con- tinue the trend of generative models proposed ear- lier for this task. The idea is to group together entities corresponding to the same role in an event template based on the similarity of the relations that these entities hold with predicates. For ex- ample, in a corpus about terrorist attacks, enti- ties that are objects of verbs to kill, to attack can be grouped together and characterized by a role named VICTIM. The output of this identification operation is a set of clusters of which members are both words and relations, associated with their probability (see an example later in <ref type="figure">Figure 4</ref>). These clusters are not labeled but each of them represents an event slot.</p><p>Our approach here is to improve this initial idea by entity disambiguation. Some ambiguous enti- ties, such as man or soldier, can match two differ- ent slots (victim or perpetrator). An entity such as terrorist can be mixed up with victims when arti- cles relate that a terrorist has been killed by police (and thus is object of to kill). Our hypothesis is that the immediate context of entities is helpful for disambiguating them. For example, the fact that man is associated with armed, dangerous, heroic or innocent can lead to a better attribution and def- inition of roles. We then introduce relations be- tween entities and their attributes in the model by means of syntactic relations.</p><p>The document level, which is generally a cen- ter notion in topic modeling, is not used in our generative model. This results in a simpler, more intuitive model, where observations are generated from slots, that are defined by probabilistic dis- tributions on entities, predicates and syntactic at- tributes. This model offers room for further exten- sions since multiple observations on an entity can be represented in the same manner.</p><p>Model parameters are estimated by Gibbs sam- pling. We evaluate the performance of this ap- proach by an automatic and empiric mapping be- tween slots from the system and slots from the ref- erence in a way similar to previous work in the domain.</p><p>The rest of this paper is organized as follows: Section 2 briefly presents previous work; in Sec- tion 3, we detail our entity and relation represen- tation; we describe our generative model in Sec- tion 4, before presenting our experiments and eval- uations in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>188</head><p>Despite efforts made for making template fill- ing as generic as possible, it still depends heav- ily on the type of events.</p><p>Mixing generic processes with a restrictive number of domain- specific rules <ref type="bibr" target="#b15">(Freedman et al., 2011</ref>) or exam- ples ( <ref type="bibr" target="#b18">Grishman and He, 2014</ref>) is a way to reduce the amount of effort needed for adapting a sys- tem to another domain. The approaches of On- demand information extraction ( <ref type="bibr" target="#b21">Hasegawa et al., 2004;</ref><ref type="bibr" target="#b35">Sekine, 2006</ref>) and Preemptive Information Extraction ( <ref type="bibr" target="#b36">Shinyama and Sekine, 2006</ref>) tried to overcome this difficulty in another way by exploit- ing templates induced from representative docu- ments selected by queries.</p><p>Event schema induction takes root in work on the acquisition from text of knowledge struc- tures, such as the Memory Organization Pack- ets <ref type="bibr" target="#b34">(Schank, 1980)</ref>, used by early text under- standing systems <ref type="bibr" target="#b10">(DeJong, 1982)</ref> and more re- cently by <ref type="bibr" target="#b12">Ferret and Grau (1997)</ref>. First attempts for applying such processes to schema induc- tion have been made in the fields of Informa- tion Extraction <ref type="bibr" target="#b9">(Collier, 1998)</ref>, Automatic Sum- marization <ref type="bibr" target="#b20">(Harabagiu, 2004</ref>) and event Question- Answering ( <ref type="bibr" target="#b13">Filatova et al., 2006;</ref><ref type="bibr" target="#b14">Filatova, 2008)</ref>.</p><p>More recently, work after ( <ref type="bibr" target="#b21">Hasegawa et al., 2004</ref>) has developed weakly supervised forms of Information Extraction including schema in- duction in their objectives. However, they have been mainly applied to binary relation extraction in practice <ref type="bibr" target="#b11">(Eichler et al., 2008;</ref><ref type="bibr" target="#b33">Rosenfeld and Feldman, 2007;</ref><ref type="bibr" target="#b24">Min et al., 2012)</ref>. In parallel, several approaches were proposed for perform- ing specifically schema induction in already ex- isting frameworks: clause graph clustering ( <ref type="bibr" target="#b31">Qiu et al., 2008)</ref>, event sequence alignment <ref type="bibr" target="#b32">(Regneri et al., 2010)</ref> or LDA-based approach relying on FrameNet-like semantic frames <ref type="bibr" target="#b1">(Bejan, 2008)</ref>. More event-specific generative models were pro- posed by <ref type="bibr" target="#b7">Chambers (2013)</ref> and <ref type="bibr" target="#b8">Cheung et al. (2013)</ref>. Finally, <ref type="bibr" target="#b3">Chambers and Jurafsky (2008)</ref>, <ref type="bibr" target="#b4">Chambers and Jurafsky (2009)</ref>, Chambers and Ju- rafsky (2011), improved by <ref type="bibr" target="#b0">Balasubramanian et al. (2013)</ref>, and Chambers (2013) focused specifically on the induction of event roles and the identifica- tion of chains of events for building representa- tions from texts by exploiting coreference resolu- tion or the temporal ordering of events. All this work is also linked to work about the induction of scripts from texts, more or less closely linked to  events, such as ( <ref type="bibr" target="#b16">Frermann et al., 2014)</ref>, <ref type="bibr" target="#b30">(Pichotta and Mooney, 2014)</ref> or <ref type="bibr" target="#b26">(Modi and Titov, 2014</ref>).</p><p>The work we present in this article is in line with Chambers (2013), which will be described in more details in Section 5, together with a quanti- tative and qualitative comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Entity Representation</head><p>An entity is represented as a triple containing: a head word h, a list A of attribute relations and a list T of trigger relations. Consider the following example:</p><p>(1) Two armed men attacked the police station and killed a policeman. An innocent young man was also wounded.</p><p>As illustrated in <ref type="figure" target="#fig_0">Figure 1</ref>, four entities, equiva- lent to four separated triples, are generated from the text above. Head words are extracted from noun phrases. A trigger relation is composed of a predicate (attack, kill, wound) and a depen- dency type (subject, object). An attribute rela- tion is composed of an argument (armed, police, young) and a dependency type (adjectival, nomi- nal or verbal modifier). In the relationship to trig- gers, a head word is argument, but in the relation- ship to attributes, it is predicate. We use Stanford NLP toolkit ( <ref type="bibr" target="#b23">Manning et al., 2014</ref>) for parsing and coreference resolution.</p><p>A head word is extracted if it is a nominal or proper noun and it is related to at least one trig- ger; pronouns are omitted. A trigger of an head word is extracted if it is a verb or an eventive noun and the head word serves as its subject, object, or preposition. We use the categories noun.EVENT and noun.ACT in WordNet as a list of eventive nouns. A head word can have more than one trig- ger. These multiple relations can come from a syn- tactic coordination inside a single sentence, as it is the case in the first sentence of the illustrating example. They can also represent a coreference chain across sentences, as we use coreference res- olution to merge the triggers of mentions corefer- ing to the same entity in a document. Coreferences are useful sources for event induction ( <ref type="bibr" target="#b5">Chambers and Jurafsky, 2011;</ref><ref type="bibr" target="#b7">Chambers, 2013)</ref>. Finally, an attribute is extracted if it is an adjective, a noun or a verb and serves as an adjective, verbal or nom- inal modifier of a head word. If there are several modifiers, only the closest to the head word is se- lected. This "best selection" heuristic allows to omit non-discriminative attributes for the entity. <ref type="figure" target="#fig_1">Figure 2</ref> shows the plate notation of our model. For each triple representing an entity e, the model first assigns a slot s for the entity from an uni- form distribution uni(1, K). Its head word h is then generated from a multinominal distribution œÄ s . Each t i of event trigger relations T e is gen- erated from a multinominal distribution œÜ s . Each a j of attribute relations A e is similarly generated from a multinominal distribution Œ∏ s . The distri- butions Œ∏, œÄ, and œÜ are generated from Dirichlet priors dir(Œ±), dir(Œ≤) and dir(Œ≥) respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Generative Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Model Description</head><p>Given a set of entities E, our model (œÄ, œÜ, Œ∏) is defined by</p><formula xml:id="formula_0">P œÄ,œÜ,Œ∏ (E) = e‚ààE P œÄ,œÜ,Œ∏ (e)<label>(2)</label></formula><p>where the probability of each entity e is defined by</p><formula xml:id="formula_1">P œÄ,œÜ,Œ∏ (e) = P (s) √ó P (h|s) √ó t‚ààTe P (t|s) √ó a‚ààAe P (a|s)<label>(3)</label></formula><p>The generative story is as follows:</p><p>for slot s ‚Üê 1 to K do Generate an attribute distribution Œ∏s from a Dirichlet prior dir(Œ±); Generate a head distribution œÄs from a Dirichlet prior dir(Œ≤); Generate a trigger distribution œÜs from a Dirichlet prior dir(Œ≥); end for entity e ‚àà E do Generate a slot s from a uniform distribution uni(1, K); Generate a head h from a multinominal distribution œÄs; for i ‚Üê 1 to |Te| do Generate a trigger ti from a multinominal distribution œÜs; end for j ‚Üê 1 to |Ae| do Generate an attribute aj from a multinominal distribution œÜs; end end</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Parameter Estimation</head><p>For parameter estimation, we use the Gibbs sam- pling method <ref type="bibr" target="#b17">(Griffiths, 2002</ref>). The slot variable s is sampled by integrating out all the other vari- ables.</p><p>Previous models ( <ref type="bibr" target="#b8">Cheung et al., 2013;</ref><ref type="bibr" target="#b7">Chambers, 2013</ref>) are based on document-level topic modeling, which originated from models such as Latent Dirichlet Allocation ( <ref type="bibr" target="#b2">Blei et al., 2003)</ref>. Our model is, instead, independent from docu- ment contexts. Its input is a sequence of entity triples. Document boundary is only used in a post- processing step of filtering (see Section 5.3 for more details). There is a universal slot distribu- tion instead of each slot distribution for one doc- ument. Furthermore, slot prior is ignored by us- ing a uniform distribution as a particular case of categorical probability. Sampling-based slot as- signment could depend on initial states and ran- dom seeds. In our implementation of Gibbs sam- pling, we use 2,000 burn-in of overall 10,000 it- erations. The purpose of burn-in is to assure that parameters converge to a stable state before esti- mating the probability distributions. Moreover, an interval step of 100 is applied between consecutive samples in order to avoid too strong coherence.</p><p>Particularly, for tracking changes in probabili- ties resulting from attribute relations, we ran in the first stage a specific burn-in with only heads and trigger relations. This stable state was then used as initialization for the second burn-in in  <ref type="figure">Figure 3</ref>: Probability convergence when using attributes in sampling. The use of attributes is started at point 50 (i.e., 50% of burn-in phase). The dotted line shows convergence without attributes; the continuous line shows convergence with attributes.</p><p>which attributes, heads, and triggers were used al- together. This specific experimental setting made us understand how the attributes modified distri- butions. We observed that non-ambiguous words or relations (i.e. explode, murder:nsubj) were only slightly modified whereas probabilities of ambigu- ous words such as man, soldier or triggers such as kill:dobj or attack:nsubj converged smoothly to a different stable state that was semantically more coherent. For instance, the model interestingly re- alized that even if a terrorist was killed (e.g. by police), he was not actually a real victim of an at- tack. <ref type="figure">Figure 3</ref> shows probability convergences of terrorist and kill:dobj given ATTACK victim and ATTACK perpetrator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluations</head><p>In order to compare with related work, we eval- uated our method on the Message Understanding Conference (MUC-4) corpus <ref type="bibr" target="#b37">(Sundheim, 1991)</ref> using precision, recall and F-score as conventional metrics for template extraction.</p><p>In what follows, we first introduce the MUC- 4 corpus (Section 5.1.1), we detail the mapping technique between learned slots and reference slots (5.1.2) as well as the hyper-parameters of our model (5.1.3). Next, we present a first exper- iment (Section 5.2) showing how using attribute relations improves overall results. The second ex- periment (Section 5.3) studies the impact of doc- ument classification. We then compare our re- sults with previous approaches, more particularly with Chambers (2013), from both quantitative and qualitative points of view (Section 5.4). Finally, Section 5.5 is dedicated to error analysis, with a special emphasis on sources of false positives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Setups</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Datasets</head><p>The MUC-4 corpus contains 1,700 news articles about terrorist incidents happening in Latin Amer- ica. The corpus is divided into 1,300 documents for the development set and four test sets, each containing 100 documents.</p><p>We follow the rules in the literature to guarantee comparable results <ref type="bibr" target="#b27">(Patwardhan and Riloff, 2007;</ref><ref type="bibr" target="#b5">Chambers and Jurafsky, 2011</ref>). The evaluation fo- cuses on four template types -ARSON, ATTACK, BOMBING, KIDNAPPING -and four slots -Perpe- trator, Instrument, Target, and Victim. Perpetrator is merged from Perpetrator Individual and Perpe- trator Organization. The matching between sys- tem answers and references is based on head word matching. A head word is defined as the right- most word of the phrase or as the right-most word of the first 'of' if the phrase contains any. Op- tional templates and slots are ignored when calcu- lating recall. Template types are ignored in eval- uation: this means that a perpetrator of BOMBING in the answers could be compared to a perpetrator of ARSON, ATTACK, BOMBING or KIDNAPPING in the reference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Slot Mapping</head><p>The model learns K slots and assigns each entity in a document to one of the learned slots. Slot mapping consists in matching each reference slot to an equivalent learned slot.</p><p>Note that among the K learned slots, some are irrelevant while others, sometimes of high quality, contain entities that are not part of the reference (spatio-temporal information, protagonist context, etc.). For this reason, it makes sense to have much more learned slots than expected event slots.</p><p>Similarly to previous work in the literature, we implemented an automatic empirical-driven slot mapping. Each reference slot was mapped to the learned slot that performed the best on the task of template extraction according to the F- score metric. Here, two identical slots of two different templates, such as ATTACK victim and KIDNAPPING victim, must to be mapped sepa- rately. <ref type="figure">Figure 4</ref> shows the most common words of two learned slots which were mapped to BOMB- ING instrument and KIDNAPPING victim. This mapping is then kept for testing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3">Parameter Tuning</head><p>We first tuned hyper-parameters of the models on the development set. The number of slots was set to K = 35. Dirichlet priors were set to Œ± = 0.1, Œ≤ = 1 and Œ≥ = 0.1. The model was learned from the whole dataset. Slot mapping was done on tst1 and tst2. Outputs from tst3 and tst4 were eval-  uated using references and were averaged across ten runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experiment 1: Using Entity Attributes</head><p>In this experiment, two versions of our model are compared: HT+A uses entity heads, event trigger relations and entity attribute relations. HT uses only entity heads and event triggers and omits at- tributes.</p><p>We studied the gain brought by attribute re- lations with a focus on their effect when coref- erence information was available or was miss- ing. The variations on the model input are named single, multi and coref. Single input has only one event trigger for each entity. A text like an armed man attacked the police station and killed a policeman results in two triples for the entity man: (armed:amod, man, attack:nsubj) and (armed:amod, man, kill:nsubj). In multi input, one entity can have several event triggers, leading for the text above to the triple (armed:amod, man, [at- tack:nsubj, kill:nsubj]). The coref input is richer than multi in that, in addition to triggers from the same sentence, triggers linked to the same coref- ered entity are merged together. For instance, if man in the above example corefers with he in He was arrested three hours later, the merged triple becomes (armed:amod, man, [attack:nsubj, kill:nsubj, arrest:dobj]). The plate notations of these model+data combinations are given in <ref type="figure" target="#fig_3">Fig- ure 5</ref>. <ref type="table">Table 1</ref> shows a consistent improvement when using attributes, both with and without corefer- ences. The best performance of 40.62 F-score is obtained by the full model on inputs with coref- This model is equivalent to 5b) with T=1; 5b) HT model ran on multi data; 5c) HT+A model ran on single data; 5d) HT+A model ran on multi data.  <ref type="table">Table 1</ref>: Improvement from using attributes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data</head><p>erences. Using both attributes in the model and coreference to generate input data results in a gain of 3 F-score points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Experiment 2: Document Classification</head><p>In the second experiment, we evaluated our model with a post-processing step of document classifi- cation.</p><p>The MUC-4 corpus contains many "irrelevant" documents. A document is irrelevant if it contains no template. Among 1,300 documents in the de- velopment set, 567 are irrelevant. The most chal- lenging part is that there are many terrorist entities, e.g. bomb, force, guerrilla, occurring in irrelevant documents. That makes filtering out those docu- ments important, but difficult. As document clas- sification is not explicitly performed by our model, a post-processing step is needed. Document clas- sification is expected to reduce false positives in ir- relevant documents while not dramatically reduc- ing recall.</p><p>Given a document d with slot-assigned entities and a set of mapped slots S m resulting from slot mapping, we have to decide whether this docu- ment is relevant or not. We define the relevance score of a document as:</p><formula xml:id="formula_2">relevance(d) = e‚ààd:s e ‚ààS m t‚ààT e P (t|s e ) e‚ààd t‚ààT e P (t|s e ) (4)</formula><p>where e is an entity in the document d; s e is the slot value assigned to e; and t is an event trigger in the list of triggers T e .</p><p>The equation (4) defines the score of an entity as the sum of the conditional probabilities of triggers given a slot. The relevance score of the document is proportional to the score of the entities assigned to mapped slots. If this relevance score is higher than a threshold Œª, then the document is consid- ered as relevant. The value of Œª = 0.02 was tuned System P R F HT+A 32.42 54.59 40.62 HT+A + doc. classification 35.57 53.89 42.79 HT+A + oracle classification 44.58 54.59 49.08 <ref type="table">Table 2</ref>: Improvement from document classifica- tion as post-processing. on the development set by maximizing the F-score of document classification. <ref type="table">Table 2</ref> shows the improvement when applying document classification. The precision increases as false positives from irrelevant documents are fil- tered out. The loss of recall comes from relevant documents that are mistakenly filtered out. How- ever, this loss is not significant and the overall F- score finally increases by 5%. We also compare our results to an "oracle" classifier that would re- move all irrelevant documents while preserving all relevant ones. The performance of this oracle clas- sification shows that there are some room for fur- ther improvement from document classification.</p><p>Irrelevant document filtering is a technique ap- plied by most supervised and unsupervised ap- proaches. Supervised methods prefer relevance detection at sentence or phrase-level <ref type="bibr" target="#b28">(Patwardhan and Riloff, 2009;</ref><ref type="bibr" target="#b27">Patwardhan and Riloff, 2007)</ref>. As for several unsupervised methods, Chambers (2013) includes document classification in his topic model. Chambers and Jurafsky (2011) and <ref type="bibr" target="#b8">Cheung et al. (2013)</ref> use the learned clusters to classify documents by estimating the relevance of a document with respect to a template from post- hoc statistics about event triggers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Comparison to State-of-the-Art</head><p>For comparing in more depth our results to the state-of-the-art in the literature. we reimple- mented the method proposed in <ref type="bibr" target="#b7">Chambers (2013)</ref> and integrated our attribute distributions into his model (as shown in <ref type="figure" target="#fig_4">Figure 6</ref>).</p><p>The main differences between this model and ours are the following:</p><p>1. The full template model of Chambers <ref type="formula" target="#formula_0">(2013)</ref> adds a distribution œà linking events to docu- ments. This makes the model more complex and maybe less intuitive since there is no rea- son to connect documents and slots (a docu- ment may contain references to several tem- plates and slot mapping does not depend on document level). A benefit of this document System P R F <ref type="bibr" target="#b8">Cheung et al. (2013)</ref> 32 <ref type="bibr">37 34 Chambers and Jurafsky (2011)</ref>  <ref type="bibr">48 25 33 Chambers (2013)</ref>   distribution is that it leads to a free classifi- cation of irrelevant documents, thus avoid- ing a pre-or post-processing for classifica- tion. However, this issue of document rel- evance is very specific to the MUC corpus and the evaluation method; In a more general use case, there would be no "irrelevant" doc- uments, only documents on various topics.</p><p>2. Each entity is linked to an event variable e. This event generates a predicate for each entity mention (recall that mentions of an entity are all occurrences of this entity in the documents, for example in a corefer- ence chain). Our work instead focus on the fact that a probabilistic model could have multiple observations at the same po- sition. Multiple triggers and multiple at- tributes are treated equally. The sources of multiple attributes and multiple triggers are not only from document-level corefer- ences but also from dependency relations (or even from domain-level entity coreferences if available). Hence, our model arguably gener- alizes better in terms of both modeling and input data.</p><p>3. Chambers (2013) applies a heuristic con- straint during the sampling process, impos- ing that subject and object of the same predi- cate (e.g. kill:nsubj and kill:dobj) are not dis- tributed into the same slot. Our model does not require this heuristic.</p><p>Some details concerning data preprocessing and model parameters are not fully specified by <ref type="bibr" target="#b7">Chambers (2013)</ref>; for this reason, our implementation of the model (applied on the same data) leads to slightly different results than those published. That is why we present the two results here (pa- per values in <ref type="table" target="#tab_5">Table 3</ref>, reimplementation values in <ref type="table" target="#tab_7">Table 4</ref>). <ref type="table" target="#tab_5">Table 3</ref> shows that our model outperforms the others on recall by a large margin. It achieves the  <ref type="formula" target="#formula_0">(2013)</ref>   best overall F-score. In addition, as stated by our experiments, precision could be further improved by more sophisticated document classification. In- terestingly, using attributes also proves to be use- ful in the model proposed by Chambers (2013) (as shown in <ref type="table" target="#tab_7">Table 4</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Error Analysis</head><p>We performed an error analysis on the output of HT+A + doc. classification to detect the origin of false positives (FPs). 38% of FPs are mentions that never occur in the reference. Within this 38%, attacker and killer are among the most frequent er- rors. These words could refer to a perpetrator of an attack. These mentions, however, do not occur in the reference, possibly because human annotators consider them as too generic terms. Apart from such generic terms, other assignments are obvious errors of the system, e.g. window, door or wall as physical target; action or massacre as perpetrator; explosion or shooting as instrument. These kinds of errors are due to the fact that in our model, as in the one of <ref type="bibr" target="#b7">Chambers (2013)</ref>, the number of slots is fixed and is not equivalent to the real number of reference slots.</p><p>On the other hand, 62% of FPs are mentions of entities that occur at least once in the reference. On top of the list are perpetrators such as guer- rilla, group and rebel. The model is capable of as- signing guerrilla to attribution slot if it is accom- panied by a trigger like announce:nsubj. How- ever, triggers that describe quasi-terrorism events (e.g. menace, threatening, military conflict) are also grouped into perpetrator slots. Similarly, mentions of frequent words such as bomb (instru- ment), building, house, office (targets) tend to be systematically grouped into these slots, regardless of their relations. Increasing the number of slots (to sharpen their content) does not help overall. This is due to the fact that the MUC corpus is very small and is biased towards terrorism events. Adding a higher level of template type as in Cham- bers (2013) partially solves the problem but makes recall decrease (as shown in <ref type="table" target="#tab_5">Table 3</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions and Perspectives</head><p>We presented a generative model for representing the roles played by the entities in an event tem- plate. We focused on using immediate contexts of entities and proposed a simpler and more effective model than those proposed in previous work. We evaluated this model on the MUC-4 corpus. Even if our results outperform other unsuper- vised approaches, we are still far from results ob- tained by supervised systems. Improvements can be obtained by several ways. First, the character- istics of the MUC-4 corpus are a limiting factor. The corpus is small and roles are similar from a template to another, which does not reflect reality.</p><p>A bigger corpus, even partially annotated but pre- senting a better variety of templates, could lead to very different approaches.</p><p>As we showed, our model comes with a unified representation of all types of relations. This opens the way to the use of multiple types of relations (syntactic, semantic, thematic, etc.) to refine the clusters.</p><p>Last but not least, the evaluation protocol, that became a kind of de facto standard, is very much imperfect. Most notably, the way of finally map- ping with reference slots can have a great influence on the results.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Entity representation as tuples of ([attributes], head, [triggers]).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Generative model for event induction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>BOMBING</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Model variants (Dirichlet priors are omitted for simplicity): 5a) HT model ran on single data. This model is equivalent to 5b) with T=1; 5b) HT model ran on multi data; 5c) HT+A model ran on single data; 5d) HT+A model ran on multi data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Variation of Chambers (2013) model: 6a) Original model; 6b) Original model + attribute distributions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head></head><label></label><figDesc>(paper values) 41 41 41 HT+A + doc. classification 36 54 43</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Comparison to state-of-the-art unsuper-
vised systems. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Performance on reimplementation of 
Chambers (2013). 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>This work was partially financed by the Foun-dation for Scientific Cooperation "Campus Paris-Saclay" (FSC) under the project Digiteo ASTRE No. 2013-0774D.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Generating Coherent Event Schemas at Scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niranjan</forename><surname>Balasubramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mausam</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 Conference on Empirical Methods in Natural Language Processing (EMNLP 2013)</title>
		<meeting><address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-10" />
			<biblScope unit="page" from="1721" to="1731" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Unsupervised Discovery of Event Scenarios from Texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cosmin Adrian Bejan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Twenty-First International Florida Artificial Intelligence Research Society Conference (FLAIRS 2008)</title>
		<meeting><address><addrLine>Coconut Grove, Florida</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="124" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Latent Dirichlet Allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Unsupervised Learning of Narrative Event Chains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL-08: HLT</title>
		<meeting><address><addrLine>Columbus, Ohio</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-06" />
			<biblScope unit="page" from="789" to="797" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Unsupervised Learning of Narrative Schemas and their Participants</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP (ACL-IJCNLP&apos;09)</title>
		<meeting><address><addrLine>Suntec, Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-08" />
			<biblScope unit="page" from="602" to="610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Template-Based Information Extraction without the Templates</title>
	</analytic>
	<monogr>
		<title level="m">49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL 2011)</title>
		<meeting><address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="976" to="986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Event Schema Induction with a Probabilistic Entity-Driven Model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-10" />
			<biblScope unit="page" from="1797" to="1807" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Probabilistic Frame Induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kit</forename><forename type="middle">Jackie</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoifung</forename><surname>Poon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucy</forename><surname>Vanderwende</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="837" to="846" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Automatic Template Creation for Information Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collier</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
		<respStmt>
			<orgName>University of Sheffield</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">An overview of the FRUMP system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerald</forename><surname>Dejong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Strategies for natural language processing</title>
		<editor>W. Lehnert and M. Ringle</editor>
		<imprint>
			<publisher>Lawrence Erlbaum Associates</publisher>
			<date type="published" when="1982" />
			<biblScope unit="page" from="149" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Unsupervised Relation Extraction From Web Documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathrin</forename><surname>Eichler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holmer</forename><surname>Hemsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G√ºnter</forename><surname>Neumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6 th Conference on Language Resources and Evaluation (LREC&apos;08), Marrakech</title>
		<meeting><address><addrLine>Morocco</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">An Aggregation Procedure for Building Episodic Memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Ferret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brigitte</forename><surname>Grau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">15 th International Joint Conference on Artificial Intelligence (IJCAI-97)</title>
		<meeting><address><addrLine>Nagoya, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="280" to="285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Automatic Creation of Domain Templates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Filatova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasileios</forename><surname>Hatzivassiloglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><surname>Mckeown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">21 st International Conference on Computational Linguistics and 44 th Annual Meeting of the Association for Computational Linguistics (COLING-ACL 2006)</title>
		<meeting><address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="207" to="214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Unsupervised Relation Learning for Event-Focused Question-Answering and Domain Modelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Filatova</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
		<respStmt>
			<orgName>Columbia University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Extreme Extraction-Machine Reading in a Week</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marjorie</forename><surname>Freedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lance</forename><surname>Ramshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elizabeth</forename><surname>Boschee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Gabbard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary</forename><surname>Kratkiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Weischedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods in Natural Language Processing</title>
		<meeting><address><addrLine>Edinburgh, Scotland, UK.</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-07" />
			<biblScope unit="page" from="1437" to="1446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A Hierarchical Bayesian Model for Unsupervised Induction of Script Knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lea</forename><surname>Frermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><surname>Pinkal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">14th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2014)</title>
		<meeting><address><addrLine>Gothenburg, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-04" />
			<biblScope unit="page" from="49" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Gibbs sampling in the generative model of Latent Dirichlet Allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Griffiths</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
		<respStmt>
			<orgName>Stanford University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An Information Extraction Customizer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">17th International Conference on Text</title>
		<editor>Petr Sojka, Ale Hork, Ivan Kopeek, and Karel Pala</editor>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">8655</biblScope>
			<biblScope unit="page" from="3" to="10" />
		</imprint>
	</monogr>
	<note>Speech and Dialogue (TSD 2014</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Message Understanding Conference-6: A Brief History</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beth</forename><surname>Sundheim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">16 th International Conference on Computational linguistics (COLING&apos;96)</title>
		<meeting><address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="466" to="471" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Incremental Topic Representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanda</forename><surname>Harabagiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th International Conference on Computational Linguistics (COLING&apos;04)</title>
		<meeting>the 20th International Conference on Computational Linguistics (COLING&apos;04)<address><addrLine>Geneva, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Discovering Relations among Named Entities from Large Corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takaaki</forename><surname>Hasegawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Sekine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">42 nd Meeting of the Association for Computational Linguistics (ACL&apos;04)</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="415" to="422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Text Segmentation and Graph-based Method for Template Filling in Information Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludovic</forename><surname>Jean-Louis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Romaric</forename><surname>Besanon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Ferret</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5 th International Joint Conference on Natural Language Processing</title>
		<meeting><address><addrLine>Chiang Mai, Thailand</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="723" to="731" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP Natural Language Processing Toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations<address><addrLine>Baltimore, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Ensemble Semantics for Largescale Unsupervised Relation Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuming</forename><surname>Bonan Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chinyew</forename><surname>Grishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<title level="m">Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL 2012</title>
		<meeting><address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="1027" to="1037" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Inducing neural models of script knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashutosh</forename><surname>Modi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eighteenth Conference on Computational Natural Language Learning</title>
		<meeting><address><addrLine>Ann Arbor, Michigan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="49" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Effective Information Extraction with Semantic Affinity Patterns and Relevant Regions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddharth</forename><surname>Patwardhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-06" />
			<biblScope unit="page" from="717" to="727" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A Unified Model of Phrasal and Sentential Evidence for Information Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddharth</forename><surname>Patwardhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the</title>
		<meeting>the</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
			</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="151" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Statistical script learning with multi-argument events</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Pichotta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">14th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2014)</title>
		<meeting><address><addrLine>Gothenburg, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="220" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Modeling Context in Scenario Template Creation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min-Yen</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Third International Joint Conference on Natural Language Processing</title>
		<meeting><address><addrLine>Hyderabad, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="157" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning Script Knowledge with Web Experiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michaela</forename><surname>Regneri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><surname>Pinkal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">48th Annual Meeting of the Association for Computational Linguistics (ACL 2010)</title>
		<meeting><address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-07" />
			<biblScope unit="page" from="979" to="988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Clustering for unsupervised relation identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Rosenfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronen</forename><surname>Feldman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sixteenth ACM conference on Conference on information and knowledge management (CIKM&apos;07)</title>
		<meeting><address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="411" to="418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Language and memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Roger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cognitive Science</title>
		<imprint>
			<date type="published" when="1980" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="243" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">On-demand information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Sekine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">21 st International Conference on Computational Linguistics and 44 th Annual Meeting of the Association for Computational Linguistics (COLING-ACL 2006)</title>
		<meeting><address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="731" to="738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Preemptive Information Extraction using Unrestricted Relation Discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuke</forename><surname>Shinyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Sekine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL 2006</title>
		<meeting><address><addrLine>New York City, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="304" to="311" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beth</forename><forename type="middle">M</forename><surname>Sundheim</surname></persName>
		</author>
		<title level="m">Third Message Understanding Evaluation and Conference</title>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Status Report</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Speech and Natural Language, HLT &apos;91</title>
		<meeting>the Workshop on Speech and Natural Language, HLT &apos;91</meeting>
		<imprint>
			<biblScope unit="page" from="301" to="305" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
