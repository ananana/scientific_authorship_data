<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:07+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Towards an Automatic Turing Test: Learning to Evaluate Dialogue Responses</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Noseworthy</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iulian</forename><forename type="middle">Vlad</forename><surname>Serban</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Angelard-Gontier</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
						</author>
						<title level="a" type="main">Towards an Automatic Turing Test: Learning to Evaluate Dialogue Responses</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</title>
						<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1116" to="1126"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-1103</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Automatically evaluating the quality of dialogue responses for unstructured domains is a challenging problem. Unfortunately, existing automatic evaluation metrics are biased and correlate very poorly with human judgements of response quality. Yet having an accurate automatic evaluation procedure is crucial for dialogue research, as it allows rapid prototyping and testing of new models with fewer expensive human evaluations. In response to this challenge, we formulate automatic dialogue evaluation as a learning problem. We present an evaluation model (ADEM) that learns to predict human-like scores to input responses, using a new dataset of human response scores. We show that the ADEM model&apos;s predictions correlate significantly, and at a level much higher than word-overlap met-rics such as BLEU, with human judgements at both the utterance and system-level. We also show that ADEM can generalize to evaluating dialogue models unseen during training, an important step for automatic dialogue evaluation.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Building systems that can naturally and meaning- fully converse with humans has been a central goal of artificial intelligence since the formulation of the Turing test <ref type="bibr" target="#b42">(Turing, 1950)</ref>. Research on one type of such systems, sometimes referred to as non-task-oriented dialogue systems, goes back to the mid-60s with Weizenbaum's famous program ELIZA: a rule-based system mimicking a Roge- rian psychotherapist by persistently either rephras- ing statements or asking questions (Weizenbaum, * Indicates equal contribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Context of Conversation</head><p>Speaker A: Hey, what do you want to do tonight? Speaker B: Why don't we go see a movie? Model Response Nah, let's do something active.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reference Response</head><p>Yeah, the film about Turing looks great! <ref type="figure">Figure 1</ref>: Example where word-overlap scores fail for dialogue evaluation; although the model response is reasonable, it has no words in common with the reference response, and thus would be given low scores by metrics such as <ref type="bibr">BLEU. 1966)</ref>. Recently, there has been a surge of inter- est towards building large-scale non-task-oriented dialogue systems using neural networks ( <ref type="bibr" target="#b40">Sordoni et al., 2015b;</ref><ref type="bibr" target="#b37">Shang et al., 2015;</ref><ref type="bibr" target="#b43">Vinyals and Le, 2015;</ref><ref type="bibr" target="#b35">Serban et al., 2016a;</ref><ref type="bibr" target="#b37">Li et al., 2015</ref>). These models are trained in an end-to-end manner to op- timize a single objective, usually the likelihood of generating the responses from a fixed corpus. Such models have already had a substantial im- pact in industry, including Google's Smart Reply system ( <ref type="bibr" target="#b19">Kannan et al., 2016)</ref>, and Microsoft's Xi- aoice chatbot <ref type="bibr" target="#b29">(Markoff and Mozur, 2015)</ref>, which has over 20 million users.</p><p>One of the challenges when developing such sys- tems is to have a good way of measuring progress, in this case the performance of the chatbot. The Turing test provides one solution to the evaluation of dialogue systems, but there are limitations with its original formulation. The test requires live hu- man interactions, which is expensive and difficult to scale up. Furthermore, the test requires carefully designing the instructions to the human interlocu- tors, in order to balance their behaviour and ex- pectations so that different systems may be ranked accurately by performance. Although unavoidable, these instructions introduce bias into the evaluation measure. The more common approach of having humans evaluate the quality of dialogue system responses, rather than distinguish them from hu- man responses, induces similar drawbacks in terms of time, expense, and lack of scalability. In the case of chatbots designed for specific conversation domains, it may also be difficult to find sufficient human evaluators with appropriate background in the topic ( <ref type="bibr" target="#b27">Lowe et al., 2015</ref>).</p><p>Despite advances in neural network-based mod- els, evaluating the quality of dialogue responses automatically remains a challenging and under- studied problem in the non-task-oriented setting. The most widely used metric for evaluating such dialogue systems is BLEU ( <ref type="bibr" target="#b31">Papineni et al., 2002</ref>), a metric measuring word overlaps originally devel- oped for machine translation. However, it has been shown that BLEU and other word-overlap metrics are biased and correlate poorly with human judge- ments of response quality ( <ref type="bibr" target="#b26">Liu et al., 2016)</ref>. There are many obvious cases where these metrics fail, as they are often incapable of considering the se- mantic similarity between responses (see <ref type="figure">Figure 1</ref>). Despite this, many researchers still use BLEU to evaluate their dialogue models ( <ref type="bibr" target="#b33">Ritter et al., 2011;</ref><ref type="bibr" target="#b40">Sordoni et al., 2015b;</ref><ref type="bibr" target="#b37">Li et al., 2015;</ref><ref type="bibr" target="#b22">Galley et al., 2015;</ref><ref type="bibr" target="#b23">Li et al., 2016a</ref>), as there are few alternatives available that correlate with human judgements. While human evaluation should always be used to evaluate dialogue models, it is often too expensive and time-consuming to do this for every model specification (for example, for every combination of model hyperparameters). Therefore, having an accurate model that can evaluate dialogue response quality automatically -what could be considered an automatic Turing test -is critical in the quest for building human-like dialogue agents.</p><p>To make progress towards this goal, we make the simplifying assumption that a 'good' chatbot is one whose responses are scored highly on ap- propriateness by human evaluators. We believe this is sufficient for making progress as current dialogue systems often generate inappropriate re- sponses. We also find empirically that asking evaluators for other metrics results in either low inter-annotator agreement, or the scores are highly correlated with appropriateness (see supp. mate- rial). Thus, we collect a dataset of appropriateness scores to various dialogue responses, and we use this dataset to train an automatic dialogue evalu- ation model (ADEM). The model is trained in a semi-supervised manner using a hierarchical recur-  <ref type="table">Table 1</ref>: Statistics of the dialogue response evalua- tion dataset. Each example is in the form (context, model response, reference response, human score). rent neural network (RNN) to predict human scores. We show that ADEM scores correlate significantly with human judgement at both the utterance-level and system-level. We also show that ADEM can of- ten generalize to evaluating new models, whose responses were unseen during training, making ADEM a strong first step towards effective auto- matic dialogue response evaluation. <ref type="bibr">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data Collection</head><p>To train a model to predict human scores to dia- logue responses, we first collect a dataset of human judgements (scores) of Twitter responses using the crowdsourcing platform Amazon Mechanical Turk (AMT). <ref type="bibr">2</ref> The aim is to have accurate human scores for a variety of conversational responses -con- ditioned on dialogue contexts -which span the full range of response qualities. For example, the responses should include both relevant and irrel- evant responses, both coherent and non-coherent responses and so on. To achieve this variety, we use candidate responses from several different models. Following ( <ref type="bibr" target="#b26">Liu et al., 2016)</ref>, we use the following 4 sources of candidate responses: (1) a response selected by a TF-IDF retrieval-based model, (2) a response selected by the Dual Encoder (DE) (Lowe et al., 2015), (3) a response generated using the hier- archical recurrent encoder-decoder (HRED) model <ref type="bibr" target="#b35">(Serban et al., 2016a)</ref>, and (4) human-generated responses. It should be noted that the human- generated candidate responses are not the reference responses from a fixed corpus, but novel human responses that are different from the reference. In addition to increasing response variety, this is nec- essary because we want our evaluation model to learn to compare the reference responses to the candidate responses. We provide the details of our AMT experiments in the supplemental material, in- cluding additional experiments suggesting that sev- eral other metrics are currently unlikely to be useful for building evaluation models. Note that, in order to maximize the number of responses obtained with a fixed budget, we only obtain one evaluation score per dialogue response in the dataset.</p><p>To train evaluation models on human judge- ments, it is crucial that we obtain scores of re- sponses that lie near the distribution produced by advanced models. This is why we use the Twitter Corpus ( <ref type="bibr" target="#b33">Ritter et al., 2011)</ref>, as such models are pre-trained and readily available. Further, the set of topics discussed is quite broad -as opposed to the very specific Ubuntu Dialogue Corpus ( <ref type="bibr" target="#b27">Lowe et al., 2015)</ref> -and therefore the model may also be suited to other chit-chat domains. Finally, since it does not require domain specific knowledge (e.g. technical knowledge), it should be easy for AMT workers to annotate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Technical Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Recurrent Neural Networks</head><p>Recurrent neural networks (RNNs) are a type of neural network with time-delayed connections be- tween the internal units. This leads to the formation of a hidden state h t , which is updated for every in- put:</p><formula xml:id="formula_0">h t = f (W hh h t−1 + W ih x t )</formula><p>, where W hh and W ih are parameter matrices, f is a non-linear acti- vation function such as tanh, and x t is the input at time t. The hidden state allows for RNNs to better model sequential data, such as language.</p><p>In this paper, we consider RNNs augmented with long-short term memory (LSTM) units <ref type="bibr" target="#b17">(Hochreiter and Schmidhuber, 1997</ref>). LSTMs add a set of gates to the RNN that allow it to learn how much to update the hidden state. LSTMs are one of the most well-established methods for dealing with the vanishing gradient problem in recurrent net- works <ref type="bibr" target="#b16">(Hochreiter, 1991;</ref><ref type="bibr" target="#b3">Bengio et al., 1994)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Word-Overlap Metrics</head><p>One of the most popular approaches for automati- cally evaluating the quality of dialogue responses is by computing their word overlap with the ref- erence response. In particular, the most popular metrics are the BLEU and METEOR scores used for machine translation, and the ROUGE score used for automatic summarization. While these metrics tend to correlate with human judgements in their target domains, they have recently been shown to highly biased and correlate very poorly with human judgements for dialogue response evaluation ( <ref type="bibr" target="#b26">Liu et al., 2016</ref>). We briefly describe BLEU here, and provide a more detailed summary of word-overlap metrics in the supplemental material.</p><p>BLEU BLEU ( <ref type="bibr" target="#b31">Papineni et al., 2002</ref>) analyzes the co-occurrences of n-grams in the reference and the proposed responses. It computes the n-gram preci- sion for the whole dataset, which is then multiplied by a brevity penalty to penalize short translations. For BLEU-N , N denotes the largest value of n- grams considered (usually N = 4).</p><p>Drawbacks One of the major drawbacks of word-overlap metrics is their failure in capturing the semantic similarity (and other structure) be- tween the model and reference responses when there are few or no common words. This problem is less critical for machine translation; since the set of reasonable translations of a given sentence or document is rather small, one can reasonably infer the quality of a translated sentence by only measuring the word-overlap between it and one (or a few) reference translations. However, in dialogue, the set of appropriate responses given a context is much larger ( <ref type="bibr" target="#b1">Artstein et al., 2009)</ref>; in other words, there is a very high response diversity that is un- likely to be captured by word-overlap comparison to a single response.</p><p>Further, word-overlap scores are computed di- rectly between the model and reference responses. As such, they do not consider the context of the conversation. While this may be a reasonable as- sumption in machine translation, it is not the case for dialogue; whether a model response is an ade- quate substitute for the reference response is clearly context-dependent. For example, the two responses in <ref type="figure">Figure 1</ref> are equally appropriate given the con- text. However, if we simply change the context to: "Have you heard of any good movies recently?", the model response is no longer relevant while the reference response remains valid.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">An Automatic Dialogue Evaluation</head><p>Model (ADEM)</p><p>To overcome the problems of evaluation with word- overlap metrics, we aim to construct a dialogue evaluation model that: (1) captures semantic sim- ilarity beyond word overlap statistics, and (2) ex- ploits both the context and the reference response to calculate its score for the model response. We call this evaluation model ADEM. ADEM learns distributed representations of the context, model response, and reference response using a hierarchical RNN encoder. Given the dia- logue context c, reference response r, and model responsê r, ADEM first encodes each of them into vectors (c, ˆ r, and r, respectively) using the RNN encoder. Then, ADEM computes the score using a dot-product between the vector representations of c, r, andˆrandˆ andˆr in a linearly transformed space: :</p><formula xml:id="formula_1">score(c, r, ˆ r) = (c T MˆrMˆr + r T NˆrNˆr − α)/β (1)</formula><p>where M, N ∈ R n are learned matrices initialized to the identity, and α, β are scalar constants used to initialize the model's predictions in the range <ref type="bibr">[1,</ref><ref type="bibr">5]</ref>.</p><p>The model is shown in <ref type="figure" target="#fig_0">Figure 2</ref>.</p><p>The matrices M and N can be interpreted as linear projections that map the model responsê r into the space of contexts and reference responses, respectively. The model gives high scores to re- sponses that have similar vector representations to the context and reference response after this projec- tion. The model is end-to-end differentiable; all the parameters can be learned by backpropagation. In our implementation, the parameters θ = {M, N } of the model are trained to minimize the squared error between the model predictions and the human score, with L2-regularization:</p><formula xml:id="formula_2">L = i=1:K [score(c i , r i , ˆ r i ) − human i ] 2 + γ||θ|| 2</formula><p>(2) where γ is a scalar constant. The simplicity of our model leads to both accurate predictions and fast evaluation (see supp. material), which is important to allow rapid prototyping of dialogue systems.</p><p>The hierarchical RNN encoder in our model con- sists of two layers of RNNs <ref type="bibr" target="#b10">(El Hihi and Bengio, 1995;</ref><ref type="bibr" target="#b39">Sordoni et al., 2015a</ref>). The lower-level RNN, the utterance-level encoder, takes as input words from the dialogue, and produces a vector output at the end of each utterance. The context-level en- coder takes the representation of each utterance as input and outputs a vector representation of the context. This hierarchical structure is useful for incorporating information from early utterances in the context ( <ref type="bibr" target="#b35">Serban et al., 2016a)</ref>. Following pre- vious work, we take the last hidden state of the context-level encoder as the vector representation of the input utterance or context. The parameters of the RNN encoder are pretrained and are not learned from the human scores.</p><p>An important point is that the ADEM procedure above is not a dialogue retrieval model: the funda- mental difference is that ADEM has access to the reference response. Thus, ADEM can compare a model's response to a known good response, which is significantly easier than inferring response qual- ity from solely the context.</p><p>Pre-training with VHRED We would like an evaluation model that can make accurate predic- tions from few labeled examples, since these exam- ples are expensive to obtain. We therefore employ semi-supervised learning, and use a pre-training procedure to learn the parameters of the encoder. In particular, we train the encoder as part of a neu- ral dialogue model; we attach a third decoder RNN that takes the output of the encoder as input, and train it to predict the next utterance of a dialogue conditioned on the context. The dialogue model we employ for pre-training is the latent variable hierarchical recurrent encoder- decoder (VHRED) model <ref type="bibr" target="#b36">(Serban et al., 2016b</ref>), shown in <ref type="figure" target="#fig_1">Figure 3</ref>. The VHRED model is an exten- sion of the original hierarchical recurrent encoder- decoder (HRED) model (Serban et al., 2016a) with a turn-level stochastic latent variable. The dialogue context is encoded into a vector using our hierarchi- cal encoder, and the VHRED then samples a Gaus- sian variable that is used to condition the decoder (see supplemental material for further details). Af- ter training VHRED, we use the last hidden state of the context-level encoder, when c, r, andˆrandˆ andˆr are fed as input, as the vector representations for c, r, andˆrandˆandˆr, respectively. We use representations from the VHRED model as it produces more diverse and coherent responses compared to HRED.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Procedure</head><p>In order to reduce the effective vocabulary size, we use byte pair encoding (BPE) <ref type="bibr" target="#b11">(Gage, 1994;</ref><ref type="bibr" target="#b34">Sennrich et al., 2015)</ref>, which splits each word into sub-words or characters. We also use layer normal- ization ( <ref type="bibr">Ba et al., 2016</ref>) for the hierarchical encoder, which we found worked better at the task of dia- logue generation than the related recurrent batch normalization ( <ref type="bibr" target="#b18">Ioffe and Szegedy, 2015;</ref><ref type="bibr" target="#b6">Cooijmans et al., 2016)</ref>. To train the VHRED model, we employed several of the same techniques found in (Serban et al., 2016b) and (Bowman et al., 2016): we drop words in the decoder with a fixed rate of 25%, and we anneal the KL-divergence term lin- early from 0 to 1 over the first 60,000 batches. We use Adam as our optimizer ( <ref type="bibr" target="#b21">Kingma and Ba, 2014)</ref>.</p><p>When training ADEM, we also employ a sub- sampling procedure based on the model response length. In particular, we divide the training exam- ples into bins based on the number of words in a response and the score of that response. We then over-sample from bins across the same score to ensure that ADEM does not use response length to predict the score. This is because humans have a tendency to give a higher rating to shorter responses than to longer responses ( <ref type="bibr" target="#b36">Serban et al., 2016b</ref>), as shorter responses are often more generic and thus are more likely to be suitable to the context. Indeed, the test set Pearson correlation between response length and human score is 0.27.</p><p>For training VHRED, we use a context em- bedding size of 2000. However, we found the ADEM model learned more effectively when this embedding size was reduced. Thus, after train- ing VHRED, we use principal component analysis (PCA) <ref type="bibr" target="#b32">(Pearson, 1901)</ref> to reduce the dimensional- ity of the context, model response, and reference response embeddings to n. We found experimen- tally that n = 50 provided the best performance.</p><p>When training our models, we conduct early stopping on a separate validation set. For the eval- uation dataset, we split the train/ validation/ test sets such that there is no context overlap (i.e. the contexts in the test set are unseen during training).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results</head><p>Utterance-level correlations We first present new utterance-level correlation results 3 for existing    <ref type="bibr" target="#b8">Dhingra et al., 2016)</ref>, and 'VHRED' indicates the dot product of VHRED embeddings (i.e. ADEM at initialization). C-and R-ADEM represent the ADEM model trained to only compare the model response to the context or reference response, respectively. We compute the baseline metric scores (top) on the full dataset to provide a more accurate estimate of their scores (as they are not trained on a training set).</p><p>word-overlap metrics, in addition to results with embedding baselines and ADEM, in <ref type="table" target="#tab_1">Table 2</ref>. The baseline metrics are evaluated on the entire dataset of 4,104 responses to provide the most accurate estimate of the score. <ref type="bibr">4</ref> We measure the correlation for ADEM on the validation and test sets, which constitute 616 responses each.</p><p>We also conduct an analysis of the response data from ( <ref type="bibr" target="#b26">Liu et al., 2016)</ref>, where the pre-processing is standardized by removing '&lt;first speaker&gt;' to- kens at the beginning of each utterance. The results are detailed in the supplemental material. We can observe from both this data, and the new data in <ref type="table" target="#tab_1">Table 2</ref>, that the correlations for the word-overlap metrics are even lower than estimated in previous scores. <ref type="bibr">4</ref> Note that our word-overlap correlation results in <ref type="table" target="#tab_1">Table  2</ref> are also lower than those presented in ( <ref type="bibr" target="#b22">Galley et al., 2015)</ref>. This is because Galley et al. measure corpus-level correlation, i.e. correlation averaged across different subsets (of size 100) of the data, and pre-filter for high-quality reference responses. studies ( <ref type="bibr" target="#b26">Liu et al., 2016;</ref><ref type="bibr" target="#b22">Galley et al., 2015</ref>). In particular, this is the case for BLEU-4, which has frequently been used for dialogue response evalu- ation ( <ref type="bibr" target="#b33">Ritter et al., 2011;</ref><ref type="bibr" target="#b40">Sordoni et al., 2015b;</ref><ref type="bibr" target="#b37">Li et al., 2015;</ref><ref type="bibr" target="#b22">Galley et al., 2015;</ref><ref type="bibr" target="#b23">Li et al., 2016a</ref>).</p><p>We can see from <ref type="table" target="#tab_1">Table 2</ref> that ADEM correlates far better with human judgement than the word- overlap baselines. This is further illustrated by the scatterplots in <ref type="figure" target="#fig_2">Figure 4</ref>. We also compare with ADEM using tweet2vec embeddings ( <ref type="bibr" target="#b8">Dhingra et al., 2016)</ref>. In this case, instead of using the VHRED pre-training method presented in Section 4, we use off-the-shelf embeddings for c, r, andˆrandˆandˆr, and fine- tune M and N on our dataset. These tweet2vec em- beddings are computed at the character-level with a bidirectional GRU on a Twitter dataset for hash- tag prediction ( <ref type="bibr" target="#b8">Dhingra et al., 2016)</ref>. We find that they obtain reasonable but inferior performance compared to using VHRED embeddings. System-level correlations We show the system- level correlations for various metrics in <ref type="table">Table 3</ref>, and present it visually in <ref type="figure" target="#fig_4">Figure 5</ref>. Each point in the scatterplots represents a dialogue model; hu- mans give low scores to TFIDF and DE responses, higher scores to HRED and the highest scores to other human responses. It is clear that existing word-overlap metrics are incapable of capturing this relationship for even 4 models. This renders them completely deficient for dialogue evaluation. However, ADEM produces almost the same model ranking as humans, achieving a significant Pearson correlation of 0.954. <ref type="bibr">5</ref> Thus, ADEM correlates well with humans both at the response and system level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generalization to previously unseen models</head><p>When ADEM is used in practice, it will take as input responses from a new model that it has not seen during training. Thus, it is crucial that ADEM correlates with human judgements for new models. We test ADEM's generalization ability by perform- ing a leave-one-out evaluation. For each dialogue model that was the source of response data for training ADEM (TF-IDF, Dual Encoder, HRED, hu- mans), we conduct an experiment where we train on all model responses except those from the cho- sen model, and test only on the model that was unseen during training.</p><p>The results are given in <ref type="table">Table 4</ref>. We observe that the ADEM model is able to generalize for all models except the Dual Encoder. This is partic- ularly surprising for the HRED model; in this case, ADEM was trained only on responses that were written by humans (from retrieval models or human-generated), but is able to generalize to responses produced by a generative neural net- work model. When testing on the entire test set,  <ref type="table">Table 3</ref>: System-level correlation, with the p-value in brackets.</p><p>the model achieves comparable correlations to the ADEM model that was trained on 25% less data selected at random.</p><p>Qualitative Analysis To illustrate some strengths and weaknesses of ADEM, we show human and ADEM scores for each of the responses to various contexts in <ref type="table" target="#tab_3">Table 5</ref>. There are several instances where ADEM predicts accurately: in particular, ADEM is often very good at assigning low scores to poor responses. This seen in the first two contexts, where most of the responses given a score of 1 from humans are given scores less than 2 by ADEM. The single exception in response (4) for the second context seems somewhat appropriate and should perhaps have been scored higher by the human evaluator. There are also several instances where the model assigns high scores to suitable responses, as in the first two contexts.</p><p>One drawback we observed is that ADEM tends to be too conservative when predicting response scores. This is the case in the third context, where the model assigns low scores to most of the re- sponses that a human rated highly. This behaviour is likely due to the squared error loss used to train ADEM; since the model receives a large penalty for incorrectly predicting an extreme value, it learns to predict scores closer to the average human score. We provide many more experiments, including in- vestigation of evaluation speed, learning curves, data efficiency, a failure analysis, and the primary source of improvement over word-overlap metrics  <ref type="table">Table 4</ref>: Correlation for ADEM when various model responses are removed from the training set. The left two columns show performance on the entire test set, and the right two columns show performance on responses only from the dialogue model not seen during training. The last row (25% at random) corresponds to the ADEM model trained on all model responses, but with the same amount of training data as the model above (i.e. 25% less data than the full training set).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Context</head><p>Reference response Model responses Human score ADEM score photo to see my television debut go to - some. some on &lt;url&gt; -hehe &lt;url&gt; → it really was you? i thought ppl were rec- ognizing someone who looked like you! were the oysters worth the wait? yeah it was me . haha i 'd kinda forgotten about it it was filmed a while ago  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Related to our approach is the literature on novel methods for the evaluation of machine translation systems, especially through the WMT evaluation task <ref type="bibr" target="#b5">(Callison-Burch et al., 2011;</ref><ref type="bibr" target="#b28">Machácek and Bojar, 2014;</ref><ref type="bibr" target="#b41">Stanojevic et al., 2015)</ref>. In particu- lar, <ref type="bibr" target="#b0">(Albrecht and Hwa, 2007;</ref><ref type="bibr" target="#b14">Gupta et al., 2015)</ref> have proposed to evaluate machine translation sys- tems using Regression and Tree-LSTMs respec- tively. Their approach differs from ours as, in the dialogue domain, we must additionally condition our score on the context of the conversation, which is not necessary in translation.</p><p>There has also been related work on estimating the quality of responses in chat-oriented dialogue systems. <ref type="bibr" target="#b7">(DeVault et al., 2011</ref>) train an automatic dialogue policy evaluation metric from 19 struc- tured role-playing sessions, enriched with para- phrases and external referee annotations. ( <ref type="bibr" target="#b13">Gandhe and Traum, 2016)</ref> propose a semi-automatic eval- uation metric for dialogue coherence, similar to BLEU and ROUGE, based on 'wizard of Oz' type data. <ref type="bibr">6 (Xiang et al., 2014</ref>) propose a framework to predict utterance-level problematic situations in a dataset of Chinese dialogues using intent and sen- timent factors. Finally, ( <ref type="bibr" target="#b15">Higashinaka et al., 2014</ref>) train a classifier to distinguish user utterances from system-generated utterances using various dialogue features, such as dialogue acts, question types, and predicate-argument structures.</p><p>Several recent approaches use hand-crafted re- ward features to train dialogue models using rein- forcement learning (RL). For example, ( <ref type="bibr" target="#b25">Li et al., 2016b</ref>) use features related to ease of answering and information flow, and ( <ref type="bibr" target="#b47">Yu et al., 2016)</ref> use metrics related to turn-level appropriateness and conversational depth. These metrics are based on hand-crafted features, which only capture a small set of relevant aspects; this inevitably leads to sub- optimal performance, and it is unclear whether such objectives are preferable over retrieval-based cross- entropy or word-level maximum log-likelihood ob- jectives. Furthermore, many of these metrics are computed at the conversation-level, and are not available for evaluating single dialogue responses.</p><p>The metrics that can be computed at the response- level could be incorporated into our framework, for example by adding a term to equation 1 consisting of a dot product between these features and a vector of learned parameters.</p><p>There has been significant work on evaluation methods for task-oriented dialogue systems, which attempt to solve a user's task such as finding a restaurant. These methods include the PARADISE framework ( <ref type="bibr" target="#b44">Walker et al., 1997</ref>) and <ref type="bibr">MeMo (Möller et al., 2006</ref>), which consider a task completion signal. PARADISE in particular is perhaps the first work on learning an automatic evaluation func- tion for dialogue, accomplished through linear re- gression. However, PARADISE requires that one can measure task completion and task complexity, which are not available in our setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Discussion</head><p>We use the Twitter Corpus to train our models as it contains a broad range of non-task-oriented conver- sations and it has been used to train many state-of- the-art models. However, our model could easily be extended to other general-purpose datasets, such as Reddit, once similar pre-trained models become publicly available. Such models are necessary even for creating a test set in a new domain, which will help us determine if ADEM generalizes to related di- alogue domains. We leave investigating the domain transfer ability of ADEM for future work.</p><p>The evaluation model proposed in this paper favours dialogue models that generate responses that are rated as highly appropriate by humans. It is likely that this property does not fully capture the desired end-goal of chatbot systems. For example, one issue with building models to approximate hu- man judgements of response quality is the problem of generic responses. Since humans often provide high scores to generic responses due to their appro- priateness for many given contexts ( <ref type="bibr" target="#b38">Shang et al., 2016)</ref>, a model trained to predict these scores will exhibit the same behaviour. An important direc- tion for future work is modifying ADEM such that it is not subject to this bias. This could be done, for example, by censoring ADEM's representations <ref type="bibr" target="#b9">(Edwards and Storkey, 2016</ref>) such that they do not contain any information about length. Alterna- tively, one can combine this with an adversarial evaluation model <ref type="bibr" target="#b20">(Kannan and Vinyals, 2017;</ref><ref type="bibr" target="#b24">Li et al., 2017</ref>) that assigns a score based on how easy it is to distinguish the dialogue model responses from human responses. In this case, a model that generates generic responses will easily be distin- guishable and obtain a low score.</p><p>An important direction of future research is building models that can evaluate the capability of a dialogue system to have an engaging and mean- ingful interaction with a human. Compared to eval- uating a single response, this evaluation is arguably closer to the end-goal of chatbots. However, such an evaluation is extremely challenging to do in a completely automatic way. We view the evaluation procedure presented in this paper as an important step towards this goal; current dialogue systems are incapable of generating responses that are rated as highly appropriate by humans, and we believe our evaluation model will be useful for measuring and facilitating progress in this direction.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The ADEM model, which uses a hierarchical encoder to produce the context embedding c.</figDesc><graphic url="image-1.png" coords="4,72.00,62.81,453.53,117.51" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The VHRED model used for pre-training. The hierarchical structure of the RNN encoder is shown in the red box around the bottom half of the figure. After training using the VHRED procedure, the last hidden state of the context-level encoder is used as a vector representation of the input text.</figDesc><graphic url="image-2.png" coords="5,117.36,62.80,362.83,209.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Scatter plot showing model against human scores, for BLEU-2 and ROUGE on the full dataset, and ADEM on the test set. We add Gaussian noise drawn from N (0, 0.3) to the integer human scores to better visualize the density of points, at the expense of appearing less correlated.</figDesc><graphic url="image-3.png" coords="6,81.97,62.81,137.87,103.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Scatterplots depicting the system-level correlation results for ADEM, BLEU-2, BLEU-4,and ROUGE on the test set. Each point represents the average scores for the responses from a dialogue model (TFIDF, DE, HRED, human). Human scores are shown on the horizontal axis, with normalized metric scores on the vertical axis. The ideal metric has a perfectly linear relationship.</figDesc><graphic url="image-6.png" coords="7,100.40,62.81,396.74,77.11" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>1</head><label></label><figDesc>) i'm not sure. i just don't know what to do with it. 2) you heard the horsepower productions remix of lee scratch perry's 'exercising' off his 'mighty upsetter' album? 3) you wont chug a fuzzy peach navelbeat call of duty!! → want a cookie? → yes!! → come get it im in kenmore at the moment 1) i'm gonna get a new phone some moro 2) no way man. 3) wow i just got a free pizza coupon! get yours before theres no more! &lt;url&gt; 4) i'm going to go to the mall.i out of twitter jail yet? testing → yeah. i posted bail → thanks. i am a right chatter tweetbox on sundays. same happened last sunday lol any news on meeting our user ? i go to the us on friday and i don 't want to miss anything arranged 1) i'm not sure if i'm going to be able to get it. 2) good to see another mac user in the leadership ranks 3) awww poor baby hope u get to feeling better soon. maybe some many work days at piedmont 4) did you tweet too much?</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Correlation between metrics and human judgements, with p-values shown in brackets. 'ADEM (T2V)' indicates ADEM with tweet2vec embeddings (</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 5 :</head><label>5</label><figDesc>Examples of scores given by the ADEM model. in the supplemental material.</figDesc><table></table></figure>

			<note place="foot" n="1"> Code and trained model parameters are available online: https://github.com/mike-n-7/ADEM. 2 All data collection was conducted in accordance with the policies of the host institutions&apos; ethics board.</note>

			<note place="foot" n="3"> We present both the Spearman correlation (computed on ranks, depicts monotonic relationships) and Pearson correlation (computed on true values, depicts linear relationships)</note>

			<note place="foot" n="5"> For comparison, BLEU achieves a system-level correlation of 0.99 on 5 models in the translation domain (Papineni et al., 2002).</note>

			<note place="foot" n="6"> In &apos;wizard of Oz&apos; scenarios, humans play the role of the dialogue system, usually unbeknown to the interlocutors.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Regression for sentence-level mt evaluation with pseudo references</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Albrecht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Hwa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Semi-formal evaluation of conversational characters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><surname>Artstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sudeep</forename><surname>Gandhe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jillian</forename><surname>Gerten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Leuski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Traum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Languages: From Formal to Natural</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="22" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><forename type="middle">Lei</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><forename type="middle">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.06450</idno>
		<imprint/>
	</monogr>
<note type="report_type">ton. 2016. Layer normalization. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning long-term dependencies with gradient descent is difficult</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrice</forename><surname>Simard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Frasconi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on neural networks</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="157" to="166" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Generating sentences from a continuous space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Samuel R Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vilnis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafal</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>COLING</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Findings of the 2011 workshop on statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omar</forename><forename type="middle">F</forename><surname>Zaidan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Workshop on Statistical Machine Translation</title>
		<meeting>the Sixth Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="22" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Cooijmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Ballas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">César</forename><surname>Laurent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.09025</idno>
		<title level="m">Recurrent batch normalization</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Toward learning and evaluation of dialogue policies with text examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Devault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Leuski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Sagae</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGDIAL 2011 Conference. Association for Computational Linguistics</title>
		<meeting>the SIGDIAL 2011 Conference. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="39" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Tweet2vec: Character-based distributed representations for social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhuwan</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dylan</forename><surname>Fitzpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Muehl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William W</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.03481</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Censoring representations with an adversary</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harrison</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amos</forename><surname>Storkey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>ICLR</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Hierarchical recurrent neural networks for long-term dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">El</forename><surname>Salah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Hihi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS. Citeseer</title>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="volume">400</biblScope>
			<biblScope unit="page">409</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A new algorithm for data compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Gage</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The C Users Journal</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="23" to="38" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.06863</idno>
		<title level="m">Chris Quirk, Margaret Mitchell, Jianfeng Gao, and Bill Dolan. 2015. deltableu: A discriminative metric for generation tasks with intrinsically diverse targets</title>
		<imprint/>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A semiautomated evaluation metric for dialogue model coherence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sudeep</forename><surname>Gandhe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Traum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Situated Dialog in Speech-Based Human-Computer Interaction</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="217" to="225" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Reval: A simple and effective machine translation evaluation metric based on recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohit</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Constantin</forename><surname>Orasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Van Genabith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Evaluating coherence in open domain conversational systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryuichiro</forename><surname>Higashinaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toyomi</forename><surname>Meguro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Imamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroaki</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshiro</forename><surname>Makino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshihiro</forename><surname>Matsuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="130" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Untersuchungen zu dynamischen neuronalen netzen. Diploma, Technische Universität München page 91</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.03167</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Smart reply: Automated response suggestion for email</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anjuli</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karol</forename><surname>Kurach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujith</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Kaufmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Tomkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balint</forename><surname>Miklos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">László</forename><surname>Lukács</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marina</forename><surname>Ganea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGKDD Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the ACM SIGKDD Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="495" to="503" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Adversarial evaluation of dialogue models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anjuli</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.08198</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1510.03055</idno>
		<title level="m">A diversity-promoting objective function for neural conversation models</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">A persona-based neural conversation model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.06155</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Learning to decode for future success</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Monroe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.06549</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Deep reinforcement learning for dialogue generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Monroe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.01541</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">How not to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chia-Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Iulian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Noseworthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pineau</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.08023</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nissan</forename><surname>Pow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iulian</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.08909</idno>
		<title level="m">The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Results of the wmt14 metrics shared task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matouš</forename><surname>Machácek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Bojar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth Workshop on Statistical Machine Translation. Citeseer</title>
		<meeting>the Ninth Workshop on Statistical Machine Translation. Citeseer</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="293" to="301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">For sympathetic ear, more chinese turn to smartphone program</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Markoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mozur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NY Times</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Memo: towards automatic usability evaluation of spoken dialogue services by user error simulations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Möller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roman</forename><surname>Englert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus-Peter</forename><surname>Engelbrecht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Verena</forename><forename type="middle">Vanessa</forename><surname>Hafner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Jameson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antti</forename><surname>Oulasvirta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH</title>
		<meeting><address><addrLine>Alexander Raake, and Norbert Reithinger</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th annual meeting on association for computational linguistics</title>
		<meeting>the 40th annual meeting on association for computational linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Principal components analysis. The London</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Pearson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Edinburgh and Dublin Philosophical Magazine and Journal</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">566</biblScope>
			<date type="published" when="1901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Data-driven response generation in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William B</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the conference on empirical methods in natural language processing</title>
		<meeting>the conference on empirical methods in natural language processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="583" to="593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1508.07909</idno>
		<title level="m">Neural machine translation of rare words with subword units</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Building end-to-end dialogue systems using generative hierarchical neural network models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Iulian Vlad Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3776" to="3784" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">A hierarchical latent variable encoder-decoder model for generating dialogues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Iulian Vlad Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.06069</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifeng</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02364</idno>
		<title level="m">Neural responding machine for short-text conversation</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Overview of the ntcir-12 short text conversation task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifeng</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tetsuya</forename><surname>Sakai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryuichiro</forename><surname>Higashinaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuke</forename><surname>Miyao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NTCIR-12 pages</title>
		<meeting>NTCIR-12 pages</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="473" to="484" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A hierarchical recurrent encoderdecoder for generative context-aware query suggestion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hossein</forename><surname>Vahabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christina</forename><surname>Lioma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><forename type="middle">Grue</forename><surname>Simonsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianyun</forename><surname>Nie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM International on Conference on Information and Knowledge Management</title>
		<meeting>the 24th ACM International on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="553" to="562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">A neural network approach to context-sensitive generation of conversational responses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.06714</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Results of the wmt15 metrics shared task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miloš</forename><surname>Stanojevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Kamran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Bojar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth Workshop on Statistical Machine Translation</title>
		<meeting>the Tenth Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="256" to="273" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Computing machinery and intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">M</forename><surname>Turing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mind</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">236</biblScope>
			<biblScope unit="page" from="433" to="460" />
			<date type="published" when="1950" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.05869</idno>
		<title level="m">A neural conversational model</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Paradise: A framework for evaluating spoken dialogue agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Marilyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><forename type="middle">J</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Candace</forename><forename type="middle">A</forename><surname>Litman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alicia</forename><surname>Kamm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Abella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the eighth conference on European chapter of the Association for Computational Linguistics. Association for Computational Linguistics</title>
		<meeting>the eighth conference on European chapter of the Association for Computational Linguistics. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="271" to="280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">ELIZAa computer program for the study of natural language communication between man and machine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weizenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="36" to="45" />
			<date type="published" when="1966" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Problematic situation analysis and automatic recognition for chi-nese online conversational system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaoyun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoqiang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Qin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CLP pages</title>
		<meeting>CLP pages</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="43" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Strategy and policy learning for nontask-oriented conversational systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhou</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziyu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">W</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><forename type="middle">I</forename><surname>Rudnicky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">17th Annual Meeting of the Special Interest Group on Discourse and Dialogue</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">404</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
