<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T13:00+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">RBPB: Regularization-Based Pattern Balancing Method for Event Extraction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sha</forename><surname>Lei</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Ministry of Education School of Electronics Engineering and Computer Science</orgName>
								<orgName type="laboratory">Key Laboratory of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Ministry of Education School of Electronics Engineering and Computer Science</orgName>
								<orgName type="laboratory">Key Laboratory of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Ministry of Education School of Electronics Engineering and Computer Science</orgName>
								<orgName type="laboratory">Key Laboratory of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujian</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Ministry of Education School of Electronics Engineering and Computer Science</orgName>
								<orgName type="laboratory">Key Laboratory of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baobao</forename><surname>Chang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Ministry of Education School of Electronics Engineering and Computer Science</orgName>
								<orgName type="laboratory">Key Laboratory of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifang</forename><surname>Sui</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Ministry of Education School of Electronics Engineering and Computer Science</orgName>
								<orgName type="laboratory">Key Laboratory of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">RBPB: Regularization-Based Pattern Balancing Method for Event Extraction</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1224" to="1234"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
					<note>2</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Event extraction is a particularly challenging information extraction task, which intends to identify and classify event triggers and arguments from raw text. In recent works, when determining event types (trigger classification), most of the works are either pattern-only or feature-only. However, although patterns cannot cover all representations of an event, it is still a very important feature. In addition, when identifying and classifying arguments, previous works consider each candidate argument separately while ignoring the relationship between arguments. This paper proposes a Regularization-Based Pattern Balancing Method (RBPB). Inspired by the progress in representation learning, we use trigger embedding, sentence-level embedding and pattern features together as our features for trigger classification so that the effect of patterns and other useful features can be balanced. In addition, RBPB uses a regularization method to take advantage of the relationship between arguments. Experiments show that we achieve results better than current state-of-art equivalents.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Event extraction has become a popular research topic in the area of information extraction. ACE 2005 defines event extraction task 1 as three sub-tasks: identifying the trigger of an event, identifying the arguments of the event, and distinguishing their corresponding roles. As an example in <ref type="figure" target="#fig_0">Figure 1</ref>, there is an "Attack" event <ref type="bibr">1</ref> http://www.itl.nist.gov/iad/mig/tests/ace/2005/ triggered by "tear through" with three arguments. Each argument has one role.</p><p>In the trigger classification stage, some previous approaches ( <ref type="bibr">Grishman et al., 2005;</ref><ref type="bibr">Ji and Grishman, 2008;</ref><ref type="bibr">Liao and Grishman, 2010;</ref><ref type="bibr">Huang and Riloff, 2012</ref>) use patterns to decide the types of event triggers. However, pattern-based approaches suffer from low recall since real world events usually have a large variety of representations. Some other approaches <ref type="bibr">(Hong et al., 2011;</ref><ref type="bibr">Li et al., 2013;</ref><ref type="bibr">Lu and Roth, 2012)</ref> identify and classify event triggers using a large set of features without using patterns. Although these features can be very helpful, patterns are still indispensable in many cases because they can identify a trigger with the correct event type with more than 96% accuracy according to our data analysis on ACE 2005 data sets.</p><p>In argument identification and classification, most approaches identify each candidate argument separately without considering the relation between arguments. We define two kinds of argument relations here: (1) Positive correlation: if one candidate argument belongs to one event, then the other is more likely to belong to the same event. For example, in <ref type="figure" target="#fig_0">Figure 1</ref>, the entity "a waiting shed" shares a common dependency head "tore" with "a powerful bomb", so when the latter entity is identified as an argument, the former is more likely to be identified. (2) Negative correlation: if one candidate argument belongs to one event, then the other is less likely to belong to the same event. For example, in <ref type="figure" target="#fig_0">Figure 1</ref>, "bus" is irrelevant to other arguments, so if other entities are identified as arguments "bus" is less likely to be identified. Note that although all the above relation examples have something to do with dependency analysis, the positive/negative relationship depends not only on dependency parsing, but many other aspects as well. In this paper, we propose using both patterns and elaborately designed features simultaneously to identify and classify event triggers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A powerful bomb tore through a waiting shed at the Davao airport while another explosion hit a bus</head><p>In addition, we propose using a regularization method to model the relationship between candidate arguments to improve the performance of argument identification. Our method is called Regularization-Based Pattern Balancing Method method.</p><p>The contributions of this paper are as follows:</p><p>• Inspired by the progress of representation learning, we use trigger embedding, sentence-level embedding, and pattern features together as the our features for balancing.</p><p>• We proposed a regularization-based method in order to make use of the relationship be- tween candidate arguments. Our experiments on the ACE 2005 data set show that the reg- ularization method does improve the perfor- mance of argument identification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>There is a large body of previous work devoted to event extraction. Many traditional works focus on using pattern based methods for identifying event type <ref type="bibr">(Kim and Moldovan, 1993;</ref><ref type="bibr">Riloff and others, 1993;</ref><ref type="bibr" target="#b7">Soderland et al., 1995;</ref><ref type="bibr">Huffman, 1996;</ref><ref type="bibr">Freitag, 1998b;</ref><ref type="bibr">Ciravegna and others, 2001;</ref><ref type="bibr" target="#b0">Califf and Mooney, 2003;</ref><ref type="bibr" target="#b4">Riloff, 1996;</ref><ref type="bibr" target="#b3">Riloff et al., 1999;</ref><ref type="bibr" target="#b10">Yangarber et al., 2000;</ref><ref type="bibr" target="#b9">Sudo et al., 2003;</ref><ref type="bibr" target="#b8">Stevenson and Greenwood, 2005;</ref><ref type="bibr">Grishman et al., 2005;</ref><ref type="bibr">Ji and Grishman, 2008;</ref><ref type="bibr">Liao and Grishman, 2010;</ref><ref type="bibr">Huang and Riloff, 2012</ref> There are also feature-based classification methods <ref type="bibr">(Freitag, 1998a;</ref><ref type="bibr">Chieu and Ng, 2002;</ref><ref type="bibr">Finn and Kushmerick, 2004;</ref><ref type="bibr">Li et al., 2005;</ref><ref type="bibr" target="#b11">Yu et al., 2005</ref>). Apart from the above methods, weakly supervised training (pattern-based and rule-based) of event extraction systems have also been explored <ref type="bibr" target="#b4">(Riloff, 1996;</ref><ref type="bibr" target="#b3">Riloff et al., 1999;</ref><ref type="bibr" target="#b10">Yangarber et al., 2000;</ref><ref type="bibr" target="#b9">Sudo et al., 2003;</ref><ref type="bibr" target="#b8">Stevenson and Greenwood, 2005;</ref><ref type="bibr">Patwardhan and Riloff, 2007;</ref><ref type="bibr">Chambers and Jurafsky, 2011)</ref>. In some of these systems, human work is needed to delete some nonsense patterns or rules. Other methods ( <ref type="bibr">Gu and Cercone, 2006;</ref><ref type="bibr" target="#b1">Patwardhan and Riloff, 2009)</ref> consider broader context when deciding on role fillers. Other systems take the whole discourse feature into consideration, such as ( <ref type="bibr">Maslennikov and Chua, 2007;</ref><ref type="bibr">Liao and Grishman, 2010;</ref><ref type="bibr">Hong et al., 2011;</ref><ref type="bibr">Huang and Riloff, 2011)</ref>. <ref type="bibr">Ji and Grishman (2008)</ref> even consider topic-related documents, proposing a cross-document method. ( <ref type="bibr">Liao and Grishman, 2010;</ref><ref type="bibr">Hong et al., 2011</ref>) use a series of global features (for example, the occurrence of one event type lead to the occurrence of another) to improve role assignment and event classification performance. Joint models ( <ref type="bibr">Li et al., 2013;</ref><ref type="bibr">Lu and Roth, 2012)</ref> are also considered an effective solution. ( <ref type="bibr">Li et al., 2013</ref>) make full use of the lexical and contextual features to get better results. The semi-CRF based method ( <ref type="bibr">Lu and Roth, 2012</ref>) trains separate models for each event type, which requires a lot of training data.</p><p>The dynamic multi-pooling convolutional neu- ral network (DMCNN) ( <ref type="bibr">Chen et al., 2015</ref>) is cur- rently the only widely used deep neural network based approach. DMCNN is mainly used to model contextual features. However, DMCNN still does not consider argument-argument interactions.</p><p>In summary, most of the above works are either pattern-only or features-only. Moreover, all of these methods consider arguments sepa-rately while ignoring the relationship between arguments, which is also important for argument identification. Even the joint method ( <ref type="bibr">Li et al., 2013</ref>) does not model argument relations directly. We use trigger embedding, sentence- level embedding, and pattern features together as our features for trigger classification and design a regularization-based method to solve the two problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">ACE Event Extraction Task</head><p>Automatic Content Extraction (ACE) is an event extraction task. It annotates 8 types and 33 sub- types of events. ACE defines the following termi- nologies:</p><p>• Entity: an object or a set of objects in one of the semantic categories of interest</p><p>• Entity mention: a reference to an entity, usu- ally a noun phrase (NP)</p><p>• Event trigger: the main word which most clearly expresses an event occurrence</p><p>• Event arguments: the entity mentions that are involved in an event</p><p>• Argument roles: the relation of arguments to the event where they participate, with 35 total possible roles</p><p>• Event mention: a phrase or sentence within which an event is described, including trigger and arguments</p><p>Given an English document, an event extraction system should identify event triggers with their subtypes and arguments from each sentence. An example is shown in <ref type="figure" target="#fig_0">Figure 1</ref>. There is an "Attack" event triggered by "tear through" with three arguments. Each argument has a role type such as "Instrument", "Target", etc. For evaluation, we follow previous works <ref type="bibr">(Ji and Grishman, 2008;</ref><ref type="bibr">Liao and Grishman, 2010;</ref><ref type="bibr">Li et al., 2013</ref>) to use the following criteria to determine the correctness of the predicted event mentions.</p><p>• A trigger is considered to be correct if and only if its event type and offsets (position in the sentence) can match the reference trigger;</p><p>• An argument is correctly identified if and on- ly if its event type and offsets can match any reference arguments;</p><p>• An argument is correctly identified and clas- sified if and only if its event type, offsets, and role match any of the reference arguments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Baseline: JET Extractor for Events</head><p>Many previous works take JET as their baseline system, including <ref type="bibr">(Ji and Grishman, 2008)</ref>, (Liao and Grishman, 2010), ( <ref type="bibr">Li et al., 2013)</ref>. JET extracts events independently for each sentence. This system uses pattern matching to predict trigger and event types, then uses statistical modeling to identify and classify arguments.</p><p>For each event mention in the training corpus of ACE, the patterns are constructed based on the sequences of constituent heads separating the trigger and arguments. After that, three Maximum Entropy classifiers are trained using lexical features.</p><p>• Argument Classifier: to distinguish argu- ments from non-arguments</p><p>• Role Classifier: to label arguments with an argument role</p><p>• Reportable-Event Classifier: to determine whether there is a reportable event mentioned (worth being taken as an event mention) according to the trigger, event type, and a set of arguments <ref type="figure">Figure 2</ref>(a) shows the whole test procedure. In the test procedure, each sentence is scanned for nouns, verbs and adjectives as trigger candidates. When a trigger candidate is found, the system tries to match the context of the trigger against the set of patterns associated with that trigger. If this pattern matching process is successful, the best pattern will assign some of the entity mentions in the sentence as arguments of a potential event mention. Then JET uses the argument classifier to judge if the remaining entity mentions should also be identified. If yes, JET uses the role classifier to assign it a role. Finally, the reportable-event classifier is applied to decide whether this event mention should be reported.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Regularization-Based Pattern Balancing Method</head><p>Different with JET, as illustrated in <ref type="figure">Figure 2</ref>(b), our work introduces two major improvements: (1) balance the effect of patterns and other features <ref type="bibr">(2)</ref> ... In Baghdad, a cameraman died when ... ... In Baghdad, a cameraman died when ... The thick-edge blocks in <ref type="figure">Figure 2</ref>(b) represent our improvements. Since JET only uses pattern- s when predicting the event type, we use a SVM classifier to decide each candidate trigger's even- t type (classify the trigger). This classifier uses trigger embedding, sentence-level embedding and pattern features together for balancing. After the outputs of argument and role classifier are calcu- lated, we make use of the argument relationship to regularize for a better result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Balancing the Pattern effects</head><p>Deciding the event type is the same as classifying an event trigger. JET only uses patterns in this step: for a candidate trigger, we find that the best matched pattern and the corresponding event type are assigned to this trigger. We propose using feature-based methods while not ignoring the effect of patterns. Inspired by progress in representation learning, we use trigger embedding, sentence-level embedding and pattern embedding together as our features.</p><p>A pattern example is as follows:</p><p>(weapon) tore <ref type="bibr">[through]</ref> (building) at (place) ⇒ Attack{Roles...} where each pair of round brackets represents an entity and the word inside is one of the 18 entity types defined by UIUC NER Tool 2 . The word in the square brackets can choose to exist or not. Af- ter the right arrow there is an event schema, which can tell us what kind of event this is and which roles each entity should take. Each pattern has a corresponding event type. A candidate trigger may match more than one pattern so that it has an event type distribution. Assume that there are N T event types in total, we denote the pattern feature vector (namely, the event type's probability distribution calculated by the trigger's pattern set) as P E ∈ R N T , which is calculated by Eq 1.</p><formula xml:id="formula_0">P E (i) = #(matched patterns of event type i) #(all matched patterns)<label>(1)</label></formula><p>Trigger embeddings are obtained using WORD2VEC 3 with the default "text8" training text data with length 200. Since all of the NPs are potential roles in the event, they must contain the main information of the event. We extract all the NPs in the sentence and take the average word embedding of these NPs' head word as the sentence-level embedding. For example, in <ref type="figure" target="#fig_0">Figure 1</ref>, these NPs' head words are bomb, shed, and airport.</p><p>Pattern feature vectors, as distributions of event types over patterns, are also composed using continuous real values, which allows them to be viewed as a kind of pattern embedding and treated similarly to trigger and sentence embedding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Capturing the Relationship Between Arguments</head><p>We find that there are two typical relations between candidate arguments: (1) positive correlation: if one candidate argument belongs to one event, then the other is more likely to belong to the same event; (2) negative correlation: if one candidate argument belongs to one event, then the other is less likely to belong to the same event.</p><p>We calculate a score for all the candidate arguments in a sentence to judge the quality of the argument identification and classification. For capturing the two kinds of relations, we intend to make that (1) the more positive relations the chosen arguments have, the higher the score is; (2) the more negative relations the chosen arguments have, the lower the score is.</p><p>For a trigger, if there are n candidate arguments, we set a n × n matrix C to represent the relation- ship between arguments. If C i,j = 1, then argu- ment i and argument j should belong to the same event. If C i,j = −1, then argument i and argu- ment j cannot belong to the same event. We will illustrate how to get matrix C in the next section.</p><p>We use a n-dim vector X to represent the iden- tification result of arguments. Each entry of X is 0 or 1. 0 represents "noArg", 1 represents "arg". X can be assigned by maximizing E(X) as defined by Eq 2.</p><formula xml:id="formula_1">X = argmax X E(X) E(X) = λ 1 X T CX + λ 2 P arg sum + (1 − λ 1 − λ 2 )P role sum (2)</formula><p>Here, X T CX means adding up all the relationship values if the two arguments are identified. Hence, the more the identified arguments are related, the larger the value X T CX is. P arg sum is the sum of all chosen arguments' probabilities. The proba- bility here is the output of the arguments' max- imum entropy classifier. P role sum is the sum of all the classified roles' probabilities. The probability here is the output of the roles' maximum entropy classifier.</p><p>Eq 2 shows that while we should identify and classify the candidate arguments with a larger probability, the argument relationship evaluation should also be as large as possible. The arguments should also follow the following constraints. These constraints together with Eq 2 can make the argument identification and classification help each other for a better result.</p><p>• Each entity can only take one role</p><p>• Each role can belong to one or more entities</p><p>• The role assignment must follow the event schema of the corresponding type, which means that only the roles in the event schema can occur in the event mention</p><p>We use the Beam Search method to search for the optimal assignment X as is shown in Algorithm 1. The hyperparameters λ 1 and λ 2 can be chosen ac- cording to development set. • means to concatenate an element to the end of a vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Training the Argument Relationship</head><p>Structure The argument relationship matrix C is very im- portant in the regularization process. We train a maximum entropy classifier to predict the connec- tion between two entities. We intend to classify the entity pairs into three classes: positive correlation, negative correlation, and unclear correlation. The entity pairs in the ground truth events (in training data) are used for our training data. We choose the following features:</p><p>• TRIGGER: the trigger of the event. The whole model is a pipelined model, so when classifying the argument relationship, the trigger has been identified and classified. So the "trigger" is a feature of the argument relation.</p><p>• ENTITY DISTANCE: the distance between the two candidate arguments in the sentence, namely the number of intervening words</p><p>• Whether the two candidate arguments occur on the same side of the trigger</p><p>• PARENT DEPENDENCY DISTANCE: the dis- tance between the two candidate arguments' parents in the dependency parse tree, namely, the path length.</p><p>• PARENT POS: if the two candidate ar- guments share the same parent, take the common parent's POS tag as a feature</p><p>• Whether the two candidate arguments occur on the same side of the common parent if the two candidate arguments share the same par- ent</p><p>For an entity pair, if both of the entities belong to the same event's arguments, we take it as positive example. For each positive example, we randomly exchange one of the entities with an irrelevant en- tity (an irrelevant entity is in the same sentence as the event, but it is not the event's argument) to get a negative example. In the testing procedure, we predict the relationship between entity i and entity j using the maximum entropy classifier. When the output of the maximum entropy classifier is around 0.5, it is not easy to figure out whether it is the first relation or the second. We call this kind of information "uncertain information"(unclear correlation). For better per- formance, we strengthen the certain information and weaken the uncertain information. We set two thresholds, if the output of the maximum entropy classifier is larger than 0.8, we set C i,j = 1 (positive correlation), if the output is lower than 0.2, we set C i,j = −1 (negative correlation), otherwise, we set C i,j = 0 (unclear correlation). The strengthen mapping is similar to the hard tanh in neural network. If we do not do this, according to the experiment, the performance cannot beat most of the baselines since the uncertain information has very bad noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Data</head><p>We utilize ACE 2005 data sets as our testbed. As is consistent with previous work, we randomly select 10 newswire texts from ACE 2005 training corpo- ra as our development set, and then conduct blind test on a separate set of 40 ACE 2005 newswire texts. The remaining 529 documents in ACE train- ing corpus are used as the training data.</p><p>The training dataset of the argument relation- ship matrix contains 5826 cases (2904 positive and 2922 negative) which are randomly generated ac- cording to the ground truth in the 529 training doc- uments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Systems to Compare</head><p>We compare our system against the following sys- tems:</p><p>• JET is the baseline of ( <ref type="bibr">Grishman et al., 2005</ref>), we report the paper values of this method;</p><p>• Cross-Document is the method proposed by <ref type="bibr">Ji and Grishman (2008)</ref>, which uses topic-related documents to help extract events in the current document;</p><p>• Cross-Event is the method proposed by <ref type="bibr">Liao and Grishman (2010)</ref>, which uses document- level information to improve the performance of ACE event extraction.</p><p>• Cross-Entity is the method proposed by <ref type="bibr">Hong et al. (2011)</ref>, which extracts events using cross-entity inference.</p><p>• Joint is the method proposed by <ref type="bibr">Li et al. (2013)</ref>, which extracts events based on structure prediction. It is the best-reported structure-based system.</p><p>• DMCNN is the method proposed by <ref type="bibr">Chen et al. (2015)</ref>, which uses a dynamic multi- pooling convolutional neural network to extract events. It is the only neural network based method.</p><p>The Cross-Document, Cross-Event and Cross- Entity are all extensions of JET. Among these</p><formula xml:id="formula_2">Method Trigger Argument Argument Classification Identification Role P R F 1 P R F 1 P R F 1 JET</formula><p>67.6 53.5 59.7 46.5 37.2 41.3 41.0 32.8 36.5 Cross-Event 68.7 68.9 68.8 50.9 49.7 50.3 45.1 44.1 44.6 Cross-Entity 72.9 64.3 68.3 53.4 52.9 53.1 51.6 45.5 48.3 Joint 73.7 62.3 67.5 69.8 47.9 56.8 64.7 44.4 52.7 DMCNN 75.6 63.6 69.1 68.8 51.9 59.1 62.2 46.9 53.5 RBPB(JET) 62.3 59.9 61.1 50.4 45.8 48.0 41.9 36.5 39.0 + ET 66.7 65.9 66.3 60.6 56.7 58.6 49.2 48.3 48.7 + Regu 67.2 61.7 64.3 62.8 57.5 60.0 52.6 48.4 50.4 + ET + Regu 70.3 67.5 68.9 63.2 59.4 61.2 54.1 53.5 53.8 <ref type="table">Table 1</ref>: Overall performance with gold-standard entities, timex, and values, the candidate arguments are annotated in ACE 2005. "ET" means the pattern balancing event type classifier, "Regu" means the regularization method methods, Cross-Event, Cross-Entity, and DM- CNN make use of the gold-standard entities, timex, and values annotated in the corpus as the argument candidates. Cross-Document uses the JET system to extract candidate arguments. <ref type="bibr">Li et al. (2013)</ref> report the performance with both gold-standard argument candidates and predicted argument candidates. Therefore, we compare our results with methods based on gold argument candidates in <ref type="table">Table 1</ref> and methods based on predicted argument candidates in <ref type="table">Table 2</ref>.</p><p>We have done a series of ablation experiments:</p><p>• RBPB(JET): Our own implementation of JET</p><p>• RBPB(JET) + ET: Add pattern balanced event type classifier to RBPB(JET)</p><p>• RBPB(JET) + Regu: Add regularization mechanism to RBPB(JET)</p><p>• RBPB(JET) + ET + Regu: Add both pattern balanced event type classifier and regulariza- tion mechanism to RBPB(JET)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.1">The Selection of Hyper-parameters</head><p>We tune the coefficients λ 1 and λ 2 of Eq 2 on the development set, and finally we set λ 1 = 0.10 and λ 2 = 0.45. <ref type="figure" target="#fig_4">Figure 3</ref> shows the variation of ar- gument identification's F 1 measure and argument classification's F 1 measure when we fix one pa- rameter and change another. Note that the third coefficient 1 − λ 1 − λ 2 must be positive, which is the reason why the curve decreases sharply when λ 2 is fixed and λ 1 &gt; 0.65. Therefore, <ref type="figure" target="#fig_4">Figure 3</ref> illustrates that the robustness of our method is very good, which means if the hyperparameters λ 1 , λ 2 are larger or smaller, it will not affect the result very much.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Experiment Results</head><p>We conduct experiments to answer the following questions.</p><p>(1) Can pattern balancing lead to a higher performance in trigger classification, argument identification, and classification while retaining the precision value? (2) Can the regularization step improve the performance of argument identification and classification? <ref type="table">Table 1</ref> shows the overall performance on the blind test set. We compare our results with the JET baseline as well as the Cross-Event, Cross- Entity, and joint methods. When adding the event type classifier, in the line titled "+ ET", we see a significant increase in the three measures over the JET baseline in recall. Although our trigger's pre- cision is lower than RBPB(JET), it gains 5.2% im- provement on the trigger's F 1 measure, 10.6% im- provement on argument identification's F 1 mea- sure and 9.7% improvement on argument classifi- cation's F 1 measure. We also test the performance with argument candidates automatically extracted by JET in <ref type="table">Table 2</ref>, our approach "+ ET" again sig- nificantly outperforms the JET baseline. Remark- ably, our result is comparable with the Joint model although we only use lexical features.</p><p>The line titled "+ Regu" in <ref type="table">Table 1 and Table 2</ref> represents the performance when we only use the regularization method. In <ref type="table">Table 1</ref>  <ref type="table">Table 2</ref>: Overall performance with predicted entities, timex, and values, the candidate arguments are extracted by JET. "ET" is the pattern balancing event type classifier, "Regu" is the regularization method  <ref type="table">Table 2</ref>, the "+ Regu" again gains a higher F 1 measure than the JET, Cross-Document, joint model baseline and "+ ET".</p><p>The complete approach is denoted as "RBPB" in <ref type="table">Table 1 and Table 2</ref>. Remarkably, our approach performances comparable in trigger classification with the state-of art methods: Cross-Document, Cross-Event, Cross-Entity, Joint model, DMCNN and significantly higher than them in argument identification as well as classification although we did not use the cross-document, cross-event information or any global feature. Therefore, the relationship between argument candidates can indeed contribute to argument identification performance.</p><p>The event type classifier also contributes a lot in trigger identification &amp; classification.</p><p>We do the Wilcoxon Signed Rank Test on trigger classification, argument identification and argument classification, all the three have p &lt; 0.01.</p><p>A more detailed study of the pattern feature's effect is shown in  <ref type="table" target="#tab_2">Table 3</ref>: The effect (F 1 value) of pattern feature much better performance than with two kinds of features alone. However, our approach is just a pipeline approach which suffers from error propagation and the argument performance may not affect the trigger too much. We can see from <ref type="table">Table 1</ref> that although we use gold argument candidates, the trigger performance is still lower than DMCNN. Another limitation is that our regularization method does not improve the argument classifi- cation too much since it only uses constraints to affect roles. Future work may be done to solve these two limitations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Analysis of Argument Relationships</head><p>The accuracy of the argument relationship max- ent classifier is 82.4%. <ref type="figure" target="#fig_5">Fig 4 shows</ref>   Others (the grey squares) are unclear correlation- s. We can see that positive correlation is between "Powerful bomb" and "A waiting shed" as well as "A waiting shed" and "Davao airport". Therefore, these entities tend to be extracted at the same time. However, "Powerful bomb" and "Bus" has a neg- ative correlation, so they tend not to be extracted at the same time. In practice, the argument prob- ability of "Powerful bomb" and "A waiting shed" are much higher than the other two. Therefore, "Powerful bomb", "A waiting shed" and "Davao airport" are the final extraction results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this paper, we propose two improvements based on the event extraction baseline JET. We find that JET depends too much on event patterns for event type priori and JET considers each candidate argument separately. However, patterns cannot cover all events and the relationship between candidate arguments may help when identifying arguments. For a trigger, if no pattern can be matched, the event type cannot be assigned and the arguments cannot be correctly identified and classified. Therefore, we develop an event type classifier to assign the event type, using both pattern matching information and other features, which gives our system the capability to deal with failed match cases when using patterns alone.</p><p>On the other hand, we train a maximum entropy classifier to predict the relationship between can- didate arguments. Then we propose a regulariza- tion method to make full use of the argument rela- tionship. Our experiment results show that the reg- ularization method is a significant improvement in argument identification over previous works.</p><p>In summary, by using the event type classifier and the regularization method, we have achieved a good performance in which the trigger classification is comparable to state-of-the- art methods, and the argument identification &amp; classification performance is significantly better than state-of-the-art methods. However, we only use sentence-level features and our method is a pipelined approach.</p><p>Also, the argument classification seems not to be affected too much by the regularization. Future work may be done to integrate our method into a joint approach, use some global feature, which may improve our performance. The code is available at https://github.com/shalei120/ RBPB/tree/master/RBET_release Wei Lu and Dan Roth. 2012. Automatic event extrac- tion with structured preference modeling. In Pro- ceedings of the 50th Annual Meeting of the Associ- ation for Computational Linguistics: Long Papers- Volume 1, pages 835-844. Association for Compu- tational Linguistics.</p><p>Mstislav Maslennikov and Tat-Seng Chua. 2007. A multi-resolution framework for information extraction from free text. In ANNUAL MEETING- ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, volume 45, page 592. Citeseer.</p><p>Siddharth Patwardhan and Ellen <ref type="bibr">Riloff. 2007</ref>. Ef- fective information extraction with semantic affinity patterns and relevant regions. In EMNLP-CoNLL, volume 7, pages 717-727. Citeseer.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Event example: This is an event trigger by "tear through" with three arguments</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>n</head><label></label><figDesc>, v, adj: trigger candidate trigger = died find best pattern get arguments &amp; roles yes MaxEnt for argument MaxEnt for role MaxEnt for reportable event (a) The flow chart of JET</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>n</head><label></label><figDesc>Figure 2: The left is the flow chart for JET. The right is the flow chart for our approach. The thick line block is our contribution</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Input:</head><label></label><figDesc>Argument relationship matrix: C the argument probabilities required by P arg sum the role probabilities required by P role sum Data: K: Beam size n: Number of candidate arguments Output: The best assignment X Set beam B ← [ϵ] ; for i ← 1 · · · n do buf← {z ′ • l|z ′ ∈ B, l ∈ {0, 1}}; B ← [ϵ] ; while j ← 1 · · · K do x best = argmax x∈buf E(x); B ← B ∪ {x best }; buf←buf−{x best }; end end Sort B descendingly according to E(X); return B[0]; Algorithm 1: Beam Search decoding algorith- m for event extraction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The trend graph when fix one coefficient and change another</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The Argument Relationship Matrix. Left is the origin matrix. Right is the strengthened matrix</figDesc><graphic url="image-1.png" coords="9,120.75,79.06,135.18,135.46" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 3 . We can see that RBPB with both plain feature and pattern feature can gain</head><label>3</label><figDesc></figDesc><table>Method (RBPB) Trigger Arg id Arg id+cl 
+ Plain feature 
66.0 
60.5 
50.4 
+ Pattern feature 
65.8 
60.1 
49.2 
+ Both 
68.9 
61.2 
53.8 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head></head><label></label><figDesc>an example of the argument relationship matrix, which works</figDesc><table>Po we rfu l bo m b 
A wa iti ng sh ed 
Da va o air po rt 
Bu s 

Powerful bomb 

A waiting shed 

Davao airport 

Bus 

Po we rfu l bo m b 
A wa iti ng sh ed 
Da va o air po rt 
</table></figure>

			<note place="foot" n="2"> http://cogcomp.cs.illinois.edu/page/software view/NETagger 3 http://code.google.com/p/word2vec/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to thank our three anonymous reviewers for their helpful advice on various aspects of this work. This research was sup-ported by the National Key Basic Research Program of China (No.2014CB340504) and the National Natural Science Foundation of China (No.61375074,61273318). The contact author for this paper is Zhifang Sui.</p></div>
			</div>

			<div type="annex">
			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Bottom-up relational learning of pattern matching rules for information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><forename type="middle">Elaine</forename><surname>Califf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="177" to="210" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A unified model of phrasal and sentential evidence for information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddharth</forename><surname>Patwardhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2009 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="151" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Automatically constructing a dictionary for information extraction tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="811" to="816" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning dictionaries for information extraction by multi-level bootstrapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rosie</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI/IAAI</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="474" to="479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Automatically generating extraction patterns from untagged text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the national conference on artificial intelligence</title>
		<meeting>the national conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="1044" to="1049" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">On-demand information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Sekine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the COLING/ACL on Main conference poster sessions</title>
		<meeting>the COLING/ACL on Main conference poster sessions</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="731" to="738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Preemptive information extraction using unrestricted relation discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuke</forename><surname>Shinyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Sekine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics</title>
		<meeting>the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="304" to="311" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Crystal: Inducing a conceptual dictionary</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Aseltine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wendy</forename><surname>Lehnert</surname></persName>
		</author>
		<idno>cmp-lg/9505020</idno>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A semantic approach to ie pattern induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Stevenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Greenwood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 43rd Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="379" to="386" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">An improved extraction pattern representation model for automatic ie pattern acquisition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiyoshi</forename><surname>Sudo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Sekine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 41st Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="224" to="231" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Automatic acquisition of domain knowledge for information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roman</forename><surname>Yangarber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pasi</forename><surname>Tapanainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silja</forename><surname>Huttunen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th conference on Computational linguistics</title>
		<meeting>the 18th conference on Computational linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2000" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="940" to="946" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Resume information extraction with cascaded hybrid model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 43rd Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="499" to="506" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
