<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:29+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Volatility Prediction using Financial Disclosures Sentiments with Word Embedding-based IR Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navid</forename><surname>Rekabsaz</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Lupu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Artem</forename><surname>Baklanov</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Dür</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linda</forename><surname>Andersson</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allan</forename><surname>Hanbury</surname></persName>
						</author>
						<title level="a" type="main">Volatility Prediction using Financial Disclosures Sentiments with Word Embedding-based IR Models</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</title>
						<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1712" to="1721"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-1157</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Volatility prediction-an essential concept in financial markets-has recently been addressed using sentiment analysis methods. We investigate the sentiment of annual disclosures of companies in stock markets to forecast volatility. We specifically explore the use of recent Information Retrieval (IR) term weighting models that are effectively extended by related terms using word embeddings. In parallel to textual information, factual market data have been widely used as the mainstream approach to forecast market risk. We therefore study different fusion methods to combine text and market data resources. Our word embedding-based approach significantly outperforms state-of-the-art methods. In addition, we investigate the characteristics of the reports of the companies in different financial sectors.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Financial volatility is an essential indicator of in- stability and risk of a company, sector or econ- omy. Volatility forecasting has gained consider- able attention during the last three decades. In addition to using historic stock prices, new meth- ods in this domain use sentiment analysis to ex- ploit various text resources, such as financial re- ports ( <ref type="bibr" target="#b9">Kogan et al., 2009;</ref><ref type="bibr" target="#b26">Wang et al., 2013;</ref><ref type="bibr" target="#b25">Tsai and Wang, 2014;</ref><ref type="bibr" target="#b20">Nopp and Hanbury, 2015)</ref>, news ( <ref type="bibr" target="#b8">Kazemian et al., 2014;</ref><ref type="bibr" target="#b3">Ding et al., 2015)</ref>, message boards ( <ref type="bibr">Nguyen and Shirai, 2015)</ref>, and earning calls ( <ref type="bibr" target="#b27">Wang and Hua, 2014</ref>).</p><p>An interesting resource of textual information are the companies' annual disclosures, known as 10-K filing reports. They contain comprehensive information about the companies' business as well as risk factors. Specifically, section Item 1A -Risk Factors of the reports contains information about the most significant risks for the company. These reports are however long, redundant, and written in a style that makes them complex to process. <ref type="bibr" target="#b5">Dyer et al. (2016)</ref> notes that: "10-K reports are getting more redundant and complex <ref type="bibr">[...]</ref> (it) re- quires a reader to have 21.6 years of formal ed- ucation to fully comprehend". Dyer et al. also analyse the topics discussed in the reports and ob- serve a constant increase over the years in both the length of the documents as well as the number of topics. They claim that the increase in length is not the result of economic factors but is due to ver- boseness and redundancy in the reports. They sug- gest that only the risk factors topic appears to be useful and informative to investors. Their analysis motivates us to study the effectiveness of the Risk Factors section for volatility prediction.</p><p>Our research builds on previous studies on volatility prediction and information analysis of 10-K reports using sentiment analysis ( <ref type="bibr" target="#b9">Kogan et al., 2009;</ref><ref type="bibr" target="#b25">Tsai and Wang, 2014;</ref><ref type="bibr" target="#b26">Wang et al., 2013;</ref><ref type="bibr" target="#b20">Nopp and Hanbury, 2015;</ref><ref type="bibr" target="#b11">Li, 2010;</ref><ref type="bibr" target="#b1">Campbell et al., 2014)</ref>, in the sense that since the reports are long (average length of 5000 words), different approaches are required, compared with studies of sentiment analysis on short-texts. Such previous studies on 10-K reports have mostly used the data before 2008 and there is little work on the analy- sis of the informativeness and effectiveness of the recent reports with regards to volatility prediction. We will indeed show that the content of the re- ports changes significantly not only before and af- ter 2008, but rather in a cycle of 3-4 years.</p><p>In terms of use of the textual content for volatil- ity prediction, this paper shows that state-of- the-art Information Retrieval (IR) term weighting models, which benefit from word embedding in- formation, have a significantly positive impact on prediction accuracy. The most recent study on the topic <ref type="bibr" target="#b25">(Tsai and Wang, 2014</ref>) used related terms obtained by word embeddings to expand the lexicon of sentiment terms. In contrast, similar to <ref type="bibr" target="#b22">Rekabsaz et al. (2016b)</ref>, we define the weight of each lexicon term by extending it to the similar terms in the document. The significant improve- ment of this approach for document retrieval by capturing the importance of the terms motivates us to apply it on sentiment analysis. We extensively evaluate various state-of-the-art sentiment analy- sis methods to investigate the effectiveness of our approach.</p><p>In addition to text, factual market data (i.e. historical prices) provide valuable resources for volatility prediction e.g. in the framework of GARCH models <ref type="bibr" target="#b6">(Engle, 1982)</ref>. An emerging question is how to approach the combination of the textual and factual market information. We propose various methods for this issue and show the performance and characteristics of each.</p><p>The financial system covers a wide variety of industries, from daily-consumption products to space mission technologies. It is intuitive to con- sider that the factors of instability and uncertainty are different between the various sectors while similar inside them. We therefore also analyse the sentiment of the reports of each sector separately and study their particular characteristics.</p><p>The present study shows the value of infor- mation in the 10-K reports for volatility predic- tion. Our proposed approach to sentiment analy- sis significantly outperforms state-of-the-art meth- ods ( <ref type="bibr" target="#b9">Kogan et al., 2009;</ref><ref type="bibr" target="#b25">Tsai and Wang, 2014;</ref><ref type="bibr" target="#b26">Wang et al., 2013</ref>). We also show that per- formance can be further improved by effectively combining textual and factual market information. In addition, we shed light on the effects of tailor- ing the analysis to each sector: despite the rea- sonable expectation that domain-specific training would lead to improvements, we show that our general model generalizes well and outperforms sector-specific trained models.</p><p>The remainder of the paper is organized as fol- lows: in the next section, we review the state-of- the-art and related studies. Section 3 formulates the problem, followed by a detailed explanation of our approach in Section 4. We explain the dataset and settings of the experiments in Section 5, fol- lowed by the full description of the experiments in Section 6. We conclude the work in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Market prediction has been attracting much at- tention in recent years in the natural language processing community. <ref type="bibr" target="#b8">Kazemian et al. (2014)</ref> use sentiment analysis for predicting stock price movements in a simulated security trading system using news data, showing the advantages of the method against simple trading strategies. <ref type="bibr" target="#b3">Ding et al. (2015)</ref> address a similar objective while using deep learning to extract and learn events in the news. <ref type="bibr" target="#b29">Xie et al. (2013)</ref> introduce a semantic tree- based model to represent news data for predict- ing stock price movement. <ref type="bibr" target="#b15">Luss et al. (2015)</ref> also exploit news in combination with return prices to predict intra-day price movements. They use the Multi Kernel Learning (MKL) algorithm for com- bining the two features. The combination shows improvement in final prediction in comparison to using each of the features alone. Motivated by this study, we investigate the performance of the MKL algorithm as one of the methods to combine the textual with non-textual information. Other data resources, such as stocks' message boards, are used by <ref type="bibr">Nguyen and Shirai (2015)</ref> to study topic modelling for aspect-based sentiment anal- ysis. <ref type="bibr" target="#b27">Wang and Hua (2014)</ref> investigate the senti- ment of the transcript of earning calls for volatility prediction using the Gaussian Copula regression model.</p><p>While the mentioned studies use short-length texts (sentence or paragraph level), approaching long texts (document level) for market prediction is mainly based on n-gram bag of words methods. <ref type="bibr" target="#b20">Nopp and Hanbury (2015)</ref> study the sentiment of banks' annual reports to assess banking systems risk factors using a finance-specific lexicon, pro- vided by <ref type="bibr" target="#b14">Loughran and McDonald (2011)</ref>, in both unsupervised and supervised manner.</p><p>More directly related to the informativeness of the 10-K reports for volatility prediction, <ref type="bibr" target="#b9">Kogan et al. (2009)</ref> use a linear Support Vector Ma- chine (SVM) algorithm on the reports published between 1996-2006. <ref type="bibr" target="#b26">Wang et al. (2013)</ref> improve upon this by using the <ref type="bibr" target="#b14">Loughran and McDonald (2011)</ref> lexicon, observing improvement in the pre- diction. Later, <ref type="bibr" target="#b25">Tsai and Wang (2014)</ref> apply the same method as <ref type="bibr" target="#b26">Wang et al. (2013)</ref> while addition- ally using word embedding to expand the financial lexicon. We reproduce all the methods in these studies, and show the advantage of our sentiment analysis approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Problem Formulation</head><p>In this section, we formulate the volatility fore- casting problem and the prediction objectives of our experiments. Similar to previous stud- ies <ref type="bibr" target="#b2">(Christiansen et al., 2012;</ref><ref type="bibr" target="#b9">Kogan et al., 2009;</ref><ref type="bibr" target="#b25">Tsai and Wang, 2014</ref>), volatility is defined as the natural log of the standard deviation of (adjusted) return prices in a window of τ days. This defi- nition is referred to as standard volatility ( <ref type="bibr" target="#b12">Li and Hong, 2011</ref>) or realized volatility ( , defined as follows:</p><formula xml:id="formula_0">v [s,s+τ ] = ln   s+τ t=s (r t − ¯ r) 2 τ   (1)</formula><p>where r t is the return price and ¯ r the mean of return prices. The return price is calculated by r t = ln(P t )−ln(P t−1 ), where P t is the (adjusted) closing price of a given stock at the trading date t.</p><p>Given an arbitrary report i, we define a predic- tion label y k i as the volatility of the stock of the re- porting company in the kth quarter-sized window starting from the issue date of the report s i :</p><formula xml:id="formula_1">y k i = v [s i +64(k−1),s i +64k]<label>(2)</label></formula><p>Every quarter is considered as per convention, 64 working days, while the full year is assumed to have 256 working days. We use 8 learners for labels y 1 to y 8 . For brevity, unless otherwise mentioned, we report the volatility of the first year by calculating the mean of the first four quartiles after the publication of each report.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Methodology</head><p>We first describe our text sentiment analysis meth- ods, followed by the features obtained from fac- tual market data, and finally explain the methods to combine textual and market feature sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Sentiment Analysis</head><p>Similar to previous studies ( <ref type="bibr" target="#b20">Nopp and Hanbury, 2015;</ref><ref type="bibr" target="#b26">Wang et al., 2013)</ref>, we extract the keyword set from a finance-specific lexicon ( <ref type="bibr" target="#b14">Loughran and McDonald, 2011</ref>) using the positive, negative, and uncertain groups, stemmed using the Porter stem- mer. We refer to this keyword set as <ref type="bibr">Lex. Tsai and Wang (2014)</ref> expanded this set by adding the top 20 related terms to each term to the origi- nal set. The related terms are obtained using the Word2Vec ( <ref type="bibr" target="#b16">Mikolov et al., 2013</ref>) model, built on the corpus of all the reports, with Cosine similar- ity. We also use this expanded set in our experi- ments and refer to it as LexExt.</p><p>The following word weighting schemes are commonly used in Information Retrieval and we consider them as well in our study: In addition to the standard weighting schemes, we use state-of-the-art weighting methods in Information Retrieval ( <ref type="bibr" target="#b22">Rekabsaz et al., 2016b</ref>) which benefit directly from word embedding mod- els: They exploit similarity values between words provided by the word embedding model into the weighting schemes by extending the weight of each lexicon keyword with its similar words:</p><formula xml:id="formula_2">TC : log(1 + tc d i (t)) TF : log(1+tc d i (t)) d i TFIDF : log(1+tc d i (t)) d i log(1 + |d i | df (t) ) BM25 : (k+1)tf d i (t) k+tf d i (t) , tf d i (t) = tc d i (t) (1−b)+b |d i | avgdl</formula><formula xml:id="formula_3">tc d i (t) = tc d i (t) + t ∈R(t) sim(t, t )tc d i (t ) (3)</formula><p>where R(t) is the list of similar words to the keyword t, and sim(t, t ) is the Cosine similar- ity value between the vector representations of the words t and t . As previously suggested by <ref type="bibr" target="#b21">Rekabsaz et al. (2016a</ref><ref type="bibr" target="#b23">Rekabsaz et al. ( , 2017</ref>, we use the Cosine sim- ilarity function with threshold 0.70 for selecting the set R(t) of similar words. We define the extended versions of the standard weighting schemes as TC, TF, TFIDF, and BM25 by replacing tc d i (t) with tc d i (t) in each of the schemes.</p><p>The feature vector generated by the weights of the Lex or LexExt lexicons is highly sparse, as the number of dimensions is larger than the num- ber of data-points. We therefore reduce the dimen- sions by applying Principle Component Analysis (PCA). Our initial experiments show 400 dimen-sion as the optimum by trying on a range of di- mensions from 50 to 1000.</p><p>Given the final feature vector x with l dimen- sions, we apply SVM as a well-known method for training both regression and classification meth- ods. Support Vector Regression ( <ref type="bibr" target="#b4">Drucker et al., 1997</ref>) formulates the training as the following op- timization problem:</p><formula xml:id="formula_4">min w∈IR l 1 2 w 2 + C N N i=1 max(0, y i − f (x i ; w) − )<label>(4)</label></formula><p>Similar to previous studies <ref type="bibr" target="#b25">(Tsai and Wang, 2014;</ref><ref type="bibr" target="#b9">Kogan et al., 2009)</ref>, we set C = 1.0 and = 0.1. To solve the above problem, the func- tion f can be re-parametrized in terms of a kernel function K with weights α i :</p><formula xml:id="formula_5">f (x i ; w) = N i=1 α i K(x i , x)<label>(5)</label></formula><p>The kernel can be considered as a (similarity) function between the feature vector of the docu- ment and vectors of all the other documents. Our initial experiments showed better performance of the Radial Basis Function (RBF) kernel in com- parison to linear and cosine kernels and is there- fore used in this paper.</p><p>In addition, motivated by <ref type="bibr" target="#b17">Moraes et al.(Moraes et al., 2013)</ref>, we use of an Artificial Neural Net- work (ANN) algorithm to test the effectiveness of neural networks for automatic feature learning. We tried several neural network architectures with different regularization methods (early-stopping, regularization term, dropout). The best perform- ing results were achieved with two hidden layers (400 and 500 nodes respectively), tanh for activa- tion function, and learning rate of 0.001 in gra- dient decent with early stopping. However, the networks could not provide superior results than the SVM regressors. Therefore, for this report, we only report the SVM methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Market Features</head><p>In addition to textual features, we define three fea- tures using the factual market data and histori- cal prices-referred to as market features-as fol- lows: Current Volatility is calculated on the window of one quartile before the issue date of the report:</p><formula xml:id="formula_6">v [s i −64,s i ] .</formula><p>GARCH <ref type="bibr" target="#b0">(Bollerslev, 1986</ref>) is a common econo- metric time-series model used for predicting stock price volatility. We use a GARCH (1, 1) model, trained separately for each report on intra-day re- turn prices. We use all price data available be- fore the issue date of the report for fitting the model. The GARCH (1, 1) model used predicts the volatility of the next day by looking at the previous day's volatility. When forecasting fur- ther than one day into the future one needs to use the model's own predictions in order to be able to make predictions for more than one day ahead. When forecasting further into the future these con- ditional forecasts of the variance will converge to a value called unconditional variance. As our fore- cast period is one quarter, we will approximate the volatility of future quarters with the unconditional variance.</p><p>Sector is the sector that the corresponding com- pany of the report belongs to, namely energy (ene), basic industries (ind), finance (fin), technol- ogy (tech), miscellaneous (misc), consumer non- durables (n-dur), consumer durables (dur), capital goods (capt), consumer services (serv), public util- ities (pub), and health care (hlth) <ref type="bibr">1</ref> . The feature is converted to numerical representation using one- hot encoding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Feature Fusion</head><p>To combine the text and market feature sets, the first approach, used also in previous studies ( <ref type="bibr" target="#b9">(Kogan et al., 2009;</ref><ref type="bibr" target="#b26">Wang et al., 2013)</ref>) is simply join- ing all the features in one feature space. In the context of multi-model learning, the method is re- ferred to as early fusion.</p><p>In contrast, late fusion approaches first learn a model on each feature set and then use/learn a meta model to combine their results. As our sec- ond approach, we use stacking (Wolpert, 1992), a special case of late fusion. In stacking, we first split the training set into two parts (70%-30% por- tions). Using the first portion, we train separate machine learning models for each of the text and market feature sets. Next, we predict labels of the second portion with the trained models and finally train another model to capture the combinations between the outputs of the base models. In our ex- periments, the final model is always trained with SVM with RBF kernel.</p><p>Stacking is computationally inexpensive. How-ever, due to the split of the training set, the base models or the meta model may suffer from lack of training data. A potential approach to learn both the feature sets in one model is the MKL method. The MKL algorithm (also called intermediate fusion ( <ref type="bibr" target="#b19">Noble et al., 2004)</ref>) extends the kernel of the SVM model by learning (simultaneous to the parameter learning) an optimum combination of several kernels. The MKL algorithm as formu- lated in <ref type="bibr" target="#b10">Lanckriet et al. (2004)</ref> adds the following criterion to Eq. 5 for kernel learning:</p><formula xml:id="formula_7">K * = i d i K i where i d i = 1, d i ≥ 0 (6)</formula><p>where K i is a predefined kernel. Gönen and Al- paydın (2011) mention two uses of MKL: learn- ing the optimum kernel in SVM, and combining multiple modalities (feature sets) via each kernel.</p><p>However, the optimization can be compu- tationally challenging.</p><p>We use the mklaren method <ref type="bibr" target="#b24">(Stražar and Curk, 2016</ref>) which has lin- ear complexity in the number of data instances and kernels. It has been shown to outperform recent multi kernel approximation approaches. We use RBF kernels for both the text and market feature sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiment Setup</head><p>In this section, we first describe the data, followed by introducing the baselines. We report the param- eters applied in various algorithms and describe the evaluation metrics.</p><p>Dataset We download the reports of companies of the U.S. stock markets from 2006 to 2015 from the U.S. Securities and Exchange Commis- sion (SEC) website 2 . We remove HTML tags and extract the text parts. We extract the Risk Factors section using term matching heuristics. Finally, the texts are stemmed using the Porter stemmer. We calculate the volatility values (Eq 1) and the volatility of the GARCH model based on the stock prices, collected from the Yahoo website. We filter the volatility values greater/smaller than the mean plus/minus three times the standard deviation of all the volatility values 3 .</p><p>Baselines GARCH: although the GARCH model is of market factual information, we use it as a baseline to compare the effectiveness of text-based methods with mainstream approaches.</p><p>Market: uses all the market features. For both the GARCH and Market baselines, we use an SVM learner with RBF kernel. <ref type="bibr" target="#b26">Wang et al. (2013)</ref>: they use the Lex key- word set with T C weighting scheme and the SVM method. They combine the textual features with current volatility using the early fusion method. <ref type="bibr" target="#b25">Tsai et al. (2014)</ref>: similar to <ref type="bibr" target="#b26">Wang et al. (2013)</ref>, while they use the LexExt keyword set.</p><p>Evaluation Metrics As a common metric in volatility prediction, we use the r 2 metric (square of the correlation coefficient) for evaluation:</p><formula xml:id="formula_8">r 2 =   n i=1 ( ˆ y i − ¯ ˆ y)(y i − ¯ y) n i=1 ( ˆ y i − ¯ ˆ y) 2 n i=1 (y i − ¯ y) 2   2 (7) wherê</formula><p>y i is the predicted value, y i denotes the la- bels and ¯ y, their mean. The r 2 metric indicates the proportion of variance in the labels explained by the prediction. The measure is close to 1 when the predicted values can explain a large propor- tion of the variability in the labels and 0 when it fails to explain the labels' variabilities. An alterna- tive metric, used in previous studies ( <ref type="bibr" target="#b26">Wang et al., 2013;</ref><ref type="bibr" target="#b25">Tsai and Wang, 2014;</ref><ref type="bibr" target="#b9">Kogan et al., 2009</ref>) is Mean Squared Error M SE = i ( ˆ y i − y i ) 2 /n. However, especially when comparing models, ap- plied on different test sets (e.g. performance of first quartile with second quartile), r 2 has better interpretability since it is independent of the scale of y. We use r 2 in all the experiments while the MSE measure is reported only when the models are evaluated on the same test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments and Results</head><p>In this section, first we analyse the contents of the reports, followed by studying our sentiment anal- ysis methods for volatility prediction. Finally, we investigate the effect of sentiment analysis of the reports in different industry sectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Content Analysis of 10-K Reports</head><p>Let us start our experiment with observing changes in the feature vectors of the reports over the years. To compare them, we use the state-of- the-art sentiment analysis method, introduced by <ref type="bibr" target="#b25">Tsai and Wang (2014)</ref>. We first represent the fea- ture vector of each year by calculating the centroid  <ref type="figure" target="#fig_1">Figure 1a</ref> shows the similarity heat-map for each pair of the years. We observe a high simi- larity between three ranges of years: <ref type="bibr">2006-2008, 2009-2011, and 2012-2015</ref>. These considerable differences between the centroid reports in years across these three groups hints at probable issues when using the data of the older years for the more recent ones.</p><p>To validate this, we apply 5-fold cross valida- tion, first on all the data <ref type="bibr">(2006)</ref><ref type="bibr">(2007)</ref><ref type="bibr">(2008)</ref><ref type="bibr">(2009)</ref><ref type="bibr">(2010)</ref><ref type="bibr">(2011)</ref><ref type="bibr">(2012)</ref><ref type="bibr">(2013)</ref><ref type="bibr">(2014)</ref><ref type="bibr">(2015)</ref>, and then on smaller sets by dropping the oldest year i.e. the next subsets use the reports <ref type="bibr">[2007]</ref><ref type="bibr">[2008]</ref><ref type="bibr">[2009]</ref><ref type="bibr">[2010]</ref><ref type="bibr">[2011]</ref><ref type="bibr">[2012]</ref><ref type="bibr">[2013]</ref><ref type="bibr">[2014]</ref><ref type="bibr">[2015]</ref><ref type="bibr">[2008]</ref><ref type="bibr">[2009]</ref><ref type="bibr">[2010]</ref><ref type="bibr">[2011]</ref><ref type="bibr">[2012]</ref><ref type="bibr">[2013]</ref><ref type="bibr">[2014]</ref><ref type="bibr">[2015]</ref> and so forth. The results of the r 2 measure are shown in <ref type="figure" target="#fig_1">Figure 1b</ref>. We observe that by drop- ping the oldest years one by one (from left to right in the <ref type="figure">figure)</ref>, the performance starts improving. We argue that this improvement is due to the re- duction of noise in data, noise caused by concep- tual drifts in the reports as also mentioned by <ref type="bibr" target="#b5">Dyer et al. (2016)</ref>. In fact, although in machine learning in general using more data results in better gener- alization of the model and therefore better predic- tion, the reports of the older years introduce noise.</p><p>As shown, the most coherent and largest data consists of the subset of the reports published be- tween 2012 to 2015. This subset is also the most recent cluster and presumably more similar to the future reports. Therefore, in the following, we only use this subset, which consists of 3892 re- ports, belonging to 1323 companies.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Volatility Prediction</head><p>Given the dataset of the 2012-2015 reports, we try all combinations of different term weighting schemes using the LexExt keyword set. All weighting schemes are then combined with the market features with the introduced fusion meth- ods. The prediction is done with 5-fold cross val- idation. The averages of the results of the first four quartiles (first year) are reported in <ref type="table" target="#tab_0">Table 1</ref>.</p><p>To make showing the results tractable, we use the best fusion (stacking) for the weighting schemes and the best scheme ( BM 25) for fusions. Regarding the weighting schemes, BM 25, BM 25, and T C show the best results. In general, the extended schemes (with hat) improve upon their normal forms. For the feature fusion meth- ods, stacking outperforms the other approaches in both evaluation measures. MKL however has better performance than early fusion while it has the highest computational complexity among the methods. Based on these results, as our best per- forming approach in the remainder of the paper, we use BM 25 (with LexExt set), reduced to 400 dimensions and stacking as the fusion method. <ref type="table" target="#tab_1">Table 2</ref>  forming method compared with previously exist- ing methods. Our method outperforms all state-of- the-art methods both when using textual features only as well as a combination of textual and mar- ket features.</p><p>Let us now take a closer look on the changes in the performance of the prediction in time. The results of 5-fold cross validation for both tasks on the dataset of the reports, published between 2012-2015 are shown in <ref type="figure" target="#fig_2">Figure 2a</ref>. The X-axes show eight quartiles after the publication date of the report. For comparison, the GARCH and only market features are depicted with dashed lines.</p><p>As shown, the performance of the GARCH method as well as that using only market features (Market) decrease faster in the later quartiles since the historical prices used for prediction become less relevant as time goes by. Using only text fea- tures (Text), we see a roughly similar performance between the first four quartiles (first year), while the performance, in general, slightly decreases in the second year. By combining the textual and market features (Text+Market), we see a consis- tent improvement in comparison to each of them alone. In comparison to using only market fea- tures, the combination of the features shows more stable results in the later quartiles. These results support the informativeness of the 10-K reports to more effectively foreseen volatility in long-term windows.</p><p>While the above experiments are based on cross-validation, for the sake of completeness it is noteworthy to consider the scenarios of real- world applications where the future prediction is based on past data. We therefore design three experiments by considering the reports published in <ref type="bibr">2013, 2014, and 2015</ref> as test set and the re- ports published before each year as training set <ref type="bibr">(only 2012, 2012-2013, and 2012-2014 respectively)</ref>. The results of predicting the reports of each year together with the cross validation sce- nario (CV) are shown in <ref type="figure" target="#fig_2">Figure 2b</ref>. While the performance becomes slightly worse in the target years 2013 and 2015, in general the combination of textual and market features can explain approx- imately half of volatility in the financial system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Sectors</head><p>Corporations in the same sector share not only similar products or services but also risks and in- stability factors. Considering the sentiment of the financial system as a homogeneous body may ne- glect the specific factors of each sector. We there- fore set out to investigate the existence and nature of these differences.</p><p>We start by observing the prediction perfor- mance on different sectors: We use our method from the previous section, but split the test set across sectors and plot the results in <ref type="figure" target="#fig_2">Figure 2c</ref>. The hashed areas indicate the GARCH and Mar- ket baselines for the Text and Text+Market feature sets, respectively. We observe considerable differ- ences between the performance of the sectors, es- pecially when using only sentiment analysis meth- ods (i.e. only text features).</p><p>Given these differences and also the probable similarities between the risk factors of the reports in the same sector, a question immediately arises: can training different models for different sectors improve the performance of prediction?</p><p>To answer it, for each sector, we train a model using only the subset of the reports in that sec- Sector-agnostic Sector-specific General model  tor and use 5-fold validation to observe perfor- mance. We refer to these models as sector-specific in contrast to the general model, trained on all the data. <ref type="figure" target="#fig_3">Figures 3a and 3b</ref> compare their results: we can see that the sector-specific bars are lower than the general model ones. This is to some ex- tent surprising, as one would expect that domain- specific training would improve the performance of sentiment analysis in text. However, we need to consider the size of the training set. By train- ing on each sector we have reduced the size of our training sets to those reported in <ref type="table" target="#tab_3">Table 3</ref>. To verify the effect of the size of training data, we train a sector-agnostic model for each sector. Each sector-agnostic model is trained by random sam- pling of a training set of the same size as the set available for its sector from all the reports, but evaluated-similar to sector-specific models-on the test set of the sector. <ref type="figure" target="#fig_3">Figures 3a and 3b</ref> also plot the results of the sector-agnostic models.</p><p>The large performance differences between sector-agnostic and -specific show the existence of particular risk factors in each sector and their im- portance. Results also confirm the hypothesis that the data for training in each sector is simply too small, and as additional data is accumulated, we can further improve on the results by training on different sectors independently.</p><p>We continue by examining some examples of essential terms in sectors. To address this, we have to train a linear regression method on all the re- ports of each sector, without using any dimension- ality reduction. Linear regression without dimen- sionality reduction has the benefit of interpretabil- ity: the coefficient of each feature (i.e. term in the lexicon) can be seen as its importance with regards to volatility prediction. After training, we observe that some keywords e.g. crisis, or delist constantly have high coefficient values in the sector-specific as well as general model. However, some key- words are particularly weighted high in specific- sector models.</p><p>For instance, the keyword fire has a high coeffi- cient in the energy sector, but very low in the oth- ers. The reason is due to the problem of ambiguity i.e. in the energy sector, fire is widely used to re- fer to explosion e.g. 'fire and explosion hazards' while in the lexicon, it is stemmed from firing and fired: the act of dismissing from a job. This later sense of word is however weighted as a low risk-sensitive keyword in the other sectors. Such an ambiguity can indeed be mitigated by sector- specific models since the variety of the words' senses are more restricted inside each sector. An- other example is an interesting observation on the word beneficial. The word is introduced as a pos- itive sentiment in the lexicon while it gains highly negative sentiments in some sectors (health care, and basic industries). Investigating in the reports, we observe the broad use of the expression 'bene- ficial owner' which is normally followed by risk- full sentences since the beneficial owners can po- tentially influence shareholders' decision power.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this work, we studied the sentiment of recent 10-K annual disclosures of companies in stock markets for forecasting volatility. Our bag-of- words sentiment analysis approach benefits from state-of-the-art models in information retrieval which use word embeddings to extend the weight of the terms to the similar terms in the docu- ment. Additionally, we explored fusion meth- ods to combine the text features with factual mar- ket features, achieved from historical prices i.e. GARCH prediction model, and current volatility. In both cases, our approach outperforms state-of- the-art volatility prediction methods with 10-K re- ports and demonstrates the effectiveness of senti- ment analysis in long-term volatility forecasting.</p><p>In addition, we studied the characteristics of each individual sector with regard to risk-sensitive terms. Our analysis shows that reports in same sectors considerably share particular risk and in- stability factors. However, despite expectations, training different models on different sectors does not improve performance compared to the general model. We traced this to the size of the avail- able data in each sector, and show that there are still benefits in considering sectors, which could be further explored in the future as more data be- comes available.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>where tc d i (t) is the number of occurrences of keyword t in report i, d i denotes the Eu- clidean norm of the keyword weights of the report, |d i | is the length of the report (number of the words in the report), avgdl is the average doc- ument length, and finally k and b are parameters. For them, we use the settings used in previous studies (Rekabsaz et al., 2016b) i.e. k = 1.2 and b = 0.65.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: (a) Cosine similarity between the centroid vectors of the years. (b) Volatility prediction performance when using reports from the specified year to 2015</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: (a) Performance of our approach on 8 quartiles using the Text and Text+Market feature sets. The dashed lines show the market-based baselines. (b) Performance of volatility prediction of each year given the past data. The hashed areas show corresponding baselines. (c) Performance per sector. Abbreviations are defined in Section 4.2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Results when retraining on sector-specific subsets versus the general model and versus subsets of the same size but sector-agnostic. The hashed area in (a) indicates the GARCH and in (b) the Market baseline.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 : Performance of sentiment analysis meth- ods for the first year.</head><label>1</label><figDesc></figDesc><table>Component 
Method 
Text 
Text+Market 
(r 2 ) 
(MSE) 
(r 2 ) 
(MSE) 

Weighting 
Schema 
(+Stacking) 


BM 25 
0.439 
0.132 
0.527 
0.111 
BM 25 
0.433 
0.136 
0.523 
0.114 

T C 
0.427 
0.136 
0.517 
0.115 
T C 
0.425 
0.137 
0.521 
0.114 

T F IDF 
0.301 
0.166 
0.502 
0.118 
T F IDF 
0.264 
0.189 
0.497 
0.119 

T F 
0.218 
0.190 
0.495 
0.120 
T F 
0.233 
0.200 
0.495 
0.120 

Feature Fusion 

(+ 
BM 25) 

Stacking 
-
-
0.527 
0.111 
MKL 
-
-
0.488 
0.126 
Early Fusion 
-
-
0.473 
0.125 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Performance of the methods using 5-fold 
cross validation. 

Method 
(r 2 ) (MSE) 
GARCH 
0.280 0.170 

Text 

Wang (2013) 0.345 0.154 
Tsai (2014) 
0.395 0.142 
Our method 
0.439 0.132 
Market 
0.485 0.122 

Text+Market 

Wang (2013) 0.499 0.118 
Tsai (2014) 
0.484 0.122 
Our method 
0.527 0.111 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Number of reports per sectors 

ene 
ind hlth fin 
tech pub 
187 160 305 847 408 217 
n-dur dur capt serv misc 
151 115 255 639 153 

</table></figure>

			<note place="foot" n="1"> We follow NASDAQ categorization of sectors.</note>

			<note place="foot" n="2"> https://www.sec.gov 3 The complete dataset is available in http://ifs. tuwien.ac.at/ ˜ admire/financialvolatility</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Acknowledgement</head><p>This paper follows work produced during the Young Scientists Summer Program (YSSP) 2016 at the International Institute for Applied Systems Analysis (IIASA) in Laxenburg, Austria. This work is funded by: Self-Optimizer (FFG 852624) in the EUROSTARS programme, funded by EU-REKA, the BMWFW and the European Union, ADMIRE (P 25905-N23) by FWF, and the Aus-trian Ministry for Science, Research and Econ-omy. Thanks to Joni Sayeler and Linus Wret-blad for their contributions in the SelfOptimizer project.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Generalized autoregressive conditional heteroskedasticity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>References</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bollerslev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of econometrics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="307" to="327" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The information content of mandatory risk factor disclosures in corporate filings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsinchun</forename><surname>John L Campbell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><forename type="middle">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsin-Min</forename><surname>Dhaliwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Logan B</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Steele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Review of Accounting Studies</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="396" to="455" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A comprehensive look at financial volatility prediction by economic variables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charlotte</forename><surname>Christiansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maik</forename><surname>Schmeling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Schrimpf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Econometrics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="956" to="977" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deep learning for event-driven stock prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junwen</forename><surname>Duan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Joint Conference on Artificial Intelligence (IJCAI&apos;15)</title>
		<meeting>the 24th International Joint Conference on Artificial Intelligence (IJCAI&apos;15)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2327" to="2333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Support vector regression machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harris</forename><surname>Drucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linda</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kaufman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="155" to="161" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">The ever-expanding 10-k: Why are 10-ks getting so much longer (and does it matter)? Available at SSRN 2741682</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Travis</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorien</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stice-Lawrence</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Autoregressive conditional heteroscedasticity with estimates of the variance of united kingdom inflation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Robert F Engle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica: Journal of the Econometric Society</title>
		<imprint>
			<biblScope unit="page" from="987" to="1007" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Multiple kernel learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehmet</forename><surname>Gönen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethem</forename><surname>Alpaydın</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2211" to="2268" />
			<date type="published" when="2011-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Evaluating sentiment analysis evaluation: A case study in securities trading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shunan</forename><surname>Siavash Kazemian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerald</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Penn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the Association for Computational Linguistics (ACL)</title>
		<meeting>the Conference of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page">119</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Predicting risk from financial reports with regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shimon</forename><surname>Kogan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitry</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><forename type="middle">S</forename><surname>Bryan R Routledge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Sagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>Annual Conference of the North American Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="272" to="280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning the kernel matrix with semidefinite programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">G</forename><surname>Gert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nello</forename><surname>Lanckriet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Cristianini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><forename type="middle">El</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename><surname>Ghaoui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine learning research</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="27" to="72" />
			<date type="published" when="2004-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The information content of forwardlooking statements in corporate filings-a na¨ıvena¨ıve bayesian machine learning approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Accounting Research</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1049" to="1102" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Financial volatility forecasting with range-based autoregressive volatility model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongquan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongmiao</forename><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Finance Research Letters</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="69" to="76" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Estimation of monthly volatility: An empirical comparison of realized volatility, garch and acd-icv methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shouwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiu Kuen</forename><surname>Tse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Research Collection School Of Economics</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">When is a liability not a liability? textual analysis, dictionaries, and 10-ks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Loughran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Finance</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="35" to="65" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Predicting abnormal returns from news using text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronny</forename><surname>Luss And Alexandre D&amp;apos;aspremont</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quantitative Finance</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="999" to="1012" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Document-level sentiment classification: An empirical comparison between svm and ann</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Moraes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">João</forename><forename type="middle">Francisco</forename><surname>Valiati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilson P Gavião</forename><surname>Neto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="621" to="633" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Topic modeling based sentiment analysis on social media for stock market prediction</title>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<editor>Thien Hai Nguyen and Kiyoaki Shirai</editor>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Support vector machine applications in computational biology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Stafford Noble</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Kernel methods in computational biology pages</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="71" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Detecting risks in the banking system by sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clemens</forename><surname>Nopp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allan</forename><surname>Hanbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of Empirical Methods in Natural Language Processing (EMNLP</title>
		<meeting>the Conference of Empirical Methods in Natural Language Processing (EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="591" to="600" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navid</forename><surname>Rekabsaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Lupu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allan</forename><surname>Hanbury</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.06086</idno>
		<title level="m">Uncertainty in neural network word embedding: Exploration of threshold for similarity</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Generalizing translation models in the probabilistic relevance framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navid</forename><surname>Rekabsaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Lupu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allan</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guido</forename><surname>Zuccon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM International Conference on Information and Knowledge Management (CIKM)</title>
		<meeting>ACM International Conference on Information and Knowledge Management (CIKM)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Exploration of a threshold for similarity based on uncertainty in word embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navid</forename><surname>Rekabsaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Lupu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allan</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guido</forename><surname>Zuccon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on IR Research (ECIR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Learning the kernel matrix via predictive low-rank approximations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Stražar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomaž</forename><surname>Curk</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1601.04366</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Financial keyword expansion via continuous word vector representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Feng</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan-Ju</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the Conference of Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1453" to="1458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Financial sentiment analysis for risk prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan-Ju</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Feng</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tse</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chinting</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference on Natural Language Processing (IJCNLP)</title>
		<meeting>the Joint Conference on Natural Language Processing (IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="802" to="808" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A semiparametric gaussian copula regression model for predicting financial risks from earnings calls</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenhao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Stacked generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wolpert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural networks</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="241" to="259" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Semantic Frames to Predict Stock Price Movement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><forename type="middle">J</forename><surname>Passonneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
