<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:01+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Thesis Proposal: An Investigation on The Effectiveness of Employing Topic Modeling Techniques to Provide Topic Awareness For Conversational Agents</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omid</forename><surname>Moradiannasab</surname></persName>
							<email>omidm@coli.uni-saarland.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Saarland University</orgName>
								<address>
									<postCode>66123</postCode>
									<settlement>Saarbrcken</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Thesis Proposal: An Investigation on The Effectiveness of Employing Topic Modeling Techniques to Provide Topic Awareness For Conversational Agents</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics-Student Research Workshop</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics-Student Research Workshop <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="80" to="85"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The idea behind this proposal is to investigate the possibility of utilizing NLP tools, statistical topic modeling techniques and freely available online resources to propose a system able to provide dialogue contribution suggestions which are relevant to the context, yet out of the main activity of the dialogue (i.e. off-activity talk). The aim is to evaluate the effects of a tool that automatically suggests off-activity talks in form of some sentences relevant to the dialogue context. The evaluation is to be done over two test-sets of open domain and closed-domain in a conversational quiz-like setting. The outcome of this work will be a satisfactory point of entry to investigate the hypothesis that adding automatically generated off-activity talks feature to a conversational agent can lead to building up engagement of the dialogue partner(s).</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Conversational agents (e.g. virtual characters, chat-bots, etc) are software programs that interact with users employing natural language processing capabilities. The ability to interact with user in natural language enables such automated agents to make task-oriented dialogues with the aim to provide services to human in different fields such as education, entertainment, help desks, etc. Tra- ditional conversational systems are designed for specific purposes, such as a banking service or navigating through a website. Dialogue in such systems is limited to task-bound talks (also called activity talks). These talks have a specific pur- pose and follow a particular structure. Traditional conversational systems are developed to attempt to engage the user in a natural, robust conversa- tion in well-defined domains. However, empirical investigations reveal that the effect of these sys- tems on engagement of the users with the system and their perception of the agent's intelligence is debatable ( <ref type="bibr" target="#b5">Dehn and Van Mulken, 2000</ref>). Re- lational agents, on the other hand, are defined in literature as "computational artifacts designed to establish and maintain long-term social-emotional relationships with their users" <ref type="bibr" target="#b1">(Bickmore and Picard, 2005</ref>).</p><p>In order to achieve relational agents, certain amount of user's trust and engagement is required. Various conversational strategies are employed in relational agents that comprise models of social dialogues with the aim of raising user's trust. The conversational strategy targeted in this work is off- activity talk. An off-activity talk is a verbal re- action which is required to be contextually rele- vant to the content of the previous interaction and preferably includes a provision of some added- information. This verbal reaction can consist of one or more sentences and is extracted from the freely available online resources. The output of this work can be employed as a generator of rele- vant utterances embedded in an artificial agent (i.e. a virtual character or a robot). The sub-tasks ad- dressed in this work are to analyze the dialogue context, to detect the topic, and to provide a ranked list of appropriate candidate utterances to be em- ployed by the dialogue manager in a conversation system.</p><p>With the presented idea as a starting point, ad- vantages or disadvantages of including automati- cally retrieved OATs in conversation systems can be studied. It is encouraging to investigate the ef- fect of embedding such system on engagement of the users with a conversation system. It is also desirable to investigate whether automatically re- trieved OATs can promote users' trust in knowl-edgeability of the agent and their perception of the agent's intelligence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Small Talk</head><p>As an instance of a conversational strategy em- ployment, small talk (also social talk) is discussed in literature. It is introduced as a kind of talk which executes conversational strategies. While interleaved between task-bound talks, social talk indirectly builds trust through the natural progres- sion of a conversation. <ref type="bibr" target="#b0">Bickmore and Cassell (2001)</ref> define small talk as "any talk in which in- terpersonal goals are emphasized and task goals are either non-existent or de-emphasized". Ac- cording to their work, "One strategy for effecting changes to the familiarity dimension of the rela- tionship model is for the speaker to disclose infor- mation about him/herself and induce the listener to do the same". Kl√ºwer (2015) defines it as a talk "often perceived as unsophisticated chit-chat in which content exchange is irrelevant and negli- gible". Following this definition, small talk (e.g. about the weather, events and objects around, sto- ries about the environment or the virtual character itself) represents the opposite of task-bound talk which aids the execution of a particular task. Thus, the range of topics and contents is definitely much more unrestricted in small talk than in task-bound talk. Small talk is useful to develop the conversa- tion and to avoid pauses. It can be used to ease the situation and to make a user feel more com- fortable in a conversation with an agent <ref type="bibr" target="#b3">(Cassell and Bickmore, 2000)</ref>. It is also introduced as a way of assuring certain amount of closeness to the user (e.g. before asking personal questions) <ref type="bibr" target="#b0">(Bickmore and Cassell, 2001</ref>). Small talk is also helpful to avoid repetitiveness of conversations which is counted in literature as a negative impact factor to the users' motivation in interaction with the agent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Off-Activity Talk (OAT)</head><p>Similar to small talk, off-activity talk (also called non-activity talk) is another technique to employ conversational strategies. Both small talk and off- activity talk enrich the task-oriented dialogue via opening the structure of the conversation. How- ever, OAT can be differentiated from small talk by the topic and the purpose of the talk. OAT has a specific purpose (e.g. knowledge exchange) and is about a specific topic (see <ref type="table">Table 1</ref>), while a small talk is an independent talk without any functional topic (e.g. talking about the weather). Several studies have found that the purpose of small talk is not to negotiate knowledge but to aid in manage- ment of social situation. On the other hand, off- activity talk is to disclose some information rel- evant to the dialogue context. Therefore, when- ever no divergence from the subject matter of the task-bound talk is required, OAT is preferred to small talk. Even though OAT is a diversion from the structure of the task-dialogue, it maintains the dialogue topic. <ref type="table">Table 1</ref> OAT was first defined by <ref type="bibr" target="#b9">Kruijff-Korbayova et al. (2014)</ref> in resemblance to small talk. In their work, the purpose of activity talk is knowledge exchange or knowledge probing while off-activity talk is used to break out of the fixed structure of task-bound dialogues. They use OAT in form of prerecorded questions around a set of prede- fined topics (e.g. hobbies, diabetes, eating habits, friends, diary, etc) to encourage the user to talk about those topics in order to elicit information from them. In this study, the focus is on off-activity talk with a similar definition but a differ- ent employment. An OAT in the current work is a follow-up added information relevant to the con- text of the previous interaction with the aim of encouraging users' engagement and possibly pro- moting their trust in knowledgeability and intelli- gence of the agent, thus no deliberate direct infor- mation elicitation is targeted in this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Use Case Scenario</head><p>The idea of context determination and relevant off- activity talk suggestion for dialogue contribution, in a broad sense, can be used in any task-oriented dialogue setting. However, due to its predomi- nantly verbal character and naturally constrained interaction structure, a conversational quiz-game setting is chosen as a good test bed for the current work. Some examples of dialogues in this setting, in addition to some sample OATs to be uttered by the agent right after this dialogue, are presented in <ref type="table">Table 1</ref>. In this scenario, the agent asks the user a multiple-choice question from an open do- main (A). After the user selects one of the choices (which can be correct or not) (B), the agent should give a verbal reaction (off-activity talk) (C). The follow-up needs to be related to the content of the previous interaction. It should be a piece of infor- mation on the main subject matter extracted from the available online resources and possibly, but not necessarily, confirm or give the correct answer. It can include a provision of some added information as a follow-up to the previous content.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Research Objectives</head><p>The goal of this project is to evaluate a tool which takes advantage of the Web as an online resource to seek for relevant sentence(s) to a given dialogue context. A quiz-game setting is used as the test bed for this project. The main benefit of such a tool will be to break out of the fixed structure of task-bound dialogues between an artificial agent and a human user, ideally leading to an increment in users' engagement. Off-activity talks suggested by this tool can be employed in an online or offline mode. In the offline mode, OATs will be used to create (or enrich) a handcrafted knowledge base for a virtual character. However, offline enrich- ment might not be feasible in open domain scenar- ios. That is why the author puts the ultimate aim of this work to provide an open-domain solution for real-time OAT suggestion.</p><p>In the process of this study, following research questions are to be answered:</p><p>1. What are the features of a suitable off-activity talk?</p><p>2. Which of the proposed approaches is more effective in providing a high quality sentence selection?</p><p>3. How far can one reach by employing topic modeling techniques in the proposed tool?</p><p>4. To what extent using online resources can help with breaking out of the fixed structure of the task-bound dialogue?</p><p>5. Does providing OATs via sentence selection increase user satisfaction?</p><p>6. Does providing OATs via sentence selection boost user's trust in knowledgeability and in- telligence of the agent?</p><p>7. Does providing OATs via sentence selection increase semantic cohesion of the dialogue?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Method</head><p>At large, the procedure is as follows. The first step is to identify topic-related focus terms of a dia- logue. Using these focus terms, the second step is to determine the major topic to be followed up in the conversation. The topic labels after this step do not necessarily need to match the terms that occurred within the previous dialogue. In closed- domain solutions, this can be done by mapping the focus terms onto a category taxonomy. In such a case, the taxonomy is utilized as a reference point to derive topic labels for a follow-up conversation. On the other hand, for an open-domain problem the task is not as straightforward. The reason to that is the lack of predefined taxonomy. Topic modeling techniques are employed to determine the major topic of the conversation (see 5.1). Iden- tified topic categories are subsequently combined with information retrieval and different linguistic filtering methods to improve candidate content re- trieval. In the end, the retrieved content will be ranked based on their relevance to the context and properness for dialogue contribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Topic Modeling</head><p>Topic Modeling, as a branch of text mining, is the process of identifying patterns in the text in order to classify words into groups called "topics". A topic is defined as a probability distribution over the terms in the vocabulary. In this process, top- ics are assigned to documents and terms are as- signed to topics each with specific probability dis- tributions. There are different methods to achieve this goal: LDA, HDP, NNMF, etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Evaluation Strategy</head><p>The main goal of the experimental evaluation in this study is to assess the potential of the proposed system in contributing to a dialogue with two dis- tinct partners: a questioner and an answerer. In this quiz-like setting, the output of the system is supposed to be an utterance by a conversational agent which follows the dialogue by elaborating on that and by providing relevant information in an appropriate way for a real-world dialogue con- tribution.</p><p>A dialogue system can be evaluated in various styles. The evaluation approach can be either sub- jective or objective ( <ref type="bibr" target="#b11">Walker et al., 1997</ref>). Evalu- ation metrics can be derived from questionnaires or log files <ref type="bibr" target="#b10">(Paek, 2001</ref>). The scale of the met- rics can vary from the utterance level to the whole dialogue ( <ref type="bibr" target="#b4">Danieli and</ref><ref type="bibr">Gerbino, 1995) (Kamm et al., 1999</ref>). The dialogue system can be treated as a "black box" or as a "transparent box" <ref type="bibr" target="#b6">(Hone and Graham, 2000</ref>). This variety of styles beside lack of any agreed-upon standards in the research com- munity and incompatibility of evaluation methods make evaluation of dialogue systems a challenge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Embedded or Stand-alone Strategy?</head><p>An ideal strategy to test a tool, which automati- cally suggests off-activity talks for dialogue con- tribution, is embedding the developed component in a test-bed application and assessing the change in the usability of that application by carrying out a subjective evaluation of user satisfaction. How- ever, it is not always easy to get access to such platforms and to perform the required embedding scheme. An alternative is to assess this applica- tion in a stand-alone scheme. There are some ad- vantages to assessing with a stand-alone scheme instead of an embedded one. As an example, by employing a stand-alone scheme, one can avoid problems which might occur during the interac- tion with the embedding system. Such problems can influence the usability results while we have no control over them. Therefore, the stand-alone strategy, in this case, brings the benefit to focus specifically on the quality of the OATs. The au- thor recommends to observe the inputs and out- puts of the system and while treating the system as a "black box", to measure the plausibility of the proposed approach. This also means that the measurement scale in the evaluation scheme is at utterance level, in contrast to dialogue level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Subjective or Objective Evaluation?</head><p>As stated earlier, evaluation of a dialogue system can be done with an objective or subjective ap- proach. In case of objective evaluation, metrics like resources used (e.g. time, turns, user atten- tion, etc) or the number of errors the system makes or inappropriate utterances made by the system can be mentioned. In some cases, a number of specified definitions of task success is used as an objective metric. However, it is not always easy to define task success in an objective way. The subjective measurement of the acceptance of an application or technology belongs to the group of usability evaluation. Usability evaluation focuses on users and their needs. Through usability eval- uation, we want to figure out if a system can be used for the specific purpose from the user's point of view, and if it allows the users to achieve their goals, meeting their expectations. The most im- portant criterion for measuring usability is user's satisfaction. The author proposes to assess the use- fulness of the suggested OATs from the tool by measuring user satisfaction with regard to a spe- cific factor. That means, the evaluation strategy falls into the category of subjective evaluation.</p><p>Information about user satisfaction is usually gathered through interviews and questionnaires in the end of a session of interaction with a dialogue system. In principle, the goal of this work is not to establish a dialogue with the human, but to create a component to be integrated in a dialogue system and provide suggestions to the dialogue manager of such a system. That is why, it is not possi- ble to evaluate user's satisfaction in the end of a dialogue session. Alternatively, we can ask par- ticipants to qualify the suggested OATs separately and regardless of any potential preceding or fol- lowing dialogue. In other words, the experiment is not designed as a dialogue; instead, pairs of inputs and outputs of the system are presented to partici- pants and they are asked to define which output is more satisfactory regarding some well-described aspects.</p><p>In contrast to objective evaluation techniques which are fairly well-established, subjective mea- surements are not as structured and straightfor- ward. A difficulty which arises here is that dia- logue systems and their users sometimes have in- consistent attitudes toward a dialogue. As a conse- quence, extra care needs to be taken to make sure that the participants of the experiments have a cor- rect sense of what is needed to measure in a quali- fication process. Different factors must be defined with regard to which the quality of an OAT is to be measured. So, It is needed to provide accu- rate instructions to make sure the participant has comprehended the differences and is able to dis- tinguish between these factors. The author also proposes to use some test questions as a means to make sure that the participants have read and clearly understood the instructions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Evaluation Factors</head><p>In order to judge the usefulness of an OAT, it is needed to define the aspects of evaluation. The type of application determines the aspects that are important for a usability evaluation. To decide about the main aspect of the evaluation, the author largely relies upon SASSI methodology <ref type="bibr" target="#b6">(Hone and Graham, 2000</ref>). SASSI is a methodology for evaluating spoken dialogue systems. They state that the previously reported subjective techniques are unproven. Also, It is argued that their con- tent and structure are, for the most part, arbi- trary and the items chosen for a questionnaire or rating scales are based neither on theory nor on well-conducted empirical research. The reasons for choosing a particular structure in the previous studies (e.g. questions, statements or numerical scales) and sub-structure (presentation, number of points on a scale, etc.) are not reported. There- fore, they use factor analysis to determine the main components of users' attitude and also define suit- able rating scales for each of these components. Resultant factors after labeling are:    The first factor (response accuracy) does not fully match this application. The reason is that ac- curacy or the number of errors refer to the users' expectation of what the system is supposed to do in response to the input utterance. So, a specific goal like acting appropriately should be defined which is not necessarily the case with a free off- activity talk. The third group <ref type="bibr">(Cognitive Demand)</ref> refers to the perceived amount of effort needed to interact with a dialogue system and the feelings re- sulting from this effort. Since in the current case the participant is not actually talking to the sys- tem but rating some contributions in a conversa- tion, therefore it is not suitable to ask their opin- ion about how it will feel to talk to it or how much effort will be needed to say something easily com- prehensible to the system. The fifth group (habit- ability) also refers to whether the user knows what to say to the system at each turn which is not use- ful as reasoned for the third group. The sixth factor (speed) is also not proper because the participants do not interact in real-time to the system and only rates some logged interactions. So, they do not know how fast the system works.</p><p>Among the factors mentioned in SASSI, lika- bility and annoyance are applicable for the cur- rent experiment. In addition, questions of some other features are also important to us (e.g. nat- uralness, repetitiveness, etc). Altogether, the au- thor proposes the items in <ref type="table">Table 2</ref>. For each ap- propriateness judgment, this list of statements is disclosed to the participants and they are asked to check those which are true in their subjective opin- ion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 2: Appropriateness judgment statements</head><p>Judgment Statement This is a natural response. Talking to a system with such a response is boring. I would enjoy talking to a system which responds like this. This talk is repetitive. Such an utterance by a robot is frustrating. The system knows how to speak to the human. The follow-up provides relevant added-information.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>: Some samples of a suitable OAT Sub-dialogue(A+B) And Follow-up OAT(C) A: What is the capital of Chechnya? B: Grozny C: Not long ago, Grozny, the capital of Chechnya, was called the most devastated city on Earth. A: What is the capital of Chechnya? B: Grozny C: Chechnya Republic is a federal subject of the Russian Federation, part of North Caucasian District. A: When was the Berlin Wall built? B: in 1961 C: Originally a barbed wire fence, the first concrete sections were built in 1965. A: When was Elvis Presley's first record recorded? B: on July 5, 1954 C: On July 5 1954, Elvis Presley changed music world forever. A: How many portions of fruit and vegetables should we try to eat? B: At least five a day C: Healthy diet means 10 portions of fruit and vegetables per day, not five.</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Relational agents: a model and implementation of building user trust</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Bickmore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justine</forename><surname>Cassell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI conference on Human factors in computing systems</title>
		<meeting>the SIGCHI conference on Human factors in computing systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="396" to="403" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Establishing and maintaining long-term humancomputer relationships</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Timothy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rosalind</forename><forename type="middle">W</forename><surname>Bickmore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Picard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Computer-Human Interaction (TOCHI)</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="293" to="327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">External manifestations of trustworthiness in the interface</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justine</forename><surname>Cassell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Bickmore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="50" to="56" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Metrics for evaluating dialogue strategies in a spoken language system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morena</forename><surname>Danieli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisabetta</forename><surname>Gerbino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1995 AAAI spring symposium on Empirical Methods in Discourse Interpretation and Generation</title>
		<meeting>the 1995 AAAI spring symposium on Empirical Methods in Discourse Interpretation and Generation</meeting>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="34" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The impact of animated interface agents: a review of empirical research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Doris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susanne</forename><surname>Dehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Mulken</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of humancomputer studies</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Towards a tool for the subjective assessment of speech system interfaces (sassi)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kate</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Hone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Graham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3&amp;4</biblScope>
			<biblScope unit="page" from="287" to="303" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Evaluating spoken language systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Candace</forename><surname>Kamm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Marilyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Litman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of AVIOS. Citeseer</title>
		<meeting>of AVIOS. Citeseer</meeting>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Social talk capabilities for dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tina</forename><surname>Kl√ºwer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Effects of off-activity talk in human-robot interaction with diabetic children</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivana</forename><surname>Kruijff-Korbayova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elettra</forename><surname>Oleari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilaria</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernd</forename><surname>Kiefer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mattia</forename><surname>Coti Zelati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clara</forename><surname>Pozzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Sanna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robot and Human Interactive Communication</title>
		<meeting><address><addrLine>RO-MAN</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="649" to="654" />
		</imprint>
	</monogr>
	<note>The 23rd IEEE International Symposium on</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Empirical methods for evaluating dialog systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Paek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the workshop on Evaluation for Language and Dialogue Systems</title>
		<meeting>the workshop on Evaluation for Language and Dialogue Systems</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2001" />
			<biblScope unit="volume">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Paradise: A framework for evaluating spoken dialogue agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Marilyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><forename type="middle">J</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Candace</forename><forename type="middle">A</forename><surname>Litman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alicia</forename><surname>Kamm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Abella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the eighth conference on European chapter of the Association for Computational Linguistics</title>
		<meeting>the eighth conference on European chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="271" to="280" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
