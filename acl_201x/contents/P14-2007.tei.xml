<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:07+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Measuring Sentiment Annotation Complexity of Text</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>June 23-25 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Joshi</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Monash University</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">IITB-Monash Research Academy</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhijit</forename><surname>Mishra</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nivvedan</forename><surname>Senthamilselvan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushpak</forename><surname>Bhattacharyya</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">IIT Bombay</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Measuring Sentiment Annotation Complexity of Text</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="36" to="41"/>
							<date type="published">June 23-25 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The effort required for a human annota-tor to detect sentiment is not uniform for all texts, irrespective of his/her expertise. We aim to predict a score that quantifies this effort, using linguistic properties of the text. Our proposed metric is called Sentiment Annotation Complexity (SAC). As for training data, since any direct judgment of complexity by a human annota-tor is fraught with subjectivity, we rely on cognitive evidence from eye-tracking. The sentences in our dataset are labeled with SAC scores derived from eye-fixation duration. Using linguistic features and annotated SACs, we train a regressor that predicts the SAC with a best mean error rate of 22.02% for five-fold cross-validation. We also study the correlation between a human annotator&apos;s perception of complexity and a machine&apos;s confidence in polarity determination. The merit of our work lies in (a) deciding the sentiment annotation cost in, for example, a crowdsourcing setting, (b) choosing the right classifier for sentiment prediction.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The effort required by a human annotator to de- tect sentiment is not uniform for all texts. Com- pare the hypothetical tweet "Just what I wanted: a good pizza." with "Just what I wanted: a cold pizza.". The two are lexically and structurally similar. However, because of the sarcasm in the second tweet (in "cold" pizza, an undesirable sit- uation followed by a positive sentiment phrase "just what I wanted", as discussed in <ref type="bibr" target="#b20">Riloff et al. (2013)</ref>), it is more complex than the first for senti- ment annotation. Thus, independent of how good the annotator is, there are sentences which will be perceived to be more complex than others. With regard to this, we introduce a metric called senti- ment annotation complexity (SAC). The SAC of a given piece of text (sentences, in our case) can be predicted using the linguistic properties of the text as features.</p><p>The primary question is whether such complex- ity measurement is necessary at all. Fort et al (2012) describe the necessity of annotation com- plexity measurement in manual annotation tasks. Measuring annotation complexity is beneficial in annotation crowdsourcing. If the complexity of the text can be estimated even before the annota- tion begins, the pricing model can be fine-tuned (pay less for sentences that are easy to annotate, for example). Also, in terms of an automatic SA engine which has multiple classifiers in its ensem- ble, a classifier may be chosen based on the com- plexity of sentiment annotation (for example, use a rule-based classifier for simple sentences and a more complex classifier for other sentences). Our metric adds value to sentiment annotation and sen- timent analysis, in these two ways. The fact that sentiment expression may be complex is evident from a study of comparative sentences by <ref type="bibr" target="#b8">Ganapathibhotla and Liu (2008)</ref>, sarcasm by <ref type="bibr" target="#b20">Riloff et al. (2013)</ref>, thwarting by <ref type="bibr" target="#b19">Ramteke et al. (2013)</ref> or implicit sentiment by <ref type="bibr" target="#b0">Balahur et al. (2011)</ref>. To the best of our knowledge, there is no general ap- proach to "measure" how complex a piece of text is, in terms of sentiment annotation.</p><p>The central challenge here is to annotate a data set with SAC. To measure the "actual" time spent by an annotator on a piece of text, we use an eye- tracker to record eye-fixation duration: the time for which the annotator has actually focused on the sentence during annotation. Eye-tracking an- notations have been used to study the cognitive as- pects of language processing tasks like translation by <ref type="bibr" target="#b4">Dragsted (2010)</ref> and sense disambiguation by <ref type="bibr">Joshi et al. (2011)</ref>. <ref type="bibr" target="#b14">Mishra et al. (2013)</ref> present a technique to determine translation difficulty index. The work closest to ours is by <ref type="bibr">Scott et al. (2011)</ref> who use eye-tracking to study the role of emotion words in reading.</p><p>The novelty of our work is three-fold: (a) The proposition of a metric to measure complexity of sentiment annotation, (b) The adaptation of past work that uses eye-tracking for NLP in the con- text of sentiment annotation, (c) The learning of regressors that automatically predict SAC using linguistic features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Understanding Sentiment Annotation Complexity</head><p>The process of sentiment annotation consists of two sub-processes: comprehension (where the an- notator understands the content) and sentiment judgment (where the annotator identifies the sen- timent). The complexity in sentiment annotation stems from an interplay of the two and we expect SAC to capture the combined complexity of both the sub-processes. In this section, we describe how complexity may be introduced in sentiment annotation in different classical layers of NLP. The simplest form of sentiment annotation com- plexity is at the lexical level. Consider the sen- tence "It is messy, uncouth, incomprehensible, vi- cious and absurd". The sentiment words used in this sentence are uncommon, resulting in com- plexity.</p><p>The next level of sentiment annotation com- plexity arises due to syntactic complexity. Con- sider the review: "A somewhat crudely con- structed but gripping, questing look at a person so racked with self-loathing, he becomes an enemy to his own race.". An annotator will face difficulty in comprehension as well as sentiment judgment due to the complicated phrasal structure in this re- view. Implicit expression of sentiment introduces complexity at the semantic and pragmatic level. Sarcasm expressed in "It's like an all-star salute to disney's cheesy commercialism" leads to difficulty in sentiment annotation because of positive words like "an all-star salute".</p><p>Manual annotation of complexity scores may not be intuitive and reliable. Hence, we use a cog- nitive technique to create our annotated dataset. The underlying idea is: if we monitor annotation of two textual units of equal length, the more com- plex unit will take longer to annotate, and hence, should have a higher SAC. Using the idea of "an- notation time" linked with complexity, we devise a technique to create a dataset annotated with SAC.</p><p>It may be thought that inter-annotator agree- ment (IAA) provides implicit annotation: the higher the agreement, the easier the piece of text is for sentiment annotation. However, in case of multiple expert annotators, this agreement is ex- pected to be high for most sentences, due to the expertise. For example, all five annotators agree with the label for 60% sentences in our data set. However, the duration for these sentences has a mean of 0.38 seconds and a standard deviation of 0.27 seconds. This indicates that although IAA is easy to compute, it does not determine sentiment annotation complexity of text in itself.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Creation of dataset annotated with SAC</head><p>We wish to predict sentiment annotation complex- ity of the text using a supervised technique. As stated above, the time-to-annotate is one good can- didate. However, "simple time measurement" is not reliable because the annotator may spend time not doing any annotation due to fatigue or distrac- tion. To accurately record the time, we use an eye-tracking device that measures the "duration of eye-fixations 1 ". Another attribute recorded by the eye-tracker that may have been used is "saccade duration 2 ". However, saccade duration is not sig- nificant for annotation of short text, as in our case. Hence, the SAC labels of our dataset are fixation durations with appropriate normalization. It may be noted that the eye-tracking device is used only to annotate training data. The actual prediction of SAC is done using linguistic features alone.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Eye-tracking Experimental Setup</head><p>We use a sentiment-annotated data set consisting of movie reviews by <ref type="bibr" target="#b17">(Pang and Lee, 2005</ref>) and tweets from http://help.sentiment140. com/for-students. A total of 1059 sen- tences (566 from a movie corpus, 493 from a twit- ter corpus) are selected.</p><p>We then obtain two kinds of annotation from five paid annotators: (a) sentiment (positive, nega- tive and objective), (b) eye-movement as recorded 3. The experiment then continues in modules of 50 sentences at a time. This is to prevent fa- tigue over a period of time. Thus, each an- notator participates in this experiment over a number of sittings.</p><p>We ensure the quality of our dataset in different ways: (a) Our annotators are instructed to avoid unnecessary head movements and eye-movements outside the experiment environment. (b) To min- imize noise due to head movements further, they are also asked to state the annotation verbally, which was then manually recorded, (c) Our an- notators are students between the ages 20-24 with English as the primary language of academic in- struction and have secured a TOEFL iBT score of 110 or above. We understand that sentiment is nuanced-to- wards a target, through constructs like sarcasm and presence of multiple entities. However, we want to capture the most natural form of sentiment anno- tation. So, the guidelines are kept to a bare mini- mum of "annotating a sentence as positive, nega- tive and objective as per the speaker". This exper- iment results in a data set of 1059 sentences with a fixation duration recorded for each sentence- annotator pair <ref type="bibr">3</ref> The multi-rater kappa IAA for sen- timent annotation is 0.686.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Calculating SAC from eye-tracked data</head><p>We now need to annotate each sentence with a SAC. We extract fixation durations of the five an- notators for each of the annotated sentences. A single SAC score for sentence s for N annotators is computed as follows:</p><formula xml:id="formula_0">SAC(s) = 1 N N n=1 z(n,dur(s,n)) len(s)</formula><p>where, z(n, dur(s, n)) = dur(s,n)−µ(dur(n))</p><formula xml:id="formula_1">σ(dur(n))<label>(1)</label></formula><p>In the above formula, N is the total number of an- notators while n corresponds to a specific annota- tor. dur(s, n) is the fixation duration of annotator n on sentence s. len(s) is the number of words in sentence s. This normalization over number of words assumes that long sentences may have high dur(s, n) but do not necessarily have high SACs. µ(dur(n)), σ(dur(n)) is the mean and standard deviation of fixation durations for anno- tator n across all sentences. z(n, .) is a function that z-normalizes the value for annotator n to stan- dardize the deviation due to reading speeds. We convert the SAC values to a scale of 1-10 using min-max normalization. To understand how the formula records sentiment annotation complexity, consider the SACs of examples in section 2. The sentence "it is messy , uncouth , incomprehensi- ble , vicious and absurd" has a SAC of 3.3. On the other hand, the SAC for the sarcastic sentence "it's like an all-star salute to disney's cheesy commer- cialism." is 8.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Predictive Framework for SAC</head><p>The previous section shows how gold labels for SAC can be obtained using eye-tracking experi- ments. This section describes our predictive for SAC that uses four categories of linguistic fea- tures: lexical, syntactic, semantic and sentiment- related in order to capture the subprocesses of an- notation as described in section 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experiment Setup</head><p>The linguistic features described in <ref type="table">Table 3</ref>.2 are extracted from the input sentences. Some of these</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feature</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Description Lexical -Word Count -Degree of polysemy Average number of Wordnet senses per word -Mean Word Length</head><p>Average number of characters per word (commonly used in readability studies as in the case of <ref type="bibr">Pascual et al. (2005)</ref>) -%ge of nouns and adjs. -%ge of Out-of- vocabulary words Syntactic -Dependency Distance</p><p>Average distance of all pairs of dependent words in the sentence (Lin, 1996) -Non-terminal to Ter- minal ratio</p><p>Ratio of the number of non-terminals to the number of terminals in the con- stituency parse of a sentence Semantic -Discourse connectors Number of discourse connectors -Co-reference distance Sum of token distance between co-referring entities of anaphora in a sentence -Perplexity</p><p>Trigram perplexity using language models trained on a mixture of sentences from the Brown corpus, the Amazon Movie corpus and Stanford twitter corpus (mentioned in Sections 3 and 5) Sentiment-related (Computed using SentiWordNet ( <ref type="bibr" target="#b5">Esuli et al., 2006</ref></p><formula xml:id="formula_2">)) - Subjective Word Count -Subjective Score</formula><p>Sum of SentiWordNet scores of all words -Sentiment Flip Count A positive word followed in sequence by a negative word, or vice versa counts as one sentiment flip </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head><p>The results are tabulated in <ref type="table" target="#tab_2">Table 2</ref>. Our obser- vation is that a quadratic kernel performs slightly better than linear. The correlation values are pos- itive and indicate that even if the predicted scores are not as accurate as desired, the system is capa- ble of ranking sentences in the correct order based on their sentiment complexity. The mean percent- age error (MPE) of the regressors ranges between 22-38.21%. The cross-domain MPE is higher than the rest, as expected.</p><p>To understand how each of the features per- forms, we conducted ablation tests by con- sidering one feature at a time.</p><p>Based on the MPE values, the best features are: Mean word length (MPE=27.54%), Degree of Polysemy (MPE=36.83%) and %ge of nouns and adjectives (MPE=38.55%). To our surprise, word count per- forms the worst (MPE=85.44%). This is unlike tasks like translation where length has been shown  to be one of the best predictors in translation dif- ficulty ( <ref type="bibr" target="#b14">Mishra et al., 2013</ref>). We believe that for sentiment annotation, longer sentences may have more lexical clues that help detect the sentiment more easily. Note that some errors may be intro- duced in feature extraction due to limitations of the NLP tools.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>Our proposed metric measures complexity of sen- timent annotation, as perceived by human annota- tors. It would be worthwhile to study the human- machine correlation to see if what is difficult for a machine is also difficult for a human. In other words, the goal is to show that the confidence scores of a sentiment classifier are negatively cor- related with SAC.</p><p>We use three sentiment classification tech- niques: Na¨ıveNa¨ıve Bayes, MaxEnt and SVM with un- igrams, bigrams and trigrams as features. The training datasets used are: a) 10000 movie reviews from Amazon Corpus <ref type="bibr" target="#b13">(McAuley et. al, 2013</ref>) and b) 20000 tweets from the twitter corpus (same as mentioned in section 3). Using NLTK and Scikit- learn 7 with default settings, we generate six posi- tive/negative classifiers, for all possible combina- tions of the three models and two datasets.</p><p>The confidence score of a classifier 8 for given text t is computed as follows:</p><formula xml:id="formula_3">P : P robability of predicted class Conf idence(t) =    P if predicted polarity is correct 1 − P otherwise<label>(2)</label></formula><p>7 http://scikit-learn.org/stable/ 8 In case of SVM, the probability of predicted class is com- puted as given in <ref type="bibr" target="#b18">Platt (1999</ref>  <ref type="table">Table 3</ref>: Correlation between confidence of the classifiers with SAC; Numbers in parentheses in- dicate classifier accuracy (%) <ref type="table">Table 3</ref> presents the accuracy of the classifiers along with the correlations between the confidence score and observed SAC values. MaxEnt has the highest negative correlation of -0.29 and -0.26. For both domains, we observe a weak yet nega- tive correlation which suggests that the perception of difficulty by the classifiers are in line with that of humans, as captured through SAC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion &amp; Future Work</head><p>We presented a metric called Sentiment Annota- tion Complexity (SAC), a metric in SA research that has been unexplored until now. First, the pro- cess of data preparation through eye tracking, la- beled with the SAC score was elaborated. Using this data set and a set of linguistic features, we trained a regression model to predict SAC. Our predictive framework for SAC resulted in a mean percentage error of 22.02%, and a moderate corre- lation of 0.57 between the predicted and observed SAC values. Finally, we observe a negative corre- lation between the classifier confidence scores and a SAC, as expected. As a future work, we would like to investigate how SAC of a test sentence can be used to choose a classifier from an ensemble, and to determine the pre-processing steps (entity- relationship extraction, for example).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Gaze-data recording using Translog-II</figDesc><graphic url="image-1.png" coords="3,72.00,63.80,219.18,53.17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Linguistic Features for the Predictive Framework 

features are extracted using Stanford Core NLP 4 
tools and NLTK (Bird et al., 2009). Words that 
do not appear in Academic Word List 5 and Gen-
eral Service List 6 are treated as out-of-vocabulary 
words. The training data consists of 1059 tuples, 
with 13 features and gold labels from eye-tracking 
experiments. 
To predict SAC, we use Support Vector Regres-
sion (SVR) (Joachims, 2006). Since we do not 
have any information about the nature of the rela-
tionship between the features and SAC, choosing 
SVR allows us to try multiple kernels. We carry 
out a 5-fold cross validation for both in-domain 
and cross-domain settings, to validate that the re-
gressor does not overfit. The model thus learned is 
evaluated using: (a) Error metrics namely, Mean 
Squared Error estimate, Mean Absolute Error esti-
mate and Mean Percentage Error. (b) the Pearson 
correlation coefficient between the gold and pre-

4 http://nlp.stanford.edu/software/ 
corenlp.shtml 
5 www.victoria.ac.nz/lals/resources/academicwordlist/ 
6 www.jbauman.com/gsl.html 

dicted SAC. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Performance of Predictive Framework for 5-fold in-domain and cross-domain validation using 
Mean Squared Error (MSE), Mean Absolute Error (MAE) and Mean Percentage Error (MPE) estimates 
and correlation with the gold labels. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>) .</head><label>.</label><figDesc></figDesc><table>Classifier (Corpus) 
Correlation 
Na¨ıveNa¨ıve Bayes (Movie) -0.06 (73.35) 
Na¨ıveNa¨ıve Bayes (Twitter) -0.13 (71.18) 
MaxEnt (Movie) 
-0.29 (72.17) 
MaxEnt (Twitter) 
-0.26 (71.68) 
SVM (Movie) 
-0.24 (66.27) 
SVM (Twitter) 
-0.19 (73.15) 

</table></figure>

			<note place="foot" n="1"> A long stay of the visual gaze on a single location. 2 A rapid movement of the eyes between positions of rest on the sentence.</note>

			<note place="foot" n="3"> The complete eye-tracking data is available at:http:// www.cfilt.iitb.ac.in/ ˜ cognitive-nlp/.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Detecting implicit expressions of sentiment in text based on commonsense knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Balahur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesús</forename><forename type="middle">M</forename><surname>Hermida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrés</forename><surname>Montoyo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis</title>
		<meeting>the 2nd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="53" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The Rediscovery of the Mind</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Batali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">R</forename><surname>Searle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="177" to="193" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Natural Language Processing with Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ewan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Loper</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<pubPlace>O&apos;Reilly Media</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Translog-II: A Program for Recording User Activity Data for Empirical Reading and Writing Research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Carl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eight International Conference on Language Resources and Evaluation</title>
		<meeting>the Eight International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Co-ordination of reading and writing processes in translation. Contribution to Translation and Cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dragsted</surname></persName>
		</author>
		<editor>Shreve, G. and Angelone, E.</editor>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Cognitive Science Society</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Sentiwordnet: A publicly available lexical resource for opinion mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Esuli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sebastiani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fabrizio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC</title>
		<meeting>LREC</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="417" to="422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">WordNet: An electronic lexical database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christiane</forename><surname>Fellbaum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge. MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karën</forename><surname>Fort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adeline</forename><surname>Nazarenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sophie</forename><surname>Rosset</surname></persName>
		</author>
		<title level="m">Modeling the complexity of manual annotation tasks: A grid of analysis Proceedings of the International Conference on Computational Linguistics</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Identifying preferred entities in comparative sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ganapathibhotla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">22nd International Conference on Computational Linguistics (COLING)</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Identifying Sarcasm in Twitter: A Closer Look</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>González-Ibáñez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Muresan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wacholder</forename><surname>Smaranda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACL</title>
		<imprint>
			<biblScope unit="page" from="581" to="586" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note>Short Papers</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
		<title level="m">Training Linear SVMs in Linear Time Proceedings of the ACM Conference on Knowledge Discovery and Data Mining (KDD)</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">On the structural complexity of natural language sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of the 16th International Conference on Computational Linguistics (COLING)</title>
		<meeting>eeding of the 16th International Conference on Computational Linguistics (COLING)</meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page">729733</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Martınez-Gómez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akiko</forename><surname>Aizawa</surname></persName>
		</author>
		<title level="m">Diagnosing Causes of Reading Difficulty using Bayesian Networks International Joint Conference on Natural Language Processing</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page">13831391</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd international conference on World Wide Web</title>
		<meeting>the 22nd international conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhijit</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pushpak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Carl</surname></persName>
		</author>
		<title level="m">Automatically Predicting Sentence Translation Difficulty Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="346" to="351" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Sentiment Analysis of Conditional Sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramanathan</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alok</forename><surname>Choudhary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2009 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="180" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Opinion mining and sentiment analysis Foundations and trends in information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 43rd Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="115" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods Advances in large margin classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Platt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="61" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankit</forename><surname>Ramteke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akshat</forename><surname>Malu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pushpak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Saketha</surname></persName>
		</author>
		<title level="m">Detecting Turnarounds in Sentiment Analysis: Thwarting Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="860" to="865" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashequl</forename><surname>Qadir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Surve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">De</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lalindra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruihong</forename><surname>Huang</surname></persName>
		</author>
		<title level="m">Sarcasm as Contrast between a Positive Sentiment and Negative Situation Conference on Empirical Methods in Natural Language Processing</title>
		<meeting><address><addrLine>Seattle, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">More than meets the eye: Study of Human Cognition in Sense Annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salil</forename><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NAACL HLT</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Diptesh Kanojia and Pushpak Bhattacharyya</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Emotion Words Affect Eye Fixations During Reading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sereno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Journal of Experimental Psychology:Learning, Memory, and Cognition 2012</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="783" to="792" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Nonparametric Statistics for the Behavioral Sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sidney</forename><surname>Siegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Castellan</surname><genName>Jr</genName></persName>
		</author>
		<imprint>
			<date type="published" when="1988" />
			<publisher>McGraw-Hill</publisher>
		</imprint>
	</monogr>
	<note>Second edition</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
