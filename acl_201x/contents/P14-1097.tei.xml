<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:45+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Step-wise Usage-based Method for Inducing Polysemy-aware Verb Classes</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>June 23-25 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daisuke</forename><surname>Kawahara</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">W</forename><surname>Peterson</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Colorado at Boulder</orgName>
								<address>
									<settlement>Boulder</settlement>
									<region>CO</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Colorado at Boulder</orgName>
								<address>
									<settlement>Boulder</settlement>
									<region>CO</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Kyoto University</orgName>
								<address>
									<settlement>Kyoto</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Step-wise Usage-based Method for Inducing Polysemy-aware Verb Classes</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1030" to="1040"/>
							<date type="published">June 23-25 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present an unsupervised method for inducing verb classes from verb uses in giga-word corpora. Our method consists of two clustering steps: verb-specific semantic frames are first induced by clustering verb uses in a corpus and then verb classes are induced by clustering these frames. By taking this step-wise approach, we can not only generate verb classes based on a massive amount of verb uses in a scalable manner, but also deal with verb polysemy, which is bypassed by most of the previous studies on verb clustering. In our experiments , we acquire semantic frames and verb classes from two giga-word corpora, the larger comprising 20 billion words. The effectiveness of our approach is verified through quantitative evaluations based on polysemy-aware gold-standard data.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A verb plays a primary role in conveying the meaning of a sentence. Capturing the sense of a verb is essential for natural language processing (NLP), and thus lexical resources for verbs play an important role in NLP.</p><p>Verb classes are one such lexical resource. Manually-crafted verb classes have been devel- oped, such as Levin's classes ( <ref type="bibr" target="#b15">Levin, 1993)</ref> and their extension, VerbNet <ref type="bibr" target="#b11">(Kipper-Schuler, 2005</ref>), in which verbs are organized into classes on the basis of their syntactic and semantic behavior. Such verb classes have been used in many NLP ap- plications that need to consider semantics in par- ticular, such as word sense disambiguation <ref type="bibr" target="#b3">(Dang, 2004)</ref>, semantic parsing ( <ref type="bibr" target="#b41">Swier and Stevenson, 2005;</ref><ref type="bibr" target="#b33">Shi and Mihalcea, 2005</ref>) and discourse pars- ing ( <ref type="bibr" target="#b37">Subba and Di Eugenio, 2009)</ref>.</p><p>There have also been many attempts to auto- matically acquire verb classes with the goal of ei- ther adding frequency information to an existing resource or of inducing similar verb classes for other languages. Most of these approaches assume that all target verbs are monosemous <ref type="bibr" target="#b36">(Stevenson and Joanis, 2003;</ref><ref type="bibr" target="#b32">Schulte im Walde, 2006;</ref><ref type="bibr" target="#b8">Joanis et al., 2008;</ref><ref type="bibr" target="#b17">Li and Brew, 2008;</ref><ref type="bibr" target="#b39">Sun et al., 2008;</ref><ref type="bibr" target="#b38">Sun and Korhonen, 2009;</ref><ref type="bibr" target="#b45">Vlachos et al., 2009;</ref><ref type="bibr" target="#b26">Parisien and Stevenson, 2010;</ref><ref type="bibr" target="#b27">Parisien and Stevenson, 2011;</ref><ref type="bibr" target="#b6">Falk et al., 2012;</ref><ref type="bibr" target="#b18">Lippincott et al., 2012;</ref><ref type="bibr" target="#b28">Reichart and Korhonen, 2013;</ref><ref type="bibr" target="#b40">Sun et al., 2013)</ref>. This monosemous assumption, however, is not realistic because many frequent verbs actually have multiple senses. Moreover, to the best of our knowledge, none of the following approaches at- tempt to quantitatively evaluate soft clusterings of verb classes induced by polysemy-aware unsuper- vised approaches ( <ref type="bibr" target="#b12">Korhonen et al., 2003;</ref><ref type="bibr" target="#b14">Lapata and Brew, 2004;</ref><ref type="bibr" target="#b16">Li and Brew, 2007;</ref><ref type="bibr" target="#b31">Schulte im Walde et al., 2008)</ref>.</p><p>In this paper, we propose an unsupervised method for inducing verb classes that is aware of verb polysemy. Our method consists of two clustering steps: verb-specific semantic frames are first induced by clustering verb uses in a cor- pus and then verb classes are induced by clus- tering these frames. By taking this step-wise ap- proach, we can not only induce verb classes with frequency information from a massive amount of verb uses in a scalable manner, but also deal with verb polysemy.</p><p>Our novel contributions are summarized as fol- lows:</p><p>• induce both semantic frames and verb classes from a massive amount of verb uses by a scal- able method,</p><p>• explicitly deal with verb polysemy,</p><p>• discover effective features for each of the clustering steps, and</p><p>• quantitatively evaluate a soft clustering of verbs.  <ref type="table" target="#tab_1">/1*#(CD?!#E=@FG!  (/D"!E=5F&lt;!</ref> 2#%2?!-"%&amp;.)%'/)+(% A%2?!-"#+%!"#%B&amp;*/#% H#%2/00%2?!-"%!"#%D?B#% 7% 7! 7! I#)'%-0? <ref type="table" target="#tab_1">((#(8!   J#B?1C-%&gt;)?B#(8!   I#)</ref>'%.(#(8! <ref type="figure">Figure 1</ref>: Overview of our two-step approach. Verb-specific semantic frames are first induced from verb uses (lower part) and then verb classes are induced from the semantic frames (upper part). The labels of verb classes are manually assigned here for better understanding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>As stated in Section 1, most of the previous studies on verb clustering assume that verbs are monose- mous. A typical method in these studies is to rep- resent each verb as a single data point and apply classification (e.g., <ref type="bibr" target="#b8">Joanis et al. (2008)</ref>) or clus- tering (e.g., <ref type="bibr" target="#b38">Sun and Korhonen (2009)</ref>) to these data points. As a representation for a data point, distributions of subcategorization frames are often used, and other semantic features (e.g., selectional preferences) are sometimes added to improve the performance. Among these studies on monosemous verb clus- tering (i.e., predominant class induction), there have been several Bayesian methods. <ref type="bibr" target="#b45">Vlachos et al. (2009)</ref> proposed a Dirichlet process mix- ture model <ref type="bibr">(DPMM;</ref><ref type="bibr" target="#b25">Neal (2000)</ref>) to cluster verbs based on subcategorization frame distributions. They evaluated their result with a gold-standard test set, where a single class is assigned to a verb. <ref type="bibr" target="#b26">Parisien and Stevenson (2010)</ref> proposed a hierar- chical Dirichlet process (HDP; <ref type="bibr" target="#b42">Teh et al. (2006)</ref>) model to jointly learn argument structures (sub- categorization frames) and verb classes by using syntactic features. <ref type="bibr" target="#b27">Parisien and Stevenson (2011)</ref> extended their model by adding semantic features. They tried to account for verb learning by children and did not evaluate the resultant verb classes. <ref type="bibr" target="#b24">Modi et al. (2012)</ref> extended the model of , which is an unsupervised model for inducing semantic roles, to jointly in- duce semantic roles and frames across verbs using the Chinese Restaurant Process <ref type="bibr">(Aldous, 1985)</ref>. All of the above methods considered verbs to be monosemous and did not deal with verb polysemy.</p><p>Our approach also uses Bayesian methods, but is designed to capture verb polysemy.</p><p>We summarize a few studies that consider poly- semy of verbs in the rest of this section. <ref type="bibr" target="#b23">Miyao and Tsujii (2009)</ref> proposed a supervised method that can handle verb polysemy. Their method represents a verb's syntactic and seman- tic features, and learns a log-linear model from the SemLink corpus ( <ref type="bibr" target="#b20">Loper et al., 2007)</ref>. <ref type="bibr" target="#b2">Boleda et al. (2007)</ref> also proposed a supervised method for Catalan adjectives considering the polysemy of adjectives.</p><p>The most closely related work to our polysemy- aware task of unsupervised verb class induction is the work of <ref type="bibr" target="#b12">Korhonen et al. (2003)</ref>, who used dis- tributions of subcategorization frames to cluster verbs. They adopted the Nearest Neighbor (NN) and Information Bottleneck (IB) methods for clus- tering. In particular, they tried to consider verb polysemy by using the IB method, which is a soft clustering method ( <ref type="bibr" target="#b43">Tishby et al., 1999</ref>). However, the verb itself is still represented as a single data point. After performing soft clustering, they noted that most verbs fell into a single class, and they decided to assign a single class to each verb by hardening the clustering. They considered multi- ple classes only in the gold-standard data used for their evaluations. We also evaluate our induced verb classes on this gold-standard data, which was created on the basis of Levin's classes <ref type="bibr" target="#b15">(Levin, 1993)</ref>. <ref type="bibr" target="#b14">Lapata and Brew (2004)</ref> and <ref type="bibr" target="#b16">Li and Brew (2007)</ref> proposed probabilistic models for calculat- ing prior probabilities of verb classes for a verb. These models are approximated to condition not on verbs but on subcategorization frames. As mentioned in <ref type="bibr" target="#b16">Li and Brew (2007)</ref>, it is desirable to extend the model to depend on verbs to fur- ther improve accuracy. They conducted several evaluations including predominant class induction and token-level verb sense disambiguation, but did not evaluate multiple classes output by their mod- els. Schulte im <ref type="bibr" target="#b31">Walde et al. (2008)</ref> also applied probabilistic soft clustering to verbs by incorporat- ing subcategorization frames and selectional pref- erences based on WordNet. This model is based on the Expectation-Maximization algorithm and the Minimum Description Length principle. Since they focused on the incorporation of selectional preferences, they did not evaluate verb classes but evaluated only selectional preferences using a lan- guage model-based measure.</p><p>Materna proposed LDA-frames, which are de- fined across verbs and can be considered to be a kind of verb class <ref type="bibr" target="#b21">(Materna, 2012;</ref><ref type="bibr" target="#b22">Materna, 2013)</ref>. LDA-frames are probabilistic semantic frames automatically induced from a raw corpus. He used a model based on latent Dirichlet allo- cation (LDA; <ref type="bibr" target="#b1">Blei et al. (2003)</ref>) and the Dirichlet process to cluster verb instances of a triple (sub- ject, verb, object) to produce semantic frames and roles. Both of these are represented as a proba- bilistic distribution of words across verbs. He ap- plied this method to the BNC and acquired 1,200 frames and 400 roles <ref type="bibr" target="#b21">(Materna, 2012</ref>). He did not evaluate the resulting frames as verb classes.</p><p>In sum, there have been no studies that quantita- tively evaluate polysemous verb classes automati- cally induced by unsupervised methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Our Approach</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview</head><p>Our objective is to automatically learn semantic frames and verb classes from a massive amount of verb uses following usage-based approaches. Although Bayesian approaches are a possible so- lution to simultaneously induce frames and verb classes from a corpus as used in previous stud- ies, it has prohibitive computational cost. For in- stance, Parisien and Stevenson applied HDP only to a small-scale child speech corpus that contains 170K verb uses to jointly induce subcategoriza- tion frames and verb classes <ref type="bibr" target="#b26">(Parisien and Stevenson, 2010;</ref><ref type="bibr" target="#b27">Parisien and Stevenson, 2011</ref>). Ma- terna applied an LDA-based method to the BNC, which contains 1.4M verb uses, to induce seman- tic frames across verbs that can be considered to be verb classes <ref type="bibr" target="#b21">(Materna, 2012;</ref><ref type="bibr" target="#b22">Materna, 2013)</ref>. However, it would take three months for this ex- periment using this 100 million word corpus. 1 Al- though it is best to use the largest possible cor- pus for this kind of knowledge acquisition tasks ( <ref type="bibr" target="#b30">Sasano et al., 2009)</ref>, it is infeasible to scale to giga-word corpora using such joint models.</p><p>In this paper, we propose a two-step approach for inducing semantic frames and verb classes. First, we make multiple data points for each verb to deal with verb polysemy (cf. polysemy-aware previous studies still represented a verb as one data point <ref type="bibr" target="#b12">(Korhonen et al., 2003;</ref><ref type="bibr" target="#b23">Miyao and Tsujii, 2009)</ref>). To do that, we induce verb-specific semantic frames by clustering verb uses. Then, we induce verb classes by clustering these verb- specific semantic frames across verbs. An interest- ing point here is that we can use exactly the same method for these two clustering steps.</p><p>Our procedure to automatically induce verb classes from verb uses is summarized as follows:</p><p>1. induce verb-specific semantic frames by clus- tering predicate-argument structures for each verb extracted from automatic parses as shown in the lower part of <ref type="figure">Figure 1</ref>, and 2. induce verb classes by clustering the induced semantic frames across verbs as shown in the upper part of <ref type="figure">Figure 1</ref>.</p><p>Each of these two steps is described in the follow- ing sections in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Inducing Verb-specific Semantic Frames</head><p>We induce verb-specific semantic frames from verb uses based on the method of <ref type="bibr" target="#b10">Kawahara et al. (2014)</ref>. Our semantic frames consist of case slots, each of which consists of word instances that can be filled. The procedure for inducing these seman- tic frames is as follows:</p><p>1. apply dependency parsing to a raw corpus and extract predicate-argument structures for each verb from the automatic parses, 2. merge the predicate-argument structures that have presumably the same meaning based on the assumption of one sense per colloca- tion <ref type="bibr" target="#b46">(Yarowsky, 1993)</ref> to get a set of initial frames, and 3. apply clustering to the initial frames based on the Chinese Restaurant Process <ref type="bibr">(Aldous, 1985)</ref> to produce verb-specific seman- tic frames.</p><p>These three steps are briefly described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Extracting Predicate-argument</head><p>Structures from a Raw Corpus We apply dependency parsing to a large raw cor- pus. We use the Stanford parser with Stanford dependencies <ref type="bibr" target="#b4">(de Marneffe et al., 2006</ref>). <ref type="bibr">2</ref> Col- lapsed dependencies are adopted to directly extract prepositional phrases.</p><p>Then, we extract predicate-argument structures from the dependency parses. Dependents that have the following dependency relations to a verb are extracted as arguments: nsubj, xsubj, dobj, iobj, ccomp, xcomp, prep * In this process, the verb and arguments are lem- matized, and only the head of an argument is pre- served for compound nouns.</p><p>Predicate-argument structures are collected for each verb and the subsequent processes are ap- plied to the predicate-argument structures of each verb.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Constructing Initial Frames from</head><p>Predicate-argument Structures To make the computation feasible, we merge the predicate-argument structures that have the same or similar meaning to get initial frames. These ini- tial frames are the input of the subsequent cluster- ing process. For this merge, we assume one sense per collocation <ref type="bibr" target="#b46">(Yarowsky, 1993)</ref> for predicate- argument structures.</p><p>For each predicate-argument structure of a verb, we couple the verb and an argument to make a unit for sense disambiguation. We select an argument in the following order by considering the degree of effect on the verb sense: 3 dobj, ccomp, nsubj, prep * , iobj.</p><p>Then, the predicate-argument structures that have the same verb and argument pair (slot and word, e.g., "dobj:effect") are merged into an ini- tial frame. After this process, we discard minor initial frames that occur fewer than 10 times.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Clustering Method</head><p>We cluster initial frames for each verb to pro- duce semantic frames using the Chinese Restau- rant Process <ref type="bibr">(Aldous, 1985)</ref>, regarding each initial frame as an instance.</p><p>We calculate the posterior probability of a clus- ter c j given an initial frame f i as follows:</p><formula xml:id="formula_0">P (c j |f i ) ∝ { n(c j ) N +α · P (f i |c j ) c j ̸ = new α N +α · P (f i |c j ) c j = new,<label>(1)</label></formula><p>where N is the number of initial frames for the tar- get verb and n(c j ) is the current number of initial frames assigned to the cluster c j . α is a hyper- parameter that determines how likely it is for a new cluster to be created. In this equation, the first term is the Dirichlet process prior and the second term is the likelihood of f i . P (f i |c j ) is defined based on the Dirichlet- Multinomial distribution as follows:</p><formula xml:id="formula_1">P (f i |c j ) = ∏ w∈V P (w|c j ) count(f i ,w) ,<label>(2)</label></formula><p>where V is the vocabulary in all case slots cooc- curring with the verb and count(f i , w) is the num- ber of w in the initial frame f i . The original method in <ref type="bibr" target="#b10">Kawahara et al. (2014)</ref> defined w as pairs of slots and words, e.g., "nsubj:child" and "dobj:bird," but does not consider slot-only fea- tures, e.g., "nsubj" and "dobj," which ignore lex- ical information. Here we experiment with both representations and compare the results. P (w|c j ) is defined as follows:</p><formula xml:id="formula_2">P (w|c j ) = count(c j , w) + β ∑ t∈V count(c j , t) + |V | · β ,<label>(3)</label></formula><p>where count(c j , w) is the current number of w in the cluster c j , and β is a hyper-parameter of Dirichlet distribution. For a new cluster, this prob- ability is uniform (1/|V |).</p><p>We regard each output cluster as a semantic frame, by merging the initial frames in a clus- ter into a semantic frame. In this way, semantic frames for each verb are acquired.</p><p>We use Gibbs sampling to realize this cluster- ing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Inducing Verb Classes from Semantic Frames</head><p>To induce verb classes across verbs, we apply clustering to the induced verb-specific semantic frames. We can use exactly the same clustering method as described in Section 3.2.3 by using se- mantic frames for multiple verbs as an input in- stead of initial frames for a single verb. This is because an initial frame has the same structure as a semantic frame, which is produced by merging initial frames. We regard each output cluster as a verb class this time.</p><p>For the features, w, in equation <ref type="formula" target="#formula_1">(2)</ref>, we try the two representations again: slot-only features and slot-word pair features. The representation using only slots corresponds to the consideration of only syntactic argument patterns. The other representa- tion using the slot-word pairs means that semantic similarity based on word overlap is naturally con- sidered by looking at lexical information. We will compare in our experiments four possible combi- nations: two feature representations for each of the two clustering steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments and Evaluations</head><p>We first describe our experimental settings and de- fine evaluation metrics to evaluate induced soft clusterings of verb classes. Then, we con- duct type-level multi-class evaluations, type-level single-class evaluations and token-level multi- class evaluations. These two levels of evaluations are performed by considering the work of <ref type="bibr" target="#b29">Reichart et al. (2010)</ref> on clustering evaluation. Finally, we discuss the results of our full experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Settings</head><p>We use two kinds of large-scale corpora: a web corpus and the English Gigaword corpus.</p><p>To prepare a web corpus, we extracted sen- tences from crawled web pages that are judged to be written in English based on the encoding infor- mation. Then, we selected sentences that consist of at most 40 words, and removed duplicated sen- tences. From this process, we obtained a corpus of one billion sentences, totaling approximately 20 billion words. We focused on verbs whose fre- quency in the web corpus was more than 1,000. There were 19,649 verbs, including phrasal verbs, and separating passive and active constructions. We extracted 2,032,774,982 predicate-argument structures.</p><p>We also used the English Gigaword corpus (LDC2011T07; English Gigaword Fifth Edition). This corpus consists of approximately 180 mil- lion sentences, which totaling four billion words. There were 7,356 verbs after applying the same frequency threshold as the web corpus. We ex- tracted 423,778,278 predicate-argument structures from this corpus.</p><p>We set the hyper-parameters α in (1) and β in (3) to 1.0. The cluster assignments for all the com- ponents were initialized randomly. We took 100 samples for each input frame and selected the clus- ter assignment that has the highest probability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation Metrics</head><p>To measure the precision and recall of a cluster- ing, modified purity and inverse purity (also called collocation or weighted class accuracy) are com- monly used in previous studies on verb clustering (e.g., <ref type="bibr" target="#b38">Sun and Korhonen (2009)</ref>). However, since these measures are only applicable to a hard clus- tering, it is necessary to extend them to be applica- ble to a soft clustering, because in our task a verb can belong to multiple clusters or classes. <ref type="bibr">4</ref> We propose a normalized version of modified purity and inverse purity. This kind of normalization for soft clusterings was performed for other evalua- tion metrics as in <ref type="bibr" target="#b35">Springorum et al. (2013)</ref>.</p><p>To measure the precision of a clustering, a nor- malized version of modified purity is defined as follows. Suppose K is the set of automatically in- duced clusters and G is the set of gold classes. Let K i be the verb vector of the i-th cluster and G j be the verb vector of the j-th gold class. Each com- ponent of these vectors is a normalized frequency, which equals a cluster/class attribute probability given a verb. Where there is no frequency in- formation available for class distribution, such as the gold-standard data described in Section 4.3, we use a uniform distribution across the verb's classes. The core idea of purity is that each clus- ter K i is associated with its most prevalent gold class. In addition, to penalize clusters that consist of only one verb, such singleton clusters in K are considered as errors, as is usual with modified pu- rity. The normalized modified purity (nmPU) can then be written as follows: where N denotes the total number of verbs, |K i | denotes the number of positive components in K i , and c iv denotes the v-th component of</p><formula xml:id="formula_3">nmPU = 1 N ∑ i s.t. |K i |&gt;1 max j δ K i (K i ∩ G j ),<label>(4)</label></formula><formula xml:id="formula_4">δ K i (K i ∩ G j ) = ∑ v∈K i ∩G j c iv ,<label>(5)</label></formula><formula xml:id="formula_5">K i . δ K i (K i ∩ G j )</formula><p>means the total mass of the set of verbs in K i ∩ G j , given by summing up the values in K i . In case of evaluating a hard clustering, this is equal to |K i ∩ G j | because all the values of c iv are equal to 1. As usual, the following normalized inverse pu- rity (niPU) is used to measure the recall of a clus- tering:</p><formula xml:id="formula_6">niPU = 1 N ∑ j max i δ G j (K i ∩ G j ).<label>(6)</label></formula><p>Finally, we use the harmonic mean (F 1 ) of nmPU and niPU as a single measure of clustering quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Type-level Multi-class Evaluations</head><p>We first evaluate our induced verb classes on the test set created by <ref type="bibr" target="#b12">Korhonen et al. (2003)</ref> (  <ref type="table" target="#tab_1">Table 1</ref>.</p><p>As our baselines, we adopt two previously pro- posed methods. We first implemented a soft clus- tering method for verb class induction proposed by <ref type="bibr" target="#b12">Korhonen et al. (2003)</ref>. They used the information bottleneck (IB) method for assigning probabilities of classes to each verb. Note that <ref type="bibr" target="#b12">Korhonen et al. (2003)</ref> actually hardened the clusterings and left method K nmPU niPU F 1 IB <ref type="bibr">(k=35, t=0.10)</ref> 35.0 53.59 51.44 52.44 IB <ref type="bibr">(k=35, t=0.05)</ref> 35.0 53.67 52.62 53.10 IB <ref type="bibr">(k=35, t=0.02)</ref> 35.0 54.42 54.43 54.40 IB <ref type="bibr">(k=35, t=0.01)</ref> 35.0 54.60 55.54 55.04 IB <ref type="bibr">(k=42, t=0.10)</ref> 41.6 55.42 49.46 52.24 IB <ref type="bibr">(k=42, t=0.05)</ref> 41.8 55.55 49.97 52.59 IB <ref type="bibr">(k=42, t=0.02)</ref> 42.0 56.19 51.24 53.58 IB <ref type="bibr">(k=42, t=0.01)</ref> 42  "S" denotes the use of slot-only features and "SW" denotes the use of slot-word pair features. For ex- ample, "SW-S" means that slot-word pair features are used for semantic frame induction and slot- only features are used for verb class induction.</p><p>the evaluations of soft clusterings for their future work. For input data, we employ VALEX ( <ref type="bibr" target="#b13">Korhonen et al., 2006</ref>), which is a publicly-available large-scale subcategorization lexicon. 5 By follow- ing the method of <ref type="bibr" target="#b12">Korhonen et al. (2003)</ref>  available on the web site. <ref type="bibr">6</ref> This frame data was in- duced from the BNC and consists of 1,200 frames and 400 semantic roles. Again, we set a threshold for frame attribute probabilities.</p><p>We report results using our methods with four feature combinations (slot-only (S) and slot-word pair (SW) features each used for both the frame- generation and verb-class clustering steps) for both the Gigaword and web corpora. <ref type="table" target="#tab_3">Table 2</ref> lists evaluation results for the baseline methods and our methods. <ref type="bibr">7</ref> The results of the IB baseline and our methods are obtained by averaging five runs.</p><p>We can see that "web/SW-S" achieved the best performance and obtained a higher F 1 than the baselines by more than nine points. "Web/SW- S" uses the combination of slot-word pair fea- tures for clustering verb-specific frames and slot- only features for clustering across verbs. Inter- estingly, this result indicates that slot distributions are more effective than lexical information in slot- word pairs for inducing verb classes similar to the gold standard. This result is consistent with ex- pectations, given a gold standard based on Levin's verb classes, which are organized according to the syntactic behavior of verbs. The use of slot-word pairs for verb class induction generally merged too many frames into each class, apparently due to ac- cidental word overlaps across verbs.</p><p>The verb classes induced from the web corpus achieved a higher F 1 than those from the Gigaword corpus. This can be attributed to the larger size of the web corpus. The employment of this kind of huge corpus is enabled by our scalable method. <ref type="bibr">6</ref> http://nlp.fi.muni.cz/projekty/lda-frames/ <ref type="bibr">7</ref> Although we do not think that the classes with very small attribute probabilities are meaningful, the F1 scores for lower thresholds than 0.01 converged to about 66 in the case of LDA-frames.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Type-level Single-class Evaluations against Predominant/Multiple Classes</head><p>Since we focus on the handling of verb polysemy, predominant class induction for each verb is not our main objective. However, we wish to compare our method with previous work on the induction of a predominant (monosemous) class for each verb.</p><p>To output a single class for each verb by us- ing our proposed method, we skip the induction of verb-specific semantic frames and instead cre- ate a single frame for each verb by merging all predicate-argument structures of the verb. Then, we apply clustering to these frames across verbs. For clustering features, we again compare two rep- resentations: slot-only features (S) and slot-word pair features (SW).</p><p>We evaluate the single-class output for each verb based on the predominant gold-standard classes, which are defined for each verb in the test set of <ref type="bibr" target="#b12">Korhonen et al. (2003)</ref>. This data con- tains 110 verbs and 33 classes. We evaluate these single-class outputs in the same manner as <ref type="bibr" target="#b12">Korhonen et al. (2003)</ref>, using the gold standard with mul- tiple classes, which we also use for our multi-class evaluations.</p><p>As we did with the multi-class evaluations, we adopt modified purity (mPU), inverse purity (iPU) and their harmonic mean (F 1 ) as the metrics for the evaluation with predominant classes. It is not nec- essary to normalize these metrics when we treat verbs as monosemous, and evaluate against the predominant sense. When we evaluate against the multiple classes in the gold standard, we do nor- malize the inverse purity.</p><p>For baselines, we once more adopt the Nearest Neighbor (NN) and Information Bottleneck (IB) methods proposed by <ref type="bibr" target="#b12">Korhonen et al. (2003)</ref>, and LDA-frames proposed by <ref type="bibr" target="#b21">Materna (2012)</ref>. The clusterings with the NN and IB methods are ob- tained by using the VALEX subcategorization lex- icon. To harden the clusterings of the IB method and the LDA-frames, the class with the highest probability is selected for each verb. This hard- ening process is exactly the same as <ref type="bibr" target="#b12">Korhonen et al. (2003)</ref>. Note that our results of the NN and IB methods are different from those reported in their paper since the data source is different. 8 <ref type="table" target="#tab_5">Table 3</ref> lists accuracies of baseline methods and our methods. Our proposed method using the web corpus achieved comparable performance with the baseline methods on the predominant class evalu- ation and outperformed them on the multiple class evaluation. More sophisticated methods for pre- dominant class induction, such as the method of <ref type="bibr" target="#b38">Sun and Korhonen (2009)</ref> using selectional pref- erences, could produce better single-class outputs, but have difficulty in producing polysemy-aware verb classes.</p><p>From the result, we can see that the induced verb classes based on slot-only features did not achieve a higher F 1 than those based on slot-word pair features in many cases. This result is differ- ent from that of multi-class evaluations in Section 4.3. We speculate that slot distributions are not so different among verbs when all uses of a verb are merged into one frame, and thus their discrimina- tion power is lower than that in the intermediate construction of semantic frames.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Token-level Multi-class Evaluations</head><p>We conduct token-level multi-class evaluations us- ing 119 verbs, which appear 100 or more times in sections 02-21 of the SemLink WSJ corpus. These 119 verbs cover 102 VerbNet classes, and 48 of them are polysemous in the sense of being in more than one VerbNet class. Each instance of these 119 verbs in this corpus belongs to one of 102 Verb- Net classes. We first add these instances to the instances from a raw corpus and apply the two- step clustering to these merged instances. Then, we compare the induced verb classes of the Sem- Link instances with their gold-standard VerbNet classes. We report the values of modified purity (mPU), inverse purity (iPU) and their harmonic mean (F 1 ). It is not necessary to normalize these metrics because the clustering of these instances is hard.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>method</head><p>K mPU iPU F 1 Gigaword/S-NIL -93.43 20.06 33.03 Gigaword/SW-NIL -94.45 41.07 57.25 Gigaword/S-S 512.2 75.06 45.26 56.47 Gigaword/SW-S 260.6 73.98 56.45 64.04 web/S-NIL -93.70 32.96 48.76 web/SW-NIL -94.51 44.95 60.92 web/S-S 500.0 72.25 52.48 60.79 web/SW-S 255.2 72.65 61.00 66.31 For clustering features, we compare two fea- ture combinations: "S-S" and "SW-S," which achieved high performance in the type-level multi- class evaluations (Section 4.3). The results of these methods are obtained by averaging five runs. For a baseline, we use verb-specific semantic frames without clustering across verbs ("S-NIL" and "SW-NIL"), where these frames are consid- ered to be verb classes but not shared across verbs. <ref type="table" target="#tab_6">Table 4</ref> lists accuracies of these methods for the two corpora. We can see that "SW-S" achieved a higher F 1 than "S-S" and the baselines without verb class induction ("S-NIL" and "SW-NIL"). <ref type="bibr" target="#b24">Modi et al. (2012)</ref> induced semantic frames across verbs using the monosemous assumption and reported an F 1 of 44.7% (77.9% PU and 31.4% iPU) for the assignment of FrameNet frames to the FrameNet corpus. We also con- ducted the above evaluation against FrameNet frames for 75 verbs. <ref type="bibr">9</ref> We achieved an F 1 of 62.79% (66.97% mPU and 59.09% iPU) for "web/SW-S," and an F 1 of 60.06% (65.58% mPU and 55.39% iPU) for "Gigaword/SW-S." It is dif- ficult to directly compare these results with <ref type="bibr" target="#b24">Modi et al. (2012)</ref>, but our induced verb classes seem to have higher F 1 accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Full Experiments and Discussions</head><p>We finally induce verb classes from the semantic frames of 1,667 verbs, which appear at least once in sections 02-21 of the WSJ corpus. Based on the best results in the above evaluations, we in- duced semantic frames using slot-word pair fea- tures, and then induced verb classes using slot- only features. We ended with 38,481 semantic frames and 699 verb classes from the Gigaword <ref type="table">Table 5</ref>: Examples of induced verb classes. Un- derlined semantic frames are shown in <ref type="table">Table 6.</ref> corpus, and 61,903 semantic frames and 840 verb classes from the web corpus. It took two days to induce verb classes from the Gigaword corpus and three days from the web corpus.</p><p>Examples of verb classes and semantic frames induced from the web corpus are shown in <ref type="table">Table  5</ref> and <ref type="table">Table 6</ref>. While there are many classes with consistent meanings, such as "Class 4" and "Class 16," some classes have mixed meanings. For in- stance, "Class 2" consists of the semantic frames "need:2" and "say:2." These frames were merged due to the high syntactic similarity of constituting slot distributions, which are comprised of a sub- ject and a sentential complement. To improve the quality of verb classes, it is necessary to develop a clustering model that can consider syntactic and lexical similarity in a balanced way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We presented a step-wise unsupervised method for inducing verb classes from instances in giga- word corpora. This method first clusters predicate- argument structures to induce verb-specific se- mantic frames and then clusters these semantic frames across verbs to induce verb classes. Both clustering steps are performed with exactly the same method, which is based on the Chinese Restaurant Process.  <ref type="table">Table 6</ref>: Examples of induced semantic frames. The number following an instance word denotes its frequency and ⟨s⟩ denotes a sentential comple- ment.</p><p>From the results, we can see that the combi- nation of the slot-word pair features for cluster- ing verb-specific frames and the slot-only features for clustering across verbs is the most effective and outperforms the baselines by approximately 10 points. This indicates that slot distributions are more effective than lexical information in slot- word pairs for the induction of verb classes, when Levin-style classes are used for evaluation. This is consistent with Levin's principle of organizing verb classes according to the syntactic behavior of verbs.</p><p>As applications of the resulting semantic frames and verb classes, we plan to integrate them into syntactic parsing, semantic role labeling and verb sense disambiguation. For instance, <ref type="bibr" target="#b9">Kawahara and Kurohashi (2006)</ref> improved accuracy of de- pendency parsing based on Japanese semantic frames automatically induced from a raw corpus. It is also valuable and promising to apply the in- duced verb classes to NLP applications as used in metaphor identification ( <ref type="bibr" target="#b34">Shutova et al., 2010)</ref> and argumentative zoning <ref type="bibr" target="#b7">(Guo et al., 2011</ref>).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 of</head><label>1</label><figDesc></figDesc><table>their paper) which was created by considering 
verb polysemy on the basis of Levin's classes and 
the LCS database (Dorr, 1997). It consists of 62 
classes and 110 verbs, out of which 35 verbs are 
monosemous and 75 verbs are polysemous. The 
average number of verb classes per verb is 2.24. 
An excerpt from this data is shown in </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Type-level multi-class evaluations. K rep-
resents the (average) number of induced classes. 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Type-level single-class evaluations against predominant/multiple classes. K represents the (av-
erage) number of induced classes. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Token-level evaluations against VerbNet 
classes. K represents the average number of in-
duced classes. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head></head><label></label><figDesc>The resulting semantic frames and verb classes are open to the public and also can be searched via our web interface. 10</figDesc><table>10 http://nlp.ist.i.kyoto-u.ac.jp/member/kawahara/cf/crp.en/ 

slot 
instance words 
nsubj you:2150273, i:7678, we:4599, ... 
need:2 ccomp ⟨s⟩:2193321 

nsubj she:1705781, he:20693, i:9422, ... 
say:2 
ccomp ⟨s⟩:1829616 
nsubj i:11100, he:10323, we:6373, ... 
dobj 
me:30646, you:27678, us:21642, ... 
inform:1 prep of decision:846, this:759, situation:688, ... 
. . . 

nsubj we:7505, you:3439, i:1035, ... 
dobj 
you:18604, us:7281, them:3649, ... 
notify:2 prep of change:1540, problem:496, status:386, ... 
. . . 

</table></figure>

			<note place="foot" n="1"> In our replication experiment, it took a week to perform 70 iterations using Materna&apos;s code and an Intel Xeon E5-2680 (2.7GHz) CPU. To reach 1,000 iterations, which are reported to be optimum, it would take three months.</note>

			<note place="foot" n="2"> http://nlp.stanford.edu/software/lex-parser.shtml 3 If a predicate-argument structure has multiple prepositional phrases, one of them is randomly selected.</note>

			<note place="foot" n="4"> Korhonen et al. (2003) evaluated hard clusterings based on a gold standard with multiple classes per verb. They reported only precision measures including modified purity, and avoided extending the evaluation metrics for soft clusterings.</note>

			<note place="foot" n="5"> http://ilexir.co.uk/applications/valex/</note>

			<note place="foot" n="8"> Korhonen et al. (2003) reported that the highest modified purity was 49% against predominant classes and 60% against multiple classes.</note>

			<note place="foot" n="9"> Since FrameNet frames are not assigned to all verbs of SemLink, the number of verbs is different from the evaluations against VerbNet classes.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported by Kyoto University John Mung Program and JST CREST. We also gratefully acknowledge the support of the National Science Foundation Grant NSF-IIS-1116782, A Bayesian Approach to Dynamic Lexical Re-sources for Flexible Language Processing. Any opinions, findings, and conclusions or recommen-dations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<title level="m">References David Aldous. 1985. Exchangeability and related topics. ´ Ecole d&apos; ´ Eté de Probabilités de Saint-Flour XIII 1983</title>
		<imprint>
			<biblScope unit="page" from="1" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Latent Dirichlet allocation. the Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Modelling polysemy in adjective classes by multi-label classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gemma</forename><surname>Boleda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabine</forename><surname>Schulte Im Walde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toni</forename><surname>Badia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="171" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Investigations into the role of lexical semantics in word sense disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoa</forename><forename type="middle">Trang</forename><surname>Dang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
		<respStmt>
			<orgName>University of Pennsylvania</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Generating typed dependency parses from phrase structure parses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Catherine</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Maccartney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Conference on Language Resources and Evaluation</title>
		<meeting>the 5th International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="449" to="454" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Large-scale dictionary construction for foreign language tutoring and interlingual machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><forename type="middle">J</forename><surname>Dorr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Translation</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="271" to="322" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Classifying French verbs using French and English lexical resources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ingrid</forename><surname>Falk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Gardent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Charles</forename><surname>Lamirel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="854" to="863" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A weakly-supervised approach to argumentative zoning of scientific documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yufan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thierry</forename><surname>Poibeau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="273" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A general feature space for automatic verb classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Joanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suzanne</forename><surname>Stevenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>James</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="337" to="367" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A fully-lexicalized probabilistic model for Japanese syntactic and case structure analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daisuke</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Human Language Technology Conference of the NAACL</title>
		<meeting>the Human Language Technology Conference of the NAACL</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="176" to="183" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Inducing example-based semantic frames from a massive amount of verb uses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daisuke</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">W</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Octavian</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 14th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">VerbNet: A BroadCoverage, Comprehensive Verb Lexicon</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karin</forename><surname>Kipper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-</forename><surname>Schuler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
		<respStmt>
			<orgName>University of Pennsylvania</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Clustering polysemic subcategorization frame distributions semantically</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuval</forename><surname>Krymolowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zvika</forename><surname>Marx</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 41st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="64" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A large subcategorization lexicon for natural language processing applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuval</forename><surname>Krymolowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ted</forename><surname>Briscoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Conference on Language Resources and Evaluation</title>
		<meeting>the 5th International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="345" to="352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Verb class disambiguation using informative priors. Computational Linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brew</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="45" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">English verb classes and alternations: A preliminary investigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beth</forename><surname>Levin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>The University of Chicago Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Disambiguating Levin verbs using untagged data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianguo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference Recent Advances in Natural Language Processing</title>
		<meeting>the International Conference Recent Advances in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Which are the best features for automatic verb classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianguo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-08: HLT</title>
		<meeting>ACL-08: HLT</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="434" to="442" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning syntactic verb frames using graphical models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Lippincott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diarmuid´o Diarmuid´ Diarmuid´o</forename><surname>Séaghdha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th</title>
		<meeting>the 50th</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<title level="m">Annual Meeting of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="page" from="420" to="429" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Combining lexical resources: mapping between PropBank and VerbNet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Loper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Szu-Ting</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Workshop on Computational Linguistics</title>
		<meeting>the 7th International Workshop on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">LDA-frames: An unsupervised approach to generating semantic frames</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiří</forename><surname>Materna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Conference CICLing 2012, Part I</title>
		<meeting>the 13th International Conference CICLing 2012, Part I</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="376" to="387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Parameter estimation for LDAframes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiří</forename><surname>Materna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="482" to="486" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Supervised learning of a probabilistic lexicon of verb semantic classes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuke</forename><surname>Miyao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun&amp;apos;ichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2009 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1328" to="1337" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Unsupervised induction of frame-semantic representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashutosh</forename><surname>Modi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Klementiev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL-HLT Workshop on the Induction of Linguistic Structure</title>
		<meeting>the NAACL-HLT Workshop on the Induction of Linguistic Structure</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Markov chain sampling methods for Dirichlet process mixture models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Neal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of computational and graphical statistics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="249" to="265" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning verb alternations in a usage-based Bayesian model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Parisien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suzanne</forename><surname>Stevenson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd Annual Meeting of the Cognitive Science Society</title>
		<meeting>the 32nd Annual Meeting of the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Generalizing between form and meaning using learned verb classes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Parisien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suzanne</forename><surname>Stevenson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd Annual Meeting of the Cognitive Science Society</title>
		<meeting>the 33rd Annual Meeting of the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Improved lexical acquisition through DPP-based verb clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="862" to="872" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Type level clustering evaluation: New measures and a POS induction case study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omri</forename><surname>Abend</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Rappoport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Conference on Computational Natural Language Learning</title>
		<meeting>the 14th Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="77" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The effect of corpus size on case frame acquisition for discourse analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryohei</forename><surname>Sasano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daisuke</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="521" to="529" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Combining EM training and the MDL principle for an automatic verb classification incorporating selectional preferences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabine</forename><surname>Schulte Im Walde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Hying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Scheible</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helmut</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-08: HLT</title>
		<meeting>ACL-08: HLT</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="496" to="504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Experiments on the automatic induction of German semantic verb classes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabine</forename><surname>Schulte Im Walde</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="159" to="194" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Putting pieces together: Combining FrameNet, VerbNet and WordNet for robust semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Linguistics and Intelligent Text Processing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="100" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Metaphor identification using verb and noun clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekaterina</forename><surname>Shutova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics</title>
		<meeting>the 23rd International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1002" to="1010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Detecting polysemy in hard and soft cluster analyses of German preposition vector spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvia</forename><surname>Springorum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabine</forename><surname>Schulte Im Walde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Utt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Joint Conference on Natural Language Processing</title>
		<meeting>the 6th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="632" to="640" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Semisupervised verb class discovery using noisy features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suzanne</forename><surname>Stevenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Joanis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Conference on Natural Language Learning</title>
		<meeting>the 7th Conference on Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="71" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">An effective discourse parser that uses rich linguistic information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajen</forename><surname>Subba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><forename type="middle">Di</forename><surname>Eugenio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="566" to="574" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Improving verb clustering with automatically acquired selectional preferences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2009 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="638" to="647" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Automatic classification of English verbs using rich syntactic features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuval</forename><surname>Krymolowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Joint Conference on Natural Language Processing</title>
		<meeting>the 3rd International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="769" to="774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Diathesis alternation approximation for verb clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, Short Papers</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics, Short Papers</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="736" to="741" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Exploiting a verb lexicon in automatic semantic role labelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Swier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suzanne</forename><surname>Stevenson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="883" to="890" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Hierarchical Dirichlet processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee Whye</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">J</forename><surname>Beal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">476</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">The information bottleneck method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naftali</forename><surname>Tishby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><forename type="middle">C</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Bialek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th Annual Allerton Conference on Communication, Control and Computing</title>
		<meeting>the 37th Annual Allerton Conference on Communication, Control and Computing</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="368" to="377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A Bayesian approach to unsupervised semantic role induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Klementiev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 13th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="12" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Unsupervised and constrained Dirichlet process mixture models for verb clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Geometrical Models of Natural Language Semantics</title>
		<meeting>the Workshop on Geometrical Models of Natural Language Semantics</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="74" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">One sense per collocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Human Language Technology</title>
		<meeting>the Workshop on Human Language Technology</meeting>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="266" to="271" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
