<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:43+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Neural Cross-Lingual Coreference Resolution And Its Application To Entity Linking</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 15-20, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gourab</forename><surname>Kundu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IBM Research</orgName>
								<address>
									<addrLine>1101 Kitchawan Road Yorktown Heights</addrLine>
									<postCode>10598</postCode>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avirup</forename><surname>Sil</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IBM Research</orgName>
								<address>
									<addrLine>1101 Kitchawan Road Yorktown Heights</addrLine>
									<postCode>10598</postCode>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Florian</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IBM Research</orgName>
								<address>
									<addrLine>1101 Kitchawan Road Yorktown Heights</addrLine>
									<postCode>10598</postCode>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wael</forename><surname>Hamza</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IBM Research</orgName>
								<address>
									<addrLine>1101 Kitchawan Road Yorktown Heights</addrLine>
									<postCode>10598</postCode>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Neural Cross-Lingual Coreference Resolution And Its Application To Entity Linking</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="395" to="400"/>
							<date type="published">July 15-20, 2018</date>
						</imprint>
					</monogr>
					<note>395</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We propose an entity-centric neural cross-lingual coreference model that builds on multilingual embeddings and language-independent features. We perform both intrinsic and extrinsic evaluations of our model. In the intrinsic evaluation, we show that our model, when trained on En-glish and tested on Chinese and Spanish, achieves competitive results to the models trained directly on Chinese and Span-ish respectively. In the extrinsic evaluation , we show that our English model helps achieve superior entity linking accuracy on Chinese and Spanish test sets than the top 2015 TAC system without using any annotated data from Chinese or Span-ish.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Cross-lingual models for NLP tasks are impor- tant since they can be used on data from a new language without requiring annotation from the new language ( <ref type="bibr" target="#b11">Ji et al., 2014</ref><ref type="bibr" target="#b10">Ji et al., , 2015</ref>. This pa- per investigates the use of multi-lingual embed- dings <ref type="bibr" target="#b7">(Faruqui and Dyer, 2014;</ref><ref type="bibr" target="#b28">Upadhyay et al., 2016</ref>) for building cross-lingual models for the task of coreference resolution <ref type="bibr" target="#b16">(Ng and Cardie, 2002;</ref><ref type="bibr" target="#b19">Pradhan et al., 2012)</ref>. Consider the follow- ing text from a Spanish news article:</p><p>"Tormenta de nieve afecta a 100 millones de personas en EEUU. Unos 100 millones de per- sonas enfrentaban el sábado nuevas dificultades tras la enorme tormenta de nieve de hace días en la costa este de Estados Unidos."</p><p>The mentions "EEUU" ("US" in English) and "Estados Unidos" ("United States" in English) are coreferent. A coreference model trained on En- glish data is unlikely to coreference these two mentions in Spanish since these mentions did not appear in English data and a regular English style abbreviation of "Estados Unidos" will be "EU" in- stead of "EEUU". But in the bilingual English- Spanish word embedding space, the word embed- ding of "EEUU" sits close to the word embedding of "US" and the sum of word embeddings of "Es- tados Unidos" sit close to the sum of word em- beddings of "United States". Therefore, a coref- erence model trained using English-Spanish bilin- gual word embeddings on English data has the po- tential to make the correct coreference decision between "EEUU" and "Estados Unidos" without ever encountering these mentions in training data.</p><p>The contributions of this paper are two-fold. Firstly, we propose an entity-centric neural cross- lingual coreference model. This model, when trained on English and tested on Chinese and Spanish from the TAC 2015 Trilingual Entity Dis- covery and Linking (EDL) Task ( <ref type="bibr" target="#b10">Ji et al., 2015)</ref>, achieves competitive results to models trained di- rectly on Chinese and Spanish respectively. Sec- ondly, a pipeline consisting of this coreference model and an Entity Linking (henceforth EL) model can achieve superior linking accuracy than the official top ranking system in 2015 on Chinese and Spanish test sets, without using any supervi- sion in Chinese or Spanish.</p><p>Although most of the active coreference re- search is on solving the problem of noun phrase coreference resolution in the Ontonotes data set, invigorated by the 2011 and 2012 CoNLL shared task <ref type="bibr" target="#b20">(Pradhan et al., 2011</ref><ref type="bibr" target="#b19">(Pradhan et al., , 2012</ref>, there are many important applications/end tasks where the men- tions of interest are not noun phrases. Consider the sentence, "(U.S. president Barack Obama who started ((his) political career) in (Illinois)), was born in (Hawaii)."</p><p>The bracketing represents the Ontonotes style noun phrases and underlines represent the phrases that should be linked to Wikipedia by an EL sys- tem. Note that mentions like "U.S." and "Barack Obama" do not align with any noun phrase. There- fore, in this work, we focus on coreference on mentions that arise in our end task of entity link- ing and conduct experiments on TAC TriLingual 2015 data sets consisting of English, Chinese and Spanish.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Coreference Model</head><p>Each mention has a mention type (m type) of ei- ther name or nominal and an entity type (e type) of Person (PER) / Location (LOC) / GPE / facility (FAC) / organization (ORG) (following standard TAC (Ji et al., 2015) notations).</p><p>The objective of our model is to compute a func- tion that can decide whether two partially con- structed entities should be coreferenced or not. We gradually merge the mentions in the given docu- ment to form entities. Mentions are considered in the order of names and then nominals and within each group, mentions are arranged in the order they appear in the document. Suppose, the sorted order of mentions are m 1 , . . ., m N 1 , m N 1 +1 , . . . , m N 1 +N 2 where N 1 and N 2 are respectively the number of the named and nominal mentions. A singleton entity is created from each mention. Let the order of entities be e 1 , . . . ,</p><formula xml:id="formula_0">e N 1 , e N 1 +1 , . . . , e N 1 +N 2 .</formula><p>We merge the named entities with other named en- tities, then nominal entities with named entities in the same sentence and finally we merge nominal entities across sentences as follows:</p><p>Step 1: For each named entity e i (1 ≤ i ≤ N 1 ), antecedents are all entities e j (1 ≤ j ≤ i − 1) such that e j and e i have same e type. Training ex- amples are triplets of the form (e i , e j , y ij ). If e i and e j are coreferent (meaning, y ij =1), they are merged.</p><p>Step 2: For each nominal entity e i (N 1 + 1 ≤ i ≤ N 1 + N 2 ), we consider antecedents e j such that e i and e j have the same e type and e j has some mention that appears in the same sentence as some mention in e i . Training examples are generated and entities are merged as in the previous step.</p><p>Step 3: This is similar to previous step, except e i and e j have no sentence restriction. Features: For each training triplet (e 1 , e 2 , y 12 ), the network takes the entity pair (e 1 , e 2 ) as input and tries to predict y 12 as output. Since each entity represents a set of mentions, the entity-pair em- bedding is obtained from the embeddings of men- tion pairs generated from the cross product of the entity pair. Let M (e 1 , e 2 ) be the set</p><formula xml:id="formula_1">{(m i ,m j ) | (m i ,m j )∈ e 1 × e 2 } . For each (m i , m j ) ∈ M (e 1 , e 2 ), a feature vector φ m i ,m j is computed.</formula><p>Then, every feature in φ m i ,m j is embedded as a vector in the real space. Let v m i ,m j dentote the concatenation of embeddings of all features in φ m i ,m j . Embeddings of all features except the words are learned in the training process. Word embeddings are pre-trained. v m i ,m j includes the following language independent features: String match: whether m i is a substring or exact match of m j and vice versa (e.g. m i = "Barack Obama" and m j = "Obama") Distance: word distance and sentence distance be- tween m i and m j discretized into bins m type: concatenation of m types for m i and m j e type: concatenation of e types for m i and m j Acronym: whether m i is an acronym of m j or vice versa (e.g. m i = "United States" and m j = "US") First name mismatch: whether m i and m j be- long to e type of PERSON with the same last name but different first name (e.g. m i ="Barack Obama" and m j = "Michelle Obama") Speaker detection: whether m i and m j both oc- cur in the context of words indicating speech e.g. "say", "said" In addition, v m i ,m j includes the average of the word embeddings of m i and average of the word embeddings of m j .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Network Architecture</head><p>The network architecture from the input to the out- put is shown in <ref type="figure" target="#fig_0">figure 1</ref>.</p><formula xml:id="formula_2">Embedding Layer: For each training triplet (e 1 , e 2 , y), a sequence of vectors v m i ,m j (for each ((m i , m j ) ∈ M (e 1 , e 2 ))) is given as input to the network. Relu Layer: v r m i ,m j = max(0, W (1) v m i ,m j ) Attention Layer:</formula><p>To generate the entity-pair em- bedding, we need to combine the embeddings of mention pairs generated from the entity-pair. Con- sider two entities e 1 = (President 1 , Obama)} and e 2 = {(President 2 , Clinton)}. Here the superscripts are used to indicate two different mentions with the same surface form. Since the named mention pair (Obama, Clinton) has no string overlap, e 1 and e 2 should not be coreferenced even though the nominal mention pair (President 1 , President 2 ) has full string overlap. So, while combining the em- beddings for the mention pairs, mention pairs with m type (name, name) should get higher weight than mention pairs with m type (nominal, nomi- nal). The entity pair embedding is the weighted sum of the mention-pair embeddings. We in- troduce 4 parameters a name,name , a name,nominal , a nominal,nominal and a nominal,name as weights for mention pair embeddings with m types of (name, name), (name, nominal), (nominal, nominal) and (nominal, name) respectively. The entity pair em- bedding is computed as follows:</p><formula xml:id="formula_3">v a e 1 ,e 2 = (m i ,m j )∈M (e 1 ,e 2 ) a m type(m i ),m type(m j ) N v r m i ,m j</formula><p>Here N is a normalizing constant given by:</p><formula xml:id="formula_4">N = (m i ,m j )∈M (e 1 ,e 2 ) a 2 m type(m i ),m type(m j )</formula><p>This layer represents attention over the men- tion pair embeddings where attention weights are based on the m types of the mention pairs. Sigmoid Layer: v s e 1 ,e 2 = σ(W (2) v a e 1 ,e 2 ) Output Layer:</p><formula xml:id="formula_5">P (y 12 = 1|e 1 , e 2 ) = 1 1 + e −w s .v s e 1 ,e 2</formula><p>The training objective is to maximize L.</p><formula xml:id="formula_6">L = d∈D (e 1 ,e 2 ,y 12 )∈S d P (y 12 |e 1 , e 2 ; W (1) , W (2) , a, w s ) (1)</formula><p>Here D is the corpus and S d is the training triplets generated from document d.</p><p>Decoding proceeds similarly to training algo- rithm, except at each of the three steps, for each entity e i , the highest scoring antecdent e j is se- lected and if the score is above a threshold, e i and e j are merged.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">A Zero-shot Entity Linking model</head><p>We use our recently proposed cross-lingual EL model, described in ( <ref type="bibr" target="#b25">Sil et al., 2018)</ref>, where our target is to perform "zero shot learning" <ref type="bibr" target="#b26">(Socher et al., 2013;</ref><ref type="bibr" target="#b18">Palatucci et al., 2009</ref>). We train an EL model on English and use it to decode on any other language, provided that we have access to multi-lingual embeddings from English and the target language. We briefly describe our tech- niques here and direct the interested readers to the paper. The EL model computes several similar- ity/coherence scores S in a "feature abstraction layer" which computes several measures of sim- ilarity between the context of the mention m in the query document and the context of the can- didate link's Wikipedia page which are fed to a feed-forward neural layer which acts as a binary classifier to predict the correct link for m. Specif- ically, the feature abstraction layer computes co- sine similarities <ref type="bibr" target="#b24">(Sil and Florian, 2016)</ref> between the representations of the source query document and the target Wikipedia pages over various gran- ularities. These representations are computed by performing CNNs and LSTMs over the context of the entities. Then these similarities are fed into a Multi-perspective Binning layer which maps each similarity into a higher dimensional vector. We also train fine-grained similarities and dissimilar- ities between the query and candidate document from multiple perspectives, combined with convo- lution and tensor networks.</p><p>The model achieves state-of-the-art (SOTA) re- sults on English benchmark EL datasets and also performs surprisingly well on Spanish and Chi- nese. However, although the EL model is "zero- shot", the within-document coreference resolu- tion in the system is a language-dependent SOTA coreference system that has won multiple TAC- KBP ( <ref type="bibr" target="#b10">Ji et al., 2015;</ref><ref type="bibr" target="#b23">Sil et al., 2015</ref>) evaluations but is trained on the target language. Hence, our aim is to apply our proposed coreference model to the EL system to perform an extrinsic evaluation of our proposed algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We evaluate cross-lingual transfer of corefer- ence models on the TAC 2015 Tri-Lingual EL datasets. It contains mentions annotated with their grounded Freebase 1 links (if such links exist) or corpus-wide clustering information for 3 lan- guages: English (henceforth, En), Chinese (hence- forth, Zh) and Spanish (henceforth, Es). <ref type="table">Table 1</ref> shows the size of the training and test sets for the three languages. The documents come from two genres of newswire and discussion forums. The mentions in this dataset are either named entities or nominals that belong to five types: PER, ORG, GPE, LOC and FAC. Hyperparameters: Every feature is embedded in a 50 dimensional space except the words which reside in a 300 dimensional space. The Relu and Sigmoid layers have 100 and 500 neurons respec- tively. We use SGD for optimization with an initial learning rate of 0.05 which is linearly reduced to  0.0001. Our mini batch size is 32 and we train for 50 epochs and keep the best model based on dev set.</p><p>Coreference Results: For each language, we fol- low the official train-test splits made in the TAC 2015 competition. Except, a small portion of the training set is held out as development set for tun- ing the models. All experimental results on all languages reported in this paper were obtained on the official test sets. We used the official CoNLL 2012 evaluation script and report MUC, B <ref type="bibr">3</ref> and CEAF scores and their average (CONLL score). See Pradhan et al. <ref type="bibr">(2011,</ref><ref type="bibr">2012)</ref>.</p><p>To test the competitiveness of our model with other SOTA models, we train the publicly avail- able system of Clark and Manning (2016) (hence- forth, C&amp;M16) on the TAC 15 En training set and test on the TAC 15 En test set. The C&amp;M16 sys- tem normally outputs both noun phrase mentions and their coreference and is trained on Ontonotes. To ensure a fair comparison, we changed the con- figuration of the system to accept gold mention boundaries both during training and testing. Since the system was unable to deal with partially over- lapping mentions, we excluded such mentions in the evaluation. <ref type="table" target="#tab_1">Table 2</ref> shows that our model out- performs C&amp;M16 by 8 points.</p><p>For cross-lingual experiments, we build mono- lingual embeddings for En, Zh and Es using the widely used CBOW word2vec model ( <ref type="bibr" target="#b14">Mikolov et al., 2013a)</ref>. Recently Canonical Correlation Analysis (CCA) <ref type="bibr" target="#b7">(Faruqui and Dyer, 2014</ref>), Multi- CCA ( <ref type="bibr" target="#b0">Ammar et al., 2016)</ref> and Weighted Regres- sion ( <ref type="bibr" target="#b15">Mikolov et al., 2013b</ref>) have been proposed for building the multi-lingual embedding space from monolingual embedding. In our prelimi-   <ref type="table" target="#tab_3">Table 3</ref>, "En Model" refers to the model that was trained on the En training set of TAC 15 using multi-lingual embeddings and tested on the Es and Zh testing set of TAC 15. "Es Model" refers to the model trained on Es training set of TAC 15 using Es embeddings. "Zh Model" refers to the model trained on the Zh training set of TAC 15 using Zh embeddings. The En model performs 0.5 point be- low the Es model on the Es test set. On the Zh test set, the En model performs only 0.3 point below the Zh model. Hence, we show that without using any target language training data, the En model with multi-lingual embeddings gives comparable results to models trained on the target language. EL Results: We replace the in-document coref- erence system (trained on the target language) of SIL18 with our En model to investigate the per- formance of our proposed algorithm on an extrin- sic task. <ref type="table" target="#tab_5">Table 4</ref> shows the EL results on Es and Zh test sets respectively. "EL -Coref" refers to the case where the first step of coreference is not used and EL is used to link the mentions directly to Freebase. "EL + En Coref" refers to the case where the neural english coreference model is first used on Zh or Es data followed by the EL model. The former is 3 points below the latter on Es and 2.6 points below Zh, implying coreference is a vi- tal task for EL. Our "EL + En Coref" outperforms the 2015 TAC best system by 0.7 points on Es and 0.8 points on Zh, without requiring any training data for coreference on Es and Zh respectively. Fi- nally, we show the SOTA results on these two data sets recently reported by SIL18. Although their EL model does not use any supervision from Es or Zh, their coreference resolution model is trained on a large internal data set on the same language as  the test set .Without using any in-language train- ing data, our results are competitive to their results (1.2% below on Es and 0.5% below on Zh).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Rule based ( <ref type="bibr" target="#b21">Raghunathan et al., 2010</ref>) and sta- tistical coreference models <ref type="bibr" target="#b1">(Bengtson and Roth, 2008;</ref><ref type="bibr" target="#b22">Rahman and Ng, 2009;</ref><ref type="bibr">Fernandes et al., 2012;</ref><ref type="bibr" target="#b5">Durrett et al., 2013;</ref><ref type="bibr" target="#b3">Clark and Manning, 2015;</ref><ref type="bibr" target="#b13">Martschat and Strube, 2015;</ref><ref type="bibr" target="#b2">Björkelund and Kuhn, 2014</ref>) are hard to transfer across lan- guages due to their use of lexical features or pat- terns in the rules. Neural coreference is promising since it allows cross-lingual transfer using multi- lingual embedding. However, most of the re- cent neural coreference models <ref type="bibr" target="#b30">(Wiseman et al., 2015</ref><ref type="bibr" target="#b29">(Wiseman et al., , 2016</ref><ref type="bibr">Manning, 2015, 2016;</ref><ref type="bibr" target="#b12">Lee et al., 2017</ref>) have focused on training and test- ing on the same language. In contrast, our model performs cross-lingual coreference. There have been some recent promising results regarding such cross-lingual models for other tasks, most notably mention detection <ref type="bibr" target="#b17">(Ni et al., 2017)</ref> and EL <ref type="bibr" target="#b27">(Tsai and Roth, 2016;</ref><ref type="bibr" target="#b24">Sil and Florian, 2016)</ref>. In this work, we show that such promise exists for coref- erence also. The tasks of EL and coreference are intrinsi- cally related, prompting joint models <ref type="bibr" target="#b6">(Durrett and Klein, 2014;</ref><ref type="bibr" target="#b9">Hajishirzi et al., 2013)</ref>. However, the recent SOTA was obtained using pipeline models of coreference and EL <ref type="bibr" target="#b25">(Sil et al., 2018</ref>). Compared to a joint model, pipeline models are easier to im- plement, improve and adapt to a new domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>The proposed cross-lingual coreference model was found to be empirically strong in both intrin- sic and extrinsic evaluations in the context of an entity linking task.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Network architecture for our coreference system. Blue circles in mention-pair embeddings layer represent embeddings of features. Green circles represent word embeddings.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Coreference results on the En test set of 
TAC 15 competition. Our model significantly out-
performs C&amp;M16. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Coreference results on the Es and Zh test 
sets of TAC 15. En model performs competitively 
to the models trained on target language data. 

nary experiments, the technique of Mikolov et al. 
(2013b) performed the best and so we used it to 
project the embeddings of Zh and Es onto En. 
In </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Performance comparison on the TAC 
2015 Es and Zh datasets. EL + En Coref outper-
forms the best 2015 TAC system (Rank 1) without 
requiring any Es or Zh coreference data. 

</table></figure>

			<note place="foot" n="1"> TAC uses BaseKB, which is a snapshot of Freebase. SIL18 links entities to Wikipedia and in-turn links them to BaseKB.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Waleed</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Mulcaire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulia</forename><surname>Tsvetkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Smith</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.01925</idno>
		<title level="m">Massively multilingual word embeddings</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Understanding the value of features for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Bengtson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning structured perceptrons for coreference resolution with latent antecedents and non-local features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Björkelund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Kuhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Entitycentric coreference resolution with model stacking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Improving coreference resolution by learning entitylevel distributed representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Decentralized entity-level modeling for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Durrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David Leo Wright</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A joint model for entity analysis: Coreference, typing, and linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Durrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Improving vector space word representations using multilingual correlation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EACL</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Cícero Nogueira Dos Santos, and Ruy Luiz Milidiú. 2012. Latent structure perceptron with feature induction for unrestricted coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Eraldo Rezende Fernandes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-CoNLL</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Joint coreference resolution and named-entity linking with multi-pass sieves</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leila</forename><surname>Zilles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Daniel S Weld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Overview of tac-kbp2015 tri-lingual entity discovery and linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
			<affiliation>
				<orgName type="collaboration">TAC</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Nothman</surname></persName>
			<affiliation>
				<orgName type="collaboration">TAC</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Hachey</surname></persName>
			<affiliation>
				<orgName type="collaboration">TAC</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Florian</surname></persName>
			<affiliation>
				<orgName type="collaboration">TAC</orgName>
			</affiliation>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Overview of tac-kbp2014 entity discovery and linking tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
			<affiliation>
				<orgName type="collaboration">TAC</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Nothman</surname></persName>
			<affiliation>
				<orgName type="collaboration">TAC</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Hachey</surname></persName>
			<affiliation>
				<orgName type="collaboration">TAC</orgName>
			</affiliation>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.07045</idno>
		<title level="m">End-to-end neural coreference resolution</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Latent structures for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Martschat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Strube</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="405" to="418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Exploiting similarities among languages for machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sutskever</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1309.4168</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Improving machine learning approaches to coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Weakly supervised cross-lingual named entity recognition via effective annotation and representation projection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgiana</forename><surname>Dinu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Florian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Zero-shot learning with semantic output codes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Palatucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dean</forename><surname>Pomerleau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom M</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Conll2012 shared task: Modeling multilingual unrestricted coreference in ontonotes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sameer Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchen</forename><surname>Uryupina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLPCoNLL</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Conll-2011 shared task: Modeling unrestricted coreference in ontonotes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lance</forename><surname>Sameer Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><surname>Ramshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Weischedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CoNLL</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A multipass sieve for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heeyoung</forename><surname>Karthik Raghunathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Sudarshan Rangarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Supervised models for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Altaf</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">The ibm systems for trilingual entity discovery and linking at tac 2015</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avirup</forename><surname>Sil</surname></persName>
			<affiliation>
				<orgName type="collaboration">TAC</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgiana</forename><surname>Dinu</surname></persName>
			<affiliation>
				<orgName type="collaboration">TAC</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Florian</surname></persName>
			<affiliation>
				<orgName type="collaboration">TAC</orgName>
			</affiliation>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">One for all: Towards language independent named entity linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avirup</forename><surname>Sil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Florian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Neural cross-lingual entity linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avirup</forename><surname>Sil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gourab</forename><surname>Kundu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Florian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wael</forename><surname>Hamza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Zero-shot learning through cross-modal transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milind</forename><surname>Ganjoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Cross-lingual wikification using multilingual embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen-Tse</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLTNAACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Cross-lingual models of word embeddings: An empirical comparison</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shyam</forename><surname>Upadhyay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning global features for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Wiseman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stuart M</forename><surname>Shieber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning anaphoricity and antecedent ranking features for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam Joshua</forename><surname>Wiseman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">Matthew</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stuart</forename><forename type="middle">Merrill</forename><surname>Shieber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
