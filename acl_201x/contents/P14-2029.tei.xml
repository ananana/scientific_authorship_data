<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:19+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Predicting Grammaticality on an Ordinal Scale</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>June 23-25 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Heilman</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Educational Testing Service Princeton</orgName>
								<orgName type="department" key="dep2">Yahoo! Research New York</orgName>
								<address>
									<region>NJ, NY</region>
									<country>USA, USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aoife</forename><surname>Cahill</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Educational Testing Service Princeton</orgName>
								<orgName type="department" key="dep2">Yahoo! Research New York</orgName>
								<address>
									<region>NJ, NY</region>
									<country>USA, USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitin</forename><surname>Madnani</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Educational Testing Service Princeton</orgName>
								<orgName type="department" key="dep2">Yahoo! Research New York</orgName>
								<address>
									<region>NJ, NY</region>
									<country>USA, USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melissa</forename><surname>Lopez</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Educational Testing Service Princeton</orgName>
								<orgName type="department" key="dep2">Yahoo! Research New York</orgName>
								<address>
									<region>NJ, NY</region>
									<country>USA, USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Mulholland</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Educational Testing Service Princeton</orgName>
								<orgName type="department" key="dep2">Yahoo! Research New York</orgName>
								<address>
									<region>NJ, NY</region>
									<country>USA, USA</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Tetreault</surname></persName>
							<email>tetreaul@yahoo-inc.com</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Educational Testing Service Princeton</orgName>
								<orgName type="department" key="dep2">Yahoo! Research New York</orgName>
								<address>
									<region>NJ, NY</region>
									<country>USA, USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Predicting Grammaticality on an Ordinal Scale</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="174" to="180"/>
							<date type="published">June 23-25 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Automated methods for identifying whether sentences are grammatical have various potential applications (e.g., machine translation, automated essay scoring, computer-assisted language learning). In this work, we construct a statistical model of grammaticality using various linguistic features (e.g., misspelling counts, parser outputs, n-gram language model scores). We also present a new publicly available dataset of learner sentences judged for grammaticality on an ordinal scale. In evaluations, we compare our system to the one from Post (2011) and find that our approach yields state-of-the-art performance.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this paper, we develop a system for the task of predicting the grammaticality of sentences, and present a dataset of learner sentences rated for grammaticality. Such a system could be used, for example, to check or to rank outputs from systems for text summarization, natural language genera- tion, or machine translation. It could also be used in educational applications such as essay scoring.</p><p>Much of the previous research on predicting grammaticality has focused on identifying (and possibly correcting) specific types of grammati- cal errors that are typically made by English lan- guage learners, such as prepositions <ref type="bibr" target="#b18">(Tetreault and Chodorow, 2008</ref>), articles ( <ref type="bibr" target="#b10">Han et al., 2006</ref>), and collocations ( <ref type="bibr" target="#b6">Dahlmeier and Ng, 2011</ref>). While some applications (e.g., grammar checking) rely on such fine-grained predictions, others might be better addressed by sentence-level grammaticality judgments (e.g., machine translation evaluation).</p><p>Regarding sentence-level grammaticality, there has been much work on rating the grammatical- ity of machine translation outputs ( <ref type="bibr" target="#b9">Gamon et al., 2005;</ref><ref type="bibr" target="#b13">Parton et al., 2011</ref>), such as the MT Quality Estimation Shared Tasks ( <ref type="bibr">Bojar et al., 2013, §6)</ref>, but relatively little on evaluating the grammatical- ity of naturally occurring text. Also, most other re- search on evaluating grammaticality involves arti- ficial tasks or datasets ( <ref type="bibr" target="#b17">Sun et al., 2007;</ref><ref type="bibr" target="#b21">Wong and Dras, 2010;</ref><ref type="bibr" target="#b15">Post, 2011)</ref>.</p><p>Here, we make the following contributions.</p><p>• We develop a state-of-the-art approach for predicting the grammaticality of sentences on an ordinal scale, adapting various techniques from the previous work described above.</p><p>• We create a dataset of grammatical and un- grammatical sentences written by English language learners, labeled on an ordinal scale for grammaticality. With this unique data set, which we will release to the research com- munity, it is now possible to conduct realis- tic evaluations for predicting sentence-level grammaticality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Dataset Description</head><p>We created a dataset consisting of 3,129 sentences randomly selected from essays written by non- native speakers of English as part of a test of English language proficiency. We oversampled lower-scoring essays to increase the chances of finding ungrammatical sentences. Two of the au- thors of this paper, both native speakers of English with linguistic training, annotated the data. We refer to these annotators as expert judges. When making judgments of the sentences, they saw the previous sentence from the same essay as context. These two authors were not directly involved in development of the system in §3. Each sentence was annotated on a scale from 1 to 4 as described below, with 4 being the most grammatical. We use an ordinal rather than bi- nary scale, following previous work such as that of <ref type="bibr" target="#b2">Clark et al. (2013)</ref> and <ref type="bibr" target="#b5">Crocker and Keller (2005)</ref> who argue that the distinction between grammati- cal and ungrammatical is not simply binary. Also, for practical applications, we believe that it is use- ful to distinguish sentences with minor errors from those with major errors that may disrupt communi- cation. Our annotation scheme was influenced by a translation rating scheme by <ref type="bibr" target="#b4">Coughlin (2003)</ref>.</p><p>Every sentence judged on the 1-4 scale must be a clause. There is an extra category ("Other") for sentences that do not fit this criterion. We exclude instances of "Other" in our experiments (see §4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Perfect</head><p>The sentence is native-sounding. It has no grammatical errors, but may contain very mi- nor typographical and/or collocation errors, as in Example (1).</p><p>(1) For instance, i stayed in a dorm when i went to collge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Comprehensible</head><p>The sentence may contain one or more minor grammatical errors, includ- ing subject-verb agreement, determiner, and mi- nor preposition errors that do not make the mean- ing unclear, as in Example (2).</p><p>(2) We know during Spring Festival, Chinese family will have a abundand family banquet with family memebers.</p><p>"Chinese family", which could be corrected to "Chinese families", "each Chinese family", etc., would be an example of a minor grammatical er- ror involving determiners.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Somewhat Comprehensible</head><p>The sentence may contain one or more serious grammatical errors, including missing subject, verb, object, etc., verb tense errors, and serious preposition errors. Due to these errors, the sentence may have multiple plausible interpretations, as in Example (3).</p><p>(3) I can gain the transportations such as buses and trains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Incomprehensible</head><p>The sentence contains so many errors that it would be difficult to correct, as in Example (4).</p><p>(4) Or you want to say he is only a little boy do not everything clearly?</p><p>The phrase "do not everything" makes the sen- tence practically incomprehensible since the sub- ject of "do" is not clear.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>O. Other/Incomplete</head><p>This sentence is incom- plete. These sentences, such as Example <ref type="formula">(5)</ref>, ap- pear in our corpus due to the nature of timed tests.</p><p>(5) The police officer handed the This sentence is cut off and does not at least in- clude one clause.</p><p>We measured interannotator agreement on a subset of 442 sentences that were independently annotated by both expert annotators. Exact agree- ment was 71.3%, unweighted κ = 0.574, and Pearson's r = 0.759. 1 For our experiments, one expert annotator was arbitrarily selected, and for the doubly-annotated sentences, only the judg- ments from that annotator were retained.</p><p>The labels from the expert annotators are dis- tributed as follows: 72 sentences are labeled 1; 538 are 2; 1,431 are 3; 978 are 4; and 110 are "O".</p><p>We also gathered 5 additional judgments using Crowdflower. <ref type="bibr">2</ref> For this, we excluded the "Other" category and any sentences that had been marked as such by the expert annotators. We used 100 (3.2%) of the judged sentences as "gold" data in Crowdflower to block contributors who were not following the annotation guidelines. For those sentences, only disagreements within 1 point of the expert annotator judgment were accepted. In preliminary experiments, averaging the six judg- ments (1 expert, 5 crowdsourced) for each item led to higher human-machine agreement. For all experiments reported later, we used this average of six judgments as our gold standard.</p><p>For our experiments ( §4), we randomly split the data into training (50%), development (25%), and testing (25%) sets. We also excluded all instances labeled "Other". These are relatively uncommon and less interesting to this study. Also, we believe that simpler, heuristic approaches could be used to identify such sentences.</p><p>We use "GUG" ("Grammatical" versus "Un- Grammatical") to refer to this dataset. The dataset is available for research at https://github. com/EducationalTestingService/ gug-data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">System Description</head><p>This section describes the statistical model ( §3.1) and features ( §3.2) used by our system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Statistical Model</head><p>We use 2 -regularized linear regression (i.e., ridge regression) to learn a model of sentence grammat- icality from a variety of linguistic features. <ref type="bibr">34</ref> To tune the 2 -regularization hyperparameter α, the system performs 5-fold cross-validation on the data used for training. The system evaluates α ∈ 10 {−4,...,4} and selects the one that achieves the highest cross-validation correlation r.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Features</head><p>Next, we describe the four types of features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Spelling Features</head><p>Given a sentence with with n word tokens, the model filters out tokens containing nonalpha- betic characters and then computes the num- ber of misspelled words n miss (later referred to as num misspelled), the proportion of mis- spelled words n miss n , and log(n miss + 1) as fea- tures. To identify misspellings, we use a freely available spelling dictionary for U.S. English. <ref type="bibr">5</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">n-gram Count and Language Model</head><p>Features Given each sentence, the model obtains the counts of n-grams (n = 1 . . . 3) from English Gigaword and computes the following features: <ref type="bibr">6</ref> • s∈Sn log(count(s) + 1) S n 3 We use ridge regression from the scikit-learn toolkit (Pedregosa et al., 2011) v0.23.1 and the SciKit-Learn Laboratory (http://github.com/ EducationalTestingService/skll). <ref type="bibr">4</ref> Regression models typically produce conservative pre- dictions with lower variance than the original training data. So that predictions better match the distribution of labels in the training data, the system rescales its predictions. It saves the mean and standard deviation of the training data gold standard (M gold and SD gold , respectively) and of its own predictions on the training data (M pred and SD pred , respec- tively). During cross-validation, this is done for each fold. From an initial predictionˆypredictionˆ predictionˆy, it produces the final prediction:</p><formula xml:id="formula_0">ˆ y = ˆ y−M pred SD pred * SD gold + M gold .</formula><p>This transformation does not affect Pearson's r correlations or rankings, but it would affect binarized predictions.</p><p>5 http://pythonhosted.org/pyenchant/ 6 We use the New York Times (nyt), the Los Ange- les Times-Washington Post (ltw), and the Washington Post- Bloomberg News (wpb) sections from the fifth edition of En- glish Gigaword (LDC2011T07).</p><p>• max s∈Sn log(count(s) + 1)</p><p>• min s∈Sn log(count(s) + 1) where S n represents the n-grams of order n from the given sentence. The model computes the fol- lowing features from a 5-gram language model trained on the same three sections of English Gi- gaword using the SRILM toolkit <ref type="bibr" target="#b16">(Stolcke, 2002</ref>):</p><p>• the average log-probability of the given sentence (referred to as gigaword avglogprob later)</p><p>• the number of out-of-vocabulary words in the sentence Finally, the system computes the average log-probability and number of out-of-vocabulary words from a language model trained on a col- lection of essays written by non-native English speakers 7 ("non-native LM").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Precision Grammar Features</head><p>Following <ref type="bibr" target="#b19">Wagner et al. (2007)</ref> and <ref type="bibr" target="#b20">Wagner et al. (2009)</ref>, we use features extracted from preci- sion grammar parsers. These grammars have been hand-crafted and designed to only provide com- plete syntactic analyses for grammatically cor- rect sentences. This is in contrast to treebank- trained grammars, which will generally provide some analysis regardless of grammaticality. Here, we use (1) the Link Grammar Parser 8 and (2) the HPSG English Resource Grammar <ref type="bibr" target="#b3">(Copestake and Flickinger, 2000</ref>) and PET parser. <ref type="bibr">9</ref> We use a binary feature, complete link, from the Link grammar that indicates whether at least one complete linkage can be found for a sen- tence. We also extract several features from the HPSG analyses. 10 They mostly reflect information about unification success or failure and the associ- ated costs. In each instance, we use the logarithm of one plus the frequency. <ref type="bibr">7</ref> This did not overlap with the data described in §2 and was a subset of the data released by <ref type="bibr" target="#b0">Blanchard et al. (2013)</ref>.</p><p>8 http://www.link.cs.cmu.edu/link/ 9 http://moin.delph-in.net/PetTop <ref type="bibr">10</ref> The complete list of relevant statistics used as features is: trees, unify cost succ, unify cost fail, unifications succ, unifications fail, subsumptions succ, subsumptions fail, words, words pruned, aedges, pedges, upedges, raedges, rpedges, medges. During development, we observed that some of these features vary for some inputs, probably due to parsing search timeouts. On 10 preliminary runs with the development set, this variance had minimal effects on correlations with human judgments (less than 0.00001 in terms of r). r our system 0.668</p><formula xml:id="formula_1">− non-native LM ( §3.2.2) 0.665 − HPSG parse ( §3.2.3) 0.664 − PCFG parse ( §3.2.4) 0.662 − spelling ( §3.2.1) 0.643 − gigaword LM ( §3.2.2)</formula><p>0.638 − link parse <ref type="figure">( §3.2.3)</ref> 0.632 − gigaword count ( §3.2.2) 0.630 <ref type="table">Table 1</ref>: Pearson's r on the development set, for our full system and variations excluding each fea- ture type. "− X" indicates the full model without the "X" features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.4">PCFG Parsing Features</head><p>We find phrase structure trees and basic depen- dencies with the Stanford Parser's English PCFG model ( <ref type="bibr" target="#b11">Klein and Manning, 2003;</ref><ref type="bibr" target="#b7">de Marneffe et al., 2006</ref>). <ref type="bibr">11</ref> We then compute the following:</p><p>• the parse score as provided by the Stan- ford PCFG Parser, normalized for sentence length, later referred to as parse prob</p><p>• a binary feature that captures whether the top node of the tree is sentential or not (i.e. the assumption is that if the top node is non- sentential, then the sentence is a fragment)</p><p>• features binning the number of dep rela- tions returned by the dependency conversion. These dep relations are underspecified for function and indicate that the parser was un- able to find a standard relation such as subj, possibly indicating a grammatical error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>Next, we present evaluations on the GUG dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Feature Ablation</head><p>We conducted a feature ablation study to iden- tify the contributions of the different types of fea- tures described in §3.2. We compared the perfor- mance of the full model with all of the features to models with all but one type of feature. For this experiment, all models were estimated from the training set and evaluated on the development set. We report performance in terms of Pearson's r between the averaged 1-4 human labels and un- rounded system predictions.</p><p>The results are shown in <ref type="table">Table 1</ref>. From these results, the most useful features appear to be the n-gram frequencies from Gigaword and whether the link parser can fully parse the sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Test Set Results</head><p>In this section, we present results on the held-out test set for the full model and various baselines, summarized in <ref type="table">Table 2</ref>. For test set evaluations, we trained on the combination of the training and development sets ( §2), to maximize the amount of training data for the final experiments.</p><p>We also trained and evaluated on binarized ver- sions of the ordinal GUG labels: a sentence was labeled 1 if the average judgment was at least 3.5 (i.e., would round to 4), and 0 otherwise. Evaluat- ing on a binary scale allows us to measure how well the system distinguishes grammatical sen- tences from ungrammatical ones. For some ap- plications, this two-way distinction may be more relevant than the more fine-grained 1-4 scale. To train our system on binarized data, we replaced the 2 -regularized linear regression model with an 2 - regularized logistic regression and used Kendall's τ rank correlation between the predicted probabil- ities of the positive class and the binary gold stan- dard labels as the grid search metric ( §3.1) instead of Pearson's r.</p><p>For the ordinal task, we report Pearson's r be- tween the averaged human judgments and each system. For the binary task, we report percentage accuracy. Since the predictions from the binary and ordinal systems are on different scales, we in- clude the nonparametric statistic Kendall's τ as a secondary evaluation metric for both tasks.</p><p>We also evaluated the binary system for the or- dinal task by computing correlations between its estimated probabilities and the averaged human scores, and we evaluated the ordinal system for the binary task by binarizing its predictions. <ref type="bibr">12</ref> We compare our work to a modified version of the publicly available 13 system from Post (2011), which performed very well on an artificial dataset. To our knowledge, it is the only publicly available system for grammaticality prediction. It is very  <ref type="table">Table 2</ref>: Human-machine agreement statistics for our system, the system from Post (2011), and simple baselines, computed from the averages of human ratings in the testing set ( §2). "*" in a Sig. column indicates a statistically significant difference from "our system" (p &lt; .05, see text for details). A majority baseline for the binary task achieves 74.8% accuracy. The best results for each metric are in bold. different from our system since it relies on par- tial tree-substitution grammar derivations as fea- tures. We use the feature computation components of that system but replace its statistical model. The system was designed for use with a dataset consist- ing of 50% grammatical and 50% ungrammatical sentences, rather than data with ordinal or continu- ous labels. Additionally, its classifier implementa- tion does not output scores or probabilities. There- fore, we used the same learning algorithms as for our system (i.e., ridge regression for the ordinal task and logistic regression for the binary task). <ref type="bibr">14</ref> To create further baselines for comparison, we selected the following features that represent ways one might approximate grammaticality if a comprehensive model was unavailable: whether the link parser can fully parse the sentence (complete link), the Gigaword language model score (gigaword avglogprob), and the number of misspelled tokens (num misspelled).</p><p>Note that we expect the number of misspelled tokens to be negatively correlated with grammaticality. We flipped the sign of the misspelling feature when computing accuracy for the binary task.</p><p>To identify whether the differences in perfor- mance for the ordinal task between our system and each of the baselines are statistically significant, we used the BC a Bootstrap ( <ref type="bibr" target="#b8">Efron and Tibshirani, 1993</ref>) with 10,000 replications to compute 95% confidence intervals for the absolute value of r for our system minus the absolute value of r for each of the alternative methods. For the binary task, we <ref type="bibr">14</ref> In preliminary experiments, we observed little difference in performance between logistic regression and the original support vector classifier used by the system from Post <ref type="bibr">(2011).</ref> used the sign test to test for significant differences in accuracy. The results are in <ref type="table">Table 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion and Conclusions</head><p>In this paper, we developed a system for predict- ing grammaticality on an ordinal scale and cre- ated a labeled dataset that we have released pub- licly ( §2) to enable more realistic evaluations in future research. Our system outperformed an ex- isting state-of-the-art system <ref type="bibr" target="#b15">(Post, 2011</ref>) in eval- uations on binary and ordinal scales. This is the most realistic evaluation of methods for predicting sentence-level grammaticality to date. Surprisingly, the system from Post (2011) per- formed quite poorly on the GUG dataset. We spec- ulate that this is due to the fact that the Post sys- tem relies heavily on features extracted from au- tomatic syntactic parses. While Post found that such a system can effectively distinguish gram- matical news text sentences from sentences gen- erated by a language model, measuring the gram- maticality of real sentences from language learn- ers seems to require a wider variety of features, including n-gram counts, language model scores, etc. Of course, our findings do not indicate that syntactic features such as those from Post (2011) are without value. In future work, it may be pos- sible to improve grammaticality measurement by integrating such features into a larger system.</p></div>
			<note place="foot" n="1"> The reported agreement values assume that &quot;Other&quot; maps to 0. For the sentences where both labels were in the 1-4 range (n = 424), Pearson&apos;s r = 0.767. 2 http://www.crowdflower.com</note>

			<note place="foot" n="11"> We use the Nov. 12, 2013 version of the Stanford Parser. 12 We selected a threshold for binarization from a grid of 1001 points from 1 to 4 that maximized the accuracy of binarized predictions from a model trained on the training set and evaluated on the binarized development set. For evaluating the three single-feature baselines discussed below, we used the same approach except with grid ranging from the minimum development set feature value to the maximum plus 0.1% of the range. 13 The Post (2011) system is available at https:// github.com/mjpost/post2011judging.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank Beata Beigman Klebanov, Yoko Futagi, Su-Youn Yoon, and the anonymous reviewers for their helpful comments. We also thank Jennifer Foster for discussions about this work and Matt Post for making his system publicly available.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">TOEFL11: A Corpus of Non-Native English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Blanchard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Tetreault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derrick</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aoife</forename><surname>Cahill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Chodorow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Educational Testing Service</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Buck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<title level="m">Proceedings of the Eighth Workshop on Statistical Machine Translation</title>
		<meeting>the Eighth Workshop on Statistical Machine Translation<address><addrLine>Sofia, Bulgaria, August</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1" to="44" />
		</imprint>
	</monogr>
	<note>Findings of the 2013 Workshop on Statistical Machine Translation</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Towards a statistical model of grammaticality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gianluca</forename><surname>Giorgolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shalom</forename><surname>Lappin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th Annual Conference of the Cognitive Science Society</title>
		<meeting>the 35th Annual Conference of the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2064" to="2069" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">An open-source grammar development environment and broad-coverage English grammar using HPSG</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ann</forename><surname>Copestake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Flickinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd International Conference on Language Resources and Evaluation</title>
		<meeting>the 2nd International Conference on Language Resources and Evaluation<address><addrLine>Athens, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Correlating automated and human assessments of machine translation quality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deborah</forename><surname>Coughlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of MT Summit IX</title>
		<meeting>MT Summit IX</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="63" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Probabilistic grammars as models of gradience in language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Crocker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Keller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Gradience in Grammar: Generative Perspectives</title>
		<imprint>
			<publisher>University Press</publisher>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Correcting Semantic Collocation Errors with L1-induced Paraphrases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Dahlmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee Tou</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Edinburgh, Scotland, UK.</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011-07" />
			<biblScope unit="page" from="107" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Generating Typed Dependency Parses from Phrase Structure Parses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Catherine</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Maccartney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC 2006</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="449" to="454" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">An Introduction to the Bootstrap</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Efron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>Chapman and Hall/CRC</publisher>
			<pubPlace>Boca Raton, FL</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Sentence-level MT evaluation without reference translations: Beyond language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Gamon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Aue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martine</forename><surname>Smets</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EAMT</title>
		<meeting>EAMT</meeting>
		<imprint>
			<publisher>SpringerVerlag</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="103" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Detecting errors in English article usage by non-native speakers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Na-Rae</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Chodorow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudia</forename><surname>Leacock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="115" to="129" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Accurate Unlexicalized Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 41st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sapporo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-07" />
			<biblScope unit="page" from="423" to="430" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Detection of Non-Native Sentences Using MachineTranslated Training Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Companion Volume, Short Papers</title>
		<meeting><address><addrLine>Rochester, New York</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-04" />
			<biblScope unit="page" from="93" to="96" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">E-rating machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristen</forename><surname>Parton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Tetreault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitin</forename><surname>Madnani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Workshop on Statistical Machine Translation</title>
		<meeting>the Sixth Workshop on Statistical Machine Translation<address><addrLine>Edinburgh, Scotland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-07" />
			<biblScope unit="page" from="108" to="115" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine Learning in Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Judging Grammaticality with Tree Substitution Grammar Derivations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011-06" />
			<biblScope unit="page" from="217" to="222" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">SRILM-An Extensible Language Modeling Toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Stolcke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Spoken Language Processing</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Detecting Erroneous Sentences using Automatically Mined Sequential Patterns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guihua</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongyang</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics</title>
		<meeting>the 45th Annual Meeting of the Association of Computational Linguistics<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-06" />
			<biblScope unit="page" from="81" to="88" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The Ups and Downs of Preposition Error Detection in ESL Writing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><forename type="middle">R</forename><surname>Tetreault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Chodorow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Computational Linguistics</title>
		<meeting>the 22nd International Conference on Computational Linguistics<address><addrLine>Manchester, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-08" />
			<biblScope unit="page" from="865" to="872" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A Comparative Evaluation of Deep and Shallow Approaches to the Automatic Detection of Common Grammatical Errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Van Genabith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL)</title>
		<meeting>the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL)<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007-06" />
			<biblScope unit="page" from="112" to="121" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Judging grammaticality: Experiments in sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Van Genabith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CALICO Journal</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="474" to="490" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Parser Features for Sentence Grammaticality Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jojo</forename><surname>Sze-Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Australasian Language Technology Association Workshop 2010</title>
		<meeting>the Australasian Language Technology Association Workshop 2010<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-12" />
			<biblScope unit="page" from="67" to="75" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
