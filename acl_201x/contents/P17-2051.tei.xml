<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:24+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Feature-Rich Networks for Knowledge Base Completion</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandros</forename><surname>Komninos</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suresh</forename><surname>Manandhar</surname></persName>
						</author>
						<title level="a" type="main">Feature-Rich Networks for Knowledge Base Completion</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</title>
						<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="324" to="329"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-2051</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We propose jointly modelling Knowledge Bases and aligned text with Feature-Rich Networks. Our models perform Knowledge Base Completion by learning to represent and compose diverse feature types from partially aligned and noisy resources. We perform experiments on Freebase utilizing additional entity type information and syntactic textual relations. Our evaluation suggests that the proposed models can better incorporate side information than previously proposed combinations of bilinear models with convolutional neu-ral networks, showing large improvements when scoring the plausibility of unob-served facts with associated textual mentions .</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Knowledge Bases (KB) are an important resource for many applications such as question answer- ing ( <ref type="bibr" target="#b13">Reddy et al., 2014</ref>), relation extraction ( <ref type="bibr" target="#b9">Mintz et al., 2009</ref>) and named entity recognition ( <ref type="bibr" target="#b8">Ling and Weld, 2012)</ref>. While large collaborative KBs like Freebase ( <ref type="bibr" target="#b1">Bollacker et al., 2008)</ref> and DBpe- dia ( <ref type="bibr" target="#b0">Auer et al., 2007</ref>) contain facts about million of entities, they are mostly incomplete and contain errors. A large amount of research has been ded- icated to automatically extend knowledge bases, a task called Entity Linking or Knowledge Base Completion (KBC). Proposed approaches to KBC either reason about the internal structure of the KB, or utilize external data sources that indicate relations between the entities in the KB.</p><p>A very successful approach to KBC is latent feature models <ref type="bibr" target="#b12">(Nickel et al., 2011;</ref><ref type="bibr" target="#b2">Bordes et al., 2013;</ref><ref type="bibr" target="#b15">Socher et al., 2013;</ref><ref type="bibr" target="#b11">Nickel et al., 2016</ref>). Such models embed the symbols of the KB into a low dimensional space and assign a score to unseen triples as a function of the latent feature representations. Most approaches define a scor- ing function as a linear or bilinear operator. La- tent feature models have shown good performance when considering the internal structure of KBs and are scalable to very large datasets.</p><p>Utilizing textual data or other external resources for KBC is a challenging task but has the poten- tial of constantly updating KBs as new informa- tion becomes available. A line of work uses the KB as a means to obtain distant supervision to train relation extraction systems that classify tex- tual mentions into one of the KBs relations ( <ref type="bibr" target="#b9">Mintz et al., 2009;</ref><ref type="bibr" target="#b4">Hoffmann et al., 2011;</ref><ref type="bibr" target="#b16">Surdeanu et al., 2012)</ref>. State-of-the-art approaches for KBC with external textual data are obtained by latent feature models that jointly embed the KB symbols and text relations into the same space ( <ref type="bibr" target="#b14">Riedel et al., 2013;</ref><ref type="bibr" target="#b17">Toutanova et al., 2015)</ref>. The benefit of such models over relation extraction systems is that they can combine both the internal structure of the KB and textual information to reason about the plausibility of unobserved facts.</p><p>A commonly used approach for augmenting a KBC given an aligned text corpus is by adopting a Universal Schema ( <ref type="bibr" target="#b14">Riedel et al., 2013)</ref>, where extracted textual relations between entities are di- rectly added to the knowledge graph and treated the same as KB relations. This allows appli- cation of any latent variable model defined over triples to jointly embed the KB and text relations to the same space. An extension to the Univer- sal Schema approach was proposed by <ref type="bibr" target="#b17">(Toutanova et al., 2015)</ref>, where representations of text re- lations are formed compositionally by Convolu- tional Neural Networks (CNNs) and then com- posed with entity vectors by a bilinear model to score a fact. However, these models show only moderate improvement when incorporating tex-  A limitation of the Universal Schema approach for joint embedding of KBs and text is that infor- mation about the correspondence between KB and text relations is only implicitly available through their co-occurrence with entities. Text relations can often be noisy and pairs of entities can co- occur in the same sentence without sharing a se- mantic relation. In addition, there is usually a mis- match in the relations found in the KB and those expressed in text. The model has to learn the align- ment between KB and text relations without ex- plicit evidence of co-occurrence between the two, and then propagate that information through the entity embeddings in order to score unseen KB triples.</p><p>We propose a different approach to combine KB and textual evidence, where the textual relations are not part of the same graph but are treated as side evidence. In our setting, a fact does not nec- essarily consist of a (sbj, rel, obj) triple, but as an n-tuple where extra elements are formed by ex- tracting additional information from the KB and aligned side resources such as text. We score the probability of the tuple being true by learn- ing latent representations for each element of the tuple, and then learning a composition and scor- ing function parameterized by a Multilayer Per- ceptron (MLP). We choose MLPs as they are a generic method to model interactions between la- tent features without having to specify the form of a composition operator for tuples of different ar- ity. When scoring the plausibility of unseen facts, all the side evidence associated with that fact be- comes explicit through the n-tuple.</p><p>We evaluate the ability of the proposed Feature- Rich Networks (FRN) for KBC on the challenging FB15k-237 ( <ref type="bibr" target="#b17">Toutanova et al., 2015)</ref>. We compare the performance of bilinear models to an MLP when facts are represented as simple triples, and the contribution of two additional types of aligned information: entity types and textual relation men- tions from a side corpus. We also evaluate the contribution of initializing feature representations from external models. Evaluation suggests that while MLPs and bilinear models perform simi- larly when treating facts as triples of KB symbols, the proposed approach can better utilize additional textual data than a combination of CNNs with bi- linear models, showing large improvements in pre- dicting unseen facts when they have linked rela- tion mentions in text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Model Definition</head><p>Knowledge Bases can be represented as a directed graph where nodes are entities e ∈ E and edges are typed relations r ∈ R. A fact in the KB is en- coded as a triple (e s , r, e o ), where e s is the subject entity and e o is the object entity. Starting with an existing KB consisting of a set of observed facts, our goal is to reason about the plausibility of un- observed facts, given some additional external re- source. In our proposed model, we expand the representation of a fact to an n-tuple by consider- ing alignments of the additional resource with ele- ments of the triple. Our most expressive model en- codes a fact as X = (e s , r, e o , t s , t o , T o,s ), where t s , t o are associated representation of types of the two entities, and T o,s is the aligned textual ev- idence associated with a pair of entities from a side corpus. Representations of entities and entity types are shared between subjects and objects.  Extracted features for a KB fact with a single associated textual relation mention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.0.1">Feature Rich Networks</head><p>We model the probability of an n-tuple being true with an MLP that learns to compose and score the compatibility of the features associated with it.</p><p>Features for each individual element of the tuple are assigned low dimensional embeddings which are concatenated to form the input to the MLP. The embeddings are jointly learned with the composi- tion and scoring model through back-propagation. The probability of a fact being true is given by:</p><formula xml:id="formula_0">p(X = 1) = σ(w 3 · g(W 2 · g(W 1 · x)) (1) x = v(e s ); v(r); v(e o ); v(t s ); v(t o ); v(T s,o ) (2)</formula><p>where <ref type="formula">W</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Additional Features</head><p>We create compositional representations for the entity types and textual relation mentions with simple aggregation functions of their feature embeddings. Although not considered in this work, the overall approach is highly modular allowing for each component to be modelled by a different kind of network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Freebase Entity Types</head><p>Entities in Freebase can have multiple types assigned to them. While entity types are explicitly provided in Freebase, we instead learn type representations by considering observed relations in the training set. Each relation in Freebase is encoded as a domain/type/property of the subject entity. We extract the set of all triples where an entity takes the subject position, and keep the domain/type part as a type feature of that entity. We aggregate embeddings of all the observed discrete features using summation followed by L2-normalization to create the final representation of an entity's type. We use a special UNKNOWN symbol for entities with no observed types in the training set (i.e., entities that do not appear as subject of a triple). We create entity type representations for both subject and object entities and concatenate them to the input vector of the network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Text Relations</head><p>We use a side corpus where pairs of entities are linked to the KB and take the shortest dependency path connecting them as a textual relation mention. Since textual relations are tied to entity pairs, we collect all mentions for a given entity pair and as- sociate them with a fact. This results in a set of phrases that act as textual evidence for relations of an entity pair.</p><p>We create a representation of the associated text for each entity pair by using a Neural Bag of Words model augmented with dependency fea- tures. A dependency feature is a symbol for a word having a specific dependency relation, such as compound knowledge, compound −1 base for the knowledge base noun compound. Similar to the Entity Type representations, em- beddings of words and dependency features are aggregated by summation followed by L2- normalization, and a special UNKNOWN symbol is assigned to tuples whose pair of entities does   <ref type="bibr" target="#b7">Komninos and Manandhar, 2016)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Initialization with Pre-trained Embeddings</head><p>We experiment with pre-trained embeddings to initialize the entity vectors and text feature em- beddings of our model. Text feature embeddings are initialized from an available dependency based skip-gram model trained on Wikipedia ( <ref type="bibr" target="#b7">Komninos and Manandhar, 2016)</ref>. Features that are not in- cluded in the vocabulary of the pre-trained model are initialized with a random vector from a nor- mal distribution with zero mean and same variance as the set of pre-trained embeddings. For entity vectors, we retrieve the English name of the en- tity from Freebase and construct a representation by averaging the embeddings of the words appear- ing in the name. Entities that do not have a name property are initialized randomly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Training</head><p>The network weights are optimized by mini- mizing the binary cross-entropy loss over mini- batches using the AdaM optimizer <ref type="bibr" target="#b6">(Kingma and Ba, 2014</ref>). To avoid the large computational cost of training with all possible unobserved facts, we make use of negative sampling. The loss function is:</p><formula xml:id="formula_1">L(Θ) = − |Xp| log p(X p ) − |Xn| log(1 − p(X n ))<label>(3)</label></formula><p>where Θ are all the parameters of the network in- cluding the feature embeddings, X p are the ob- served facts in the training set and X n are ran- domly drawn unobserved facts. We construct the negative samples by fixing the subject entity and relation, and uniformly sampling an object entity with the restriction that the resulting triple is not included in the training set. We then expand the triple with entity type and text alignments. This negative sampling schedule follows the evaluation procedure, where the network has to rank triples that only differ in the object entity position. Ex- periments in the validation set indicated that for a fixed number of negative samples, only consider- ing negative samples that differ in the object po- sition performs better than also including negative samples for the subject position.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset and Evaluation Protocol</head><p>The FB15k237 dataset consists of about 15k en- tities and 237 relations derived from the FB15k dataset ( <ref type="bibr" target="#b17">Toutanova et al., 2015)</ref>. This sub-set of relations does not contain redundant re- lations that can be easily inferred, resulting in a more challenging task compared to the origi- nal FB15k dataset. There are 310,116 triples in the dataset split into 272,115/17,535/20,466 for training/validation/testing. In addition to the KB, the dataset includes dependency paths of approxi- mately 2.7 million relation instances of linked en- tity mentions extracted from the ClueWeb corpus ( <ref type="bibr" target="#b3">Gabrilovich et al., 2013)</ref>.</p><p>Evaluation follows the procedure of ( <ref type="bibr" target="#b17">Toutanova et al., 2015)</ref>. Given a positive fact in the test set, the subject entity and relation are fixed and models have to rank all facts formed by the object entities appearing in the training set. The reported met- rics are mean reciprocal rank (MRR) and hits@10. Hits@10 is the fraction of positive facts ranked in the top 10 positions. Positive facts in the training, validation and test set are removed before ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Implementation Details</head><p>Hyperparameters of the model were chosen by maximizing MRR on the validation set. We use two 300-dimensional hidden layers for the MLP, and dimensions of feature embeddings are: 300 for entity and text features, 100 for relations and 20 for entity type features. The number of nega- tive samples was set to 20 as increasing their num- ber only resulted in minor gains, and the batch size was set to 420. Best models were chosen among 20 epochs of training by monitoring valida- tion MRR. Models with embedding initializations converged within the first 10 epochs. Initialization in the text model includes initializing entity and re- lation embeddings from a model without text men- tions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results</head><p>We compare our Feature-Rich Networks with the bilinear models F and E ( <ref type="bibr" target="#b14">Riedel et al., 2013)</ref>, model DistMult ( <ref type="bibr" target="#b18">Yang et al., 2014)</ref> and their CNN augmented versions ( <ref type="bibr" target="#b17">Toutanova et al., 2015)</ref>. Re- sults can be seen in <ref type="table">Table 1</ref>.</p><p>We first observe that when modelling just KB triples, the MLP model outperforms individual bi- linear formulations, performing similarly to the best combination of DistMult + E. This shows that an additive combination of bilinear models is a strong baseline even though it does not use addi- tional parameters other than embeddings to com- pose and score triples. The addition of entity type information has a positive but small contribution to performance. This is not surprising as entity type information is extracted from observed re- lations, and latent feature models can effectively learn that during training. On the other hand, ini- tializing entity embeddings with averaged word embeddings of their names results in a substan- tial performance gain of about 1.5 points in both MRR and hits@10. In general, we observe that all models perform worse on facts with textual rela- tion mentions when they have not access to such mentions.</p><p>When textual relation mentions are added, we observe that our proposed model increases its per- formance score about 3 points in MRR and 4.5 in hits@10 compared to the best model that does not include text. Contrary to the conv-bilinear models, the performance gain is much larger for facts with textual mentions, reaching an additional 15/20 in MRR/hits@10 respectively. We attribute this gain to the explicitly represented textual relation align- ments with the KB symbols as encoded by the ex- panded tuple representations, and the non-linear composition of its elements by the MLP. We also notice that embedding initialization performs bet- ter overall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we propose joint modelling of Knowledge Bases and text with Feature-Rich Net- works. Our models can learn to combine informa- tion from different sources and better utilize noisy information from text than bilinear models aug- mented with convolutional neural networks. Be- sides text, we experiment with entity types and initialization with pre-trained embeddings, getting positive gains in performance. An interesting di- rection for future work is to combine our models with additional aligned information, such as mul- tiple KBs and to experiment with different compo- nents such as CNNs or LSTMs for text encoding.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Feature-Rich Network with all the aligned feature types associated with a fact.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Francis</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>1 ,</head><label>1</label><figDesc>W 2 , w 3 are the weights of the network, g(•) is a non-linear function applied element- wise, σ(•) is the sigmoid function and v(•) are latent feature representations of each element of the tuple. We use Rectified Linear Units as non- linearities (Nair and Hinton, 2010).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>All</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Ford Coppola, director of The Godfather, …</head><label></label><figDesc></figDesc><table>appos 
nmod:of 

subject entity 
/m/02vyw 
object entity 
/m/07g1sm 
relation 
/film/director/film 
subject entity types /people/person /film/director/ /award/award winner 
object entity types 
/film/film /award/award winning work 
text features 
appos −1 Esbj director appos director 
of nmod:of −1 director nmod:of Eobj 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Dbpedia: A nucleus for a web of open data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sören</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Bizer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgi</forename><surname>Kobilarov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Cyganiak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Ives</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The semantic web</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="722" to="735" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Freebase: a collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 ACM SIGMOD international conference on Management of data</title>
		<meeting>the 2008 ACM SIGMOD international conference on Management of data</meeting>
		<imprint>
			<publisher>AcM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1247" to="1250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multirelational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Garciaduran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oksana</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2787" to="2795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Facc1: Freebase annotation of clueweb corpora, version 1 (release date</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Ringgaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amarnag</forename><surname>Subramanya</surname></persName>
		</author>
		<ptr target="http://lemurproject.org/clueweb09/FACC1/Citedby5" />
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2013" to="2019" />
		</imprint>
	</monogr>
	<note>format version 1, correction level 0</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Knowledgebased weak supervision for information extraction of overlapping relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Congle</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th</title>
		<meeting>the 49th</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<title level="m">Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="541" to="550" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Dependency based embeddings for sentence classification tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandros</forename><surname>Komninos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suresh</forename><surname>Manandhar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL:HLT. Association for Computational Linguistics</title>
		<meeting>NAACL:HLT. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1490" to="1500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Fine-grained entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daniel S Weld</surname></persName>
		</author>
		<editor>AAAI. Citeseer</editor>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction without labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Mintz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bills</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rion</forename><surname>Snow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1003" to="1011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Rectified linear units improve restricted boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinod</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th international conference on machine learning (ICML-10)</title>
		<meeting>the 27th international conference on machine learning (ICML-10)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="807" to="814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A review of relational machine learning for knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volker</forename><surname>Tresp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="11" to="33" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A three-way model for collective learning on multi-relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Peter</forename><surname>Volker Tresp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kriegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th international conference on machine learning (ICML-11)</title>
		<meeting>the 28th international conference on machine learning (ICML-11)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="809" to="816" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Large-scale semantic parsing without questionanswer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siva</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="377" to="392" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Relation extraction with matrix factorization and universal schemas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin M</forename><surname>Marlin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Reasoning with neural tensor networks for knowledge base completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="926" to="934" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Multi-instance multi-label learning for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julie</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 joint conference on empirical methods in natural language processing and computational natural language learning</title>
		<meeting>the 2012 joint conference on empirical methods in natural language processing and computational natural language learning</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="455" to="465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Representing text for joint embedding of text and knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Pantel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoifung</forename><surname>Poon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pallavi</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Gamon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP. Citeseer</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1499" to="1509" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Embedding entities and relations for learning and inference in knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bishan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6575</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
