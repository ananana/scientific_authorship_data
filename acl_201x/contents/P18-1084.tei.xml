<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:45+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Bridging Languages through Images with Deep Partial Canonical Correlation Analysis</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 15-20, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guy</forename><surname>Rotman</surname></persName>
							<email>grotman@campus.technion.ac.il</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Industrial Engineering and Management</orgName>
								<address>
									<settlement>Technion</settlement>
									<country>IIT</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><forename type="middle">Vuli´c</forename><surname>Vuli´c</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Language Technology Lab</orgName>
								<orgName type="institution">University of Cambridge</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Reichart</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Industrial Engineering and Management</orgName>
								<address>
									<settlement>Technion</settlement>
									<country>IIT</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Bridging Languages through Images with Deep Partial Canonical Correlation Analysis</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="910" to="921"/>
							<date type="published">July 15-20, 2018</date>
						</imprint>
					</monogr>
					<note>910</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present a deep neural network that leverages images to improve bilingual text embeddings. Relying on bilingual image tags and descriptions, our approach conditions text embedding induction on the shared visual information for both languages , producing highly correlated bilingual embeddings. In particular, we propose a novel model based on Partial Canonical Correlation Analysis (PCCA). While the original PCCA finds linear projections of two views in order to maximize their canon-ical correlation conditioned on a shared third variable, we introduce a non-linear Deep PCCA (DPCCA) model, and develop a new stochastic iterative algorithm for its optimization. We evaluate PCCA and DPCCA on multilingual word similarity and cross-lingual image description retrieval. Our models outperform a large variety of previous methods, despite not having access to any visual signal during test time inference. 1</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Research in multi-modal semantics deals with the grounding problem <ref type="bibr" target="#b24">(Harnad, 1990)</ref>, motivated by evidence that many semantic concepts, irrespec- tive of the actual language, are grounded in the perceptual system ( <ref type="bibr" target="#b4">Barsalou and Wiemer-Hastings, 2005</ref>). In particular, recent studies have shown that performance on NLP tasks can be improved by joint modeling of text and vision, with multi- modal and perceptually enhanced representation learning outperforming purely textual representa-tions <ref type="bibr" target="#b18">(Feng and Lapata, 2010;</ref><ref type="bibr" target="#b35">Kiela and Bottou, 2014;</ref><ref type="bibr" target="#b42">Lazaridou et al., 2015)</ref>.</p><p>These findings are not surprising, and can be explained by the fact that humans understand lan- guage not only by its words, but also by their vi- sual/perceptual context. The ability to connect vi- sion and language has also enabled new tasks which require both visual and language understanding, such as visual question answering ( <ref type="bibr" target="#b1">Antol et al., 2015;</ref><ref type="bibr" target="#b19">Fukui et al., 2016;</ref><ref type="bibr" target="#b64">Xu and Saenko, 2016)</ref>, image-to-text retrieval and text-to-image retrieval ( <ref type="bibr" target="#b40">Kiros et al., 2014;</ref><ref type="bibr" target="#b49">Mao et al., 2014</ref>), image caption generation ( <ref type="bibr" target="#b16">Farhadi et al., 2010;</ref><ref type="bibr" target="#b48">Mao et al., 2015;</ref><ref type="bibr" target="#b59">Vinyals et al., 2015;</ref>, and visual sense disambiguation ( <ref type="bibr" target="#b21">Gella et al., 2016)</ref>.</p><p>While the main focus is still on monolingual set- tings, the fact that visual data can serve as a natural bridge between languages has sparked additional interest towards multilingual multi-modal model- ing. Such models induce bilingual multi-modal spaces based on multi-view learning <ref type="bibr" target="#b22">Gella et al., 2017;</ref><ref type="bibr" target="#b55">Rajendran et al., 2016)</ref>.</p><p>In this work, we propose a novel effective ap- proach for learning bilingual text embeddings con- ditioned on shared visual information. This addi- tional perceptual modality bridges the gap between languages and reveals latent connections between concepts in the multilingual setup. The shared vi- sual information in our work takes the form of images with word-level tags or sentence-level de- scriptions assigned in more than one language.</p><p>We propose a deep neural architecture termed Deep Partial Canonical Correlation Analysis (DPCCA) based on the Partial CCA (PCCA) method <ref type="bibr" target="#b56">(Rao, 1969)</ref>. To the best of our knowledge, PCCA has not been used in multilingual settings before. In short, PCCA is a variant of CCA which learns maximally correlated linear projections of two views (e.g., two language-specific "text-based views") conditioned on a shared third view (e.g., the "visual view"). We discuss the PCCA and DPCCA methods in §3 and show how they can be applied without having access to the shared images at test time inference.</p><p>PCCA inherits one disadvantageous property from CCA: both methods compute estimates for covariance matrices based on all training data. This would prevent feasible training of their deep non- linear variants, since deep neural nets (DNNs) are predominantly optimized via stochastic optimiza- tion algorithms. To resolve this major hindrance, we propose an effective optimization algorithm for DPCCA, inspired by the work of <ref type="bibr" target="#b63">Wang et al. (2015b)</ref> on Deep CCA (DCCA) optimization.</p><p>We evaluate our DPCCA architecture on two se- mantic tasks: 1) multilingual word similarity and 2) cross-lingual image description retrieval. For the former, we construct and provide to the commu- nity a new Word-Image-Word (WIW) dataset con- taining bilingual lexicons for three languages with shared images for 5K+ concepts. WIW is used as training data for word similarity experiments, while evaluation is conducted on the standard multilin- gual SimLex-999 dataset ( <ref type="bibr" target="#b27">Hill et al., 2015;</ref><ref type="bibr" target="#b43">Leviant and Reichart, 2015)</ref>.</p><p>The results reveal stable improvements over a large space of non-deep and deep CCA-style base- lines in both tasks. Most importantly, 1) PCCA is overall better than other methods which do not use the additional perceptual view; 2) DPCCA out- performs PCCA, indicating the importance of non- linear transformations modeled through DNNs; 3) DPCCA outscores DCCA, again verifying the im- portance of conditioning multilingual text embed- ding induction on the shared visual view; and 4) DPCCA outperforms two recent multi-modal bilin- gual models which also leverage visual information <ref type="bibr" target="#b22">(Gella et al., 2017;</ref><ref type="bibr" target="#b55">Rajendran et al., 2016</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>This work is related to two research threads: 1) multi-modal models that combine vision and lan- guage, with a focus on multilingual settings; 2) cor- relational multi-view models based on CCA which learn a shared vector space for multiple views.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multi-Modal Modeling in Multilingual Settings</head><p>Research in cognitive science suggests that human meaning representations are grounded in our per- ceptual system and sensori-motor experience <ref type="bibr" target="#b24">(Harnad, 1990;</ref><ref type="bibr" target="#b41">Lakoff and Johnson, 1999;</ref><ref type="bibr" target="#b46">Louwerse, 2011</ref>). Visual context serves as a useful cross- lingual grounding signal ( <ref type="bibr" target="#b6">Bruni et al., 2014;</ref><ref type="bibr" target="#b23">Glavaš et al., 2017</ref>) due to its language invariance, even en- abling the induction of word-level bilingual seman- tic spaces solely through tagged images obtained from the Web (Bergsma and Van Durme, 2011; <ref type="bibr" target="#b38">Kiela et al., 2015)</ref>. Vuli´c <ref type="bibr" target="#b60">Vuli´c et al. (2016)</ref> combine text embeddings with visual features via simple tech- niques of concatenation and averaging to obtain bilingual multi-modal representations, with noted improvements over text-only embeddings on word similarity and bilingual lexicon extraction. How- ever, similar to the monolingual model of <ref type="bibr" target="#b35">Kiela and Bottou (2014)</ref>, their models lack the training phase, and require the visual signal at test time.</p><p>Recent work from <ref type="bibr" target="#b22">Gella et al. (2017)</ref> exploits vi- sual content as a bridge between multiple languages by optimizing a contrastive loss function. Further- more, <ref type="bibr" target="#b55">Rajendran et al. (2016)</ref> extend the work of  and propose to use a pivot representation in multimodal multilingual setups, with English representations serving as the pivot. While these works learn shared multimodal mul- tilingual vector spaces, we demonstrate improved performance with our models (see §7).</p><p>Finally, although not directly comparable, recent work in neural machine translation has constructed models that can translate image descriptions by additionally relying on visual features of the im- age provided <ref type="bibr" target="#b14">Elliott et al., 2015;</ref><ref type="bibr" target="#b28">Hitschler et al., 2016;</ref><ref type="bibr" target="#b32">Huang et al., 2016;</ref><ref type="bibr" target="#b54">Nakayama and Nishida, 2017</ref>, inter alia).</p><p>Correlational Models CCA-based techniques support multiple views on related data: e.g., when coupled with a bilingual dictionary, input monolin- gual word embeddings for two different languages can be seen as two views of the same latent se- mantic signal. Recently, CCA-based models for bilingual text embedding induction were proposed. These models rely on the basic CCA model <ref type="bibr" target="#b17">Faruqui and Dyer, 2014)</ref>, its deep variant ( , and a CCA extension which supports more than two views ( <ref type="bibr" target="#b20">Funaki and Nakayama, 2015;</ref><ref type="bibr" target="#b57">Rastogi et al., 2015)</ref>. In this work, we propose to use (D)PCCA, which organ- ically supports our setup: it conditions the two (textual) views on a shared (visual) view.</p><p>CCA-based methods (including PCCA) require the estimation of covariance matrices over all train- ing data ( <ref type="bibr" target="#b33">Kessy et al., 2017)</ref>. This hinders the use of DNNs with these models, as DNNs are typi- cally trained via stochastic optimization over mini-batches on very large training sets. To address this limitation, various optimization methods for Deep CCA were proposed. <ref type="bibr" target="#b0">Andrew et al. (2013)</ref> use L-BFGS ( <ref type="bibr" target="#b7">Byrd et al., 1995</ref>) over all training samples, while  and <ref type="bibr" target="#b66">Yan and Mikolajczyk (2015)</ref> train with large batches. However, these methods suffer from high memory complexity with unstable numerical computations. <ref type="bibr" target="#b63">Wang et al. (2015b)</ref> have recently proposed a stochastic approach for CCA and DCCA which copes well with small and large batch sizes while preserving high model performance. They use or- thogonal iterations to estimate a moving average of the covariance matrices, which improves memory consumption. Therefore, we base our novel opti- mization algorithm for DPCCA on this approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology: Deep Partial CCA</head><p>Given two image descriptions x and y in two lan- guages and an image z that they refer to, the task is to learn a shared bilingual space such that similar descriptions obtain similar representations in the in- duced space. The image z serves as a shared third view on the textual data during training. The rep- resentation model is then utilized in cross-lingual and monolingual tasks. In this paper we focus on the more realistic scenario where no relevant vi- sual content is available at test time. For this goal we propose a novel Deep Partial CCA (DPCCA) framework.</p><p>In what follows, we first review the CCA model and its deep variant: DCCA. We then introduce our DPCCA architecture, and describe our new stochastic optimization algorithm for DPCCA. The goal is to project the features of X and</p><formula xml:id="formula_0">Y into a shared L-dimensional (1 ≤ L ≤ min(D x , D y )) space such that the canonical corre- lation of the final outputs F (X) = W T f (X) and G(Y ) = V T g(Y ) is maximized. W ∈ R D</formula><p>x ×L and V ∈ R D y ×L are projection matrices: they project the final outputs of the DNNs to the shared space. W f and V g (the parameters of f and g) and the projection matrices are the model parameters:</p><formula xml:id="formula_1">W F = {W f , W }; V G = {V g , V }. 2</formula><p>Formally, the DCCA objective can be written as:</p><formula xml:id="formula_2">max W F ,V G T r( ˆ Σ F G ) so thatˆΣthatˆ thatˆΣ F F = ˆ Σ GG = I. (1) ˆ Σ F G ≡ 1 N −1 F (X)G(Y ) T is the estimation of the cross-covariance matrix of the outputs, andˆΣandˆ andˆΣ F F ≡ 1 N −1 F (X)F (X) T , ˆ Σ GG ≡ 1 N −1 G(Y )G(Y )</formula><p>T are the estimations of the auto- covariance matrices of the outputs. 3 Further, fol- lowing <ref type="bibr" target="#b63">Wang et al. (2015b)</ref>, the optimal solution of Eq. <ref type="formula">(1)</ref> is equivalent to the optimal solution of the following:</p><formula xml:id="formula_3">min W F ,V G 1 N − 1 F (X) − G(Y ) 2 F s.t. ˆ Σ F F = ˆ Σ GG = I.<label>(2)</label></formula><p>The main disadvantage of DCCA is its inability to support more than two views, and to learn condi- tioned on an additional shared view, which is why we introduce Deep Partial CCA. <ref type="figure" target="#fig_1">Figure 1b</ref> illustrates the architecture of DPCCA. The training data now consists of triplets (x i , y i , z i ) N 1=1 from three views, forming the columns of X, Y and Z, where x i ∈ R Dx , y i ∈ R Dy , z i ∈ R Dz for i = 1, . . . , N . The objective is to maximize the canonical correlation of the first two views X and Y conditioned on the shared third variable Z. Following Rao (1969)'s work on Partial CCA, we first consider two multivariate linear multiple regression models: A, B ∈ R L×Dz are matrices of coefficients, and F (X|Z), G(Y |Z) ∈ R L×N are normal random error matrices: residuals. We then minimize the mean-squared error regression criterion:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">New Model: Deep Partial CCA</head><formula xml:id="formula_4">F (X) = AZ + F (X|Z), (3) G(Y ) = BZ + G(Y |Z).<label>(4)</label></formula><formula xml:id="formula_5">min A 1 N − 1 F (X) − AZ 2 F ,<label>(5)</label></formula><formula xml:id="formula_6">min B 1 N − 1 G(Y ) − BZ 2 F .<label>(6)</label></formula><p>After obtaining the optimal solutions for the coeffi- cients, ˆ A andˆBandˆ andˆB, the residuals are as follows:</p><formula xml:id="formula_7">F (X|Z) = F (X) − ˆ AZ = F (X) − ˆ ΣF Z ˆ Σ −1 ZZ Z.<label>(7)</label></formula><p>G(Y |Z) is computed in the analogous man- ner, now relying on G(Y ) andˆBZandˆ andˆBZ. ˆ Σ S Z ≡ 1 N −1 SZ T refers to the covariance matrix es- timator of S and Z, where</p><formula xml:id="formula_8">(S , S) ∈ {(F , F (X)), (G, G(Y )), (Z, Z)}. 4</formula><p>The canonical correlation between the residual matrices F (X|Z) and G(Y |Z) is referred to as the partial canonical correlation. The Deep PCCA objective can be obtained by replacing F (X) and G(Y ) with their residuals in Eq. <ref type="formula" target="#formula_3">(2)</ref>:</p><formula xml:id="formula_9">min W F ,V G 1 N − 1 F (X|Z) − G(Y |Z) 2 F s.t. ˆ Σ F F |Z = ˆ Σ GG|Z = I.<label>(8)</label></formula><p>The computation of the conditional covariance ma- trixˆΣtrixˆ trixˆΣ F F |Z can be formulated as follows:</p><formula xml:id="formula_10">ˆ Σ F F |Z ≡ 1 N − 1 F (X|Z)F (X|Z) T = ˆ ΣF F − ˆ ΣF Z ˆ Σ −1 ZZˆΣ ZZˆ ZZˆΣ T F Z .<label>(9)</label></formula><p>4 A small value &gt; 0 is added to the main diagonal of the covariance estimators for numerical stability.</p><p>The other conditional covariance matrixˆΣmatrixˆ matrixˆΣ GG|Z is again computed in the analogous manner, replacing F with G and X with Y . <ref type="bibr">5</ref> While the (D)PCCA objective is computed over the residuals, after the network is trained (using multilingual texts and corresponding images) we can compute the representations of F (X) and G(Y ) at test time without having access to im- ages (see the network structure in <ref type="figure" target="#fig_1">Figure 1b)</ref>. This heuristic enables the use of DPCCA in a real-life scenario in which images are unavailable at test time, and its encouraging results are demonstrated in §7.</p><p>Model Variants We consider two DPCCA vari- ants : 1) in DPCCA Variant A, the shared view Z is kept fixed; 2) DPCCA Variant B also optimizes over Z, as illustrated in <ref type="figure" target="#fig_1">Figure 1b</ref>. Variant A may be seen as a special case of Variant B. <ref type="bibr">6</ref> Variant B learns a non-linear function of the shared variable, H(Z) = U T h(Z), during train- ing, where h : R Dz×N → R D z ×N is a DNN hav- ing the same architecture as f and g. U ∈ R D z ×L is the final linear layer of H, such that over- all, the additional parameters of the model are U H = {U h , U }. Instead of assuming a linear connection between F (X) and G(Y ) to Z, as in Variant A, we now assume that the linear con- nection takes place with H(Z). This assumption <ref type="bibr">5</ref> The original PCCA objective can be recovered by setting</p><formula xml:id="formula_11">D x = Dx, D y = Dy and f (X) = idX , g(Y ) = idY . 6</formula><p>For Variant A, in order for Z to be on the same range of values as in F and G, we pass it through the activation function of the network, Z = σ(Z). Due to space constraints we discuss DPCCA Variant A in the supplementary material only. changes Eq. <ref type="formula">(3)</ref> and Eq. (4) to: 7</p><formula xml:id="formula_12">F (X) = A · H(Z) + F (X|H(Z)),<label>(10)</label></formula><formula xml:id="formula_13">G(Y ) = B · H(Z) + G(Y |H(Z)).<label>(11)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DPCCA: Optimization Algorithm</head><p>Training deep variants of CCA-style multi-view models is non-trivial due to estimation on the en- tire training set related to whitening constraints (i.e., the orthogonality of covariance matrices). To overcome this issue, <ref type="bibr" target="#b63">Wang et al. (2015b)</ref> proposed a stochastic optimization algorithm for DCCA via non-linear orthogonal iterations (DCCA NOI). Re- lying on the solution for DCCA ( §4.1), we develop a new optimization algorithm for DPCCA in §4.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Optimization of DCCA</head><p>The DCCA optimization from <ref type="bibr" target="#b63">Wang et al. (2015b)</ref>, fully provided in Algorithm 1, relies on three key steps. First, the estimation of the covariance matri- ces in the form ofˆΣofˆ ofˆΣ F F t at time t is calculated by a moving average over the minibatches:</p><formula xml:id="formula_14">ˆ Σ F F t ←ρˆΣ←ρˆ ←ρˆΣ F F t−1 + (1 − ρ) |bt| N − 1 −1 F (Xb t )F (Xb t ) T . (12)</formula><p>b t is the minibatch at time t, X bt is the current in- put matrix at time t, and ρ ∈ [0, 1] controls the ratio between the overall covariance estimation and the covariance estimation of the current minibatch. 8 This step eliminates the need of estimating the co- variances over all training data, as well as the in- herent bias when the estimate relies only on the current minibatch. Second, the DCCA NOI algorithm forces the whitening constraints to hold by performing an explicit matrix transformation in the form of:</p><formula xml:id="formula_15">F (Xb t ) = ˆ Σ − 1 2 F F t F (Xb t ).<label>(13)</label></formula><p>According to <ref type="bibr" target="#b29">Horn et al. (1988)</ref>, if ρ = 0:</p><formula xml:id="formula_16">|bt| N − 1 −1 F (Xb t ) F (Xb t ) T = I.<label>(14)</label></formula><p>Finally, in order to optimize the DCCA objective (see Eq. <ref type="formula" target="#formula_3">(2)</ref>), the weights of the two DNNs are de- coupled: i.e., the objective is disassembled into two separate mean-squared error objectives. Instead of Algorithm 1 The non-linear orthogonal iterations (NOI) algorithm for DCCA (DCCA NOI)</p><p>Input: Data matrices X ∈ R Dx×N , Y ∈ R Dy ×N , time constant ρ, learning rate η.</p><p>initialization: Initialize weights (WF , VG).</p><p>Randomly choose a minibatch (Xb 0 , Yb 0 ). Initialize covariances: <ref type="figure" target="#fig_1">1, 2, .</ref> . . , n do Randomly choose a minibatch (Xb t , Yb t ).</p><formula xml:id="formula_17">ˆ ΣF F ← N −1 |b 0 | F (Xb 0 )F (Xb 0 ) T ˆ ΣGG ← N −1 |b 0 | G(Yb 0 )G(Yb 0 ) T for t =</formula><p>Update covariances:</p><formula xml:id="formula_18">ˆ ΣF F ← ρ ˆ ΣF F + (1 − ρ) N −1 |b t | F (Xb t )F (Xb t ) T ˆ ΣGG ← ρ ˆ ΣGG + (1 − ρ) N −1 |b t | G(Yb t )G(Yb t ) T Fix G(Yb t ) = ˆ Σ − 1 2 GG G(Yb t )</formula><p>, and compute WF with respect to: min</p><formula xml:id="formula_19">W F 1 |b t | F (Xb t ) − G(Yb t ) 2 F</formula><p>Update parameters:</p><formula xml:id="formula_20">WF ← WF − ηWF Fix F (Xb t ) = ˆ Σ − 1 2 F F F (Xb t )</formula><p>, and compute VG with respect to: min</p><formula xml:id="formula_21">V G 1 |b t | G(Yb t ) − F (Xb t ) 2 F</formula><p>Update parameters:</p><formula xml:id="formula_22">VG ← VG − ηVG end for Output: (WF , VG)</formula><p>trying to bring F (X bt ) and G(Y bt ) closer in one gradient descent step, two steps are performed: one of the views is fixed, and a gradient step over the other is performed, and so on, iteratively. The final objective functions at each time step are: <ref type="bibr" target="#b63">Wang et al. (2015b)</ref> show that the projection ma- trices W and V converge to the exact solutions of CCA as t→ ∞ when considering linear CCA.</p><formula xml:id="formula_23">min W F 1 |bt| F (Xb t ) − G(Yb t ) 2 F ,<label>(15)</label></formula><formula xml:id="formula_24">min V G 1 |bt| G(Yb t ) − F (Xb t ) 2 F .<label>(16)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Optimization of DPCCA</head><p>Our DPCCA optimization is based on the DCCA NOI algorithm with several adjustments. Besides the requirement to obtain the sample covariancesˆΣcovariancesˆ covariancesˆΣ F F andˆΣandˆ andˆΣ GG , when calculating the conditional variables F (X|Z), G(Y |Z), ˆ Σ F F |Z andˆΣandˆ andˆΣ GG|Z , we additionally have to obtain the stochastic estimatorsˆΣestimatorsˆ estimatorsˆΣ F Z , ˆ Σ GZ andˆΣ andˆ andˆΣ ZZ . To this end, we use the moving average esti- mation from Eq. (12). Next, we define the whiten- ing transformation on the residuals:</p><formula xml:id="formula_25">F (Xb t |Zb t ) = ˆ Σ − 1 2 F F t |Z F (Xb t |Zb t ),<label>(17)</label></formula><formula xml:id="formula_26">G(Yb t |Zb t ) = Σ − 1 2 GG t |Z G(Yb t |Zb t ).<label>(18)</label></formula><p>As before, the whitening constraints hold when ρ = 0. From here, we derive our two final objective functions over the residuals at time t:</p><formula xml:id="formula_27">min W F 1 |bt| F (Xb t |Zb t ) − G(Yb t |Zb t ) 2 F ,<label>(19)</label></formula><formula xml:id="formula_28">min V G 1 |bt| G(Yb t |Zb t ) − F (Xb t |Zb t ) 2 F .<label>(20)</label></formula><p>Equivalently to Eq. <ref type="formula" target="#formula_5">(15)</ref>- <ref type="formula" target="#formula_6">(16)</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Tasks and Data</head><p>Cross-lingual Image Description Retrieval The cross-lingual image description retrieval task is formulated as follows: taking an image description as a query in the source language, the system has to retrieve a set of relevant descriptions in the target language which describe the same image. Our evaluation assumes a single-best scenario, where only a single target description is relevant for each query. In addition, in our setup, images are not available during inference: retrieval is performed based solely on text queries. This enables a fair comparison between our model and many baseline models that cannot represent images and text in a shared space. Moreover, it allows us to test our model in the realistic setup where images are not available at test time. To avoid the use of images at retrieval time with DPCCA, we perform the retrieval on F (X) and G(Y ), rather than on F (X|Z) and G(Y |Z) (see §3.2).</p><p>We use the Multi30K dataset (Elliott et al., 2016), originated from Flickr30K ( <ref type="bibr" target="#b67">Young et al., 2014</ref>) that is comprised of Flicker images described with 1-5 English descriptions per image. Multi30K adds Algorithm 2 The non-linear orthogonal iterations (NOI) algorithm for DPCCA Variant B Input: Data matrices X ∈ R Dx×N , Y ∈ R Dy ×N , Z ∈ R Dz ×N , time constant ρ, learning rate η.</p><p>initialization: Initialize weights (WF , VG, UH ). Randomly choose a minibatch (Xb 0 , Yb 0 , Zb 0 ). Initialize covariances:</p><formula xml:id="formula_29">ˆ ΣF F ← N −1 |b 0 | F (Xb 0 )F (Xb 0 ) T ˆ ΣGG ← N −1 |b 0 | G(Yb 0 )G(Yb 0 ) T ˆ ΣHH ← N −1 |b 0 | H(Zb 0 )H(Zb 0 ) T ˆ ΣF H ← N −1 |b 0 | F (Xb 0 )H(Zb 0 ) T ˆ ΣGH ← N −1 |b 0 | G(Yb 0 )H(Zb 0 ) T for t = 1, 2, . . . , n do Randomly choose a minibatch (Xb t , Yb t , Zb t ). Update covariances: ˆ ΣF F ← ρ ˆ ΣF F + (1 − ρ) N −1 |b t | F (Xb t )F (Xb t ) T ˆ ΣGG ← ρ ˆ ΣGG + (1 − ρ) N −1 |b t | G(Yb t )G(Yb t ) T ˆ ΣHH ← ρ ˆ ΣHH + (1 − ρ) N −1 |b t | H(Zb t )H(Zb t ) T ˆ ΣF H ← ρ ˆ ΣF H + (1 − ρ) N −1 |b t | F (Xb t )H(Zb t ) T ˆ ΣGH ← ρ ˆ ΣGH + (1 − ρ) N −1 |b t | G(Yb t )H(Zb t ) T Update conditional variables: F |H ← F (Xb t ) − ˆ ΣF H ˆ Σ −1 HH H(Zb t ) G|H ← G(Yb t ) − ˆ ΣGHˆΣΣGHˆ ΣGHˆΣ −1 HH H(Zb t ) ˆ Σ F F |H ← ˆ ΣF F − ˆ ΣF H ˆ Σ −1 HHˆΣ HHˆ HHˆΣ T F H ˆ Σ GG|H ← ˆ ΣGG − ˆ ΣGHˆΣΣGHˆ ΣGHˆΣ −1 HHˆΣ HHˆ HHˆΣ T GH Fix G|H = ˆ Σ − 1 2</formula><p>GG|H G|H, and compute WF , UH with respect to: min</p><formula xml:id="formula_30">W F ,U H 1 |b t | F |H − G|H 2 F Update parameters: WF ← WF − ηWF , UH ← UH − ηUH Fix F |H = ˆ Σ − 1 2</formula><p>F F |H F |H, and compute VG, UH with respect to: min</p><formula xml:id="formula_31">V G ,U H 1 |b t | G|H − F |H 2 F Update parameters: VG ← VG − ηVG, UH ← UH − ηUH end for Output: (WF , VG, UH )</formula><p>German descriptions to a total of 30,014 images: most were written independently of the English de- scriptions, while some are direct translations. Each image is associated with one English and one Ger- man description. We rely on the original Multi30K splits with 29,000, 1,014, and 1,000 triplets for training, validation, and test, respectively.</p><p>Multilingual Word Similarity The word simi- larity task tests the correlation between automatic and human generated word similarity scores. We evaluate with the Multilingual SimLex-999 dataset ( <ref type="bibr" target="#b43">Leviant and Reichart, 2015)</ref>: the 999 English (EN) <ref type="table" target="#tab_1">Nouns  4606  4735  4106  Adjectives  405  416  348  Verbs  392  400  227  Adverbs  167  161  142  Prepositions 12  12  9</ref> Total 5598 5740 4838 word pairs from SimLex-999 ( <ref type="bibr" target="#b27">Hill et al., 2015)</ref> were translated to German (DE), Italian (IT), and Russian (RU), and similarity scores were crowd- sourced from native speakers. We introduce a new dataset termed Word-Image- Word (WIW), which we use to train word-level models for the multilingual word similarity task. WIW contains three bilingual lexicons (EN-DE, EN-IT, EN-RU) with images shared between words in a lexicon entry. Each WIW entry is a triplet: an English word, its translation in DE/IT/RU, and a set of images relevant to the pair.</p><note type="other">EN-DE EN-IT EN-RU</note><p>English words were taken from the January 2017 Wikipedia dump. After removing stop words and punctuation, we extract the 6,000 most fre- quent words from the cleaned corpus not present in SimLex. DE/IT/RU words were obtained semi- automatically from the EN words using Google Translate. The images are crawled from the Bing search engine using MMFeat 9 <ref type="bibr" target="#b34">(Kiela, 2016)</ref> by querying the EN words only. Following the sugges- tions from the study of , we save the top 20 images as relevant images. <ref type="bibr">10</ref> Table 1 provides a summary of the WIW dataset. The dataset contains both concrete and abstract words, and words of different POS tags. 11 This property has an influence on the image collection: similar to , we have noticed that images of more concrete concepts are less dis- persed (see also examples from <ref type="figure">Figure 2</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experimental Setup</head><p>Data Preprocessing and Embeddings For the sentence-level task, all descriptions were lower- <ref type="figure">Figure 2</ref>: WIW examples from each of the three bilingual lexicons. Note that the designated words can be either abstract (true), express an action (dance) or be more concrete (plant). cased and tokenized. Each sentence is represented with one vector: the average of its word embed- dings. For English, we rely on 500-dimensional En- glish skip-gram word embeddings ( <ref type="bibr" target="#b51">Mikolov et al., 2013</ref>) trained on the January 2017 Wikipedia dump with bag-of-words contexts (window size of 5). For German we use the deWaC 1.7B corpus ( <ref type="bibr" target="#b3">Baroni et al., 2009</ref>) to obtain 500-dimensional German em- beddings using the same word embedding model. For word similarity, to be directly comparable to previous work, we rely on 300-dim word vectors in EN, DE, IT, and RU from Mrkši´ <ref type="bibr" target="#b52">Mrkši´c et al. (2017)</ref>.</p><p>Visual features are extracted from the penul- timate layer (FC7) of the VGG-19 network <ref type="bibr" target="#b58">(Simonyan and Zisserman, 2015)</ref>, and compressed to the dimensionality of the textual inputs by a Princi- pal Component Analysis (PCA) step. For the word similarity task, we average the visual vectors across all images of each word pair as done in, e.g., <ref type="bibr" target="#b60">(Vuli´cVuli´c et al., 2016)</ref>, before the PCA step.</p><p>Baseline Models We consider a wide variety of multi-view CCA-based baselines. First, we compare against the original (linear) CCA model <ref type="bibr" target="#b31">(Hotelling, 1936)</ref>, and its deep non-linear exten- sion DCCA ( <ref type="bibr" target="#b0">Andrew et al., 2013</ref>). For DCCA: 1) we rely on its improved optimization algorithm from <ref type="bibr" target="#b62">Wang et al. (2015a)</ref> which uses a stochas- tic approach with large minibatches; 2) we com- pare against the DCCA NOI variant ( <ref type="bibr" target="#b63">Wang et al., 2015b</ref>) described by Algorithm 1, and another re- cent DCCA variant with the optimization algorithm based on a stochastic decorrelational loss ( <ref type="bibr" target="#b11">Chang et al., 2017</ref>) (DCCA SDL); and 3) we also test the DCCA Autoencoder model (DCCAE) ( <ref type="bibr" target="#b62">Wang et al., 2015a</ref>), which offers a trade-off between maximizing the canonical correlation of two sets of variables and finding informative features for their reconstruction.</p><p>Another baseline is Generalized CCA (GCCA) ( <ref type="bibr" target="#b20">Funaki and Nakayama, 2015;</ref><ref type="bibr" target="#b30">Horst, 1961;</ref><ref type="bibr" target="#b57">Rastogi et al., 2015</ref>): a linear model which extends CCA to three or more views. Unlike PCCA, GCCA does not condition two variables on the third shared one, but rather seeks to maximize the canonical correla- tions of all pairs of views. We also compare to Non- parametric CCA (NCCA) ( <ref type="bibr" target="#b50">Michaeli et al., 2016)</ref>, and to a probabilistic variant of PCCA (PPCCA, <ref type="bibr" target="#b53">Mukuta and Harada (2014)</ref>).</p><p>Finally, we compare with the two recent models which operate in the setup most similar to ours: 1) Bridge Correlational Networks (BCN) <ref type="bibr" target="#b55">(Rajendran et al., 2016)</ref>; and 2) Image Pivoting (IMG PIVOT) from <ref type="bibr" target="#b22">Gella et al. (2017)</ref>. For both models, we re- port results only with the strongest variant based on the findings from the original papers, also verified by additional experimentation in our work. <ref type="bibr">12</ref> Hyperparameter Tuning The hyperparameters of the different models are tuned with a grid search over the following values: {2,3,4,5} for number of layers, {tanh, sigmoid, ReLU} as the activation functions (we use the same activation function in all the layers of the same network), {64,128,256} for minibatch size, {0.001,0.0001} for learning rate, and {128,256} for L (the size of the output vectors). The dimensions of all mid-layers are set to the input size. We use the Adam optimizer ( <ref type="bibr" target="#b39">Kingma and Ba, 2015)</ref>, with the number of epochs set to 300.</p><p>For all participating models, we report test per- formance of the best hyperparameter on the valida- tion set. For word similarity, following a standard practice ( <ref type="bibr" target="#b44">Levy et al., 2015;</ref> we tune all models on one half of the SimLex data and evaluate on the other half, and vice versa. The reported score is the average of the two halves. Similarity scores for all tasks were computed using the cosine similarity measure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Results and Discussion</head><p>Cross-lingual Image Description Retrieval We report two standard evaluation metrics: 1) Recall at 1 (R@1) scores, and 2) the sentence-level BLEU+1 metric ( <ref type="bibr" target="#b45">Lin and Och, 2004</ref>), a variant of BLEU which smooths terms for higher-order n-grams, making it more suitable for evaluating short sentences. The scores for the retrieval task with all models are summarized in <ref type="table" target="#tab_2">Table 2</ref>. <ref type="bibr">12</ref> More details about preprocessing and baselines (includ- ing all links to their code), are in the the supplementary mate- rial. We use original readily available implementations of all baselines whenever this is possible, and our in-house imple- mentations for baselines for which no code is provided by the original authors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>R@1 BLEU+1</head><p>Model EN→DE DE→EN EN→DE DE→EN DPCCA (Variant A) 0.795 0.779 0.836 0.827 DPCCA <ref type="table">(Variant B)</ref> 0.809 0.794 0.848 0.839 DPCCA(B)+DCCA NOI (concat) 0.826 0.791 0.863 0.837 DCCA NOI ( <ref type="bibr" target="#b63">Wang et al., 2015b)</ref> 0.812 0.788 0.849 0.830 DCCA SDL ( <ref type="bibr" target="#b11">Chang et al., 2017)</ref> 0.507 0.487 0.552 0.533 DCCA ( <ref type="bibr" target="#b62">Wang et al., 2015a)</ref> 0.619 0.621 0.664 0.673 DCCAE ( <ref type="bibr" target="#b62">Wang et al., 2015a)</ref> 0.564 0.542 0.607 0.598 IMG PIVOT ( <ref type="bibr" target="#b22">Gella et al., 2017)</ref> 0.772 0.763 0.789 0.781 BCN ( <ref type="bibr" target="#b55">Rajendran et al., 2016)</ref> 0.579 0.570 0.628 0.629 PCCA <ref type="bibr" target="#b56">(Rao, 1969)</ref> 0.785 0.737 0.825 0.787 CCA <ref type="bibr" target="#b31">(Hotelling, 1936)</ref> 0.764 0.704 0.803 0.754 GCCA ( <ref type="bibr" target="#b20">Funaki and Nakayama, 2015)</ref> 0.699 0.690 0.742 0.743 NCCA ( <ref type="bibr" target="#b50">Michaeli et al., 2016)</ref> 0.157 0.165 0.205 0.213 PPCCA ( <ref type="bibr" target="#b53">Mukuta and Harada, 2014)</ref> 0.035 0.050 0.063 0.086 The results clearly demonstrate the superiority of DPCCA (with a slight advantage to the more complex Variant B) and of the concatenation of their representation with that of the DCCA NOI (strongest) baseline. Furthermore, the non-deep, linear PCCA achieves strong results: it outscores all non-deep models, as well as all deep models except from DCCA NOI, IMG PIVOT in one case, and its deep version: DPCCA. This emphasizes our contribution in proposing PCCA for multilingual processing with images as a cross-lingual bridge.</p><p>The results suggest that: 1) the inclusion of vi- sual information in the training process helps the retrieval task even without such information during inference. DPCCA outscores all DCCA variants (either alone or through a concatenation with the DCCA NOI representation), and PCCA outscores the original two-view CCA model; and 2) deep, non-linear architectures are useful: our DPCCA outperforms the linear PCCA model. We also note clear improvements over the two re- cent models which also rely on visual information: IMG PIVOT and BCN. The gain over IMG PIVOT is observed despite the fact that IMG PIVOT is a more complex multi-modal model which relies on RNNs, and is tailored to sentence-level tasks. Finally, the scores from <ref type="table" target="#tab_2">Table 2</ref> suggest that im- proved performance can be achieved by an en- semble model, that is, a simple concatenation of DPCCA (B) and DCCA NOI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multilingual Word Similarity</head><p>The results, pre- sented as standard Spearman's rank correlation scores, are summarized in    <ref type="table" target="#tab_5">Table 4</ref> presents results on all SimLex word pairs. The POS class result patterns for EN-IT and EN-RU are very similar to the patterns in <ref type="table" target="#tab_3">Table 3</ref> and are provided in the supplementary material. First, the results over the initial monolingual embeddings before training (INIT EMB) clearly indicate that multilingual information is beneficial for the word similarity task. We observe improvements with all models (the only exception being extremely low- scoring PPCCA and NCCA, not shown). More- over, by additionally grounding concepts from two languages in the visual modality it is possible to further boost word similarity scores. This result is in line with prior work in monolingual settings ( <ref type="bibr">Chrupała et al., 2015;</ref><ref type="bibr" target="#b35">Kiela and Bottou, 2014;</ref><ref type="bibr" target="#b42">Lazaridou et al., 2015)</ref>, which have shown to profit from multi-modal features.</p><p>The results on the POS classes represented in SimLex-999 (nouns, verbs, adjectives, <ref type="table" target="#tab_3">Table 3</ref>) form our main finding: conditioning the multilin- gual representations on a shared image leads to im- provements in verb and adjective representations. While for nouns one of the DPCCA variants is the best performing model for both languages, the gaps from the best performing baselines are much smaller. This is interesting since, e.g., verbs are more abstract than nouns ( <ref type="bibr" target="#b25">Hartmann and Søgaard, 2017;</ref>). Considering the fact that SimLex-999 consists of 666 noun pairs, 222 verb pairs and 111 adjective pairs, this is the reason that the gains of DPCCA over the strongest baselines across the entire evaluation set are more modest <ref type="table" target="#tab_5">(Table 4</ref>). We note again that the same patterns presented in <ref type="table" target="#tab_3">Table 3</ref> for EN-DE -more promi- nent verb and adjective gains and a smaller gain on nouns -also hold for EN-IT and EN-RU (see the supplementary material).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion and Future Work</head><p>We addressed the problem of utilizing images as a bridge between languages to learn improved bilin- gual text representations. Our main contribution is two-fold. First, we proposed to use the Partial CCA (PCCA) method. In addition, we proposed a stochastic optimization algorithm for the deep version of PCCA that overcomes the challenges posed by the covariance estimation required by the method. Our experiments reveal the effectiveness of these methods for both sentence-level and word- level tasks. Crucially, our proposed solution does not require access to images at inference/test time, in line with the realistic scenario where images that describe sentential queries are not readily available.</p><p>In future work we plan to improve our meth- ods by exploiting the internal structure of images and sentences as well as by effectively integrating signals from more than two languages.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>3</head><label></label><figDesc>.1 CCA and Deep CCA DCCA (Andrew et al., 2013) extends CCA by learning non-linear (instead of linear) transforma- tions of features contained in the input matrices X ∈ R Dx×N and Y ∈ R Dy×N , where D x and D y are input vector dimensionalities, and N is the number of input items. Since CCA is a special case of the non-linear DCCA (see below), we here briefly outline the more general DCCA model. The DCCA architecture is illustrated in Fig- ure 1a. Non-linear transformations are achieved through two DNNs f : R Dx×N → R D x ×N and g : R Dy×N → R D y ×N for X and Y . D x and D y are the output dimensionalities. A final linear layer is added to resemble the linear CCA projection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: DCCA and DPCCA architectures. (a): DCCA. X and Y (English and German image descriptions) are fed through two identical deep feed-forward neural networks followed by a final linear layer. The final nodes of the networks F (X) and G(Y ) are then maximally correlated via the CCA objective. (b): DPCCA. In addition, a third (shared) variable Z (an image) is either optimized via an identical architecture of the two main views (DPCCA Variant B, illustrated here) or kept fixed (DPCCA Variant A). The final nodes of the networks F (X) and G(Y ) are maximally correlated conditioned on the final node in the middle network H(Z) (or directly on the input node Z in DPCCA Variant A).</figDesc><graphic url="image-1.png" coords="4,74.70,63.11,215.28,90.03" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>for the projection matrices of the residuals. Algorithm 2 shows the full optimization pro- cedure for the more complex DPCCA Variant B. The full algorithm for Variant A is provided in the supplementary material. The main difference is that with Variant B we replace Z with H(Z) in all equations where it appears, and we optimize over U H along with W F and V G in Eq. (19) and Eq. (20), respectively.</figDesc><table>that replace Eq. (2), 
Eq. (19)-(20) replace Eq. (8) by performing 
stochastic, decoupled and unconstrained steps. As 
our algorithm performs CCA over the residuals, we 
gain the same guarantees as Wang et al. (2015b), 
now </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>WIW statistics: the number of WIW en-
tries across POS classes in each language pair. The 
numbers of words per POS class are not summed 
to the total number of words as other (less frequent) 
POS tags are also represented. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Results on cross-lingual image description 
retrieval. NN-based models are above the dashed 
line. Best overall results are in bold. Best results 
with non-deep models are underlined. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 : we present fine-grained results over different POS classes for EN and DE, and compare them to the results from</head><label>3</label><figDesc></figDesc><table>English-German 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Results on EN and DE SimLex-999 (POS-based evaluation). All scores are Spearman's rank 
correlations. INIT EMB refers to initial pre-trained monolingual word embeddings (see  §6). 

EN-DE WIW EN-IT WIW EN-RU WIW 

Model 
EN 
DE 
EN 
IT 
EN 
RU 

DPCCA (A) 0.398 0.400 0.412 0.429 0.404 0.407 
DPCCA (B) 0.405 0.400 0.413 0.427 0.413 0.402 
PCCA 
0.374 0.301 0.370 0.386 0.374 0.374 

DCCA NOI 0.390 0.398 0.413 0.422 0.407 0.398 
GCCA 
0.395 0.386 0.414 0.407 0.412 0.396 

INIT EMB 0.321 0.278 0.321 0.361 0.321 0.385 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Results (Spearman rank correlation) of our 
models and the strongest baselines on Multilingual 
SimLex-999 (all data). 

a selection of strongest baselines. Further, </table></figure>

			<note place="foot" n="1"> Our code and data are available at: https://github. com/rotmanguy/DPCCA.</note>

			<note place="foot" n="2"> For notational simplicity, we assume f (X) and g(Y ) to have zero-means, otherwise it is possible to centralize them at the final layer of each network to the same effect. 3 The CCA model can be seen as a special (linear) case of the more general DCCA model. The basic CCA objective can be recovered from the DCCA objective by simply setting D x = Dx, D y = Dy and f (X) = idX , g(Y ) = idY ; id is the identity mapping.</note>

			<note place="foot" n="7"> Note that the matrices of coefficients A , B ∈ R L×L. 8 Setting ρ to a high value indicates slow updates of the estimator; setting it low mostly erases the overall estimation and relies more on the current minibatch estimation.</note>

			<note place="foot" n="9"> https://github.com/douwekiela/mmfeat. 10 Offensive words and images are manually cleaned. 11 POS tag information is taken from the NLTK toolkit for the English words.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>IV is supported by the ERC Consolidator Grant LEXICAL: Lexical Acquisition Across Languages (no 648909). GR and RR are supported by the Infomedia Magnet Grant and by an AOL grant on "connected experience technologies".</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deep canonical correlation analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Galen</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raman</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Bilmes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Livescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1247" to="1255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">VQA: Visual question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislaw</forename><surname>Antol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aishwarya</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiasen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><forename type="middle">C</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2425" to="2433" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Multi-view CCA-based acoustic features for phonetic recognition across speakers and domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raman</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Livescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="7135" to="7139" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The WaCky Wide Web: A collection of very large linguistically processed web-crawled corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvia</forename><surname>Bernardini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriano</forename><surname>Ferraresi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eros</forename><surname>Zanchetta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language Resources and Evaluation</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="209" to="226" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Grounding cognition: The role of perception and action in memory, language, and thought</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katja</forename><surname>Barsalou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wiemer-Hastings</surname></persName>
		</author>
		<editor>D. Pecher and R. Zwaan</editor>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="129" to="163" />
		</imprint>
	</monogr>
	<note>Situating abstract concepts</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning bilingual lexicons using the visual similarity of labeled web images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shane</forename><surname>Bergsma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI</title>
		<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1764" to="1769" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Multimodal distributional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elia</forename><surname>Bruni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nam</forename><forename type="middle">Khanh</forename><surname>Tram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="1" to="47" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A limited memory algorithm for bound constrained optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peihuang</forename><surname>Byrd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jorge</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ciyou</forename><surname>Nocedal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Scientific Computing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1190" to="1208" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Incorporating global visual features into attention-based neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iacer</forename><surname>Calixto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="992" to="1003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Multilingual multi-modal embeddings for natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iacer</forename><surname>Calixto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Campbell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.01101</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Correlational neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarath</forename><surname>Chandar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mitesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Khapra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaraman</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ravindran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="257" to="285" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobin</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<title level="m">Deep multi-view learn</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Chrupała</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akos</forename><surname>Kádár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Afra</forename><surname>Alishahi</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning language through pictures</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<biblScope unit="page" from="112" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Desmond</forename><surname>Elliott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stella</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eva</forename><surname>Hasler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1510.04709</idno>
		<title level="m">Multilingual image description with neural sequence models</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Multi30K: Multilingual EnglishGerman image descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Desmond</forename><surname>Elliott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stella</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khalil</forename><surname>Sima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th Workshop on Vision and Language</title>
		<meeting>the 5th Workshop on Vision and Language</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="70" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Every picture tells a story: Generating sentences from images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohsen</forename><surname>Hejrati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><forename type="middle">Amin</forename><surname>Sadeghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cyrus</forename><surname>Rashtchian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hockenmaier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Forsyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="15" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Improving vector space word representations using multilingual correlation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EACL</title>
		<meeting>EACL</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="462" to="471" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Visual information in semantic representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yansong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Multimodal compact bilinear pooling for visual question answering and visual grounding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akira</forename><surname>Fukui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><forename type="middle">Huk</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daylen</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="457" to="468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Imagemediated learning for zero-shot cross-lingual document retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruka</forename><surname>Funaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hideki</forename><surname>Nakayama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="585" to="590" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Unsupervised visual sense disambiguation for verbs using multimodal embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spandana</forename><surname>Gella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Keller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="182" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Image pivoting for learning multilingual multimodal representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spandana</forename><surname>Gella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2839" to="2845" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">If sentences could see: Investigating visual information for semantic textual similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Goran</forename><surname>Glavaš</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vuli´cvuli´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><forename type="middle">Paolo</forename><surname>Ponzetto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IWCS</title>
		<meeting>IWCS</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The symbol grounding problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stevan</forename><surname>Harnad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physica D: Nonlinear Phenomena</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="1" to="3" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Limitations of cross-lingual learning from image search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mareike</forename><surname>Hartmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
		<idno>abs/1709.05914</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Multi-modal models for concrete and abstract concept meaning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the ACL</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="285" to="296" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Simlex-999: Evaluating semantic models with (genuine) similarity estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="665" to="695" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Multimodal pivots for image caption translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Hitschler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shigehiko</forename><surname>Schamoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Riezler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2399" to="2409" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Closed-form solution of absolute orientation using orthonormal matrices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">P</forename><surname>Berthold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugh</forename><forename type="middle">M</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shahriar</forename><surname>Hilden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Negahdaripour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Optical Society of America</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1127" to="1135" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Generalized canonical correlations and their applications to experimental data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Horst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Clinical Psychology</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="331" to="347" />
			<date type="published" when="1961" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Relations between two sets of variates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harold</forename><surname>Hotelling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3/4</biblScope>
			<biblScope unit="page" from="321" to="377" />
			<date type="published" when="1936" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Attention-based multimodal neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Po-Yao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederick</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sz-Rung</forename><surname>Shiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WMT</title>
		<meeting>WMT</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="639" to="645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Optimal whitening and decorrelation. The American Statistician</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agnan</forename><surname>Kessy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Lewin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Korbinian</forename><surname>Strimmer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">MMFeat: A toolkit for extracting multi-modal features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL System Demonstrations</title>
		<meeting>ACL System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning image embeddings using convolutional neural networks for improved multi-modal semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="36" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Improving multi-modal representations using image dispersion: Why less is sometimes more</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="835" to="841" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Comparing data sources and architectures for deep visual representation learning in semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anita</forename><forename type="middle">Lilla</forename><surname>Ver˝ O</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="447" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Visual bilingual lexicon induction with transferred ConvNet features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vuli´cvuli´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="148" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR (Conference Track)</title>
		<meeting>ICLR (Conference Track)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Multimodal neural language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="595" to="603" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Philosophy in the flesh: The embodied mind and its challenge to Western thought</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Lakoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Combining language and vision with a multimodal skip-gram model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angeliki</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nghia The</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="153" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Judgment language matters: Multilingual vector space models for judgment language aware lexical semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ira</forename><surname>Leviant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<idno>abs/1508.00106</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Improving distributional similarity with lessons learned from word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the ACL</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="211" to="225" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">ORANGE: A method for evaluating automatic evaluation metrics for machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz Josef</forename><surname>Och</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING</title>
		<meeting>COLING</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="501" to="507" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Symbol interdependency in symbolic and embodied cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><forename type="middle">M</forename><surname>Louwerse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Topics in Cognitive Science</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="617" to="645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Deep multilingual correlation for improved word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ang</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiran</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Livescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="250" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Deep captioning with multimodal recurrent neural networks (mRNN)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junhua</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR (Conference Track)</title>
		<meeting>ICLR (Conference Track)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junhua</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1410.1090</idno>
		<title level="m">Explain images with multimodal recurrent neural networks</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Nonparametric canonical correlation analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomer</forename><surname>Michaeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiran</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Livescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1967" to="1976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR (Conference Track)</title>
		<meeting>ICLR (Conference Track)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Semantic specialization of distributional word vector spaces using monolingual and cross-lingual constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Mrkši´mrkši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vuli´cvuli´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diarmuid´odiarmuid´</forename><forename type="middle">Diarmuid´o</forename><surname>Séaghdha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ira</forename><surname>Leviant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Gaši´gaši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the ACL</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="309" to="324" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Probabilistic partial canonical correlation analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuke</forename><surname>Mukuta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Harada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1449" to="1457" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Zeroresource machine translation by multimodal encoder-decoder network with multimedia pivot. Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hideki</forename><surname>Nakayama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noriki</forename><surname>Nishida</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="49" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Bridge correlational neural networks for multilingual multimodal representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janarthanan</forename><surname>Rajendran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mitesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarath</forename><surname>Khapra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaraman</forename><surname>Chandar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ravindran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="171" to="181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Partial canonical correlations. Trabajos de estadistica y de investigación operativa</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">Raja</forename><surname>Rao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1969" />
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="211" to="219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Multiview LSA: Representation learning via generalized CCA</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushpendre</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raman</forename><surname>Arora</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACLHLT</title>
		<meeting>NAACLHLT</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="556" to="566" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR (Workshop Track)</title>
		<meeting>ICLR (Workshop Track)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Show and tell: A neural image caption generator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3156" to="3164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Multi-modal representations for improved bilingual lexicon learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vuli´cvuli´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mariefrancine</forename><surname>Moens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="188" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Automatic selection of context configurations for improved class-specific word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vuli´cvuli´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Rappoport</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL</title>
		<meeting>CoNLL</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="112" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">On deep multi-view representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiran</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raman</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Livescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Bilmes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1083" to="1092" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Stochastic optimization for deep CCA via nonlinear orthogonal iterations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiran</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raman</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Livescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Srebro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Communication, Control, and Computing</title>
		<meeting>Communication, Control, and Computing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="688" to="695" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Ask, attend and answer: Exploring question-guided spatial attention for visual question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huijuan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="451" to="466" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Show, attend and tell: Neural image caption generation with visual attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhudinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2048" to="2057" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Deep correlation for matching images and text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krystian</forename><surname>Mikolajczyk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3441" to="3450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alice</forename><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the ACL</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="67" to="78" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Micah Hodosh, and Julia Hockenmaier</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
