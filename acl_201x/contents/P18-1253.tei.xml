<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:13+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Object-oriented Neural Programming (OONP) for Document Understanding</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 15-20, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianggen</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Biomedical Engineering</orgName>
								<orgName type="department" key="dep2">School of Medicine</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Beijing Innovation Center for Future Chip</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Laboratory for Brain and Intelligence</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haotian</forename><surname>Cui</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Biomedical Engineering</orgName>
								<orgName type="department" key="dep2">School of Medicine</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Beijing Innovation Center for Future Chip</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Laboratory for Brain and Intelligence</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ai</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Yan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Biomedical Engineering</orgName>
								<orgName type="department" key="dep2">School of Medicine</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Beijing Innovation Center for Future Chip</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Laboratory for Brain and Intelligence</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daqi</forename><surname>Zheng</surname></persName>
						</author>
						<title level="a" type="main">Object-oriented Neural Programming (OONP) for Document Understanding</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2717" to="2726"/>
							<date type="published">July 15-20, 2018. 2018</date>
						</imprint>
					</monogr>
					<note>2717</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We propose Object-oriented Neural Programming (OONP), a framework for semantically parsing documents in specific domains. Basically, OONP reads a document and parses it into a predesigned object-oriented data structure that reflects the domain-specific semantics of the document. An OONP parser models semantic parsing as a decision process: a neural net-based Reader sequentially goes through the document, and builds and updates an intermediate ontology during the process to summarize its partial understanding of the text. OONP supports a big variety of forms (both symbolic and differentiable) for representing the state and the document , and a rich family of operations to compose the representation. An OONP parser can be trained with supervision of different forms and strength, including supervised learning (SL) , reinforcement learning (RL) and hybrid of the two. Our experiments on both synthetic and real-world document parsing tasks have shown that OONP can learn to handle fairly complicated ontology with training data of modest sizes.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Mapping a document into a structured "machine readable" form is a canonical and probably the most effective way for document understanding. There are quite some recent efforts on designing neural net-based learning machines for this pur- pose, which can be roughly categorized into two groups: 1) sequence-to-sequence model with the * The work was done when these authors worked as in- terns at DeeplyCurious.ai. neural net as the black box ( <ref type="bibr" target="#b11">Liang et al., 2017)</ref>, and 2) neural net as a component in a pre-designed sta- tistical model ( <ref type="bibr" target="#b19">Zeng et al., 2014</ref>). Both categories are hindered in tackling document with compli- cated structures, by either the lack of effective rep- resentation of knowledge or the flexibility in fus- ing them in the model.</p><p>Towards solving this problem, we proposed Object-oriented Neural Programming (OONP), a framework for semantically parsing in-domain documents (illustrated in <ref type="figure" target="#fig_0">Figure 1</ref>). OONP main- tains an object-oriented data structure, where ob- jects from different classes are to represent entities (people, events, items etc) which are connected through links with varying types. Each object en- capsulates internal properties (both symbolic and differentiable), allowing both neural and symbolic reasoning over complex structures and hence mak- ing it possible to represent rich semantics of docu- ments. An OONP parser is neural net-based, but it has sophisticated architecture and mechanism designed for taking and yielding discrete struc- tures, hence nicely combining symbolism (for in- terpretability and formal reasoning) and connec- tionism (for flexibility and learnability).</p><p>For parsing, OONP reads a document and parses it into this object-oriented data structure through a series of discrete actions along reading the doc- ument sequentially. OONP supports a rich fam-ily of operations for composing the ontology, and flexible hybrid forms for knowledge representa- tion. An OONP parser can be trained with super- vised learning (SL), reinforcement learning (RL) and hybrid of the two.</p><p>OONP in a nutshell The key properties of OONP can be summarized as follows</p><p>1. OONP models parsing as a decision process: as the "reading and comprehension" agent goes through the text it gradually forms the ontology as the representation of the text through its action; 2. OONP uses a symbolic memory with graph structure as part of the state of the parsing process. This memory will be created and updated through the sequential actions of the decision process, and will be used as the se- mantic representation of the text at the end 3. OONP can blend supervised learning (SL) and reinforcement learning (RL) in tuning its pa- rameters to suit the supervision signal in dif- ferent forms and strength.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Works</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Semantic Parsing</head><p>Semantic parsing is concerned with translating language utterances into executable logical forms and plays a key role in building conversational interfaces <ref type="bibr" target="#b10">(Jonathan and Percy, 2014</ref>). Dif- ferent from common tasks of semantic pars- ings, such as parsing the sentence to dependency structure ( <ref type="bibr" target="#b1">Buys and Blunsom, 2017)</ref> and exe- cutable commands <ref type="bibr" target="#b7">(Herzig and Berant, 2017)</ref>, OONP parses documents into a predesigned object- oriented data structure which is easily readable for both human and machine. It is related to seman- tic web <ref type="bibr" target="#b0">(Berners-Lee et al., 2001</ref>) as well as frame semantics <ref type="bibr" target="#b2">(Charles J, 1982)</ref> in the way semantics is represented, so in a sense, OONP can be viewed as a neural-symbolic implementation of semantic parsing with similar semantic representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">State Tracking</head><p>OONP is inspired by <ref type="bibr" target="#b3">Daumé III et al. (2009)</ref> on modeling parsing as a decision process, and the work on state-tracking models in dialogue system ( <ref type="bibr" target="#b6">Henderson et al., 2014</ref>) for the mix- ture of symbolic and probabilistic representa- tions of dialogue state. For modeling a docu- ment with entities, <ref type="bibr" target="#b17">Yang et al. (2017)</ref> use coref- erence links to recover entity clusters, though they only model entity mentions as containing a sin- gle word. However, entities whose names consist of multiple words are not considered. Entity Net- works ( <ref type="bibr" target="#b5">Henaff et al., 2017)</ref> and <ref type="bibr">EntityNLM (Ji et al., 2017)</ref> have addressed above problem and are the pioneers to model on tracking entities, but they have not considered the properties of the entities. In fact, explicitly modeling the entities both with their properties and contents is important to under- stand a document, especially a complex document. For example, if there are two persons named 'Av- ery', it is vital to know their genders or last names to avoid confusion. Therefore, we propose OONP to sketch objects and their relationships by build- ing a structured graph for document parsing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">OONP: Overview</head><p>An OONP parser ( illustrated in <ref type="figure" target="#fig_1">Figure 2</ref>) consists of a Reader equipped with read/write heads, Inline Memory that represents the document, and Carry-on Memory that summarizes the current understanding of the document at each time step. For each docu- ment to parse, OONP first preprocesses it and puts it into the Inline Memory, and then Reader controls the read-heads to sequentially go through the Inline Memory and at the same time update the Carry-on Memory. We will give a more detailed description of the major components below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Memory</head><p>we have two types of memory, Carry-on Memory and Inline Memory. Carry-on Memory is designed to save the state in the decision process and summa- rize current understanding of the document based on the text that has been "read", while Inline Mem- ory is designed to save location-specific informa- tion about the document. In a sense, the informa- tion in Inline Memory is low-level and unstructured, waiting for Reader to fuse and integrate into more structured representation. Carry-on Memory has three compartments:</p><p>• Object Memory: denoted M obj , the object- oriented data structure constructed during the parsing process;</p><p>• Matrix Memory: denoted M mat , a matrix- type memory with fixed size, for differen- tiable read/write by the controlling neural net ( <ref type="bibr" target="#b4">Graves et al., 2014</ref>). In the simplest case, it could be just a vector as the hidden state of conventional RNN;</p><p>• Action History: symbolic memory to save the entire history of actions made during the parsing process.</p><p>Intuitively, Object Memory stores the extracted knowledge of the document with defined structure and strong evidence, while Matrix Memory keeps the knowledge that is fuzzy, uncertain or incomplete, waiting for further information to confirm, com- plete or clarify.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Object Memory</head><p>Object Memory stores an object-oriented represen- tation of document, as illustrated in <ref type="figure" target="#fig_2">Figure 3</ref>. Each object is an instance of a particular class * , which specifies the innate structure of the object, includ- ing internal properties, operations, and how this object can be connected with others. The inter- nal properties can be of different types, for exam- ple string or category, which usually correspond to different actions in specifying them: the string- type property is usually "copied" from the original text in Inline Memory, while the category properties need to be rendered by a classifier. The links are in general directional and typed, resembling a spe- cial property viewing from the "source object". In <ref type="figure" target="#fig_2">Figure 3</ref>, there are six "linked" objects of three classes (namely, PERSON, EVENT, and ITEM) . Taking ITEM-object I02 for example, it has five internal properties (Type, Model, Color, Value, Status), and is linked with two EVENT-objects through stolen and disposed link respectively. In addition to the symbolic properties and links, each object had also its object-embedding as the distributed interface with Reader. For description simplicity, we will refer to the symbolic part of this hybrid representation of objects as the Ontol- ogy, with some slight abuse of this word. Object- embedding is complementary to the symbolic part of the object, recording all the relevant informa- tion associated with it but not represented in the Ontology, e.g., the contextual information when the object is created. Both Ontology and the object embeddings will be updated in time by the class- dependent operations driven by the actions issued by the Policy-net in Reader.</p><p>According to the way the Ontology evolves with time, the parsing task can be roughly classified into two categories: 1) Stationary: there is a fi- nal ground truth that does not change with time, and 2) Dynamical: the truth changes with time. For stationary Ontology, see Section 5.2 and 5.3 for example, and for dynamical Ontology, please see Section 5.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Inline Memory</head><p>Inline Memory stores the relatively raw represen- tation of the document with the sequential struc- ture. Basically, Inline Memory is an array of mem- ory cells, each corresponding to a pre-defined lan- guage unit (e.g., word) in the same order as they are in the original text. Each cell can have dis- tributed part and symbolic part, designed to save the result of preprocessing of text, e.g., plain word embedding, hidden states of RNN, or some sym- bolic processing.</p><p>Inline Memory provides a way to represent locally encoded "low level" knowledge of the text, which will be read, evaluated and combined with the global semantic representation in Carry-on Memory by Reader. One particular advantage of this setting is that it allows us to incorporate the local deci- sions of some other models, including "higher or- der" ones like local relations across multiple lan- guage units, as illustrated in <ref type="figure" target="#fig_3">Figure 4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Reader</head><p>Reader is the control center of OONP, coordinating and managing all the operations of OONP. More   <ref type="bibr" target="#b4">Graves et al., 2014</ref>), NNC is equipped with multiple read-heads and write-heads for differentiable read/write over Ma- trix Memory and (the distributed part of) Inline Mem- ory, with a variety of addressing strategies ( <ref type="bibr" target="#b4">Graves et al., 2014</ref>). Policy-net however issues discrete outputs (i.e., actions), which gradually builds and updates the Object Memory in time. The symbolic processors are designed to handle information in symbolic form from Object Memory, Inline Memory, Action History, and Policy-net, while that from Inline Memory and Action History is eventually generated by Policy-net. In Appendix.A † , we give a particular implementation of Reader with more details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">OONP: Actions</head><p>The actions issued by Policy-net can be generally categorized as the following</p><p>• New-Assign : determine whether to create an new object for the information at hand or as- sign it to a certain existed object; • Update.X : determine which internal prop- erty or link of the selected object to update; • Update2what : determine the content of the updating, which could be about string, cate- gory or links;</p><p>The typical order of actions is New-Assign → Update.X → Update2what, but it is common to have New-Assign action followed by nothing, when, for example, an object is mentioned but no † The appendix is also available at https://arxiv.org/abs/1709.08853 substantial information is provided. As shown in <ref type="figure" target="#fig_5">Figure 6</ref>, we give an example of the entire episode of OONP parsing on the short text given in <ref type="figure" target="#fig_0">Fig- ure 1</ref>, to show that a sequence of actions gradu- ally forms the complete representation of the doc- ument.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">An examples of actions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">New-Assign</head><p>With any information at hand (denoted as S t ) at time t, the choices of New-Assign include the following three categories of actions: 1) creating (New) an object of a certain type, 2) assigning S t to an existed object, and 3) doing nothing for S t and moving on. For Policy-net, the stochastic pol- icy is to determine the following probabilities:</p><formula xml:id="formula_0">prob(c, new|St), c = 1, 2, · · · , |C| prob(c, k|St), for O c,k t ∈ M t obj prob(none|St)</formula><p>where |C| stands for the number of classes, O c,k t stands for the k th object of class c at time t. Deter- mining whether to new an object always relies on the following two signals</p><p>1. The information at hand cannot be contained by any existed objects;</p><p>2. Linguistic hints that suggest whether a new object is introduced.</p><p>Based on those intuitions, we take a score-based approach to determine the above-mentioned prob- ability. More specifically, for a given S t , Reader forms a "temporary" object with its own struc- ture (denotedˆOdenotedˆ denotedˆO t ) with both symbolic and dis- tributed sections. We also have a virtual object for the New action for each class c, denoted O c,new t , which is typically a time-dependent vector formed by Reader based on information in Matrix Memory. For a givenˆOgivenˆ givenˆO t , we can then define the following |C| + |M t obj | + 1 types of score functions:</p><formula xml:id="formula_1">New: score (c) new (O c,new t , ˆ Ot; θ (c) new ), c = 1, 2, · · · , |C| Assign: score (c) assign (O c,k t , ˆ Ot; θ (c) assign ), for O c,k t ∈ M t obj</formula><p>Do nothing: scorenone( ˆ Ot; θnone).</p><p>to measure the level of matching between the in- formation at hand and existed objects, as well as the likeliness for creating an object or doing noth- ing. This process is pictorially illustrated in <ref type="figure" target="#fig_6">Fig- ure 7</ref>. We therefore can define the following prob- ability for the stochastic policy </p><formula xml:id="formula_2">new (O c,new t , ˆ O t ;θ (c) new ) Z(t)<label>(1)</label></formula><formula xml:id="formula_3">prob(c, k|St) = e score (c) assign (O c,k t , ˆ O t ;θ (c) assign ) Z(t)<label>(2)</label></formula><formula xml:id="formula_4">prob(none|St) = e scorenone( ˆ O t ;θnone) Z(t)<label>(3)</label></formula><p>where</p><formula xml:id="formula_5">Z(t) = c ∈C e score (c ) new (O c ,new t , ˆ O t ;θ (c ) new ) + (c ,k )∈idx(M t obj ) e score (c ) assign (O c ,k t , ˆ O t ;θ (c ) assign ) + e scorenone( ˆ O t ;θnone)</formula><p>is the normalizing factor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Updating Objects</head><p>In Update.X step, Policy-net needs to choose the property or external link (or none) to update for the selected object determined by New-Assign step. If Update.X chooses to update an external link, Policy-net needs to further determine which object it links to. After that, Update2what updates the chosen property or links. In task with static On- tology, most internal properties and links will be "locked" after they are updated for the first time, with some exception on a few semi-structured properties (e.g., the Description property in the experiment in Section 7.2). For dynamical Ontol- ogy, on the contrary, some properties and links are always subject to changes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Learning</head><p>The parameters of OONP models (denoted Θ) in- clude that for all operations and that for compos- ing the distributed sections in Inline Memory. They can be trained with supervised learning (SL) , re- inforcement learning (RL), and a hybrid of the two in different ways. With pure SL, the oracle gives the ground truth about the "right action" at each time step during the entire decision process, with which the parameter can be tuned to maximize the likelihood of the truth, with the following objec- tive function</p><formula xml:id="formula_6">J SL (Θ) = − 1 N N i T i t=1 log(π (i) t [a t ])<label>(4)</label></formula><p>where N stands for the number of instances, T i stands for the number of steps in decision process for the i th instance, π</p><formula xml:id="formula_7">(i) t [·]</formula><p>stands for the probabil- ities of the actions at t from the stochastic policy, and a t stands for the ground truth action in step t. With RL, the supervision is given as rewards during the decision process, for which an extreme case is to give the final reward at the end of the decision process by comparing the generated On- tology and the ground truth, e.g.,</p><formula xml:id="formula_8">r (i) t = 0, if t = Ti match(M T i obj , Gi), if t = Ti<label>(5)</label></formula><p>where the match(M T i obj , Gi) measures the consistency between the Ontology of in the Object Memory M T i obj and the ground truth G . We can use policy search algorithm to maximize the expected total reward, e.g. the commonly used REINFORCE <ref type="bibr" target="#b15">(Williams, 1992)</ref> for training, with the gradient</p><formula xml:id="formula_9">ΘJ RL (Θ) = −Eπ θ Θ log πΘ a i t |s i t r (i) t:T<label>(6)</label></formula><formula xml:id="formula_10">≈ − 1 N Ti N i T t=1 Θ log πΘ a i t |s i t r (i) t:T i .<label>(7)</label></formula><p>When OONP is applied to real-world tasks, there is often quite natural supervision signals for both SL and RL. More specifically, for static Ontology one can infer some actions from the final ontology based on some basic assumption, e.g.,</p><p>• the system should New an object the first time it is mentioned; • the system should put an extracted string (say, that for Name ) into the right property of right object at the end of the string. For those that can not be fully inferred, say the categorical properties of an object (e.g., Type for event objects), we have to resort to RL to deter- mine the time of decision, while we also need SL to train Policy-net on the content of the decision. Fortunately it is quite straightforward to combine the two learning paradigms in optimization. More specifically, we maximize this combined objective</p><formula xml:id="formula_11">J (Θ) = J SL (Θ) + λJ RL (Θ),<label>(8)</label></formula><p>where J SL and J RL are over the parameters within their own supervision mode and λ coordinates the weight of the two learning mode on the parameters they share. Equation <ref type="formula" target="#formula_11">(8)</ref> actually indicates a deep coupling of supervised learning and reinforcement learning, since for any episode the samples of ac- tions related to RL might affect the inputs to the models under supervised learning. For dynamical Ontology (see Section 7.1 for ex- ample), it is impossible to derive most of the de- cisions from the final Ontology since they may change over time. For those we have to rely mostly on the supervision at the time step to train the action (supervised mode) or count on OONP to learn the dynamics of the ontology evolution by fitting the final ground truth. Both scenarios are discussed in Section 7.1 on a synthetic task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Experiments</head><p>We applied OONP on three document parsing tasks, to verify its efficacy on parsing documents with different characteristics and investigate dif- ferent components of OONP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Task-I: bAbI Task</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data and Task</head><p>We implemented OONP on enriched version of bAbI tasks (Johnson, 2017) with intermediate rep- resentation for history of arbitrary length. In this experiment, we considered only the original bAbi task-2 ( <ref type="bibr" target="#b14">Weston et al., 2015)</ref>, with an instance shown in the left panel <ref type="figure" target="#fig_7">Figure 8</ref>. The ontology has three types of objects: PERSON-object, ITEM- object, and LOCATION-object, and three types of links specifying relations between them (see <ref type="figure" target="#fig_7">Fig- ure 8</ref> for an illustration). All three types of objects have Name as the only internal property.</p><p>The task for OONP is to read an episode of story and recover the trajectory of the evolving ontol- ogy. We choose bAbI for its dynamical ontol- ogy that evolves with time and ground truth given for each snapshot. Comparing with the real-world tasks we will present later, bAbi has almost trivial internal properties but relatively rich opportunities for links, considering that any two objects of dif- ferent types could potentially have a link.  <ref type="table">Table 1</ref>: Actions for bAbI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implementation Details</head><p>For preprocessing, we have a trivial NER to find the names of people, items and locations (saved in the symbolic part of Inline Memory) and word- level bi-directional GRU for the distributed rep- resentations of Inline Memory. In the parsing pro- cess, Reader goes through the inline word-by- word in the temporal order of the original text, makes New-Assign action at every word, leaving Update.X and Update2what actions to the time steps when the read-head on Inline Memory reaches a punctuation (see more details of actions in Ta- ble 1). For this simple task, we use an almost fully neural Reader (with MLPs for Policy-net) and a vector for Matrix Memory, with however a Sym- bolic Reasoner to maintain the logical consistency after updating the relations with the actions (see Appendx.B for more details).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and Analysis</head><p>For training, we use 1,000 episodes with length evenly distributed from one to six. We use just REINFORCE with only the final reward defined as the overlap between the generated ontology and the ground truth, while step-by-step supervision on actions yields almost perfect result (result omit- ted). For evaluation, we use the F1 ( <ref type="bibr" target="#b13">Rijsbergen, 1979)</ref> between the generated links and the ground truth averaged over all snapshots of all test in- stances, since the links are sparse compared with all the possible pairwise relations between objects, with which we get F1= 94.80% without Symbolic Reasoner and F1= 95.30% with it.</p><p>Clearly OONP can learn fairly well on recover- ing the evolving ontology with such a small train- ing set and weak supervision (RL with the final reward), showing that the credit assignment over to earlier snapshots does not cause much difficulty in the learning of OONP even with a generic pol- icy search algorithm. It is not so surprising to ob- serve that Symbolic Reasoner helps to improve the results on discovering the links, while it does not improve the performance on identifying the ob- jects although it is taken within the learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Task-II: Parsing Police Report</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data &amp; Task</head><p>We implement OONP for parsing Chinese police report (brief description of criminal cases written by policeman), as illustrated in the left panel of <ref type="figure" target="#fig_8">Figure 9</ref>. We consider a corpus of 5,500 cases with a variety of crime categories, including theft, robbery, drug dealing and others. Although the language is reasonably formal, the corpus cov- ers a big variety of topics and language styles, and has a high proportion of typos. The ontol- ogy we designed for this task mainly consists of a number of PERSON-objects and ITEM-objects connected through an EVENT-object with several types of relations, as illustrated in the right panel of <ref type="figure" target="#fig_8">Figure 9</ref>. A PERSON-object has three inter- nal properties: Name (string), Gender (categori- cal) and Age (number), and two types of exter- nal links (suspect and victim) to an EVENT- object. An ITEM-object has three internal prop- erties: Name (string), Quantity (string) and Value (string), and six types of external links (stolen, drug, robbed, swindled, damaged, and other) to an EVENT-object. On average, a sample has 95.24 Chinese words and the ontology has 3.35 objects, 3.47 mentions and 5.02 relationships. Compared with bAbI in Section 7.1, the police report ontol- ogy has less pairwise links but much richer inter- nal properties for objects of all three objects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implementation Details</head><p>The OONP model is to generate the ontology as il- lustrated in <ref type="figure" target="#fig_8">Figure 9</ref> through a decision process with actions in <ref type="table">Table 2</ref>. As pre-processing, we performed third party NER algorithm to find peo-ple names, locations, item etc. For the distributed part of Inline Memory, we used dilated CNN with different choices of depth and kernel size ( <ref type="bibr" target="#b18">Yu and Koltun, 2016</ref>), all of which will be jointly learned during training. In updating objects with its string- type properties (e.g., Name for a PERSON-object ), we use Copy-Paste strategy for extracted string (whose NER tag already specifies which property in an object it goes to) as Reader sees it. For un- determined category properties in existed objects, Policy-net will determine the object to update (a New-Assign action without New option), its prop- erty to update (an Update.X action), and the up- dating operation (an Update2what action) at mile- stones of the decision process , e.g., when reaching an punctuation. For this task, since all the relations are between the single by-default EVENT-object and other objects, the relations can be reduced to category-type properties of the corresponding ob- jects in practice. For category-type properties, we cannot recover New-Assign and Update.X actions from the label (the final ontology), so we resort RL for learning to determine that part, which is mixed with the supervised learning for Update2what and other actions for string-type properties.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Action Description</head><p>NewObject(c) New an object of class-c. AssignObject(c, k)</p><p>Assign the current information to existed object (c, k) UpdateObject(c, k).Name Set the name of object-(c, k) with the extracted string. UpdateObject(PE R S O N, k).Gender</p><p>Set the name of a PERSON-object indexed k with the extracted string. UpdateObject(IT E M, k).Quantity Set the quantity of an ITEM-object indexed k with the extracted string. UpdateObject(IT E M, k).Value Set the value of an ITEM-object indexed k with the extracted string. UpdateObject(EV E N T, 1).Items.x</p><p>Set the link between the EVENT-object and an ITEM-object, where x ∈{stolen, drug, robbed, swindled, damaged, other} UpdateObject(EV E N T, 1).Persons.x Set the link between the EVENT-object and an PERSON-object, and x ∈{victim, suspect} <ref type="table">Table 2</ref>: Actions for parsing police report.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results &amp; Discussion</head><p>We use 4,250 cases for training, 750 for validation an held-out 750 for test. We consider the follow- ing four metrics in comparing the performance of different models:</p><p>Assignment Accuracy the accuracy on New-Assign actions made by the model Category Accuracy the accuracy of predicting the category properties of all the objects Ontology Accuracy the proportion of instances for which the generated Objects is exactly the same as the ground truth Ontology Accuracy-95 the proportion of instances for which the generated Objects achieves 95% consistency with the ground truth which measures the accuracy of the model in mak- ing discrete decisions as well as generating the fi- nal ontology.  We empirically investigated two competing models, Bi-LSTM and EntityNLM , as baselines. Both models can be viewed as simplified versions of OONP. Bi-LSTM consists of a bi-directional LSTM as Inline Memory encoder and a two-layer MLP on top of that as Policy-net. Bi-LSTM does not sup- port categorical prediction for objects due to the lack of explicit object representation, which will only be trained to perform New-Assign actions and evaluated on them (with the relevant metrics modified for it). EntityNLM, on the other hand, has some modest capability for modeling entities with the original purpose of predicting entity men- tions ( <ref type="bibr" target="#b8">Ji et al., 2017</ref>) which has been adapted and re-implemented for this scenario. For OONP , we consider three variants:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>• OONP (neural): simple version of OONP with only distributed representation in Reader; • OONP (structured): OONP that considers the matching between two structured objects in New-Assign actions; • OONP (RL): another version of OONP (struc- tured) that uses RL ‡ to determine the time for predicting the category properties, while OONP (neural) and OONP (structured) use a rule-based approach to determine the time. The experimental results are given in <ref type="table" target="#tab_1">Table 3</ref>. As shown in <ref type="table" target="#tab_1">Table 3</ref>, Bi-LSTM struggles to achieve around 73% Assignment Accuracy on test set, while OONP (neural) can boost the performance to 88.5%. Arguably, this difference in performance is due to the fact that Bi-LSTM lacks Object Mem- ory, so all relevant information has to be stored in the Bi-LSTM hidden states along the reading pro- cess. When we start putting symbolic representa- tion and operation into Reader, as shown in the re- sult of OONP (structure), the performance is again significantly improved on all four metrics.</p><p>From the result of OONP (RL), RL improves not only the prediction of categorical property (and hence the overall ontology accuracy) but also tasks trained with purely SL (i.e., learning the New-Assign actions). This indicates there might be some deep entanglement between SL and RL through the obvious interaction between features in parsing and/or sharing of parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Task-III: Parsing court judgment docs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data and Task</head><p>Comparing with Task-II, court judgements are typically much longer, containing multiple events ‡ A more detailed exposition of this idea can be found in ( <ref type="bibr" target="#b12">Liu et al., 2018)</ref>, where RL is used for training a multi-label classifier of text <ref type="figure" target="#fig_0">Figure 10</ref>: Left: the judgement document with highlighted part being the description the facts of crime; right: the corresponding ontology of different types and large amount of irrelevant text. The dataset contains 4056 Chinese judge- ment documents, divided into training/dev/testing set 3256/400/400 respectively. The ontology for this task mainly consists of a number of PER- SON-objects and ITEM-objects connected through a number EVENT-object with several types of links. An EVENT-object has three internal prop- erties: Time (string), Location (string), and Type (category, ∈{theft, restitution, disposal}), four types of external links to <ref type="bibr">PERSON-objects (namely, principal, companion, buyer, victim)</ref> and four types of external links to ITEM-objects (stolen, damaged, restituted, disposed ). In addition to the external links to EVENT-objects , a PERSON-object has only the Name (string) as the internal property. An ITEM-object has three in- ternal properties: Description (array of strings), Value (string) and <ref type="bibr">Returned(binary)</ref> in addition to its external links to EVENT-objects , where Description consists of the words describing the corresponding item, which could come from mul- tiple segments across the document. An object could be linked to more than one EVENT-object, for example a person could be the principal sus- pect in event A and also a companion in event B. An illustration of the judgement document and the corresponding ontology can be found in <ref type="figure" target="#fig_0">Figure 10</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implementation Details</head><p>We use a model configuration similar to that in Section 7.2, with event-based segmentation of text given by third-party extraction algorithm ( <ref type="bibr" target="#b16">Yan et al., 2017</ref>) in Inline Memory, which enables OONP to trivially New EVENT-objectwith rules. OONP reads the Inline Memory, fills the EVENT- objects, creates and fills PERSON-objects and ITEM-objects, and specifies the links between them, with the actions summarized in <ref type="table">Table 4</ref>. When an object is created during a certain event, it will be given an extra feature (not an internal property) indicating this connection, which will be used in deciding links between this object and event object, as well as in determining the future New-Assign actions.</p><p>Action for 2nd-round Description NewObject(c)</p><p>New an object of class-c. AssignObject(c, k)</p><p>Assign the current information to existed object (c, k) UpdateObject(PE R S O N, k).Name Set the name of the k th PERSON-object with the extracted string. UpdateObject(IT E M, k).Description Add to the description of an k th ITEM-object with the extracted string. UpdateObject(IT E M, k).Value Set the value of an k th ITEM-object with the extracted string. UpdateObject(EV E N T, k).Time Set the time of an k th EVENT-object with the extracted string. UpdateObject(EV E N T, k).Location Set the location of an k th EVENT-object with the extracted string. UpdateObject(EV E N T, k).Type Set the type of the k th EVENT-object among {theft, disposal, restitution} UpdateObject(EV E N T, k).Items.x</p><p>Set the link between the k th EVENT-object and an ITEM-object, where x ∈ {stolen, damaged, restituted, disposed } UpdateObject(EV E N T, k).Persons.x</p><p>Set the link between the k th EVENT-object and an PERSON-object, and x ∈ {principal, companion, buyer, victim} <ref type="table">Table 4</ref>: Actions for parsing court judgements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and Analysis</head><p>We use the same metric as in Section 7.2, and com- pare two OONP variants, OONP (neural) and OONP (structured), with two baselines EntityNLM and Bi- LSTM.</p><p>The two baselines will be tested only on the second-round reading, while both OONP variants are tested on a two-round reading. The results are shown in  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>We proposed Object-oriented Neural Program- ming (OONP), a framework for semantically pars- ing in-domain documents. OONP is neural net- based, but equipped with sophisticated architec- ture and mechanism for document understanding, therefore nicely combining interpretability and learnability. Experiments on both synthetic and real-world datasets have shown that OONP outper- forms several strong baselines by a large margin on parsing fairly complicated ontology.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Illustration of OONP on a parsing task.</figDesc><graphic url="image-1.png" coords="1,307.28,222.54,226.77,120.47" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The overall diagram of OONP, where S stands for symbolic representation, D for distributed representation, and S+D for a hybrid of symbolic and distributed parts.</figDesc><graphic url="image-2.png" coords="2,307.28,62.81,226.76,89.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: An example of objects of three classes.</figDesc><graphic url="image-3.png" coords="3,307.28,62.81,226.78,154.89" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Inline Memory with symbolic knowledge.</figDesc><graphic url="image-4.png" coords="4,77.72,62.81,204.09,63.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The overall digram of OONP</figDesc><graphic url="image-5.png" coords="4,111.74,151.85,136.07,68.21" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: A pictorial illustration of a full episode of OONP parsing, where we assume the description of cars (highlighted with shadow) are segmented in preprocessing. prob(c, new|St) = e score (c)</figDesc><graphic url="image-7.png" coords="5,324.34,460.09,181.42,147.03" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: A pictorial illustration of what the Reader sees in determining whether to New an object and the relevant object when the read-head on Inline Memory reaches the last word in the text in Figure 2. The color of the arrow line stands for different matching functions for object classes, where the dashed lines are for the new object.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: One instance of bAbI (6-sentence episode) and the ontology of two snapshots. Action Description NewObject(c) New an object of class-c. AssignObject(c, k) Assign the current information to existed object (c, k) Update(c, k).AddLink(c , k , ) Add an link of type-from object-(c, k) to object-(c , k ) Update(c, k).DelLink(c , k , ) Delete the link of type-from object-(c, k) to object-(c , k )</figDesc><graphic url="image-8.png" coords="7,81.55,59.98,196.44,101.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Example of police report &amp; its ontology.</figDesc><graphic url="image-9.png" coords="7,307.28,59.97,218.27,96.94" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 3 : OONP on parsing police reports.</head><label>3</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 5 .</head><label>5</label><figDesc></figDesc><table>OONP parsers attain accuracy 
significantly higher than Bi-LSTM. Among, OONP 
(structure) achieves over 71% accuracy on getting 
the entire ontology right and over 77% accuracy 
on getting 95% consistency with the ground truth. 
We omitted the RL results since the model RL 
model chooses to predict the type properties same 
as the simple rules. 

Model 
Assign Acc. (%) Type Acc. (%) Ont. Acc. (%) Ont. Acc-95 (%) 
Bi-LSTM (baseline) 
84.66 ± 0.20 
-
18.20 ± 0.74 
36.88 ± 1.01 
ENTITYNLM (baseline) 
90.50 ± 0.21 
96.33 ± 0.39 
39.85 ± 0.20 
48.29 ± 1.96 
OONP (neural) 
94.50 ± 0.24 
97.73 ± 0.12 
53.29 ± 0.26 
72.22 ± 1.01 
OONP (structured) 
96.90 ± 0.22 
98.80 ± 0.08 
71.11 ± 0.54 
77.27 ± 1.05 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 5 : OONP on judgement documents.</head><label>5</label><figDesc></figDesc><table></table></figure>

			<note place="foot">* We only consider flat structure of classes, but it is possible to have a hierarchy of classes with different levels of abstractness, and to allow an object to go from abstract class to its child during parsing with more information obtained.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Fandong Meng and Hao Xiong for their insightful discussion. We also thank Classic Law Institute for providing the raw data.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The semantic web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Berners-Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hendler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ora</forename><surname>Lassila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific American</title>
		<imprint>
			<biblScope unit="volume">284</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="34" to="43" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Robust incremental neural semantic graph parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Buys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics(ACL)</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics(ACL)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1215" to="1226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Frame semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fillmore</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Linguistics in the Morning Calm</title>
		<imprint>
			<date type="published" when="1982" />
			<biblScope unit="page" from="111" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Search-based structured prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Langford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning Journal</title>
		<imprint>
			<date type="published" when="2009" />
			<publisher>MLJ</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Neural turing machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Wayne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivo</forename><surname>Danihelka</surname></persName>
		</author>
		<idno>CoRR abs/1410.5401</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Tracking the world state with recurrent entity networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikael</forename><surname>Henaff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Word-based dialog state tracking with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blaise</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL)</title>
		<meeting>the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="292" to="299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Neural semantic parsing over multiple knowledge-bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics(ACL)</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics(ACL)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="623" to="628" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Dynamic entity representations in neural language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenhao</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Martschat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing(EMNLP)</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing(EMNLP)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1830" to="1839" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning graphical state transitions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the International Conference on Learning Representations(ICLR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Semantic parsing via paraphrasing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Berant</forename><surname>Jonathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Percy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Neural symbolic machines: Learning semantic parsers on freebase with weak supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ni</forename><surname>Kenneth D Forbus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics(ACL)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Jumper: Learning when to make classification decisions in reading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianggen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lili</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haotian</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sen</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Van Rijsbergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Retrieval. Butterworth-Heinemann</title>
		<imprint>
			<date type="published" when="1979" />
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Towards ai-complete question answering: A set of prerequisite toy tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<idno>CoRR abs/1502.05698</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Simple statistical gradientfollowing algorithms for connectionist reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ronald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="229" to="256" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Event identification as a decision process with non-linear representation of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daqi</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sen</forename><surname>Song</surname></persName>
		</author>
		<idno>CoRR abs/1710.00969</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Reference-aware language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zichao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Ling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing(EMNLP)</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing(EMNLP)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1850" to="1859" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Multi-scale context aggregation by dilated convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Relation classification via convolutional deep neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daojian</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siwei</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangyou</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING</title>
		<meeting>COLING</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
