<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:21+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Claim Synthesis via Predicate Recycling</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Bilu</surname></persName>
							<email>yonatanb@il.ibm.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">IBM Haifa Research Lab Mount Carmel, Haifa</orgName>
								<orgName type="institution">IBM Haifa Research Lab Mount Carmel</orgName>
								<address>
									<postCode>31905, 31905</postCode>
									<settlement>Haifa</settlement>
									<country>Israel, Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Slonim</surname></persName>
							<email>noams@il.ibm.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">IBM Haifa Research Lab Mount Carmel, Haifa</orgName>
								<orgName type="institution">IBM Haifa Research Lab Mount Carmel</orgName>
								<address>
									<postCode>31905, 31905</postCode>
									<settlement>Haifa</settlement>
									<country>Israel, Israel</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Claim Synthesis via Predicate Recycling</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="525" to="530"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Computational Argumentation has two main goals-the detection and analysis of arguments on the one hand, and the synthesis of arguments on the other. Much attention has been given to the former, but considerably less to the latter. A key component in synthesizing arguments is the synthesis of claims. One way to do so is by employing argumentation mining to detect claims within an appropriate corpus. In general, this appears to be a hard problem. Thus, it is interesting to explore if-for the sake of synthesis-there may be other ways to generate claims. Here we explore such a method: we extract the predicate of simple, manually-detected, claims, and attempt to generate novel claims from them. Surprisingly, this simple method yields fairly good results.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>When people argue, how do they come up with the arguments they present, and can a machine emu- late this? The motivation for this work comes from this second question, for which the relevant field of study is Computational Argumentation, an emerg- ing field with roots in Computer Science, Mathe- matics, Philosophy and Rhetorics. However, while much attention is given in the field to the modeling and analysis of arguments, automatic synthesis of arguments receives considerably less.</p><p>So, how do people come up with arguments? One way is to read-up on the topic and present the arguments you find in the literature. Another -if the topic at hand is within your field of ex- pertise -is to communicate your opinion. Yet a third way is to "recycle" arguments you are famil- iar with and apply them to new domains. For ex- ample, someone who's concerned about the free speech might use an argument like "it's a viola- tion of free speech" when discussing any one of these topics: whether violent video games should be banned, whether some Internet content should be censored, or whether certain types of advertise- ment should be restricted.</p><p>Argumentation Mining (Mochales <ref type="bibr" target="#b8">Palau and Moens, 2011</ref>) is analogous to the first option: Given a corpus, it aims to detect arguments therein (and the relations among them). Thus, it can be used to suggest claims when a relevant corpus is available. The second option is analogous to Natu- ral Language Generation (NLG; <ref type="bibr" target="#b9">(Reiter and Dale, 2000)</ref>), where applications such as recommender systems synthesize arguments to explain their rec- ommendations, as done for example in <ref type="bibr">(Carenini and Moore, 2006</ref>) .</p><p>These approaches yield good results when ap- plied to specific domains. In an NLG applica- tion, there is commonly a specific knowledge base which the system communicates. The form and content of arguments are derived and determined by it and are thus limited to the knowledge therein. Similarly, argument mining works well when an argument-rich and topic-related corpus is available -e.g. ( <ref type="bibr" target="#b14">Wyner et al., 2010</ref>) -but in general seems to be hard ( <ref type="bibr" target="#b4">Levy et al., 2014</ref>). Thus, it is interest- ing and challenging to synthesize arguments in an open domain. To the best of our knowledge, this is the first work that directly attempts to address this task.</p><p>Modeling of arguments goes back to the an- cient Greeks and Aristotle, and more modern work starting perhaps most famously with the Toulmin argument model <ref type="bibr" target="#b11">(Toulmin, 1958)</ref>. A common el- ement in all such models is the claim (or conclu- sion) being forwarded by the argument. Thus, a natural first step in synthesizing arguments in a general setting is being able to synthesize claims in such a setting.</p><p>We suggest here a simple way for doing so, based on the aforementioned notion of argument "recycling". Specifically, that the predicate of a claim -what it says on the topic at hand -may be applicable to other topics as well. For exam- ple, if we are familiar with the claim "banning vi- olent video games is a violation of free speech" in the context of the topic "banning violent video games", we could synthesize the claim "Internet censorship is a violation of free speech" when pre- sented with the topic "Internet Censorship". The challenge is then to determine whether the synthe- sized claim is actually coherent and relevant to the new topic, which we do using statistical Machine Learning techniques, as described in Section 2.1. This two-stages framework -generating text and then selecting whether or not it is appropriate - is reminiscent of Statistical NLG (SNLG; <ref type="bibr">(Langklide and Knight, 1998)</ref>). In an SNLG system, af- ter the macro-planning and micro-planning stages (see <ref type="bibr" target="#b9">(Reiter and Dale, 2000)</ref>) are executed, and the message to be communicated is determined, mul- tiple candidate realizations are produced, and then statistical methods are used to determine which of these realizations is the best (based on a reference corpus).</p><p>Our work differs from SNLG in that there are no pre-determined messages. The generation stage produces candidate content. Each candidate claim is a different message, and the selection stage at- tempts to identify those which are coherent and relevant, rather than best realized. In other words, while the classical NLG paradigm is to first se- lect the content and then realize it in a natural lan- guage, here our building blocks from the onset are natural language elements, and statistical methods are used to determine which content selections - implied by combining them -are valid.</p><p>Finally, the notion that predicates of claims re- garding one topic may be applicable to another is reminiscent of the motivation for the work of <ref type="bibr">(Card et al., 2015)</ref>, who observe that there are commonalities (so called "framing dimensions") among the way different topics are framed in news articles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Algorithm</head><p>The claim synthesis algorithm is composed of three components. The first is a pre-processing component, in which the Predicate Lexicon is con- structed. The second is the Generation Compo- nent -the input to this component is a topic (and the Predicate Lexicon), and the output is a list of candidate claims. The final component is the Se- lection Component, in which a classifier is used to determine which (if any) of the candidate claims are coherent and relevant for the topic. In what follows we describe these three steps in greater de- tail.</p><p>The Predicate Lexicon (PL) was constructed by parsing manually-detected claims ( <ref type="bibr" target="#b4">Aharoni et al., 2014</ref>) using the Watson ESG parser <ref type="bibr" target="#b5">(McCord et al., 2012)</ref>, and considering those which have ex- actly one verb. Then the verb and a concatena- tion of its right-modifiers, termed here the pred- icate, were extracted from each claim and added to the PL if they contained at least one sentiment word from the sentiment lexicon of ( <ref type="bibr" target="#b1">Hu and Liu, 2004</ref>). The sentiment criterion was added to se- lect for predicates which have a clear stance with respect to the topic. All in all, there are 1203 en- tries in the PL used here. <ref type="bibr">1</ref> A key feature in filtering and selecting can- didate claims is text similarity. The similarity between text segments was defined based on the constituent words' word2vec embedding ( <ref type="bibr">Mikolov et al., 2013)</ref>: Consider two list of words, l = w 1 , . . . , w n and l = w 1 , . . . , w n . Denote by w2v(w, w ) the word2vec similarity between w and w -the cosine of the angle between the embeddings of w and w . Then the similar- ity between l and l is defined : sim(l, l ) = 1 n i=1,...,n max j=1,...,n w2v(w i , w j ) + 1 n j=1,...,n max i=1,...,n w2v(w j , w i ) (words without embeddings are ignored). Addition- ally, if S is a set of text segments, define:</p><formula xml:id="formula_0">sim(l, S) = max l ∈S sim(l, l ).</formula><p>Given a new topic t, the Generation Compo- nent sorts the predicates p in the PL according to sim(t, p), and takes the top k. It then constructs k claim candidate sentences by setting the subject of the sentence to be the topic t, and the predicate to be one of these k. This may require some ma- nipulation, as the plurality of the topic determines the appropriate surface realization of the predicate verb. We determine the topic's plurality using the Watson parser <ref type="bibr" target="#b5">(McCord et al., 2012)</ref>, and do the surface realization with SimpleNLG ( <ref type="bibr" target="#b0">Gatt and Reiter, 2009</ref>) and the NIH lexicon 2 .</p><p>The Selection Component uses a logistic regres- sion classifier to first predict which of the candi- date claims generated by the Generation Compo- nent are valid, and then to rank the valid candi- dates according to the classifier's score. It receives two parameters, κ and τ . If the fraction of valid candidates (according to the classifier) is less than τ , then it selects none of them. This is designed to allow the algorithm not to synthesize claims for topics where the PL does not seem to yield a sub- stantial number of valid claims. If the number of valid candidates is at least τ , the top κ valid candi- dates are returned (or all of them, if there are less than κ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Classification Features</head><p>To describe the classification features used, we need to define -given a topic -the topic's n-gram Lexicon (n-TL). This is a list of n-grams which are presumably related to the topic. Specifically, given an n-gram, we assume its appearance in Wikipedia articles follows a hyper-geometric dis- tribution, and estimate the distribution's parame- ters by counting the n-gram's appearance in a large set of Wikipedia articles. With these parameters, the p-value for its appearances in topic-related ar- ticles is calculated. The n-TL is the list of n-grams with Bonferroni-corrected p-value at most 0.05. The topic-related articles were identified manually (see <ref type="bibr" target="#b4">(Aharoni et al., 2014)</ref>).</p><p>For a candidate claim c, denote its words by w 1 , . . . , w m . Recall that c is composed of the given topic, t, and a predicate p ∈ P L. Recall also that p was extracted from a manually-detected claim c p . Denote by t p the topic for which c p was detected, and by s p the subject of the claim sen- tence c p . Denote by m t the number of words in t.</p><p>For example, consider the second candidate claim in <ref type="table" target="#tab_0">Table 1</ref>, c = Truth and reconciliation commissions are a source of conflict. There t = truth and reconciliation commissions and p = are a source of conflict. p was extracted from the claim c p = religion is a source of conflict in the labeled data, which is associated with the topic atheism (and the debatabase motion atheism is the only way). Hence, t p = atheism and s p = religion.</p><p>The classification features we used are of three types: One aims to identify predicates which are inherently amenable to generation of claims, that http://www.ncbi.nlm.nih.gov/books/NBK9680/ is, which state something fairly general about their subject, and which are not very specific to the topic in which the predicate was originally found (e.g., low sim(p, t p )). The second aims to find predicates which are relevant for the new topic for which claims are synthesized (e.g., high sim(p,n- TL)). Finally, we'd like the claim to be a valid and plausible sentence, and so look for the frequency of its words, and sub-phrases of it, in Wikipedia.</p><p>All in all 15 features were defined: m, the number of words in c; Number of Lucene hits for w 1 , . . . , w m (as a bag of words); Number of Wikipedia sentences containing all w 1 , . . . , w m ; Largest k, such that the k-gram w 1 . . . w k ap- pears in Wikipedia; Number of times the 3-gram w mt w mt+1 w mt+2 appears in Wikipedia; Number of times p appears in a claim candidate labeled positive, and the number of times in one labeled negative (claim candidates generated for t are ex- cluded, see Section 3 for labeling details); Inclu- sion of p's verb in a manually-crafted list of "cau- sation verbs"; sim(p,n-TL) , for n = 1, 2, 3; sim(p, t); sim(p, t p ); sim(s p , t p ); sim(s p , t).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Setup</head><p>We generated claims for 67 topics, extracted from debatabase motions (http://idebate.org) for which we have previously annotated relevant Wikipedia articles (for the benefit of the n-TLs construction; see Section 2.1). Importantly, when generating candidate claims for a topic, predicates which originated from this topic were not used.</p><p>For each topic 28 candidate claims were gener- ated, and in addition one manually-detected claim (as per ( <ref type="bibr" target="#b4">Aharoni et al., 2014)</ref>) and one mock claim were included for control. The mock claim was constructed by setting the topic as the subject of a sentence, and selecting a mock predicate at ran- dom from a hand-crafted list.</p><p>These 67 × 30 candidate claims were annotated using Amazon's Mechanical Turk (AMT). In each HIT (Human Intelligence Task) we presented the annotators with a debatabase motion and 10 can- didate claims, and asked which of the claims is ap- propriate for the motion (10 annotators per HIT).</p><p>After filtering out the less reliable annotators based on mutual agreement and control questions, a reasonable agreement was apparent (average κ = 0.73). After this filtering 45 of the ini- tial 82 annotators remained, as well as 955 of the initial 2010 annotated candidate claims (discard-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Claim</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Original</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Subject Label</head><p>Democratization con- tributes to stability.</p><p>Nuclear weapons 1</p><p>Truth and reconciliation commissions are a source of conflict.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Religion 1</head><p>Graduated response lacks moral legitimacy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The State 1</head><p>Nuclear weapons cause lung cancer.</p><p>Smoking 0</p><p>A global language leads to great exhaustion. Great anar- chy 0 ing claims with less than 5 valid annotators, those without a clear majority decision, as well as the control claims). See <ref type="table" target="#tab_0">Table 1</ref> for some examples. We note that annotation tasks like this are in- herently subjective <ref type="bibr" target="#b4">((Aharoni et al., 2014</ref>) report κ = 0.4), so discarding candidates without a clear majority decision can be seen as discarding those for which the true label is not well defined. Nonetheless, the reason for discarding most of the candidate claims was annotator's (lack of) reliabil- ity, not ambiguity of the true label.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Results</head><p>Initially we thought to label a candidate claim as either positive or negative examples, based on the majority vote of the annotators. This lead to a seemingly 52% of the candidates being "good". However, anecdotal examination of this majority labeling suggested that the many annotators were biased toward answering "good" -even on some of the control questions which contained nonsensical sentences. This, along side relatively low mean agreement, raised the need for filtering mentioned above. After filtering, 40% of the candidate claims were taken to be positive examples. The accuracy of the Selection Component was assessed using a leave-one-out methodology, leaving out one topic at each iteration. The overall accuracy achieved by the classifier was 0.75 <ref type="table" target="#tab_2">(Table 2</ref> depicts the confu- sion matrix).</p><p>We also examined the trade-off between the number of selected candidate claims and the frac- tion of them which are valid. <ref type="figure" target="#fig_0">Figure 1</ref>   .</p><p>average precision when varying the two Selection Component parameters, κ and τ . For example, at the most conservative setting, where the com- ponent outputs at most one claim per topic, and only for a topic for which at least half the candi- date claims were predicted to be valid (31 of the 67 topics), the precision is 0.94. Recall that in the entire dataset, 40% of the examples are positive. We note that this precision is significantly higher than reported for claim detection ( <ref type="bibr" target="#b4">Levy et al., 2014)</ref>, where, for example, mean precision at 5 is 0.28 (in our case it is 0.7 − 0.8). One should note, however, that this is not a fair comparison. First, we permit the algorithm to discard some top- ics. Second, here the definition of a valid claim is less strict than in ( <ref type="bibr" target="#b4">Levy et al., 2014)</ref>.</p><p>Examining the impact of individual features, we first looked which of them, on their own, are most correlated with the labels. These turned out to be the number of times p appears in a claim candi- date labeled positive and negative (Pearson's cor- relation 0.33 and -0.34 resp.). We then examined which features received the most weight in the lo- gistic regression classifier (trained over all data; features were scaled to a <ref type="bibr">[0,</ref><ref type="bibr">1]</ref>). The top feature was the number of sentences in which all words appear, and following it were the aforementioned appearance counts in negative and positive exam- ples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion and Work in Progress</head><p>The Generation Component can be thought of as constructing sentences by using pre-defined templates, of the form "&lt;topic-slot&gt; &lt;extracted predicate&gt;". These "generation templates" are created by "mining" a corpus of manually- detected claims and extracting the predicate from them. They are then filled in during run-time, by inserting a new topic in that slot. There are sev- eral ways which we have started exploring to ex- tend this paradigm -automatically identifying the grammatical position of a"topic slot" in a corpus claim rather than assuming it is the subject; using unsupervised methods for mining the predicates directly from Wikipedia; and generating candidate claims by using several variants for the subject and object, rather than just the topic and the PL entry. Initial results are promising, but more work is re- quired to achieve reasonable accuracy.</p><p>Another interesting alternative is to construct the PL manually, rather than automatically. This can be seen as analogous to Argumentation Schemes <ref type="bibr" target="#b13">(Walton et. al, 2008</ref>). Argumentation Schemes can be thought of as templates for model- ing arguments -defining a slot for a premise or two (which may be implicit), a slot for a conclusion or claim, and some fixed connecting text. While Ar- gumentation Schemes are used for detecting <ref type="bibr" target="#b12">(Walton, 2012</ref>) and analyzing argumentative structures, in principle they can also be used to synthesize them. In this sense, our work here can be seen as applying the same concept at finer granularity - at the claim level instead of the argument.</p><p>While at the onset we presented claim synthe- sis as an alternative to argumentation mining for the purpose of generating arguments, it is interest- ing how the two augment each other. Specifically, we have started looking at whether claim synthe- sis can generate claims which do not appear in our corpus ( <ref type="bibr" target="#b4">Aharoni et al., 2014)</ref>, and whether match- ing Evidence to claims <ref type="bibr" target="#b10">(Rinott et. al, 2015</ref>) can improve claim synthesis. Regarding the novelty of synthesized claims, we looked at 18 synthesized claims, labeled as valid for 3 topics -criminaliza- tion of blasphemy, building high-rise for housing and making physical education compulsory -and compared them to the 94 manually detected claims for these topics (each topic separately). Of the 18 claims, 5 appear to be novel.</p><p>A more circumvent method to assess novelty is as follows -for each candidate claim we looked for the most similar claim (for the same topic) in our annotated data. We then computed Pearson's correlation between these similarity scores and the labels of the candidate claim, getting a coefficient of 0. <ref type="bibr">29 (p-value=10 −27 )</ref>. This is similar to the correlation between for the strongest classification features, suggesting again that many of the gener- ated claims are not novel, yet similarity to anno- tated claims on its own is not enough to determine a candidate-claim's validity.</p><p>Similarly, we examined whether having a matching evidence in the annotated corpus (matches were determined using the algorithm of <ref type="bibr" target="#b10">(Rinott et. al, 2015)</ref>), is indicative of a candidate- claim's validity. Computing correlation (over the 51 topic for which annotated evidence was avail- able) gave a Pearson's coefficient of 0.23. This suggests that matching Evidence can be a power- ful feature in improving our current classification model.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Mean Precision (micro average): Colors indicate different values of τ. In parenthesis is the number of topics for which claims were selected.</figDesc><graphic url="image-1.png" coords="4,307.28,288.82,226.78,181.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Examples of candidate claims (top-
ics in italics, predicates in bold), the subject 
of the claim sentence which originated their 
predicate, and their label. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 : Confusion Matrix: Number of claim candidates according to AMT annota- tion (x-axis) and predicted label (y-axis)</head><label>2</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="1"> data is avaiable at https://www.research.ibm. com/haifa/dept/vst/mlta_data.shtml. 2 UMLS Reference Manual [Internet]. Bethesda (MD): National Library of Medicine (US); 2009 Sep-. 6, SPECIALIST Lexicon and Lexical Tools. Available from:</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Acknowledgements</head><p>We thank Liat Ein-Dor for her contibution to this work, and especially for the development of the Topic Lexicons. We thank Uri Zakai, Ran Levy and Daniel Hershcovich for insightful discussions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">SimpleNLG: A realisation engine for practical applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gatt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Reiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ENLG-2009</title>
		<meeting>ENLG-2009</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Mining and summarizing customer reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minqing</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Knowledge Discovery and Data Mining</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="168" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The measurement of observer agreement for categorical data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Landis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">G</forename><surname>Kock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">159174</biblScope>
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Generation that exploits corpus-based statistical knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irene</forename><surname>Langkilde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics-Volume</title>
		<meeting>the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics-Volume<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1998" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="704" to="710" />
		</imprint>
	</monogr>
	<note>ACL &apos;98)</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Context Dependent Claim Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ran</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Bilu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Hershcovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehud</forename><surname>Aharoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Slonim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 25th International Conference on Computational Linguistics</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deep parsing in Watson</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">C</forename><surname>Mccord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">William</forename><surname>Murdock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Branimir</forename><forename type="middle">K</forename><surname>Boguraev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Journal of Research and Development</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="3" to="4" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<title level="m">Distributed representations of words and phrases and their compositionality</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Argumentation mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mochales</forename><surname>Palau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Intelligence and Law</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Building Natural Language Generation Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehud</forename><surname>Reiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Dale</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>Cambridge University Press</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Show Me Your Evidencean Automatic Method for Context Dependent Evidence Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruty</forename><surname>Rinott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lena</forename><surname>Dankin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Alzate</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mitesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehud</forename><surname>Khapra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Aharoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Slonim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in NLP (EMNLP)</title>
		<meeting>the 2015 Conference on Empirical Methods in NLP (EMNLP)<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="17" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">The Uses of Argument</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Toulmin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1958" />
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Argument Mining by Applying Argumentation Schemes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><surname>Walton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Studies in Logic</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="38" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Argumentation schemes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><surname>Walton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabrizio</forename><surname>Macagno</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Approaches to text mining arguments from legal cases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Wyner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Mochales-Palau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Milward</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Semantic processing of legal texts</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="60" to="79" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
