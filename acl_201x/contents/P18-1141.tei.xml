<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:24+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Embedding Learning Through Multilingual Concept Induction</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 15-20, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Dufter</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Information and Language Processing</orgName>
								<orgName type="institution">CIS) LMU Munich</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengjie</forename><surname>Zhao</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Ecole Polytechnique Fédérale de Lausanne</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Schmitt</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Information and Language Processing</orgName>
								<orgName type="institution">CIS) LMU Munich</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Fraser</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Information and Language Processing</orgName>
								<orgName type="institution">CIS) LMU Munich</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sch¨</forename><surname>Schütze</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Information and Language Processing</orgName>
								<orgName type="institution">CIS) LMU Munich</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Embedding Learning Through Multilingual Concept Induction</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1520" to="1530"/>
							<date type="published">July 15-20, 2018. 2018</date>
						</imprint>
					</monogr>
					<note>1520</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present a new method for estimating vector space representations of words: embedding learning by concept induction. We test this method on a highly parallel corpus and learn semantic representations of words in 1259 different languages in a single common space. An extensive experimental evaluation on crosslin-gual word similarity and sentiment analysis indicates that concept-based multilingual embedding learning performs better than previous approaches.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Vector space representations of words are widely used because they improve performance on mono- lingual tasks. This success has generated inter- est in multilingual embeddings, shared representa- tion of words across languages ( <ref type="bibr" target="#b14">Klementiev et al., 2012)</ref>. Such embeddings can be beneficial in ma- chine translation in sparse data settings because multilingual embeddings provide meaning repre- sentations of source and target in the same space. Similarly, in transfer learning, models trained in one language on multilingual embeddings can be deployed in other languages <ref type="bibr">(Zeman and Resnik, 2008;</ref><ref type="bibr">McDonald et al., 2011;</ref><ref type="bibr">Tsvetkov et al., 2014</ref>). Automatically learned embeddings have the added advantage of requiring fewer resources for training ( <ref type="bibr" target="#b14">Klementiev et al., 2012;</ref><ref type="bibr">Hermann and Blunsom, 2014b;</ref><ref type="bibr" target="#b10">Guo et al., 2016</ref>). Thus, mas- sively multilingual word embeddings (i.e., cover- ing 100s or 1000s of languages) are likely to be important in NLP.</p><p>The basic information many embedding learn- ers use is word-context information; e.g., the em- bedding of a word is optimized to predict a rep- resentation of its context. We instead learn em- ^ <ref type="figure">Figure 1</ref>: Example of a CLIQUE concept: "water"</p><p>beddings from word-concept information. As a first approximation, a concept is a set of seman- tically similar words. <ref type="figure">Figure 1</ref> shows an example concept and also indicates one way we learn con- cepts: we interpret cliques in the dictionary graph as concepts. The nodes of the dictionary graph are words, its edges connect words that are trans- lations of each other. A dictionary node has the form prefix:word, e.g., "tpi:wara" (upper left node in the <ref type="figure">figure)</ref>. The prefix is the ISO 639-3 code of the language; tpi is Tok Pisin. Our method takes a parallel corpus as input and induces a dictionary graph from the parallel cor- pus. Concepts and word-concept pairs are then induced from the dictionary graph. Finally, em- beddings are learned from word-concept pairs.</p><p>A key application of multilingual embeddings is transfer learning. Transfer learning is mainly of interest if the target is resource-poor. We there- fore select as our dataset 1664 translations in 1259 languages of the New Testament from PBC, the Parallel Bible Corpus. Since "translation" is an ambiguous word, we will from now on refer to the 1664 translations as "editions". PBC is aligned <ref type="bibr">English King James Version (KJV)</ref> German Elberfelder 1905 Spanish Americas And he said , Do it the second time . And they did it the second time . . . Und er sprach : Füllet vier Eimer mit Wasser , und gießet es auf das Brandopfer und auf das Holz . Und er sprach : Tut es zum zweiten Male ! Und sie taten es zum zweiten Male . . .</p><p>Y dijo : Llenad cuatro cántaros de agua y derramadla so- bre el holocausto y sobre la leña . Después dijo : Hacedlo por segunda vez ; y lo hicieron por segunda vez . . . <ref type="table">Table 1</ref>: Instances of verse 11018034. This multi-sentence verse is an example of verse misalignment.</p><p>on the verse level; most verses consist of a single sentence, but some contain several (see <ref type="table">Table 1</ref>). PBC is a good model for resource-poverty; e.g., the training set (see below) of KJV contains fewer than 150,000 tokens in 6458 verses.</p><p>We evaluate multilingual embeddings on two tasks, roundtrip translation (RT) and sentiment analysis. RT on the word level is -to our knowl- edge -a novel evaluation method: a query word w of language L 1 is translated to its closest (with respect to embedding similarity) neighbor v in L 2 and then backtranslated to its closest neighbor w in L 1 . RT is successful if w = w . There are well-known concerns about RT when it is used in the context of machine translation. A successful roundtrip translation does not necessarily imply that v is of high quality and it is not possible to decide whether an error occurred in the forward or backward translations. Despite these concerns about RT on the sentence level, we show that RT on the word level is a difficult task and an effective measure of embedding quality.</p><p>Contributions. (i) We introduce a new em- bedding learning method, multilingual embedding learning through concept induction. (ii) We show that this new concept-based method outperforms previous approaches to multilingual embeddings. (iii) We propose both word-level and character- level dictionary induction methods and present evidence that concepts induced from word-level dictionaries are better for easily tokenizable lan- guages and concepts induced from character-level dictionaries are better for difficult-to-tokenize lan- guages. (iv) We evaluate our methods on a corpus of 1664 editions in 1259 languages. To the best of our knowledge, this is the first detailed evaluation, involving challenging tasks like word translation and crosslingual sentiment analysis, that has been done on such a large number of languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Pivot languages</head><p>Most of our methods are based on bilingual dic- tionary graphs. With 1664 editions, it is com- putationally expensive to consider all editions si- multaneously (more than 10 6 dictionaries). Thus we split the set of editions in 10 pivot and 1654 remaining editions, and do not compute nor use dictionaries within the 1654 editions. We refer to the ten pivot editions as pivot languages and give them a distinct role in concept induction. We refer to all editions (including pivot editions) as target editions. Thus, a pivot edition has two roles: as a pivot language and as a target edition.</p><p>We select the pivot languages based on their sparseness. Sparseness is a challenge in NLP. In the case of embeddings, it is hard to learn a high-quality embedding for any infrequent word. Many of the world's languages (including many PBC languages) exhibit a high degree of sparse- ness. But some languages suffer comparatively little from sparseness when simple preprocessing like downcasing and splitting on whitespace is em- ployed.</p><p>A simple measure of sparseness that affects em- bedding learning is the number of types. Fewer types is better since their average frequency will be higher. <ref type="table" target="#tab_1">Table 2</ref> shows the ten languages in PBC that have the smallest number of types in 5000 randomly selected verses. We randomly sample 5000 verses per edition and compare the number of types based on this selection because most edi- tions do not contain a few of the selected 6458 verses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Character-level modeling (CHAR)</head><p>We will see that tokenization-based models have poor performance on a subset of the 1259 lan- guages. To overcome tokenization problems, we represent a verse of length m bytes, as a sequence of m − (n − 1) + 2 overlapping byte n-grams. In this paper, "n-gram" always refers to "byte n- gram". We pad the verse with initial and final space, resulting in two additional n-grams (hence "+2"). This representation is in the spirit of earlier byte-level processing, e.g., <ref type="bibr" target="#b8">(Gillick et al., 2016</ref>  We refer to this ngram representation as CHAR and to standard tokenization as WORD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Dictionary induction</head><p>Alignment-based dictionary. We use fastalign <ref type="bibr" target="#b6">(Dyer et al., 2013)</ref> to compute word alignments and use GDFA for symmetrization. All align- ment edges that occurred at least twice are added to the dictionary graph. Initial experiments indi- cated that alignment-based dictionaries have poor quality for CHAR, probably due to the fact that overlapping ngram representations of sentences have properties quite different from the tokenized sentences that aligners are optimized for. Thus we use this dictionary induction method only for WORD and developed the following alternative for CHAR.</p><p>Correlation-based dictionary (χ 2 ). χ 2 is a greedy algorithm, shown in <ref type="figure">Figure 2</ref>, that selects, in each iteration, the pair of units that has the high- est χ 2 score for cooccurrence in verses. Each se- lected pair is added to the dictionary and removed from the corpus. Low-frequency units are se- lected first and high-frequency units last; this pre- vents errors due to spurious association of high- frequency units with low-frequency units. We per- form d max = 5 passes; in each pass, the maximum degree of a dictionary node is 1 ≤ d ≤ d max . So if the node has reached degree d, it is ineligible for additional edges during this pass. Again, this avoids errors due to spurious association of high- frequency units that already participate in many</p><formula xml:id="formula_0">Algorithm 1 χ 2 -based dictionary induction 1: procedure DICTIONARYGRAPH(C) 2: A = all-edges(C), E = [] 3: for d ∈ [1, 2, . . . , dmax] do 4: f max = 2 5:</formula><p>while f max ≤ |C| do 6:</p><p>f min = max(min(5, f max),</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">10</head><p>f max) 7:</p><p>(χ 2 , s, t) = max-χ 2 -edge(A, f min , f max, d) 8:</p><p>if χ 2 &lt; χ min then 9:</p><p>f max = f max + 1; continue 10:</p><p>end if 11:</p><formula xml:id="formula_1">T = extend-ngram(A, f min , f max, d, s, t) 12:</formula><p>append(E, s, T ) 13:</p><p>remove-edges(A, s, T ) 14:</p><p>end while 15:</p><p>end for 16:</p><p>return dictionary-graph = (nodes(E), E) 17: end procedure <ref type="figure">Figure 2</ref>: χ 2 -based dictionary induction. C is a sentence-aligned corpus. A is initialized to con- tain all edges, i.e., the fully connected bipartite graph for each parallel verse. E collects the se- lected dictionary edges. d is the edge degree: in each pass through the loop only edges are consid- ered whose participating units have a degree less than d. f max is the maximum frequency during this pass. |C| is the number of sentences in the cor- pus. extend-ngram extends a target ngram to left / right; e.g., if s = "jisas" is aligned with ngram t = "Jesu" in English, then "esus" is added to T . t is always a member of T . remove-edges removes edges in A between s and a member of T . edges with low-frequency units. Recall that this method is only applied for CHAR.</p><p>Intra-pivot dictionary. We assume that pivot languages are easily tokenizable. Thus we only consider alignment-based dictionaries (in total 45) within the set of pivot languages.</p><p>Pivot-to-target dictionary. We compute an alignment-based and a χ 2 -based dictionary be- tween each pivot language and each target edition, yielding a total of 10*1664 dictionaries per dictio- nary type. (Note that this implies that, for χ 2 , the WORD version of the pivot language is aligned with its CHAR version.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Concepts</head><p>A concept is defined as a set of units that has two subsets: (i) a defining set of words from the ten pivot languages and (ii) a set of target units (words or n-grams) that are linked, via dictionary edges,</p><formula xml:id="formula_2">Algorithm 2 CLIQUE concept induction 1: procedure CONCEPTS(I ∈ R n×n , θ, ν) 2: G = ([n], {(i, j) ∈ [n] × [n] | Iij &gt; θ}) 3: cliques = get-cliques(G, 3) 4: Gc := (Vc, Ec) = (∅, ∅) 5: for c1, c2 ∈ cliques × cliques do 6: if |c1 ∩ c2| ≥ ν min{|c1|, |c2|} then 7: Vc = Vc ∪ {c1, c2}, Ec = Ec ∪ {(c1, c2)} 8:</formula><p>end if 9:</p><p>end for 10: metacliques = get cliques(Gc, 1) 11: concepts = {flatten(c) | c ∈ metacliques} 12: return concepts 13: end procedure I is a normalized adjacency matrix of a dictio- nary graph (i.e., relative frequency of alignment edges with respect to possible alignment edges). get-cliques(G, n) returns all cliques in G of size greater or equal to n. flatten(A) flattens a set of sets.</p><p>[n] denotes {1, 2, . . . , n}. θ = 0.4, ν = 0.6.</p><p>to the pivot subset. We selected the ten "easiest" of the 1664 editions as pivot languages. Our premise is that semantic information is encoded in a simply accessible form in the pivot languages and so they should offer a good basis for learning concepts.</p><p>We induce concepts from the dictionary graph, a multipartite graph consisting of ten pivot language node/word sets and all target edition node/unit sets (where units are words or n-grams). Edges either connect pivot nodes with other pivot nodes or pivot nodes with target units.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.1">CLIQUE concept induction</head><p>If concepts corresponded to each other in the overtly coding pivot languages, if words were not ambiguous and if alignments were perfect, then concepts would be cliques in the pivot part of the dictionary graph. These conditions are too strict for natural languages, so we relax them in our CLIQUE concept induction algorithm <ref type="figure" target="#fig_0">(Fig- ure 3</ref>). The algorithm identifies maximal multilin- gual cliques (size ≥ 3) within the dictionary graph of the pivot languages and then merges two cliques if they share enough common words. The merging lets us identify clique-based concepts even if, e.g., a dictionary edge between two words is missing. It also accommodates the situation where more than one word of a pivot language should be part of a concept. The merging step can also be interpreted as metaconcept induction.</p><p>Once we have identified the cliques, we project N (t) ={bis:Jorim, ium:yo-lim, sag:Yorim, tpi:Jorim} t∈T ={ac0:Yorim,atg0:iJorimu,bav0:Jorim,bom0:Yorim, dik0:Jorim, dtp0:Yorim, duo0:Jorim, eng1:Jorim, engb:Jorim, fij2:Lorima, fij3:Jorima, gor0:Yorim, hvn0:Yorim, ibo0:Jorim, iri0:Jorri, kmr0:YorˆımYorˆım, ksd0:Iorim, kwd0:Jorim, lia0:Yorimi, loz0:Jorimi, mbd0:Hurim, mfh0:Yorim, min0:Yorim, mrw0:Yorim,mse0:Jorimma,naq0:Jorimmi, smo1:Iorimo, srn1:Yorim, tsn2:Jorime, yor2:Jórímù} <ref type="figure">Figure 4</ref>: Target neighborhood concept example:</p><formula xml:id="formula_3">N (t) ∪ T . N (t)</formula><p>is the target neighborhood for each of the target words in T .</p><p>them to the target editions: a target-unit is added to a clique if it is connected to a proportion ν = 0.6 of its member words (to allow for missing edges). This identifies around 150k clique concepts that cover around 8k of the total vocabulary of 24k En- glish words (WORD).</p><p>As an alternative to cliques, <ref type="bibr" target="#b2">Ammar et al. (2016)</ref> use connected components (CCs). The reachability relation (induced by CC) is the tran- sitive closure of the edge relation. This results in semantically unrelated words being in the same concept for very low levels of noise. In contrast, cliques are more "strict": only node subsets are considered whose corresponding edge relation is already transitive (or almost so for ν = 0.6). Transitivity across languages often does not hold in alignments or dictionaries; see, e.g., <ref type="bibr" target="#b25">Simard (1999)</ref>. This is why we only consider cliques (which reflect already existent transitivity) rather than CCs, which impose transitivity where it does not hold naturally.</p><p>2.4.2 N (t) (target neighborhood) concept induction Let N (t) be the neighborhood of target node t in the multipartite dictionary graph, i.e., the set of pivot words that are linked to t. We refer to N (t) as target neighborhood. <ref type="figure">Figure 4</ref> shows an exam- ple of such a target neighborhood, the set N (t) consisting of four words. 1 A target neighborhood concept consists of a set T of pivot words and all target words t for which T = N (t) holds.</p><p>Motivation. Suppose N (t) = N (u) for tar- get nodes t and u from two different languages and |N (t)| covers several pivot languages, e.g., |N (t)| = |N (u)| = 4 as in the figure. Again, if units closely corresponded to concepts, if there were no ambiguity, if the dictionary were perfect, then we could safely conclude that the meanings of t and u are similar; if the meanings of t and u were unrelated, it is unlikely that they would be aligned to the exact same words in four different languages. In reality, there is no exact meaning- form correspondence, there is ambiguity and the dictionary is not perfect. Still, we will see be- low that defining concepts as target neighborhoods works well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.3">Filtering target neighborhood concepts</head><p>In contrast to CLIQUE, we do not put any con- straint on the pivot-to-pivot connections within target neighborhoods; e.g., in <ref type="figure">Figure 4</ref>, we do not require that "bis:Jorim" and "sag:Yorim" are connected by an edge. We evaluate three post- filtering steps of target neighborhoods to increase their quality: restricting target neighborhoods to those that are cliques in N (t)-CLIQUE; to those that are connected components in N (t)-CC; and to those of size two that are valid edges in the dictionary in N (t)-EDGE. For N (t)-EDGE, we found that taking all edges performs well, so we also consider edges that are proper subsets of tar- get neighborhoods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Embedding learning</head><p>We adopt the framework of embedding learning algorithms that define contexts and then sample pairs of an input word (more generally, an input unit) and a context word (more generally, a con- text unit) from each context. The only difference is that our contexts are concepts. For simplicity, we use word2vec ( <ref type="bibr" target="#b18">Mikolov et al., 2013a</ref>) as the implementation of this model. <ref type="bibr">2</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Baselines</head><p>Baselines for multilingual embedding learning. One baseline is inspired by <ref type="bibr">(Vuli´cVuli´c and Moens, 2015)</ref>. We consider words of one aligned verse in the pivot languages and one target language as a bag of words (BOW) and consider this bag as a context. <ref type="bibr">3</ref> Levy et al. <ref type="formula">(2017)</ref> show that sentence ID fea- tures (interpretable as an abstract representation of the word's context) are effective. We use a corpus with lines consisting of pairs of an identifier of a verse and a unit extracted from that verse as input to word2vec and call this baseline S-ID. <ref type="bibr">Lardilleux and Lepage (2009)</ref> propose a sim- ple and efficient baseline: sample-based concept induction. Words that strictly occur in the same verses are assigned to the same concept. To in- crease coverage, they propose to sample many dif- ferent subcorpora. <ref type="bibr">4</ref> We induce concepts using this method and project them analogous to CLIQUE. We call this baseline SAMPLE.</p><p>One novel contribution of this paper is roundtrip evaluation of embeddings. We learn embeddings based on a dictionary. The question arises: are the embeddings simply reproducing the information already in the dictionary or are they improving the performance of roundtrip search?</p><p>As a baseline, we perform RTSIMPLE, a sim- ple dictionary-based roundtrip translation method. Retrieve the pivot word p in pivot language L p (i.e., p ∈ L p ) that is closest to the query q ∈ L q . Retrieve the target unit t ∈ L t that is closest to p. Retrieve the pivot word p ∈ L p that is closest to t. Retrieve the unit q ∈ L q that is closest to p . If q = q , this is an exact hit. We run this experiment for all pivot and target languages.</p><p>Note that roundtrip evaluation tests the capabil- ity of a system to go from any language to any other language. In an embedding space, this re- quires two hops. In a highly multilingual dataset of n languages in which not all O(n 2 ) bilingual dictionaries exist, this requires four hops.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data</head><p>We use PBC <ref type="bibr">(Mayer and Cysouw, 2014</ref>). The version we pulled on 2017-12-11 contains 1664 Bible editions in 1259 languages (based on ISO 639-3 codes) after we discarded editions that have low coverage of the New Testament. We use 7958 verses that have good coverage in these 1664 edi- tions. The data is verse aligned; a verse of the New Testament can consist of multiple sentences. We randomly split verses 6458/1500 into train/test.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Evaluation</head><p>For sentiment analysis, we represent a verse as the IDF-weighted sum of its embeddings. Senti- ment classifiers (linear SVMs) are trained on the training set of the World English Bible edition for the two decision problems positive vs. non- positive and negative vs. non-negative. We create a silver standard by labeling verses in English edi- tions with the NLTK ( <ref type="bibr" target="#b4">Bird et al., 2009</ref>) sentiment classifier.</p><p>A positive vs. negative classification is not rea- sonable for the New Testament because a large number of verses is mixed, e.g., "Now is come salvation . . . the power of his Christ: for the ac- cuser . . . cast down, which accused them before our God . . . " Note that this verse also cannot be said to be neutral. Splitting the sentiment anal- ysis into two subtasks ("contains positive senti- ment: yes/no" and "contains negative sentiment: yes/no") is an effective solution for this paper.</p><p>The two trained models are then applied to the test set of all 1664 editions. All embeddings in this paper are learned on the training set only. So no test information was used for learning the em- beddings.</p><p>Roundtrip translation. There are no gold stan- dards for the genre of our corpus (the New Tes- tament); for only a few languages out-of-domain gold standards are available. Roundtrip evalua- tion is an evaluation method for multilingual em- beddings that can be applied if no resources are available for a language. Loosely speaking, for a query q in a query language L q (in our case En- glish) and a target language L t , roundtrip transla- tion finds the unit w t in L t that is closest to q and then the English unit w e that is closest to w t . If the semantics of q and w e are identical (resp. are unre- lated), this is deemed evidence for (resp. counter- evidence against) the quality of the embeddings. We work on the level of Bible edition, i.e., two editions in the same language are considered dif- ferent "languages".</p><p>For a query q, we denote the set of its k I near- est neighbors in the target edition e by I e (q) = {u 1 , u 2 , . . . , u k I }. For each intermediate entry we then consider its k T nearest neighbors in English. Overall we get a set T e (q) with k I k T predictions for each intermediate Bible edition e. See <ref type="figure" target="#fig_1">Figure 5</ref> for an example.</p><p>We evaluate the predictions T e (q) using two sets G s (q) (strict) and G r (q) (relaxed) of ground-truth semantic equivalences in English. Precision for a query q is defined as p i (q) := 1/|E| e∈E min{1, |T e (q) ∩ G i (q)|} where E is the set of all Bible editions and i ∈ {s, r}. We report the mean and median across a inter- query mediate predictions woman ⇒ mujer ⇒ wife woman women widows daughters daughter marry married ⇒ esposa ⇒ marry wife woman married marriage virgin daughters bridegroom  set of 70 queries selected from Swadesh (1946)'s list of 100 universal linguistic concepts. We create G s and G r as follows. For WORD, we define G s (q) = {q} and G r (q) = L(q) where L(q) is the set of words with the same lemma and POS as q. For CHAR, we need to find ngrams that correspond uniquely to the query q. Given a candidate ngram g we consider c qg := 1/c(g) q ∈L(q),substring(g,q ) c(q ) where c(x) is the count of character sequence x across all edi- tions in the query language. We add g to G i (q) if c qg &gt; σ i where σ s = .75 and σ r = .5. We only consider queries where G s (q) is non-empty.</p><p>We vary the evaluation parameters (i, k I , k T ) as follows: "S1" represents (s, 1, 1), "S4" (s, 2, 2), "S16" (s, 2, 8), and "R1" (r, 1, 1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Corpus generation and hyperparameters</head><p>We train with the skipgram model and set vector dimensionality to 200; word2vec default parame- ters are used otherwise. Each concept -the union of a set of pivot words and a set of target units linked to the pivot words -is written out as a line or (if the set is large) as a sequence of shorter lines. Training corpus size is approximately 50 GB for all experiments. We write several copies of each line (shuffling randomly to ensure lines are differ- ent) where the multiplication factor is chosen to result in an overall corpus size of approximately 50 GB.</p><p>There are two exceptions. For BOW, we did not find a good way of reducing the corpus size, so this roundtrip translation sentiment <ref type="table" target="#tab_2">analysis  WORD  CHAR  WORD  CHAR  S1  R1  S4  S16  S1  R1  S4</ref> S16 µ Md µ Md µ Md µ Md N µ Md µ Md µ Md <ref type="table" target="#tab_1">µ Md N  pos neg pos neg  1  RTSIMPLE  33 24 37 36  67 24 13 32 21  70  2  BOW  7 5 8 7 13 12 26 28 69  3 2 3 2 5 4 10 11 70  33 81  13 83  3  S-ID  46 46 52 55 63 76 79 91 65  9 5 9 5 14 9 25 22 70  79 88  65 86  4  SAMPLE  33 23 43 42 54 59 82 96 65 53 59 59 72 67 85 79 99 58  82 89  77 89  5  CLIQUE  43 36 59 63 67 77 93 99 69 42 46 48 55 60 76 73 98 53  84 89  69 88  6</ref> N(t) 54 59 61 69 80 87 94 100 69 50 53 54 59 73 82 90 99 66 82 89 87 90 7 N(t)-CLIQUE 11 0</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11">0 16 0 22 0 18 39 45 41 47 58 74 76 94 56 22 84 61 84 8 N(t)-CC 3 0 3 0 5 0 7 0 5 0 0 16 0 25 0 21 4 84 40 83 9 N(t)-EDGE 35 30 43 36 56 55 87 94 69 39 29 49 52 64 78 88 100 63 84 90 84 89</head><p>Table 3: Roundtrip translation (mean/median accuracy) and sentiment analysis (F 1 ) results for word- based (WORD) and character-based (CHAR) multilingual embeddings. N (coverage): # queries con- tained in the embedding space. The best result across WORD and CHAR is set in bold.</p><p>corpus is 10 times larger than the others. For S- ID, we use <ref type="bibr">Levy et al. (2017)</ref>'s hyperparameters; in particular, we trained for 100 iterations and we wrote each verse-unit pair to the corpus only once, resulting in a corpus of about 4 GB. We set the n parameter of n-grams to n = 4 for Bible editions with ρ &lt; 2, n = 8 for Bible editions with 2 ≤ ρ &lt; 3 and n = 12 for Bible editions with ρ ≥ 3 where ρ is the ratio between size in bytes of the edition and median size of the 1664 editions. In χ 2 dictionary induction, we set χ min = 100. In the concept induction algorithm we set θ = 0.4 and ν = 0.6. Except for SAMPLE and CLIQUE, we filter out hapax legomena. <ref type="table">Table 3</ref> presents evaluation results for roundtrip translation and sentiment analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Results</head><p>Validity of roundtrip (RT) evaluation results. RTSIMPLE (line 1) is not competitive; e.g., its ac- curacy is lower by almost half compared to N (t). We also see that RT is an excellent differentiator of poor multilingual embeddings (e.g., BOW) vs. higher-quality ones like S-ID and N (t). This indi- cates that RT translation can serve as an effective evaluation measure.</p><p>The concept-based multilingual embedding learning algorithms CLIQUE and N (t) (lines 5-6) consistently (except S1 WORD) outperform BOW and S-ID (lines 2-3) that are not based on con- cepts. BOW performs poorly in our low-resource setting; this is not surprising since BOW methods rely on large datasets and are therefore expected to fail in the face of severe sparseness. S-ID per- forms reasonably well for WORD, but even in that case it is outperformed by N (t), in some cases by a large margin, e.g., µ of 63 for S-ID vs. 80 for N (t) for S4. For CHAR, S-ID results are poor. On sentiment classification, N (t) also consistently outperforms S-ID.</p><p>While S-ID provides a clearer signal to the em- bedding learner than BOW, it is still relatively crude to represent a word as -essentially -its bi- nary vector of verse occurrence. Concept-based methods perform better because they can exploit the more informative dictionary graph.</p><p>Comparison of graph-theoretic definitions of concepts: N (t)-CLIQUE, N (t)-CC. N (t) (line 6) has the most consistent good performance across tasks and evaluation measures. Postfilter- ing target neighborhoods down to cliques (line 7) and CCs (line 8) does not work. The reason is that the resulting number of concepts is too small; see, e.g., low coverages of N = 18 (N (t)-CLIQUE) and N = 5 (N (t)-CC) for WORD and N = 21 (N (t)-CC) for CHAR. N (t)-CLIQUE results are highly increased for CHAR, but still poorer by a large margin than the best methods. We can inter- pret this result as an instance of a precision-recall tradeoff: presumably the quality of the concepts found by N (t)-CLIQUE and N (t)-CC is better (higher precision), but there are too few of them (low recall) to get good evaluation numbers.</p><p>Comparison of graph-theoretic definitions of concepts: CLIQUE. CLIQUE has strong perfor- mance for a subset of measures, e.g., ranks consis- tently second for RT (except S1 WORD) and sen- timent analysis in WORD. Although CLIQUE is perhaps the most intuitive way of inducing a con- cept from a dictionary graph, it may suffer in rela- tively high-noise settings like ours.</p><p>Comparison of graph-theoretic definitions of concepts: N (t) vs. N (t)-EDGE. Recall that N (t)-EDGE postfilters target neighborhoods by <ref type="bibr">2018, 16:31</ref> [ksw] ဒ" #တ◌"ကမၣ◌် လၢအပာ် လၢယလိ ၤခဲ ကနံ ၣ◌် အံ ၤ⋆, ⋆ထu #ပ( ◌ၤအ3 ၣ◌် အသးတန့ "ဘၣ◌် ⋆.</p><note type="other">Page 1 of 1 extokenise 07/05/</note><p>[cso] Hi³⋆sa³jun³⋆lɨ́¹³⋆ma³tson²⋆tsú²⋆Hi³⋆sa³jun³⋆lɨ́Hi³⋆sa³jun³⋆lɨ́¹³⋆ma³tson²⋆tsú²⋆ lɨ³ua³⋆cáun²⋆tso³⋆ñí¹⋆hná¹⋆nɨ́²⋆lɨ³ua³⋆cáun²⋆tso³⋆ñí¹⋆hná¹⋆nɨ́lɨ³ua³⋆cáun²⋆tso³⋆ñí¹⋆hná¹⋆nɨ́²⋆.</p><p>[eng] Neither⋆can⋆they⋆prove⋆the⋆things⋆ whereof⋆they⋆now⋆accuse⋆me⋆.</p><p>Figure 7: Verse 44024013. "*" = tokenization boundary. S'gaw Karen (ksw) is difficult to to- kenize and CHAR &gt; WORD for N (t). Chinan- teco de Sochiapan (cso) has few types, similar to a pivot language, and CHAR &lt; WORD for N (t).   <ref type="bibr">[WORD]</ref> with four other methods. Difference in mean performance (across queries) in R1 per edition. Positive number means better performance of N (t) <ref type="bibr">[WORD]</ref>.</p><formula xml:id="formula_4">N(t) S-ID SAMPLE CLIQUE [CHAR] [WORD] [WORD] [WORD] iso ∆ iso ∆ iso ∆ iso ∆<label>arb1</label></formula><p>only considering pairs of pivot words that are linked by a dictionary edge. This "quality" filter does seem to work in some cases, e.g., best perfor- mance S16 Md for CHAR. But results for WORD are much poorer.</p><p>SAMPLE performs best for CHAR: best results in five out of eight cases. However, its coverage is low: N = 58. This is also the reason that it does not perform well on sentiment analysis for CHAR (F 1 = 77 for pos).</p><p>Target neighborhoods N (t). The overall best method is N (t). It is the best method more of- ten than any other method and in the other cases, it ranks second. This result suggests that the as- sumption that two target units are semantically similar if they have dictionary edges with exactly the same set of pivot words is a reasonable approx- imation of reality. Postfiltering by putting con- straints on eligible sets of pivot words (i.e., the pivot words themselves must have a certain dictio- nary link structure) does not consistently improve upon target neighborhoods. WORD vs. CHAR. For roundtrip, WORD is a better representation than CHAR if we just count the bold winners: seven (WORD) vs. three (CHAR), with two ties. For sentiment, the more difficult task is pos and for this task, CHAR is better by 3 points than WORD (F 1 = 87, line 6, vs. F 1 = 84, lines 9/5). However, <ref type="table" target="#tab_2">Table 4</ref> shows that CHAR &lt; WORD for one subset of edi- tions (exemplified by cso in <ref type="figure">Figure 7</ref>) and CHAR &gt; WORD for a different subset (exemplified by ksw). So there are big differences between CHAR and WORD in both directions, depending on the language. For some languages, WORD performs a lot better, for others, CHAR performs a lot better.</p><p>We designed RT evaluation as a word-based evaluation that disfavors CHAR in some cases. The fourgram "ady@" in the World English Bible occurs in "already" (32 times), "ready" (31 times) and "lady" (9 times). Our RT evaluation thus dis- qualifies "ady@" as a strict match for "ready". But all 17 aligned occurrences of "ady@" are part of "ready" -all others were not aligned. So in the χ 2 - alignment interpretation, P (ready|ady@) = 1.0. In contrast to RT, we only used aligned ngrams in the sentiment evaluation. This discrepancy may explain why the best method for sentiment is a CHAR method whereas the best method for RT is a WORD method.</p><p>First NLP task evaluation on more than 1000 languages. <ref type="table">Table 3</ref> presents results for 1664 edi- tions in 1259 languages. To the best of our knowl- edge, this is the first detailed evaluation, involv- ing two challenging NLP tasks, that has been done on such a large number of languages. For sev- eral methods, the results are above baseline for all 1664 editions; e.g., S1 measures are above 20% for all 1664 editions for N (t) on CHAR. Group A trains monolingual embedding spaces and subsequently uses a transformation to create a unified space. <ref type="bibr" target="#b19">Mikolov et al. (2013b)</ref> find the transformation by minimizing the Euclidean dis- tance between word pairs. Similarly, <ref type="bibr">Zou et al. (2013)</ref>, <ref type="bibr">Xiao and Guo (2014)</ref> and <ref type="bibr" target="#b7">Faruqui and Dyer (2014)</ref> use different data sources for iden- tifying word pairs and creating the transformation (e.g., by CCA). <ref type="bibr" target="#b5">Duong et al. (2017)</ref> is also simi-lar. These approaches need large datasets to obtain high quality monolingual embedding spaces and are thus inappropriate for a low-resource setting of 150,000 tokens per language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related Work</head><p>Group B starts from the premise that repre- sentation of aligned sentences should be similar. Neural network approaches include ( <ref type="bibr">Hermann and Blunsom, 2014a</ref>) (BiCVM) and <ref type="bibr" target="#b24">(Sarath Chandar et al., 2014</ref>) (autoencoders). Again, we have not enough data for training neural networks of this size. <ref type="bibr">Søgaard et al. (2015)</ref> learn an interlingual space by using Wikipedia articles as concepts and applying inverted indexing. <ref type="bibr">Levy et al. (2017)</ref> show that what we call S-ID is a strongly perform- ing embedding learning method. We use S-ID as a baseline.</p><p>Group C combines mono-and multilingual in- formation in the embedding learning objective. <ref type="bibr" target="#b14">Klementiev et al. (2012)</ref> add a word-alignment based term in the objective. <ref type="bibr">Luong et al. (2015)</ref> extend <ref type="bibr" target="#b18">Mikolov et al. (2013a)</ref>'s skipgram model to a bilingual model. <ref type="bibr" target="#b9">Gouws et al. (2015)</ref> intro- duce a crosslingual term in the objective, which does not rely on any word-pair or alignment infor- mation. For n editions, including O(n 2 ) bilingual terms in the objective function does not scale.</p><p>Group D creates pseudocorpora by merging data from multiple languages into a single corpus. One such method, due to Vuli´c <ref type="bibr">Vuli´c and Moens (2015)</ref>, is our baseline BOW. ¨ Ostling (2014) generates multilingual con- cepts using a Chinese Restaurant process, a com- putationally expensive method. <ref type="bibr" target="#b10">Wang et al. (2016)</ref> base their concepts on cliques. We extend their notion of clique from the bilingual to the multi- lingual case. <ref type="bibr" target="#b2">Ammar et al. (2016)</ref> use connected components. Our baseline SAMPLE, based on ( <ref type="bibr">Lardilleux and</ref><ref type="bibr">Lepage, 2007, 2009)</ref>, samples aligned sentences from a multilingual corpus and extracts perfect alignments. <ref type="bibr">Malaviya et al. (2017)</ref>, <ref type="bibr" target="#b3">Asgari and Schütze (2017)</ref>, ¨ Ostling and <ref type="bibr" target="#b23">Tiedemann (2017)</ref> and Tiede- mann (2018) perform evaluation on the language level (e.g., typology prediction) for 1000+ lan- guages or perform experiments on 1000+ lan- guages without evaluating each language. We present the first work that evaluates on 1000+ lan- guages on the sentence level on a difficult task. <ref type="bibr" target="#b27">Somers (2005)</ref> criticizes RT evaluation on the sentence level; but see <ref type="bibr" target="#b1">Aiken and Park (2010)</ref>. We demonstrated that when used on the word/unit level, it distinguishes weak from strong embed- dings and correlates well with an independent sen- timent evaluation.</p><p>Any alignment algorithm can be used for dic- tionary induction. We only used a member of the IBM class of models ( <ref type="bibr" target="#b6">Dyer et al., 2013</ref>), but presumably we could improve results by us- ing either higher performing albeit slower align- ers or non-IBM aligners (e.g., <ref type="bibr" target="#b20">(Och and Ney, 2003;</ref><ref type="bibr">Tiedemann, 2003;</ref><ref type="bibr" target="#b16">Melamed, 1997)</ref>). Other alignment algorithms include 2D linking ( <ref type="bibr" target="#b15">Kobdani et al., 2009)</ref>, sampling based methods (e.g., <ref type="bibr">Vulic and Moens (2012)</ref>) and EFMARAL <ref type="bibr" target="#b22">( ¨ Ostling and Tiedemann, 2016)</ref>. EFMARAL is especially in- triguing as it is based on IBM1 and Agi´c <ref type="bibr" target="#b0">Agi´c et al. (2016)</ref> find IBM2-based models to favor closely related languages more than models based on IBM1. However, the challenge is that we need to compute tens of thousands of alignments, so speed is of the essence. We ran character-based and word-based induction separately; combining them is promising future research; cf. <ref type="bibr" target="#b13">(Heyman et al., 2017)</ref>.</p><p>There is much work on embedding learning that does not require parallel corpora, e.g., <ref type="bibr">(Vuli´cVuli´c and Moens, 2012;</ref><ref type="bibr" target="#b2">Ammar et al., 2016)</ref>. This work is more generally applicable, but a parallel corpus provides a clearer signal and is more promising (if available) for low-resource research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Summary</head><p>We presented a new method for estimating vec- tor space representations of words: embedding learning by concept induction. We tested this method on a highly parallel corpus and learned semantic representations of words in 1259 differ- ent languages in a single common space. Our extensive experimental evaluation on crosslingual word similarity and sentiment analysis indicates that concept-based multilingual embedding learn- ing performs better than previous approaches.</p><p>The embedding spaces of the 1259 languages (SAMPLE, CLIQUE and N (t)) are available: </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: CLIQUE concept induction. I is a normalized adjacency matrix of a dictionary graph (i.e., relative frequency of alignment edges with respect to possible alignment edges). get-cliques(G, n) returns all cliques in G of size greater or equal to n. flatten(A) flattens a set of sets. [n] denotes {1, 2,. .. , n}. θ = 0.4, ν = 0.6.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Roundtrip translation example for KJV and Americas Bible (Spanish). In this example min{1, |T e (q) ∩ G i (q)|} equals 0 for S1 and R1, and 1 for S4 and S16. connu(3), connais(3), connaissent(3), savez(2), sachant(2), sait(2), sachiez(2), savoir, sçai, ignorez, connaissiez, sache connaissez, connaissais, savent, savaient, connoissez, connue, reconnaˆıtrezreconnaˆıtrez, sais, connaissant, savons, connaissait, savait</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Intermediates aggregated over 17 French editions. q="know", N (t) embeddings, S16. Intermediates are correct with two possible exceptions: "ignorez" 'you do not know'; "reconnaˆıtrezconnaˆıtrez" 'you recognize'.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Following</head><label></label><figDesc>Upadhyay et al. (2016), we group mul- tilingual embedding methods into classes A, B, C, D.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Our ten pivot languages, the languages in 
PBC with the lowest number of types. Tokens in 
1000s. Tok Pisin and Bislama are English-based 
and Sango is a Ngbandi-based creole. PNG = 
Papua New Guinea 

UTF-8 has properties different from Chinese UTF-
8. Thus, universal language processing is easier to 
design on the byte level. 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Comparison of N (t)</table></figure>

			<note place="foot" n="1"> We use numbers and lowercase letters at the fourth position of the prefix to distinguish different editions in the same language, e.g., &quot;0&quot;, &quot;3&quot; and &quot;e&quot; in &quot;ace0&quot;, &quot;fij3&quot;, &quot;enge&quot;.</note>

			<note place="foot" n="2"> We use code.google.com/archive/p/word2vec 3 The actual implementation slightly differs to avoid very long lines. It does only consider two pivot languages at a time, but writes each verse multiple times.</note>

			<note place="foot" n="4"> We use this implementation: anymalign.limsi.fr</note>
		</body>
		<back>
			<div type="annex">
			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Multilingual projection for parsing truly low-resource languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeljko</forename><surname>Agi´cagi´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Johannsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Héctor Alonso Martínez, Natalie Schluter, and Anders Søgaard</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The efficacy of round-trip translation for MT evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milam</forename><surname>Aiken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mina</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Translation Journal</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">14</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Waleed</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Mulcaire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulia</forename><surname>Tsvetkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Smith</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.01925</idno>
		<title level="m">Massively multilingual word embeddings</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Past, present, future: A computational investigation of the typology of tense in 1000 languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehsaneddin</forename><surname>Asgari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Natural language processing with Python: Analyzing text with the natural language toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ewan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Loper</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<pubPlace>O&apos;Reilly Media</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Multilingual training of crosslingual word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Duong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroshi</forename><surname>Kanayama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengfei</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter</title>
		<meeting>the 15th Conference of the European Chapter</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A simple, fast, and effective reparameterization of ibm model 2</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Chahuneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Improving vector space word representations using multilingual correlation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 14th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Multilingual language processing from bytes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Gillick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cliff</forename><surname>Brunk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amarnag</forename><surname>Subramanya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Bilbowa: fast bilingual distributed representations without word alignments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Gouws</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on International Conference on Machine Learning</title>
		<meeting>the 32nd International Conference on International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A representation learning framework for multi-source transfer parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th AAAI Conference on Artificial Intelligence</title>
		<meeting>the 30th AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Multilingual distributed representations without word alignment</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 International Conference on Learning Representations</title>
		<editor>Karl Moritz Hermann and Phil Blunsom</editor>
		<meeting>the 2014 International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Multilingual models for compositional distributed semantics</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<editor>Karl Moritz Hermann and Phil Blunsom</editor>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Bilingual lexicon induction by learning to combine word-level and character-level representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geert</forename><surname>Heyman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vuli´cvuli´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Inducing crosslingual distributed representations of words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Klementiev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Binod</forename><surname>Bhattarai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on Computational Linguistics</title>
		<meeting>the 24th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Word alignment by thresholded twodimensional normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamidreza</forename><surname>Kobdani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Fraser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeedings of the 12th Machine Translation Summit</title>
		<meeting>eeedings of the 12th Machine Translation Summit</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A word-to-word model of translational equivalence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Melamed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th</title>
		<meeting>the 35th</meeting>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<title level="m">Annual Meeting of the Association for Computational Linguistics and 8th Conference of the European Chapter</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Exploiting similarities among languages for machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sutskever</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1309.4168</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A systematic comparison of various statistical alignment models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Franz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">29</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Bayesian word alignment for massively parallel texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert¨ostlingrobert¨</forename><surname>Robert¨ostling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 14th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Efficient word alignment with Markov Chain Monte Carlo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert¨ostlingrobert¨</forename><surname>Robert¨ostling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jörg</forename><surname>Tiedemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Prague Bulletin of Mathematical Linguistics</title>
		<imprint>
			<biblScope unit="page">106</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Continuous multilinguality with language vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert¨ostlingrobert¨</forename><surname>Robert¨ostling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jörg</forename><surname>Tiedemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter</title>
		<meeting>the 15th Conference of the European Chapter</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">An autoencoder approach to learning bilingual word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislas</forename><surname>Ap Sarath Chandar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Lauly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mitesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaraman</forename><surname>Khapra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ravindran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Vikas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amrita</forename><surname>Raykar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Saha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Annual Conference on Neural Information Processing Systems</title>
		<meeting>the 2014 Annual Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Text-translation alignment: Three languages are better than two</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Simard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1999 Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora</title>
		<meeting>the 1999 Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora</meeting>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Inverted indexing for cross-lingual nlp</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Héctor Martínez</forename><surname>Zeljko Agi´cagi´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Alonso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernd</forename><surname>Plank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Bohnet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Johannsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference of the Asian Federation of Natural Language Processing</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Round-trip translation: What is it good for?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harold</forename><surname>Somers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Australasian Language Technology Workshop</title>
		<meeting>the Australasian Language Technology Workshop</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Linguistic Structures of Native America</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morris</forename><surname>Swadesh</surname></persName>
		</author>
		<editor>Cornelius Osgood</editor>
		<imprint>
			<date type="published" when="1946" />
			<publisher>Johnson Reprint Corp</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>South Greenlandic (Eskimo)</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
