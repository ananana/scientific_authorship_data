<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:35+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">End-to-End Non-Factoid Question Answering with an Interactive Visualization of Neural Attention Weights</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Rücklé</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
						</author>
						<title level="a" type="main">End-to-End Non-Factoid Question Answering with an Interactive Visualization of Neural Attention Weights</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of ACL 2017, System Demonstrations</title>
						<meeting>ACL 2017, System Demonstrations <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="19" to="24"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-4004</idno>
					<note>‡ Ubiquitous Knowledge Processing Lab (UKP-DIPF) German Institute for Educational Research www.ukp.tu-darmstadt.de</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Advanced attention mechanisms are an important part of successful neural network approaches for non-factoid answer selection because they allow the models to focus on few important segments within rather long answer texts. Analyzing attention mechanisms is thus crucial for understanding strengths and weaknesses of particular models. We present an extensible, highly modular service architecture that enables the transformation of neural network models for non-factoid answer selection into fully featured end-to-end question answering systems. The primary objective of our system is to enable researchers a way to interactively explore and compare attention-based neural networks for answer selection. Our interactive user interface helps researchers to better understand the capabilities of the different approaches and can aid qualitative analyses. The source-code of our system is publicly available. 1</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Attention-based neural networks are increasingly popular because of their ability to focus on the most important segments of a given input. These models have proven to be extremely effective in many different tasks, for example neural machine translation ( <ref type="bibr">Luong et al., 2015;</ref><ref type="bibr" target="#b6">Tu et al., 2016)</ref>, neural image caption generation ( <ref type="bibr" target="#b8">Xu et al., 2015)</ref>, and multiple sub-tasks in question answering <ref type="bibr" target="#b3">(Hermann et al., 2015;</ref><ref type="bibr" target="#b9">Yin et al., 2016;</ref><ref type="bibr" target="#b0">Andreas et al., 2016)</ref>.</p><p>Attention-based neural networks are especially successful in answer selection for non-factoid ques-tions, where approaches have to deal with complex multi-sentence texts. The objective of this task is to re-rank a list of candidate answers according to a non-factoid question, where the best-ranked candidate is selected as an answer. Models usually learn to generate dense vector representations for questions and candidates, where representations of a question and an associated correct answer should lie closely together within the vector space <ref type="bibr" target="#b2">(Feng et al., 2015)</ref>. Accordingly, the ranking score can be determined with a simple similarity met- ric. Attention in this scenario works by calculating weights for each individual segment in the input (attention vector), where segments with a higher weight should have a stronger impact on the result- ing representation. Several approaches have been recently proposed, achieving state-of-the-art results on different datasets <ref type="bibr" target="#b7">Wang et al., 2016)</ref>.</p><p>The success of these approaches clearly shows the importance of sophisticated attention mecha- nisms for effective answer selection models. How- ever, it has also been shown that attention mecha- nisms can introduce certain biases that negatively influence the results ( <ref type="bibr" target="#b7">Wang et al., 2016)</ref>. As a consequence, the creation of better attention mech- anisms can improve the overall answer selection performance. To achieve this goal, researchers are required to perform in-depth analyses and compar- isons of different approaches to understand what the individual models learn and how they can be improved. Due to the lack of existing tool-support to aid this process, such analyses are complex and require substantial development effort. This impor- tant issue led us to creating an integrated solution that helps researchers to better understand the ca- pabilities of different attention-based models and can aid qualitative analyses.</p><p>In this work, we present an extensible service architecture that can transform models for non-  <ref type="figure">Figure 1</ref>: A high-level view on our service archi- tecture.</p><p>factoid answer selection into fully featured end-to- end question answering systems. Our sophisticated user interface allows researchers to ask arbitrary questions while visualizing the associated attention vectors with support for both, one-way and two- way attention mechanisms. Users can explore dif- ferent attention-based models at the same time and compare two attention mechanisms side-by-side within the same view. Due to the loose coupling and the strictly separated responsibilities of the components in our service architecture, our system is highly modular and can be easily extended with new datasets and new models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Overview</head><p>To transform attention-based answer selection mod- els into end-to-end question answering systems, we rely on a service orchestration that integrates multiple independent webservices with separate responsibilities. Since all services communicate using a well-defined HTTP REST API, our sys- tem achieves strong extensibility properties. This makes it simple to replace individual services with own implementations. A high-level view on our system architecture is shown in <ref type="figure">Figure 1</ref>. For each question, we retrieve a list of candidate an- swers from a given dataset (candidate retrieval).</p><p>We then rank these candidates with the answer se- lection component (candidate ranking), which in- tegrates the attention-based neural network model that should be explored. The result contains the top- ranked answers and all associated attention weights, which enables us to interactively visualize the at- tention vectors in the user interface. Our architecture is similar to the pipelined struc- tures of earlier work in question answering that rely on a retrieval step followed by a more expen- sive supervised ranking approach ( <ref type="bibr" target="#b4">Surdeanu et al., 2011;</ref><ref type="bibr">Higashinaka and Isozaki, 2008)</ref>. We primar- ily chose this architecture because it allows the user to directly relate the results of the system to the an- swer selection model. The use of more advanced components (e.g. query expansion or answer merg- ing) would negate this possibility due to the added complexity.</p><p>Because all components in our extensible ser- vice architecture are loosely coupled, it is possible to use multiple candidate ranking services with different attention mechanisms at the same time. The user interface exploits this ability and allows researchers to interactively compare two models side-by-side within the same view. A screenshot of our UI is shown in <ref type="figure" target="#fig_0">Figure 2</ref>, and an example of a side-by-side comparison is available in <ref type="figure" target="#fig_1">Figure 4</ref>.</p><p>In the following sections, we describe the in- dividual services in more detail and discuss their technical properties.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Candidate Retrieval</head><p>The efficient retrieval of answer candidates is a key component in our question answering approach. It allows us to narrow down the search space for more sophisticated, computationally expensive attention- based answer selection approaches in the subse- quent step, and enables us to retrieve answers within seconds. We index all existing candidates of the target dataset with ElasticSearch, an open- source high-performance search engine. Our ser- vice provides a unified interface for the retrieval of answer candidates, where we query the index with the question text using BM25 as a similarity measure.</p><p>The service implementation is based on Scala and the Play Framework. Our implementation con- tains data readers that allow to index InsuranceQA ( <ref type="bibr" target="#b2">Feng et al., 2015</ref>) and all publicly available dumps of the StackExchange platform. <ref type="bibr">2</ref> Researchers can easily add new datasets by implementing a single data reader class.</p><p>Analysis Enabling researchers to directly relate the results of our question answering system to the answer selection component requires the ab- sence of major negative influences from the answer retrieval component. To analyze the potential influ- ence, we evaluated the list of retrieved candidates (size 500) for existing questions of InsuranceQA and of different StackExchange dumps. Questions in these datasets have associated correct answers, <ref type="bibr">3</ref> which we treat as the ground-truth that should be included in the retrieved list of candidates. Oth- erwise it would be impossible for the answer se- lection model to find the correct answer, and the results would be negatively affected. <ref type="table">Table 1</ref> shows the number of questions with candidate lists that include at least one ground-truth answer. Since the ratio is sufficiently high for all analyzed datasets (83% to 88%), we conclude that the chosen re- trieval approach is a valid choice for our end-to-end question answering system.  <ref type="table">Table 1</ref>: Performance of the retrieval service for different datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Candidate Ranking</head><p>retrieval of attention vectors from the model. These values are bundled with the top-ranked answers and are returned as a result of the service call. Since our primary objective was to enable re- searchers to explore different attention-based ap- proaches, we created a fully configurable and mod- ular framework that includes different modules to train and evaluate answer selection models. The key properties of this framework are:</p><p>• Fully configurable with external YAML files.</p><p>• Dynamic instantiation and combination of configured module implementations (e.g. for the data reader and the model).  <ref type="figure">Figure 3</ref>: Our answer selection framework and candidate ranking service.</p><p>Our framework implementation is based on Python and relies on TensorFlow for the neural network components. It uses Flask for the service imple- mentation.</p><p>A high-level view on the framework structure is shown in <ref type="figure">Figure 3</ref>. A particularly important prop- erty is the dynamic instantiation and combination of module implementations. A central configu- ration file is used to define all necessary options that enable to train and evaluate neural networks within our framework. An excerpt of such config- uration is shown in Listing 1. The first four lines describe the module import paths of the desired im- plementations. Our framework dynamically loads and instantiates the configured modules and uses them to perform the training procedure. The re- maining lines define specific configuration options to reference resource paths or to set specific neural network settings. This modular structure enables a high flexibility and provides a way to freely com- bine different models, training procedures, and data readers.</p><p>Additionally, our framework is capable of start- ing a seamlessly integrated webserver that uses a configured model to rank candidate answers. Since model states can be saved, it is possible to load pre- trained models to avoid a lengthy training process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">QA-Frontend and User Interface</head><p>The central part of our proposed system is the QA- Frontend. This component coordinates the other services and combines them into a fully functional question answering system. Since our primary goal was to provide a way to explore and com- pare attention-based models, we especially focused on the user interface. Our UI fulfills the following requirements:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">d a t a −module: d a t a . i n s u r a n c e q a . v2 2 model−module: model . a p l s t m 3 t r a i n i n g −module: t r a i n i n g . dynamic 4 e v a l u a t i o n −module: e v a l u a t i o n . d e f a u l t 5 6 d a t a : 7 map oov: t r u e 8 e m b e d d i n g s : d a t a / g l o v e . 6 B. 0 0 d . t x t 9</head><p>i n s u r a n c e q a : d a t a / i n s u r a n c e Q A 10</p><p>. . .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11">12 model: 13 l s t m c e l l s i z e : 141 14 m a r g i n : 0 . 2 15 t r a i n a b l e e m b e d d i n g s : t r u e 16 . . . 17 18 t r a i n i n g : 19 n e g a t i v e a n s w e r s : 50 20 b a t c h s i z e : 20 21 e p o c h s : 100 22 s a v e f o l d e r : c h e c k p o i n t s / a p l s t m 23 d r o p o u t : 0 . 3 24 o p t i m i z e r : adam 25 s c o r e r : a c c u r a c y 26</head><p>. . .</p><p>Listing 1: An excerpt of a YAML configuration file for the candidate ranking framework.</p><p>• Use a visualization for the attention vectors similar to <ref type="bibr" target="#b3">Hermann et al. (2015)</ref> and Dos San- tos et al. (2016).</p><p>• Support for both, one-way attention mecha- nisms ( ) and two-way attention mechanisms ).</p><p>• Enable to query multiple models within the same view.</p><p>• Provide a side-by-side comparison of different attention-based models.</p><p>We implemented the user interface with modern web technologies, such as Angular, TypeScript, and SASS. The QA-Frontend service was implemented in Python with Flask. It is fully configurable and allows multiple candidate ranking services to be used at the same time.</p><p>A screenshot of our user interface is shown in <ref type="figure" target="#fig_0">Figure 2</ref>. In the top row, we include an input field that allows users to enter the question text. This input field also contains a dropdown menu to select the target model that should be used for the can- didate ranking. This makes it possible to ask the same question for multiple models and compare the outputs to gain a better understanding of the key differences. Below this input field we offer multiple ways to interactively change the attention visualization. In particular, we allow to change the sensitivity s and the threshold t of the visualization component. We calculate the opacity of an atten- tion highlight o i that corresponds to the weight w i in position i as follows:</p><formula xml:id="formula_0">a = min (w std , w max − w avg ) (1) o i = s · w i −wavg a , if w i ≥ w avg + a · t 0, otherwise (2)</formula><p>Where w avg , w std and w max are the average, stan- dard deviation and maximum of all weights in the text. We use a instead of w std because in rare cases it can occur that w std &gt; w max − w avg , which would lead to visualizations without fully opaque positions. These two options make it possible to adapt the attention visualization to fit the need of the analysis. For example, it is possible to only highlight the most important sections by increasing the threshold. On the other hand, it is also possible to highlight all segments that are slightly relevant by increasing the sensitivity and at the same time reducing the threshold. When the user hovers over an answer and the target model employs a two-way attention mecha- nism, the question input visualizes the associated attention weights. To get a more in-depth view on the attention vectors, the user can hover over any specific word in a text to view the exact value of the associated weight. This enables numerical compar- isons and helps to get an advanced understanding of the employed answer selection model.</p><p>Finally, each answer offers the option to com- pare the attention weights to the output of another configured model. This action enables a side-by- side comparison of different attention mechanisms and gives researchers a powerful tool to explore the advantages and disadvantages of the different ap- proaches. A screenshot of a side-by-side visualiza- tion is shown in <ref type="figure" target="#fig_1">Figure 4</ref>. It displays two attention mechanisms that result in very different behavior. Whereas the model to the left strongly focuses on few individual words (especially in the question), the model to the right is less selective and focuses on more segments that are similar. Our user inter- face makes it simple to analyze such attributes in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this work, we presented a highly extensible ser- vice architecture that can transform non-factoid answer selection models into fully featured end-to- end question answering systems. Our key contri- bution is the simplification of in-depth analyses of attention-based models to non-factoid answer selec- tion. We enable researchers to interactively explore and understand their models qualitatively. This can help to create more advanced attention mechanisms that achieve better answer selection results. Besides enabling the exploration of individual models, our user interface also allows researchers to compare different attention mechanisms side-by-side within the same view.</p><p>All components of our system are highly mod- ular which allows it to be easily extended with additional functionality. For example, our mod- ular answer retrieval component makes it simple to integrate new datasets, and our answer ranking framework allows researchers to add new models without requiring to change any other part of the application.</p><p>The source-code of all presented components as well as the user interface is publicly available. We provide a documentation for all discussed APIs. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The user interface of our question answering system with the interactive visualization of neural attention weights. The UI includes several options to adapt the attention visualization.</figDesc><graphic url="image-1.png" coords="3,72.00,62.81,453.50,254.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: A side-by-side comparison of two different attention-based models. It allows the user to quickly spot the differences of the used models and can be used to better analyze their benefits and drawbacks.</figDesc><graphic url="image-2.png" coords="6,72.00,62.81,453.50,219.14" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>The candidate ranking service provides an interface to the attention-based neural network, which the researcher chose to analyze. It provides a method to rank a list of candidate answers according to a given question text. An important property is the</figDesc><table>Dataset 
Candidate Lists with 
Ground-Truth 

InsuranceQA (v1) 
84.1% (13,200/15,687) 
InsuranceQA (v2) 
83.3% (14,072/16,889) 
StackExchange/Travel 
85.8% (13,978/16,294) 
StackExchange/Cooking 88.0% (12,025/13,668) 
StackExchange/Photo 
83.0% (10,856/13,079) 

</table></figure>

			<note place="foot" n="1"> https://github.com/UKPLab/ acl2017-non-factoid-qa</note>

			<note place="foot" n="2"> https://archive.org/details/ stackexchange</note>

			<note place="foot" n="3"> For StackExchange, we consider all answers as correct that have a positive user voting. We only include questions with a positive user voting and at least one correct answer.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work has been supported by the German Re-search Foundation as part of the QA-EduInf project (grant GU 798/18-1 and grant RI 803/12-1). We gratefully acknowledge the support of NVIDIA Corporation with the donation of the Tesla K40 GPU used for this research.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning to Compose Neural Networks for Question Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<idno type="doi">10.18653/v1/N16-1181</idno>
		<ptr target="https://doi.org/10.18653/v1/N16-1181" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1545" to="1554" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Attentive Pooling Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Cicero Dos Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhou</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1602.03609" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Applying deep learning to answer selection: A study and an open task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minwei</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">R</forename><surname>Glass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="doi">10.1109/ASRU.2015.7404872</idno>
		<ptr target="https://doi.org/10.1109/ASRU.2015.7404872" />
	</analytic>
	<monogr>
		<title level="m">2015 IEEE Workshop on Automatic Speech Recognition and Understanding</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="813" to="820" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Teaching machines to read</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Moritz Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomáš</forename><surname>Kočisk´kočisk´y</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lasse</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><surname>Suleyman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning to rank answers to non-factoid questions from web collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimiliano</forename><surname>Ciaramita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Zaragoza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Improved representation learning for question answer matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Cicero Dos Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhou</surname></persName>
		</author>
		<idno type="doi">10.18653/v1/P16-1044</idno>
		<ptr target="https://doi.org/10.18653/v1/P16-1044" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="464" to="473" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Modeling Coverage for Neural Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<idno type="doi">10.1145/2856767.2856776</idno>
		<ptr target="https://doi.org/10.1145/2856767.2856776" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational</title>
		<meeting>the 54th Annual Meeting of the Association for Computational</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="76" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Inner attention based recurrent neural networks for answer selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingning</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="doi">10.18653/v1/P16-1122</idno>
		<ptr target="https://doi.org/10.18653/v1/P16-1122" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1288" to="1297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Aaron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
		<idno type="doi">10.1109/72.279181</idno>
		<ptr target="https://doi.org/10.1109/72.279181" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 32nd International Conference on Machine Learning</title>
		<meeting>The 32nd International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2048" to="2057" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Abcnn: Attention-based convolutional neural network for modeling sentence pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Wenpeng Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Schütze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association of Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="259" to="272" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
