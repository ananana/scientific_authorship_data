<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:21+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Did the Model Understand the Question?</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 15-20, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pramod</forename><forename type="middle">K</forename><surname>Mudrakarta</surname></persName>
							<email>pramodkm@uchicago.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Kedar Dhamdhere Google</orgName>
								<orgName type="institution">University of Chicago</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><forename type="middle">Taly</forename><surname>Google</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Kedar Dhamdhere Google</orgName>
								<orgName type="institution">University of Chicago</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brain</forename><surname>Mukund</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Kedar Dhamdhere Google</orgName>
								<orgName type="institution">University of Chicago</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sundararajan</forename><surname>Google</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Kedar Dhamdhere Google</orgName>
								<orgName type="institution">University of Chicago</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Did the Model Understand the Question?</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1896" to="1906"/>
							<date type="published">July 15-20, 2018. 2018</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We analyze state-of-the-art deep learning models for three tasks: question answering on (1) images, (2) tables, and (3) passages of text. Using the notion of at-tribution (word importance), we find that these deep networks often ignore important question terms. Leveraging such behavior , we perturb questions to craft a variety of adversarial examples. Our strongest attacks drop the accuracy of a visual question answering model from 61.1% to 19%, and that of a tabular question answering model from 33.5% to 3.3%. Additionally, we show how attributions can strengthen attacks proposed by Jia and Liang (2017) on paragraph comprehension models. Our results demonstrate that attributions can augment standard measures of accuracy and empower investigation of model performance. When a model is accurate but for the wrong reasons, attributions can surface erroneous logic in the model that indicates inadequacies in the test data.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recently, deep learning has been applied to a va- riety of question answering tasks. For instance, to answer questions about images (e.g. ( <ref type="bibr" target="#b12">Kazemi and Elqursh, 2017)</ref>), tabular data (e.g. <ref type="bibr" target="#b16">(Neelakantan et al., 2017)</ref>), and passages of text (e.g. ( <ref type="bibr" target="#b29">Yu et al., 2018)</ref>). Developers, end-users, and review- ers (in academia) would all like to understand the capabilities of these models.</p><p>The standard way of measuring the goodness of a system is to evaluate its error on a test set. High accuracy is indicative of a good model only if the test set is representative of the underlying real- world task. Most tasks have large test and training sets, and it is hard to manually check that they are representative of the real world.</p><p>In this paper, we propose techniques to analyze the sensitivity of a deep learning model to ques- tion words. We do this by applying attribution (as discussed in section 3), and generating adversar- ial questions. Here is an illustrative example: re- call Visual Question Answering ( <ref type="bibr" target="#b1">Agrawal et al., 2015)</ref> where the task is to answer questions about images. Consider the question "how symmetrical are the white bricks on either side of the build- ing?" (corresponding image in <ref type="figure" target="#fig_1">Figure 1</ref>). The sys- tem that we study gets the answer right ("very"). But, we find (using an attribution approach) that the system relies on only a few of the words like "how" and "bricks". Indeed, we can construct ad- versarial questions about the same image that the system gets wrong. For instance, "how spherical are the white bricks on either side of the build- ing?" returns the same answer ("very"). A key premise of our work is that most humans have ex- pertise in question answering. Even if they cannot manually check that a dataset is representative of the real world, they can identify important ques- tion words, and anticipate their function in ques- tion answering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Our Contributions</head><p>We follow an analysis workflow to understand three question answering models. There are two steps. First, we apply Integrated Gradients (hence- forth, IG) ( <ref type="bibr" target="#b27">Sundararajan et al., 2017</ref>) to attribute the systems' predictions to words in the questions. We propose visualizations of attributions to make analysis easy. Second, we identify weaknesses (e.g., relying on unimportant words) in the net- works' logic as exposed by the attributions, and leverage them to craft adversarial questions.</p><p>A key contribution of this work is an overstabil- ity test for question answering networks. <ref type="bibr" target="#b10">Jia and Liang (2017)</ref> showed that reading comprehension networks are overly stable to semantics-altering edits to the passage. In this work, we find that such overstability also applies to questions. Fur- thermore, this behavior can be seen in visual and tabular question answering networks as well. We use attributions to a define a general-purpose test for measuring the extent of the overstability (sec- tions 4.3 and 5.3). It involves measuring how a network's accuracy changes as words are system- atically dropped from questions.</p><p>We emphasize that, in contrast to model- independent adversarial techniques such as that of <ref type="bibr" target="#b10">Jia and Liang (2017)</ref>, our method exploits the strengths and weaknesses of the model(s) at hand. This allows our attacks to have a high success rate. Additionally, using insights derived from attribu- tions we were able to improve the attack success rate of Jia and Liang (2017) (section 6.2). Such extensive use of attributions in crafting adversarial examples is novel to the best of our knowledge.</p><p>Next, we provide an overview of our results. In each case, we evaluate a pre-trained model on new inputs. We keep the networks' parameters intact.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Visual QA (section 4): The task is to answer</head><p>questions about images. We analyze the deep net- work in <ref type="bibr" target="#b12">Kazemi and Elqursh (2017)</ref>. We find that the network ignores many question words, rely- ing largely on the image to produce answers. For instance, we show that the model retains more than 50% of its original accuracy even when ev- ery word that is not "color" is deleted from all questions in the validation set. We also show that the model under-relies on important ques- tion words (e.g. nouns) and attaching content- free prefixes (e.g., "in not many words, . . .") to questions drops the accuracy from 61.1% to 19%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>QA on tables (section 5):</head><p>We analyze a sys- tem called Neural Programmer (henceforth, NP) ( <ref type="bibr" target="#b16">Neelakantan et al., 2017</ref>) that answers ques- tions on tabular data. NP determines the answer to a question by selecting a sequence of opera- tions to apply on the accompanying table (akin to an SQL query; details in section 5). We find that these operation selections are more influenced by content-free words (e.g., "in", "at", "the", etc.) in questions than important words such as nouns or adjectives. Dropping all content-free words reduces the validation accuracy of the network from 33.5% 1 to 28.5%. Similar to Visual QA, we</p><p>show that attaching content-free phrases (e.g., "in not a lot of words") to the question drops the net- work's accuracy from 33.5% to 3.3%. We also find that NP often gets the answer right for the wrong reasons. For instance, for the question "which nation earned the most gold medals?", one of the operations selected by NP is "first" <ref type="table">(pick the first row of the table)</ref>. Its answer is right only because the table happens to be arranged in order of rank. We quantify this weakness by eval- uating NP on the set of perturbed tables generated by <ref type="bibr" target="#b19">Pasupat and Liang (2016)</ref> and find that its ac- curacy drops from 33.5% to 23%. Finally, we show an extreme form of overstability where the table itself induces a large bias in the network re- gardless of the question. For instance, we found that in tables about Olympic medal counts, NP was predisposed to selecting the "prev" operator.</p><p>Reading comprehension (Section 6): The task is to answer questions about paragraphs of text. We analyze the network by <ref type="bibr" target="#b29">Yu et al. (2018)</ref>. Again, we find that the network often ignores words that should be important. <ref type="bibr" target="#b10">Jia and Liang (2017)</ref> proposed attacks wherein sentences are added to paragraphs that ought not to change the network's answers, but sometimes do. Our main finding is that these attacks are more likely to succeed when an added sentence includes all the question words that the model found important (for the original paragraph). For instance, we find that attacks are 50% more likely to be successful when the added sentence includes top-attributed nouns in the question. This insight should allow the construction of more successful attacks and better training data sets.</p><p>In summary, we find that all networks ignore important parts of questions. One can fix this by either improving training data, or introducing an inductive bias. Our analysis workflow is helpful in both cases. It would also make sense to expose end-users to attribution visualizations. Knowing which words were ignored, or which operations the words were mapped to, can help the user de- cide whether to trust a system's response.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>We are motivated by <ref type="bibr" target="#b10">Jia and Liang (2017)</ref>. As they discuss, "the extent to which [reading comprehen- sion systems] truly understand language remains unclear". The contrast between Jia and Liang (2017) and our work is instructive. Their main contribution is to fix the evaluation of reading comprehension systems by augmenting the test set with adversarially constructed examples. (As they point out in Section 4.6 of their paper, this does not necessarily fix the model; the model may simply learn to circumvent the specific attack underlying the adversarial examples.) Their method is inde- pendent of the specification of the model at hand. They use crowdsourcing to craft passage perturba- tions intended to fool the network, and then query the network to test their effectiveness.</p><p>In contrast, we propose improving the analy- sis of question answering systems. Our method peeks into the logic of a network to identify high- attribution question terms. Often there are sev- eral important question terms (e.g., nouns, adjec- tives) that receive tiny attribution. We leverage this weakness and perturb questions to craft targeted attacks. While Jia and Liang (2017) focus exclu- sively on systems for the reading comprehension task, we analyze one system each for three differ- ent tasks. Our method also helps improve the ef- ficacy Jia and Liang (2017)'s attacks; see <ref type="table" target="#tab_7">table 4</ref> for examples. Our analysis technique is specific to deep-learning-based systems, whereas theirs is not.</p><p>We could use many other methods instead of Integrated Gradients (IG) to attribute a deep net- work's prediction to its input features ( <ref type="bibr" target="#b2">Baehrens et al., 2010;</ref><ref type="bibr" target="#b25">Simonyan et al., 2013;</ref><ref type="bibr" target="#b24">Shrikumar et al., 2016;</ref><ref type="bibr" target="#b4">Binder et al., 2016;</ref><ref type="bibr" target="#b26">Springenberg et al., 2014</ref>). One could also use model agnos- tic techniques like <ref type="bibr" target="#b23">Ribeiro et al. (2016b)</ref>. We choose IG for its ease and efficiency of imple- mentation (requires just a few gradient-calls) and its axiomatic justification (see <ref type="bibr" target="#b27">Sundararajan et al. (2017)</ref> for a detailed comparison with other attri- bution methods).</p><p>Recently, there have been a number of tech- niques for crafting and defending against adver- sarial attacks on image-based deep learning mod- els (cf. <ref type="bibr" target="#b7">Goodfellow et al. (2015)</ref>). They are based on oversensitivity of models, i.e., tiny, impercepti- ble perturbations of the image to change a model's response. In contrast, our attacks are based on models' over-reliance on few question words even when other words should matter.</p><p>We discuss task-specific related work in corre- sponding sections (sections 4 to 6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Integrated Gradients (IG)</head><p>We employ an attribution technique called Inte- grated Gradients (IG) ( <ref type="bibr" target="#b27">Sundararajan et al., 2017)</ref> to isolate question words that a deep learning sys- tem uses to produce an answer.</p><p>Formally, suppose a function F : R n ! [0, 1] represents a deep network, and an input x = (x 1 , . . . , x n ) 2 R n . An attribution of the predic- tion at input x relative to a baseline input x 0 is a vector A F (x, x 0 ) = (a 1 , . . . , a n ) 2 R n where a i is the contribution of x i to the prediction F (x). One can think of F as the probability of a specific response. x 1 , . . . , x n are the question words; to be precise, they are going to be vector represen- tations of these terms. The attributions a 1 , . . . , a n are the influences/blame-assignments to the vari- ables x 1 , . . . , x n on the probability F .</p><p>Notice that attributions are defined relative to a special, uninformative input called the baseline. In this paper, we use an empty question as the base- line, that is, a sequence of word embeddings cor- responding to padding value. Note that the context (image, table, or passage) of the baseline x 0 is set to be that of x; only the question is set to empty. We now describe how IG produces attributions.</p><p>Intuitively, as we interpolate between the base- line and the input, the prediction moves along a trajectory, from uncertainty to certainty (the final probability). At each point on this trajectory, one can use the gradient of the function F with respect to the input to attribute the change in probability back to the input variables. IG simply aggregates the gradients of the probability with respect to the input along this trajectory using a path integral.</p><p>Definition 1 (Integrated Gradients) Given an input x and baseline x 0 , the integrated gradient along the i th dimension is defined as follows.</p><formula xml:id="formula_0">IG i (x, x 0 ) ::= (x i x 0 i )⇥ Z 1 ↵=0 @F (x 0 +↵⇥(xx 0 )) @x i d↵ (here @F (x) @x i</formula><p>is the gradient of F along the i th di- mension at x). IG satisfies the condition that the attributions sum to the difference between the probabilities at the input and the baseline. We call a variable unin- fluential if all else fixed, varying it does not change the output probability. IG satisfies the property that uninfluential variables do not get any attribu- tion. Conversely, influential variables always get some attribution. Attributions for a linear com- bination of two functions F 1 and F 2 are a lin- ear combination of the attributions for F 1 and F 2 . Finally, IG satisfies the condition that symmetric variables get equal attributions.</p><p>In this work, we validate the use of IG em- pirically via question perturbations. We observe that perturbing high-attribution terms changes the networks' response (sections 4.4 and 5.5). Con- versely, perturbing terms that receive a low attribu- tion does not change the network's response (sec- tions 4.3 and 5.3). We use these observations to craft attacks against the network by perturbing in- stances where generic words (e.g., "a", "the") re- ceive high attribution or contentful words receive low attribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Visual Question Answering</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Task, model, and data</head><p>The Visual Question Answering Task ( <ref type="bibr" target="#b1">Agrawal et al., 2015;</ref><ref type="bibr">Teney et al., 2017;</ref><ref type="bibr" target="#b12">Kazemi and Elqursh, 2017;</ref><ref type="bibr" target="#b3">Ben-younes et al., 2017;</ref><ref type="bibr" target="#b31">Zhu et al., 2016</ref>) requires a system to answer questions about images ( <ref type="figure" target="#fig_1">fig. 1)</ref>. We analyze the deep network from <ref type="bibr" target="#b12">Kazemi and Elqursh (2017)</ref>. It achieves 61.1% accuracy on the validation set (the state of the art ( <ref type="bibr" target="#b6">Fukui et al., 2016</ref>) achieves 66.7%). We chose this model for its easy reproducibility.</p><p>The VQA 1.0 dataset (Agrawal et al., 2015) consists of 614,163 questions posed over 204,721 images (3 questions per image). The images were taken from COCO ( <ref type="bibr" target="#b14">Lin et al., 2014)</ref>, and the ques- tions and answers were crowdsourced.</p><p>The network in <ref type="bibr" target="#b12">Kazemi and Elqursh (2017)</ref> treats question answering as a classification task wherein the classes are 3000 most frequent an- swers in the training data. The input question is tokenized, embedded and fed to a multi-layer LSTM. The states of the LSTM attend to a featur- ized version of the image, and ultimately produce a probability distribution over the answer classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Observations</head><p>We applied IG and attributed the top selected an- swer class to input question words. The base- line for a given input instance is the image and an Question: how symmetrical are the white bricks on either side of the building Prediction: very Ground truth: very empty question 2 . We omit instances where the top answer class predicted by the network remains the same even when the question is emptied (i.e., the baseline input). This is because IG attributions are not informative when the input and the baseline have the same prediction.</p><p>A visualization of the attributions is shown in <ref type="figure" target="#fig_1">fig. 1</ref>. Notice that very few words have high at- tribution. We verified that altering the low at- tribution words in the question does not change the network's answer. For instance, the following questions still return "very" as the answer: "how spherical are the white bricks on either side of the building", "how soon are the bricks fading on ei- ther side of the building", "how fast are the bricks speaking on either side of the building".</p><p>On analyzing attributions across examples, we find that most of the highly attributed words are words such as "there", "what", "how", "doing"- they are usually the less important words in ques- tions. In section 4.3 we describe a test to measure the extent to which the network depends on such words. We also find that informative words in the question (e.g., nouns) often receive very low attri- bution, indicating a weakness on part of the net- work. In Section 4.4, we describe various attacks that exploit this weakness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Overstability test</head><p>To determine the set of question words that the net- work finds most important, we isolate words that most frequently occur as top attributed words in questions. We then drop all words except these and compute the accuracy. <ref type="figure" target="#fig_2">Figure 2</ref> shows how the accuracy changes as the size of this isolated set is varied from 0 to 5305.</p><p>We find that just one word is enough for the model to achieve more than 50% of its final accuracy. That word is "color". Note that even when empty questions are passed as input to the network, its accuracy remains at about 44.3% of its original accuracy. This shows that the model is largely reliant on the image for producing the answer.</p><p>The accuracy increases (almost) monotonically with the size of the isolated set. The top 6 words in the isolated set are "color", "many", "what", "is", "there", and "how". We suspect that generic words like these are used to determine the type of the an- swer. The network then uses the type to choose between a few answers it can give for the image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Attacks</head><p>Attributions reveal that the network relies largely on generic words in answering questions (sec- tion 4.3). This is a weakness in the network's logic. We now describe a few attacks against the network that exploit this weakness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Subject ablation attack</head><p>In this attack, we replace the subject of a ques- tion with a specific noun that consistently receives low attribution across questions. We then deter- mine, among the questions that the network orig- inally answered correctly, what percentage result in the same answer after the ablation. We repeat this process for different nouns; specifically, "fits", "childhood", "copyrights", "mornings", "disor- der", "importance", "topless", "critter", "jumper", "tweet", and average the result.  We find that, among the set of questions that the network originally answered correctly, 75.6% of the questions return the same answer despite the subject replacement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prefix attack</head><p>In this attack, we attach content-free phrases to questions. The phrases are manually crafted us- ing generic words that the network finds impor- tant (section 4.3). <ref type="table" target="#tab_1">Table 1</ref> (top half) shows the resulting accuracy for three prefixes -"in not a lot of words", "what is the answer to", and "in not many words". All of these phrases nearly halve the model's accuracy. The union of the three attacks drops the model's accuracy from 61.1% to 19%.</p><p>We note that the attributions computed for the network were crucial in crafting the prefixes. For instance, we find that other prefixes like "tell me", "answer this" and "answer this for me" do not drop the accuracy by much; see table 1 (bottom half). The union of these three ineffective prefixes drops the accuracy from 61.1% to only 46.9%. Per attributions, words present in these prefixes are not deemed important by the network. <ref type="bibr" target="#b0">Agrawal et al. (2016)</ref> analyze several VQA mod- els. Among other attacks, they test the models on question fragments of telescopically increas- ing length. They observe that VQA models often arrive at the same answer by looking at a small fragment of the question. Our stability analysis in section 4.3 explains, and intuitively subsumes this; indeed, several of the top attributed words appear in the prefix, while important words like "color" often occur in the middle of the ques- tion. Our analysis enables additional attacks, for instance, replacing question subject with low attri-bution nouns. <ref type="bibr" target="#b22">Ribeiro et al. (2016a)</ref> use a model explanation technique to illustrate overstability for two examples. They do not quantify their anal- ysis at scale. <ref type="bibr" target="#b11">Kafle and Kanan (2017)</ref>;  examine the VQA data, identify de- ficiencies, and propose data augmentation to re- duce over-representation of certain question/an- swer types.  propose the VQA 2.0 dataset, which has pairs of similar images that have different answers on the same question. We note that our method can be used to improve these datasets by identifying inputs where models ig- nore several words. <ref type="bibr" target="#b9">Huang et al. (2017)</ref> evalu- ate robustness of VQA models by appending ques- tions with semantically similar questions. Our pre- fix attacks in section 4.4 are in a similar vein and perhaps a more natural and targeted approach. Fi- nally, <ref type="bibr" target="#b5">Fong and Vedaldi (2017)</ref> use saliency meth- ods to produce image perturbations as adversarial examples; our attacks are on the question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Related work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Question Answering over Tables</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Task, model, and data</head><p>We now analyze question answering over ta- bles based on the WikiTableQuestions benchmark dataset <ref type="bibr" target="#b18">(Pasupat and Liang, 2015</ref>  <ref type="bibr" target="#b16">(Neelakantan et al., 2017)</ref>. NP is the state of the art among models that are weakly su- pervised, i.e., supervised using the final answer in- stead of the correct structured program. It achieves 33.5% accuracy on the validation set.</p><p>NP translates the input into a structured pro- gram consisting of four operator and table column selections. An example of such a program is "reset (score), reset (score), min (score), print (name)", where the output is the name of the person who has the lowest score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Observations</head><p>We applied IG to attribute operator and column selection to question words. NP preprocesses inputs and whenever applicable, appends sym- bols tm token, cm token to questions that sig- nify matches between a question and the accom- panying table. These symbols are treated the same as question words. NP also computes priors for column selection using question-table matches. These vectors, tm and cm, are passed as addi- tional inputs to the neural network. In the baseline for IG, we use an empty question, and zero vectors for column selection priors 3 . We visualize the attributions using an alignment matrix; they are commonly used in the analysis of translation models ( <ref type="figure" target="#fig_3">fig. 3)</ref>. Observe that the oper- ator "first" is used when the question is asking for a superlative. Further, we see that the word "gold" is a trigger for this operator. We investigate impli- cations of this behavior in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Overstability test</head><p>Similar to the test we did for Visual QA (sec- tion 4.3), we check for overstability in NP by look- ing at accuracy as a function of the vocabulary size. We treat table match annotations tm token, cm token and the out-of-vocab token (unk ) as part of the vocabulary. The results are in <ref type="figure" target="#fig_4">fig. 4</ref>. We see that the curve is similar to that of Visual QA ( <ref type="figure" target="#fig_2">fig. 2)</ref>. Just 5 words (along with the column se- lection priors) are sufficient for the model to reach more than 50% of its final accuracy on the valida- tion set. These five words are: "many", "number", "tm token", "after", and "total".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Table-specific default programs</head><p>We saw in the previous section that the model re- lies on only a few words in producing correct an- swers. An extreme case of overstability is when Operator sequence # Triggers Insights reset, reset, max, print 109 [unk, date, position, points, name, competition, notes, no, year, venue] sports reset, prev, max, print 68 [unk, rank, total, bronze, gold, silver, nation, name, date, no] medal tallies reset, reset, first, print 29 [name, unk, notes, year, nationality, rank, location, date, comments, hometown] player rankings reset, mfe, first, print 25 [notes, date, title, unk, role, genre, year, score, opponent, event] awards reset, reset, min, print 17 [year, height, unk, name, position, floors, notes, jan, jun, may] building info. reset, mfe, max, print 14 [opponent, date, result, location, rank, site, attendance, notes, city, listing] politics reset, next, first, print 10 [unk, name, year, edition, birth, death, men, time, women, type] census  the operator sequences produced by the model are independent of the question. We find that if we supply an empty question as an input, i.e., the out- put is a function only of the table, then the dis- tribution over programs is quite skewed. We call these programs table-specific default programs. On average, about 36.9% of the selected operators match their table-default counterparts, indicating that the model relies significantly on the table for producing an answer.</p><p>For each default program, we used IG to at- tribute operator and column selections to column names and show ten most frequently occurring ones across tables in the validation set (table 2).</p><p>Here is an insight from this analysis: NP uses the combination "reset, prev" to exclude the last row of the table from answer computation. The de- fault program corresponding to "reset, prev, max, print" has attributions to column names such as "rank", "gold", "silver", "bronze", "nation", "year". These column names indicate medal tal- lies and usually have a "total" row. If the table happens not to have a "total" row, the model may  produce an incorrect answer. We now describe attacks that add or drop content-free words from the question, and cause NP to produce the wrong answer. These attacks leverage the attribution analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Attacks</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question concatenation attacks</head><p>In these attacks, we either suffix or prefix content- free phrases to questions. The phrases are crafted using irrelevant trigger words for operator selec- tions (supplementary material, table 5). We man- ually ensure that the phrases are content-free. <ref type="table" target="#tab_5">Table 3</ref> describes our results. The first 4 phrases use irrelevant trigger words and result in a large drop in accuracy. For instance, the first phrase uses "not" which is a trigger for "next", "last", and "min", and the second uses "same" which is a trig- ger for "next" and "mfe". The four phrases com- bined results in the model's accuracy going down from 33.5% to 3.3%. The first two phrases alone drop the accuracy to 5.6%.</p><p>The next set of phrases use words that receive low attribution across questions, and are hence non-triggers for any operator. The resulting drop in accuracy on using these phrases is relatively low. Combined, they result in the model's accu- racy dropping from 33.5% to 27.1%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stop word deletion attacks</head><p>We find that sometimes an operator is selected based on stop words like: "a", "at", "the", etc. For instance, in the question, "what ethnicity is at the top?", the operator "next" is triggered on the word "at". Dropping the word "at" from the question changes the operator selection and causes NP to return the wrong answer.</p><p>We drop stop words from questions in the val- idation dataset that were originally answered cor- rectly and test NP on them. The stop words to be dropped were manually selected 4 and are shown in <ref type="figure">Figure 5</ref> in the supplementary material.</p><p>By dropping stop words, the accuracy drops from 33.5% to 28.5%. Selecting operators based on stop words is not robust. In real world search queries, users often phrase questions without stop words, trading grammatical correctness for con- ciseness. For instance, the user may simply say "top ethnicity". It may be possible to defend against such examples by generating synthetic training data, and re-training the network on it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Row reordering attacks</head><p>We found that NP often got the question right by leveraging artifacts of the table. For instance, the operators for the question "which nation earned the most gold medals" are "reset", "prev", "first" and "print". The "prev" operator essentially ex- cludes the last row from the answer computation. It gets the answer right for two reasons: (1) the an- swer is not in the last row, and (2) rows are sorted by the values in the column "gold".</p><p>In general, a question answering system should not rely on row ordering in tables. To quantify the extent of such biases, we used a perturbed ver- sion of WikiTableQuestions validation dataset as described in <ref type="bibr" target="#b19">Pasupat and Liang (2016)</ref>  <ref type="bibr">5</ref> and eval- uated the existing NP model on it (there was no re-training involved here). We found that NP has only 23% accuracy on it, in constrast to an accu- racy of 33.5% on the original validation dataset.</p><p>One approach to making the network robust to row-reordering attacks is to train against perturbed tables. This may also help the model generalize better. Indeed, <ref type="bibr" target="#b15">Mudrakarta et al. (2018)</ref> note that the state-of-the-art strongly supervised 6 model on WikiTableQuestions ( <ref type="bibr" target="#b13">Krishnamurthy et al., 2017</ref>) enjoys a 7% gain in its final accuracy by leverag- ing perturbed tables during training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Reading Comprehension</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Task, model, and data</head><p>The reading comprehension task involves identi- fying a span from a context paragraph as an an- swer to a question. The SQuAD dataset <ref type="bibr" target="#b21">(Rajpurkar et al., 2016</ref>) for machine reading com- prehension contains 107.7K query-answer pairs, with 87.5K for training, 10.1K for validation, and another 10.1K for testing. Deep learning meth- ods are quite successful on this problem, with the state-of-the-art F1 score at 84.6 achieved by <ref type="bibr" target="#b29">Yu et al. (2018)</ref>; we analyze their model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Analyzing adversarial examples</head><p>Recall the adversarial attacks proposed by Jia and Liang (2017) for reading comprehension systems. Their attack ADDSENT appends sentences to the paragraph that resemble an answer to the question without changing the ground truth. See the second column of table 4 for a few examples.</p><p>We investigate the effectiveness of their attacks using attributions. We analyze 100 examples gen- erated by the ADDSENT method in <ref type="bibr" target="#b10">Jia and Liang (2017)</ref>, and find that an adversarial sentence is successful in fooling the model in two cases:</p><p>First, a contentful word in the question gets low/zero attribution and the adversarially added sentence modifies that word. E.g. in the question, "Who did Kubiak take the place of after Super Bowl XXIV?", the word "Super" gets low attribu- tion. Adding "After Champ Bowl XXV, Crowton took the place of Jeff Dean" changes the prediction for the model. Second, a contentful word in the question that is not present in the context. For e.g. in the question "Where hotel did the Panthers stay at?", "hotel", is not present in the context. Adding "The Vikings stayed at Chicago hotel." changes the prediction for the model.</p><p>On the flip side, an adversarial sentence is un- successful when a contentful word in the question having high attribution is not present in the added sentence. E.g. for "Where according to gross state product does Victoria rank in Australia?", "Aus- tralia" receives high attribution. Adding "Accord-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question</head><p>ADDSENT attack that does not work Attack that works Who was Count of Melfi Jeff Dean was the mayor of Bracco. Jeff Dean was the mayor of Melfi.</p><p>What country was Abhisit Vejjajiva prime minister of , despite having been born in Newcastle ?</p><p>Samak Samak was prime minister of the country of Chicago, despite hav- ing been born in Leeds.</p><p>Abhisit Vejjajiva was chief minister of the country of Chicago, despite having been born in Leeds.</p><p>Where  <ref type="table" target="#tab_7">Table 4</ref>: ADDSENT attacks that failed to fool the model. With modifications to preserve nouns with high attributions, these are successful in fooling the model. Question words that receive high attribution are colored red (intensity indicates magnitude).</p><p>ing to net state product, Adelaide ranks 7 in New Zealand." does not fool the model. However, retaining "Australia" in the adversarial sentence does change the model's prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Predicting the effectiveness of attacks</head><p>Next we correlate attributions with efficacy of the ADDSENT attacks. We analyzed 1000 (question, attack phrase) instances 7 where <ref type="bibr" target="#b29">Yu et al. (2018)</ref> model has the correct baseline prediction. Of the 1000 cases, 508 are able to fool the model, while 492 are not. We split the examples into two groups. The first group has examples where a noun or adjective in the question has high attribu- tion, but is missing from the adversarial sentence and the rest are in the second group. Our attri- bution analysis suggests that we should find more failed examples in the first group. That is indeed the case. The first group has 63% failed examples, while the second has only 40%.</p><p>Recall that the attack sentences were con- structed by (a) generating a sentence that answers the question, (b) replacing all the adjectives and nouns with antonyms, and named entities by the nearest word in GloVe word vector space <ref type="bibr" target="#b20">(Pennington et al., 2014</ref>) and (c) crowdsourcing to check that the new sentence is grammatically cor- rect. This suggests a use of attributions to improve the effectiveness of the attacks, namely ensuring that question words that the model thinks are im- portant are left untouched in step (b) (we note that other changes in should be carried out). In we show a few examples where an original attack did not fool the model, but preserving a noun with high attribution did.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We analyzed three question answering models us- ing an attribution technique. Attributions helped us identify weaknesses of these models more ef- fectively than conventional methods (based on val- idation sets). We believe that a workflow that uses attributions can aid the developer in iterating on model quality more effectively.</p><p>While the attacks in this paper may seem un- realistic, they do expose real weaknesses that af- fect the usage of a QA product. Under-reliance on important question terms is not safe. We also be- lieve that other QA models may share these weak- nesses. Our attribution-based methods can be di- rectly used to gauge the extent of such problems. Additionally, our perturbation attacks (sections 4.4 and 5.5) serve as empirical validation of attribu- tions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reproducibility</head><p>Code to generate attributions and reproduce our results is freely available at https://github. com/pramodkaushik/acl18_results.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Sundararajan et al. (2017) discuss several prop- erties of IG. Here, we informally mention a few desirable ones, deferring the reader to Sundarara- jan et al. (2017) for formal definitions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Visual QA (Kazemi and Elqursh, 2017): Visualization of attributions (word importances) for a question that the network gets right. Red indicates high attribution, blue negative attribution, and gray near-zero attribution. The colors are determined by attributions normalized w.r.t the maximum magnitude of attributions among the question's words.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: VQA network (Kazemi and Elqursh, 2017): Accuracy as a function of vocabulary size, relative to its original accuracy. Words are chosen in the descending order of how frequently they appear as top attributions. The X-axis is on logscale, except near zero where it is linear.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Visualization of attributions. Question words, preprocessing tokens and column selection priors on the Yaxis. Along the X-axis are operator and column selections with their baseline counterparts in parentheses. Operators and columns not affecting the final answer, and those which are same as their baseline counterparts, are given zero attribution.</figDesc><graphic url="image-2.png" coords="6,307.28,169.95,218.27,136.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Accuracy as a function of vocabulary size. The words are chosen in the descending order of their frequency appearance as top attributions to question terms. The X-axis is on logscale, except near zero where it is linear. Note that just 5 words are necessary for the network to reach more than 50% of its final accuracy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>VQA network (Kazemi and Elqursh, 2017): Ac-

curacy for prefix attacks; original accuracy is 61.1%. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head></head><label></label><figDesc>). The dataset has 22033 questions posed over 2108 tables scraped from Wikipedia. Answers are either contents of ta- ble cells or some table aggregations. Models per- forming QA on tables translate the question into a structured program (akin to an SQL query) which is then executed on the table to produce the an- swer. We analyze a model called Neural Program- mer (NP)</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Attributions to column names for table-specific default programs (programs returned by NP on empty input ques-

tions). See supplementary material, table 6 for the full list. These results are indication that the network is predisposed towards 
picking certain operators solely based on the table. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Neural Programmer (Neelakantan et al., 2017): 

Left: Validation accuracy when attack phrases are concate-
nated to the question. (Original: 33.5%) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>table 4 ,</head><label>4</label><figDesc></figDesc><table>7 data 
sourced 
from 
https:// 
worksheets.codalab.org/worksheets/ 
0xc86d3ebe69a3427d91f9aaa63f7d1e7d/ 

</table></figure>

			<note place="foot" n="1"> This is the single-model accuracy that we obtained on training the Neural Programmer network. The accuracy reported in the paper is 34.1%.</note>

			<note place="foot" n="2"> We do not black out the image in our baseline as our objective is to study the influence of just the question words for a given image</note>

			<note place="foot" n="3"> Note that the table is left intact in the baseline</note>

			<note place="foot" n="4"> We avoided standard stop word lists (e.g. NLTK) as they contain contentful words (e.g &quot;after&quot;) which may be important in some questions (e.g. &quot;who ranked right after turkey?&quot;) 5 based on data at https://nlp.stanford.edu/ software/sempre/wikitable/dpd/</note>

			<note place="foot" n="6"> supervised on the structured program</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the anonymous reviewers and Kevin Gimpel for feedback on our work, and David Do-han for helping with the reading comprehension network. We are grateful to JiříJiříˇJiříŠimša for helpful comments on drafts of this paper.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Analyzing the behavior of visual question answering models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aishwarya</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.07356</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aishwarya</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiasen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislaw</forename><surname>Antol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.00468</idno>
		<title level="m">Vqa: Visual question answering</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">How to explain individual classification decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Baehrens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timon</forename><surname>Schroeter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Harmeling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Motoaki</forename><surname>Kawanabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katja</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klausrobert</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="page" from="1803" to="1831" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Mutan: Multimodal tucker fusion for visual question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hedi</forename><surname>Ben-Younes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rémi</forename><surname>Cadene</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Thome</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.06676</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Layer-wise relevance propagation for neural networks with local renormalization layers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grégoire</forename><surname>Montavon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus-Robert</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Samek</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Interpretable explanations of black boxes by meaningful perturbation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ruth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Fong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3429" to="3437" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akira</forename><surname>Fukui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><forename type="middle">Huk</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daylen</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.01847</idno>
		<title level="m">Multimodal compact bilinear pooling for visual question answering and visual grounding</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Explaining and harnessing adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Making the v in vqa matter: Elevating the role of image understanding in visual question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yash</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tejas</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><surname>Summers-Stay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.00837</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">A novel framework for robustness analysis of visual qa models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Hong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cuong</forename><forename type="middle">Duc</forename><surname>Dao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Modar</forename><surname>Alfadly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernard</forename><surname>Ghanem</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.06232</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Adversarial examples for evaluating reading comprehension systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark, Septem</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="9" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">An analysis of visual question answering algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kushal</forename><surname>Kafle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Kanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1983" to="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Show, ask, attend, and answer: A strong baseline for visual question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vahid</forename><surname>Kazemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Elqursh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.03162</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Neural semantic parsing with type constraints for semi-structured tables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jayant</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pradeep</forename><surname>Dasigi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1516" to="1526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><surname>Pramod Kaushik Mudrakarta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mukund</forename><surname>Taly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kedar</forename><surname>Sundararajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dhamdhere</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.04579</idno>
		<title level="m">It was the training data pruning too! arXiv preprint</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Learning a natural language interface with neural programmer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martín</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Amodei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Neural programmer: Inducing latent programs with gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations ICLR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Compositional semantic parsing on semi-structured tables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panupong</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panupong</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.06900</idno>
		<title level="m">Inferring logical forms from denotations</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-10-25" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
	<note>A meeting of SIGDAT, a Special Interest Group of the ACL</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Squad: 100, 000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-11-01" />
			<biblScope unit="page" from="2383" to="2392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Nothing else matters: modelagnostic explanations by identifying prediction invariance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Marco Tulio Ribeiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guestrin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.05817</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Why should i trust you?: Explaining the predictions of any classifier</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Marco Tulio Ribeiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1135" to="1144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Not just a black box: Learning important features through propagating activation differences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avanti</forename><surname>Shrikumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peyton</forename><surname>Greenside</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Shcherbina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anshul</forename><surname>Kundaje</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Deep inside convolutional networks: Visualising image classification models and saliency maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Striving for simplicity: The all convolutional net</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jost</forename><surname>Tobias Springenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><forename type="middle">A</forename><surname>Riedmiller</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Axiomatic attribution for deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mukund</forename><surname>Sundararajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><surname>Taly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiqi</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning<address><addrLine>Sydney, NSW</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-08-11" />
			<biblScope unit="page" from="3319" to="3328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Xiaodong He, and Anton van den Hengel. 2017. Tips and tricks for visual question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Damien</forename><surname>Teney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Anderson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.02711</idno>
	</analytic>
	<monogr>
		<title level="m">Learnings from the 2017 challenge</title>
		<imprint/>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Fast and accurate reading comprehension by combining self-attention and convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adams</forename><forename type="middle">Wei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Yin and yang: Balancing and answering binary visual questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yash</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><surname>Summers-Stay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2016 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="5014" to="5022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Visual7w: Grounded question answering in images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuke</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Groth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Feifei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4995" to="5004" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
