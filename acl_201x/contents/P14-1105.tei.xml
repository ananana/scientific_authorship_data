<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:23+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Political Ideology Detection Using Recursive Neural Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>June 23-25 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Maryland</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Enns</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Maryland</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Boyd-Graber</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Maryland</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
							<email>resnik@umd.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Maryland</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Science</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Maryland</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Linguistics</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Maryland</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Umiacs</forename></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Maryland</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Political Ideology Detection Using Recursive Neural Networks</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1113" to="1122"/>
							<date type="published">June 23-25 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>An individual&apos;s words often reveal their political ideology. Existing automated techniques to identify ideology from text focus on bags of words or wordlists, ignoring syntax. Taking inspiration from recent work in sentiment analysis that successfully models the compositional aspect of language, we apply a recursive neural network (RNN) framework to the task of identifying the political position evinced by a sentence. To show the importance of modeling subsen-tential elements, we crowdsource political annotations at a phrase and sentence level. Our model outperforms existing models on our newly annotated dataset and an existing dataset.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Many of the issues discussed by politicians and the media are so nuanced that even word choice entails choosing an ideological position. For ex- ample, what liberals call the "estate tax" conser- vatives call the "death tax"; there are no ideolog- ically neutral alternatives <ref type="bibr" target="#b13">(Lakoff, 2002</ref>). While objectivity remains an important principle of jour- nalistic professionalism, scholars and watchdog groups claim that the media are biased ( <ref type="bibr" target="#b9">Groseclose and Milyo, 2005;</ref><ref type="bibr" target="#b5">Gentzkow and Shapiro, 2010;</ref><ref type="bibr" target="#b17">Niven, 2003)</ref>, backing up their assertions by pub- lishing examples of obviously biased articles on their websites. Whether or not it reflects an under- lying lack of objectivity, quantitative changes in the popular framing of an issue over time-favoring one ideologically-based position over another-can have a substantial effect on the evolution of policy ( <ref type="bibr" target="#b4">Dardis et al., 2008)</ref>.</p><p>Manually identifying ideological bias in polit- ical text, especially in the age of big data, is an impractical and expensive process. Moreover, bias They dubbed it the death tax "</p><p>" and created a big lie about its adverse effects on small businesses <ref type="figure" target="#fig_3">Figure 1</ref>: An example of compositionality in ideo- logical bias detection (red → conservative, blue → liberal, gray → neutral) in which modifier phrases and punctuation cause polarity switches at higher levels of the parse tree.</p><p>may be localized to a small portion of a document, undetectable by coarse-grained methods. In this pa- per, we examine the problem of detecting ideologi- cal bias on the sentence level. We say a sentence contains ideological bias if its author's political position (here liberal or conservative, in the sense of U.S. politics) is evident from the text.</p><p>Ideological bias is difficult to detect, even for humans-the task relies not only on political knowledge but also on the annotator's ability to pick up on subtle elements of language use. For example, the sentence in <ref type="figure" target="#fig_3">Figure 1</ref> includes phrases typically associated with conservatives, such as "small businesses" and "death tax". When we take more of the structure into account, however, we find that scare quotes and a negative propositional attitude (a lie about X) yield an evident liberal bias.</p><p>Existing approaches toward bias detection have not gone far beyond "bag of words" classifiers, thus ignoring richer linguistic context of this kind and often operating at the level of whole documents. In contrast, recent work in sentiment analysis has used deep learning to discover compositional ef- fects ( <ref type="bibr" target="#b25">Socher et al., 2011b;</ref><ref type="bibr" target="#b27">Socher et al., 2013b)</ref>.</p><p>Building from those insights, we introduce a re- cursive neural network (RNN) to detect ideological bias on the sentence level. This model requires w b = change w a = climate w d = so-called p c = climate change p e = so-called climate change <ref type="figure">Figure 2</ref>: An example RNN for the phrase "so- called climate change". Two d-dimensional word vectors (here, d = 6) are composed to generate a phrase vector of the same dimensionality, which can then be recursively used to generate vectors at higher-level nodes.</p><formula xml:id="formula_0">x d = x c = x e = x a = x b = W L W R W R W L</formula><p>richer data than currently available, so we develop a new political ideology dataset annotated at the phrase level. With this new dataset we show that RNNs not only label sentences well but also im- prove further when given additional phrase-level annotations. RNNs are quantitatively more effec- tive than existing methods that use syntactic and semantic features separately, and we also illustrate how our model correctly identifies ideological bias in complex syntactic constructions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Recursive Neural Networks</head><p>Recursive neural networks (RNNs) are machine learning models that capture syntactic and semantic composition. They have achieved state-of-the-art performance on a variety of sentence-level NLP tasks, including sentiment analysis, paraphrase <ref type="bibr">detection, and parsing (Socher et al., 2011a;</ref><ref type="bibr">Hermann and Blunsom, 2013)</ref>. RNN models represent a shift from previous research on ideological bias detec- tion in that they do not rely on hand-made lexicons, dictionaries, or rule sets. In this section, we de- scribe a supervised RNN model for bias detection and highlight differences from previous work in training procedure and initialization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Model Description</head><p>By taking into account the hierarchical nature of language, RNNs can model semantic composition, which is the principle that a phrase's meaning is a combination of the meaning of the words within that phrase and the syntax that combines those words. While semantic composition does not ap- ply universally (e.g., sarcasm and idioms), most language follows this principle. Since most ide- ological bias becomes identifiable only at higher levels of sentence trees (as verified by our annota- tion, <ref type="figure">Figure 4</ref>), models relying primarily on word- level distributional statistics are not desirable for our problem.</p><p>The basic idea behind the standard RNN model is that each word w in a sentence is associated with a vector representation x w ∈ R d . Based on a parse tree, these words form phrases p <ref type="figure">(Figure 2)</ref>. Each of these phrases also has an associated vector x p ∈ R d of the same dimension as the word vectors. These phrase vectors should represent the meaning of the phrases composed of individual words. As phrases themselves merge into complete sentences, the underlying vector representation is trained to retain the sentence's whole meaning.</p><p>The challenge is to describe how vectors com- bine to form complete representations. If two words w a and w b merge to form phrase p, we posit that the phrase-level vector is</p><formula xml:id="formula_1">x p = f (W L · x a + W R · x b + b 1 ),<label>(1)</label></formula><p>where W L and W R are d × d left and right com- position matrices shared across all nodes in the tree, b 1 is a bias term, and f is a nonlinear activa- tion function such as tanh. The word-level vectors x a and x b come from a d × V dimensional word embedding matrix W e , where V is the size of the vocabulary.</p><p>We are interested in learning representations that can distinguish political polarities given labeled data. If an element of this vector space, x d , repre- sents a sentence with liberal bias, its vector should be distinct from the vector x r of a conservative- leaning sentence.</p><p>Supervised RNNs achieve this distinction by ap- plying a regression that takes the node's vector x p as input and produces a predictionˆypredictionˆ predictionˆy p . This is a softmax layerˆy</p><formula xml:id="formula_2">layerˆ layerˆy d = softmax(W cat · x p + b 2 ),<label>(2)</label></formula><p>where the softmax function is</p><formula xml:id="formula_3">softmax(q) = exp q k j=1 exp q j (3)</formula><p>and W cat is a k × d matrix for a dataset with k- dimensional labels.</p><p>We want the predictions of the softmax layer to match our annotated data; the discrepancy between categorical predictions and annotations is measured through the cross-entropy loss. We optimize the model parameters to minimize the cross-entropy loss over all sentences in the corpus. The cross- entropy loss of a single sentence is the sum over the true labels y i in the sentence,</p><formula xml:id="formula_4">(ˆ y s ) = k p=1 y p * log(ˆ y p ).<label>(4)</label></formula><p>This induces a supervised objective function over all sentences: a regularized sum over all node losses normalized by the number of nodes N in the training set,</p><formula xml:id="formula_5">C = 1 N N i (pred i ) + λ 2 θ 2 .<label>(5)</label></formula><p>We use L-BFGS with parameter averag- ing ( <ref type="bibr" target="#b11">Hashimoto et al., 2013</ref>) to optimize the model</p><formula xml:id="formula_6">parameters θ = (W L , W R , W cat , W e , b 1 , b 2 ).</formula><p>The gradient of the objective, shown in Eq. <ref type="formula" target="#formula_7">(6)</ref>, is computed using backpropagation through struc- ture <ref type="bibr" target="#b7">(Goller and Kuchler, 1996)</ref>,</p><formula xml:id="formula_7">∂C ∂θ = 1 N N i ∂(ˆ y i ) ∂θ + λθ.<label>(6)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Initialization</head><p>When initializing our model, we have two choices: we can initialize all of our parameters randomly or provide the model some prior knowledge. As we see in Section 4, these choices have a significant effect on final performance.</p><p>Random The most straightforward choice is to initialize the word embedding matrix W e and com- position matrices W L and W R randomly such that without any training, representations for words and phrases are arbitrarily projected into the vector space.</p><p>word2vec The other alternative is to initialize the word embedding matrix W e with values that reflect the meanings of the associated word types. This improves the performance of RNN models over ran- dom initializations <ref type="bibr" target="#b3">(Collobert and Weston, 2008;</ref><ref type="bibr" target="#b24">Socher et al., 2011a)</ref>. We initialize our model with 300-dimensional word2vec toolkit vectors gener- ated by a continuous skip-gram model trained on around 100 billion words from the Google News corpus ( <ref type="bibr" target="#b15">Mikolov et al., 2013)</ref>. The word2vec embeddings have linear relation- ships (e.g., the closest vectors to the average of "green" and "energy" include phrases such as "re- newable energy", "eco-friendly", and "efficient lightbulbs"). To preserve these relationships as phrases are formed in our sentences, we initialize our left and right composition matrices such that parent vector p is computed by taking the average of children a and b (W L = W R = 0.5I d×d ). This initialization of the composition matrices has pre- viously been effective for parsing <ref type="bibr" target="#b26">(Socher et al., 2013a</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Datasets</head><p>We performed initial experiments on a dataset of Congressional debates that has annotations on the author level for partisanship, not ideology. While the two terms are highly correlated (e.g., a member of the Republican party likely agrees with conserva- tive stances on most issues), they are not identical. For example, a moderate Republican might agree with the liberal position on increased gun control but take conservative positions on other issues. To avoid conflating partisanship and ideology we cre- ate a new dataset annotated for ideological bias on the sentence and phrase level. In this section we describe our initial dataset (Convote) and explain the procedure we followed for creating our new dataset (IBC). <ref type="bibr">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Convote</head><p>The Convote dataset ( <ref type="bibr" target="#b28">Thomas et al., 2006</ref>) con- sists of US Congressional floor debate transcripts from 2005 in which all speakers have been labeled with their political party (Democrat, Republican, or independent). We propagate party labels down from the speaker to all of their individual sentences and map from party label to ideology label (Demo- crat → liberal, Republican → conservative). This is an expedient choice; in future work we plan to make use of work in political science characteriz- ing candidates' ideological positions empirically based on their behavior ( <ref type="bibr" target="#b2">Carroll et al., 2009)</ref>.</p><p>While the Convote dataset has seen widespread use for document-level political classification, we are unaware of similar efforts at the sentence level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Biased Sentence Selection</head><p>The strong correlation between US political parties and political ideologies (Democrats with liberal, Republicans with conservative) lends confidence that this dataset contains a rich mix of ideological statements. However, the raw Convote dataset con- tains a low percentage of sentences with explicit ideological bias. <ref type="bibr">2</ref> We therefore use the features in <ref type="bibr" target="#b31">Yano et al. (2010)</ref>, which correlate with politi- cal bias, to select sentences to annotate that have a higher likelihood of containing bias. Their fea- tures come from the Linguistic Inquiry and Word Count lexicon (LIWC) ( <ref type="bibr" target="#b19">Pennebaker et al., 2001</ref>), as well as from lists of "sticky bigrams" <ref type="bibr" target="#b1">(Brown et al., 1992</ref>) strongly associated with one party or another (e.g., "illegal aliens" implies conservative, "universal healthcare" implies liberal).</p><p>We first extract the subset of sentences that con- tains any words in the LIWC categories of Negative Emotion, Positive Emotion, Causation, Anger, and Kill verbs. <ref type="bibr">3</ref> After computing a list of the top 100 sticky bigrams for each category, ranked by log- likelihood ratio, and selecting another subset from the original data that included only sentences con- taining at least one sticky bigram, we take the union of the two subsets. Finally, we balance the resulting dataset so that it contains an equal number of sen- tences from Democrats and Republicans, leaving us with a total of 7,816 sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Ideological Books</head><p>In addition to Convote, we use the Ideologi- cal Books Corpus (IBC) developed by . This is a collection of books and maga- zine articles written between 2008 and 2012 by au- thors with well-known political leanings. Each doc- ument in the IBC has been manually labeled with coarse-grained ideologies (right, left, and center) as well as fine-grained ideologies (e.g., religious-right, libertarian-right) by political science experts.</p><p>There are over a million sentences in the IBC, most of which have no noticeable political bias. Therefore we use the filtering procedure outlined in Section 3.1.1 to obtain a subset of 55,932 sen- tences. Compared to our final Convote dataset, an even larger percentage of the IBC sentences exhibit no noticeable political bias. <ref type="bibr">4</ref> Because our goal is to distinguish between liberal and conservative 2 Many sentences in Convote are variations on "I think this is a good/bad bill", and there is also substantial parliamentary boilerplate language.</p><p>3 While Kill verbs are not a category in LIWC, <ref type="bibr" target="#b31">Yano et al. (2010)</ref> adopted it from <ref type="bibr" target="#b8">Greene and Resnik (2009)</ref> and showed it to be a useful predictor of political bias. It includes words such as "slaughter" and "starve". <ref type="bibr">4</ref> This difference can be mainly attributed to a historical topics in the IBC (e.g., the Crusades, American Civil War). In Convote, every sentence is part of a debate about 2005 political policy. bias, instead of the more general task of classify- ing sentences as "neutral" or "biased", we filter the dataset further using DUALIST <ref type="bibr" target="#b22">(Settles, 2011)</ref>, an active learning tool, to reduce the proportion of neutral sentences in our dataset. To train the DUALIST classifier, we manually assigned class la- bels of "neutral" or "biased" to 200 sentences, and selected typical partisan unigrams to represent the "biased" class. DUALIST labels 11,555 sentences as politically biased, 5,434 of which come from con- servative authors and 6,121 of which come from liberal authors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Annotating the IBC</head><p>For purposes of annotation, we define the task of political ideology detection as identifying, if pos- sible, the political position of a given sentence's author, where position is either liberal or conser- vative. <ref type="bibr">5</ref> We used the Crowdflower crowdsourcing platform (crowdflower.com), which has previously been used for subsentential sentiment annotation ( <ref type="bibr" target="#b21">Sayeed et al., 2012)</ref>, to obtain human annotations of the filtered IBC dataset for political bias on both the sentence and phrase level. While members of the Crowdflower workforce are certainly not ex- perts in political science, our simple task and the ubiquity of political bias allows us to acquire useful annotations.</p><p>Crowdflower Task First, we parse the filtered IBC sentences using the Stanford constituency parser ( <ref type="bibr" target="#b26">Socher et al., 2013a</ref>). Because of the ex- pense of labeling every node in a sentence, we only label one path in each sentence. The process for selecting paths is as follows: first, if any paths contain one of the top-ten partisan unigrams, <ref type="bibr">6</ref> we select the longest such path; otherwise, we select the path with the most open class constituencies (NP, VP, ADJP). The root node of a sentence is always included in a path.</p><p>Our task is shown in <ref type="figure" target="#fig_0">Figure 3</ref>. Open class con- stituencies are revealed to the worker incrementally, starting with the NP, VP, or ADJP furthest from the root and progressing up the tree. We choose this design to prevent workers from changing their lower-level phrase annotations after reading the full sentence.</p><p>Filtering the Workforce To ensure our anno- tators have a basic understanding of US politics, we restrict workers to US IP addresses and require workers manually annotate one node from 60 dif- ferent "gold " paths annotated by the authors. We select these nodes such that the associated phrase is either obviously biased or obviously neutral. Work- ers must correctly annotate at least six of eight gold paths before they are granted access to the full task. In addition, workers must maintain 75% accu- racy on gold paths that randomly appear alongside normal paths. Gold paths dramatically improve the quality of our workforce: 60% of contributors passed the initial quiz (the 40% that failed were barred from working on the task), while only 10% of workers who passed the quiz were kicked out for mislabeling subsequent gold paths.</p><p>Annotation Results Workers receive the following instructions:</p><p>Each task on this page contains a set of phrases from a single sentence. For each phrase, decide whether or not the author fa- vors a political position to the left (Liberal) or right (Conservative) of center.</p><p>• If the phrase is indicative of a position to the left of center, please choose Liberal.</p><p>• If the phrase is indicative of a position to the right of center, please choose Conser- vative.</p><p>• If you feel like the phrase indicates some position to the left or right of the political center, but you're not sure which direc- tion, please mark Not neutral, but I'm unsure of which direction.</p><p>• If the phrase is not indicative of a posi- tion to the left or right of center, please mark Neutral.</p><p>We had workers annotate 7,000 randomly se- lected paths from the filtered IBC dataset, with half of the paths coming from conservative authors and the other half from liberal authors, as annotated by . Three workers annotated each path in the dataset, and we paid $0.03 per sentence. Since identifying political bias is a rela- tively difficult and subjective task, we include all sentences where at least two workers agree on a label for the root node in our final dataset, except when that label is "Not neutral, but I'm unsure of which direction". We only keep phrase-level an- notations where at least two workers agree on the label: 70.4% of all annotated nodes fit this defini- tion of agreement. All unannotated nodes receive the label of their closest annotated ancestor. Since the root of each sentence is always annotated, this strategy ensures that every node in the tree has a label. Our final balanced IBC dataset consists of 3,412 sentences (4,062 before balancing and re- moving neutral sentences) with a total of 13,640 annotated nodes. Of these sentences, 543 switch polarity (liberal → conservative or vice versa) on an annotated path.</p><p>While we initially wanted to incorporate neutral labels into our model, we observed that lower-level phrases are almost always neutral while full sen- tences are much more likely to be biased <ref type="figure">(Figure 4</ref>). Due to this discrepancy, the objective function in Eq. (5) was minimized by making neutral predic- tions for almost every node in the dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section we describe our experimental frame- work. We discuss strong baselines that use lexi- cal and syntactic information (including framing- specific features from previous work) as well as multiple RNN configurations. Each of these mod- els have the same task: to predict sentence-level ideology labels for sentences in a test set. To ac- count for label imbalance, we subsample the data so that there are an equal number of labels and report accuracy over this balanced dataset.   <ref type="figure">Figure 4</ref>: Proportion of liberal, conservative, and neutral annotations with respect to node depth (dis- tance from root). As we get farther from the root of the tree, nodes are more likely to be neutral.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Baselines</head><p>• The RANDOM baseline chooses a label at ran- dom from {liberal, conservative}.</p><p>• LR1, our most basic logistic regression base- line, uses only bag of words (BoW) features.</p><p>• LR2 uses only BoW features. However, <ref type="bibr">LR2</ref> also includes phrase-level annotations as sep- arate training instances. 7 • LR3 uses BoW features as well as syntac- tic pseudo-word features from <ref type="bibr" target="#b8">Greene &amp; Resnik (2009)</ref>. These features from depen- dency relations specify properties of verbs (e.g., transitivity or nominalization). 8 • LR-(W2V) is a logistic regression model trained on the average of the pretrained word embeddings for each sentence (Section 2.2).</p><p>The LR-(W2V) baseline allows us to compare against a strong lexical representation that encodes syntactic and semantic information without the RNN tree structure. (LR1, LR2) offer a compari- son to simple bag of words models, while the LR3 baseline contrasts traditional syntactic features with those learned by RNN models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">RNN Models</head><p>For <ref type="bibr">RNN</ref>  -69.3% To analyze the effects of initialization and phrase-level annotations, we report results for three different RNN settings. All three models were im- plemented as described in Section 2 with the non- linearity f set to the normalized tanh function,</p><formula xml:id="formula_8">f (v) = tanh(v) tanh(v) .<label>(7)</label></formula><p>We perform 10-fold cross-validation on the training data to find the best RNN hyperparameters. <ref type="bibr">9</ref> We report results for RNN models with the fol- lowing configurations:</p><p>• RNN1 initializes all parameters randomly and uses only sentence-level labels for training.</p><p>• RNN1-(W2V) uses the word2vec initialization described in Section 2.2 but is also trained on only sentence-level labels.</p><p>• RNN2-(W2V) is initialized using word2vec embeddings and also includes annotated phrase labels in its training. For this model, we also introduce a hyperparameter β that weights the error at annotated nodes (1 − β) higher than the error at unannotated nodes (β); since we have more confidence in the anno- tated labels, we want them to contribute more towards the objective function.</p><p>For all RNN models, we set the word vector dimension d to 300 to facilitate direct comparison against the LR-(W2V) baseline. <ref type="bibr">10</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Where Compositionality Helps Detect Ideological Bias</head><p>In this section, we examine the RNN models to see why they improve over our baselines. We also give examples of sentences that are correctly classified by our best RNN model but incorrectly classified by all of the baselines. Finally, we investigate sentence constructions that our model cannot handle and offer possible explanations for these errors.</p><p>Experimental Results <ref type="table" target="#tab_2">Table 1</ref> shows the RNN models outperforming the bag-of-words base- lines as well as the word2vec baseline on both datasets. The increased accuracy suggests that the trained RNNs are capable of detecting bias polar- ity switches at higher levels in parse trees. While phrase-level annotations do not improve baseline performance, the RNN model significantly bene- fits from these annotations because the phrases are themselves derived from nodes in the network struc- ture. In particular, the phrase annotations allow our best model to detect bias accurately in complex sentences that the baseline models cannot handle.</p><p>Initializing the RNN W e matrix with word2vec embeddings improves accuracy over randomly ini- tialization by 1%. This is similar to improvements from pretrained vectors from neural language mod- els ( <ref type="bibr" target="#b25">Socher et al., 2011b</ref>).</p><p>We obtain better results on Convote than on IBC with both bag-of-words and RNN models. This result was unexpected since the Convote labels are noisier than the annotated IBC labels; however, there are three possible explanations for the discrep- ancy. First, Convote has twice as many sentences as IBC, and the extra training data might help the model more than IBC's better-quality labels. Sec- ond, since the sentences in Convote were originally spoken, they are almost half as short (21.3 words per sentence) as those in the IBC (42.2 words per sentence). Finally, some information is lost at ev- ery propagation step, so RNNs are able to model the shorter sentences in Convote more effectively than the longer IBC sentences.</p><p>Qualitative Analysis As in previous work <ref type="bibr" target="#b25">(Socher et al., 2011b</ref>), we visualize the learned vector space by listing the most probable n-grams for each political affiliation in <ref type="table">Table 2</ref>. As expected, conservatives emphasize values such as freedom and religion while disparaging excess government spending and their liberal opposition. Meanwhile, liberals inveigh against the gap between the rich and the poor while expressing concern for minority groups and the working class.</p><p>Our best model is able to accurately model the compositional effects of bias in sentences with com- plex syntactic structures. The first three sentences in <ref type="figure" target="#fig_2">Figure 5</ref> were correctly classified by our best model (RNN2-(W2V)) and incorrectly classified by all of the baselines. <ref type="figure" target="#fig_2">Figures 5A and C</ref> show tradi- tional conservative phrases, "free market ideology" and "huge amounts of taxpayer money", that switch polarities higher up in the tree when combined with phrases such as "made worse by" and "saved by". <ref type="figure" target="#fig_2">Figure 5B</ref> shows an example of a bias polarity switch in the opposite direction: the sentence neg- atively portrays supporters of nationalized health care, which our model picks up on.</p><p>Our model often makes errors when polarity switches occur at nodes that are high up in the tree. In <ref type="figure" target="#fig_2">Figure 5D</ref>, "be used as an instrument to achieve charitable or social ends" reflects a lib- eral ideology, which the model predicts correctly. However, our model is unable to detect the polarity switch when this phrase is negated with "should not". Since many different issues are discussed in the IBC, it is likely that our dataset has too few examples of some of these issues for the model to adequately learn the appropriate ideological posi- tions, and more training data would resolve many of these errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>A growing NLP subfield detects private states such as opinions, sentiment, and beliefs ( <ref type="bibr" target="#b30">Wilson et al., 2005;</ref><ref type="bibr" target="#b18">Pang and Lee, 2008</ref>) from text. In general, work in this category tends to combine traditional surface lexical modeling (e.g., bag-of-words) with hand-designed syntactic features or lexicons. Here we review the most salient literature related to the present paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Automatic Ideology Detection</head><p>Most previous work on ideology detection ignores the syntactic structure of the language in use in favor of familiar bag-of-words representations for be used as an instrument to achieve charitable or social ends should not the law  Recently,  have proposed a model to infer mixtures of ideological positions in documents, applied to understanding the evolu- tion of ideological rhetoric used by political can- didates during the campaign cycle. They use an HMM-based model, defining the states as a set of fine-grained political ideologies, and rely on a closed set of lexical bigram features associated with each ideology, inferred from a manually la- beled ideological books corpus. Although it takes elements of discourse structure into account (cap- turing the"burstiness" of ideological terminology usage), their model explicitly ignores intrasenten- tial contextual influences of the kind seen in </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Subjectivity Detection</head><p>Detecting subjective language, which conveys opin- ion or speculation, is a related NLP problem. While sentences lacking subjective language may con- tain ideological bias (e.g., the topic of the sen- tence), highly-opinionated sentences likely have obvious ideological leanings. In addition, senti- ment and subjectivity analysis offers methodolog- ical approaches that can be applied to automatic bias detection. <ref type="bibr" target="#b29">Wiebe et al. (2004)</ref> show that low-frequency words and some collocations are a good indica- tors of subjectivity. More recently, <ref type="bibr" target="#b20">Recasens et al. (2013)</ref> detect biased words in sentences using indi- cator features for bias cues such as hedges and fac- tive verbs in addition to standard bag-of-words and part-of-speech features. They show that this type of linguistic information dramatically improves per- formance over several standard baselines. <ref type="bibr" target="#b8">Greene and Resnik (2009)</ref> also emphasize the connection between syntactic and semantic rela- tionships in their work on "implicit sentiment", n Most conservative n-grams Most liberal n-grams 1 Salt, Mexico, housework, speculated, consensus, lawyer, pharmaceuticals, ruthless, deadly, Clinton, redistribution rich, antipsychotic, malaria, biodiversity, richest, gene, pesticides, desertification, Net, wealthiest, labor, fertil- izer, nuclear, HIV 3 prize individual liberty, original liberal idiots, stock mar- ket crash, God gives freedom, federal government inter- ference, federal oppression nullification, respect individ- ual liberty, Tea Party patriots, radical Sunni Islamists, Obama stimulus programs rich and poor,"corporate greed", super rich pay, carrying the rich, corporate interest groups, young women work- ers, the very rich, for the rich, by the rich, soaking the rich, getting rich often, great and rich, the working poor, corporate income tax, the poor migrants 5 spending on popular government programs, bailouts and unfunded government promises, North America from external threats, government regulations place on busi- nesses, strong Church of Christ convictions, radical Is- lamism and other threats the rich are really rich, effective forms of worker partic- ipation, the pensions of the poor, tax cuts for the rich, the ecological services of biodiversity, poor children and pregnant women, vacation time for overtime pay 7 government intervention helped make the Depression Great, by God in His image and likeness, producing wealth instead of stunting capital creation, the tradi- tional American values of limited government, trillions of dollars to overseas oil producers, its troubled assets to federal sugar daddies, Obama and his party as racialist fanatics</p><p>African Americans and other disproportionately poor groups; the growing gap between rich and poor; the Bush tax cuts for the rich; public outrage at corporate and societal greed; sexually transmitted diseases , most notably AIDS; organize unions or fight for better condi- tions, the biggest hope for health care reform <ref type="table">Table 2</ref>: Highest probability n-grams for conservative and liberal ideologies, as predicted by the RNN2- (W2V) model. which refers to sentiment carried by sentence struc- ture and not word choice. They use syntactic depen- dency relation features combined with lexical infor- mation to achieve then state-of-the-art performance on standard sentiment analysis datasets. However, these syntactic features are only computed for a thresholded list of domain-specific verbs. This work extends their insight of modeling sentiment as an interaction between syntax and semantics to ideological bias.</p><p>Future Work There are a few obvious directions in which this work can be expanded. First, we can consider more nuanced political ideologies beyond liberal and conservative. We show that it is pos- sible to detect ideological bias given this binary problem; however, a finer-grained study that also includes neutral annotations may reveal more sub- tle distinctions between ideologies. While acquir- ing data with obscure political biases from the IBC or Convote is unfeasible, we can apply a similar analysis to social media (e.g., Twitter or Facebook updates) to discover how many different ideologies propagate in these networks. Another direction is to implement more sophis- ticated RNN models (along with more training data) for bias detection. We attempted to apply syntactically-untied <ref type="bibr">RNNs (Socher et al., 2013a)</ref> to our data with the idea that associating separate matrices for phrasal categories would improve rep- resentations at high-level nodes. While there were too many parameters for this model to work well here, other variations might prove successful, espe- cially with more data. Finally, combining sentence- level and document-level models might improve bias detection at both levels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this paper we apply recursive neural networks to political ideology detection, a problem where previous work relies heavily on bag-of-words mod- els and hand-designed lexica. We show that our approach detects bias more accurately than existing methods on two different datasets. In addition, we describe an approach to crowdsourcing ideological bias annotations. We use this approach to create a new dataset from the IBC, which is labeled at both the sentence and phrase level.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Example political ideology annotation task showing incremental reveal of progressively longer phrases.</figDesc><graphic url="image-1.png" coords="5,171.76,37.76,405.29,216.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Predictions by RNN2-(W2V) on four sentences from the IBC. Node color is the true label (red for conservative, blue for liberal), and an "X" next to a node means the model's prediction was wrong. In A and C, the model accurately detects conservative-to-liberal polarity switches, while in B it correctly predicts the liberal-to-conservative switch. In D, negation confuses our model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig- ure 1 .</head><label>1</label><figDesc>Other approaches on the document level use topic models to analyze bias in news articles, blogs, and political speeches (Ahmed and Xing, 2010; Lin et al., 2008; Nguyen et al., 2013).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>models, we generate a feature vector for every node in the tree. Equation 1 allows us to</figDesc><table>Model 
Convote 
IBC 

RANDOM 

50% 
50% 

LR1 

64.7% 62.1% 

LR2 

-61.9% 

LR3 

66.9% 62.6% 

LR-(W2V) 

66.6% 63.7% 

RNN1 

69.4% 66.2% 

RNN1-(W2V) 

70.2% 67.1% 

RNN2-(W2V) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Sentence-level bias detection accuracy. 
The RNN framework, adding phrase-level data, and 
initializing with word2vec all improve performance 
over logistic regression baselines. The LR2 and 
RNN2-(W2V) models were not trained on Convote 
since it lacks phrase annotations. 

percolate the representations to the root of the tree. 
We generate the final instance representation by 
concatenating the root vector and the average of 
all other vectors (Socher et al., 2011b). We train 
an L 2 -regularized logistic regression model over 
these concatenated vectors to obtain final accuracy 
numbers on the sentence level. 
</table></figure>

			<note place="foot" n="1"> Available at http://cs.umd.edu/ ˜ miyyer/ibc</note>

			<note place="foot" n="5"> This is a simplification, as the ideological hierarchy in IBC makes clear. 6 The words that the multinomial na¨ıvena¨ıve Bayes classifier in DUALIST marked as highest probability given a polarity: market, abortion, economy, rich, liberal, tea, economic, taxes, gun, abortion</note>

			<note place="foot" n="7"> The Convote dataset was not annotated on the phrase level, so we only provide a result for the IBC dataset. 8 We do not include phrase-level annotations in the LR3 feature set because the pseudo-word features can only be computed from full sentence parses.</note>

			<note place="foot" n="9"> [λW e =1e-6, λW =1e-4, λW cat =1e-3, β = 0.3]</note>

			<note place="foot" n="10"> Using smaller vector sizes (d ∈ {50, 100}, as in previous work) does not significantly change accuracy.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the anonymous reviewers, Hal Daumé, Yuening Hu, Yasuhiro Takayama, and Jyothi Vinju-mur for their insightful comments. We also want to thank Justin Gross for providing the IBC and Asad Sayeed for help with the Crowdflower task design, as well as Richard Socher and Karl Moritz Her-mann for assisting us with our model implemen-tations. This work was supported by NSF Grant CCF-1018625. Boyd-Graber is also supported by NSF Grant IIS-1320538. Any opinions, findings, conclusions, or recommendations expressed here are those of the authors and do not necessarily re-flect the view of the sponsor.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Staying informed: supervised and semi-supervised multi-view topical analysis of ideological perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amr</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Class-based n-gram models of natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Peter F Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">L</forename><surname>Desouza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent J Della</forename><surname>Mercer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenifer C</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comp. Ling</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="467" to="479" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Measuring bias and uncertainty in dw-nominate ideal point estimates via the parametric bootstrap</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Royce</forename><surname>Carroll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">B</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Howard</forename><surname>Keith T Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rosenthal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Political Analysis</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="261" to="275" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A unified architecture for natural language processing: Deep neural networks with multitask learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Media framing of capital punishment and its impact on individuals&apos; cognitive responses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Frank E Dardis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amber</forename><forename type="middle">E</forename><surname>Baumgartner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suzanna</forename><forename type="middle">De</forename><surname>Boydstun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuyuan</forename><surname>Boef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Mass Communication &amp; Society</publisher>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="115" to="140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">What drives media slant? evidence from us daily newspapers. Econometrica</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Gentzkow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><forename type="middle">M</forename><surname>Shapiro</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="35" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Predicting legislative roll calls from text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Gerrish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning taskdependent distributed representations by backpropagation through structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Goller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Kuchler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Networks</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">More than words: Syntactic packaging and implicit sentiment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Greene</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A measure of media bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Groseclose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Milyo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Quarterly Journal of Economics</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1191" to="1237" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Testing the etch-a-sketch hypothesis: A computational analysis of mitt romney&apos;s ideological makeover during the 2012 primary vs. general elections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brice</forename><surname>Acree</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanchuan</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">APSA 2013 Annual Meeting Paper</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Simple customization of recursive neural networks for semantic relation classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuma</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makoto</forename><surname>Miwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshimasa</forename><surname>Tsuruoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takashi</forename><surname>Chikayama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The Role of Syntax in Vector Space Models of Compositional Semantics</title>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<editor>Karl Moritz Hermann and Phil Blunsom</editor>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Moral Politics: How Liberals and Conservatives Think, Second Edition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Lakoff</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>University of Chicago Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A joint topic and perspective model for ideological discourse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Hao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Hauptmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning and Knowledge Discovery in Databases</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="17" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Lexical and hierarchical topic regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Viet-An Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Resnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1106" to="1114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Objective evidence on media bias: Newspaper coverage of congressional party switchers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Niven</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journalism &amp; Mass Communication Quarterly</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="311" to="326" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Opinion mining and sentiment analysis. Foundations and trends in information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="2" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Linguistic inquiry and word count</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">W</forename><surname>Pennebaker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><forename type="middle">E</forename><surname>Francis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><forename type="middle">J</forename><surname>Booth</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
	<note>computer software</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Linguistic models for analyzing and detecting biased language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><surname>Recasens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Danescu-Niculescu-Mizil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Grammatical structures for word-level sentiment detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Asad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Sayeed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><surname>Rusk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Closing the loop: Fast, interactive semi-supervised annotation with queries on features and instances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Burr</forename><surname>Settles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Measuring ideological proportions in political speeches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanchuan</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brice</forename><surname>Acree</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><forename type="middle">H</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Dynamic Pooling and Unfolding Recursive Autoencoders for Paraphrase Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Parsing With Compositional Vector Grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Recursive deep models for semantic compositionality over a sentiment treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Perelygin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Get out the vote: Determining support or opposition from Congressional floor-debate transcripts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning subjective language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Bruce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melanie</forename><surname>Martin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comp. Ling</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="277" to="308" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Recognizing contextual polarity in phrase-level sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Hoffmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Shedding (a thousand points of) light on biased language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tae</forename><surname>Yano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon&apos;s Mechanical Turk</title>
		<meeting>the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon&apos;s Mechanical Turk</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="152" to="158" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
