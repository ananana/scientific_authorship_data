<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:44+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yevgeni</forename><surname>Berzak</surname></persName>
							<email>berzak@mit.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">CSAIL MIT</orgName>
								<orgName type="department" key="dep2">EECS &amp; Linguistics MIT</orgName>
								<orgName type="department" key="dep3">Linguistics MIT</orgName>
								<orgName type="department" key="dep4">EECS MIT</orgName>
								<orgName type="department" key="dep5">Linguistics MIT</orgName>
								<orgName type="department" key="dep6">Linguistics MIT</orgName>
								<orgName type="department" key="dep7">CSAIL MIT</orgName>
								<orgName type="institution">Universal Dependencies for Learner English</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jessica</forename><surname>Kenney</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">CSAIL MIT</orgName>
								<orgName type="department" key="dep2">EECS &amp; Linguistics MIT</orgName>
								<orgName type="department" key="dep3">Linguistics MIT</orgName>
								<orgName type="department" key="dep4">EECS MIT</orgName>
								<orgName type="department" key="dep5">Linguistics MIT</orgName>
								<orgName type="department" key="dep6">Linguistics MIT</orgName>
								<orgName type="department" key="dep7">CSAIL MIT</orgName>
								<orgName type="institution">Universal Dependencies for Learner English</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carolyn</forename><surname>Spadine</surname></persName>
							<email>cspadine@mit.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">CSAIL MIT</orgName>
								<orgName type="department" key="dep2">EECS &amp; Linguistics MIT</orgName>
								<orgName type="department" key="dep3">Linguistics MIT</orgName>
								<orgName type="department" key="dep4">EECS MIT</orgName>
								<orgName type="department" key="dep5">Linguistics MIT</orgName>
								<orgName type="department" key="dep6">Linguistics MIT</orgName>
								<orgName type="department" key="dep7">CSAIL MIT</orgName>
								<orgName type="institution">Universal Dependencies for Learner English</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><forename type="middle">Xian</forename><surname>Wang</surname></persName>
							<email>jxwang@mit.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">CSAIL MIT</orgName>
								<orgName type="department" key="dep2">EECS &amp; Linguistics MIT</orgName>
								<orgName type="department" key="dep3">Linguistics MIT</orgName>
								<orgName type="department" key="dep4">EECS MIT</orgName>
								<orgName type="department" key="dep5">Linguistics MIT</orgName>
								<orgName type="department" key="dep6">Linguistics MIT</orgName>
								<orgName type="department" key="dep7">CSAIL MIT</orgName>
								<orgName type="institution">Universal Dependencies for Learner English</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Lam</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">CSAIL MIT</orgName>
								<orgName type="department" key="dep2">EECS &amp; Linguistics MIT</orgName>
								<orgName type="department" key="dep3">Linguistics MIT</orgName>
								<orgName type="department" key="dep4">EECS MIT</orgName>
								<orgName type="department" key="dep5">Linguistics MIT</orgName>
								<orgName type="department" key="dep6">Linguistics MIT</orgName>
								<orgName type="department" key="dep7">CSAIL MIT</orgName>
								<orgName type="institution">Universal Dependencies for Learner English</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meche</forename><surname>Mit</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">CSAIL MIT</orgName>
								<orgName type="department" key="dep2">EECS &amp; Linguistics MIT</orgName>
								<orgName type="department" key="dep3">Linguistics MIT</orgName>
								<orgName type="department" key="dep4">EECS MIT</orgName>
								<orgName type="department" key="dep5">Linguistics MIT</orgName>
								<orgName type="department" key="dep6">Linguistics MIT</orgName>
								<orgName type="department" key="dep7">CSAIL MIT</orgName>
								<orgName type="institution">Universal Dependencies for Learner English</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keiko</forename><forename type="middle">Sophie</forename><surname>Mori</surname></persName>
							<email>ksmori@mit.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">CSAIL MIT</orgName>
								<orgName type="department" key="dep2">EECS &amp; Linguistics MIT</orgName>
								<orgName type="department" key="dep3">Linguistics MIT</orgName>
								<orgName type="department" key="dep4">EECS MIT</orgName>
								<orgName type="department" key="dep5">Linguistics MIT</orgName>
								<orgName type="department" key="dep6">Linguistics MIT</orgName>
								<orgName type="department" key="dep7">CSAIL MIT</orgName>
								<orgName type="institution">Universal Dependencies for Learner English</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Garza</surname></persName>
							<email>sjgarza@mit.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">CSAIL MIT</orgName>
								<orgName type="department" key="dep2">EECS &amp; Linguistics MIT</orgName>
								<orgName type="department" key="dep3">Linguistics MIT</orgName>
								<orgName type="department" key="dep4">EECS MIT</orgName>
								<orgName type="department" key="dep5">Linguistics MIT</orgName>
								<orgName type="department" key="dep6">Linguistics MIT</orgName>
								<orgName type="department" key="dep7">CSAIL MIT</orgName>
								<orgName type="institution">Universal Dependencies for Learner English</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><surname>Katz</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">CSAIL MIT</orgName>
								<orgName type="department" key="dep2">EECS &amp; Linguistics MIT</orgName>
								<orgName type="department" key="dep3">Linguistics MIT</orgName>
								<orgName type="department" key="dep4">EECS MIT</orgName>
								<orgName type="department" key="dep5">Linguistics MIT</orgName>
								<orgName type="department" key="dep6">Linguistics MIT</orgName>
								<orgName type="department" key="dep7">CSAIL MIT</orgName>
								<orgName type="institution">Universal Dependencies for Learner English</orgName>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="737" to="746"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We introduce the Treebank of Learner En-glish (TLE), the first publicly available syntactic treebank for English as a Second Language (ESL). The TLE provides manually annotated POS tags and Universal Dependency (UD) trees for 5,124 sentences from the Cambridge First Certificate in English (FCE) corpus. The UD annotations are tied to a pre-existing error annotation of the FCE, whereby full syntactic analyses are provided for both the original and error corrected versions of each sentence. Further on, we delineate ESL annotation guidelines that allow for consistent syntactic treatment of ungram-matical English. Finally, we benchmark POS tagging and dependency parsing performance on the TLE dataset and measure the effect of grammatical errors on parsing accuracy. We envision the treebank to support a wide range of linguistic and computational research on second language acquisition as well as automatic processing of ungrammatical language 1 .</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The majority of the English text available world- wide is generated by non-native speakers <ref type="bibr" target="#b2">(Crystal, 2003)</ref>. Such texts introduce a variety of chal- lenges, most notably grammatical errors, and are of paramount importance for the scientific study of language acquisition as well as for NLP. De- spite the ubiquity of non-native English, there is currently no publicly available syntactic treebank for English as a Second Language (ESL).</p><p>To address this shortcoming, we present the Treebank of Learner English (TLE), a first of its kind resource for non-native English, contain- ing 5,124 sentences manually annotated with POS tags and dependency trees. The TLE sentences are drawn from the FCE dataset <ref type="bibr" target="#b25">(Yannakoudakis et al., 2011)</ref>, and authored by English learners from 10 different native language backgrounds. The tree- bank uses the Universal Dependencies (UD) for- malism <ref type="bibr" target="#b18">Nivre et al., 2016)</ref>, which provides a unified annotation frame- work across different languages and is geared to- wards multilingual NLP ( <ref type="bibr" target="#b14">McDonald et al., 2013)</ref>. This characteristic allows our treebank to sup- port computational analysis of ESL using not only English based but also multilingual approaches which seek to relate ESL phenomena to native lan- guage syntax.</p><p>While the annotation inventory and guidelines are defined by the English UD formalism, we build on previous work in learner language anal- ysis ( <ref type="bibr" target="#b5">Dıaz-Negrillo et al., 2010;</ref><ref type="bibr" target="#b7">Dickinson and Ragheb, 2013)</ref> to formulate an additional set of annotation conventions aiming at a uniform treat- ment of ungrammatical learner language. Our annotation scheme uses a two-layer analysis, whereby a distinct syntactic annotation is pro- vided for the original and the corrected version of each sentence. This approach is enabled by a pre-existing error annotation of the FCE <ref type="bibr" target="#b17">(Nicholls, 2003)</ref> which is used to generate an error corrected variant of the dataset. Our inter-annotator agree- ment results provide evidence for the ability of the annotation scheme to support consistent annota- tion of ungrammatical structures.</p><p>Finally, a corpus that is annotated with both grammatical errors and syntactic dependencies paves the way for empirical investigation of the relation between grammaticality and syntax. Un- derstanding this relation is vital for improving tag- ging and parsing performance on learner language <ref type="bibr" target="#b11">(Geertzen et al., 2013)</ref>, syntax based grammati- cal error correction <ref type="bibr" target="#b24">(Tetreault et al., 2010;</ref><ref type="bibr" target="#b16">Ng et al., 2014)</ref>, and many other fundamental challenges in NLP. In this work, we take the first step in this direction by benchmarking tagging and pars- ing accuracy on our dataset under different train- ing regimes, and obtaining several estimates for the impact of grammatical errors on these tasks.</p><p>To summarize, this paper presents three contri- butions. First, we introduce the first large scale syntactic treebank for ESL, manually annotated with POS tags and universal dependencies. Sec- ond, we describe a linguistically motivated anno- tation scheme for ungrammatical learner English and provide empirical support for its consistency via inter-annotator agreement analysis. Third, we benchmark a state of the art parser on our dataset and estimate the influence of grammatical errors on the accuracy of automatic POS tagging and de- pendency parsing.</p><p>The remainder of this paper is structured as fol- lows. We start by presenting an overview of the treebank in section 2. In sections 3 and 4 we provide background information on the annota- tion project, and review the main annotation stages leading to the current form of the dataset. The ESL annotation guidelines are summarized in section 5. Inter-annotator agreement analysis is presented in section 6, followed by parsing experiments in sec- tion 7. Finally, we review related work in section 8 and present the conclusion in section 9.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Treebank Overview</head><p>The TLE currently contains 5,124 sentences (97,681 tokens) with POS tag and dependency an- notations in the English Universal Dependencies (UD) formalism <ref type="bibr" target="#b18">Nivre et al., 2016</ref>). The sentences were obtained from the FCE corpus <ref type="bibr" target="#b25">(Yannakoudakis et al., 2011</ref>), a collection of upper intermediate English learner essays, containing error annotations with 75 error categories <ref type="bibr" target="#b17">(Nicholls, 2003)</ref>. Sentence level seg- mentation was performed using an adaptation of the NLTK sentence tokenizer 2 . Under-segmented sentences were split further manually. Word level tokenization was generated using the Stanford PTB word tokenizer <ref type="bibr">3</ref> .</p><p>The treebank represents learners with 10 dif- ferent native language backgrounds: Chinese, French, German, Italian, Japanese, Korean, Por- tuguese, Spanish, Russian and Turkish. For every native language, we randomly sampled 500 au- tomatically segmented sentences, under the con- straint that selected sentences have to contain at least one grammatical error that is not punctuation or spelling.</p><p>The TLE annotations are provided in two ver- sions. The first version is the original sentence au- thored by the learner, containing grammatical er- rors. The second, corrected sentence version, is a grammatical variant of the original sentence, gen- erated by correcting all the grammatical errors in the sentence according to the manual error anno- tation provided in the FCE dataset. The resulting corrected sentences constitute a parallel corpus of standard English. <ref type="table">Table 1</ref>  To avoid potential annotation biases, the anno- tations of the treebank were created manually from scratch, without utilizing any automatic annota- tion tools. To further assure annotation quality, each annotated sentence was reviewed by two ad- ditional annotators. To the best of our knowledge, TLE is the first large scale English treebank con- structed in a completely manual fashion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Annotator Training</head><p>The treebank was annotated by six students, five undergraduates and one graduate. Among the un- dergraduates, three are linguistics majors and two are engineering majors with a linguistic minor. The graduate student is a linguist specializing in syntax. An additional graduate student in NLP participated in the final debugging of the dataset.</p><p>Prior to annotating the treebank sentences, the annotators were trained for about 8 weeks. Dur- ing the training, the annotators attended tutorials on dependency grammars, and learned the English UD guidelines 4 , the Penn Treebank POS guide- lines <ref type="bibr" target="#b22">(Santorini, 1990)</ref>, the grammatical error an- notation scheme of the FCE <ref type="bibr" target="#b17">(Nicholls, 2003)</ref>, as well as the ESL guidelines described in section 5 and in the annotation manual.</p><p>Furthermore, the annotators completed six an- notation exercises, in which they were required to annotate POS tags and dependencies for practice sentences from scratch. The exercises were done individually, and were followed by group meet- ings in which annotation disagreements were dis- cussed and resolved. Each of the first three exer- cises consisted of 20 sentences from the UD gold standard for English, the English Web Treebank (EWT) ( ). The remaining three exercises contained 20-30 ESL sentences from the FCE. Many of the ESL guidelines were introduced or refined based on the disagreements in the ESL practice exercises and the subsequent group dis- cussions. Several additional guidelines were in- troduced in the course of the annotation process.</p><p>During the training period, the annotators also learned to use a search tool that enables formulat- ing queries over word and POS tag sequences as regular expressions and obtaining their annotation statistics in the EWT. After experimenting with both textual and graphical interfaces for perform- ing the annotations, we converged on a simple text based format described in section 4.1, where the annotations were filled in using a spreadsheet or a text editor, and tested with a script for detect- ing annotation typos. The annotators continued to meet and discuss annotation issues on a weekly basis throughout the entire duration of the project.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Annotation Procedure</head><p>The formation of the treebank was carried out in four steps: annotation, review, disagreement reso- lution and targeted debugging.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Annotation</head><p>In the first stage, the annotators were given sen- tences for annotation from scratch. We use a CoNLL based textual template in which each word is annotated in a separate line. Each line contains 6 columns, the first of which has the word index <ref type="bibr">4</ref> http://universaldependencies.org/#en (IND) and the second the word itself (WORD). The remaining four columns had to be filled in with a Universal POS tag (UPOS), a Penn Tree- bank POS tag (POS), a head word index (HIND) and a dependency relation (REL) according to ver- sion 1 of the English UD guidelines.</p><p>The annotation section of the sentence is pre- ceded by a metadata header. The first field in this header, denoted with SENT, contains the FCE er- ror coded version of the sentence. The annotators were instructed to verify the error annotation, and add new error annotations if needed. Corrections to the sentence segmentation are specified in the SEGMENT field <ref type="bibr">5</ref> . Further down, the field TYPO is designated for literal annotation of spelling er- rors and ill formed words that happen to form valid words (see section 5.2).</p><p>The example below presents a pre-annotated original sentence given to an annotator. Upon completion of the original sentence, the annotators proceeded to annotate the corrected sentence version. To reduce annotation time, an- notators used a script that copies over annotations from the original sentence and updates head in- dices of tokens that appear in both sentence ver- sions. Head indices and relation labels were filled in only if the head word of the token appeared in both the original and corrected sentence versions. Tokens with automatically filled annotations in- cluded an additional # sign in a seventh column of each word's annotation. The # signs had to be removed, and the corresponding annotations ei- ther approved or changed as appropriate. Tokens that did not appear in the original sentence version were annotated from scratch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Review</head><p>All annotated sentences were randomly assigned to a second annotator (henceforth reviewer), in a double blind manner. The reviewer's task was to mark all the annotations that they would have an- notated differently. To assist the review process, we compiled a list of common annotation errors, available in the released annotation manual.</p><p>The annotations were reviewed using an active editing scheme in which an explicit action was re- quired for all the existing annotations. The scheme was introduced to prevent reviewers from over- looking annotation issues due to passive approval. Specifically, an additional # sign was added at the seventh column of each token's annotation. The reviewer then had to either "sign off" on the exist- ing annotation by erasing the # sign, or provide an alternative annotation following the # sign.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Disagreement Resolution</head><p>In the final stage of the annotation process all annotator-reviewer disagreements were resolved by a third annotator (henceforth judge), whose main task was to decide in favor of the annotator or the reviewer. Similarly to the review process, the judging task was carried out in a double blind manner. Judges were allowed to resolve annotator- reviewer disagreements with a third alternative, as well as introduce new corrections for annotation issues overlooked by the reviewers.</p><p>Another task performed by the judges was to mark acceptable alternative annotations for am- biguous structures determined through review dis- agreements or otherwise present in the sentence. These annotations were specified in an additional metadata field called AMBIGUITY. The ambigu- ity markings are provided along with the resolved version of the annotations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Final Debugging</head><p>After applying the resolutions produced by the judges, we queried the corpus with debugging tests for specific linguistics constructions. This additional testing phase further reduced the num- ber of annotation errors and inconsistencies in the treebank. Including the training period, the tree- bank creation lasted over a year, with an aggregate of more than 2,000 annotation hours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Annotation Scheme for ESL</head><p>Our annotations use the existing inventory of En- glish UD POS tags and dependency relations, and follow the standard UD annotation guidelines for English. However, these guidelines were for- mulated with grammatical usage of English in mind and do not cover non canonical syntactic structures arising due to grammatical errors 6 . To encourage consistent and linguistically motivated annotation of such structures, we formulated a complementary set of ESL annotation guidelines.</p><p>Our ESL annotation guidelines follow the gen- eral principle of literal reading, which emphasizes syntactic analysis according to the observed lan- guage usage. This strategy continues a line of work in SLA which advocates for centering analy- sis of learner language around morpho-syntactic surface evidence <ref type="bibr" target="#b19">(Ragheb and Dickinson, 2012;</ref><ref type="bibr" target="#b7">Dickinson and Ragheb, 2013)</ref>. Similarly to our framework, which includes a parallel annotation of corrected sentences, such strategies are often presented in the context of multi-layer annota- tion schemes that also account for error corrected sentence forms ( <ref type="bibr" target="#b12">Hirschmann et al., 2007;</ref><ref type="bibr">DıazNegrillo et al., 2010;</ref><ref type="bibr" target="#b21">Rosen et al., 2014)</ref>.</p><p>Deploying a strategy of literal annotation within UD, a formalism which enforces cross-linguistic consistency of annotations, will enable meaning- ful comparisons between non-canonical structures in English and canonical structures in the author's native language. As a result, a key novel character- istic of our treebank is its ability to support cross- lingual studies of learner language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Literal Annotation</head><p>With respect to POS tagging, literal annotation im- plies adhering as much as possible to the observed morphological forms of the words. Syntactically, argument structure is annotated according to the usage of the word rather than its typical distribu- tion in the relevant context. The following list of conventions defines the notion of literal reading for some of the common non canonical structures associated with grammatical errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Argument Structure</head><p>Extraneous prepositions We annotate all nominal dependents introduced by extraneous prepositions as nominal modifiers. In the following sentence, "him" is marked as a nominal modifier (nmod) in- stead of an indirect object (iobj) of "give".</p><p>#SENT=...I had to give &lt;ns type="UT"&gt;&lt;i&gt;to&lt;/i&gt; &lt;/ns&gt; him water... Omitted prepositions We treat nominal depen- dents of a predicate that are lacking a preposition as arguments rather than nominal modifiers. In the example below, "money" is marked as a direct ob- ject (dobj) instead of a nominal modifier (nmod) of "ask". As "you" functions in this context as a second argument of "ask", it is annotated as an in- direct object (iobj) instead of a direct object (dobj).</p><p>#SENT=...I have to ask you &lt;ns type="MT"&gt; &lt;c&gt;for&lt;/c&gt;&lt;/ns&gt; the money &lt;ns type= "RT"&gt; &lt;i&gt;of&lt;/i&gt;&lt;c&gt;for&lt;/c&gt;&lt;/ns&gt; the tickets back. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Word Formation</head><p>Erroneous word formations that are contextually plausible and can be assigned with a PTB tag are annotated literally. In the following example, "stuffs" is handled as a plural count noun. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Exceptions to Literal Annotation</head><p>Although our general annotation strategy for ESL follows literal sentence readings, several types of word formation errors make such readings unin- formative or impossible, essentially forcing cer- tain words to be annotated using some degree of interpretation <ref type="bibr" target="#b20">(Rosén and De Smedt, 2010)</ref>. We hence annotate the following cases in the original sentence according to an interpretation of an in- tended word meaning, obtained from the FCE er- ror correction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Spelling</head><p>Spelling errors are annotated according to the cor- rectly spelled version of the word. To support error analysis of automatic annotation tools, misspelled words that happen to form valid words are anno- tated in the metadata field TYPO for POS tags with respect to the most common usage of the misspelled word form. In the example below, the TYPO field contains the typical POS annotation of "where", which is clearly unintended in the con- text of the sentence. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Word Formation</head><p>Erroneous word formations that cannot be as- signed with an existing PTB tag are annotated with respect to the correct word form.   In particular, ill formed adjectives that have a plural suffix receive a standard adjectival POS tag. When applicable, such cases also receive an addi- tional marking for unnecessary agreement in the error annotation using the attribute "ua".   Wrong word formations that result in a valid, but contextually implausible word form are also annotated according to the word correction. In the example below, the nominal form "sale" is likely to be an unintended result of an ill formed verb. Similarly to spelling errors that result in valid words, we mark the typical literal POS an- notation in the TYPO metadata field. Taken together, our ESL conventions cover many of the annotation challenges related to gram- matical errors present in the TLE. In addition to the presented overview, the complete manual of ESL guidelines used by the annotators is pub- licly available. The manual contains further details on our annotation scheme, additional annotation guidelines and a list of common annotation errors. We plan to extend and refine these guidelines in future releases of the treebank.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Editing Agreement</head><p>We utilize our two step review process to estimate agreement rates between annotators 7 . We measure agreement as the fraction of annotation tokens ap- proved by the editor. <ref type="table">Table 2</ref> presents the agree- ment between annotators and reviewers, as well as the agreement between reviewers and the judges. Agreement measurements are provided for both the original the corrected versions of the dataset.</p><p>Overall, the results indicate a high agreement rate in the two editing tasks. Importantly, the gap between the agreement on the original and cor- rected sentences is small. Note that this result is obtained despite the introduction of several ESL annotation guidelines in the course of the annota- tion process, which inevitably increased the num- ber of edits related to grammatical errors. We in- terpret this outcome as evidence for the effective- ness of the ESL annotation scheme in supporting consistent annotations of learner language.  <ref type="table">Table 2</ref>: Inter-annotator agreement on the entire TLE corpus. Agreement is measured as the frac- tion of tokens that remain unchanged after an edit- ing round. The four evaluation columns corre- spond to universal POS tags, PTB POS tags, un- labeled attachment, and dependency labels. Co- hen's Kappa scores <ref type="bibr" target="#b1">(Cohen, 1960)</ref> for POS tags and dependency labels in all evaluation conditions are above 0.96.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Parsing Experiments</head><p>The TLE enables studying parsing for learner lan- guage and exploring relationships between gram- matical errors and parsing performance. Here, we present parsing benchmarks on our dataset, and provide several estimates for the extent to which grammatical errors degrade the quality of auto- matic POS tagging and dependency parsing. Our first experiment measures tagging and pars- ing accuracy on the TLE and approximates the global impact of grammatical errors on automatic annotation via performance comparison between the original and error corrected sentence versions. In this, and subsequent experiments, we utilize version 2.2 of the Turbo tagger and Turbo parser <ref type="bibr" target="#b13">(Martins et al., 2013</ref>), state of the art tools for sta- tistical POS tagging and dependency parsing. <ref type="table">Table 3</ref> presents tagging and parsing results on a test set of 500 TLE sentences (9,591 original to- kens, 9,700 corrected tokens). Results are pro- vided for three different training regimes. The first regime uses the training portion of version 1.3 of the EWT, the UD English treebank, contain- ing 12,543 sentences (204,586 tokens). The sec- ond training mode uses 4,124 training sentences (78,541 original tokens, 79,581 corrected tokens) from the TLE corpus. In the third setup we com- bine these two training corpora. The remaining 500 TLE sentences (9,549 original tokens, 9,695 corrected tokens) are allocated to a development set, not used in this experiment. Parsing of the test sentences was performed on predicted POS tags.</p><p>The EWT training regime, which uses out of do- main texts written in standard English, provides the lowest performance on all the evaluation met-  <ref type="table">Table 3</ref>: Tagging and parsing results on a test set of 500 sentences from the TLE corpus. EWT is the English UD treebank. TLE orig are original sen- tences from the TLE. TLE corr are the correspond- ing error corrected sentences.</p><p>rics. An additional factor which negatively af- fects performance in this regime are systematic differences in the EWT annotation of possessive pronouns, expletives and names compared to the UD guidelines, which are utilized in the TLE. In particular, the EWT annotates possessive pronoun UPOS as PRON rather than DET, which leads the UPOS results in this setup to be lower than the PTB POS results. Improved results are obtained using the TLE training data, which, despite its smaller size, is closer in genre and syntactic char- acteristics to the TLE test set. The strongest PTB POS tagging and parsing results are obtained by combining the EWT with the TLE training data, yielding 95.77 POS accuracy and a UAS of 90.3 on the original version of the TLE test set. The dual annotation of sentences in their orig- inal and error corrected forms enables estimating the impact of grammatical errors on tagging and parsing by examining the performance gaps be- tween the two sentence versions. Averaged across the three training conditions, the POS tagging ac- curacy on the original sentences is lower than the accuracy on the sentence corrections by 1.0 UPOS and 0.61 POS. Parsing performance degrades by 1.9 UAS, 1.59 LA and 2.21 LAS.</p><p>To further elucidate the influence of grammati- cal errors on parsing quality, table 4 compares per- formance on tokens in the original sentences ap- pearing inside grammatical error tags to those ap- pearing outside such tags. Although grammatical errors may lead to tagging and parsing errors with respect to any element in the sentence, we expect erroneous tokens to be more challenging to ana- lyze compared to grammatical tokens.</p><p>This comparison indeed reveals a substantial difference between the two types of tokens, with an average gap of <ref type="bibr">5</ref>  <ref type="table">Table 4</ref>: Tagging and parsing results on the origi- nal version of the TLE test set for tokens marked with grammatical errors (Ungrammatical) and to- kens not marked for errors (Grammatical).</p><p>the global measurements in the first experiment, this analysis, which focuses on the local impact of remove/replace errors, suggests a stronger ef- fect of grammatical errors on the dependency la- bels than on the dependency structure. Finally, we measure tagging and parsing perfor- mance relative to the fraction of sentence tokens marked with grammatical errors. Similarly to the previous experiment, this analysis focuses on re- move/replace rather than insert errors. Points connected by continuous lines denote per- formance on the original TLE sentences. Points connected by dashed lines denote performance on the corresponding error corrected sentences. The number of sentences whose errors fall within each percentage range appears in parenthesis. <ref type="figure" target="#fig_1">Figure 1</ref> presents the average sentential perfor- mance as a function of the percentage of tokens in the original sentence marked with grammati-cal errors. In this experiment, we train the parser on the EWT training set and test on the entire TLE corpus. Performance curves are presented for POS, UAS and LAS on the original and error corrected versions of the annotations. We observe that while the performance on the corrected sen- tences is close to constant, original sentence per- formance is decreasing as the percentage of the er- roneous tokens in the sentence grows.</p><p>Overall, our results suggest a negative, albeit limited effect of grammatical errors on parsing. This outcome contrasts a study by <ref type="bibr" target="#b11">Geertzen et al. (2013)</ref> which reported a larger performance gap of 7.6 UAS and 8.8 LAS between sentences with and without grammatical errors. We believe that our analysis provides a more accurate estimate of this impact, as it controls for both sentence content and sentence length. The latter factor is crucial, since it correlates positively with the number of gram- matical errors in the sentence, and negatively with parsing accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Related Work</head><p>Previous studies on learner language proposed several annotation schemes for both POS tags and syntax ( <ref type="bibr" target="#b12">Hirschmann et al., 2007;</ref><ref type="bibr" target="#b5">Dıaz-Negrillo et al., 2010;</ref><ref type="bibr" target="#b7">Dickinson and Ragheb, 2013;</ref><ref type="bibr" target="#b21">Rosen et al., 2014</ref>). The unifying theme in these proposals is a multi-layered analysis aiming to decouple the observed language usage from conventional struc- tures in the foreign language.</p><p>In the context of ESL, <ref type="bibr">Dıaz et al. (2010)</ref> pro- pose three parallel POS tag annotations for the lexical, morphological and distributional forms of each word. In our work, we adopt the distinc- tion between morphological word forms, which roughly correspond to our literal word readings, and distributional forms as the error corrected words. However, we account for morphological forms only when these constitute valid existing PTB POS tags and are contextually plausible. Fur- thermore, while the internal structure of invalid word forms is an interesting object of investiga- tion, we believe that it is more suitable for anno- tation as word features rather than POS tags. Our treebank supports the addition of such features to the existing annotations.</p><p>The work of <ref type="bibr" target="#b6">Ragheb and Dickinson (2009;</ref><ref type="bibr" target="#b19">2012;</ref> proposes ESL annotation guidelines for POS tags and syntactic dependencies based on the CHILDES annotation framework. This ap- proach, called "morphosyntactic dependencies" is related to our annotation scheme in its focus on surface structures. Differently from this proposal, our annotations are grounded in a parallel anno- tation of grammatical errors and include an ad- ditional layer of analysis for the corrected forms. Moreover, we refrain from introducing new syn- tactic categories and dependency relations specific to ESL, thereby supporting computational treat- ment of ESL using existing resources for standard English. At the same time, we utilize a multilin- gual formalism which, in conjunction with our lit- eral annotation strategy, facilitates linking the an- notations to native language syntax.</p><p>While the above mentioned studies focus on an- notation guidelines, attention has also been drawn to the topic of parsing in the learner language do- main. However, due to the shortage of syntactic resources for ESL, much of the work in this area resorted to using surrogates for learner data. <ref type="bibr">For example, in Foster (2007)</ref> and <ref type="bibr" target="#b8">Foster et al. (2008)</ref> parsing experiments are carried out on synthetic learner-like data, that was created by automatic in- sertion of grammatical errors to well formed En- glish text. In <ref type="bibr" target="#b0">Cahill et al. (2014)</ref> a treebank of sec- ondary level native students texts was used to ap- proximate learner text in order to evaluate a parser that utilizes unlabeled learner data.</p><p>Syntactic annotations for ESL were previously developed by <ref type="bibr" target="#b15">Nagata et al. (2011)</ref>, who annotate an English learner corpus with POS tags and shal- low syntactic parses. Our work departs from shal- low syntax to full syntactic analysis, and provides annotations on a significantly larger scale. Fur- thermore, differently from this annotation effort, our treebank covers a wide range of learner na- tive languages. An additional syntactic dataset for ESL, currently not available publicly, are 1,000 sentences from the EFCamDat dataset <ref type="bibr" target="#b11">(Geertzen et al., 2013)</ref>, annotated with Stanford dependen- cies <ref type="bibr" target="#b3">(De Marneffe and Manning, 2008)</ref>. This dataset was used to measure the impact of gram- matical errors on parsing by comparing perfor- mance on sentences with grammatical errors to er- ror free sentences. The TLE enables a more direct way of estimating the magnitude of this perfor- mance gap by comparing performance on the same sentences in their original and error corrected ver- sions. Our comparison suggests that the effect of grammatical errors on parsing is smaller that the one reported in this study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusion</head><p>We present the first large scale treebank of learner language, manually annotated and double- reviewed for POS tags and universal dependen- cies. The annotation is accompanied by a linguis- tically motivated framework for handling syntactic structures associated with grammatical errors. Fi- nally, we benchmark automatic tagging and pars- ing on our corpus, and measure the effect of gram- matical errors on tagging and parsing quality. The treebank will support empirical study of learner syntax in NLP, corpus linguistics and second lan- guage acquisition.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>#SENT=I am &lt;ns type="IV"&gt;&lt;i&gt;writting&lt;/i&gt; &lt;c&gt;writing&lt;/c&gt;&lt;/ns&gt;...</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>1</head><label>1</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>#SENT=..</head><label></label><figDesc>.&lt;ns type="IJ" ua=true&gt; &lt;i&gt;interestings&lt;/i&gt;&lt;c&gt;interesting&lt;/c&gt;&lt;/ns&gt; things...</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>.</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Mean per sentence POS accuracy, UAS and LAS of the Turbo tagger and Turbo parser, as a function of the percentage of original sentence tokens marked with grammatical errors. The tagger and the parser are trained on the EWT corpus, and tested on all 5,124 sentences of the TLE. Points connected by continuous lines denote performance on the original TLE sentences. Points connected by dashed lines denote performance on the corresponding error corrected sentences. The number of sentences whose errors fall within each percentage range appears in parenthesis.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>presents basic statistics of both versions of the annotated sentences.</figDesc><table>original 
corrected 
sentences 
5,124 
5,124 
tokens 
97,681 
98,976 
sentence length 
19.06 (std 9.47) 19.32 (std 9.59) 
errors per sentence 2.67 (std 1.9) 
-
authors 
924 
native languages 
10 

Table 1: Statistics of the TLE. Standard deviations 
are denoted in parenthesis. 

</table></figure>

			<note place="foot" n="1"> The treebank is available at universaldependencies.org. The annotation manual used in this project and a graphical query engine are available at esltreebank.org.</note>

			<note place="foot" n="2"> http://www.nltk.org/api/nltk.tokenize.html</note>

			<note place="foot" n="3"> http://nlp.stanford.edu/software/tokenizer.shtml</note>

			<note place="foot" n="5"> The released version of the treebank splits the sentences according to the markings in the SEGMENT field when those apply both to the original and corrected versions of the sentence. Resulting segments without grammatical errors in the original version are currently discarded.</note>

			<note place="foot" n="6"> The English UD guidelines do address several issues encountered in informal genres, such as the relation &quot;goeswith&quot;, which is used for fragmented words resulting from typos.</note>

			<note place="foot" n="7"> All experimental results on agreement and parsing exclude punctuation tokens.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">Acknowledgements</head><p>We thank Anna Korhonen for helpful discussions and insightful comments on this paper. We also thank Dora Alexopoulou, Andrei Barbu, Markus Dickinson, Sue Felshin, Jeroen Geertzen, Yan Huang, Detmar Meurers, Sampo Pyysalo, Roi Re-ichart and the anonymous reviewers for valuable feedback on this work. This material is based upon work supported by the Center for Brains, Minds, and Machines (CBMM), funded by NSF STC award CCF-1231216.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Self-training for parsing learner text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aoife</forename><surname>Cahill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Binod</forename><surname>Gyawali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James V</forename><surname>Bruno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Joint Workshop on Statistical Parsing of Morphologically Rich Languages and Syntactic Analysis of Non-Canonical Languages</title>
		<meeting>the First Joint Workshop on Statistical Parsing of Morphologically Rich Languages and Syntactic Analysis of Non-Canonical Languages</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="66" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A Coefficient of Agreement for Nominal Scales</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Educational and Psychological Measurement</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">37</biblScope>
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">English as a global language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Crystal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<publisher>Ernst Klett Sprachen</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Stanford typed dependencies manual</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Catherine De</forename><surname>Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
		<respStmt>
			<orgName>Stanford University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Universal stanford dependencies: A cross-linguistic typology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Catherine De</forename><surname>Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Dozat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Silveira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katri</forename><surname>Haverinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Ginter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC</title>
		<meeting>LREC</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="4585" to="4592" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Towards interlanguage pos annotation for effective learner corpora in sla and flt</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ana</forename><surname>Dıaz-Negrillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Detmar</forename><surname>Meurers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salvador</forename><surname>Valera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Wunsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language Forum</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="139" to="154" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Dependency annotation for learner corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Dickinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marwa</forename><surname>Ragheb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth Workshop on Treebanks and Linguistic Theories (TLT-8)</title>
		<meeting>the Eighth Workshop on Treebanks and Linguistic Theories (TLT-8)</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="59" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Annotation for learner English guidelines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Dickinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marwa</forename><surname>Ragheb</surname></persName>
		</author>
		<idno>v. 0.1</idno>
		<imprint>
			<date type="published" when="2013-06-09" />
			<pubPlace>Bloomington, IN</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Indiana University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Adapting a wsj-trained parser to grammatically noisy text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Van Genabith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th</title>
		<meeting>the 46th</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<title level="m">Annual Meeting of the Association for Computational Linguistics on Human Language Technologies: Short Papers</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="221" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Foster</surname></persName>
		</author>
		<title level="m">Treebanks gone bad. International Journal of Document Analysis and Recognition (IJDAR)</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="129" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Automatic linguistic annotation of large scale l2 databases: The ef-cambridge open language database (efcamdat)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeroen</forename><surname>Geertzen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theodora</forename><surname>Alexopoulou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st Second Language Research Forum</title>
		<meeting>the 31st Second Language Research Forum<address><addrLine>Somerville, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Cascadilla Proceedings Project</publisher>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Syntactic annotation of noncanonical linguistic structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hagen</forename><surname>Hirschmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seanna</forename><surname>Doolittle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anke</forename><surname>Lüdeling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Turning on the turbo: Fast third-order non-projective turbo parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">T</forename><surname>André</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (2)</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="617" to="622" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Universal dependency annotation for multilingual parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Ryan T Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yvonne</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Quirmbachbrundage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuzman</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ganchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Keith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Täckström</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="92" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Creating a manually error-tagged and shallow-parsed learner corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryo</forename><surname>Nagata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Whittaker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vera</forename><surname>Sheinman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1210" to="1219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The conll-2014 shared task on grammatical error correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hwee Tou Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mei</forename><surname>Siew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ted</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Briscoe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">Hendy</forename><surname>Hadiwinoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Susanto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bryant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CoNLL Shared Task</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The cambridge learner corpus: Error coding and analysis for lexicography and elt</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><surname>Nicholls</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Corpus Linguistics 2003 conference</title>
		<meeting>the Corpus Linguistics 2003 conference</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="572" to="581" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Universal dependencies v1: A multilingual treebank collection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Catherine</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Ginter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Hajič</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sampo</forename><surname>Pyysalo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Silveira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Conference on Language Resources and Evaluation</title>
		<meeting>the 10th International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<publisher>LREC</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Defining syntax for learner language annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marwa</forename><surname>Ragheb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Dickinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING (Posters)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="965" to="974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Syntactic annotation of learner corpora. Systematisk, variert, men ikke tilfeldig</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victoria</forename><surname>Rosén</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koenraad De</forename><surname>Smedt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="120" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Evaluating and automating the annotation of a learner corpus. Language Resources and Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandr</forename><surname>Rosen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jirka</forename><surname>Hana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barboraštindlovábarboraˇbarboraštindlová</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Feldman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="65" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Part-of-speech tagging guidelines for the penn treebank project (3rd revision)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatrice</forename><surname>Santorini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<publisher>CIS</publisher>
		</imprint>
	</monogr>
<note type="report_type">Technical Reports</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A gold standard dependency corpus for english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Silveira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Dozat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Catherine</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miriam</forename><surname>Samuel R Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International Conference on Language Resources and Evaluation</title>
		<meeting>the Ninth International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page">2014</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Using parse features for preposition selection and error detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Tetreault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Chodorow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the acl 2010 conference short papers</title>
		<meeting>the acl 2010 conference short papers</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="353" to="358" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A new dataset and method for automatically grading ESOL texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helen</forename><surname>Yannakoudakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ted</forename><surname>Briscoe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Medlock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="180" to="189" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
