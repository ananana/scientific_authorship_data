<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:12+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Adaptive Quality Estimation for Machine Translation</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>June 23-25 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Turchi</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonios</forename><surname>Anastasopoulos</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">National Technical University of Athens</orgName>
								<address>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jos√©</forename><forename type="middle">G C</forename><surname>De Souza</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Trento</orgName>
								<address>
									<country>Italy (</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Negri</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">)</forename><surname>Fbk -Fondazione</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bruno</forename><surname>Kessler</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<address>
									<addrLine>Via Sommarive 18</addrLine>
									<postCode>38123</postCode>
									<settlement>Trento</settlement>
									<country>Italy (</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Adaptive Quality Estimation for Machine Translation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="710" to="720"/>
							<date type="published">June 23-25 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The automatic estimation of machine translation (MT) output quality is a hard task in which the selection of the appropriate algorithm and the most predictive features over reasonably sized training sets plays a crucial role. When moving from controlled lab evaluations to real-life scenarios the task becomes even harder. For current MT quality estimation (QE) systems , additional complexity comes from the difficulty to model user and domain changes. Indeed, the instability of the systems with respect to data coming from different distributions calls for adaptive solutions that react to new operating conditions. To tackle this issue we propose an online framework for adaptive QE that targets reactivity and robustness to user and domain changes. Contrastive experiments in different testing conditions involving user and domain changes demonstrate the effectiveness of our approach.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>After two decades of steady progress, research in statistical machine translation (SMT) started to cross its path with translation industry with tan- gible mutual benefit. On one side, SMT research brings to the industry improved output quality and a number of appealing solutions useful to increase translators' productivity. On the other side, the market needs suggest concrete problems to solve, providing real-life scenarios to develop and eval- uate new ideas with rapid turnaround. The evolu- tion of computer-assisted translation (CAT) envi- ronments is an evidence of this trend, shown by the increasing interest towards the integration of suggestions obtained from MT engines with those derived from translation memories (TMs).</p><p>The possibility to speed up the translation pro- cess and reduce its costs by post-editing good- quality MT output raises interesting research chal- lenges. Among others, these include deciding what to present as a suggestion, and how to do it in the most effective way.</p><p>In recent years, these issues motivated research on automatic QE, which addresses the problem of estimating the quality of a translated sentence given the source and without access to reference translations ( <ref type="bibr">Blatz et al., 2003;</ref><ref type="bibr" target="#b30">Specia et al., 2009;</ref><ref type="bibr" target="#b22">Mehdad et al., 2012)</ref>. Despite the substantial progress done so far in the field and in success- ful evaluation campaigns <ref type="bibr" target="#b6">(Callison-Burch et al., 2012;</ref><ref type="bibr" target="#b5">Bojar et al., 2013)</ref>, focusing on concrete market needs makes possible to further define the scope of research on QE. For instance, moving from controlled lab testing scenarios to real work- ing environments poses additional constraints in terms of adaptability of the QE models to the vari- able conditions of a translation job. Such variabil- ity is due to two main reasons:</p><p>1. The notion of MT output quality is highly subjective <ref type="bibr" target="#b16">(Koponen, 2012;</ref><ref type="bibr" target="#b34">Turchi et al., 2013;</ref><ref type="bibr" target="#b33">Turchi and Negri, 2014)</ref>. Since the quality standards of individual users may vary considerably (e.g. according to their knowledge of the source and target lan- guages), the estimates of a static QE model trained with data collected from a group of post-editors might not fit with the actual judgements of a new user;</p><p>2. Each translation job has its own specifici- ties (domain, complexity of the source text, average target quality). Since data from a new job may differ from those used to train the QE model, its estimates on the new in- stances might result to be biased or uninfor- mative.</p><p>The ability of a system to self-adapt to the be-haviour of specific users and domain changes is a facet of the QE problem that so far has been disregarded. To cope with these issues and deal with the erratic conditions of real-world trans- lation workflows, we propose an adaptive ap- proach to QE that is sensitive and robust to dif- ferences between training and test data. Along this direction, our main contribution is a framework in which QE models can be trained and can continu- ously evolve over time accounting for knowledge acquired from post editors' work. Our approach is based on the online learning paradigm and exploits a key difference between such framework and the batch learning methods currently used. On one side, the QE models ob- tained with batch methods are learned exclusively from a predefined set of training examples under the assumption that they have similar characteris- tics with respect to the test data. This makes them suitable for controlled evaluation scenarios where such condition holds. On the other side, online learning techniques are designed to learn in a step- wise manner (either from scratch, or by refining an existing model) from new, unseen test instances by taking advantage of external feedback. This makes them suitable for real-life scenarios where the new instances to be labelled can considerably differ from the data used to train the QE model. To develop our approach, different online algo- rithms have been embedded in the backbone of a QE system. This required the adaptation of its standard batch learning workflow to:</p><p>1. Perform online feature extraction from a source-target pair (i.e. one instance at a time instead of processing an entire training set);</p><p>2. Emit a prediction for the input instance;</p><p>3. Gather user feedback for the instance (i.e. calculating a "true label" based on the amount of user post-editions);</p><p>4. Send the true label back to the model to up- date its predictions for future instances.</p><p>Focusing on the adaptability to user and domain changes, we report the results of comparative ex- periments with two online algorithms and the stan- dard batch approach. The evaluation is carried out by measuring the global error of each algorithm on test sets featuring different degrees of similar- ity with the data used for training. Our results show that the sensitivity of online QE models to different distributions of training and test instances makes them more suitable than batch methods for integration in a CAT framework.</p><p>Our adaptive QE infrastructure has been re- leased as open source. Its C++ implementation is available at http://hlt.fbk.eu/technologies/ aqet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>QE is generally cast as a supervised machine learning task, where a model trained from a col- lection of (source, target, label) instances is used to predict labels 1 for new, unseen test items <ref type="bibr" target="#b31">(Specia et al., 2010)</ref>.</p><p>In the last couple of years, research in the field received a strong boost by the shared tasks orga- nized within the WMT workshop on SMT, 2 which is also the framework of our first experiment in ¬ß5. Current approaches to the tasks proposed at WMT have mainly focused on three main direc- tions, namely: i) feature engineering, as in <ref type="bibr" target="#b12">(Hardmeier et al., 2012;</ref><ref type="bibr" target="#b11">de Souza et al., 2013b;</ref><ref type="bibr" target="#b26">Rubino et al., 2013b</ref>), ii) model learning with a variety of classification and regres- sion algorithms, as in <ref type="bibr" target="#b3">(Bicici, 2013;</ref><ref type="bibr" target="#b0">Beck et al., 2013;</ref>, and iii) feature selec- tion as a way to overcome sparsity and overfitting issues, as in ( . Being optimized to perform well on specific WMT sub-tasks and datasets, current systems re- flect variations along these directions but leave im- portant aspects of the QE problem still partially investigated or totally unexplored. 3 Among these, the necessity to model the diversity of human qual- ity judgements and correction strategies <ref type="bibr" target="#b16">(Koponen, 2012;</ref>) calls for solu- tions that: i) account for annotator-specific be- haviour, thus being capable of learning from inher- ently noisy datasets produced by multiple annota- tors, and ii) self-adapt to changes in data distribu- tion, learning from user feedback on new, unseen test items.</p><p>These interconnected issues are particularly rel- evant in the CAT framework, where translation jobs from different domains are routed to pro- fessional translators with different idiolect, back- ground and quality standards.</p><p>The first aspect, modelling annotators' individ- ual behaviour and interdependences, has been ad- dressed by , who explored multi-task Gaussian Processes as a way to jointly learn from the output of multiple annotations. This technique is suitable to cope with the unbalanced distribution of training instances and yields better models when heterogeneous training datasets are available.</p><p>The second problem, the adaptability of QE models, has not been explored yet. A common trait of all current approaches, in fact, is the re- liance on batch learning techniques, which assume a "static" nature of the world where new unseen instances that will be encountered will be similar to the training data. <ref type="bibr">4</ref> However, similarly to trans- lation memories that incrementally store translated segments and evolve over time incorporating users style and terminology, all components of a CAT tool (the MT engine and the mechanisms to assign quality scores to the suggested translations) should take advantage of translators feedback.</p><p>On the MT system side, research on adaptive approaches tailored to interactive SMT and CAT scenarios explored the online learning protocol <ref type="bibr" target="#b17">(Littlestone, 1988)</ref> to improve various aspects of the decoding process ( <ref type="bibr" target="#b7">Cesa-Bianchi et al., 2008;</ref><ref type="bibr" target="#b23">Ortiz-Mart√≠nez et al., 2010;</ref><ref type="bibr" target="#b19">Mart√≠nez-G√≥mez et al., 2011;</ref><ref type="bibr" target="#b20">Mart√≠nez-G√≥mez et al., 2012;</ref><ref type="bibr" target="#b21">Mathur et al., 2013;</ref><ref type="bibr" target="#b2">Bertoldi et al., 2013)</ref>.</p><p>As regards QE models, our work represents the first investigation on incremental adaptation by ex- ploiting users feedback to provide targeted (sys- tem, user, or project specific) quality judgements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Online QE for CAT environments</head><p>When operating with advanced CAT tools, transla- tors are presented with suggestions (either match- ing fragments from a translation memory or auto- matic translations produced by an MT system) for each sentence of a source document. Before being approved and published, translation suggestions may require different amounts of post-editing op- erations depending on their quality. Each post-edition brings a wealth of dynamic knowledge about the whole translation process and the involved actors. For instance, adaptive QE components could exploit information about the distance between automatically assigned scores and the quality standards of individual translators (inferred from the amount of their corrections) to "profile" their behaviour.</p><p>The online learning paradigm fits well with this research objective. In the online framework, dif- ferently from the batch mode, the learning al- gorithm sequentially processes an unknown se- quence of instances X = x 1 , x 2 , ..., x n , returning a prediction p(x i ) as output at each step. Differ- ences between p(x i ) and the true labe√Æ p(x i ) ob- tained as feedback are used by the learner to refine the next prediction p(x i+1 ).</p><p>In our experiments on adaptive QE we aim to predict the quality of the suggested translations in terms of HTER, which measures the minimum edit distance between the MT output and its man- ually post-edited version in the <ref type="bibr">[0,</ref><ref type="bibr">1]</ref> interval. <ref type="bibr">5</ref> In this scenario:</p><p>‚Ä¢ The set of instances X is represented by (source, target) pairs;</p><p>‚Ä¢ The prediction p(x i ) is the automatically es- timated HTER score;</p><p>‚Ä¢ The true labe√Æ p(x i ) is the actual HTER score calculated over the target and its post-edition.</p><p>At each step of the process, the goal of the learner is to exploit user post-editions to reduce the differ- ence between the predicted HTER values and the true labels for the following (source, target) pairs.</p><p>As depicted in <ref type="figure" target="#fig_0">Figure 1</ref>, this is done as follows:</p><p>1. At step i, an unlabelled (source, target) pair x i is sent to a feature extraction component.  4. The true label is sent back to the online al- gorithm for a stepwise model improvement. The updated model is then ready to process the following instance x i+1 .</p><p>This new paradigm for QE makes it possible to: i) let the QE system learn from one point at a time without complete re-training from scratch, ii) customize the predictions of an existing QE model with respect to a specific situation (post- editor or domain), or even iii) build a QE model from scratch when training data is not available.</p><p>For the sake of clarity it is worth observing that, at least in principle, a model built in a batch fash- ion could also be adapted to new test data. For in- stance, this could be done by running periodic re- training routines once a certain amount of new la- belled instances has been collected (de facto mim- icking an online process). Such periodic updates, however, would not represent a viable solution in the CAT framework where post-editors' work can- not be slowed by time-consuming procedures to re-train core system components from scratch. <ref type="bibr">7</ref> goo.gl/nkh2rE</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation framework</head><p>To measure the adaptation capability of different QE models, we experiment with a range of condi- tions defined by variable degrees of similarity be- tween training and test data.</p><p>The degree of similarity depends on several fac- tors: the MT engine used, the domain of the docu- ments to be translated, and the post-editing style of individual translators. In our experiments, the de- gree of similarity is measured in terms of ‚àÜHTER, which is computed as the absolute value of the dif- ference between the average HTER of the training and test sets. Large values indicate a low simi- larity between training and test data and a more challenging scenario for the learning algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental setup</head><p>In the range of possible evaluation scenarios, our experiments cover:</p><p>‚Ä¢ One artificial setting ( ¬ß5) obtained from the WMT12 QE shared task data, in which train- ing/test instances are arranged to reflect ho- mogeneous distributions of the HTER labels.</p><p>‚Ä¢ Two settings obtained from data collected with a CAT tool in real working condi- tions, in which different facets of the adap- tive QE problem interact with each other.</p><p>In the first (user change, ¬ß6.1), train- ing and test data from the same domain are obtained from different users. In the sec-ond (user+domain change, ¬ß6.2), train- ing and test data are obtained from different users and domains.</p><p>For each setting, we compare an adaptive and an empty model against a system trained in batch mode. The adaptive model is built on top of an existing model created from the training data and exploits the new test instances to refine its predic- tions in a stepwise manner. The empty model only learns from the test set, simulating the worst con- dition where training data is not available. The batch model is built by learning only from the training data and is evaluated on the test set with- out exploiting information from the test instances.</p><p>Each model is also compared against a common baseline for regression tasks, which is particularly relevant in settings featuring different data distri- butions between training and test sets. This base- line (¬µ henceforth) is calculated by labelling each instance of the test set with the mean HTER score of the training set. Previous works ( <ref type="bibr" target="#b25">Rubino et al., 2013a</ref>) demonstrated that its results can be partic- ularly hard to beat.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Performance indicator and feature set</head><p>To measure the adaptability of our model to a given test set we compute the Mean Absolute Er- ror (MAE), a metric for regression problems also used in the WMT QE shared tasks. The MAE is the average of the absolute errors e i = |f i ‚àí y i |, where f i is the prediction of the model and y i is the true value for the i th instance.</p><p>As our focus is on the algorithmic aspect, in all experiments we use the same feature set, which consists of the seventeen features proposed in ( <ref type="bibr" target="#b30">Specia et al., 2009)</ref>. This feature set, fully de- scribed in <ref type="bibr" target="#b6">(Callison-Burch et al., 2012)</ref>, takes into account the complexity of the source sentence (e.g. number of tokens, number of translations per source word) and the fluency of the target trans- lation (e.g. language model probabilities). The results of previous WMT QE shared tasks have shown that these baseline features are particularly competitive in the regression task (with only few systems able to beat them at WMT12).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Online algorithms</head><p>In our experiments we evaluate two online algo- rithms, OnlineSVR <ref type="bibr" target="#b24">(Parrella, 2007)</ref>  <ref type="bibr" target="#b1">8</ref> and Passive-Aggressive Perceptron ( <ref type="bibr" target="#b9">Crammer et al., 2006</ref>), 9 by comparing their performance with a batch learning strategy based on the Scikit-learn implementation of Support Vector Regression (SVR). <ref type="bibr">10</ref> The choice of the OnlineSVR and Passive- Aggressive (OSVR and PA henceforth) is moti- vated by different considerations. From a perfor- mance point of view, as an adaptation of -SVR which proved to be one of the top performing algo- rithms in the regression QE tasks at WMT, OSVR seems to be the best candidate. For this reason, we use the online adaptation of -SVR proposed by <ref type="figure">(Ma et al., 2003)</ref>. The goal of OnlineSVR is to find a way to add each new sample to one of three sets (support, empty, error) maintaining the con- sistency of a set of conditions known as Karush- Kuhn Tucker (KKT) conditions. For each new point, OSVR starts a cycle where the samples are moved across the three sets until the KKT condi- tions are verified and the new point is assigned to one of the sets. If the point is identified as a sup- port vector, the parameters of the model are up- dated. This allows OSVR to benefit from the pre- diction capability of -SVR in an online setting.</p><p>From a practical point of view, providing the best trade off between accuracy and computational time <ref type="bibr" target="#b13">(He and Wang, 2012)</ref>, PA represents a good solution to meet the demand of efficiency posed by the CAT framework. For each instance i, after emitting a prediction and receiving the true label, PA computes the -insensitive hinge loss function. If its value is larger than the tolerance parameter (), the weights of the model are updated as much as the aggressiveness parameter C allows. In con- trast with OSVR, which keeps track of the most important points seen in the past (support vectors), the update of the weights is done without consid- ering the previously processed i-1 instances. Al- though it makes PA faster than OSVR, this is a riskier strategy because it may lead the algorithm to change the model to adapt to outlier points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments with WMT12 data</head><p>The motivations for experiments with training and test data featuring homogeneous label distribu- tions are twofold. First, since in this artificial sce- nario adaptation capabilities are not required for the QE component, batch methods operate in the ideal conditions (as training and test are indepen-  <ref type="table">Table 1</ref>: MAE of the best performing batch, adaptive and empty models on WMT12 data. Training sets of different size and the test set have been arranged to reflect homogeneous label distributions. dent and identically distributed). This makes pos- sible to obtain from batch models the best possible performance to compare with. Second, this sce- nario provides the fairest conditions for such com- parison because, in principle, online algorithms are not favoured by the possibility to learn from the diversity of the test instances.</p><p>For our controlled experiments we use the WMT12 English-Spanish corpus, which consists of 2,254 source-target pairs (1,832 for training, 422 for test). The HTER labels for our regression task are calculated from the post-edited version and the target sentences provided in the dataset.</p><p>To avoid biases in the label distribution, the WMT12 training and test data have been merged, shuffled, and eventually separated to generate three training sets of different size (200, 600, and 1500 instances), and one test set with 754 in- stances. For each algorithm, the training sets are used for learning the QE models, optimizing pa- rameters (i.e. C, , the kernel and its parame- ters for SVR and OSVR; tolerance and aggressive- ness for PA) through grid search in 10-fold cross- validation.</p><p>Evaluation is carried out by measuring the per- formance of the batch (learning only from the training set), the adaptive (learning from the train- ing set and adapting to the test set), and the empty (learning from scratch from the test set) models in terms of global MAE scores on the test set. <ref type="table">Table 1</ref> reports the results achieved by the best performing algorithm for each type of model (batch, adaptive, empty). As can be seen, close MAE values show a similar behaviour for the three types of models. 11 With the same amount of train- ing data, the performance of the batch and the adaptive models (in this case always obtained with OSVR) is almost identical. This demonstrates that, as expected, the online algorithms do not take <ref type="bibr">11</ref> Results marked with the " * " symbol are NOT statisti- cally significant compared to the corresponding batch model. The others are always statistically significant at p‚â§0.005, cal- culated with approximate randomization <ref type="bibr" target="#b35">(Yeh, 2000).</ref> advantage of test data with a label distribution sim- ilar to the training set. All the models outper- form the baseline, even if the minimal differences confirm the competitiveness of such a simple ap- proach.</p><p>Overall, these results bring some interesting in- dications about the behaviour of the different on- line algorithms. First, the good results achieved by the empty models (less than one MAE point separates them from the best ones built on the largest training set) suggest their high potential when training data are not available. Second, our results show that OSVR is always the best performing algorithm for the adaptive and empty models. This suggests a lower capability of PA to learn from instances similar to the training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments with CAT data</head><p>To experiment with adaptive QE in more realis- tic conditions we used a CAT tool <ref type="bibr">12</ref> to collect two datasets of (source, target, post edited tar- get) English-Italian tuples.The source sentences in the datasets come from two documents from dif- ferent domains, respectively legal (L) and infor- mation technology (IT). The L document, which was extracted from a European Parliament resolu- tion published on the EUR-Lex platform, 13 con- tains 164 sentences. The IT document, which was taken from a software user manual, contains 280 sentences. The source sentences were translated with two SMT systems built by training the Moses toolkit ( <ref type="bibr" target="#b14">Koehn et al., 2007</ref>) on parallel data from the two domains (about 2M sentences for IT and 1.5M for L). Post-editions were collected from eight professional translators (four for each docu- ment) operating with the CAT tool in real working conditions.</p><p>According to the way they are created, the two datasets allow us to evaluate the adaptability of different QE models with respect to user changes  within the same domain ( ¬ß6.1), as well as user and domain changes at the same time ( ¬ß6.2).</p><p>For each document D (L or IT), these two sce- narios are obtained by dividing D into two parts of equal size (80 instances for L and 140 for IT). The result is one training set and one test set for each post-editor within the same domain. For the user change experiments, training and test sets are selected from different post-editors within the same domain. For the user+domain change experiments, training and test sets are selected from different post-editors in different domains.</p><p>On each combination of training and test sets, the batch, adaptive, and empty models are trained and evaluated in terms of global MAE scores on the test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Dealing with user changes</head><p>Among the possible combinations of training and test data from different post-editors in the same domain, <ref type="table" target="#tab_3">Table 2</ref> refers to two opposite scenarios. For each domain, these respectively involve the most dissimilar and the most similar post-editors according to the ‚àÜHTER. Also in this case, for each model (batch, adaptive and empty) we only report the MAE of the best performing algorithm.</p><p>The first scenario defines a challenging situation where two post-editors (rad and cons) are charac- terized by opposite behaviour. As evidenced by the high ‚àÜHTER values, one of them (rad) is the most "radical" post-editor (performing more cor- rections) while the other (cons) is the most "con- servative" one. As shown in <ref type="table" target="#tab_3">Table 2</ref>, global MAE scores for the online algorithms (both adaptive and empty) indicate their good adaptation capabilities. This is evident from the significant improvements both over the baseline (¬µ) and the batch models. Interestingly, the best results are always achieved by the empty models (with MAE reductions up to 10 points when tested on rad in the L domain, and 3.2 points when tested on rad in the IT do- main). These results (MAE reductions are always statistically significant) suggest that, when deal- ing with datasets with very different label distri- butions, the evident limitations of batch methods are more easily overcome by learning from scratch from the feedback of a new post-editor. This also holds when the amount of test points to learn from is limited, as in the L domain where the test set contains only 80 instances. From the application- oriented perspective that motivates our work, con- sidering the high costs of acquiring large and rep- resentative QE training data, this is an important finding.</p><p>The second scenario defines a less challeng- ing situation where the two post-editors (sim1 and sim2) are characterized by the most similar be- haviour (small ‚àÜHTER). This scenario is closer to the situation described in Section ¬ß5. Also in this case MAE results for the adaptive and empty mod- els are slightly worse, but not significantly, than those of the batch models and the baseline. How- ever, considering the very small amount of "unin- formative" instances to learn from (especially for the empty models), these lower results are not sur- prising.</p><p>A closer look at the behaviour of the online al- gorithms in the two domains leads to other obser- vations. First, OSVR always outperforms PA for the empty models and when post-editors have sim-  <ref type="table">Table 3</ref>: MAE of the best performing batch, adaptive and empty models on CAT data collected from different users and domains.</p><p>ilar behaviour, which are situations where the al- gorithm does not have to quickly adapt or react to sudden changes. Second, PA seems to perform better for the adaptive models when the post-editors have sig- nificantly different behaviour and a quick adapta- tion to the incoming points is required. This can be motivated by the fact that PA relies on a simpler and less robust learning strategy that does not keep track of all the information coming from the previ- ously processed instances, and can easily modify its weights taking into consideration the last seen point (see Section ¬ß3). For OSVR the addition of new points to the support set may have a limited effect on the whole model, in particular if the num- ber of points in the set is large. This also results in a different processing time for the two algo- rithms. <ref type="bibr">14</ref> For instance, in the empty configurations on IT data, OSVR devotes 6.0 ms per instance to update the model, while PA devotes 4.8 ms, which comes at the cost of lower performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Dealing with user and domain changes</head><p>In the last round of experiments we evaluate the reactivity of different online models to simultane- ous user and domain changes. To this aim, our QE models are created using a training set coming from one domain (L or IT), and then used to pre- dict the HTER labels for the test instances coming from the other domain (e.g. training on L, testing on IT).</p><p>Among the possible combinations of training <ref type="bibr">14</ref> Their complexity depends on the number of features (f ) and the number of previously seen instances (n). While for PA it is linear in f, i.e. O(f), for OSVR it is quadratic in n, i.e. O(n 2 *f). and test data, <ref type="table">Table 3</ref> refers to scenarios involv- ing the most conservative and radical post-editors in each domain (previously identified with cons and rad) 15 . In the table, results are ordered ac- cording to the ‚àÜHTER computed between the se- lected post-editor in the training domain (e.g. L cons) and the selected post-editor in the test do- main (e.g. IT rad). For the sake of comparison, we also report (grey rows) the results of the ex- periments within the same domain presented in ¬ß6.1. For each type of model (batch, adaptive and empty) we only show the MAE obtained by the best performing algorithm.</p><p>Intuitively, dealing with simultaneous user and domain changes represents a more challenging problem compared to the previous setting where only post-editors changes were considered. Such intuition is confirmed by the results of the adaptive models that outperform both the baseline (¬µ) and the batch models even for low ‚àÜHTER values. Al- though in these cases the distance between train- ing and test data is comparable to the experiments with similar post-editors working in the same do- main (sim1 and sim2), here the predictive power of the batch models seems in fact to be lower. The same holds also for the empty models except in two cases where the ‚àÜHTER is the smallest (2.2 and 5.0). This is a strong evidence of the fact that, in case of domain changes, online models can still learn from new test instances even if they have a label distribution similar to the training set.</p><p>When the distance between training and test in- creases, our results confirm our previous findings about the potential of the empty models. The ob- served MAE reductions range in fact from 10.4 to 12.9 points for the two combinations with the highest ‚àÜHTER.</p><p>From the algorithmic point of view, our results indicate that OSVR achieves the best performance for all the combinations involving user and domain changes. This contrasts with the results of most of the combinations involving only user changes with post-editors characterized by opposite behaviour (grey rows in <ref type="table">Table 3</ref>). However, it has to be re- marked that in the case of heterogeneous datasets the difference between the two algorithms is al- ways very high. In our experiments, when PA out- performs OSVR, its MAE results are significantly lower and vice-versa (respectively up to 1.5 and 1.7 MAE points). This suggests that, although PA is potentially capable of achieving higher results and better adapt to the new test points, its instabil- ity makes it less reliable for practical use.</p><p>As a final analysis of our results, we investi- gated how the performance of the different types of models (batch, adaptive, empty) relates to the distance between training and test sets. To this aim, we computed the Pearson correlation be- tween the ‚àÜHTER (column 3 in <ref type="table">Table 3</ref>) and the MAE of each model (columns 5, 6 and 8), which respectively resulted in 0.9 for the batch, 0.63 for the adaptive and -0.07 for the empty model. These values confirm that batch models are heavily af- fected by the dissimilarity between training and test data: large differences in the label distribution imply higher MAE results and vice-versa. This is in line with our previous findings about batch models that, learning only from the training set, cannot leverage possible dissimilarities of the test set. The lower correlation observed for the adap- tive models also confirms our intuitions: adapting to the new test points, these models are in fact more robust to differences with the training data. As expected, the results of the empty models are completely uncorrelated with the ‚àÜHTER since they only use the test set. This analysis confirms that, even when dealing with different domains, the similarity between the training and test data is one of the main factors that should drive the choice of the QE model. When this distance is minimal, batch models can be a reasonable option, but when the gap between train- ing and test data increases, adaptive or empty mod- els are a preferable choice to achieve good results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In the CAT scenario, each translation job can be seen as a complex situation where the user (his personal style and background), the source doc- ument (the language and the domain) and the un- derlying technology (the translation memory and the MT engine that generate translation sugges- tions) contribute to make the task unique. So far, the adaptability to such specificities (a major chal- lenge for CAT technology) has been mainly sup- ported by the evolution of translation memories, which incrementally store translated segments in- corporating the user style. The wide adoption of translation memories demonstrates the importance of capitalizing on such information to increase translators productivity.</p><p>While this lesson recently motivated research on adaptive MT decoders that learn from user cor- rections, nothing has been done to develop adap- tive QE components. In the first attempt to ad- dress this problem, we proposed the application of the online learning protocol to leverage users feedback and to tailor QE predictions to their qual- ity standards. Besides highlighting the limitations of current batch methods to adapt to user and domain changes, we performed an application- oriented analysis of different online algorithms fo- cusing on specific aspects relevant to the CAT sce- nario. Our results show that the wealth of dynamic knowledge brought by user corrections can be ex- ploited to refine in a stepwise fashion the qual- ity judgements in different testing conditions (user changes as well as simultaneous user and domain changes).</p><p>As an additional contribution, to spark further research on this facet of the QE problem, our adap- tive QE infrastructure (integrating all the compo- nents and the algorithms described in this paper) has been released as open source. Its C++ im- plementation is available at http://hlt.fbk.eu/ technologies/aqet.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Online QE workflow. &lt;src&gt;, &lt;trg&gt; and &lt;pe&gt; respectively stand for the source sentence, the target translation and the post-edited target.</figDesc><graphic url="image-1.png" coords="4,138.30,62.81,320.95,208.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc>MAE of the best performing batch, adaptive and empty models on CAT data collected from different users in the same domain.</figDesc><table></table></figure>

			<note place="foot" n="1"> Possible label types include post-editing effort scores (e.g. 1-5 Likert scores indicating the estimated percentage of MT output that has to be corrected), HTER values (Snover et al., 2006), and post-editing time (e.g. seconds per word). 2 http://www.statmt.org/wmt13/ 3 For a comprehensive overview of the QE approaches proposed so far we refer the reader to the WMT12 and WMT13 QE shared task reports (Callison-Burch et al., 2012; Bojar et al., 2013).</note>

			<note place="foot" n="4"> This assumption holds in the WMT evaluation scenario, but it is not necessarily valid in real operating conditions.</note>

			<note place="foot" n="8"> http://www2.imperial.ac.uk/ Àú gmontana/ onlinesvr.htm</note>

			<note place="foot" n="9"> https://code.google.com/p/sofia-ml/ 10 http://scikit-learn.org/</note>

			<note place="foot" n="12"> MateCat-http://www.matecat.com/ 13 http://eur-lex.europa.eu/</note>

			<note place="foot" n="15"> For brevity, we omit the results for the other post-editors which, however, show similar trends with respect to the previous experiments.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work has been partially supported by the EC-funded project MateCat (ICT-2011.4.2-287688).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">SHEF-Lite: When less is more for translation quality estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kashif</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 718</title>
		<meeting>the 718</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<title level="m">th Workshop on Statistical Machine Translation</title>
		<meeting><address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Cache-based Online Adaptation for Machine Translation Enhanced Computer Assisted Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mauro</forename><surname>Cettolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the XIV Machine Translation Summit</title>
		<meeting>the XIV Machine Translation Summit<address><addrLine>Nice, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1147" to="1162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Feature decay algorithms for fast deployment of accurate statistical machine translation systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ergun</forename><surname>Bicici</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8 th Workshop on Statistical Machine Translation</title>
		<meeting>the 8 th Workshop on Statistical Machine Translation<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Alberto Sanchis, and Nicola Ueffing. 2003. Confidence Estimation for Machine Translation. Summer workshop final report</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blatz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erin</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simona</forename><surname>Gandrabur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cyril</forename><surname>Goutte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kulesza</surname></persName>
		</author>
		<imprint>
			<publisher>JHU/CLSP</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Buck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<title level="m">Proceedings of the 8 th Workshop on Statistical Machine Translation, WMT-2013</title>
		<meeting>the 8 th Workshop on Statistical Machine Translation, WMT-2013<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1" to="44" />
		</imprint>
	</monogr>
	<note>Findings of the 2013 Workshop on Statistical Machine Translation</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Findings of the 2012 Workshop on Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7 th Workshop on Statistical Machine Translation (WMT&apos;12)</title>
		<meeting>the 7 th Workshop on Statistical Machine Translation (WMT&apos;12)<address><addrLine>Montr√©al, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="10" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Online Learning Algorithms for Computer-Assisted Translation. Deliverable D4.2, SMART: Statistical Multilingual Analysis for Retrieval and Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Nico√¨ O Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandor</forename><surname>Reverberi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Szedmak</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Modelling Annotator Bias with Multi-task Gaussian Processes: An Application to Machine Translation Quality Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51 st Annual Meeting of the Association for Computational Linguistics, ACL-2013</title>
		<meeting>the 51 st Annual Meeting of the Association for Computational Linguistics, ACL-2013<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="32" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Shai Shalev-Shwartz, and Yoram Singer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ofer</forename><surname>Dekel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Keshet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="551" to="585" />
			<date type="published" when="2006-12" />
		</imprint>
	</monogr>
	<note>Online Passive-Aggressive Algorithms</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">FBK-UEdin participation to the WMT13 quality estimation shared task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">C</forename><surname>Jos√©</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Buck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Turchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Negri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8 th Workshop on Statistical Machine Translation</title>
		<meeting>the 8 th Workshop on Statistical Machine Translation<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Exploiting Qualitative Information from Automatic Word Alignment for Cross-lingual NLP Tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">C</forename><surname>Jos√©</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>De Souza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Miquelesp√¨ A-Gomis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Turchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Negri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51 st Annual Meeting of the Association for Computational Linguistics-Short Papers</title>
		<meeting>the 51 st Annual Meeting of the Association for Computational Linguistics-Short Papers<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="771" to="776" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Tree Kernels for Machine Translation Quality Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Hardmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J√∂rg</forename><surname>Tiedemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Workshop on Statistical Machine Translation (WMT&apos;12)</title>
		<meeting>the Seventh Workshop on Statistical Machine Translation (WMT&apos;12)<address><addrLine>Montr√©al, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="109" to="113" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A Comparison and Improvement of Online Learning Algorithms for Sequence Labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houfeng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on Computational Linguistics (COLING 2012)</title>
		<meeting>the 24th International Conference on Computational Linguistics (COLING 2012)<address><addrLine>Mumbai, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1147" to="1162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Moses: open source toolkit for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brooke</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wade</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ond≈ôej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Herbst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45 th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL &apos;07</title>
		<meeting>the 45 th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL &apos;07</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="177" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Post-editing Time as a Measure of Cognitive Effort</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarit</forename><surname>Koponen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilker</forename><surname>Aziz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luciana</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AMTA 2012 Workshop on Post-editing Technology and Practice (WPTP 2012)</title>
		<meeting>the AMTA 2012 Workshop on Post-editing Technology and Practice (WPTP 2012)<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Comparing Human Perceptions of Post-editing Effort with Post-editing Operations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Maarit Koponen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Workshop on Statistical Machine Translation</title>
		<meeting>the Seventh Workshop on Statistical Machine Translation<address><addrLine>Montr√©al, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="181" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning Quickly when Irrelevant Attributes Abound: A New Linear-Threshold Algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Littlestone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1988" />
			<biblScope unit="page" from="285" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Accurate Online Support Vector Regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junshui</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Theiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Perkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="2683" to="2703" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Online Learning via Dynamic Reranking for Computer Assisted Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascual</forename><surname>Mart√≠nez-G√≥mez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Germ√°n</forename><surname>Sanchis-Trilles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Casacuberta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th international conference on Computational linguistics and intelligent text processing-Volume Part II, CICLing&apos;11</title>
		<meeting>the 12th international conference on Computational linguistics and intelligent text processing-Volume Part II, CICLing&apos;11</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Online adaptation strategies for statistical machine translation in postediting scenarios</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascual</forename><surname>Mart√≠nez-G√≥mez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Germ√°n</forename><surname>Sanchis-Trilles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Casacuberta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="3193" to="3203" />
			<date type="published" when="2012-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Online Learning Approaches in Computer Assisted Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prashant</forename><surname>Mathur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mauro</forename><surname>Cettolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8 th Workshop on Statistical Machine Translation</title>
		<meeting>the 8 th Workshop on Statistical Machine Translation<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Match without a Referee: Evaluating MT Adequacy without Reference Translations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yashar</forename><surname>Mehdad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7 th Workshop on Statistical Machine Translation</title>
		<meeting>the 7 th Workshop on Statistical Machine Translation<address><addrLine>Montr√©al, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="171" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Online learning for interactive statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Ortiz-Mart√≠nez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ismael</forename><surname>Garc√≠a-Varea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Casacuberta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, HLT &apos;10</title>
		<meeting><address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="546" to="554" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Online support vector regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Parrella</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<pubPlace>Genoa, Italy</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Department of Information Science, University of</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Master&apos;s Thesis</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Topic Models for Translation Quality Estimation for Gisting Purposes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Rubino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">C</forename><surname>Jos√©</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>De Souza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Machine Translation Summit XIV</title>
		<meeting>the Machine Translation Summit XIV<address><addrLine>Nice, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The CNGL-DCU-Prompsit translation systems for WMT13</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Rubino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Toral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cort√©s</forename><surname>Va√≠llo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofeng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Doherty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8 th Workshop on Statistical Machine Translation</title>
		<meeting>the 8 th Workshop on Statistical Machine Translation<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="211" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">An Efficient and User-friendly Tool for Machine Translation Quality Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kashif</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Turchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9 t h International Conference on Language Resources and Evaluation</title>
		<meeting>the 9 t h International Conference on Language Resources and Evaluation<address><addrLine>Reykjavik, Iceland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A study of translation edit rate with targeted human annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Snover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Dorr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linnea</forename><surname>Micciulla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Makhoul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Association for Machine Translation in the Americas</title>
		<meeting>Association for Machine Translation in the Americas<address><addrLine>Cambridge, Massachusetts, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="223" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The SDL Language Weaver Systems in the WMT12 Quality Estimation Shared Task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nguyen</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziyuan</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7 th Workshop on Statistical Machine Translation (WMT&apos;12)</title>
		<meeting>the 7 th Workshop on Statistical Machine Translation (WMT&apos;12)<address><addrLine>Montr√©al, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="145" to="151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Estimating the sentence-level quality of machine translation systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Cancedda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Dymetman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Turchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nello</forename><surname>Cristianini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13 th Annual Conference of the European Association for Machine Translation (EAMT&apos;09)</title>
		<meeting>the 13 th Annual Conference of the European Association for Machine Translation (EAMT&apos;09)<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="28" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Machine Translation Evaluation versus Quality Estimation. Machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhwaj</forename><surname>Raj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Turchi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="39" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">QuEst-A Translation Quality Estimation Framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kashif</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">C</forename><surname>Jos√©</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>De Souza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51 st Annual Meeting of the Association for Computational Linguistics: System Demonstrations, ACL2013</title>
		<meeting>the 51 st Annual Meeting of the Association for Computational Linguistics: System Demonstrations, ACL2013<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="79" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Automatic Annotation of Machine Translation Datasets with Binary Quality Judgements</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Turchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Negri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9 th International Conference on Language Resources and Evaluation</title>
		<meeting>the 9 th International Conference on Language Resources and Evaluation<address><addrLine>Reykjavik, Iceland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Coping with the Subjectivity of Human Judgements in MT Quality Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Turchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8 th Workshop on Statistical Machine Translation</title>
		<meeting>the 8 th Workshop on Statistical Machine Translation<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="240" to="251" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">More Accurate Tests for the Statistical Significance of Result Differences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Yeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th conference on Computational linguistics (COLING</title>
		<meeting>the 18th conference on Computational linguistics (COLING<address><addrLine>Saarbrucken, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="947" to="953" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
