<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:44+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Abstractive Multi-Document Summarization via Phrase Selection and Merging *</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidong</forename><surname>Bing</surname></persName>
							<email>lbing@cs.cmu.edu,</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piji</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Liao</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wai</forename><surname>Lam</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Guo</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><forename type="middle">J</forename><surname>Passonneau</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Center for Computational Learning Systems</orgName>
								<orgName type="institution">Columbia University</orgName>
								<address>
									<settlement>New York</settlement>
									<region>NY</region>
									<country>USA §</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Machine Learning Department</orgName>
								<orgName type="department" key="dep2">Department of Systems Engineering and Engineering Management</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">The Chinese University of Hong Kong † Yahoo Labs</orgName>
								<address>
									<settlement>Sunnyvale</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Abstractive Multi-Document Summarization via Phrase Selection and Merging *</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1587" to="1597"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We propose an abstraction-based multi-document summarization framework that can construct new sentences by exploring more fine-grained syntactic units than sentences , namely, noun/verb phrases. Different from existing abstraction-based approaches , our method first constructs a pool of concepts and facts represented by phrases from the input documents. Then new sentences are generated by selecting and merging informative phrases to maximize the salience of phrases and meanwhile satisfy the sentence construction constraints. We employ integer linear optimization for conducting phrase selection and merging simultaneously in order to achieve the global optimal solution for a summary. Experimental results on the benchmark data set TAC 2011 show that our framework outperforms the state-of-the-art models under automated pyramid evaluation metric, and achieves reasonably well results on manual linguistic quality evaluation.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Existing multi-document summarization (MDS) methods fall in three categories: extraction-based, compression-based and abstraction-based. Most * The work described in this paper is substan- tially supported by grants from the Research and De- velopment Grant of Huawei Technologies Co. Ltd (YB2013090068/TH138232) and the Research Grant Coun- cil of the Hong Kong Special Administrative Region, China (Project Codes: 413510 and 14203414). The work was done when Weiwei Guo was in Columbia Uni- versity summarization systems adopt the extraction- based approach which selects some original sen- tences from the source documents to create a short summary ( <ref type="bibr" target="#b11">Erkan and Radev, 2004;</ref><ref type="bibr" target="#b48">Wan et al., 2007)</ref>. However, the restriction that the whole sen- tence should be selected potentially yields some overlapping information in the summary. To this end, some researchers apply compression on the selected sentences by deleting words or phrases <ref type="bibr" target="#b27">(Knight and Marcu, 2000;</ref><ref type="bibr" target="#b34">Lin, 2003;</ref><ref type="bibr" target="#b53">Zajic et al., 2006</ref>; <ref type="bibr" target="#b22">Harabagiu and Lacatusu, 2010;</ref>, which is the compression-based method. Yet, these compressive summarization models cannot merge facts from different source sentences, because all the words in a summary sentence are solely from one source sentence.</p><p>In fact, previous investigations show that human-written summaries are more abstractive, which can be regarded as a result of sentence ag- gregation and fusion <ref type="bibr" target="#b7">(Cheung and Penn, 2013;</ref><ref type="bibr" target="#b24">Jing and McKeown, 2000</ref>). Some works, albeit less popular, have studied abstraction-based ap- proach that can construct a sentence whose frag- ments come from different source sentences. One important work developed by Barzilay and McK- eown (2005) employed sentence fusion, followed by <ref type="bibr" target="#b13">(Filippova and Strube, 2008;</ref><ref type="bibr" target="#b14">Filippova, 2010)</ref>. These works first conduct clustering on sentences to compute the salience of topical themes. Then, sentence fusion is applied within each cluster of related sentences to generate a new sentence con- taining common information units of the sen- tences. The abstractive-based approaches gather information across sentence boundary, and hence have the potential to cover more content in a more concise manner.</p><p>In this paper, we propose an abstractive MDS framework that can construct new sentences by exploring more fine-grained syntactic units than sentences, namely, noun/verb phrases (NPs/VPs). This idea is based on two observations. First, the major constituent phrases loosely correspond to the concepts and facts. After reading a set of doc- uments describing the same topic or event, a per- son digests these documents as key concepts and facts in his/her mind, such as "an armed man" and "walked into an Amish school" from <ref type="figure" target="#fig_0">Figure  1</ref>. Second, a summary writer re-organizes the key concepts and facts to form new sentences for the summary. Accordingly, our proposed framework has two major components corresponding to the above observations. The first component creates a pool of concepts and facts represented by NPs and VPs from the input documents. A salience score is computed for each phrase by exploiting redun- dancy of the document content in a global man- ner. The second component constructs new sen- tences by selecting and merging phrases based on their salience scores, and ensures the validity of new sentences using a integer linear optimization model.</p><p>The contribution of this paper is two folds. (1) We extract NPs/VPs from constituency trees to represent key concepts/facts, and merge them to construct new sentences, which allows more sum- mary content units (SCUs) <ref type="bibr" target="#b39">(Nenkova and Passonneau, 2004</ref>) to be included in a sentence by break- ing the original sentence boundaries. (2) The de- signed optimization framework for addressing the problem is unique and effective. Our optimiza- tion algorithm simultaneously selects and merges a set of phrases that maximize the number of cov- ered SCUs in a summary. Meanwhile, since the basic unit is phrases, we design compatibility re- lations among NPs and VPs, as well as other op- timization constraints, to ensure that the gener- ated sentences contain correct facts. Compared with the sentence fusion approaches that compute salience scores of sentence clusters, our proposed framework explores a more fine-grained textual unit (i.e., phrases), and maximizes the salience of selected phrases in a global manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Description of Our Framework</head><p>We first introduce how to extract NPs and VPs from constituency trees, and subsequently calcu- late salience scores for them. Then we formulate the sentence generation task as an optimization problem, and design constraints. In the end, we perform several post-processing steps to improve the order and the readability of the generated sen- tences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Phrase Salience Calculation</head><p>The first component decomposes the sentences in documents into a set of noun phrases (NPs) de- rived from the subject parts of a constituency tree and a set of verb-object phrases (VPs), represent- ing potential key concepts and key facts, respec- tively. These phrases will serve as the basic ele- ments for sentence generation.</p><p>We employ Stanford parser <ref type="bibr" target="#b26">(Klein and Manning, 2003</ref>) to obtain a constituency tree for each input sentence. After that, we extract NPs and VPs from the tree as follows: (1) The NPs and VPs that are the direct children of the sentence node (repre-sented by the S node) are extracted. (2) VPs (NPs) in a path on which all the nodes are VPs (NPs) are also recursively extracted and regarded as hav- ing the same parent node S. Recursive operation in the second step will only be carried out in two levels since the phrases in the lower levels may not be able to convey a complete fact. Take the tree in <ref type="figure" target="#fig_0">Figure 1</ref> as an example, the corresponding sentence is decomposed into phrases "An armed man", "walked into an Amish school, sent the boys outside and tied up and shot the girls, killing three of them", "walked into an Amish school", "sent the boys outside", and "tied up and shot the girls, killing three of them". 1 Because of the recursive operation, the extracted phrases may have over- laps. Later, we will show how to avoid such over- lapping in phrase selection.</p><p>A salience score is calculated for each phrase to indicate its importance. Different types of salience can be incorporated in our framework, such as position-based method <ref type="bibr" target="#b52">(Yih et al., 2007)</ref>, statis- tical feature based method <ref type="bibr" target="#b50">(Woodsend and Lapata, 2012</ref>), concept-based method ), etc. One key characteristic of our approach is that the considered basic units are phrases instead of sentences. Such finer granularity leaves more room for better global salience score by poten- tially covering more distinct facts. In our imple- mentation, we adopt a concept-based weight in- corporating the position information. The con- cept set is designated to be the union set of un- igrams, bigrams, and named entities in the docu- ments. We remove stopwords and perform lemma- tization before extracting unigrams and bigrams. The position-based term frequency is used in the concept weighting scheme. When counting the frequency, each occurrence of a concept in an in- put document is weighted with the paragraph po- sition. The weight larger than 1 is given to the concept occurrences in the first few paragraphs. Specifically, the weight of the first paragraph is B and the weight decreases as the position of the paragraph increases from the beginning of the doc- <ref type="bibr">1</ref> We only consider the recursive operation for a VP with more than one parallel sub-VPs, such as the highest VP in <ref type="figure" target="#fig_0">Figure 1</ref>. The sub-VPs following modal, link or auxiliary verbs are not extracted as individual VPs. In addition, we also extract the clauses functioning as subjects of sentences as NPs, such as "that clause". Note that we also mention such clauses as "noun phrase" although their syntactic labels could be "SBAR" or "S". ument. The weighting function is:</p><formula xml:id="formula_0">H(p) = ρ p * B if p &lt; −(log B/ log ρ) 1 otherwise ,</formula><p>(1) where p is the position of the paragraph starting from 0, from beginning of the document, and ρ is a positive constant and smaller than 1. Then, the salience of a phrase is calculated as the summed weights of its concepts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">New Sentence Construction Model</head><p>The construction of new sentences is formulated as an optimization problem which is able to si- multaneously generate a group of sentences. Each new sentence is composed of one NP and at least one VP, where the NP and VPs may come from different source sentences. In the process of new sentence generation, the compatibility relation be- tween NP and VP and a variety of summarization requirements are jointly considered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Compatibility Relation</head><p>Compatibility relation is designed to indicate whether an NP and a VP can be used to form a new sentence. For example, the NP "Police" from another sentence should not be the subject of the VP "sent the boys outside" extracted from <ref type="figure" target="#fig_0">Figure  1</ref>. We use some heuristics to find compatibility, and then expand the compatibility relation to more phrases by extracting coreference.</p><p>To find coreference NPs (different mentions for the same entity), we first conduct coreference res- olution for each document with Stanford corefer- ence resolution package ( <ref type="bibr" target="#b28">Lee et al., 2013</ref>). We adopt those resolution rules that are able to achieve high quality and address our need for summariza- tion. In particular, Sieve 1, 2, 3, 4, 5, 9, and 10 in the package are used. A set of clusters are ob- tained and each cluster contains the mentions that refer to the same entity in a document. The clus- ters from different documents in the same topic are merged by matching the named entities. After merging, the mentions that are not NPs extracted in the phrase extraction step are removed in each cluster. Two NPs in the same cluster are deter- mined as alternative of each other.</p><p>To find alternative VPs, Jaccard Index is em- ployed as the similarity measure. Specifically, each VP is represented as a set of its concepts and the index value is calculated for each pair of VPs. If the value is larger than a threshold, the two VPs are determined as alternative of each other.</p><p>We then define an indicator matrix Γ |N||V| , in which Γ[i, j] = 1 if an NP N i and a VP V j come from the same node S in the constituency tree, oth- erwise, Γ[i, j] = 0. Let˜NLet˜ Let˜N i and˜Vand˜ and˜V i represent the al- ternative phrases of N i and V i as described above. The compatibility matrix˜Γmatrix˜ matrix˜Γ |N||V| is defined as fol- lows:</p><formula xml:id="formula_1">˜ Γ[p, q] =            1 if N p ∈ ˜ N i ∧ Γ[i, q] = 1 1 if V q ∈ ˜ V j ∧ Γ[p, j] = 1 1 if Γ[p, q] = 1 0 otherwise (2)</formula><p>where˜Γwhere˜ where˜Γ[p, q] = 1 means N p and V q are compat- ible/permitted for constructing a new sentence. ˜ Γ is the final compatibility matrix that we use in the optimization. The first case of Equation 2 implies that if N p and N i are coreferent, N p can replace N i and serve as the subject of N i 's VP (i.e., V q ). The second case implies that if V q is very similar to V j , V q can be concatenated to V j 's NP (i.e., N p ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Phrase-based Content Optimization</head><p>The overall objective function of our optimization formulation to select NPs and VPs is defined as:</p><formula xml:id="formula_2">max{ i α i S N i − i&lt;j α ij (S N i + S N j )R N ij + i β i S V i − i&lt;j β ij (S V i + S V j )R V ij },<label>(3)</label></formula><p>where α i and β i are selection indicators for the NP N i and the VP V i , respectively. S N i and S V i are the salience scores of N i and V i . α ij and β ij are co-occurrence indicators of pairs (N i , N j ) and (V i , V j ). R N ij and R V ij are the similarity of pairs (N i , N j ) and (V i , V j ). If N i and N j are coreferent, R N ij = 1. Otherwise, the similarity is calculated with the above Jaccard Index based method. The notations are summarized in <ref type="table" target="#tab_1">Table 1</ref>.</p><p>Specifically, we maximize the salience score of the selected NPs and VPs as indicated by the first and the third terms in Equation 3, and penalize the selection of similar NP pairs and similar VP pairs as indicated by the second and the fourth terms. Meanwhile, the phrase selection is governed by a set of constraints so that the selected phrases can generate valid sentences. The constraints will be explained in details in Section 2.2.3.</p><p>One characteristic of our objective function is that NPs and VPs are treated differently, i.e., there</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Notation Description Ni, Vi</head><p>Noun phrase i and verb phrase i αi, βi Selection indicators of Ni and Vi αij, βij</p><p>Co-occurrence indicators of pairs (Ni, Nj) and  are different selection/penalty terms for NP and VP. Such design enables us to avoid the false penalty between an NP and a VP. For example, the algorithm produces two sentences: the first sen- tence is "the gunman shot ..." with an NP "the gunman", and the other sentence has a VP "con- firmed the gunman died". Obviously, we should not penalize the redundancy between them, be- cause mentioning the gunman is necessary in both sentences.</p><formula xml:id="formula_3">(Vi, Vj) S N i , S V i</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Sentence Generation Constraints</head><p>To summarize the related sentences in the docu- ments, human writers usually merge the important facts in different VPs about the same entity into a single sentence, and omit the trivial facts. Also, the same entity is likely to be described by coref- erent NPs. Therefore, in our approach, only one NP is selected and employed as the subject of the newly generated sentence, which is then concate- nated with the merged facts (i.e., VPs). If the com- patibility entry˜Γentry˜ entry˜Γ <ref type="bibr">[i, j]</ref> for N i and V j is 1, we de- fine a sentence generation indicator˜γindicator˜ indicator˜γ ij to indicate whether both N i and V j are selected to construct a new sentence in the summary. We design the following groups of constraints to realize our aim of phrase selection and new sentence construction. The objective function and constraints are linear, therefore the problem can be solved by existing Integer Linear Programming (ILP) solvers such as simplex algorithm <ref type="bibr" target="#b9">(Dantzig and Thapa, 1997)</ref>. NP validity. To maintain the consistency be- tween the selection indicator α and the compati- bility entry˜Γentry˜ entry˜Γ for NP N i , we introduce two con- straints as follows:</p><formula xml:id="formula_4">∀i, j, α i ≥ ˜ γ ij ; ∀i, j ˜ γ ij ≥ α i .<label>(4)</label></formula><p>These two constraints work together to ensure the valid assignment of α according to the compatibil- ity entry˜Γentry˜ entry˜Γ. VP legality. Similarly, the following require- ment guarantees the consistency between the se- lection indicator β and the compatibility entry˜Γentry˜ entry˜Γ for selected VP V i :</p><formula xml:id="formula_5">∀j, i ˜ γ ij = β j .<label>(5)</label></formula><p>The above two constraints jointly ensure that the selected NPs and VPs are able to form new sum- mary sentences according to the values of sentence generation indicators. Not i-within-i. Two phrases in the same path of a constituency tree cannot be chosen at the same time:</p><formula xml:id="formula_6">if ∃V k V j , then β k + β j ≤ 1, if ∃N k N j , then α k + α j ≤ 1.<label>(6)</label></formula><p>For example, "walked into an Amish school, sent the boys outside and tied up and shot the girls, killing three of them" and "walked into an Amish school" cannot be both incorporated in the sum- mary, because of the obvious redundancy. Phrase co-occurrence. These constraints control the co-occurrence relation of NPs or VPs. For NPs, we introduce three constraints:</p><formula xml:id="formula_7">α ij − α i ≤ 0,<label>(7)</label></formula><formula xml:id="formula_8">α ij − α j ≤ 0,<label>(8)</label></formula><formula xml:id="formula_9">α i + α j − α ij ≤ 1.<label>(9)</label></formula><p>Constraints 7 to 9 ensure a valid solution of NP selection. The first two constraints state that if the units N i and N j co-occur in the summary (i.e., α ij = 1), then we have to include them individ- ually (i.e., α i = 1 and α j = 1). The third con- straint is the inverse of the first two. Similarly, the constraints for VPs are as follows:</p><formula xml:id="formula_10">β ij − β i ≤ 0,<label>(10)</label></formula><formula xml:id="formula_11">β ij − β j ≤ 0,<label>(11)</label></formula><formula xml:id="formula_12">β i + β j − β ij ≤ 1.<label>(12)</label></formula><p>Sentence number. In abstractive summariza- tion, we do not prefer to generate many short sen- tences. This is controlled by:</p><formula xml:id="formula_13">i α i ≤ K,<label>(13)</label></formula><p>where K is the maximum number of sentences.</p><p>Short sentence avoidance. We do not select the VPs from very short sentences because a short sentence normally cannot convey a complete key fact <ref type="bibr" target="#b50">(Woodsend and Lapata, 2012)</ref>.</p><formula xml:id="formula_14">if l(S) &lt; M, V i ∈ S, then β i = 0,<label>(14)</label></formula><p>where M is the threshold of the sentence length. Pronoun avoidance. We exclude the NPs that are pronouns from being selected as the sub- ject of the new sentences. As previously observed <ref type="bibr" target="#b50">(Woodsend and Lapata, 2012)</ref>, pronouns are nor- mally not used by human summary writers. It is because the summary is short and the narration relation of sentences is relatively simple so that pronouns are not needed. Moreover, in automatic summary, pronouns will cause ambiguity in the summary, especially when the sentence order is automatically determined. Therefore, we model the constraint as:</p><formula xml:id="formula_15">if N i is pronoun, then α i = 0.<label>(15)</label></formula><p>Length constraint. The overall length of the selected NPs and VPs is no larger than a limit L:</p><formula xml:id="formula_16">i {l(N i ) * α i } + j {l(V j ) * β j } ≤ L,<label>(16)</label></formula><p>where l() is the word-based length of a phrase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Postprocessing</head><p>Recall that we require that one NP and at least one VP compose a sentence. Thus, we form a raw sentence with a selected NP as the subject followed by the corresponding selected VPs that are indicated by sentence generation indicator˜γindicator˜ indicator˜γ ij having the value 1. The VPs in a summary sen- tence are ordered according to their natural order if they come from the same document. Otherwise, they are ordered according to the timestamps of the corresponding documents. After that, if the to- tal length is smaller than L, we add conjunctions such as "and" and "then" to concatenate the VPs for improving the readability of the newly gener- ated sentences. The pseudo-timestamp of a sen- tence is defined as the earliest timestamp of its VPs and the sentences are ordered based on their pseudo-timestamps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Relation to Existing MDS Approaches</head><p>Many existing extraction-based and compression- based MDS approaches could be regarded as spe- cial cases under our framework: (1) To simulate extraction-based summarization, we just need to constrain that the highest NP and the highest VP from the same sentence are selected simultane- ously. In addition, no NPs and VPs in lower lev- els can be selected. Thus, the output only con- tains the original sentences of the source docu- ments. (2) To simulate compression-based sum- marization, we can adapt our framework to con- duct sentence selection and sentence compression in a joint manner. Specifically, we only need to re- strict that the NP and VPs of a summary sentence must come from the same original sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental Setup</head><p>The data set of traditional summarization task in Text Analysis Conference (TAC) 2011 is used to evaluate the performance of our approach. This data set is the latest one and it contains 44 topics. Each topic falls into one of 5 predefined event cat- egories and contains 10 related news documents. There are four writers to write model summaries for each topic. The data set of traditional summarization task in TAC 2010 is employed as the development/tuning data set. This data set contains 46 topics from the same predefined categories. Each topic also has 10 documents and 4 model summaries.</p><p>Based on the tuning set, the key parameters of our model are set as follows. The constants B and ρ in the weighting function are set to 6 and 0.5 repectively. The similarity threshold in obtaining the alternative VPs is 0.75. We did not observe sig- nificant difference between cosine similarity and Jaccard Index.</p><p>We mainly evaluate the system by pyramid eval- uation. To gain a comprehensive understanding, we also evaluate by ROUGE evaluation and man- ual linguistic quality evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results with Pyramid Evaluation</head><p>The pyramid evaluation metric (Nenkova and Pas- sonneau, 2004) involves semantic matching of summary content units (SCUs) so as to recognize alternate realizations of the same meaning. Differ- ent weights are assigned to SCUs based on their frequency in model summaries. A weighted inven- tory of SCUs named a pyramid is created, which constitutes a resource for investigating alternate realizations of the same meaning. Such property makes pyramid method more suitable to evalu- Auto-pyr <ref type="bibr">Auto-pyr Rank in System (Th: .6)</ref>  <ref type="table" target="#tab_1">(Th: .65) TAC 2011  Our  0.905  0.793  NA  22  0.878  0.775  1  43  0.875  0.756  2  17</ref> 0.860 0.741 3  <ref type="bibr">, 2004</ref>). Therefore, in recent summarization evaluation workshops such as TAC, the pyramid is used as the major metric.</p><p>Since manual pyramid evaluation is time- consuming, and the exact evaluation scores are not reproducible especially when the assessors for our results are different from those of TAC, we employ the automated version of pyramid pro- posed in ( <ref type="bibr" target="#b43">Passonneau et al., 2013</ref>). The automated pyramid scoring procedure relies on distributional semantics to assign SCUs to a target summary. Specifically, all n-grams within sentence bounds are extracted, and converted into 100 dimension latent topical vectors via a weighted matrix fac- torization model <ref type="bibr" target="#b21">(Guo and Diab, 2012)</ref>. Simi- larly, the contributors and the label of an SCU are transformed into 100 dimensional vector rep- resentations. An SCU is assigned to a summary if there exists an n-gram such that the similarity score between the SCU low dimensional vector and the n-gram low dimensional vector exceeds a threshold. <ref type="bibr" target="#b43">Passonneau et al. (2013)</ref> showed that the distributional similarity based method pro- duces automated scores that correlate well with manual pyramid scores, yielding more accurate pyramid scores than string matching based auto- mated methods <ref type="bibr" target="#b23">(Harnly et al., 2005</ref>   <ref type="table" target="#tab_2">Table 2</ref> shows the comparison with them under the auto- mated pyramid evaluation. Our method achieves the best results in both thresholds, which means that our method is able to find more semantic con- tent units (SCUs) than the state-of-the-art system in TAC 2011. In addition, paired t-test (with p &lt; 0.01) comparing our model with the best system in TAC 2011, i.e., System 22, shows that the per- formance of our model is significantly better. It is worth noting that the three systems used additional external linguistic resources: System 22 used a Wikipedia corpus for providing domain knowl- edge, System 17 and 43 defined some category- specific features. Without any domain adaption, our framework can still achieve encouraging per- formance.</p><p>We calculate Pearson's correlation to measure how well the automatic pyramid approximates the manual pyramid scores for 50 system submissions in TAC 2011. The values are 0.91 and 0.93 for thresholds 0.6 and 0.65 respectively. It demon- strates that the automated pyramid is reliable to differentiate the performance of different methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results with ROUGE Evaluation</head><p>As mentioned above, we favor the pyramid evalua- tion over the ROUGE score because it can measure the summary quality beyond simply string match- ing. Here, we also provide ROUGE score for our reference. ROUGE-1.5.5 package 3 is employed with the same parameters as in TAC. The results are summarized in <ref type="table" target="#tab_4">Table 3</ref>. Our performance is slightly better than System 22, and it is not as good as System 43 and 17. The reason is that System 43 and 17 used category-specific features and trained the feature weights with the category information in TAC 2010 data. These features help them se- lect better category-specific content for the sum- mary. However, the usability of such features de- pends on the availability of predefined categories in the summarization task, as well as the avail- ability of training data with the same predefined categories for estimating feature weights. There- fore, the adaptability of these methods is limited to some extent. In contrast, our framework does not define any category-specific feature and only uses TAC 2010 data to tune the parameters for general summarization purpose.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Linguistic Quality Evaluation</head><p>The linguistic quality of summaries is evaluated using the five linguistic quality questions on gram- maticality (Q1), non-redundancy (Q2), referential clarity (Q3), focus (Q4), and coherence (Q5) in Document Understanding Conferences (DUC). A Likert scale with five levels is employed with 5 be- ing very good with 1 being very poor. A summary was blindly evaluated by three assessors on each question. System 22 performed better than Sys- tem 43 and 17 in TAC 2011 on the evaluation of readability, which is an aggregation of the above questions. Considering the intensive labor force of manual assessment, we only conduct comparison with System 22.</p><p>The results are given in <ref type="table">Table 4</ref>. On average, the two systems perform very closely. System 22 is an extraction-based method that picks the orig- inal sentences, hence it achieves higher score in Q1 grammaticality, while our approach has some new sentences with grammar mistakes, which is a common problem for abstractive methods and de- serves more future research effort. For Q4 focus, our score is higher than System 22, which reveals that our summary sentences are relatively more co- hesive. The score of Q3 referential clarity shows that the referential relation is basically clear in our summaries, even when new sentences are automat- ically generated. In general, ignoring the gram- maticality scores, our system still performs better than System 22. Specifically, the average scores of our system and System 22 on the last four ques- tions are 3.37 and 3.33 respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Qualitative Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Analysis of Summary Sentence Type</head><p>There are three types of sentences in the sum- maries generated by our framework, namely, new System Q1 Q2 Q3 Q4 Q5 AVG Our 3.67 3.50 3.90 3.23 2.83 3.43 22 4.13 3.50 3.97 2.97 2.87 3.49 <ref type="table">Table 4</ref>: Evaluation of linguistic quality.</p><p>sentences, compressed sentences, and original sentences. A new sentence is constructed by merg- ing the phrases from different original sentences. A compressed sentence is generated by deleting phrases from an original sentence. An original sentence in the summary is directly extracted from the input documents.</p><p>The percentage of different types of sentences in our summaries is calculated. About 33% of the summary sentences are newly constructed. This demonstrates that our framework has good capa- bility of merging phrases from the original sen- tences so as to convey more information in com- pacted summaries. In addition, about 44% of the summary sentences are generated by compression. It shows a unique characteristic of our framework: sentence construction and sentence compression are conducted in a unified model. <ref type="table">Table 5</ref> shows the summary of the first topic, i.e., "Amish Shooting", by our framework. The summary sentence ID and the sentence type are given in the form of "[summary sentence ID: sentence type]". Each selected phrase and the original sentence ID where the phrase originated are given in the form of "{selected phrase (original sentence ID)}". There are three compressed sentences with IDs 1, 2, and 4, one new sentence with ID 3, and two original sentences with IDs 5 and 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Case Study</head><p>The new sentence is constructed from the fol- lowing original sentences in which the extracted NPs and VPs are indicated with colored parenthe- ses: [1:C] {An armed man (25)} {walked into an Amish school (25)} {tied up and shot the girls, killing three of them. (25)} [2:C] {A man who laid siege to a one-room Amish schoolhouse (64)} {told his wife shortly be- fore opening fire that he had molested two young girls who were his relatives decades ago (64)} {was tormented by dreams of molesting again. (64)} [3:N] {Charles Carl Roberts IV (84)} {killed himself as police stormed the building (85)} {left what they described as rambling notes for his family. (150)} [4:C] {The gun- man (145)} {was not Amish (145)} {had not attended the school. (145)} [5:O] {The shoot- ings (148)} {occurred about 10:45 a.m.(148)} [6:O] {Police (149)} {could offer no explana- tion for the killings. (149)} <ref type="table">Table 5</ref>: The summary of "Amish Shooting" topic.</p><p>The NPs of these sentences are coreferent so that some of their VPs are merged and concatenated with one NP, i.e., "Charles Carl Roberts IV".</p><p>The summary sentences with IDs 1, 2, and 4 are compressions from the following original sen- tences respectively:</p><p>(25): (NP An armed man) (VP(VP walked into an Amish school), (VP sent the boys outside) and (VP tied up and shot the girls, killing three of them)), (NP authorities) (VP said). (64): (NP(NP A man)who laid siege to a one-room Amish schoolhouse),(VP killing five girls),(VP(VP told his wife shortly before open- ing fire that he had molested two young girls who were his relatives decades ago)and(VP was tor- mented by "dreams of molesting again")),(NP authorities)(VP said Tue). (145): According to media reports, (NP the gunman) (VP(VP was not Amish) and (VP had not attended the school)).</p><p>Some uncritical information is excluded from the summary sentences, such as "sent the boys outside", "authorities said", etc. In addition, the VP "killing five girls" of the original sentence with ID 64 is also excluded since it has significant redundancy with the summary sentence with ID 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Existing multi-document summarization (MDS) works can be classified into three categories: extraction-based approaches, compression-based approaches, and abstraction-based approaches.</p><p>Extraction-based approaches are the most stud- ied of the three. Early studies mainly followed a greedy strategy in sentence selection <ref type="bibr" target="#b5">(C ¸ elikyilmaz and Hakkani-Tür, 2011;</ref><ref type="bibr" target="#b20">Goldstein et al., 2000;</ref><ref type="bibr" target="#b48">Wan et al., 2007)</ref>. Each sentence in the docu- ments is firstly assigned a salience score. Then, sentence selection is performed by greedily select- ing the sentence with the largest salience score among the remaining ones. The redundancy is controlled during the selection by penalizing the remaining ones according to their similarity with the selected sentences. An obvious drawback of such greedy strategy is that it is easily trapped in local optima. Later, unified models are pro- posed to conduct sentence selection and redun- dancy control simultaneously <ref type="bibr" target="#b37">(McDonald, 2007;</ref><ref type="bibr" target="#b12">Filatova and Hatzivassiloglou, 2004;</ref><ref type="bibr" target="#b52">Yih et al., 2007;</ref><ref type="bibr" target="#b19">Gillick et al., 2007;</ref><ref type="bibr" target="#b31">Lin and Bilmes, 2010;</ref><ref type="bibr" target="#b32">Lin and Bilmes, 2012;</ref><ref type="bibr" target="#b46">Sipos et al., 2012)</ref>. How- ever, extraction-based approaches are unable to evaluate the salience and control the redundancy on the granularity finer than sentences. Thus, the selected sentences may still contain unimportant or redundant phrases.</p><p>Compression-based approaches have been in- vestigated to alleviate the above limitation. As a natural extension of the extractive method, the early works adopted a two-step approach <ref type="bibr" target="#b34">(Lin, 2003;</ref><ref type="bibr" target="#b53">Zajic et al., 2006;</ref><ref type="bibr" target="#b18">Gillick and Favre, 2009</ref>). The first step selects the sentences, and the second step removes the unimportant or redundant units from the sentences. Recently, integrated models have been proposed that jointly conduct sentence extraction and compression <ref type="bibr" target="#b36">(Martins and Smith, 2009;</ref><ref type="bibr" target="#b49">Woodsend and Lapata, 2010;</ref><ref type="bibr" target="#b0">Almeida and Martins, 2013;</ref><ref type="bibr" target="#b3">Berg-Kirkpatrick et al., 2011;</ref>. Note that our model also jointly con- ducts phrase selection and phrase merging (new sentence generation). Nonetheless, compressive methods are unable to merge the related facts from different sentences.</p><p>On the other hand, abstraction-based ap- proaches can generate new sentences based on the facts from different source sentences. In addition to the previously mentioned sentence fusion work, new directions have been explored. Researchers developed an information extraction based ap- proach that extracts information items (Genest and Lapalme, 2011) or abstraction schemes <ref type="bibr" target="#b17">(Genest and Lapalme, 2012)</ref> as components for generat- ing sentences. Summary revision was also inves- tigated to improve the quality of automatic sum- mary by rewriting the noun phrases or people ref- erences in the summaries <ref type="bibr" target="#b40">(Nenkova, 2008;</ref><ref type="bibr" target="#b45">Siddharthan et al., 2011</ref>). Sentence generation with word graph was applied for summarizing customer opinions and chat conversations ( <ref type="bibr" target="#b15">Ganesan et al., 2010;</ref><ref type="bibr" target="#b38">Mehdad et al., 2014</ref>).</p><p>Recently, the factors of information certainty and timeline in MDS task were explored ( <ref type="bibr" target="#b47">Wan and Zhang, 2014;</ref><ref type="bibr" target="#b51">Yan et al., 2011</ref>). Researchers also explored some variants of the typical MDS setting, such as query-chain focused summarization that combines aspects of update summarization and query-focused summarization ( <ref type="bibr" target="#b2">Baumel et al., 2014)</ref>, and hierarchical summa- rization that scales up MDS to summarize a large set of documents ( <ref type="bibr" target="#b8">Christensen et al., 2014)</ref>. A data-driven method for mining sentence structures on large news archive was proposed and utilized to summarize unseen news events ( <ref type="bibr" target="#b44">Pighin et al., 2014</ref>). Moreover, some works ( <ref type="bibr" target="#b35">Liu et al., 2012;</ref><ref type="bibr" target="#b25">Kågebäck et al., 2014;</ref><ref type="bibr" target="#b10">Denil et al., 2014;</ref><ref type="bibr" target="#b4">Cao et al., 2015</ref>) utilized deep learning techniques to tackle some summarization tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions and Future Work</head><p>We propose an abstractive MDS framework that constructs new sentences by exploring more fine- grained syntactic units, namely, noun phrases and verb phrases. The designed optimization frame- work operates on the summary level so that more complementary semantic content units can be in- corporated. The phrase selection and merging is done simultaneously to achieve global optimal. Meanwhile, the constructed sentences should sat- isfy the constraints related to summarization re- quirements such as NP/VP compatibility. Exper- imental results on TAC 2011 summarization data set show that our framework outperforms the top systems in TAC 2011 under the pyramid metric. For future work, one aspect is to enhance the grammar quality of the generated new sentences and compressed sentences. Another aspect is to improve time efficiency of our framework, and its major bottleneck is the time consuming ILP opti- mzation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The constituency tree of a sentence from a news document.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>On Monday morning, (NP Charles Carl Roberts IV) (VP (VP entered the West Nickel Mines Amish School in Lancaster County) and (VP shot 10 girls), (VP killing five)). (85): (NP Roberts) (VP killed himself as police stormed the building). (150): (NP Roberts) (VP left what they de- scribed as rambling notes for his family).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 : Notations.</head><label>1</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Comparison with the top 3 systems in 
TAC 2011. 

ate summaries. Another widely used evaluation 
metric is ROUGE (Lin and Hovy, 2003) and it 
evaluates summaries from word overlapping per-
spective. Because of the strict string matching, it 
ignores the semantic content units and performs 
better when larger sets of model summaries are 
available. In contrast to ROUGE, pyramid scor-
ing is robust with as few as four model summaries 
(Nenkova and Passonneau</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head></head><label></label><figDesc>). In this pa- per, we adopt the same setting as in (Passonneau et al., 2013): a 100 dimension matrix factorization model is learned on a domain independent corpus, which is drawn from sense definitions of WordNet and Wiktionary 2 , and Brown corpus. We exper-</figDesc><table>ROUGE-2 

ROUGE-SU4 
System P 
R 
F1 
P 
R 
F1 
Our 0.117 0.117 0.117 0.148 0.147 0.148 
22 
0.112 0.114 0.113 0.147 0.150 0.148 
43 
0.132 0.135 0.134 0.162 0.166 0.164 
17 
0.128 0.131 0.129 0.157 0.160 0.159 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Performance under ROUGE metric. 

iment with 2 threshold values, i.e., 0.6 and 0.65, 
similar to those used in (Passonneau et al., 2013). 
The top three systems in TAC 2011 evaluated 
with manual pyramid score were System 22 (Li et 
al., 2011), 43, and 17 (Ng et al., 2011). </table></figure>

			<note place="foot" n="2"> http://en.wiktionary.org/</note>

			<note place="foot" n="3"> http://www.berouge.com/Pages/default.aspx</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Fast and robust compressive summarization with dual decomposition and multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andre</forename><surname>Martins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="196" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Sentence fusion for multidocument news summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><forename type="middle">R</forename><surname>Mckeown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Linguist</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="297" to="328" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Query-chain focused summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tal</forename><surname>Baumel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Elhadad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="913" to="922" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Jointly learning to extract and compress</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Gillick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="481" to="490" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Ranking with recursive neural networks and its application to multi-document summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziqiang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C ¸</forename><surname>Asli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Elikyilmaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hakkani-Tür</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Concept-based classification for multi-document summarization</title>
	</analytic>
	<monogr>
		<title level="m">ICASSP</title>
		<imprint>
			<biblScope unit="page" from="5540" to="5543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Towards robust abstractive multi-document summarization: A caseframe analysis of centrality and domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jackie</forename><forename type="middle">Chi</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kit</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerald</forename><surname>Penn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1233" to="1242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Hierarchical summarization: Scaling up multi-document summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janara</forename><surname>Christensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gagan</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mausam</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="902" to="912" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Linear Programming 1: Introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mukund</forename><forename type="middle">N</forename><surname>Dantzig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Thapa</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York, Inc</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Misha</forename><surname>Denil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Demiraj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nando De</forename><surname>Freitas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.3830</idno>
		<title level="m">Modelling, visualising and summarising documents with a single convolutional neural network</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Lexrank: Graph-based lexical centrality as salience in text summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Günes</forename><surname>Erkan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><forename type="middle">R</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Artif. Int. Res</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="457" to="479" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A formal model for information selection in multisentence text extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Filatova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasileios</forename><surname>Hatzivassiloglou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Sentence fusion via dependency graph compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katja</forename><surname>Filippova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Strube</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="177" to="185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Multi-sentence compression: Finding shortest paths in word graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katja</forename><surname>Filippova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="322" to="330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Opinosis: A graph-based approach to abstractive summarization of highly redundant opinions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kavita</forename><surname>Ganesan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="340" to="348" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Framework for abstractive summarization using text-to-text generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre-</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Etienne</forename><surname>Genest</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guy</forename><surname>Lapalme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MTTG</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="64" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Fully abstractive approach to guided summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre-</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Etienne</forename><surname>Genest</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guy</forename><surname>Lapalme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="354" to="358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A scalable global model for summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Gillick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoit</forename><surname>Favre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on ILP for NLP</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="10" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The icsi summarization system at tac</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Gillick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Benoit Favre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hakkani-Tür</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Text Understanding Conference</title>
		<meeting>of Text Understanding Conference</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Multi-document summarization by sentence extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jade</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vibhu</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Kantrowitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-ANLPAutoSum</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="40" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Modeling sentences in the latent space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="864" to="872" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Using topic themes for multi-document summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanda</forename><surname>Harabagiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Finley</forename><surname>Lacatusu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">47</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Automation of summary evaluation by the pyramid method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Harnly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Passonneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Owen</forename><surname>Rambow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RANLP</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Cut and paste based text summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyan</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><forename type="middle">R</forename><surname>Mckeown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="178" to="185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Extractive summarization using continuous vector space models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikael</forename><surname>Kågebäck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olof</forename><surname>Mogren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nina</forename><surname>Tahmasebi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devdatt</forename><surname>Dubhashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVSC@EACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="31" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Accurate unlexicalized parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="423" to="430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Statisticsbased summarization-step one: Sentence compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI-IAAI</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="703" to="710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deterministic coreference resolution based on entity-centric, precision-ranked rules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heeyoung</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angel</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yves</forename><surname>Peirsman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Linguist</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="885" to="916" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Pkutm participation in tac2011</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huiying</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeyuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianguo</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of TAC</title>
		<meeting>TAC</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Reader-aware multi-document summarization via sparse coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piji</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidong</forename><surname>Bing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wai</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Liao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Multi-document summarization via budgeted maximization of submodular functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Bilmes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="912" to="920" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning mixtures of submodular shells with application to document summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Bilmes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="479" to="490" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Automatic evaluation of summaries using n-gram cooccurrence statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="71" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Improving summarization performance by sentence compression: a pilot study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the sixth international workshop on Information retrieval with Asian languages</title>
		<meeting>the sixth international workshop on Information retrieval with Asian languages</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Query-oriented multi-document summarization via unsupervised deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng-Hua</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Summarization with a joint model for sentence extraction and compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">T</forename><surname>André</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on ILP for NLP</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A study of global inference algorithms in multi-document summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECIR</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="557" to="564" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Abstractive summarization of spoken and written conversations based on phrasal queries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yashar</forename><surname>Mehdad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Carenini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">T</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1220" to="1230" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Evaluating content selection in summarization: The pyramid method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><forename type="middle">J</forename><surname>Passonneau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="145" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Entity-driven rewrite for multidocument summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Third International Joint Conference on Natural Language Processing</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="118" to="125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Swing: Exploiting category-specific information for guided summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Ping</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Bysani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Min Yen Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chew Lim Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of TAC</title>
		<meeting>TAC</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Exploiting timelines to enhance multidocument summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Ping</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min-Yen</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhoujun</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="923" to="933" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Automated pyramid scoring of summaries using distributional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><forename type="middle">J</forename><surname>Passonneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dolores</forename><surname>Perin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (2)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="143" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Modelling events through memory-based, open-ie patterns for abstractive summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniele</forename><surname>Pighin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Cornolti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enrique</forename><surname>Alfonseca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katja</forename><surname>Filippova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="892" to="901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Information status distinctions and referring expressions: An empirical study of references to people in news summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Advaith</forename><surname>Siddharthan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><surname>Mckeown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Linguist</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="811" to="842" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Large-margin learning of submodular summarization models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruben</forename><surname>Sipos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pannaga</forename><surname>Shivaswamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EACL</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="224" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Ctsum: Extracting more certain summaries for news articles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="787" to="796" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Manifold-ranking based topic-focused multidocument summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianguo</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="2903" to="2908" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Automatic generation of story highlights</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristian</forename><surname>Woodsend</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="565" to="574" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Multiple aspect summarization using integer linear programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristian</forename><surname>Woodsend</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-CoNLL</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="233" to="243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Evolutionary timeline summarization: A balanced optimization framework via iterative substitution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jahna</forename><surname>Otterbacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="745" to="754" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Multi-document summarization by maximizing informative content-words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucy</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hisami</forename><surname>Vanderwende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Suzuki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1776" to="1782" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Sentence compression as a component of a multi-document summarization system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Zajic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><forename type="middle">J</forename><surname>Dorr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DUC at NLT/NAACL</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
