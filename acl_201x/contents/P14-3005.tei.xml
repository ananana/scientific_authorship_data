<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:48+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Mapping-Based Approach for General Formal Human Computer Interaction Using Natural Language</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>June 22-27 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Letard</surname></persName>
							<email>letard@limsi.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">LIMSI CNRS</orgName>
								<orgName type="institution" key="instit2">LIMSI CNRS</orgName>
								<orgName type="institution" key="instit3">LIMSI CNRS</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sophie</forename><surname>Rosset</surname></persName>
							<email>rosset@limsi.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">LIMSI CNRS</orgName>
								<orgName type="institution" key="instit2">LIMSI CNRS</orgName>
								<orgName type="institution" key="instit3">LIMSI CNRS</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Illouz</surname></persName>
							<email>illouz@limsi.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">LIMSI CNRS</orgName>
								<orgName type="institution" key="instit2">LIMSI CNRS</orgName>
								<orgName type="institution" key="instit3">LIMSI CNRS</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A Mapping-Based Approach for General Formal Human Computer Interaction Using Natural Language</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the ACL 2014 Student Research Workshop</title>
						<meeting>the ACL 2014 Student Research Workshop <address><addrLine>Baltimore, Maryland USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="34" to="40"/>
							<date type="published">June 22-27 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We consider the problem of mapping natural language written utterances expressing operational instructions 1 to formal language expressions, applied to French and the R programming language. Developing a learning operational assistant requires the means to train and evaluate it, that is, a baseline system able to interact with the user. After presenting the guidelines of our work, we propose a model to represent the problem and discuss the fit of direct mapping methods to our task. Finally, we show that, while not resulting in excellent scores, a simple approach seems to be sufficient to provide a baseline for an interactive learning system.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Technical and theoretical advances allow achiev- ing more and more powerful and efficient opera- tions with the help of computers. However, this does not necessarily make it easier to work with the machine. Recent supervised learning work <ref type="bibr" target="#b1">(Allen et al., 2007;</ref><ref type="bibr" target="#b13">Volkova et al., 2013)</ref> exploited the richness of human-computer interaction for improving the efficiency of a human performed task with the help of the computer.</p><p>Contrary to most of what was proposed so far, our long term goal is to build an assistant system learning from interaction to construct a correct for- mal language (FL) command for a given natural language (NL) utterance, see <ref type="table">Table 1</ref>. However, designing such a system requires data collection, and early attempts highlighted the importance of usability for the learning process: a system that is hard to use (eg. having very poor performance) would prevent from extracting useful learning ex- amples from the interaction. We thus need to pro- vide the system with a basis of abilities and knowl- edge to allow both incremental design and to keep the interest of the users, without which data turn to be way more tedious to collect. We assume that making the system usable requires the ability to provide help to the user more often than it needs help from him/her, that is an accuracy over 50%.</p><p>We hypothesize that a parametrized direct mapping between the NL utterances and the FL commands can reach that score. A knowledge set K is built from parametrized versions of the asso- ciations shown in <ref type="table">Table 1</ref>. The NL utterance U best from K that is the closest to the request-utterance according to a similarity measure is chosen and its associated command C(U best ) is adapted to the parameters of the request-utterance and returned. For example, given the request-utterance U req : "Load the file data.csv", the system should rank the utterances of K by similarity with U req . Con- sidering the associations represented in <ref type="table">Table 1</ref>, the first utterance should be the best ranked, and the system should return the command: "var1 &lt;-read.csv("data.csv")". Note that several commands can be proposed at the same time to give the user alternate choices.</p><p>We use Jaccard, tf-idf, and BLEU similarity measures, and consider different selection strate- gies. We highlight that the examined similarity measures show enough complementarity to permit the use of combination methods, like vote or sta- tistical classification, to improve a posteriori the efficiency of the retrieval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Mapping Natural Language to Formal Language</head><p>Related problems have been previously processed using different learning methods. Branavan (2009,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NL utterances</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FL commands (in R)</head><p>1 Charge les données depuis "res.csv" var1=read.csv("res.csv")</p><p>Load the data from "res.csv"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2</head><p>Trace l'histogramme de la colonne 2 de tab plot(hist(tab <ref type="bibr">[[2]</ref>]))</p><p>Draw a bar chart with column 2 of tab 3 Dessine la répartition de la colonne 3 de tab plot(hist(tab <ref type="bibr">[[3]</ref>]))</p><p>Draw the distribution of column 3 of tab 4 Somme les colonnes 3 et 4 de tab var2=c(sum(tab <ref type="bibr">[3]</ref>),sum(tab <ref type="bibr">[4]</ref>))</p><p>Compute the sum of columns 3 and 4 of tab 5 Somme les colonnes 3 et 4 de tab</p><formula xml:id="formula_0">var3=sum(c(tab[[3]],tab[[4]]))</formula><p>Compute the sum of columns 3 and 4 of tab <ref type="table">Table 1</ref>: A sample of NL utterances to FL commands mapping These examples specify the expected command to be returned for each utterance. The tokens in bold font are linked with the commands parameters, cf. section 4. Note that the relation between utterances and commands is a n to n. Several utterances can be associated to the same command and conversely.</p><p>2010) uses reinforcement learning to map En- glish NL instructions to a sequence of FL com- mands. The mapping takes high-level instructions and their constitution into account. The scope of usable commands is yet limited to graphical interaction possibilities. As a result, the learn- ing does not produce highly abstract schemes. In the problematic of interactive continuous learning, Artzi and Zettlemoyer (2011) build by learning a semantic NL parser based on combinatory cate- gorial grammars (CCG). <ref type="bibr" target="#b8">Kushman and Barzilay (2013)</ref> also use CCG in order to generate regu- lar expressions corresponding to their NL descrip- tions. This constructive approach by translation allows to generalize over learning examples, while the expressive power of regular expressions cor- respond to the type-3 grammars of the Chomsky hierarchy. This is not the case for the program- ming languages since they are at least of type-2. <ref type="bibr" target="#b14">Yu and Siskind (2013)</ref> use hidden Markov mod- els to learn a mapping between object tracks from a video sequence and predicates extracted from a NL description. The goal of their approach is different from ours but the underlying problem of finding a map between objects can be compared. The matched objects constitute here a FL expres- sion instead of a video sequence track.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Machine Translation</head><p>Machine translation usually refers to transforming a NL sentence from a source language to another sentence of the same significance in another natu- ral language, called target language. This task is achieved by building an intermediary representa- tion of the sentence structure at a given level of abstraction, and then encoding the obtained object into the target language. While following a dif- ferent goal, one of the tasks of the XLike project <ref type="bibr">(Marko Tadi´cTadi´c et al., 2012</ref>) was to examine the possibility of translating statements from NL (En- glish) to FL (Cycl). Adapting such an approach to operational formal target language can be inter- esting to investigate, but we will not focus on that track for our early goal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Information Retrieval</head><p>The issue of information retrieval systems can be compared with the operational assistant's (OA), when browsing its knowledge. Question an- swering systems in particular <ref type="bibr" target="#b7">(Hirschman and Gaizauskas, 2001</ref>), turn out to be similar to OA since both types of systems have to respond to a NL utterance of the user by generating an accu- rate reaction (which is respectively a NL utterance containing the wanted information, or the execu- tion of a piece of FL code). However, as in ( <ref type="bibr" target="#b12">Toney et al., 2008)</ref>, questions answering systems usually rely on text mining to retrieve the right informa- tion. Such a method demands large sets of anno- tated textual data (either by hand or using an au- tomatic annotator). Yet, tutorials, courses or man- uals which could be used in order to look for re- sponses for operational assistant systems are het- erogeneous and include complex or implicit ref- erences to operational knowledge. This makes the annotation of such data difficult. Text min- ing methods are thus not yet applicable to oper- ational assistant systems but could be considered once some annotated data is collected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Problem Formulation</head><p>As we introduced in the first section, we represent the knowledge K as a set of examples of a binary relation R : N L → F L associating a NL utter- ance to a FL command. If we consider the simple case of a functional and injective relation, each utterance is associated to exactly one command. This is not realistic since it is possible to reformu- late nearly any NL sentence. The case of a non in- jective relation covers better the usual cases: each command can be associated with one or more ut- terances, this situation is illustrated by the second and third examples of <ref type="table">Table 1</ref>. Yet, the real-life case should be a non injective nor functional rela- tion. Not only multiple utterances can refer to a same command, but one single utterance can also stand for several distinct commands (see the fourth and fifth examples 2 in <ref type="table">Table 1</ref>). We must consider all these associations when matching a request- utterance U req for command retrieval in K.</p><p>At this point, several strategies can be used to determine what to return, with the help of the sim- ilarity measure σ : N L × N L → R between two NL utterances. Basically, we must determine if a response should be given, and if so how many commands to return. To do this, two potential strategies can be considered for selecting the as- sociated utterances in K.</p><p>The first choice focuses on the number of re- sponses that are given for each request-utterance. The n first commands according to the rankings of their associated utterances in K are returned. The rank r of a given utterance U is computed with:</p><formula xml:id="formula_1">r(U |Ureq) = ˛ ˛ ˘ U ′ ∈ K : σ(Ureq, U ′ ) &gt; σ(Ureq, U ) ¯˛ ˛<label>(1)</label></formula><p>The second strategy choice can be done by de- termining an absolute similarity threshold below which the candidate utterances from K and their associated sets of commands are considered too different to match. The resulting set of commands is given by:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Approach</head><p>We are given a simple parsing result of both the ut- terance and the command. The first step to address is the acquisition of examples and the way to up- date the knowledge. Then we examine the meth- ods for retrieving a command from the knowledge and a given request-utterance.</p><p>Correctly mapping utterances to commands re- quires at least to take their respective parameters into account (variable names, numeric values, and quoted strings). We build generic representations of utterances and commands by identifying the pa- rameters in the knowledge example pair (see <ref type="table">Ta- ble 1</ref>), and use them to reconstruct the command with the parameters of the request-utterance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Retrieving the Commands</head><p>We applied three textual similarity measures to our model in order to compare their strengths and weaknesses on our task: the Jaccard similarity co- efficient (Jaccard index), a tf-idf (Term frequency- inverse document frequency) aggregation, and the BLEU (Bilingual Evaluation Understudy) mea- sure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Jaccard index</head><p>The Jaccard index measures a similarity between two sets valued in the same superset. For the present case, we compare the set of words of the input NL instruction and the one of the compared candidate instruction, valued in the set of possible tokens. The adapted formula for two sentences S 1 and S 2 results in:</p><formula xml:id="formula_2">J(s1, s2) = |W (s1) ∩ W (s2)| |W (s1) ∪ W (s2)|<label>(3)</label></formula><p>where W (S) stands for the set of words of the sentence S. The Jaccard index is a baseline to compare co-occurences of unigrams, and should be efficient mainly with corpora containing few ambiguous examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">tf-idf</head><p>The tf-idf measure permits, given a word, to clas- sify documents on its importance in each one, re- garding its importance in the whole set. This mea- sure should be helpful to avoid noise bias when it comes from frequent terms in the corpus. Here, the documents are the NL utterances from K, and they are classified regarding the whole request- utterance, or input sentence s i . We then use the following aggregation of the tf-idf values for each word of s i .</p><formula xml:id="formula_3">tf idfS(si, sc) = 1 |W (si)| X w∈W (s i ) tf idf (w, sc, S) (4)</formula><p>with S = {s|(s, com) ∈ K}, where s i is the input sentence, s c ∈ S is the compared sentence, and where the tf-idf is given by:</p><formula xml:id="formula_4">tf idf (w, sc, S) = f (w, sc)idf (w, S)<label>(5)</label></formula><formula xml:id="formula_5">idf (w, S) = log " |S| |{s ∈ S|w ∈ s}| « (6)</formula><p>where at last f (w, s) is the frequency of the word w in the sentence s. As we did for the Jaccard in- dex, we performed the measures on both raw and lemmatized words. On the other hand, getting rid of the function words and closed class words is not here mandatory since the tf-idf measure already takes the global word frequency into account.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">The BLEU measure</head><p>The bilingual evaluation understudy algorithm ( <ref type="bibr" target="#b9">Papineni et al., 2002</ref>) focuses on n-grams co- occurrences. This algorithm can be used to dis- card examples where the words ordering is too far from the candidate. It computes a modified pre- cision based on the ratio of the co-occurring n- grams within candidate and reference sentences, on the total size of the candidate normalized by n.</p><p>PBLEU (si, S) = X grn∈s i maxs c∈S occ(grn, sc) grams(si, n)</p><p>where grams(s, n) = |s| − (n − 1) is the number of n-grams in the sentence s and occ(gr n , s) = grn ′ ∈s [gr n = gr n ′ ] is the number of occur- rences of the n-gram gr n in s. BLEU also uses a brevity penalty to prevent long sentences from being too disadvantaged by the n-gram based pre- cision formula. Yet, the scale of the length of the instructions in our corpus is sufficiently reduced not to require its use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Optimizing the similarity measure</head><p>We applied several combinations of filters to the utterances compared before evaluating their sim- ilarity. We can change the set of words taken into account, discarding or not the non open-class words <ref type="bibr">3</ref> . Identified non-lexical references such as variable names, quoted character strings and nu- meric values can also be discarded or transformed to standard substitutes. Finally, we can apply or not a lemmatization 4 on lexical tokens.By discard- ing non open-class words, keeping non-lexical ref- erences and applying the lemmatization, the sec- ond utterance of <ref type="table">Table 1</ref> would then become:</p><p>draw bar chart column xxVALxx xxVARxx</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Setup</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Parsing</head><p>The NL utterances first pass through an arith- metic expression finder to completely tag them be- fore the NL analyzer. They are then parsed us- ing WMATCH, a generic rule-based engine for language analysis developed by Olivier Galibert (2009). This system is modular and dispose of rules sets for both French and English. As an ex- ample, the simplified parsing result of the first ut- terance of <ref type="table">Table 1</ref> looks like: &lt;_operation&gt; &lt;_action&gt; charge|_˜V &lt;/_action&gt; &lt;_det&gt; les &lt;/_det&gt; &lt;_subs&gt; données|_˜N &lt;/_subs&gt; &lt;_prep&gt; depuis &lt;/_prep&gt; &lt;_unk&gt; "res.csv" &lt;/_unk&gt; &lt;/_operation&gt; Words tagged as unknown are considered as po- tential variable or function names. We also added a preliminary rule to identify character strings and count them among the possibly linked features of the utterance. The commands are normalized by inserting spaces between every non semantically linked character pair and we identify numeric val- ues, variable/function names and character strings as features.</p><p>Only generative forms of the commands are associated to utterances in the knowledge. This form consists in a normalized command with unre- solved references for every parameter linked with the learning utterance. These references are re- solved at the retrieving phase by matching with the tokens of the request-utterance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Corpus Constitution</head><p>Our initial corpus consists in 605 associations be- tween 553 unique NL utterances in French and 240 unique R commands.</p><p>The low number of documents describing a majority of R commands and their heterogeneity make automatic example gathering not yet achiev- able. These documentations are written for human readers having global references on the task. Thus, we added each example pair manually, making sure that the element render all the example infor- mation and that the format correspond to the cor- pus specifications. Those specifications are meant to be the least restrictive, that is: a NL utterance must be written as to ask for the execution of the associated R task. It therefore should be mostly in the imperative form and reflect, for experienced people, a usual way they would express the con- cerned operation for non specialists.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Evaluation Metrics</head><p>The measures that can contribute to a relevant evaluation of the system depend on its purpose. Precision and recall values of information retrieval systems are computed as follows:</p><formula xml:id="formula_7">P = # correct responses # responses given (8) R = # correct responses # responses in K<label>(9)</label></formula><p>Note that the recall value is not as important as for information retrieval: assuming that the situation showed by the fourth and fifth associations of <ref type="table">Ta- ble 1</ref> are not usual 5 , there should be few different valid commands for a given request-utterance, and most of them should be equivalent. Moreover, the number of responses given is fixed (so is the num- ber of responses in K), the recall thus gives the same information as the precision, with a linear coefficient variation. These formulae can be applied to the "command level", that is measuring the accuracy of the sys- tem in terms of its good command ratio. However, the user satisfaction can be better measured at the "utterance level" since it represents the finest gran- ularity for the user experience. We define the ut- terance precision uP as:</p><formula xml:id="formula_8">uP = # correct utterances # responses given<label>(10)</label></formula><p>where "# correct utterances" stands for the num- ber of request-utterances for which the system pro- vided at least one good command.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results and Discussion</head><p>The system was tested on 10% of the corpus (61 associations). The set of known associations K contains 85% of the corpus (514 associations), in- stead of 90% in order to allow several distinct drawings (40 were tested), and thus avoid too much noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Comparing similarity measures</head><p>As shown in <ref type="table" target="#tab_1">Table 2</ref> the tf-idf measure outper- forms the Jaccard and BLEU measures, whichever filter combination is applied. The form of the ut- terances in the corpus causes indeed the repetition of a small set of words across the associations. This can explain why the inverse document fre- quency is that better.  The lemmatization and the inclusion of non open-class words (not shown here) does not seem to have a clear influence on uP , whereas including the non-lexical tokens allows a real improvement. This behaviour must result from the low length av- erage (7.5 words) of the utterances in the corpus. Note that uP is obtained with Equation 10, which explains the increase of the precision along the number of responses. <ref type="figure" target="#fig_0">Figure 1</ref> shows the precision obtained with tfidf while increasing the number of commands given for each request-utterance. It comes out that it is useful to propose at least 3 commands to the user. It would not be interesting, though, to offer a choice of more than 5 items, because the gain on uP would be offset by the time penalty for retriev- ing the good command among the proposals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Allowing silence</head><p>We also tested the strategy of fixing an absolute threshold to decide between response and silence. Given a request-utterance and an associated order- ing of K according to σ, the system will remain silent if the similarity of the best example in K is below the defined threshold.</p><p>Surprisingly, it turned out that for every mea- sure, the 6 best similar responses at least were all wrong. This result seems to be caused by the ex- istence, in the test set of commands uncovered by K, of some very short utterances that contain only one or two lexical tokens. Having tested several methods giving differ- ent results, combining these methods can be very interesting depending on their complementarity. The oracle vote using the best response among the 6 best methods shows an encouraging progres- sion margin (cf. <ref type="figure" target="#fig_1">Figure 2)</ref>. The actual vote it- self outperforms the best method for giving up to 3 responses (reaching 50% for only 2 responses). However, the curve position is less clear for more responses, and tests must be performed on other drawings of K to measure the noise influence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Combinations</head><p>The complementarity of the methods can also be exploited by training a classification model to identify when a method is better than the others. We used the similarity values as features and the measure that gave a good response as the refer- ence class label (best similarity if multiple, and "none" class if no good response). This setup was tested with the support vector machines using lib- svm ( <ref type="bibr" target="#b5">Chang and Lin, 2011)</ref> and results are shown in <ref type="figure" target="#fig_1">Figure 2</ref>. As expected, machine learning per- forms poorly on our tiny corpus. The accuracy is under 20% and the system only learned when to use the best method, and when to give no re- sponse. Still, it manages to be competitive with the best method and should be tested again with more data and multiple drawings of K.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion and Future Work</head><p>The simple mapping methods based on similar- ity ranking showed up to 60% of utterance pre- cision 6 remaining below a reasonable level of user sollicitation, which validate our prior hypothesis. A lot of approaches can enhance that score, such as adding or developing more suitable similarity measures ( <ref type="bibr" target="#b0">Achananuparp et al., 2008)</ref>, combining learning and vote or learning to rerank utterances.</p><p>However, while usable as a baseline, these methods only allow poor generalization and really need more corpus to perform well. As we pointed out, the non-functionality of the mapping relation also introduces ambiguities that cannot be solved using the only knowledge of the system.</p><p>Thanks to this baseline method, we are now able to collect more data by developing an interactive agent that can be both an intelligent assistant and a crowdsourcing platform. We are currently de- veloping a web interface for this purpose. Finally, situated human computer interaction will allow the real-time resolving of ambiguities met in the re- trieval with the help of the user or with the use of contextual information from the dialogue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Aknowledgements</head><p>The authors are grateful to every internal and ex- ternal reviewer for their valuable advices. We also would like to thank Google for the financial sup- port for the authors participation to the conference.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Utterance precision (uP ) for a fixed number of responses by utterance. The tfidf inl curve includes the non-lexical tokens. Note that uP is obtained with Equation 10, which explains the increase of the precision along the number of responses.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Comparison of the combinations with the tf-idf inl method. Oracle and actual vote are done using tf-idf, Jaccard, and BLEU, with and without non-lexical tokens. The training set for learning is the result of a run on K.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Scores of precision by utterance (uP ), 
providing 3 responses for each request-utterance. 

</table></figure>

			<note place="foot" n="1"> We call operational instruction the natural language expression of a command in any programming language.</note>

			<note place="foot">Res = {C ∈ F L : (U, C) ∈ K, σ(Ureq, U ) &lt; t} (2) with t the selected threshold. Once selected the set of commands to be given as response, if there are more than one, the choice of the one to execute can be done interactively with the help of the user. 2 The command 4 returns a vector of the sums of each column, while the command 5 returns the sum of the columns as a single integer.</note>

			<note place="foot" n="3"> Open-class words include nouns, verbs, adjectives, adverbs and interjections.</note>

			<note place="foot" n="4"> Lemmatization is the process of transforming a word to its canonical form, or lemma, ignoring the inflections. It can be performed with a set of rules or with a dictionary. The developed system uses a dictionary.</note>

			<note place="foot" n="5"> Increasing the tasks covering of the corpus will make these collisions more frequent, but this hypothesis seems reasonable for a first approach.</note>

			<note place="foot" n="6"> The corpus will soon be made available.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The Evaluation of Sentence Similarity Measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Palakorn</forename><surname>Achananuparp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiajiong</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data Warehousing and Knowledge Discovery</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">PLOW: A Collaborative Task Learning Agent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Ferguson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucian</forename><surname>Galescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyuckchul</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><surname>Swift</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Tayson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd National Conference on Artificial Intelligence</title>
		<meeting>the 22nd National Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Bootstrapping semantic parsers from conversations. Proceedings of the conference on empirical methods in natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Reading Between the Lines: Learning to Map High-level Instructions to Commands</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R K</forename><surname>Branavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Reinforcement Learning for Mapping Instructions to Actions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R K</forename><surname>Branavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harr</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">LIBSVM: A Library for Support Vector Machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Chung</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Jen</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Intelligent Systems and Technology</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Approches et méthodologies pour la réponse automatiquè a des questions adaptéesadaptées`adaptéesà un cadre interactif en domaine ouvert. Doctoral dissertation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Galibert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<pubPlace>Université Paris Sud XI</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Natural language question answering: The view from here</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lynette</forename><surname>Hirschman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Gaizauskas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="2001" />
		</imprint>
		<respStmt>
			<orgName>Cambridge University Press</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Using Semantic Unification to Generate Regular Expressions from Natural Language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nate</forename><surname>Kushman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>the Conference of the North American Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Bleu: a Method for Automatic Evaluation of Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 40th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marko</forename><surname>Tadi´ctadi´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Božo</forename><surname>Bekavac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeljko</forename><surname>Agi´cagi´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matea</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Early machine translation based semantic annotation prototype XLike project www.xlike.org</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daša</forename><surname>Srebači´srebači´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danijela</forename><surname>Berovi´cberovi´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Merkler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">An Evaluation of Spoken and Textual Interaction on the RITEL Interactive Question Answering System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dave</forename><surname>Toney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sophie</forename><surname>Rosset</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurélien</forename><surname>Max</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Galibert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Billinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth International Conference on Language Resources and Evaluation</title>
		<meeting>the Sixth International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Lightly Supervised Learning of Procedural Dialog System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svitlana</forename><surname>Volkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pallavi</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Quirk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haonan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">Mark</forename><surname>Siskind</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Grounded Language Learning from Video Described with Sentences</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st</title>
		<meeting>the 51st</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<title level="m">Annual Meeting of the Association for Computational Linguistics</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
