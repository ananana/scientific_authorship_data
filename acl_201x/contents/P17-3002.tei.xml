<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:02+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Improving Distributed Representations of Tweets - Present and Future</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ganesh</forename><surname>Jawahar</surname></persName>
							<email>ganesh.j@research.iiit.ac.in</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Information Retrieval and Extraction Laboratory IIIT Hyderabad Telangana</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Improving Distributed Representations of Tweets - Present and Future</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of ACL 2017, Student Research Workshop</title>
						<meeting>ACL 2017, Student Research Workshop <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="4" to="10"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-3002</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Unsupervised representation learning for tweets is an important research field which helps in solving several business applications such as sentiment analysis, hashtag prediction, paraphrase detection and mi-croblog ranking. A good tweet representation learning model must handle the id-iosyncratic nature of tweets which poses several challenges such as short length, informal words, unusual grammar and mis-spellings. However, there is a lack of prior work which surveys the representation learning models with a focus on tweets. In this work, we organize the models based on its objective function which aids the understanding of the literature. We also provide interesting future directions , which we believe are fruitful in advancing this field by building high-quality tweet representation learning models.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Twitter is a widely used microblogging platform, where users post and interact with messages, "tweets". Understanding the semantic represen- tation of tweets can benefit a plethora of applica- tions such as sentiment analysis <ref type="bibr" target="#b23">(Ren et al., 2016;</ref><ref type="bibr" target="#b10">Giachanou and Crestani, 2016)</ref>, hashtag predic- tion ( <ref type="bibr" target="#b5">Dhingra et al., 2016)</ref>, paraphrase detec- tion ( <ref type="bibr" target="#b28">Vosoughi et al., 2016</ref>) and microblog rank- ing ( <ref type="bibr" target="#b13">Huang et al., 2013;</ref><ref type="bibr" target="#b24">Shen et al., 2014</ref>). How- ever, tweets are difficult to model as they pose several challenges such as short length, informal words, unusual grammar and misspellings. Re- cently, researchers are focusing on leveraging un- supervised representation learning methods based on neural networks to solve this problem. Once these representations are learned, we can use off- the-shelf predictors taking the representation as in- put to solve the downstream task <ref type="bibr" target="#b1">(Bengio, 2013a;</ref><ref type="bibr" target="#b2">Bengio et al., 2013b</ref>). These methods enjoy sev- eral advantages: (1) they are cheaper to train, as they work with unlabelled data, (2) they reduce the dependence on domain level experts, and (3) they are highly effective across multiple applications, in practice.</p><p>Despite this, there is a lack of prior work which surveys the tweet-specific unsupervised represen- tation learning models. In this work, we attempt to fill this gap by investigating the models in an or- ganized fashion. Specifically, we group the mod- els based on the objective function it optimizes. We believe this work can aid the understanding of the existing literature. We conclude the pa- per by presenting interesting future research direc- tions, which we believe are fruitful in advancing this field by building high-quality tweet represen- tation learning models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Unsupervised Tweet Representation Models</head><p>There are various models spanning across differ- ent model architectures and objective functions in the literature to compute tweet representation in an unsupervised fashion. These models work in a semi-supervised way -the representations gener- ated by the model is fed to an off-the-shelf pre- dictor like Support Vector Machines (SVM) to solve a particular downstream task. These mod- els span across a wide variety of neural network based architectures including average of word vec- tors, convolutional-based, recurrent-based and so on. We believe that the performance of these mod- els is highly dependent on the objective function it optimizes -predicting adjacent word (within- tweet relationships), adjacent tweet (inter-tweet relationships), the tweet itself (autoencoder), mod-  <ref type="figure">Figure 1</ref>: Unsupervised Tweet Representation Models Hierarchy based on Optimized Objective Function eling from structured resources like paraphrase databases and weak supervision. In this section, we provide the first of its kind survey of the recent tweet-specific unsupervised models in an orga- nized fashion to understand the literature. Specif- ically, we categorize each model based on the op- timized objective function as shown in <ref type="figure">Figure 1</ref>. Next, we study each category one by one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Modeling within-tweet relationships</head><p>Motivation: Every tweet is assumed to have a la- tent topic vector, which influences the distribution of the words in the tweet. For example, though the appearance of the phrase catch the ball is fre- quent in the corpus, if we know that the topic of a tweet is about "technology", we can expect words such as bug or exception after the word catch (ig- noring the) instead of the word ball since catch the bug/exception is more plausible under the topic "technology". On the other hand, if the topic of the tweet is about "sports", then we can expect ball after catch. These intuitions indicate that the prediction of neighboring words for a given word strongly relies on the tweet also. Models: (Le and Mikolov, 2014)'s work is the first to exploit this idea to compute distributed docu- ment representations that are good at predicting words in the document. They propose two mod- els: PV-DM and PV-DBOW, that are extensions of Continuous Bag Of Words (CBOW) and Skip- gram model variants of the popular Word2Vec model ( <ref type="bibr" target="#b21">Mikolov et al., 2013</ref>) respectively -PV- DM inserts an additional document token (which can be thought of as another word) which is shared across all contexts generated from the same doc- ument; PV-DBOW attempts to predict the sam- pled words from the document given the document representation. Although originally employed for paragraphs and documents, these models work better than the traditional models: BOW <ref type="bibr" target="#b11">(Harris, 1954)</ref> and LDA ( <ref type="bibr" target="#b3">Blei et al., 2003</ref>) for tweet classi- fication and microblog retrieval tasks ( <ref type="bibr" target="#b29">Wang et al., 2016</ref>). The authors in ( <ref type="bibr" target="#b29">Wang et al., 2016</ref>) make the PV-DM and PV-DBOW models concept-aware (a rich semantic signal from a tweet) by augmenting two features: attention over contextual words and conceptual tweet embedding, which jointly exploit concept-level senses of tweets to compute better representations. Both the discussed works have the following characteristics: (1) they use a shal- low architecture, which enables fast training, (2) computing representations for test tweets requires computing gradients, which is time-consuming for real-time Twitter applications, and (3) most impor- tantly, they fail to exploit textual information from related tweets that can bear salient semantic sig- nals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Modeling inter-tweet relationships</head><p>Motivation: To capture rich tweet semantics, researchers are attempting to exploit a type of sentence-level Distributional Hypothesis <ref type="bibr" target="#b11">(Harris, 1954;</ref><ref type="bibr" target="#b22">Polajnar et al., 2015)</ref>. The idea is to infer the tweet representation from the content of adjacent tweets in a related stream like users' Twitter time- line, topical, retweet and conversational stream. This approach significantly alleviates the context insufficiency problem caused due to the ambigu- ous and short nature of tweets ( <ref type="bibr" target="#b23">Ren et al., 2016;</ref><ref type="bibr" target="#b8">Ganesh et al., 2017)</ref>. Models: Skip-thought vectors ( ) (STV) is a widely popular sentence encoder, which is trained to predict adjacent sentences in the book corpus ( . Although the testing is cheap as it involves a cheap forward propagation of the test sentence, STV is very slow to train thanks to its complicated model architec- ture. To combat this computational inefficiency, FastSent ( <ref type="bibr" target="#b12">Hill et al., 2016)</ref> propose a simple ad- ditive (log-linear) sentence model, which predicts adjacent sentences (represented as BOW) taking the BOW representation of some sentence in con- text. This model can exploit the same signal, but at a much lower computational expense. Paral- lel to this work, Siamase CBOW ( <ref type="bibr" target="#b15">Kenter et al., 2016</ref>) develop a model which directly compares the BOW representation of two sentence to bring the embeddings of a sentence closer to its adja- cent sentence, away from a randomly occurring sentence in the corpus. For FastSent and Siamese CBOW, the test sentence representation is a sim- ple average of word vectors obtained after train- ing. Both of these models are general purpose sentence representation models trained on book corpus, yet give a competitive performance over previous models on the tweet semantic similarity computation task. ( <ref type="bibr" target="#b8">Ganesh et al., 2017)</ref>'s model attempt to exploit these signals directly from Twit- ter. With the help of attention technique and learned user representation, this log-linear model is able to capture salient semantic information from chronologically adjacent tweets of a target tweet in users' Twitter timeline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Modeling from structured resources</head><p>Motivation: In recent times, building represen- tation models based on supervision from richly structured resources such as Paraphrase Database (PPDB) ( <ref type="bibr" target="#b9">Ganitkevitch et al., 2013</ref> <ref type="bibr">et al., 2016b</ref>) conduct a comprehensive analysis of models spanning the range of complexity from word averaging to LSTMs for its ability to do transfer and supervised learning after optimizing a margin based loss on PPDB. For transfer learning, they find models based on word averaging perform well on both the in-domain and out-of-domain tex- tual similarity tasks, beating LSTM model by a large margin. On the other hand, the word averag- ing models perform well for both sentence similar- ity and textual entailment tasks, outperforming the LSTM. However, for sentiment classification task, they find LSTM (trained on PPDB) to beat the av- eraging models to establish a new state of the art. The above results suggest that structured resources play a vital role in computing general-purpose em- beddings useful in downstream applications.</p><note type="other">) (containing noisy phrase pairs) has yielded high quality sen- tence representations. These methods work by maximizing the similarity of the sentences in the learned semantic space. Models: CHARAGRAM (Wieting et al., 2016a) embeds textual sequences by learning a character- based compositional model that involves addition of the vectors of its character n-grams followed by an elementwise nonlinearity. This simpler archi- tecture trained on PPDB is able to beat models with complex architectures like CNN, LSTM on SemEval 2015 Twitter textual similarity task by a large margin. This result emphasizes the impor- tance of character-level models that address differ- ences due to spelling variation and word choice. The authors in their subsequent work (Wieting</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Modeling as an autoencoder</head><p>Motivation: The autoencoder based approach learns latent (or compressed) representation by re- constructing its own input. Since textual data like tweets contain discrete input signals, sequence- to-sequence models (Sutskever et al., <ref type="bibr">2014</ref>) like STV can be used to build the solution. The en- coder model which encodes the input tweet can typically be a CNN <ref type="bibr" target="#b17">(Kim, 2014</ref>), recurrent models like RNN, GRU, LSTM (Karpathy et al., 2015) or memory networks ( <ref type="bibr" target="#b25">Sukhbaatar et al., 2015</ref>). The decoder model which generates the output tweet can typically be a recurrent model that predicts a output token at every time step. Models: Sequential Denoising Autoencoders (SDAE) ( <ref type="bibr" target="#b12">Hill et al., 2016</ref>) is a LSTM-based sequence-to-sequence model, which is trained to recover the original data from the corrupted ver- sion. SDAE produces robust representations by learning to represent the data in terms of fea- tures that explain its important factors of varia- tion. <ref type="bibr">Tweet2Vec (Vosoughi et al., 2016</ref>) is a recent model which uses a character-level CNN-LSTM encoder-decoder architecture trained to construct the input tweet directly. This model outper- forms competitive models that work on word-level like PV-DM, PV-DBOW on semantic similarity computation and sentiment classification tasks, thereby showing that the character-level nature of Tweet2Vec is best-suited to deal with the noise and idiosyncrasies of tweets. Tweet2Vec controls the generalization error by using a data augmentation technique, wherein tweets are replicated and some of the words in the replicated tweets are replaced with their synonyms. Both SDAE and Tweet2Vec has the advantage that they don't need a coherent inter-sentence narrative (like STV), which is hard to obtain in Twitter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Modeling using weak supervision</head><p>Motivation: In a weakly supervised setup, we create labels for a tweet automatically and pre- dict them to learn potentially sophisticated mod- els than those obtained by unsupervised learning alone. Examples of labels include sentiment of the overall tweet, words like hashtag present in the tweet and so on. This technique can create a huge labeled dataset especially for building data- hungry, sophisticated deep learning models. Models: <ref type="bibr" target="#b27">(Tang et al., 2016</ref>) learns sentiment- specific word embedding (SSWE), which encodes the polarity information in the word representa- tions so that words with contrasting polarities and similar syntactic context (like good and bad) are pushed away from each other in the semantic space that it learns. SSWE utilizes the massive distant-supervised tweets collected by positive and negative emoticons to build a powerful tweet rep- resentation, which are shown to be useful in tasks such as sentiment classification and word simi- larity computation in sentiment lexicon. <ref type="bibr" target="#b5">(Dhingra et al., 2016)</ref> observes that hashtags in tweets can be considered as topics and hence tweets with similar hashtags must come closer to each other. Their model predicts the hashtags by using a Bi- GRU layer to embed the tweets from its charac- ters. Due to subword modeling, such character- level models can approximate the representations for rare words and new words (words not seen dur- ing training) in the test tweets really well. This model outperforms the word-level baselines for hashtag prediction task, thereby concluding that exploring character-level models for tweets is a worthy research direction to pursue. Both these works fail to study the model's generality <ref type="bibr" target="#b31">(Weston et al., 2014</ref>), i.e., the ability of the model to trans- fer the learned representations to diverse tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Future Directions</head><p>In this section we present the future research di- rections which we believe can be worth pursuing to generate high quality tweet embeddings.</p><p>• <ref type="figure">(Ren et al., 2016)</ref> propose a supervised neural network utilizing contextualized fea- tures from conversation, author and topic based context about a target tweet to per- form well in classification of tweet. Apart from ( <ref type="bibr" target="#b8">Ganesh et al., 2017</ref>)'s work which uti- lizes author context, there is no other work which builds unsupervised tweet representa- tion model on Twitter-specific contexts such as conversation and topical streams. We be- lieve such a solution directly exploits seman- tic signals (or nuances) from Twitter, unlike STV or Siamese CBOW which are trained on books corpus.</p><p>• (dos <ref type="bibr" target="#b6">Santos and Gatti, 2014</ref>) propose a super- vised, hybrid model exploiting both the char- acter and word level information for Twit- ter sentiment analysis task. Since the set- tings when the character level model beats the word level model is not well understood yet, we believe it would be interesting to explore such a hybrid compositional model to build unsupervised tweet representations.</p><p>• Twitter provides a platform for the users to interact with other users. To the best of our knowledge, there is no related work that com- putes unsupervised tweet representation by exploiting the user profile attributes like pro- file picture, user biography and set of fol- lowers, and social interactions like retweet context (set of surrounding tweets in a users retweet stream) and favorite context (set of surrounding tweets in a users favorite tweet stream).</p><p>• DSSM ( <ref type="bibr" target="#b13">Huang et al., 2013;</ref><ref type="bibr" target="#b24">Shen et al., 2014)</ref> propose a family of deep models that are trained to maximize the relevance of clicked documents given a query. Such a ranking loss function helps the model cater to a wide vari- ety of applications 1 such as web search rank- ing, ad selection/relevance, question answer- ing, knowledge inference and machine trans- lation. We observe such a loss function has not been explored for building unsupervised tweet representations. We believe employing a ranking loss directly on tweets using a large scale microblog dataset 2 can result in repre- sentations which can be useful to Twitter ap- plications beyond those studied in the tweet representation learning literature.</p><p>• Linguists assume that language is best un- derstood as a hierarchical tree of phrases, rather than a flat sequence of words or charac- ters. It's difficult to get the syntactic trees for tweets as most of them are not grammatically correct. The average of word vectors model has the most simplest compositional archi- tecture with no additional parameters, yet displays a strong performance outperforming complex architectures such as CNN, LSTM and so on for several downstream applica- tions ( <ref type="bibr">Wieting et al., 2016a,b)</ref>. We believe a theoretical understanding of why word av- eraging models perform well can help in em- bracing these models by linguists.</p><p>• Models in (Wieting et al., 2016a,b) learn from noisy phrase pairs of PPDB. Note that the source of the underlying texts is com- pletely different from Twitter. It can be inter- esting to see the effectiveness of such mod- els when directly trained on structural re- sources from Twitter like Twitter Paraphrase Corpus ( <ref type="bibr" target="#b34">Xu et al., 2014</ref>). The main challenge with this approach is the small size of the an- notated Twitter resources, which can encour- age models like ( <ref type="bibr" target="#b0">Arora et al., 2017</ref>) that work well even when the training data is scarce or nonexistent.</p><p>• Tweets mostly have an accompanying im- age which sometimes has visual correspon- dence with its textual content ( <ref type="bibr">Wang et al., 2014) ('visual' tweet)</ref>. To the best of our knowledge, there is no work which explores the following question: can we build multimodal representations for tweets accompanying correlated visual con- tent and compare with traditional bench- marks?. We can leverage insights from mul- timodal skip-gram model ( <ref type="bibr" target="#b19">Lazaridou et al., 2015</ref>) which builds multimodally-enhanced word vectors that perform well in the tradi- tional semantic benchmarks. However, it's hard to detect visual tweets and learning from a non-visual tweet can degrade its tweet rep- resentation. It would be interesting to see if a dispersion metric ( <ref type="bibr" target="#b16">Kiela et al., 2014</ref>) for tweets can be explored to overcome this prob- lem of building a nondegradable, improved tweet representation.</p><p>• Interpreting the tweet representations to un- earth the encoded features responsible for its performance on a downstream task is an important, but a less studied research area.</p><p>( <ref type="bibr" target="#b7">Ganesh et al., 2016</ref>)'s work is the first to open the blackbox of vector embeddings for tweets. They propose elementary property prediction tasks which predicts the accuracy to which a given tweet representation en- codes the elementary property (like slang words, hashtags, mentions, etc). The main drawback of the work is that they fail to cor- relate their study with downstream applica- tions. We believe performing such a correla- tion study can clearly highlight the set of el- ementary features behind the performance of a particular representation model over other for a given downstream task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this work we study the problem of learning unsupervised tweet representations. We believe our survey of the existing works based on the ob- jective function can give vital perspectives to re- searchers and aid their understanding of the field. We also believe the future research directions stud- ied in this work can help in breaking the barriers in building high quality, general purpose tweet repre- sentation models.</p></div>
			<note place="foot" n="1"> https://www.microsoft.com/en-us/ research/project/dssm/ 2 http://trec.nist.gov/</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">A simple but tough-to-beat baseline for sentence embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingyu</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengyu</forename><surname>Ma</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deep Learning of Representations: Looking Forward</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 1 st Intl. Conf. on Statistical Language and Speech Processing</title>
		<meeting>of the 1 st Intl. Conf. on Statistical Language and Speech essing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Representation Learning: A Review and New Perspectives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1798" to="1828" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Latent Dirichlet Allocation. Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Understanding and classifying image tweets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyuan</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min-Yen</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Cui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Multimedia Conference, MM &apos;13</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="781" to="784" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Tweet2Vec: Character-Based Distributed Representations for Social Media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhuwan</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dylan</forename><surname>Fitzpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Muehl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 54 th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>of the 54 th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Deep convolutional neural networks for sentiment analysis of short texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cícero</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maira</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gatti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">25 th Intl. Conf. on Computational Linguistics</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="69" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Interpreting the syntactic and social elements of the tweet representations via elementary property prediction tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manish</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasudeva</forename><surname>Varma</surname></persName>
		</author>
		<idno>CoRR abs/1611.04887</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Improving tweet representations using temporal and user context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manish</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasudeva</forename><surname>Varma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Information Retrieval-39 th European Conference on IR Research, ECIR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="575" to="581" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">PPDB: the paraphrase database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juri</forename><surname>Ganitkevitch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of conf. of the North American Chapter of the Association of Computational Linguistics</title>
		<meeting>of conf. of the North American Chapter of the Association of Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="758" to="764" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Like it or not: A Survey of Twitter Sentiment Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anastasia</forename><surname>Giachanou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Crestani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Methods. ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">28</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zellig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Harris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Distributional Structure. Word</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="146" to="162" />
			<date type="published" when="1954" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning Distributed Representations of Sentences from Unlabelled Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conf. of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>of the Conf. of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1367" to="1377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning Deep Structured Semantic Models for Web Search using Clickthrough Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Po-Sen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Acero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><forename type="middle">P</forename><surname>Heck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 22 nd ACM Intl. Conf. on Information and Knowledge Management</title>
		<meeting>of the 22 nd ACM Intl. Conf. on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2333" to="2338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Visualizing and understanding recurrent networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei-Fei</forename><surname>Li</surname></persName>
		</author>
		<idno>CoRR abs/1506.02078</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Siamese CBOW: Optimizing Word Embeddings for Sentence Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kenter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Borisov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 54 th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>of the 54 th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Improving multi-modal representations using image dispersion: Why less is sometimes more</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 52 nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>of the 52 nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="835" to="841" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Convolutional Neural Networks for Sentence Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2014 Conf. on Empirical Methods in Natural Language Processing</title>
		<meeting>of the 2014 Conf. on Empirical Methods in Natural Language essing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1746" to="1751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Antonio Torralba, and Sanja Fidler</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2015 Intl. Conf. on Advances in Neural Information Processing Systems</title>
		<meeting>of the 2015 Intl. Conf. on Advances in Neural Information essing Systems</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3294" to="3302" />
		</imprint>
	</monogr>
	<note>Skip-Thought Vectors</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Combining language and vision with a multimodal skip-gram model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angeliki</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nghia The</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of conf. of the North American Chapter of the Association of Computational Linguistics</title>
		<meeting>of conf. of the North American Chapter of the Association of Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="153" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Distributed Representations of Sentences and Documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 31 st Intl. Conf. on Machine Learning</title>
		<meeting>of the 31 st Intl. Conf. on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1188" to="1196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Distributed Representations of Words and Phrases and Their Compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 26 th Intl. Conf. on Neural Information Processing Systems</title>
		<meeting>of the 26 th Intl. Conf. on Neural Information essing Systems</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">An exploration of discourse-based sentence spaces for compositional distributional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamara</forename><surname>Polajnar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Rimell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics (LSDSem)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Context-sensitive twitter sentiment classification using neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yafeng</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meishan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghong</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 13 th AAAI Conference on Artificial Intelligence</title>
		<meeting>of the 13 th AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="215" to="221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A Latent Semantic Model with Convolutional-Pooling Structure for Information Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yelong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grégoire</forename><surname>Mesnil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 23 rd ACM Intl. Conf. on Conference on Information and Knowledge Management</title>
		<meeting>of the 23 rd ACM Intl. Conf. on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="101" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">End-to-end memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sainbayar</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2440" to="2448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Sentiment Embeddings with Applications to Sentiment Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="496" to="509" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Tweet2Vec: Learning Tweet Embeddings Using Character-level CNN-LSTM EncoderDecoder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soroush</forename><surname>Vosoughi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prashanth</forename><surname>Vijayaraghavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deb</forename><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 39 th Intl. ACM SIGIR Conf. on Research and Development in Information Retrieval</title>
		<meeting>of the 39 th Intl. ACM SIGIR Conf. on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1041" to="1044" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">CSE: conceptual sentence embeddings based on attention model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yashen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heyan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiahui</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiong</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 54 th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>of the 54 th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Bilateral correspondence model for words-and-pictures association in multimedia-rich microblogs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lexing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenwu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Rui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiqiang</forename><surname>Yang</surname></persName>
		</author>
		<idno>34:1-34:21</idno>
	</analytic>
	<monogr>
		<title level="j">TOMCCAP</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">#tagspace: Semantic embeddings from hashtags</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Adams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2014 Conf. on Empirical Methods in Natural Language Processing</title>
		<meeting>of the 2014 Conf. on Empirical Methods in Natural Language essing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1822" to="1827" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Charagram: Embedding words and sentences via character n-grams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Wieting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Livescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>of the 2016 Conference on Empirical Methods in Natural Language essing</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1504" to="1515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Towards universal paraphrastic sentence embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Wieting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Livescu</surname></persName>
		</author>
		<idno>CoRR abs/1511.08198</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Extracting lexically divergent paraphrases from twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">B</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TACL</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="435" to="448" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Aligning books and movies: Towards story-like visual explanations by watching movies and reading books</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Intl. Conf. on Computer Vision, ICCV</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="19" to="27" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
