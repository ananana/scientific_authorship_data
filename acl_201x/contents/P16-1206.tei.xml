<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:40+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A New Psychometric-inspired Evaluation Metric for Chinese Word Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Qian</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="laboratory">Shanghai Key Laboratory of Intelligent Information Processing</orgName>
								<orgName type="institution" key="instit1">Fudan University</orgName>
								<orgName type="institution" key="instit2">Fudan University</orgName>
								<address>
									<addrLine>825 Zhangheng Road</addrLine>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="laboratory">Shanghai Key Laboratory of Intelligent Information Processing</orgName>
								<orgName type="institution" key="instit1">Fudan University</orgName>
								<orgName type="institution" key="instit2">Fudan University</orgName>
								<address>
									<addrLine>825 Zhangheng Road</addrLine>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="laboratory">Shanghai Key Laboratory of Intelligent Information Processing</orgName>
								<orgName type="institution" key="instit1">Fudan University</orgName>
								<orgName type="institution" key="instit2">Fudan University</orgName>
								<address>
									<addrLine>825 Zhangheng Road</addrLine>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A New Psychometric-inspired Evaluation Metric for Chinese Word Segmentation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="2185" to="2194"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Word segmentation is a fundamental task for Chinese language processing. However , with the successive improvements, the standard metric is becoming hard to distinguish state-of-the-art word segmentation systems. In this paper, we propose a new psychometric-inspired evaluation metric for Chinese word segmentation, which addresses to balance the very skewed word distribution at different levels of difficulty 1. The performance on a real evaluation shows that the proposed metric gives more reasonable and distinguishable scores and correlates well with human judgement. In addition, the proposed metric can be easily extended to evaluate other sequence labelling based NLP tasks.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Word segmentation is a fundamental task for Chinese language processing. In recent years, Chinese word segmentation (CWS) has undergone great development, which is, to some degree, driven by evaluation conferences of CWS, such as SIGHAN Bakeoffs <ref type="bibr" target="#b2">(Emerson, 2005;</ref><ref type="bibr" target="#b12">Levow, 2006;</ref><ref type="bibr" target="#b8">Jin and Chen, 2008;</ref><ref type="bibr" target="#b20">Zhao and Liu, 2010)</ref>. The current state-of-the-art methods regard word segmentation as a sequence labeling problem <ref type="bibr" target="#b18">(Xue, 2003;</ref><ref type="bibr" target="#b15">Peng et al., 2004</ref>). The goal of sequence labeling is to assign labels to all elements in a sequence, which can be handled with supervised learning algorithms, such as maximum entropy (ME) ( <ref type="bibr" target="#b0">Berger et al., 1996)</ref>, conditional random fields (CRF) ( <ref type="bibr" target="#b11">Lafferty et al., 2001</ref>) and Perceptron <ref type="bibr" target="#b1">(Collins, 2002</ref>).</p><p>Benefiting from the public datasets and feature engineering, Chinese word segmentation achieves quite high precision after years of intensive research. To evaluate a word segmenter, the standard metric consists of precision p, recall r, and an evenly-weighted F-score f 1 .</p><p>However, with the successive improvement of performance, state-of-the-art segmenters are hard to be distinguished under the standard metric. Therefore, researchers also report results with some other measures, such as out-of-vocabulary (OOV) recall, to show their strengths besides p, r and f 1 .</p><p>Furthermore, although state-of-the-art methods have achieved high performances on p, r and f 1 , there exists inconsistence between the evaluation ranking and the intuitive feelings towards the segmentation results of these methods. The inconsistence is caused by two reasons:</p><p>(1) The high performance is due to the fact that the distribution of difficulties of words is unbalanced. The proportion of trivial cases is very high, such as '的 ('s)'，'我们 (we)', which results in that the non-trivial cases are relatively despised. Therefore, a good measure should have a capability to balance the skewed distribution by weighting the test cases.</p><p>(2) Human judgement depends on difficulties of segmentations. A segmenter can earn extra credits when correctly segmenting a difficult word than an easy word. Conversely, a segmenter can take extra penalties when wrongly segmenting an easy word than a difficult word.</p><p>Taking a sentence and two predicted segmenta- tions as an example: S : 白藜芦醇 是 一 种 酚类 物质 (Trans: Resveratrol is a kind of phenols material.) P1: 白 藜芦 醇 是 一种 酚类 物质 P2: 白藜 芦醇 是 一 种 酚类物 质 We can see that the two segmentations have the same scores in p, r and f 1 . But intuitively, P1 should be better than P2, since P2 is worse even on the trivial cases, such as '酚类 (phenols)' and '物质 (material)'. Therefore, we think that an appropriate evalua- tion metric should not only provide an all-around quantitative analysis of system performances, but also explicitly reveal the strengths and potential weaknesses of a model.</p><p>Inspired by psychometrics, we propose a new evaluation metric for Chinese word segmentation in this paper. Given a labeled dataset, not all words have the same contribution to judge the performance of a segmenter.</p><p>Based on psychometric research ( <ref type="bibr" target="#b13">Lord et al., 1968)</ref>, we assign a difficulty value to each word. The difficulty of a word is automatically rated by a committee of segmenters, which are diversified by training on different datasets and features. We design a balanced precision, recall to pay different attentions to words according to their difficulties.</p><p>We also give detailed analysis on a real eval- uation of Chinese word segmentation with our proposed metric. The analysis result shows that the new metric gives a more balanced evaluation result towards the human intuition of the segmentation quality. We will release the weighted datasets focused this paper to the academic community.</p><p>Although our proposed metric is applied to Chinese word segmentation for a case study, it can be easily extended to other sequence labelling based NLP tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Standard Evaluation Metric</head><p>The standard evaluation usually uses three measures: precision, recall and balanced F-score.</p><p>Precision p is defined as the number of correctly segmented words divided by the total number of words in the automatically segmented corpus.</p><p>Recall r is defined as the number of correctly segmented words divided by the total number of words in the gold standard, which is the manually annotated corpus.</p><p>F-score f 1 the harmonic mean of precision and recall.</p><p>Given a sentence, the gold-standard segmen- tation of a sentence is w 1 , · · · , W N , N is the number of words. The predicted segmentation is w ′ 1 , · · · , w ′ N ′ , N ′ is the number of words. Among that, the number of words correctly identified by the predicted segmentation is c, and the number of incorrectly predicted words is e. p, r and f 1 are defined as follows:</p><formula xml:id="formula_0">p = c N ′ ,<label>(1)</label></formula><formula xml:id="formula_1">r = c N ,<label>(2)</label></formula><formula xml:id="formula_2">f 1 = 2 × p × r p + r .<label>(3)</label></formula><p>As a complement to these metrics, researchers also use the recall of out-of-vocabulary (OOV) words to measure the segmenter's performance in detecting unknown words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">A New Psychometric-inspired Evaluation Metric</head><p>We involve the basic idea from psychometrics and improve the evaluation metric by assigning weights to test cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Background Theory</head><p>This work is inspired by the test theory in psychometrics ( <ref type="bibr" target="#b13">Lord et al., 1968)</ref>. Psychologists, as well as educators, have studied the way of analyzing items in a psychological test, such as IQ test. The general idea is that test cases should be given different weights, which reflects the effectiveness of a certain item to a certain measuring object.</p><p>Similarly, we consider an evaluation task as a kind of special psychological test. The psycho- logical traits, or the ability of the model, is not an explicit characteristics. We propose that the test cases for NLP task should also be assigned a real value to account for the credits that the tagger earned from answering the test case.</p><p>In analogy to the way of computing difficulty in psychometrics, the difficulty of a target word w i is defined as the error rate of a committee in the case of word segmentation.</p><p>Given a committee of K base segmenter- s, we can get K segmentations for sentence w 1 , · · · , W N . We use a mark m k i ∈ {0, 1} to indicate whether word w i is correctly segmented by the k-th segmenter.</p><p>The number of words c k correctly identified by the k-th segmenter is</p><formula xml:id="formula_3">c k = N ∑ i=1 m k i .<label>(4)</label></formula><p>Thus, we can calculate the degree of difficulty of each word w i .</p><formula xml:id="formula_4">d i = 1 K K ∑ k=1 (1 − m k i ).<label>(5)</label></formula><p>This methodology of measuring test item diffi- culty is also widely applied in assessing standard- ized exams such as TOEFL (Service, 2000).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Psychometric-Inspired Evaluation Metric</head><p>Since the distribution of the difficulties of words is very skew, we design a new metric to balance the weights of different words according to their difficulties. In addition, we also should keep strictly a fair rule for rewards and punishments.</p><p>Intuitively, if the difficulty of a word is high, a correct segmentation should be given an extra rewards; otherwise, if the difficulty of a word is low, it is reasonable to give an extra punishment to a wrong segmentation.</p><p>Our new metric of precision, recall and balanced F-score is designed as follows.</p><p>Balanced Recall Given a new predicted seg- mentation, the mark m i ∈ {0, 1} indicates whether word w i is correctly segmented. d i is the degree of difficulty of word w i .</p><p>According to the difficulties of each word, we can calculated the reward recall r reward which biased for the difficult cases.</p><formula xml:id="formula_5">r reward = ∑ N i=1 d i × m i ∑ N i=1 d i ,<label>(6)</label></formula><p>where r ′ reward ∈ [0, 1] is biased recall, which places more attention on the difficult cases and less attention on the easy cases.</p><p>Conversely, we can calculated another punish- ment recall r punishment which biased for the easy cases.</p><formula xml:id="formula_6">r punishment = ∑ N i=1 (1 − d i ) × m i ∑ N i=1 (1 − d i ) ,<label>(7)</label></formula><p>where r punishment ∈ [0, 1] is biased recall, which places more attention on the easy cases and less attention on the difficult cases. r punishment can be interpreted as a punishment as bellows.</p><formula xml:id="formula_7">r punishment = ∑ N i=1 (1 − d i ) × m i ∑ N i=1 (1 − d i ) ,<label>(8)</label></formula><formula xml:id="formula_8">= 1 − ∑ N i=1 (1 − d i ) × (1 − m i ) ∑ N i=1 (1 − d i ) .<label>(9)</label></formula><p>From Eq (9), we can see that an extra pun- ishment is given to wrong segmentation for low difficult word. In detailed, for a word w i that is easy to segment, its weights</p><formula xml:id="formula_9">(1 − d i ) is relative higher. When its segmentation is wrong, m i = 0. Therefore, (1 − d i ) × (1 − m i ) = (1 − d i )</formula><p>will be larger, which results to a smaller final score.</p><p>To balance the reward and punishment, a balanced recall r b is used, which is the harmonic mean of r reward and r punishment .</p><formula xml:id="formula_10">r b = 2 × r punishment × r reward r punishment + r reward (10) Balanced Precision Given a new predicted seg- mentation, the mark m ′ i ∈ {0, 1} to indicate whether segment s ′ i is correctly segmented. d ′ i</formula><p>is the degree of difficulty of segment s ′ i , which is an average difficulty of the corresponding gold words.</p><p>Similar to balanced recall, we use the same way to calculate balance precision p b . Here N ′ is the number of words in the predicted segmentation. d ′ i is the weight for the predicted segmentation unit w ′ i . It equals to the word difficulty of the corresponding word w that cover the right boundary of w ′ i in the gold segmentation.</p><formula xml:id="formula_11">p reward = ∑ N i=1 (1 − d i ) × m i ∑ N ′ i=1 (1 − d ′ i ) ,<label>(11)</label></formula><formula xml:id="formula_12">p punishment = ∑ N i=1 (1 − d i ) × m i ∑ N ′ i=1 (1 − d ′ i ) ,<label>(12)</label></formula><formula xml:id="formula_13">p b = 2 × p reward × p punishment p reward + p punishment . (13)<label>(14)</label></formula><p>Balanced F-score The final balanced F-score is</p><formula xml:id="formula_14">f b = 2 × p balanced × r balanced p balanced + r balanced .<label>(15)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Committee of Segmenters</head><p>It is infeasible to manually judge the difficulty of each word in a dataset. Therefore, an empirical method is needed to rate each word. Since the difficulty is also not derivable from the observation of the surface forms of the text, we use a committee of automatic segmenters instead. To keep fairness  and justice of the committee, we need a large number of diversified committee members. Thus, the grading result of committee is fair and accurate, avoiding the laborious human annotation and the deviation caused by the subjective factor of the artificial judgement.</p><formula xml:id="formula_15">C i T 0 , (i = −1, 0, 1) C i:i+1 T 0 , (i = −1, 0) T −1,0 F2 C i T 0 , (i = −2, −1, 0, 1, 2) C i:i+1 T 0 , (i = −2, −1, 0, 1) T −1,0 F3 C i T 0 , (i = −2, −1, 0, 1, 2) C i:i+1 T 0 , (i = −2, −1, 0, 1) C i:i+2 T 0 , (i = −2, −1, 0) T −1,0</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Building the Committee</head><p>Base Segmenters The committee is composed of a series of base segmenters, which are based on discriminative character-based sequence labeling method. Each character is labeled as one of {B, M, E, S} to indicate the segmentation. 'B' indicates the beginning character of a word. 'M' indicates the middle character of a word. 'E' indicates the end character of a word. 'S' indicates that the word consists of only a single character.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Diversity of Committee</head><p>To objectively assess the difficulty of a word, we need to maintain a large enough committee with diversity.</p><p>To encourage diversity among committee mem- bers, we train them with different datasets and features. Specifically, each base segmenter adopts one of three types of feature templates (shown in <ref type="table" target="#tab_0">Table 1</ref>), and are trained on randomly sampling training sets. To keep a large diversity, we set sampling ratio to be 10%, 20% and 30%. In short, each base segmenter is constructed with a random combination of the candidate feature template and the sampling ratio for training dataset.</p><p>Size of Committee To obtain a valid and reliable assessment for a word, we need to choose the appropriate size of committee. For a given test case, the judgement of its difficulty should be relatively stable. We analyze how the judgement of its difficulty changes as the size of committee increases. <ref type="figure" target="#fig_2">Figure 2</ref> show PKU data <ref type="bibr">from SIGHAN 2005</ref><ref type="bibr" target="#b2">(Emerson, 2005</ref>) the difficulty is stable when the sample size is large enough.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Interpreting Difficulty with Linguistic Features</head><p>Since we get the difficulty for each word empirically, we naturally want to know whether the difficulty is explainable, as what TOEFL researchers have done <ref type="bibr" target="#b5">(Freedle and Kostin, 1993;</ref><ref type="bibr" target="#b10">Kostin, 2004</ref>). We would like to know whether the variation of word difficulty can be partially expalined by a series of traceable linguistic features.</p><p>Based on the knowledge about the charac- teristics of Chinese grammar and the practical experiences of corpus annotation, we consider the following surface linguistic features. In order to explicitly display the relationship between the linguistic predictors and the distribution of the word difficulty at a micro level, we divide the difficulty scale into ten discrete intervals and calculate the distributions of these linguistic features on different ranges of difficulty.</p><p>Here, we interpret the difficulties of the words from the perspective of three important linguistic features:</p><p>Idiom In Chinese, the 4-character idioms have special linguistic structures. These structure usually form a different pattern that is hard for the machine algorithm to understand. Therefore, it is reasonable to hypothesize that the an idiom phrase is more likely to be a difficult word for word segmentation task. We can see from <ref type="figure" target="#fig_2">Figure 2a</ref> that 58.1% of idioms have a difficulty at (0.9,1]. The proportion does increase with the degree of difficulty, which corresponds with the human intuition.</p><p>Dissyllabic Word Disyllabic word is a word formed by two consecutive Chinese characters. We can see from <ref type="figure" target="#fig_2">Figure 2b</ref> that the frequency of disyllabic words has a negative correlations with the degree of difficulty. This is an interesting result. It means that a two-syllable word pattern is easy for a machine algorithm to recognize. This is consistent with the lexical statistics <ref type="bibr" target="#b19">(Yip, 2000)</ref>, which shows that dissyllabic words account for 64% of the common words in Chinese.</p><p>Out-of-vocabulary Word Processing out-of- vocabulary (OOV) word is regarded as one of the key factors to the improvement of model performance. Since these words never occur in the training dataset, it is for sure that the word segmentation system will find it hard to correctly recognize these words from the contexts. We can see from <ref type="figure" target="#fig_2">Figure 2c</ref> that OOV generally has high difficulty. However, a lot of OOV is relatively easy for segmenters. All the linguistic predictors above prove that the degree of difficulty, namely the weight for each word, is not only rooted in the foundation of test theory, but also correlated with linguistic intuition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation with New Metric</head><p>Here we demonstrate the effectiveness of the proposed method in a real evaluation by re- analyzing the submission results from NLPCC 2015 Shared Task 2 of Chinese word segmentation. The dataset of this shared task is collected from micro-blog text. For convenience, we use WB to represent this dataset in the following discussions.</p><p>We select the submissions of all 7 participants from the closed track and the submissions of all We compare the standard precision, recall and F-score with our new metric. The result is displayed in <ref type="figure" target="#fig_3">Figure 3</ref>. Considering the related privacy issues, we will refer to the participants as P1, P2, etc. The order of these participants in the sub-figures is sorted according to the original ranking given by the standard metric in each track. The same ID number refers to the same participants.</p><p>It is interesting to see that the proposed metric gives out significantly different rankings for the participants, compared to the original rankings. Based on the standard metric, Participant 1 (P1) ranks the top in closed track while P7 is ranked as the worst in both tracks. However, P2 ranks first under the evaluation of the new metric in the Closed track. P7 also get higher ranking than its original one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Correlation with Human Judgement</head><p>To tell whether the standard metric or the pro- posed metric is more reasonable, we asked three experts to evaluate the quality of the submissions from the participants. We randomly selected 50 test sentences from the WB dataset. For each test sentence, we present all the submitted candidate segmentation results to the human judges in random order. Then, the judges are asked to choose the best candidate(s) with the highest segmentation quality as well as the second-best candidate(s) among all the submissions. Human judges had no access to the source of the sentences.</p><p>Once we collect the human judgement of the segmentation quality, we can compute the score for each participants. If a candidate segmentation result from a certain participant is ranked first for n times, then this participants earned n point. If second for m times, then this participants earned m 2 points. Then we can get the probability of a participants being ranked the best or sub-best by computing n+ m 2 50 . Finally, we get the human- intuition-based gold ranking of the participants through the means of scores from all the human judges.</p><p>It is worth noticing that the ranking result of our proposed metric correlates with the human judgements better than that of the standard metric, as is shown in <ref type="figure" target="#fig_3">Figure 3</ref>. The Pearson corre- lation between our proposed metric and human judgements are 0.9056 (p = 0.004) for closed session and 0.8799 (p = 0.04) for open session while the Pearson correlation between standard metric and human judgements are only 0.096 (p = 0.836) for closed session and 0.670 (p = 0.216). This evidence strongly supports that the proposed method is a good approximate of human judgements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Detailed Analysis</head><p>Since we have empirically got the degree of difficulty for each word in the test dataset, we can compute the distribution of the difficulty for words that have been correctly segmented. We divided the whole range of difficulty into 10 intervals. Then, we count the ratio of the correct segmented units for each difficulty interval. In this way, we can quantitatively measure to what extent the segmentation system performs on difficult test cases and easy test cases.</p><p>As is shown in <ref type="figure" target="#fig_4">Figure 4</ref>, P7 works better on difficult cases than other systems, but the worst on easy cases. This explains why P7 gets good rank based on the new evaluation metric. Besides,  if we compare P1 and P2, we will notice that P2 performs just slightly worse than P1 on easy cases, but much better than P1 on difficult cases. Therefore, conventional evaluation metric rank P1 as the top system because the P1 gets a lot of credits from a large portion of easy cases. Unlike conventional metric, our new metric achieves balance between hard cases and easy cases and ranks P2 as the top system. The experiment result indicates that the new metric can reveal the implicit difference and improvement of the model, while standard metric cannot provide us with such a fine-grained result. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Validity and Reliability</head><p>Jones <ref type="formula">(</ref> Regarding reliability, we perform the parallel- test experiment. We randomly split the test dataset into two halves. These two halves have similar difficulty distribution and, therefore, can be con- sidered as a parallel test. Then different models, including those used in the first experiment, are evaluated on the first half and the second half. The results in <ref type="figure" target="#fig_6">Figure 6</ref> shows that the performances of different models with our proposed evaluation metric are significantly correlated in two parallel tests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Visualization of the Weight</head><p>As is known, there might be some annotation inconsistency in the dataset. We find that most of the cases with high weight are really valuable difficult test cases, such as the visualized sentences from WB dataset in <ref type="figure" target="#fig_9">Figure 7</ref>. In the first sentence, the word 'BMW 族' (NOUN.People who take bus, metro and then walk to the destination) is an OOV word and contains English characters. The weight of this word, as expected, is very high. In the second sentence, the word '素不相 识' (VERB.not familiar with each other) is a 4- character Chinese idiom. the conjunction word '就 算' (CONJ.even if) has structural ambiguity. It can also be decomposed into a two-word phrase '就' (ADV.just) and '算' (VERB.count). From the visualization of the weight, we can see that these difficult words are all given high weights.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Corpus Size</head><note type="other">p r f 1 p b r b f</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Comparisons on SIGHAN datasets</head><p>In this section, we give comparisons on SIGHAN datasets.</p><p>We use four simplified Chinese datasets: PKU and MSR <ref type="bibr">(SIGHAN 2005</ref>) as well as NCC and SXU <ref type="bibr">(SIGHAN 2008)</ref>.</p><p>For each dataset, we train four segmenters with varying abilities, based on 20%, 50%, 80% and 100% of training data respectively. The used feature template is F2 in <ref type="table" target="#tab_0">Table 1.  Table 2</ref> shows the different evaluation results with standard metric and our balanced metric. We can see that the proposed evaluation metric generally gives lower and more distinguishable score, compared with the standard metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Related work</head><p>Evaluation metrics has been a focused topic for a long time. Researchers have been trying to evaluate various NLP tasks towards human intuition ( <ref type="bibr" target="#b14">Papineni et al., 2002;</ref><ref type="bibr" target="#b6">Graham, 2015a;</ref><ref type="bibr" target="#b7">Graham, 2015b)</ref>. Previous work <ref type="bibr" target="#b3">(Fournier and Inkpen, 2012;</ref><ref type="bibr" target="#b4">Fournier, 2013;</ref><ref type="bibr" target="#b16">Pevzner and Hearst, 2002</ref>) mainly deal with the near-miss error case on the context of text segmentation. Much attention has been given to different penalization for the error. These work criticize that traditional metrics such as precision, recall and F-score, consider all the error similar. In this sense, some studies aimed at assigning different penalization to the word. We think that these explorations can be regarded as the foreshadowing of our evaluation metric that balances reward and punishment.</p><p>Our paper differs from previous research in that we take the difficulty of the test case into consideration, while previous works only focus on the variation of error types and penalisation. We involve the basic idea from psychometrics and improve the evaluation with a balance between difficult cases and easy cases, reward and punish- ment.</p><p>We would like to emphasize that our weighted evaluation metric is not a replacement of the traditional precision, recall, and F-score. Instead, our new weighted metrics can reveal more details that traditional evaluation may not be able to present.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>In this paper, we put forward a new psychometric-inspired method for Chinese word segmentation evaluation by weighting all the words in test dataset based on the methodology applied to psychological tests and standardized exams. We empirically analyze the validity and reliability of the new metric on a real evaluation dataset. Experiment results reveal that our weighted evaluation metrics gives more reasonable and distinguishable scores and  <ref type="table">90   by  this  way  travel  of  people thus  be called  BMW</ref>  correlates well with human judgement. We will release the weighted datasets to the academic community. Additionally, the proposed evaluation metric can be easily extended to word segmentation task for other languages (e.g. Japanese) and other sequence labelling-based NLP tasks, with just tiny changes. Our metric also points out a promising direction for the researchers to take into the account of the biased distribution of test case difficulty and focus on tackling the hard bones of natural language processing.</p><note type="other">0.00 0.15 0.30 0.45 0.60 0.75 0.</note></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>F1</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Judgement of difficulty against the committee size. Each line represents a sampled word.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Difficulty distribution of (a) idioms, (b) dysyllabic words and (c) Out-of-vocabulary words from PKU dataset. Similar pattern has also been found in other datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Comparisons of standard metric and our new metric for the closed track and the open track of NLPCC 2015 Weibo Text Word Segmentation Shared Task. The black lines for f 1 and f b are plotted against the left y-axis. The red lines for human judgement scores are plotted against the right y-axis.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Accuracies of different participants in Closed Track by different difficulties on WB dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Comparisons of standard and weighted precision and recall on NLPCC Closed Track.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Correlation between the evaluation results f b of two parallel testsets with the proposed metrics on a collection of models. The Pearson correlation is 0.9961, p = 0.000.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>1994) concluded some important criteria for the evaluation metrics of NLP system. It is very important to check the validity and reliability of a new metric. Previous section has displayed the validity of the proposed evaluation metric by comparing the evaluation results with human judgements. The evaluation results with our new metric correlated with human intuition well.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Visualising the word weight of WB dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Feature templates. C represents a Chinese 
character, and T represents the character-based tag 
in set {B, M, E, S}. The subscript indicates its 
position relative to the current character, whose 
subscript is 0. C i:j represents the subsequence of 
characters form relative position i to j. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Model evaluation with standard metric and our new metric. Models vary in the amount of training data and feature types.</figDesc><table></table></figure>

			<note place="foot" n="2"> Conference on Natural Language Processing and Chinese Computing. http://tcci.ccf.org.cn/conference/2015/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank the anonymous re-viewers for their valuable comments. This work was partially funded by National Natural Science Foundation of China (No. 61532011, 61473092, and 61472088), the National High Technology Research and Development Program of China (No. 2015AA015408).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A maximum entropy approach to natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">J</forename><surname>Della Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Della Pietra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="71" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2002 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The second international Chinese word segmentation bakeoff</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Emerson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth SIGHAN Workshop on Chinese Language Processing</title>
		<meeting>the Fourth SIGHAN Workshop on Chinese Language Processing<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="123" to="133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Segmentation similarity and agreement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Fournier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Inkpen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="152" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Evaluating text segmentation using boundary edit distance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Fournier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1702" to="1712" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The prediction of toefl reading item difficulty: Implications for construct validity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Freedle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irene</forename><surname>Kostin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language Testing</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="133" to="170" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Improving evaluation of machine translation quality estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yvette</forename><surname>Graham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53th Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 53th Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Re-evaluating automatic summarization with bleu and 192 shades of rouge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yvette</forename><surname>Graham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The fourth international Chinese language processing bakeoff: Chinese word segmentation, named entity recognition and Chinese pos tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sixth SIGHAN Workshop on Chinese Language Processing</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page">69</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Towards better nlp system evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Sparck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jones</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the workshop on Human Language Technology</title>
		<meeting>the workshop on Human Language Technology</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1994" />
			<biblScope unit="page" from="102" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Exploring item characteristics that are related to the difficulty of toefl dialogue items</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irene</forename><surname>Kostin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ETS Research Report Series</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">59</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">D</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><forename type="middle">C N</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighteenth International Conference on Machine Learning</title>
		<meeting>the Eighteenth International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The third international chinese language processing bakeoff: Word segmentation and named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gina-Anne</forename><surname>Levow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing</title>
		<meeting>the Fifth SIGHAN Workshop on Chinese Language Processing<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-07" />
			<biblScope unit="page" from="108" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Statistical Theories of Mental Test Scores</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Frederic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allan</forename><surname>Melvin R Novick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Birnbaum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1968" />
			<publisher>Addison-Wesley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Bleu: A method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th annual meeting on association for computational linguistics</title>
		<meeting>the 40th annual meeting on association for computational linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Chinese segmentation and new word detection using conditional random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th international conference on Computational Linguistics</title>
		<meeting>the 20th international conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A critique and improvement of an evaluation metric for text segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Pevzner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Marti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hearst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="19" to="36" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Computer-Based TOEFL Score User Guide</title>
	</analytic>
	<monogr>
		<title level="j">Educational Testing Service</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Chinese word segmentation as character tagging. Computational Linguistics and Chinese Language Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Xue</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="29" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">The Chinese Lexicon: A Comprehensive Survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Po-Ching</forename><surname>Yip</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>Psychology Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The cips-sighan clp 2010 chinese word segmentation bakeoff</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First CPS-SIGHAN Joint Conference on Chinese Language Processing</title>
		<meeting>the First CPS-SIGHAN Joint Conference on Chinese Language Processing</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
