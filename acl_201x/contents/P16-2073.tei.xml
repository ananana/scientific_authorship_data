<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T13:03+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">User Embedding for Scholarly Microblog Recommendation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computer Science and Technology</orgName>
								<orgName type="laboratory">The MOE Key Laboratory of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<postCode>100871</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computer Science and Technology</orgName>
								<orgName type="laboratory">The MOE Key Laboratory of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<postCode>100871</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinjie</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computer Science and Technology</orgName>
								<orgName type="laboratory">The MOE Key Laboratory of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<postCode>100871</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">User Embedding for Scholarly Microblog Recommendation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="449" to="453"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Nowadays, many scholarly messages are posted on Chinese microblogs and more and more researchers tend to find scholarly information on microblogs. In order to exploit microblogging to benefit scientific research, we propose a scholarly mi-croblog recommendation system in this study. It automatically collects and mines scholarly information from Chinese mi-croblogs, and makes personalized recommendations to researchers. We propose two different neural network models which learn the vector representations for both users and microblog texts. Then the recommendation is accomplished based on the similarity between a user&apos;s vector and a microblog text&apos;s vector. We also build a dataset for this task. The two embedding models are evaluated on the da-taset and show good results compared to several baselines.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Online social networks such as microblogs have drawn growing attention in recent years, and more and more researchers are involved in mi- croblogging websites. Besides expressing their own emotions and exchanging their life experi- ences just like other users, these researchers also write from time to time about their latest findings or recommend useful research resources on their microblogs, which may be insightful to other researchers in the same field. We call such mi- croblog texts scholarly microblog texts. The vol- ume of scholarly microblog texts is huge, which makes it time-consuming for a researcher to browse and find the ones that he or she is inter- ested in.</p><p>In this study, we aim to build a personalized recommendation system for recommending scholarly microblogs. With such a system a re- searcher can easily obtain the scholarly mi- croblogs he or she has interests in. The system first collects the latest scholarly microblogs by crawling from manually selected microblog users or by applying scholarly microblog classification methods, as introduced in ( <ref type="bibr" target="#b11">Yu and Wan, 2016)</ref>. Second, the system models the relevance of each scholarly microblog to a researcher and make personalized recommendation. In this study, we focus on the second step of the system and aim to model the interest and preference of a researcher by embedding the researcher into a dense vector. We also embed each scholarly microblog into a dense vector, and thus the relevance of a scholar- ly microblog to a researcher can be estimated based on their vector representations.</p><p>In this paper, we propose two neural embed- ding algorithms for learning the vector represen- tations for both users (researchers) and mi- croblog texts. By extending the paragraph vector representation method proposed by <ref type="bibr" target="#b5">(Le and Mikolov, 2014)</ref>, the vector representations are jointly learned in a single framework. By model- ing the user preferences into the same vector space with the words and texts, we can obtain the similarity between them in a straightforward way, and use this relevance for microblog recommen- dation. We build a real evaluation dataset from Sina Weibo. Evaluation results on the dataset show the efficacy of our proposed methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>There have been a few previous studies focusing on microblog recommendation. <ref type="bibr" target="#b2">Chen et al. (2012)</ref> proposed a collaborative ranking model. Their approach takes advantage of collaborative filter- ing based recommendation by collecting prefer- ence information from many users. Their ap- proach takes into account the content of the tweet, user's social relations and certain other explicitly defined features. <ref type="bibr" target="#b6">Ma et al. (2011)</ref> generated rec- ommendations by adding additional social regu- larization terms in MF to constrain the user latent feature vectors to be similar to his or her friends' average latent features. <ref type="bibr" target="#b1">Bhattacharya et al. (2014)</ref> proposed a method benefiting from knowing the user's topics of interest, inferring the topics of interest for an individual user. Their idea is to infer them from the topical expertise of the users whom the user follows. <ref type="bibr">Khater and Elmongu (2015)</ref> proposed a dynamic personalized tweet recommendation system capturing the user's in- terests, which change over the time. Their sys- tem shows the messages that correspond to such dynamic interests. <ref type="bibr" target="#b4">Kuang et al. (2016)</ref> consid- ered three major aspects in their proposed tweet recommending model, including the popularity of a tweet itself, the intimacy between the user and the tweet publisher, and the interest fields of the user. They also divided the users into three types by analyzing their behaviors, using differ- ent weights for the three aspects when recom- mending tweets for different types of users. Most of the above studies make use of the re- lationships between users, while in this study, we focus on leveraging only the microblog texts for addressing the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Our Approach</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Task Definition</head><p>We denote a set of users by </p><formula xml:id="formula_0">    tt d u d u </formula><p>as possible. In this section, we introduce one baseline method and then propose two different neural network methods for user and microblog embed- ding. The baseline averages the vector represen- tation of microblog texts into a user vector repre- sentation. Our proposed two methods learn user vector representations jointly with word and text vectors, either indirectly or directly from word vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Paragraph Vector</head><p>As our methods are mainly based on the Para- graph Vector model proposed by <ref type="bibr" target="#b5">(Le and Mikolov, 2014)</ref>, we start by introducing this framework first.</p><p>Paragraph Vector is an unsupervised frame- work that learns continuous distributed vector representations for pieces of texts. In this ap- proach, every paragraph is mapped to a unique vector, represented by a column in matrix D and every word is also mapped to a unique vector, represented by a column in matrix W . This ap- proach is similar to the Word2Vec approach pro- posed in ( , except that a paragraph token is added to the paragraph and is treated as a special word. The paragraph vector is asked to contribute to the prediction work in ad- dition to the word vectors in the context of the word to be predicted. The paragraph vector and word vectors are averaged to predict the next word in a context. token, k as the window size, the Paragraph Vec- tor model applies hierarchical softmax to maxim- ize the average log probability 1 log ( | , ,..., )</p><formula xml:id="formula_1">t i t k t k t p w d w w T  </formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Averaging Microblog Text Vectors as User Vector</head><p>An intuitive baseline approach to map a mi- croblog user into a vector space is to build such representation from the vector representations of the microblogs he or she likes. We treat microblog texts as paragraphs, and then apply the Paragraph Vector model intro- duced in Section 3.2 to learn vector representa- tions of the microblog texts. After learning all vector representations of microblog texts, for each user, we average all vectors of microblog   texts he or she likes in the training set as the user vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Learning User Vectors Indirectly From Word Vectors</head><p>Besides the above-mentioned baseline approach we further consider to jointly learn the vectors of users and microblog texts. The structure of this framework is shown in <ref type="figure" target="#fig_1">Figure 1</ref>. We name this framework User2Vec#1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Learning User Vectors Directly From Word Vectors</head><p>In the above framework, the user vectors are learned only from microblog text vectors, not directly from word vectors. Another framework we proposed for learning user vector representa- tion is to put user vectors and microblog vectors in the same layer. Unlike User2Vec#1, we do not use user vectors to predict microblog text vector. Instead, we directly add user vectors into the in- put layer of word vector prediction task, along with the microblog text vector. In this framework, the average log probability we want to maximize is 1 1 ( log ( | , ,..., , ,..., )</p><formula xml:id="formula_2">h t i t k t k i i t p w d w w u u T  </formula><p>In practical tasks, we modify the dataset by copying each microblog once for each user in í µí±¢ ̃(í µí± í µí± ), and make each copied microblog text only relate to one user. All copies of the same mi- croblog text share a same vector representation.</p><p>The structure of the framework is shown in <ref type="figure" target="#fig_3">Figure 2</ref>. We name this framework User2Vec#2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Recommending Microblogs</head><p>When recommending microblogs, given a mi- croblog j d and a user k u , we compute the cosine distance between their vector representations, and use the cosine distance to determine whether j d should be recommended to k u or not.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data Preparation</head><p>To evaluate our proposed user embedding meth- ods in a scholarly microblog recommending sys- tem, we built a dataset by crawling from the website Machine Learning Daily 1 . The Machine Learning Daily is a Chinese website which focuses on collecting and labeling scholarly microblogs related to machine learning, natural language processing, information retriev- al and data mining on Sina Weibo. These mi- croblog texts were collected by a combination of manual and automatic methods, and each mi- croblog text is annotated with multiple tags by experts, yielding an excellent dataset for our ex- periment. The microblog texts in our dataset can be written in a mixture of both Chinese and Eng- lish. We removed stop words from the raw texts, leaving 16,797 words in our corpus. The texts were then segmented with the Jieba Chinese text segmentation tool 2 .  Average Embedding User2Vec#1 User2Vec#2</p><p>After crawling the microblogs from the Ma- chine Learning Daily, we used Sina Weibo API to retrieve the list of users who retweeted or commented on those microblogs. These retweet- ing and commenting actions indicated that those users have interests in the microblogs they re- tweeted or commented, and such microblogs were considered the gold-standard (positive) mi- croblogs for the users in the recommendation system. Then we filtered out the users who have less than two hundred positive samples to avoid the data sparseness problem. This left us with 711 users and 10,620 microblog texts in our cor- pus. Each user was associated with 282.3 posi- tive microblogs on average.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation Setup</head><p>Because there is no API that can directly grant us the access to the follower and followee list for each user without authorization on Sina Weibo, when evaluating the effectiveness of our methods, we randomly choose one hundred positive sam- ples and another four hundred negative samples randomly selected from the crawled microblogs, to simulate the timeline of a user, and use this simulated timeline as the test dataset. The re- maining positive samples are used for training.</p><p>We adopt two additional baselines: Bag-of- Words and SVM on Bag-of-Words. For the Bag- of-Words baseline, we use the Bag-of-Words vector of each microblog text as the microblog text vector, and average them to obtain user vec- tors. For the SVM on Bag-of-Words baseline, we randomly choose the same amount of negative samples as that of positive samples for training. We use the Bag-of-Words vector of each mi- croblog text as the features, and run the SVM algorithm implemented in LibSVM 3 once for every user. Note that the Average Embedding 3 https://www.csie.ntu.edu.tw/~cjlin/libsvm/ method introduced in Section 3.3 is considered a strong baseline for comparison.</p><p>For each method and each user, we sort the microblog texts according to their similarity with the user and select the top k microblog texts as recommendation results, where k varies from 10 to 100.</p><p>Besides precision and recall values, we also compute mean reciprocal rank (MRR) to meas- ure the recommendation results in our experi- ments, which is the average of the multiplicative inverse of the rank of the positive samples in the output of the recommending system, and then averaged again across all users. Note that when k is set to 100, the precision and recall value will be equal to each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluation Results</head><p>The comparison results with respect to differ- ent k are shown in <ref type="table" target="#tab_3">Table 1</ref>. As we can see, the two proposed joint learning methods outperform the simple average embedding method and the two other baselines, indicating the effectiveness of the proposed methods. Moreover, User2Vec#2 yields better results than User2Vec#1.We believe this is because in User2Vec#2, the word vectors have a direct contribution to the user vectors, which improves the learning effect of the user k=10 k=20 k=50 k=100  vectors learnt in the framework. Furthermore, the precision/recall scores of the embedding methods (k=100) with respect to different vector dimen- sions are shown in <ref type="figure" target="#fig_5">Figure 3</ref>. We can see that the dimension size has little impact on the recom- mendation performance, and our proposed two methods always outperform the strong baseline.</p><formula xml:id="formula_3">Preci- sion Recall MRR Preci- sion Recall MRR Preci- sion Recall MRR Preci- sion Recall MRR Bag-of-</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we proposed two neural embedding methods for learning the vector representations for both the users and the microblog texts. We tested their performance by applying them to recommending scholarly microblogs. In future work, we will investigate leveraging user rela- tionships and temporal information to further improve the recommendation performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Formally speaking, given a paragraph   12 , , , , iT d w w w  with i d as the paragraph</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. The proposed User2Vec#1 framework for learning user vector representation. In this framework, the word vectors do not directly contribute to the user vectors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. The proposed User2Vec#2 framework for learning user vector representation. In this framework, the word vectors contribute directly to the user vectors, along with the microblog text vectors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Precision/Recall@k=100 w.r.t. vector dimension.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head> , we denote the set of microblogs that t u is interested in by   t du . In our task, the entire sets of d and u are given, while given a user t uu  , only a subset of   t du is known. This subset is used as the train- ing set, denoted as   t du . Our task aims to re- trieve a subset ' d of d , that ' d is as similar to</head><label></label><figDesc></figDesc><table> 
 

12 , , , m 
u 
u u 
u 
 

, 
and 
a set 
of 
microblog texts by 

 
 

12 , , , n 
d 
d d 
d 
 
. We assume that a user 
tweeting, retweeting or commenting on a mi-
croblog text reflects that the user is interested in 
that microblog. Given t 

uu </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Word Matrix W Microblog text Matrix D User Matrix U Average Average</head><label></label><figDesc></figDesc><table>t 

w t-3 
w t-2 
w t-1 
d i 

u i1 
u i2 
u i3 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 1 . Overview of results.</head><label>1</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="1"> http://ml.memect.com/ 2 https://github.com/fxsjy/jieba</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The work was supported by National Natural Science Foundation of China <ref type="formula">(61331011)</ref> </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Towards social-based user modeling and personalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Barla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences and Technologies Bulletin of the ACM Slovakia</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Inferring user interests in the twitter social network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parantapa</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><forename type="middle">Bilal</forename><surname>Zafar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niloy</forename><surname>Ganguly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saptarshi</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krishna</forename><forename type="middle">P</forename><surname>Gummadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th ACM Conference on Recommender systems</title>
		<meeting>the 8th ACM Conference on Recommender systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Collaborative personalized tweet recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kailong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoqing</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ou</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enpeng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 35th international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Tweets You Like: Personalized Tweets Recommendation based on Dynamic Users Interests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaymaa</forename><surname>Khater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hicham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Elmongui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ASE Conference</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A comprehensive ranking model for tweets big data in online social network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Kuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meiqi</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujian</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kehua</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EURASIP Journal on Wireless Communications and Networking</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">2016</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mikolov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1405.4053</idno>
		<title level="m">Distributed representations of sentences and documents</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Recommender systems with social regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dengyong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">R</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irwin</forename><surname>King</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fourth ACM international conference on Web search and data mining</title>
		<meeting>the fourth ACM international conference on Web search and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Dynamic user modeling in social media systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Hongzhi Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofang</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">33</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">TopicSTG: Extending the session-based temporal graph approach for personalized tweet recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianjun</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenglu</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the companion publication of the 23rd international conference on World Wide Web companion. International World Wide Web Conferences Steering Committee</title>
		<meeting>the companion publication of the 23rd international conference on World Wide Web companion. International World Wide Web Conferences Steering Committee</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">MicroScholar: Mining Scholarly Information from Chinese Microblogs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirtieth AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
