<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:01+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">On the Challenges of Translating NLP Research into Commercial Products</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Dahlmeier</surname></persName>
							<email>d.dahlmeier@sap.com</email>
							<affiliation key="aff0">
								<orgName type="department">SAP Innovation Center</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">On the Challenges of Translating NLP Research into Commercial Products</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</title>
						<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="92" to="96"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-2015</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper highlights challenges in industrial research related to translating research in natural language processing into commercial products. While the interest in natural language processing from industry is significant, the transfer of research to commercial products is non-trivial and its challenges are often unknown to or underestimated by many researchers. I discuss current obstacles and provide suggestions for increasing the chances for translating research to commercial success based on my experience in industrial research.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Natural language processing (NLP) has made sig- nificant progress over the last two decades, in par- ticular due to the success of data-driven machine learning methods. Recently, deep learning has led to another wave of remarkable improvements in NLP and other areas of machine learning and ar- tificial intelligence (AI). Not surprisingly, many industry players are investing heavily in machine learning and AI to create new products and ser- vices <ref type="bibr">(MIT Technology Review, 2016)</ref>.</p><p>However, translating research into a success- ful product has its own challenges. Tradition- ally, technology transfer is often assumed to hap- pen in a linear transition from pure research to applied research to commercialization <ref type="bibr" target="#b19">(Stokes, 1997</ref>). The model assumes that the discoveries from researchers will naturally be picked up by engineers and industry players who will use it to build new products. In reality, the transfer from research to commercial products is considerably more complex and far from guaranteed. In fact, many research projects fail to successfully trans- fer their discoveries to commercial products.</p><p>In this position paper, I highlight some of the reasons why it is so difficult to translate NLP re- search into successful products. This paper does not contain any new algorithms, experiments, or results. Instead, it seeks to share my experience working at the intersection of academic research and industry with the aim to stimulate a discus- sion how technology transfer of NLP research can be improved. I want to emphasize upfront that the paper is not arguing that all NLP researchers should focus their efforts on building commercial products nor does every new product require a re- search breakthrough to be successful. The paper's aim is rather to discuss how we can improve use- inspired basic research that satisfies both the de- sire for fundamental understanding and consider- ations of use, sometimes referred to as Pasteur's quadrant <ref type="bibr" target="#b19">(Stokes, 1997)</ref>.</p><p>The contributions of this paper are twofold. First, I highlight common obstacles in the path of transferring research into commercial prod- ucts. Second, I offer suggestions for increasing the chances of success based on my experience at SAP, the world's largest enterprise software com- pany.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Challenges to Innovation</head><p>This section highlights challenges in NLP research that make it difficult to translate the results into impactful innovation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Lack of Value Focus</head><p>The first step to creating a successful product is understanding your customers. That is why many methodologies for creating new products or busi- ness models start with a user persona and how to create value for the user <ref type="bibr" target="#b16">(Ries, 2011;</ref><ref type="bibr" target="#b12">Osterwalder et al., 2014</ref>). Similarly, to conduct research with practical impact, it is worthwhile to consider what potential applications the research could enable and what the value proposition for a potential user might be. The value proposition is closely linked to the user persona and the tasks that she tries to solve in her daily life <ref type="bibr" target="#b4">(Christensen and Raynor, 2013)</ref>. Thus, choosing the right research task is important when aiming for impactful research. It is instructive that NLP tasks which solve practical problems, like machine translation or sentiment analysis, have seen significant adoption in com- mercial applications. But many applications that are requested by industry are still beyond the capa- bilities of current NLP research, for example chat- bots that can respond to arbitrary user questions.</p><p>It is also important for researchers to understand that the priorities in industry are different from priorities in academic research. In academic re- search, the priorities are to create contributions to the body of knowledge in the field, e.g., defining a new task, a novel, elegant model, or a new state- of-the-art benchmark result. In industry the prior- ities are creating innovative products that delight users and create new revenue streams. To have the best of both worlds, researchers should occa- sionally take a step back and consider what value proposition their work has for people outside the NLP community.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Lack of Reproducibility</head><p>Reproducible research is one of the pillars of the scientific method and thus important to good re- search work in general. But the ability to repro- duce a model is also a prerequisite to incorporat- ing it into a product. As NLP models often depend on a complex set of parameters and pre-processing steps which cannot always be explained in all de- tail in a paper, it is often hard to reproduce other's results. The author himself has his own experience trying to (unsuccessfully) reproduce published re- sults. As problems to reproduce research are sel- dom reported (but see <ref type="bibr" target="#b1">(Bikel, 2004</ref>) for an excep- tion), it is also hard for researchers to find informa- tion on how to improve their implementation when they struggle to re-produce published results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Lack of (Domain) Data</head><p>Data is the fuel that powers machine learning and most of NLP research. While the "big data" rev- olution has given us access to large quantities of text data from some domains, for many industry problems there is no or very limited data avail- able to conduct research on. For example, in my group we have been working on text classi- fication for customer service tickets. While there are many datasets available for text classification, these are primarily from newswire or online re- views. For customer service, there is no public dataset to compare to. Due to the confidential na- ture of the data and data privacy concerns, compa- nies who have such data cannot easily release it for research purposes. Some companies host shared tasks or data science competitions in which they make data available, for example on Kaggle 1 , but access to data remains one of the biggest obsta- cles for researcher who want to work on industry problems.</p><p>Even when there is data available from public sources, e.g., from the web, using the data for commercial purposes can be tricky from a legal standpoint. Crawling data from web (or using cor- pora created by others in this manner) might be ac- ceptable for research purposes, but when building a commercial product the exact license, copyright, etc. of every data source needs to be checked. The same holds for publicly available NLP models de- rived from such data.</p><p>For everyone who believes that working in in- dustry solves all data problem, I note here that working with real data sets has its own challenges. Real data sets are often small, noisy, scrambled, or otherwise incomplete, making it hard to achieve good results. To effectively use the data, re- searchers also have to understand the data schema and the business process behind the data. This can be challenging without and in-depth domain knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Overemphasis on Test Scores</head><p>The empirical evaluation of statistical methods on common benchmarks has without a doubt revolu- tionized NLP <ref type="bibr" target="#b7">(Johnson, 2009)</ref>. However, some- times the score on the test set is taken as the only factor that determines the success of a piece of research. For practical applications, the test score on a benchmark dataset is only one criteria among many when it comes to choosing an algo- rithm for practical use. Other factors include the time and costs required to implement the method, the computational resources required, speed and performance, the ease of integration, support for multi-lingual input, the ability to adapt and cus- tomize the method, the ability to incorporate prior knowledge, and the ability to interpret and explain the model. For example, in our text categoriza- tion work, we encountered the requirement to ac- commodate changes in the the output classes, i.e., adding, merging, splitting, and removing classes, without re-training the model from scratch. These factors are currently underrepresented in NLP re- search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Difficulty of Adoption</head><p>No matter how good an NLP model is, it cannot have practical impact if it is never implemented. But in any application, the NLP model will only be one component in a larger software system. How easily the NLP component can work together with the remaining components is important for the ease of adoption of the method into productive applications. Unlike rule-based methods, statisti- cal NLP models often require expensive collection and labeling of data, data pre-processing, model (re-)training, parameter tuning, and monitoring of the model to avoid model staleness. This makes it harder to adopt statistical models in practical ap- plications ( <ref type="bibr" target="#b3">Chiticariu et al., 2013</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Timelines</head><p>The time horizon within which stakeholders expect results is generally shorter in industry projects. While research grants typically run for three to five years, industry research is under pres- sure to deliver tangible outcomes in less than two years. For projects with actual customers and proof of concepts, timelines are usually not longer than a few months. This results in the following chicken and egg problem: it is difficult to produce groundbreaking research within a short time frame but long investments into research are hard to jus- tify if the value the research will ultimately pro- duce is not clear. That is why academic research is generally better equipped to focus on funda- mental research questions. Fundamental research does not exclude practical usage but incremental research that fine-tunes every aspect of the imple- mentation of an NLP model is often better done in industry labs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Bridging the Gap</head><p>In this section, I offer some suggestions about how the disconnect between NLP research and com- mercial products can be reduced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">A "Recipe" for Qualifying a Research Problem</head><p>The following approach describes the criteria that we typically apply in our team when we evaluate new machine learning use cases, including NLP use cases. First, we make sure we understand the "job to be done": what is the business problem, who is the potential user and what problem are we try- ing to solve? Once we have understood the task, a first question to ask is whether the task actually requires NLP. Is the data volume so high that au- tomation is needed? Would it be easier or cheaper to solve the task manually? Can the task be solved via simple rules? Typically, tasks with high data volume and complex or ambiguous rules are good candidates for NLP.</p><p>To ensure that the use cases we work on have practical relevance, we include stakeholders from the lines of business and industry units in the com- pany in any new project right from the beginning and gather feedback from actual customers.</p><p>Once we believe that NLP is required, we try to formulate the problem as a machine learning task. The simple template given X, predict Y together with the question what are the inputs and what are the outputs? helps significantly to get from a vague idea to a concrete task formulation. At this stage, we can often already map the problem to a standard NLP task, e.g., text classification, se- quence tagging, or sequence-to-sequence learning.</p><p>Next, we establish whether data is available. If real data is not available easily, can we work with publicly available proxy data? For example for learning to classify customer service tickets, we can start with text classification on public datasets. If it is unlikely that data will be available in the foreseeable future, we do not proceed with a use case.</p><p>Next, we make a best guess whether the prob- lem can be solved with the current state of the art in NLP. Is there an intuitive regularity in the data which we believe a statistical model could pick up? Can we represent the input via meaningful features? Do we have a way to measure the suc- cess of the method with a well-defined metric?</p><p>Finally, we determine the right approach to ex- ecute the use case. If it is a hard problem which needs at least a few more years of research be- fore it becomes useful, we would most likely de- cide on a research project. We fund external research projects at top universities around the world, where we provide the research problem and the data and let others try to crack the tough prob- lems. We also sponsor Ph.D. students who are working at SAP during their studies.</p><p>If we think that the use case has a strong busi- ness case and the technology is mature enough, we will move it to building a proof of concept, and ultimately a commercial product. While this "recipe" for qualifying an NLP use case is simple and common sense, we have found it helpful in prioritizing use cases.</p><p>Researchers in academia might not have access to a business unit to provide feedback on research ideas but many funding bodies are trying to en- courage increased collaborations between industry and academia. The European Union, for example, has specifically funded an initiative, LT-innovate 2 to encourage commercial exploitation of NLP re- search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Engineering Approach to NLP</head><p>I believe that a more rigorous application of (soft- ware) engineering principles and tools can greatly increase the odds of having practical impact with NLP research.</p><p>To address the problem of reproducibility, I sug- gest the following. First, the community should be more stringent about reproducibility. In some research communities, for example databases, the criteria for reproducible research are a lot stricter. If the results are not reproducible, the results are generally not considered valid. However, the large number of parameters and implementation details in NLP systems makes it hard to exactly repro- duce published results based on the paper alone. Therefore, we should encourage the dissemination of results through software tools that make code reproducible. To reproduce the results in a pa- per, we essentially need the code, the data, and the parameters of the experimental run that pro- duced the results of the experiment. Fortunately, the open source community has created great tools that make this possible. First, social code reposi- tory platforms, such as GitHub 3 , make it easy to share code and data. In fact, the ease of shar- ing and contributing to code has arguably acceler- ated the progress in machine learning significantly. Second, interactive computational environments, such as Jupyter notebooks <ref type="bibr">4</ref> , that tie together data, code, and documentation, allow for reproducible results that can easily be shared and published. Fi- nally, software containers, such as Docker 5 , allow light-weight virtualization that pulls in all soft- ware dependencies and allow the same code to run in a reliable and reproducible manner. If a Jupyter notebook or Dockerfile is published with the pa- per, it should be easier for other researchers to re- produce results and integrate them into larger sys- tems. Projects like CodaLab 6 try to build online platforms for reproducible research with similar goals.</p><p>On the problem of data availability, there is al- ready a considerable amount of work in the area of building NLP models in low-resource environ- ments (see for example <ref type="bibr" target="#b5">(Duong et al., 2014;</ref><ref type="bibr" target="#b6">Garrette and Baldridge, 2013;</ref><ref type="bibr" target="#b21">Wang et al., 2015)</ref>) which deals with limited data availability. Tech- niques like domain adaptation, semi-supervised learning and transfer learning <ref type="bibr" target="#b13">(Pan and Yang, 2010)</ref> are extremely relevant to address the prob- lem of data availability for industry applications. Finally, recent work on learning models from pri- vate data <ref type="bibr">(Papernot et al., 2016</ref>) and federated learning across many devices <ref type="bibr" target="#b10">(McMahan et al., 2016</ref>) appear to be promising directions for prac- tical NLP engineering research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Industry Papers</head><p>I believe that there is an opportunity to increase the exchange between industry and the research community by establishing an industry paper sub- mission format, potentially with its own industry track at NLP conferences. Such a track could offer a venue to discuss practical challenges in building large-scale NLP systems and deploying NLP models in production settings, such as scal- ability, trade-offs between accuracy and compu- tational costs, robustness, data quality, etc. This would help to counter-balance the overemphasis on test scores in pure research papers and aid the adoption of research in industry applications. In- dustry tracks are common in other communities and have strong participation from industry play- ers there.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related Work</head><p>Wagstaff (2012) argues for making machine learn- ing research more relevant. He laments a hyper- focus on UCI benchmark datasets and abstract metrics. <ref type="bibr" target="#b18">Spector et al. (2012)</ref> present Google's hybrid approach to research, which tries to avoid separation between research and engineering. Re- cently, several groups at Google have published papers on practical challenges in deploying ma- chine learning in production ( <ref type="bibr" target="#b17">Sculley et al., 2014;</ref><ref type="bibr" target="#b9">McMahan et al., 2013;</ref><ref type="bibr" target="#b2">Breck et al., 2016)</ref>. <ref type="bibr" target="#b0">Belz (2009)</ref> discusses the practical applications of NLP research. <ref type="bibr" target="#b8">Mani (2011)</ref> gives suggestions for im- proving the review process. None of the works provides a detailed discussion on the difficulties in bringing NLP research to commercial products - the main contribution of this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>I have highlighted difficulties that exist for re- searchers who try to bring NLP research into com- mercially products and offered suggestions for im- proving the odds of commercial success. I hope that my experience can stimulate creative thought and a healthy discussion in the NLP community.</p></div>
			<note place="foot" n="1"> https://www.kaggle.com</note>

			<note place="foot" n="2"> http://www.lt-innovate.org 3 https://github.com/</note>

			<note place="foot" n="4"> http://jupyter.org/ 5 https://www.docker.com/ 6 http://codalab.org/</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">That&apos;s nice... what can you do with it?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anja</forename><surname>Belz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Intricacies of Collins&apos; parsing model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Bikel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Whats your ML test score? A rubric for ML production systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Breck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanqing</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Nielsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Salib</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sculley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Reliable Machine Learning in the Wild-NIPS 2016 Workshop</title>
		<meeting>Reliable Machine Learning in the Wild-NIPS 2016 Workshop</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Rule-based information extraction is dead! long live rule-based information extraction systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Chiticariu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunyao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederick</forename><forename type="middle">R</forename><surname>Reiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">The Innovator&apos;s Solution: Creating and Sustaining Successful Srowth</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Clayton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">E</forename><surname>Christensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Raynor</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Harvard Business Review Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">What can we get from 1000 tokens? A case study of multilingual POS tagging for resource-poor languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Duong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karin</forename><surname>Verspoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning a part-of-speech tagger from two hours of annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Garrette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Baldridge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of HLT-NAACL</title>
		<meeting>HLT-NAACL</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">How the statistical revolution changes (computational) linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the EACL 2009 Workshop on the Interaction between Linguistics and Computational Linguistics</title>
		<meeting>the EACL 2009 Workshop on the Interaction between Linguistics and Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Improving our reviewing processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inderjeet</forename><surname>Mani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Arnar Mar Hrafnkelsson, Tom Boulos, and Jeremy Kubica</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brendan</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary</forename><surname>Holt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sculley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dietmar</forename><surname>Ebner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Grady</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lan</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Davydov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Golovin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharat</forename><surname>Chikkerur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Wattenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIGKDD</title>
		<meeting>ACM SIGKDD</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Ad click prediction: a view from the trenches</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Communication-efficient learning of deep networks from decentralized data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brendan</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eider</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Ramage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seth</forename><surname>Hampson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blaise</forename><surname>Agera Y Arcas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AISTATS</title>
		<meeting>AISTATS</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">MIT Technology Review</title>
		<imprint>
			<date type="published" when="2016" />
			<publisher>AI Takes Off</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Value proposition design: How to create products and services customers want</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Osterwalder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yves</forename><surname>Pigneur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Bernarda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Smith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A survey on transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on knowledge and data engineering</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">10</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martín</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ulfar Erlingsson</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Semisupervised knowledge transfer for deep learning from private training data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunal</forename><surname>Talwar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">The lean startup: How today&apos;s entrepreneurs use continuous innovation to create radically successful businesses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Ries</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Crown Business</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Machine learning: The high interest credit card of technical debt</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sculley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary</forename><surname>Holt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Golovin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Davydov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dietmar</forename><surname>Ebner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinay</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SE4ML: Software Engineering for Machine Learning</title>
		<meeting>SE4ML: Software Engineering for Machine Learning</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Google&apos;s hybrid approach to research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alfred</forename><surname>Spector</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Norvig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Pasteur&apos;s quadrant: Basic Science and Technological Innovation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><forename type="middle">E</forename><surname>Stokes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<publisher>Brookings Institution Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Machine learning that matters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiri</forename><surname>Wagstaff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Building a semantic parser overnight</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yushi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
