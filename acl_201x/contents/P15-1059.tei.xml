<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:35+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Building a Scientific Concept Hierarchy Database (SCHBASE)</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eytan</forename><surname>Adar</surname></persName>
							<email>eadar@umich.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Michigan Ann Arbor</orgName>
								<orgName type="institution" key="instit2">University of Michigan</orgName>
								<address>
									<postCode>48104, 48104</postCode>
									<settlement>Ann Arbor</settlement>
									<region>MI, MI</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srayan</forename><surname>Datta</surname></persName>
							<email>srayand@umich.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Michigan Ann Arbor</orgName>
								<orgName type="institution" key="instit2">University of Michigan</orgName>
								<address>
									<postCode>48104, 48104</postCode>
									<settlement>Ann Arbor</settlement>
									<region>MI, MI</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Building a Scientific Concept Hierarchy Database (SCHBASE)</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="606" to="615"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Extracted keyphrases can enhance numerous applications ranging from search to tracking the evolution of scientific discourse. We present SCHBASE, a hierarchical database of keyphrases extracted from large collections of scientific literature. SCHBASE relies on a tendency of scientists to generate new abbreviations that &quot;extend&quot; existing forms as a form of signaling novelty. We demonstrate how these keyphrases/concepts can be extracted, and their viability as a database in relation to existing collections. We further show how keyphrases can be placed into a semantically-meaningful &quot;phylogenetic&quot; structure and describe key features of this structure. The complete SCHBASE dataset is available at: http://cond.org/schbase.html.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Due to the immense practical value to Informa- tion Retrieval and other text mining applications, keyphrase extraction has become an extremely popular topic of research. Extracted keyphrases, specifically those derived from scientific literature, support search tasks <ref type="bibr" target="#b1">(Anick, 2003)</ref>, classification and tagging <ref type="bibr" target="#b20">(Medelyan et al., 2009)</ref>, informa- tion extraction ( <ref type="bibr" target="#b33">Wu and Weld, 2008)</ref>, and higher- level analysis such as the tracking of influence and dynamics of information propagation <ref type="bibr" target="#b30">(Shi et al., 2010;</ref><ref type="bibr" target="#b26">Ohniwa et al., 2010)</ref>. In our own work we use the extracted hierarchies to predict scien- tific emergence based on how rapidly new vari- ants emerge. Keyphrases themselves capture a diverse set of scientific language (e.g., methods, techniques, materials, phenomena, processes, dis- eases, devices).</p><p>Keyphrases, and their uses, have been stud- ied extensively <ref type="bibr" target="#b12">(Gil-Leiva and Alonso-Arroyo, 2007)</ref>. However, automated keyphrase extrac- tion work has often focused on large-scale statis- tical techniques and ignored the scientific com- munication literature. This literature points to the complex ways in which keyphrases are cre- ated in light of competing demands: expressive- ness, findability, succinct writing, signaling nov- elty, signaling community membership, and so on <ref type="bibr" target="#b14">(Hartley and Kostoff, 2003;</ref><ref type="bibr" target="#b16">Ibrahim, 1989;</ref><ref type="bibr" target="#b13">Grange and Bloom, 2000;</ref><ref type="bibr">Gil-Leiva and AlonsoArroyo, 2007</ref>). Furthermore, the tendency to ex- tract keyphrases through statistical mechanisms often leads to flat keyphrase spaces that make anal- ysis of evolution and emergence difficult.</p><p>Our contention, and the main motivation be- hind our work, is that we can do better by lever- aging explicit mechanisms adopted by authors in keyphrase generation. Specifically, we focus on a tendency to expand keyphrases by adding terms, coupled with a pressure to abbreviate to retain succinctness. As we argue below, scien- tific communication has evolved the use of ab- breviations to deal with various constraints. Ab- breviations, and acronyms specifically, are rela- tively new in many scientific domains <ref type="bibr" target="#b13">(Grange and Bloom, 2000;</ref><ref type="bibr" target="#b9">Fandrych, 2008)</ref> but are now ubiq- uitous <ref type="bibr" target="#b16">(Ibrahim, 1989;</ref><ref type="bibr" target="#b4">Cheng, 2010)</ref>.</p><p>Keyphrase selection is often motivated by increasing article findability within a domain (thereby increasing citation). This strategy leads to keyphrase reuse. A competing pressure, how- ever, is to signal novelty in an author's work which is often done by creating new terminology (e.g., creating a "brand" around a system or idea). For example, a machine learning expert working on a new type of Support Vector Machine will want their article found when someone searches for "Support Vector Machine," but will also want to add their own unique brand. In response, they will often augment the original keyphrase (e.g., "Least- Squares Support Vector Machine") rather than in- venting a completely new one. Unfortunately, continuous expansion will soon render a paper un- readable (e.g., one of many extensions to Poly- merase Chain Reaction is Standard Curve Quan- titative Competitive Reverse Transcription Poly- merase Chain Reaction). Thus emerges a second strategy: abbreviation.</p><p>Our assertion is that abbreviations are a key mechanism for resolving competing demands. Authors can simultaneously expand keyphrases, thus maintaining both findability and novelty, while at the same time addressing the need to be succinct and non-repetitive. Of interest to us is the phenomena that if a new keyphrase expands an existing keyphrase that has an established ab- breviation, the new keyphrase will also be ab- breviated (e.g., LS-SVM and SVM). This ten- dency allows us to construct hierarchies of evolved keyphrases (rather than assuming a flat keyphrase space) which can be leveraged to identify emer- gence, keyphrase "mash-ups," and perform other high level analysis. As we demonstrate below, edges represent the rough semantic of EXTENDS or ISSUBTYPEOF. So if keyphrase A is connected to B, we can say A is a subtype of B (e.g., A is "Least-Squares Support Vector Machine" and B is "Support Vector Machine").</p><p>In this paper we introduce SCHBASE, a hi- erarchical database of keyphrases. We demon- strate how we can simply, but effectively, extract keyphrases by mining abbreviations from scien- tific literature and composing those keyphrases into semantically-meaningful hierarchies. We fur- ther show that abbreviations are a viable mech- anism for building a domain-specific keyphrase database by comparing our extracted keyphrases to a number of author-defined and automatically- created keyphrase corpora. Finally, we illustrate how authors build upon each others' terminology over time to create new keyphrases. 1 <ref type="bibr">1</ref> Full database available at: http://cond.org/schbase.html</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Initial work in keyphrase extraction utilized heuristics that were based on the understood struc- ture of scientific documents <ref type="bibr" target="#b7">(Edmundson, 1969)</ref>. As more data became available, it was possible to move away from heuristic cues and to lever- age statistical techniques <ref type="bibr" target="#b27">(Paice and Jones, 1993;</ref><ref type="bibr" target="#b32">Turney, 2000;</ref><ref type="bibr">Frank et al., 1999</ref>) that could iden- tify keyphrases within, and between, documents. The guiding model in this approach is that phrases that appear as statistical "anomalies" (by some measure) are effective for summarizing a docu- ment or corpus. This style of keyphrase extrac- tion represents much of the current state-of-the- art ( <ref type="bibr" target="#b17">Kim et al., 2010)</ref>. Specific extensions in this space involve the use of network structures <ref type="bibr" target="#b22">(Mihalcea and Tarau, 2004;</ref><ref type="bibr" target="#b19">Litvak and Last, 2008;</ref><ref type="bibr" target="#b6">Das Gollapalli and Caragea, 2014)</ref>, part-of-speech features <ref type="bibr" target="#b2">(Barker and Cornacchia, 2000;</ref><ref type="bibr" target="#b15">Hulth, 2003)</ref>, or more sophisticated metrics <ref type="bibr" target="#b31">(Tomokiyo and Hurst, 2003)</ref>.</p><p>However, as we note above, these statistical ap- proaches largely ignore the underlying tensions in scientific communication that lead to the creation of new keyphrases and how they are signaled to others. The result is that these techniques often find statistically "anomalous" phrases which often are not valid scientific concepts (but are simply un- common phrasing), are unstructured and discon- nected, and inflexible to size variance (as in the case of fixed length n-grams), and fail to capture extremely rare terminology.</p><p>The idea that abbreviations may be useful for keyphrase extraction has been partially realized. <ref type="bibr" target="#b23">Nguyen et al., (2007)</ref> found that they could pro- duce better keyphrases by extending existing mod- els ( <ref type="bibr">Frank et al., 1999</ref>) to include an acronym in- dicator as a feature. That is, if a candidate phrase had an associated parenthetical acronym associ- ated with it in the text a binary feature would be set. This approach has been implemented by oth- ers ( <ref type="bibr" target="#b3">Bordea and Buitelaar, 2010)</ref>. We propose to expand on this idea by implementing a simple, but effective, solution by performing abbreviation ex- traction to build a hierarchical keyphrase database -a form of open-information extraction ( <ref type="bibr" target="#b8">Etzioni et al., 2008</ref>) on large scientific corpora.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Keyphrases and Hierarchies</head><p>Our high level strategy for finding an initial set of keyphrases is to mine a corpus for abbrevia-tion expansions. This is a simple strategy, but as we show below, highly effective. Though the idea that abbreviations and keyphrases are linked fits within our understanding of scientific writing, we confirmed our intuition through a small exper- iment. Specifically, we looked at the 85 unique keyphrases (in this case, article titles) listed in the Wikipedia entry for List of Machine Learning Concepts <ref type="bibr" target="#b32">(Wikipedia, 2014</ref>). These ranged from well known terms (e.g., Support Vector Machines and Autoencoders) to less known (e.g., Informa- tion fuzzy networks). In all 85 cases we were able to find an abbreviation on the Web (using Google) alongside the expansion (e.g., searching for the phrases "Support Vector Machines (SVMs)" or "Information Fuzzy Networks (IFN)"). Though there may be bias in the use of abbreviations in the Machine Learning literature, our experience has been that this holds in other domains as well. When a scientific keyphrase is used often enough, someone, somewhere, will have abbreviated it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Abbreviation Extraction</head><p>To find all abbreviation expansions we use the un- supervised SaRAD algorithm <ref type="bibr" target="#b0">(Adar, 2004</ref>). This algorithm is simple to implement, does not re- quire extremely large amounts of data, works for both acronyms and more general abbreviations, and has been demonstrated as effective in various contexts <ref type="bibr" target="#b0">(Adar, 2004;</ref><ref type="bibr" target="#b29">Schwartz and Hearst, 2003)</ref>. However, our solution does not depend on a spe- cific implementation, only that we are able to ac- curately identify abbreviation expansions.</p><p>Adar <ref type="formula">(2004)</ref> presents the full details for the al- gorithm, but for completeness we present the high level details. The algorithm progresses by identi- fying abbreviations inside of parentheses (defined as single words with at least one capital letter). The algorithm then extracts a "window" of text preceding the parenthesis, up to n words long (where n is the character length of the abbrevia- tion plus padding). This window does not cross sentence boundaries. Within the window all possi- ble "explanations" of the abbreviation are derived.</p><p>An explanation consists of a continuous sub- sequence of words that contain all the characters of the original abbreviation in order. For example, the window "determine the geographical distribu- tion of ribonucleic acid" preceding the abbrevia- tion "RNA" includes the explanations: "determine the geographical," "graphical distribution of ri- bonucleic acid" and "ribonucleic acid" (matching characters in italics). In the example above there are ten explanations (five unique). Each explana- tion is scored heuristically: 1 point for each ab- breviation character at the start of a word; 1 point subtracted for every word between the explanation and the parenthesis; 1 point bonus if the explana- tion is adjacent to the parenthesis; 1 point sub- tracted for each extra word beyond the abbrevia- tion length. For the explanations above, the scores are −4, 0, and 3 respectively. The highest scor- ing match (we require a minimum of 1 point) is returned as the mostly likely expansion.</p><p>In practice, pairs of extracted abbrevia- tions/expansions are pulled from a large textual corpus. This both allows us to identify vari- ants of expansions (e.g., different pluralization, spelling, hyphenation, etc.) as well as finding more plausible expansions (those that are repeated multiple times in a corpus). Thus, each ex- pansion/abbreviation pair has an associated count which can be used to threshold and filter for in- creased quality. To discard units of measurement, single letter abbreviations and single word expan- sions are removed. We return to this decision later, but our experience is also that single word keyphrases are rare. Additionally, expansions con- taining brackets are not considered as they usually represent mathematical formulae.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">The ABBREVCORPUS</head><p>In our experiments we utilize the ACM Digital Li- brary (ACMDL) as our main corpus. Though the ACMDL is more limited than other collections, it has a number of desirable properties: spanning nearly the entire history ) of a domain (Computer Science) with full-text and clean meta- data. The corpus itself contains both journal and conference articles <ref type="bibr">(77k and 197k, respectively)</ref>.</p><p>In addition to the filtering rules described above, we manually constructed a set of fil- ter terms to remove publication venues, agen- cies, and other institutions: 'university', 'confer- ence', 'symposium', 'journal', 'foundation', 'con- sortium', 'agency', 'institute' and 'school' are dis- carded. We further normalize our keyphrases by lowercasing, removing hyphens, and using the Snowball stemmer <ref type="bibr" target="#b28">(Porter, 2001</ref>) to merge plu- ral variants. After stemming and normalizing, we found a total of 155,957 unique abbreviation ex- pansions. Among these, 48,890 expansions occur more than once, 25,107 expansions thrice or more and 16,916 expansions four or more times. We re- fer to this collection as the ABBREVCORPUS.</p><p>For each keyphrase we search within the full- text corpus to identify set of documents containing the keyphrase. This allowed us to find both the earliest mention of the keyphrase (the expansion, not the abbreviation) as well as overall popularity of keyphrases. We do not argue that abbreviations are the norm in the introduction of new keyphrases and may, in fact, only happen much later when the domain is familiar enough with the phrase.</p><p>To find the expansions in the full-text we uti- lize a modified suffix-tree that greedily finds the longest-matching phrase and avoids "double- counting". For example, if the text contains the phrase, ". . . we utilize a Least-Squares Sup- port Vector Machine for . . . " it will match against Least-Squares Support Vector Machine but not Least Squares, Support Vector Machines, or Support Vector (also keyphrases in our collec- tion). The distribution of keyphrase frequency is a power-law (many keyphrases appearing once with a long tail) with exponent (α) of 2.17 (fit using Clauset et al., <ref type="formula">(2009)</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Building Keyphrase Hierarchies</head><p>We employ a very simple method of text con- tainment to build keyphrase hierarchies from AB- BREVCORPUS. If a keyphrase A is a substring of keyphrase B, A is said to be contained by B (B → A). If a third keyphrase, C, contains B and is contained by A, the containment link between A and B is dropped and two new ones (A → C and C → B) are added. For example for the keyphrases, circuit switching, optical circuit switching and dynamic optical circuit switching, there are links from optical circuit switching to cir- cuit switching, and dynamic optical circuit switch- ing to optical circuit switching, but there is no link from dynamic optical circuit switching to circuit switching. The hierarchies formed in this manner are mostly trees, but in rare cases a keyphrase can have links to multiple branches. Example hierar- chies are displayed in <ref type="figure">Figure 1</ref>.</p><p>For efficiency we sort all keyphrases by length (from largest to shortest) and iterate over each one, testing for containment in all previously "seen" keyphrases. This is computationally intensive, O(n 2 ), but can be parallelized.</p><p>A potential issue with string containment is that negating prefixes can also appear (e.g., non- monotonic reasoning and monotonic reasoning). Our algorithm uses a dictionary of negations and can annotate the results. However, in practice we find that only .6% of our data has a leading negating-prefix ("internal" negating prefixes can also be caught in this way, but are similarly rare). It is an application-specific question if we want to consider such pairs as "siblings" or "parent-child" (with both supported).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Overlap with Keyphrase Corpora</head><p>To test our newly-constructed keyphrase database we generate a mixture of human-and machine- built datasets to compare. Our goal is to char- acterize both the intersection (keyphrases appear- ing in our corpus as well as the external datasets) as well as those keyphrases uniquely captured by each dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">ACM Author keyphrases (ACMCORPUS)</head><p>The metadata for articles in ACM corpus contain author-provided keyphrases. In the corpus de- scribed above, we found 145,373 unique author- provided keyphrases after stemming and normal- ization. We discard 16,418 single-word keywords and those that do not appear in the full-text of any document. We retain 116,246 keyphrases which we refer to as the ACMCORPUS. within the ACM full-text.</p><formula xml:id="formula_0">ACMCORPUS WIKICORPUS MSRACORPUS MESHCORPUS M E S H C O R P U S W IK IC O R P U S M S R A C O R P U S A C M C O R P U S</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Microsoft Academic (MSRACORPUS)</head><p>Our second keyphrase dataset comes from the Mi- crosoft Academic (MSRA) search corpus <ref type="bibr" target="#b21">(Microsoft, 2015)</ref>. While particularly focused on fault tolerance <ref type="bibr">(1969)</ref> fault tolerance index <ref type="formula">(2006)</ref> software fault tolerance <ref type="bibr">(1973)</ref> algorithm based fault tolerance <ref type="bibr">(1984)</ref> partial fault tolerance <ref type="bibr">(1975)</ref> byzantine fault tolerance (1991) practical byzantine fault tolerance <ref type="formula">(2000)</ref> geographic information <ref type="bibr">(1973)</ref> volunteered geographic information <ref type="bibr">(2008)</ref> geographic information network <ref type="formula">(2011)</ref> geographic information science (1996) geographic information science and technology <ref type="formula">(2010)</ref> geographic information services <ref type="formula">(2000)</ref> geographic information system <ref type="bibr">(1975)</ref> geographic information retrieval <ref type="bibr">(1976)</ref> geographic information systems and science <ref type="bibr">(2003)</ref> Figure 1: Keyphrase hierarchy for Fault Tolerance (top) and Geographic Information (Bottom). Colors encode earliest appearance (brighter green is earlier)</p><p>Computer Science, this collection contains arti- cles and keyphrases from over a dozen domains 2 . MSRA provides a list of keyphrases with unique IDs and different stemming variations of each keyphrase. There are a total of 46,978 (without counting stemming variations) of which 30,477 keyphrases occur in ACM full-text corpus after stemming and normalization (64% coverage).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">MeSH (MESHCORPUS)</head><p>Medical Subject Headings (MeSH) <ref type="bibr" target="#b18">(Lipscomb, 2000</ref>) is set of subject headings or descriptors in the life sciences domain. For the purpose of our work, we use the 27,149 keyphrases from the 2014 MeSH dataset. Similar to the other keyphrase lists we only use stemmed and normalized multi-word keywords that occur in in the ACM full-text cor- pus, which is 4,363 in case of MeSH.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Wikipedia (WIKICORPUS)</head><p>Scientific article headings in Wikipedia can often be used as a proxy for keyphrases. To collect rele- vant titles, we find Wikipedia articles that exactly match (in title name) existing MeSH and MSRA keyphrases. For these "seed" articles, we com- pile their categories and mark all the articles in these categories as potentially "relevant." How- ever, as this also captures scientist names (e.g., a researcher's page may be placed under the "Com- puter Science" category), research institutes and other non-keyphrase matches, we use the page's infobox as a further filter. Pages containing "per- son," "place," infoboxes, in "book," "video game," "TV show" or other related "media" category, and those with geographical coordinates are removed. After applying these filters, we obtain 110,102 unique article titles (after stemming) which we treat as keyphrases. Of these, 39,974 occur in the ACM full-text corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Results</head><p>The total overlap for ACMCORPUS, MESH- CORPUS, MSRACORPUS and WIKICORPUS are 14.12%, 12.28%, 32.33% and 17.41% respec- tively. While these numbers seem low, it is worth noting that many of these terms only appear once in the ACM full-text corpus (see <ref type="figure" target="#fig_0">Figure 2)</ref>. <ref type="figure" target="#fig_1">Figure 3</ref> illustrates the relationship between the number of times a keyphrase appears in the full-text and the probability that it will appear in ABBREVCORPUS. In all cases, the more of- ten a keyphrase appears in the corpus, the more likely it is to have an abbreviation. If we quali- tatively examine popular phrases that do not ap- pear in ABBREVCORPUS we find mathematical forms (e.g., of-the-form, well-defined or a priori), and nouns/entities that are largely unrelated to sci- entific keyphrases (e.g., New Jersey, Government Agency, and Private Sector). More importantly, the majority of phrases that are never abbreviated are simply not Computer Science keyphrases (we return to this in Section 4.6).</p><p>We were somewhat surprised by the poor over- lap of the ACMCORPUS, even for terms that were very common in the full-text. We found that the cause was a large set of "bad" keyphrases. Specif- ically, 69.3k (69.5%) of author-defined keyphrases (occurring in ACMCORPUS but not in AB- BREVCORPUS) are used as a keyword in only one paper. However, they appear more than once in the full-text -often many times. For example, one author (and only one) used if and only if as a keyphrase, which matched a great many articles. The result is that there is little correlation between the number of times a keyphrase appears in the full-text and how many times it used explicitly as a keyphrase in the document metadata. Because these will never be found as an abbreviation, they "pull" the mean probability down.</p><p>Instead of counting the number of times a keyphrase occurs in the full-text we generate a fre- quency count based on the number of times au- thors explicitly use it in the metadata. This new curve, labeled as ACMCORPUS (KEY) in <ref type="figure" target="#fig_1">Figure 3</ref> displays a very different tendency, with a rapid upward slope that peaks at 100% for frequently- occurring keyphrases. Notably, only 16k (16%) keyphrases appear once in full-text but are never abbreviated (far fewer than the 69.5% above).</p><p>It is worth briefly considering those terms that appear in ABBREVCORPUS and not in the other keyphrases lists. We find roughly <ref type="bibr">17.6k, 24.7k, 19.4k, and 21.4k</ref> terms that appear in AB- BREVCORPUS (with a threshold of 2 to elimi- nate "noisy" expansions), but not in ACMCOR- PUS, MESHCORPUS, MSRACORPUS, and WI- KICORPUS respectively. As MeSH keyphrases tend to be focused on the biological keyphrases this is perhaps unsurprising but the high numbers for the author-provided ACM keyphrases is unex- pected. We find that some of the keyphrases that are in ABBREVCORPUS but not in ACMCORPUS are highly specific (e.g., Multi-object Evolutionary Algorithm Based on Decomposition or Stochastic Variable Graph Model). However, many are also extremely generic terms that one would expect to find in a computer science corpus: Run-Time Er- ror Detection, Parallel Execution Tree, and Little Endian. Our hypothesis is that these are often not the focus of a paper and are unlikely to be selected by the author. We believe this provides further evi- dence of the viability of the abbreviation approach to generating good keyphrase lists.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Domain keyphrases</head><p>When looking at keyphrases that appear in MESH- CORPUS but not in the ABBREVCORPUS we find that many phrases do, in fact, appear in the full text but are never abbreviated. For example, Color Perception and Blood Cell both appear in ACM articles but are not abbreviated. Our hypothesis- which is motivated by the tendency of scientists to abbreviate terms that are deeply familiar to their community <ref type="bibr" target="#b13">(Grange and Bloom, 2000</ref>)-is that terms that are possibly distant from the core do- main focus tend not to be abbreviated. This is sup- ported by the fact that these terms are abbreviated in other collections (e.g., one can find CP as an ab- breviation for Color Perception in psychology and cognition work and BC, for Blood Cell, in medi- cal and biological journals). Additional evidence is apparent in <ref type="figure" target="#fig_1">Figure 3</ref> which shows that ACM- CORPUS keyphrases are more likely to be abbre- viated (with far fewer repeats necessary). MSRA- CORPUS, which contains many Computer Science articles, also has higher probabilities (though not nearly matching the ACM).</p><p>To test this systematically, we calculated se- mantic similarity between each keyphrase in the WikiCorpus dataset to "computer science." Specifically, we utilize Explicit Semantic Anal- ysis ( <ref type="bibr" target="#b11">Gabrilovich and Markovitch, 2009</ref>) to cal- culate similarity. In this method, every segment of text is represented in a very high dimensional space in terms of keyphrases (based on Wikipedia categories). The similarity score for each term is between 0 (unrelated) and 1 (very similar). <ref type="figure">Figure 4</ref> demonstrates that with increasing sim- ilarity, the likelihood of abbreviation increases. From this, one may infer that to generate a domain-specific database that excludes unrelated keyphrases, the abbreviation-derived corpus is highly appropriate. Conversely, to get coverage of keyphrases from all scientific domains it is insuffi- cient to mine for abbreviations in one specific do- main's text. Even though a keyphrase may appear in the full-text it will simply never be abbreviated. <ref type="figure">Figure 4</ref>: Probability of a keyphrase appearing in ABBREVCORPUS (y-axis) based on semantic sim- ilarity of the keyphrase to "Computer Science" (x- axis, binned exponentially for readability).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Keyphrase Hierarchies</head><p>Our hierarchy generation process (see Section 3.2) generated 1716 hierarchies accounting for 8661 unique keyphrases. Most of the hierarchies (1002 or 58%) only contained two nodes (a root and one child). The degree distribution, aggregated across all hierarchies, is again power-law (α = 2.895). Hierarchy sizes are power-law distributed (α = 2.807) and an average "diameter" (max height) of 1.135. The hierarchies contain a giant component with 2302 nodes and 2436 edges.</p><p>While most of our hierarchies are trees, keyphrases can connect to two independent branches. For example, Least-Squares Support Vector Machines (LS-SVMs) appears in both the Least Squares and Support Vector hierarchies. In total, 649 keyphrases appear in multiple hi- erarchies, the majority appearing 2. Only 17 keyphrases appear in 3 hierarchies. For exam- ple, the particularly long Single Instruction Mul- tiple Thread Evolution Strategy Pattern Search appears in the Evolution(ary) Strategy, Pattern Search, and Single-Instruction-Multiple-Thread hierarchies. These collisions are interesting in that they reflect a mash-ups of different concepts, and by extension, different sub-disciplines or tech- niques. In some situations, where there is an overlap in many sub-keyphrases, this may indicate that two root keyphrases are in fact equivalent or highly related (e.g., likelihood ratio and log likeli- hood). We do not currently handle such ambiguity in SCHBASE.</p><p>To test the semantic interpretation of edges as EXTENDS/ISSUBTYPEOF we randomly sampled 200 edges and manually checked these. We found that in 92% (184) this interpretation was cor- rect. The remaining 16 were largely an artifact of normalization errors rather than a wrong "type" (e.g., "session identifier" and "session id" where clearly a more accurate interpretation is ISEXPAN- SIONOF). We believe it is fair to say that the hier- archies we construct are the "skeleton" of a full EXTENDS hierarchy but one that is nonetheless fairly encompassing. Our qualitative analysis is that most keyphrases that share a type also share a root keyphrase (e.g., "classifier").</p><p>It is interesting to consider if edges which are derived by "containment" reflect a temporal pat- tern. That is, if keyphrase A EXTENDS B, does the first mention of A in the literature happen af- ter B? We find that this is almost always the case. Among the 7136 edges generated by our algorithm only 165 (2.3%) are "reversed." Qualitatively, we find that these instances appear either due to miss- ing data (the parent keyphrase first appeared out- side the ACM) or publication ordering (in some cases the difference in first-appearance is only a year). In most situations the date is only 1-2 years apart. This high degree of consistency lends fur- ther support to the tendency of scientists to expand upon keyphrases over time. <ref type="figure" target="#fig_2">Figure 5</ref> depicts the mean change in length of "children" in keyphrase hierarchies. The numbers depicted are relative change. Thus, at year "0", the year the root keyphrase is introduced, there is no relative increase. Within 1 year, new children of that root are 50% larger in character length and after that children continue to "grow" as authors add additional keyphrases. A particularly obvious example of this is the branch for Petri Net (PN) which was extended as Queueing Petri Net (QPN) and then Hierarchically Combined Queueing Petri Nets (HCQPN) and finally Extended Hierarchi- cally Combined Queueing Petri Nets (EHCQPN). Notably, this may have implications to other ex- tractors that assume fixed-sized entities over the history of the collection. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion and Future Work</head><p>Our decision to eliminate single-word keyphrases from consideration is an explicit one. Of the 145k keyphrases in the original ACMCORPUS (pre-filtering), 16,418 (11.29%) were single-word keyphrases. Our experience with the ACM author- defined keyphrases is that such terms are too generic to be useful as "scientific" keyphrases. For example, In all the ACM proceedings, the top- 5 most common single-word keyphrases are se- curity, visualization, evaluation, design, and pri- vacy. Even in specific sub-domains, such as rec- ommender systems (Proceedings of Recsys), the most popular single-word keyphrases are person- alization, recommendation, evaluation, and trust. Contrast these to the most popular multi-word terms: recommender system(s), collaborative fil- tering, matrix factorization, and social network(s).</p><p>Notably, in the MSRA corpus, which is algo- rithmically filtered, only .46% (226 keyphrases) were single word. MeSH, in contrast, has a full 37% of keyphrases as single-term. In most sit- uations these reflect chemical names (e.g., 382 single-word enzymes) or biological structures. In such a domain, and if these keyphrases are desir- able, it may be advisable to retain single-word ab- breviations. While it may seem surprising, even single words are often abbreviated (e.g., Transal- dolase is "T" and Ultrafiltration is "U" or "U/F").</p><p>A second key observation is that while the ACM full-text corpus is large, it is by no means "big." We selected to use it because it controlled and "clean." However, we have also run our al- gorithms on the MSRA Corpus (which contains only abstracts) and CiteSeer (which contains full- text). Because the corpora contain more text we find significantly higher overlap with the differ- ent keyphrase corpora. However, this comes at the cost of not being able to isolate the domain- specific keyphrases. To put it differently, the broader full-text collections enable to us gener- ate a more fleshed out keyphrase hierarchies that tracks keyphrases across all domains but which may not be appropriate for certain workloads.</p><p>Finally, it is worth considering the possibility of building hierarchies (and connecting them) by relations other than "containment." We have be- gun to utilize metrics such as co-occurrence of keyphrases (e.g., PMI) as well as higher level cita- tion and co-citation structure in the corpora. Thus, we are able to connect terms that are highly related but are textually dissimilar. When experimenting with PMI, for example, we have found a diverse set of edge types including ISUSEDFOR (e.g., "n- gram language model" and "machine translation") or ISUSEDIN (e.g., "Expectation Maximization" and "Baum-Welch" or "euclidean algorithm" and "k-means"). By necessity, edges generated by this technique require an additional classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Summary</head><p>We have introduced SCHBASE, a simple, robust, and highly effective system and database of sci- entific concepts/keyphrases. By leveraging the incentive structure of scientists to expand exist- ing ideas while simultaneously signaling novelty we are able to construct semantically-meaningful hierarchies of related keyphrases. The further tendency by authors to succinctly describe new keyphrases results in a general habit of utilizing abbreviations. We have demonstrated a mecha- nism to identify these keyphrases by extracting ab- breviation expansions and have shown that these keyphrases cover the bulk of "useful" keyphrases within the domain of the corpus. We believe that SCHBASE will enable a number of appli- cations ranging from search, categorization, and analysis of scientific communication patterns.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Keyphrase counts for the ACMCORPUS (powerlaw α = 2.36), WIKICORPUS (2.49), MSRACORPUS (2.55) and MESHCORPUS (2.7) within the ACM full-text.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The probability of inclusion of keyphrases in ABBREVCORPUS based on frequency of appearance in full text or, in the case if ACMCORPUS (KEY), frequency of use as a keyword. At frequency x, the y value represents probability of appearence in ABBREVCORPUS if we only consider terms that appear at least x times in the other corpus.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Average increase in character length of sub-keyphrases over time</figDesc></figure>

			<note place="foot" n="2"> We know these keyphrases are algorithmically derived, but the details are not disclosed.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors thank the Microsoft Academic team, Jaime Teevan, Susan Dumais, and Carl Lagoze for providing us with data and advice. This work is supported by the Intelligence Advanced Research Projects Activity (IARPA) via Department of In-terior National Business Center contract number D11PC20155. The U.S. government is authorized to reproduce and distribute reprints for Govern-mental purposes notwithstanding any copyright annotation thereon. Disclaimer: The views and conclusions contained herein are those of the au-thors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of IARPA, DoI/NBC, or the U.S. Government.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">SaRAD: a simple and robust abbreviation dictionary</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eytan</forename><surname>Adar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="527" to="533" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Using terminological feedback for web search refinement: A log-based study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Anick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Informaion Retrieval, SIGIR &apos;03</title>
		<meeting>the 26th Annual International ACM SIGIR Conference on Research and Development in Informaion Retrieval, SIGIR &apos;03<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="88" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Using noun phrase heads to extract document keyphrases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ken</forename><surname>Barker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nadia</forename><surname>Cornacchia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Artificial Intelligence</title>
		<editor>Howard J. Hamilton</editor>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2000" />
			<biblScope unit="volume">1822</biblScope>
			<biblScope unit="page" from="40" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deriunlp: A context based approach to automatic keyphrase extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgeta</forename><surname>Bordea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Buitelaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th international workshop on semantic evaluation</title>
		<meeting>the 5th international workshop on semantic evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="146" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">What&apos;s in a name? another unexplained acronym!</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Tsung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Cardiology</title>
		<imprint>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="291" to="292" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Power-law distributions in empirical data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Clauset</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cosma</forename><forename type="middle">Rohilla</forename><surname>Shalizi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Review</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="661" to="703" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Extracting keyphrases from research papers using citation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Das</forename><surname>Sujatha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cornelia</forename><surname>Gollapalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Caragea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Twenty-Eighth AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">New methods in automatic extracting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Harold P Edmundson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="264" to="285" />
			<date type="published" when="1969-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Open information extraction from the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michele</forename><surname>Banko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="68" to="74" />
			<date type="published" when="2008-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Submorphemic elements in the formation of acronyms, blends and clippings 147</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ingrid</forename><surname>Fandrych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lexis</title>
		<imprint>
			<biblScope unit="page">105</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Nevill-Manning. 1999. Domain-specific keyphrase extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eibe</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gordon</forename><forename type="middle">W</forename><surname>Paynter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Gutwin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Craig</forename><forename type="middle">G</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 16th International Joint Conference on Artificial Intelligence<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="668" to="673" />
		</imprint>
	</monogr>
	<note>IJCAI&apos;99</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Wikipedia-based semantic interpretation for natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaul</forename><surname>Markovitch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="443" to="498" />
			<date type="published" when="2009-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Keywords given by authors of scientific articles in database descriptors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isidoro</forename><surname>Gil-Leiva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adolfo</forename><surname>Alonso-Arroyo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Society for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1175" to="1187" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Acronyms, abbreviations and initialisms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bob</forename><surname>Grange</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Bloom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BJU International</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="6" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">How useful are &apos;key words&apos; in scientific journals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hartley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ronald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kostoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Information Science</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="433" to="438" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Improved automatic keyword extraction given more linguistic knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anette</forename><surname>Hulth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;03</title>
		<meeting>the 2003 Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;03<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="216" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Acronyms observed. Professional Communication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Ibrahim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="27" to="28" />
			<date type="published" when="1989-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Semeval-2010 task 5: Automatic keyphrase extraction from scientific articles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olena</forename><surname>Su Nam Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min-Yen</forename><surname>Medelyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Workshop on Semantic Evaluation</title>
		<meeting>the 5th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="21" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Medical subject headings (mesh)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Carolyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lipscomb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bull Med Libr Assoc</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">265266</biblScope>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Graph-based keyword extraction for single-document summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marina</forename><surname>Litvak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Last</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Multisource Multilingual Information Extraction and Summarization, MMIES &apos;08</title>
		<meeting>the Workshop on Multisource Multilingual Information Extraction and Summarization, MMIES &apos;08<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="17" to="24" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Human-competitive tagging using automatic keyphrase extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eibe</forename><surname>Olena Medelyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">H</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Witten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2009 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1318" to="1327" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Microsoft academic search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Microsoft</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Textrank: Bringing order into texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Tarau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2004</title>
		<editor>Dekang Lin and Dekai Wu</editor>
		<meeting>EMNLP 2004<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004-07" />
			<biblScope unit="page" from="404" to="411" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thuydung</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min-Yen</forename><surname>Kan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Keyphrase extraction in scientific publications</title>
	</analytic>
	<monogr>
		<title level="m">Asian Digital Libraries. Looking Back 10 Years and Forging New Frontiers</title>
		<editor>Dion Hoe-Lian Goh, Tru Hoang Cao, Ingeborg Torvik Sølvberg, and Edie Rasmussen</editor>
		<imprint>
			<biblScope unit="volume">4822</biblScope>
			<biblScope unit="page" from="317" to="326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heidelberg</forename><surname>Springer Berlin</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Trends in research foci in life science fields over the last 30 years monitored by emerging topics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ryosuke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aiko</forename><surname>Ohniwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunio</forename><surname>Hibino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Takeyasu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientometrics</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="111" to="127" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The identification of important concepts in highly structured technical papers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><forename type="middle">D</forename><surname>Paice</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><forename type="middle">A</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;93</title>
		<meeting>the 16th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;93<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1993" />
			<biblScope unit="page" from="69" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Snowball: A language for stemming algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><forename type="middle">F</forename><surname>Porter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A simple algorithm for identifying abbreviation definitions in biomedical text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ariel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marti A</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hearst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page">451462</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Citing for high impact</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">A</forename><surname>Mcfarland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th Annual Joint Conference on Digital Libraries, JCDL &apos;10</title>
		<meeting>the 10th Annual Joint Conference on Digital Libraries, JCDL &apos;10<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="49" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A language model approach to keyphrase extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takashi</forename><surname>Tomokiyo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Hurst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2003 Workshop on Multiword Expressions: Analysis, Acquisition and Treatment</title>
		<meeting>the ACL 2003 Workshop on Multiword Expressions: Analysis, Acquisition and Treatment<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="33" to="40" />
		</imprint>
	</monogr>
	<note>MWE &apos;03. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning algorithms for keyphrase extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Turney</surname></persName>
		</author>
		<ptr target="http://en.wiki-pedia.org/wiki/Listofmachinelearningconcepts" />
	</analytic>
	<monogr>
		<title level="j">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2015" to="2017" />
			<date type="published" when="2000-05" />
		</imprint>
	</monogr>
	<note>Wikipedia: List of machine learning concepts</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Automatically refining the wikipedia infobox ontology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th International Conference on World Wide Web, WWW &apos;08</title>
		<meeting>the 17th International Conference on World Wide Web, WWW &apos;08<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="635" to="644" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
