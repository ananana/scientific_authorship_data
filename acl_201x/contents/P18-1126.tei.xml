<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:35+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Are BLEU and Meaning Representation in Opposition?</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 15-20, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Cífka</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Mathematics and Physics Institute of Formal and Applied Linguistics</orgName>
								<orgName type="institution">Charles University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Mathematics and Physics Institute of Formal and Applied Linguistics</orgName>
								<orgName type="institution">Charles University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Are BLEU and Meaning Representation in Opposition?</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1362" to="1371"/>
							<date type="published">July 15-20, 2018. 2018</date>
						</imprint>
					</monogr>
					<note>1362</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>One of possible ways of obtaining continuous space sentence representations is by training neural machine translation (NMT) systems. The recent attention mechanism however removes the single point in the neural network from which the source sentence representation can be extracted. We propose several variations of the attentive NMT architecture bringing this meeting point back. Empirical evaluation suggests that the better the translation quality, the worse the learned sentence representations serve in a wide range of classification and similarity tasks.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Deep learning has brought the possibility of au- tomatically learning continuous representations of sentences. On the one hand, such representations can be geared towards particular tasks such as classifying the sentence in various aspects (e.g. sentiment, register, question type) or relating the sentence to other sentences (e.g. semantic sim- ilarity, paraphrasing, entailment). On the other hand, we can aim at "universal" sentence repre- sentations, that is representations performing rea- sonably well in a range of such tasks.</p><p>Regardless the evaluation criterion, the repre- sentations can be learned either in an unsuper- vised way (from simple, unannotated texts) or su- pervised, relying on manually constructed training sets of sentences equipped with annotations of the appropriate type. A different approach is to ob- tain sentence representations from training neural machine translation models ( <ref type="bibr" target="#b11">Hill et al., 2016)</ref>.</p><p>Since <ref type="bibr" target="#b11">Hill et al. (2016)</ref>, NMT has seen substan- tial advances in translation quality and it is thus natural to ask how these improvements affect the learned representations.</p><p>One of the key technological changes was the introduction of "attention" ( ), making it even the very central component in the network <ref type="bibr">(Vaswani et al., 2017)</ref>. Attention allows the NMT system to dynamically choose which parts of the source are most important when deciding on the current output token. As a conse- quence, there is no longer a static vector represen- tation of the sentence available in the system.</p><p>In this paper, we remove this limitation by proposing a novel encoder-decoder architecture with a structured fixed-size representation of the input that still allows the decoder to explicitly fo- cus on different parts of the input. In other words, our NMT system has both the capacity to attend to various parts of the input and to produce static representations of input sentences.</p><p>We train this architecture on English-to-German and English-to-Czech translation and evaluate the learned representations of English on a wide range of tasks in order to assess its performance in learn- ing "universal" meaning representations.</p><p>In Section 2, we briefly review recent efforts in obtaining sentence representations. In Section 3, we introduce a number of variants of our novel architecture. Section 4 describes some standard and our own methods for evaluating sentence rep- resentations. Section 5 then provides experimental results: translation and representation quality. The relation between the two is discussed in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>The properties of continuous sentence representa- tions have always been of interest to researchers working on neural machine translation. In the first works on RNN sequence-to-sequence mod- els,  and <ref type="bibr" target="#b24">Sutskever et al. (2014)</ref>  <ref type="table">Compound attention   ATTN  FINAL  FINAL-CTX   *POOL *POOL-CTX ATTN-CTX ATTN-ATTN  Encoder states used  all  final  final  all  all  all  all  Combined using . . .  - - - pooling  pooling  inner att.</ref> inner att. Sent. emb. available <ref type="table" target="#tab_0">Table 1</ref>: Different RNN-based architectures and their properties. Legend: "pooling" -vectors combined by mean or max (AVGPOOL, MAXPOOL); "sent. emb." -sentence embedding, i.e. the fixed-size sentence representation computed by the encoder. "init" -initial decoder state. "ctx" -context vector, i.e. input for the decoder cell. "input for att." -input for the decoder attention.</p><note type="other">Bahdanau et al. Sutskever et al. Cho et al.</note><formula xml:id="formula_0">✗ ✓ ✓ ✓ ✓ ✓ ✓ Dec. attends to enc. states ✓ ✗ ✗ ✗ ✗ ✗ ✗ Dec. attends to sent. emb. ✗ ✗ ✗ ✗ ✗ ✗ ✓ Sent. emb. used in . . . - init init+ctx init init+ctx init+ctx input for att.</formula><p>provided visualizations of the phrase and sentence embedding spaces and observed that they reflect semantic and syntactic structure to some extent. <ref type="bibr" target="#b11">Hill et al. (2016)</ref> perform a systematic evalua- tion of sentence representation in different models, including NMT, by applying them to various sen- tence classification tasks and by relating semantic similarity to closeness in the representation space. <ref type="bibr" target="#b23">Shi et al. (2016)</ref> investigate the syntactic prop- erties of representations learned by NMT systems by predicting sentence-and word-level syntactic labels (e.g. tense, part of speech) and by generat- ing syntax trees from these representations. <ref type="bibr" target="#b20">Schwenk and Douze (2017)</ref> aim to learn language-independent sentence representations using NMT systems with multiple source and tar- get languages. They do not consider the atten- tion mechanism and evaluate primarily by similar- ity scores of the learned representations for similar sentences (within or across languages).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model Architectures</head><p>Our proposed model architectures differ in (a) which encoder states are considered in subse- quent processing, (b) how they are combined, and (c) how they are used in the decoder.  , resp. The last column (ATTN- ATTN) is our main proposed architecture: com- pound attention, described here in Section 3.1.</p><p>In addition to RNN-based models, we experi- ment with the Transformer model, see Section 3.3. </p><formula xml:id="formula_1">s 1 s 2 s 3 s T � + c 3 − → h 1 ← − h 1 − → h 2 ← − h 2 − → h 3 ← − h 3 − → h T ← − h T + α 21 α 22 α 23 α 2T . . . M 2 M 1 M 3 M 4 β 31 β 32 β 33 β 34 = M � = H decoder encoder x 1 x 2 x 3 x T . . .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Compound Attention</head><p>Our compound attention model incorporates atten- tion in both the encoder and the decoder, <ref type="figure" target="#fig_0">Fig. 1</ref>.</p><p>Encoder with inner attention. First, we pro- cess the input sequence x 1 , x 2 , . . . , x T using a bi- directional recurrent network with gated recurrent units (GRU, :</p><formula xml:id="formula_2">− → h t = −−→ GRU(x t , − − → h t−1 ), ← − h t = ←−− GRU(x t , ← − − h t+1 ), h t = [ − → h t , ← − h t ].</formula><p>We denote by u the combined number of units in the two RNNs, i.e. the dimensionality of h t . Next, our goal is to combine the states (h 1 , h 2 , . . . , h T ) = H of the encoder into a vector of fixed dimensionality that represents the entire sentence. Traditional seq2seq models concatenate the final states of both encoder RNNs ( − → h T and ← − h 1 ) to obtain the sentence representation (denoted as FINAL in <ref type="table" target="#tab_0">Table 1</ref>). Another option is to combine all encoder states using the average or maximum over time <ref type="bibr" target="#b3">(Collobert and Weston, 2008;</ref><ref type="bibr" target="#b20">Schwenk and Douze, 2017</ref>) (AVGPOOL and MAXPOOL in <ref type="table" target="#tab_0">Table 1</ref> and following).</p><p>We adopt an alternative approach, which is to use inner attention 1 ( <ref type="bibr" target="#b16">Liu et al., 2016;</ref><ref type="bibr" target="#b13">Li et al., 2016)</ref> to compute several weighted averages of the encoder states ( <ref type="bibr" target="#b15">Lin et al., 2017</ref>). The main moti- vation for incorporating these multiple "views" of the state sequence is that it removes the need for the RNN cell to accumulate the representation of the whole sentence as it processes the input, and therefore it should have more capacity for model- ing local dependencies.</p><p>Specifically, we fix a number r, the number of attention heads, and compute an r ×T matrix A of attention weights α jt , representing the importance of position t in the input for the j th attention head. We then use this matrix to compute r weighted sums of the encoder states, which become the rows of a new matrix M :</p><formula xml:id="formula_3">M = AH.<label>(1)</label></formula><p>A vector representation of the source sentence (the "sentence embedding") can be obtained by flatten- ing the matrix M . In our experiments, we project the encoder states h 1 , h 2 , . . . , h T down to a given dimensionality before applying Eq. (1), so that we can control the size of the representation. Following <ref type="bibr" target="#b15">Lin et al. (2017)</ref>, we compute the at- tention matrix by feeding the encoder states to a two-layer feed-forward network:</p><formula xml:id="formula_4">A = softmax(U tanh(W H � )),<label>(2)</label></formula><p>where W and U are weight matrices of dimen- sions d × u and r × d, respectively (d is the num- ber of hidden units); the softmax function is ap- plied along the second dimension, i.e. across the encoder states.</p><p>Attentive decoder. In vanilla seq2seq models with a fixed-size sentence representation, the de- coder is usually conditioned on this representation via the initial RNN state. We propose to instead leverage the structured sentence embedding by ap- plying attention to its components. This is no dif- ferent from the classical attention mechanism used in NMT ( , except that it acts on this fixed-size representation instead of the se- quence of encoder states.</p><p>In the i th decoding step, the attention mecha- nism computes a distribution {β ij } r j=1 over the r components of the structured representation. This is then used to weight these components to obtain the context vector c i , which in turn is used to up- date the decoder state. Again, we can write this in matrix form as</p><formula xml:id="formula_5">C = BM,<label>(3)</label></formula><p>where</p><formula xml:id="formula_6">B = (β ij ) T � ,r i=1,j=1</formula><p>is the attention matrix and C = (c i , c 2 , . . . , c T � ) are the context vectors.</p><p>Note that by combining Eqs. <ref type="formula" target="#formula_3">(1)</ref> and <ref type="formula" target="#formula_5">(3)</ref>, we get</p><formula xml:id="formula_7">C = (BA)H.<label>(4)</label></formula><p>Hence, the composition of the encoder and de- coder attentions (the "compound attention") de- fines an implicit alignment between the source and the target sequence. From this viewpoint, our model can be regarded as a restriction of the con- ventional attention model. The decoder uses a conditional GRU cell (cGRU att ; <ref type="bibr" target="#b22">Sennrich et al., 2017)</ref>, which consists of two consecutively applied GRU blocks. The first block processes the previous target token y i−1 , while the second block receives the context vec- tor c i and predicts the next target token y i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Constant Context</head><p>Compared to the FINAL model, the compound at- tention architecture described in the previous sec- tion undoubtedly benefits from the fact that the decoder is presented with information from the encoder (i.e. the context vectors c i ) in every de- coding step. To investigate this effect, we include baseline models where we replace all context vec- tors c i with the entire sentence embedding (indi- cated by the suffix "-CTX" in <ref type="table" target="#tab_0">Table 1</ref>). Specifi- cally, we provide either the flattened matrix M (for models with inner attention; ATTN or ATTN-CTX), the final state of the encoder (FINAL-CTX), or the result of mean-or max-pooling (*POOL-CTX) as a constant input to the decoder cell.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Name</head><p>Cl. Train Test <ref type="table" target="#tab_0">Task  Example Input and Label  MR  2  11k</ref> -sentiment (movies) an idealistic love story that brings out the latent 15-year-old romantic in everyone. <ref type="table" target="#tab_1">(+)  CR  2  4k</ref> -product review polarity no way to contact their customer service. <ref type="table" target="#tab_0">(−)  SUBJ  2  10k</ref> -subjectivity a little weak -and it isn't that funny. (subjective) MPQA 2 11k -opinion polarity was hoping (+), breach of the very constitution (−) SST2 2 68k 2k sentiment (movies) contains very few laughs and even less surprises (−) SST5 5 10k 2k sentiment (movies) it's worth taking the kids to. (4) TREC 6 5k 500 question type What was Einstein s IQ? (NUM) MRPC 2 4k 2k semantic equivalence Lawtey is not the first faith-based program in Florida's prison system. / But Lawtey is the first entire prison to take that path. (−) SNLI 3 559k 10k natural language inference Two doctors perform surgery on patient. / Two surgeons are having lunch. (contradiction) SICK-E 3 5k 5k natural language inference A group of people is near the ocean / A crowd of people is near the water (entailment)  <ref type="table">Table 3</ref>: SentEval semantic relatedness tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Transformer with Inner Attention</head><p>The Transformer ( <ref type="bibr">Vaswani et al., 2017</ref>) is a re- cently proposed model based entirely on feed- forward layers and attention. It consists of an en- coder and a decoder, each with 6 layers, consisting of multi-head attention on the previous layer and a position-wise feed-forward network.</p><p>In order to introduce a fixed-size sentence rep- resentation into the model, we modify it by adding inner attention after the last encoder layer. The at- tention in the decoder then operates on the com- ponents of this representation (i.e. the rows of the matrix M ). This variation on the Transformer model corresponds to the ATTN-ATTN column in <ref type="table" target="#tab_0">Table 1</ref> and is therefore denoted TRF-ATTN-ATTN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Representation Evaluation</head><p>Continuous sentence representations can be eval- uated in many ways, see e.g. <ref type="bibr" target="#b12">Kiros et al. (2015)</ref>, <ref type="bibr" target="#b4">Conneau et al. (2017)</ref> or the RepEval workshops. <ref type="bibr">2</ref> We evaluate our learned representations with classification and similarity tasks from SentEval (Section 4.1) and by examining clusters of sen- tence paraphrase representations (Section 4.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">SentEval</head><p>We perform evaluation on 10 classification and 7 similarity tasks using the SentEval 3 (Conneau et al., 2017) evaluation tool. This is a superset of the tasks from <ref type="bibr" target="#b12">Kiros et al. (2015)</ref>. <ref type="table" target="#tab_1">Table 2</ref> describes the classification tasks (num- ber of classes, data size, task type and an example) and <ref type="table">Table 3</ref> lists the similarity tasks. The simi- larity (relatedness) datasets contain pairs of sen- tences labeled with a real-valued similarity score. A given sentence representation model is evalu- ated either by learning to directly predict this score given the respective sentence embeddings ("re- gression"), or by computing the cosine similarity of the embeddings ("similarity") without the need of any training. In both cases, Pearson and Spear- man correlation of the predictions with the gold ratings is reported.</p><p>See <ref type="bibr" target="#b6">Dolan et al. (2004)</ref> for details on MRPC and <ref type="bibr" target="#b11">Hill et al. (2016)</ref> for the remaining tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Paraphrases</head><p>We also evaluate the representation of para- phrases. We use two paraphrase sources for this purpose: COCO and HyTER Networks.</p><p>COCO (Common Objects in Context; <ref type="bibr" target="#b14">Lin et al., 2014</ref>) is an object recognition and image caption- ing dataset, containing 5 captions for each image. We extracted the captions from its validation set to form a set of 5 × 5k = 25k sentences grouped by the source image. The average sentence length is 11 tokens and the vocabulary size is 9k types.</p><p>HyTER Networks (Dreyer and Marcu, 2014) are large finite-state networks representing a sub-set of all possible English translations of 102 Ara- bic and 102 Chinese sentences. The networks were built by manually based on reference sen- tences in Arabic, Chinese and English. Each net- work contains up to hundreds of thousands of pos- sible translations of the given source sentence.</p><note type="other">We randomly generated 500 translations for each source sentence, obtaining a corpus of 102k sen- tences grouped into 204 clusters, each containing 500 paraphrases. The average length of the 102k English sentences is 28 tokens and the vocabulary size is 11k token types.</note><p>For every model, we encode each dataset to ob- tain a set of sentence embeddings with cluster la- bels. We then compute the following metrics:</p><p>Cluster classification accuracy (denoted "Cl"). We remove 1 point (COCO) or half of the points (HyTER) from each cluster, and fit an LDA classifier on the rest. We then compute the accuracy of the classifier on the removed points.</p><p>Nearest-neighbor paraphrase retrieval accu- racy (NN). For each point, we find its nearest neighbor according to cosine or L 2 distance, and count how often the neighbor lies in the same clus- ter as the original point.</p><p>Inverse Davies-Bouldin index (iDB). The Davies-Bouldin index <ref type="bibr" target="#b5">(Davies and Bouldin, 1979)</ref> measures cluster separation. For every pair of clusters, we compute the ratio R ij of their com- bined scatter (average L 2 distance to the centroid) S i + S j and the L 2 distance of their centroids d ij , then average the maximum values for all clusters:</p><formula xml:id="formula_8">R ij = S i + S j d ij<label>(5)</label></formula><formula xml:id="formula_9">DB = 1 N N � i=1 max j� =i R ij<label>(6)</label></formula><p>The lower the DB index, the better the separation.</p><p>To match with the rest of our metrics, we take its inverse: iDB = 1 DB .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Results</head><p>We trained English-to-German and English-to- Czech NMT models using Neural Monkey 4 (Helcl and Libovick´yLibovick´y, 2017a). In the following, we dis- tinguish these models using the code of the target language, i.e. de or cs. The de models were trained on the Multi30K multilingual image caption dataset (Elliott et al., <ref type="bibr">4</ref> https://github.com/ufal/neuralmonkey 2016), extended by Helcl and Libovick´yLibovick´y (2017b), who acquired additional parallel data using back- translation ( <ref type="bibr" target="#b21">Sennrich et al., 2016</ref>) and perplexity- based selection ( <ref type="bibr">Yasuda et al., 2008)</ref>. This ex- tended dataset contains 410k sentence pairs, with the average sentence length of 12 ± 4 tokens in English. We train each model for 20 epochs with the batch size of 32. We truecased the training data as well as all data we evaluate on. For Ger- man, we employed Neural Monkey's reversible pre-processing scheme, which expands contrac- tions and performs morphological segmentation of determiners. We used a vocabulary of at most 30k tokens for each language (no subword units).</p><p>The cs models were trained on CzEng 1.7 (Bo- jar et al., 2016). <ref type="bibr">5</ref> We used byte-pair encoding (BPE) with a vocabulary of 30k sub-word units, shared for both languages. For English, the aver- age sentence length is 15 ± 19 BPE tokens and the original vocabulary size is 1.9M. We performed 1 training epoch with the batch size of 128 on the entire training section (57M sentence pairs).</p><p>The datasets for both de and cs models come with their respective development and test sets of sentence pairs, which we use for the evaluation of translation quality. (We use 1k randomly selected sentence pairs from CzEng 1.7 dtest as a develop- ment set. For evaluation, we use the entire etest.)</p><p>We also evaluate the InferSent model 6 (Con- neau et al., 2017) as pre-trained on the natu- ral language inference (NLI) task. InferSent has been shown to achieve state-of-the-art results on the SentEval tasks. We also include a bag-of- words baseline (GloVe-BOW) obtained by averag- ing GloVe 7 word vectors ( <ref type="bibr" target="#b19">Pennington et al., 2014</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Translation Quality</head><p>We estimate translation quality of the vari- ous models using single-reference case-sensitive BLEU ( <ref type="bibr" target="#b18">Papineni et al., 2002</ref>) as implemented in Neural Monkey (the reference implementation is mteval-v13a.pl from NIST or Moses). <ref type="table" target="#tab_3">Tables 4 and 5</ref> provide the results on the two datasets. The cs dataset is much larger and the training takes much longer. We were thus able to experiment with only a subset of the possible model configurations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Size Heads BLEU dev test <ref type="bibr">de</ref>   <ref type="table">Table 5</ref>: Translation quality of cs models.</p><p>The columns "Size" and "Heads" specify the to- tal size of sentence representation and the number of heads of encoder inner attention.</p><p>In both cases, the best performing is the ATTN Bahdanau et al. model, followed by Transformer (de only) and our ATTN-ATTN (compound atten- tion). The non-attentive FINAL Cho et al. is the worst, except cs-MAXPOOL.</p><p>For 5 selected cs models, we also performed the WMT-style 5-way manual ranking on 200 sen- tence pairs. The annotations are interpreted as simulated pairwise comparisons. For each model, the final score is the number of times the model was judged better than the other model in the pair. Tied pairs are excluded. The results, shown in Ta- ble 5, confirm the automatic evaluation results.</p><p>We also checked the relation between BLEU and the number of heads and representation size. While there are many exceptions, the general ten- dency is that the larger the representation or the more heads, the higher the BLEU score. The Pear- son correlation between BLEU and the number of heads is 0.87 for cs and 0.31 for de.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">SentEval</head><p>Due to the large number of SentEval tasks, we present the results abridged in two different ways: by reporting averages <ref type="table" target="#tab_6">(Table 6)</ref> and by showing only the best models in comparison with other methods ( <ref type="table" target="#tab_8">Table 7)</ref>. The full results can be found in the supplementary material. <ref type="table" target="#tab_6">Table 6</ref> provides averages of the classification and similarity results, along with the results of selected tasks (SNLI, SICK-E). As the baseline for classifications tasks, we assign the most fre- quent class to all test examples. <ref type="bibr">8</ref> The de models are generally worse, most likely due to the higher OOV rate and overall simplicity of the training sentences. On cs, we see a clear pattern that more heads hurt the performance. The de set has more variations to consider but the results are less con- clusive.</p><p>For the similarity results, it is worth noting that cs-ATTN-ATTN performs very well with 1 atten- tion head but fails miserably with more heads. Otherwise, the relation to the number of heads is less clear. <ref type="table" target="#tab_8">Table 7</ref> compares our strongest models with other approaches on all tasks. Besides InferSent and GloVe-BOW, we include SkipThought as evaluated by <ref type="bibr" target="#b4">Conneau et al. (2017)</ref>, and the NMT- based embeddings by <ref type="bibr" target="#b11">Hill et al. (2016)</ref> trained on the English-French WMT15 dataset (this is the best result reported by Hill et al. for NMT).</p><p>We see that the supervised InferSent clearly out- performs all other models in all tasks except for MRPC and TREC. Results by Hill et al. are al- ways lower than our best setups, except MRPC and TREC again. On classification tasks, our mod- els are outperformed even by GloVe-BOW, except for the NLI tasks (SICK-E and SNLI) where cs- FINAL-CTX is better. <ref type="table" target="#tab_6">Table 6</ref> also provides our measurements based on sentence paraphrases. For paraphrase retrieval (NN), we found cosine distance to work better   AvgAcc is the average of all 10 SentEval classification tasks (see <ref type="table" target="#tab_0">Table S1</ref> in supplementary material), AvgSim averages all 7 similarity tasks (see <ref type="table" target="#tab_1">Table S2</ref>). Hy-and CO-stand for HyTER and COCO, respectively. "H." is the number of attention heads. We give the out-of-vocabulary (OOV) rate and the perplexity of a 4-gram language model (LM) trained on the English side of the respective parallel corpus and evaluated on all available data for a given task.   than L 2 distance. We therefore do not list L 2 - based results (except in the supplementary mate- rial). This evaluation seems less stable and discern- ing than the previous two, but we can again con- firm the victory of InferSent followed by our non- attentive cs models. cs and de models are no longer clearly separated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Paraphrase Scores</head><note type="other">Name Size H. SNLI SICK-E AvgAcc AvgSim Hy-Cl Hy-NN Hy-iDB CO-Cl CO-NN CO-iDB InferSent 4096</note><note type="other">-ATTN-ATTN 4000 4 65.2 78.0 71.2 .39 99.54 98.98 0.252 11.52 5.51 0.303 cs-ATTN-ATTN 1000 4 64.6 78.0 70.8 .39 99.26 98.93 0.253 10.84 5.20 0.299 cs-ATTN-ATTN 1000 8 63.2 76.6 70.0 .36 99.41 98.09 0.243 10.24 4.64 0.287 de-MAXPOOL-CTX 600 - 68.0 78.8 67.1 .50 98.42 99.90 0.343 21.54 15.62 0.341 de-ATTN-CTX 1200 12 65.0 77.4 66.7 .52 98.88 99.91 0.347 20.06 16.68 0.348 de-ATTN-CTX 600 8 64.0 75.7 65.8 .51 98.11 99.90 0.348 21.64 17.32 0.349 de-AVGPOOL-CTX 600 - 65.2 77.5 65.6 .48 97.72 99.60 0.312 20.04 14.27 0.337 de-ATTN-CTX 600 12 61.9 76.0 65.5 .50 97.79 99.89 0.360 20.22 16.10 0.344 de-FINAL 600 - 64.7 77.0 65.3 .47 97.01 99.30 0.305 19.88 12.40 0.328 de-ATTN-CTX 600 3 63.3 76.0 65.3 .50 97.81 99.87 0.328 19.74 16.43 0.343 de-ATTN-ATTN 600 1 63.8 76.9 64.8 .50 97.70 99.73 0.352 19.74 16.26 0.340 de-ATTN-ATTN 600 3 61.5 74.7 64.5 .47 97.42 99.75 0.314 17.36 14.35 0.333 de-FINAL-CTX 600 - 62.6 76.2 64.5 .48 96.65 99.70 0.323 17.22 12.84 0.333 de-ATTN-ATTN 1200 6 59.6 72.3 64.3 .41 98.05 99.80 0.289 11.90 10.69 0.327 de-TRF-ATTN-ATTN 600 3 61.4 72.5 63.9 .49 95.79 99.64 0.315 15.76 14.04 0.340 de-ATTN-ATTN 1200 12 58.2 72.5 63.4 .</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Name</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>To assess the relation between the various mea- sures of sentence representations and translation quality as estimated by BLEU, we plot a heatmap of Pearson correlations in <ref type="figure" target="#fig_1">Fig. 2</ref>. As one exam- ple, <ref type="figure" target="#fig_2">Fig. 3</ref> details the cs models' BLEU scores and AvgAcc.</p><p>A good sign is that on the cs dataset, most met- rics of representation are positively correlated (the pairwise Pearson correlation is 0.78 ± 0.32 on av- erage), the outlier being TREC (−0.16 ± 0.16 cor- relation with the other metrics on average)</p><p>On the other hand, most representation metrics correlate with BLEU negatively (−0.57±0.31) on cs. The pattern is less pronounced but still clear also on the de dataset.</p><p>A detailed understanding of what the learned representations contain is difficult. We can only  speculate that if the NMT model has some capabil- ity for following the source sentence superficially, it will use it and spend its capacity on closely matching the target sentences rather than on deriv- ing some representation of meaning which would reflect e.g. semantic similarity. We assume that this can be a direct consequence of NMT being trained for cross entropy: putting the exact word forms in exact positions as the target sentence re- quires. Performing well in single-reference BLEU is not an indication that the system understands the meaning but rather that it can maximize the chance of producing the n-grams required by the reference.</p><p>The negative correlation between the number of attention heads and the representation metrics from <ref type="figure" target="#fig_2">Fig. 3</ref> (−0.81 ± 0.12 for cs and −0.18 ± 0.19 for de, on average) can be partly explained by the following observation. We plotted the induced alignments (e.g. <ref type="figure" target="#fig_3">Fig. 4</ref>) and noticed that the heads tend to "divide" the sentence into segments. While one would hope that the segments correspond to some meaningful units of the sentence (e.g. sub- ject, predicate, object), we failed to find any such interpretation for ATTN-ATTN and for cs models in general. Instead, the heads divide the source sen- tence more or less equidistantly, as documented by <ref type="figure" target="#fig_4">Fig. 5</ref>. Such a multi-headed sentence repre- sentation is then less fit for representing e.g. para- phrases where the subject and object swap their position due to passivization, because their rep- resentations are then accessed by different heads, and thus end up in different parts of the sentence embedding vector.</p><p>For de-ATTN-CTX models, we observed a much  flatter distribution of attention weights for each head and, unlike in the other models, we were of- ten able to identify a head focusing on the main verb. This difference between ATTN-ATTN and some ATTN-CTX models could be explained by the fact that in the former, the decoder is oblivious to the ordering of the heads (because of decoder at- tention), and hence it may not be useful for a given head to look for a specific syntactic or semantic role.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We presented a novel variation of attentive NMT models ( <ref type="bibr">Vaswani et al., 2017</ref>) that again provides a single meeting point with a continuous representation of the source sen- tence. We evaluated these representations with a number of measures reflecting how well the mean- ing of the source sentence is captured. While our proposed "compound attention" leads to translation quality not much worse than the fully attentive model, it generally does not per- form well in the meaning representation. Quite on the contrary, the better the BLEU score, the worse the meaning representation.</p><p>We believe that this observation is important for representation learning where bilingual MT now seems less likely to provide useful data, but per- haps more so for MT itself, where the struggle towards a high single-reference BLEU score (or even worse, cross entropy) leads to systems that refuse to consider the meaning of the sentence.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An illustration of compound attention with 4 attention heads. The figure shows the computations that result in the decoder state s 3 (in addition, each state s i depends on the previous target token y i−1 ). Note that the matrix M is the same for all positions in the output sentence and it can thus serve as the source sentence representation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Pearson correlations. Upper triangle: de models, lower triangle: cs models. Positive values shown in shades of green. For similarity tasks, only the Pearson (not Spearman) coefficient is represented.</figDesc><graphic url="image-1.png" coords="8,105.29,95.56,174.97,174.97" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: BLEU vs. AvgAcc for cs models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Alignment between a source sentence (left) and the output (right) as represented in the ATTN-ATTN model with 8 heads and size of 1000. Each color represents a different head; the stroke width indicates the alignment weight; weights ≤ 0.01 pruned out. (Best viewed in color.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Attention weight by relative position in the source sentence (average over dev set excluding sentences shorter than 8 tokens). Same model as in Fig. 4. Each plot corresponds to one head.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 summarizes</head><label>1</label><figDesc></figDesc><table>all the examined config-
urations of RNN-based models. The first three 
(ATTN, FINAL, FINAL-CTX) correspond roughly to 
the standard sequence-to-sequence models, Bah-
danau et al. (2014), Sutskever et al. (2014) and 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>SentEval classification tasks. Tasks without a test set use 10-fold cross-validation. 

Name 
Train Test Method 
SICK-R 
5k 
5k regression 
STSB 
7k 
1k regression 
STS12 
-
3k cosine similarity 
STS13 
-
2k cosine similarity 
STS14 
-
4k cosine similarity 
STS15 
-
9k cosine similarity 
STS16 
-
9k cosine similarity 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 4 : Translation quality of de models.</head><label>4</label><figDesc></figDesc><table>Model 
Size Heads 
BLEU 
Manual 
dev test &gt; others 
cs-ATTN 
-
-22.8 22.2 
89.1 
cs-ATTN-ATTN 1000 
8 19.1 18.4 
78.8 
cs-ATTN-ATTN 4000 
4 18.4 17.9 
-
cs-ATTN-ATTN 1000 
4 17.5 17.1 
-
cs-ATTN-CTX 1000 
4 16.6 16.1 
58.8 
cs-FINAL-CTX 1000 
-16.1 15.5 
-
cs-ATTN-ATTN 1000 
1 15.3 14.8 
49.1 
cs-FINAL 
1000 
-11.2 10.8 
-
cs-AVGPOOL 1000 
-11.1 10.6 
-
cs-MAXPOOL 1000 
-
5.4 5.4 
3.0 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Abridged SentEval and paraphrase evaluation results. Full results in supplementary material. 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table>Comparison of state-of-the-art SentEval results with our best models and the Glove-BOW base-
line. "H." is the number of attention heads. Reprinted results are marked with  †, others are our measure-
ments. </table></figure>

			<note place="foot" n="1"> Some papers call the same or similar approach selfattention or single-time attention.</note>

			<note place="foot" n="2"> https://repeval2017.github.io/ 3 https://github.com/facebookresearch/ SentEval/</note>

			<note place="foot" n="5"> http://ufal.mff.cuni.cz/czeng/czeng17 6 https://github.com/facebookresearch/ InferSent 7 https://nlp.stanford.edu/projects/ glove/</note>

			<note place="foot" n="8"> For MR, CR, SUBJ, and MPQA, where there is no distinct test set, the class is established on the whole collection. For other tasks, the class is learned from the training set.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>This work has been supported by the grants 18-24210S of the Czech Science Foundation, SVV 260 453 and "Progress" Q18+Q48 of Charles University, and using language resources dis-tributed by the LINDAT/CLARIN project of the Ministry of Education, Youth and Sports of the Czech Republic (projects LM2015071 and OP VVV VI CZ.02.1.01/0.0/0.0/16 013/0001781).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno>abs/1409.0473</idno>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">CzEng 1.6: Enlarged CzechEnglish Parallel Corpus with Processing Tools Dockered</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text, Speech, and Dialogue (TSD), number 9924 in LNAI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="231" to="238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gülçehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Holger Schwenk, and Yoshua Bengio</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A unified architecture for natural language processing: deep neural networks with multitask learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Supervised learning of universal sentence representations from natural language inference data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lo¨ıclo¨ıc</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A cluster separation measure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><forename type="middle">W</forename><surname>Davies</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bouldin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="page" from="1" to="224" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Unsupervised construction of large paraphrase corpora: Exploiting massively parallel news sources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">B</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Quirk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">HyTER networks of selected OpenMT08/09 sentences. Linguistic Data Consortium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Dreyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Multi30k: Multilingual englishgerman image descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Desmond</forename><surname>Elliott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stella</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khalil</forename><surname>Sima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<idno>abs/1605.00459</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Neural Monkey: An open-source tool for sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jindřich</forename><surname>Helcl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jindřich</forename><surname>Libovick´ylibovick´y</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Prague Bulletin of Mathematical Linguistics</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="17" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">CUNI System for the WMT17 Multimodal Traslation Task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jindřich</forename><surname>Helcl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jindřich</forename><surname>Libovick´ylibovick´y</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning distributed representations of sentences from unlabelled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Raquel Urtasun, and Sanja Fidler</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Skip-thought vectors. In NIPS</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="3294" to="3302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Dataset and neural recurrent sequence labeling model for open-domain factoid question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuguang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<idno>abs/1607.06275</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lubomir</forename><forename type="middle">D</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
		<idno>abs/1405.0312</idno>
		<title level="m">Microsoft COCO: common objects in context. CoRR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">A structured self-attentive sentence embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouhan</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minwei</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cícero</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
		<idno>abs/1703.03130</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Learning natural language inference using bidirectional LSTM model and inner-attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengjie</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Corr</surname></persName>
		</author>
		<idno>abs/1605.09090</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">BLEU: a Method for Automatic Evaluation of Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Learning joint multilingual sentence representations with neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<idno>abs/1704.04154</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Improving neural machine translation models with monolingual data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<idno>abs/1511.06709</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Nematus: a toolkit for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EACL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Does string-based neural MT learn source syntax? In EMNLP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inkit</forename><surname>Padhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
