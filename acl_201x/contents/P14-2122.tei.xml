<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:06+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Empirical Study of Unsupervised Chinese Word Segmentation Methods for SMT on Large-scale Corpora</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>June 23-25 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolin</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">National Institute of Information and Communications Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masao</forename><surname>Utiyama</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">National Institute of Information and Communications Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Finch</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">National Institute of Information and Communications Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eiichiro</forename><surname>Sumita</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">National Institute of Information and Communications Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Empirical Study of Unsupervised Chinese Word Segmentation Methods for SMT on Large-scale Corpora</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="752" to="758"/>
							<date type="published">June 23-25 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Unsupervised word segmentation (UWS) can provide domain-adaptive segmenta-tion for statistical machine translation (SMT) without annotated data, and bilingual UWS can even optimize segmenta-tion for alignment. Monolingual UWS approaches of explicitly modeling the probabilities of words through Dirichlet process (DP) models or Pitman-Yor process (PYP) models have achieved high accuracy, but their bilingual counterparts have only been carried out on small corpora such as basic travel expression corpus (BTEC) due to the computational complexity. This paper proposes an efficient unified PYP-based monolingual and bilingual UWS method. Experimental results show that the proposed method is comparable to supervised segmenters on the in-domain NIST OpenMT corpus, and yields a 0.96 BLEU relative increase on NTCIR PatentMT corpus which is out-of-domain.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Many languages, especially Asian languages such as Chinese, Japanese and Myanmar, have no ex- plicit word boundaries, thus word segmentation (WS), that is, segmenting the continuous texts of these languages into isolated words, is a prerequi- site for many natural language processing applica- tions including SMT.</p><p>Though supervised-learning approaches which involve training segmenters on manually seg- mented corpora are widely used ( <ref type="bibr" target="#b2">Chang et al., 2008</ref>), yet the criteria for manually annotat- ing words are arbitrary, and the available anno- tated corpora are limited in both quantity and genre variety. For example, in machine transla- tion, there are various parallel corpora such as BTEC for tourism-related dialogues <ref type="bibr" target="#b17">(Paul, 2008)</ref> and PatentMT in the patent domain <ref type="bibr" target="#b7">(Goto et al., 2011)</ref>  <ref type="bibr">1</ref> , but researchers working on Chinese- related tasks often use the Stanford Chinese seg- menter ( <ref type="bibr" target="#b22">Tseng et al., 2005</ref>) which is trained on a small amount of annotated news text.</p><p>In contrast, UWS, spurred by the findings that infants are able to use statistical cues to determine word boundaries ( <ref type="bibr" target="#b19">Saffran et al., 1996)</ref>, relies on statistical criteria instead of manually crafted stan- dards. UWS learns from unsegmented raw text, which are available in large quantities, and thus it has the potential to provide more accurate and adaptive segmentation than supervised approaches with less development effort being required.</p><p>The approaches of explicitly modeling the probability of words <ref type="bibr" target="#b0">(Brent, 1999;</ref><ref type="bibr" target="#b23">Venkataraman, 2001;</ref><ref type="bibr" target="#b5">Goldwater et al., 2006;</ref><ref type="bibr" target="#b6">Goldwater et al., 2009;</ref><ref type="bibr" target="#b10">Mochihashi et al., 2009</ref>) significantly out- performed a heuristic approach ( <ref type="bibr" target="#b26">Zhao and Kit, 2008)</ref> on the monolingual Chinese SIGHAN-MSR corpus <ref type="bibr" target="#b4">(Emerson, 2005)</ref>, which inspired the work of this paper.</p><p>However, bilingual approaches that model word probabilities suffer from computational complex- ity. <ref type="bibr" target="#b24">Xu et al. (2008)</ref> proposed a bilingual method by adding alignment into the generative model, but was only able to test it on small-scale BTEC data. <ref type="bibr" target="#b13">Nguyen et al. (2010)</ref> used the local best alignment to increase the speed of the Gibbs sampling in training but the impact on accuracy was not ex- plored.</p><p>This paper is dedicated to bilingual UWS on large-scale corpora to support SMT. To this end, we model bilingual UWS under a similar frame- work with monolingual UWS in order to improve efficiency, and replace Gibbs sampling with ex- pectation maximization (EM) in training.</p><p>We aware that variational bayes (VB) may be used for speeding up the training of DP-based or PYP-based bilingual UWS. However, VB re- quires formulating the m expectations of (m − 1)- dimensional marginal distributions, where m is the number of hidden variables. For UWS, the hidden variables are indicators that identify sub- strings of sentences in the corpus as words. These variables are large in number and it is not clear how to apply VB to UWS, and as far the authors aware there is no previous work related to the ap- plication of VB to monolingual UWS. Therefore, we have not explored VB methods in this paper, but we do show that our method is superior to the existing methods.</p><p>The contributions of this paper include,</p><p>• state-of-the-art accuracy in monolingual UWS;</p><p>• the first bilingual UWS method practical for large corpora;</p><p>• improvement of BLEU scores compared to supervised Stanford Chinese word seg- menter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>This section describes our unified monolingual and bilingual UWS scheme. <ref type="table" target="#tab_0">Table 1</ref> lists the main notation. The set F is chosen to represent an un- segmented foreign language sentence (a sequence of characters), because an unsegmented sentence can be seen as the set of all possible segmentations of the sentence denoted F , i.e. F ∈ F.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Notation Meaning</head><formula xml:id="formula_0">F an unsegmented foreign sentence F k ′ k unsegmented substring of the un- derlying string of F from k to k ′ F a segmented foreign sentence f j the j-th foreign word M monolingual segmentation model P M (x)</formula><p>probability of x being a word ac- cording to M E a tokenized English sentence e i the i-th English word (F,E) a bilingual sentence pair B bilingual segmentation model P B (x|e i ) probability of x being a word ac- cording to B given e i Monolingual and bilingual WS can be formu- lated as follows, respectively,</p><formula xml:id="formula_1">ˆ F (F) = argmax F ∈F P (F |F, M),<label>(1)</label></formula><formula xml:id="formula_2">ˆ F (F, E) = argmax F ∈F a P (F, a|F, E, B), (2)</formula><p>where a is an alignment between F and E. The English sentence E is used in the generation of a segmented sentence F . UWS learns models by maximizing the likeli- hood of the unsegmented corpus, formulated as,</p><formula xml:id="formula_3">ˆ M = argmax M F ∈F F ∈F P (F |M) ,<label>(3)</label></formula><formula xml:id="formula_4">ˆ B = argmax B (F ,E)∈B F ∈F a P (F, a|F, E, B) .<label>(4)</label></formula><p>Our method of learning M and B proceeds in a similar manner to the EM algorithm. The follow- ing two operations are performed iteratively for each sentence (pair).</p><p>• Exclude the previous expected counts of the current sentence (pair) from the model, and then derive the current sentence in all pos- sible ways, calculating the new expected counts for the words (see Section 2.1), that is, we calculate the expected probabilities of the F k ′ k being words given the data excluding</p><formula xml:id="formula_5">F, i.e. E F/{F } (P (F k ′ k |F)) = P (F k ′ k |F, M</formula><p>) in a similar manner to the marginalization in the Gibbs sampling process which we are re- placing;</p><p>• Update the respective model M or B accord- ing to these expectations (see Section2.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Expectation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Monolingual Expectation</head><formula xml:id="formula_6">P (F k ′ k |F, M)</formula><p>is the marginal probability of all the possible F ∈ F that contain F k ′ k as a word, which can be calculated efficiently through dy- namic programming (the process is similar to the foreward-backward algorithm in training a hidden Markov model (HMM) <ref type="bibr" target="#b18">(Rabiner, 1989)</ref>):</p><formula xml:id="formula_7">P a (k) = U u=1 P a (k − u)P M (F k k−u ) P b (k ′ ) = U u=1 P b (k ′ + u)P M (F k ′ +u k ′ ) P (F k ′ k |F, M) = P a (k)P M (F k ′ k )P b (k ′ ), (5)</formula><p>where U is the predefined maximum length of for- eign language words, P a (k) and P b (k ′ ) are the forward and backward probabilities, respectively. This section uses a unigram model for description convenience, but the method can be extended to n-gram models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Bilingual Expectation</head><formula xml:id="formula_8">P (F k ′ k |F, E, B)</formula><p>is the marginal probability of all the possible F ∈ F that contain F k ′ k as a word and are aligned with E, formulated as:</p><formula xml:id="formula_9">P (F k ′ k |F, E, B) = F ∈F F k ′ k ∈F a P (F, a|E, B) ≈ F ∈F F j k =F k ′ k a J j=1 P (a j |j, I, J)P B (f j |e a j ) = F ∈F f j k =F k ′ k J j=1 a P (a j |j, I, J)P B (f j |e a j ),<label>(6)</label></formula><p>where J and I are the number of foreign and En- glish words, respectively, and a j is the position of the English word that is aligned to f j in the align- ment a. For the alignment we employ an approx- imation to IBM model 2 ( <ref type="bibr" target="#b1">Brown et al., 1993;</ref><ref type="bibr" target="#b14">Och and Ney, 2003</ref>) described below.</p><p>We define the conditional probability of f j given the corresponding English sentence E and the model B as:</p><formula xml:id="formula_10">P B (f j |E) = a P (a j |j, I, J)P B (f j |e a j ) (7)</formula><p>Then, the previous dynamic programming method can be extended to the bilingual expecta- tion</p><formula xml:id="formula_11">P a (k|E) = U u=1 P a (k − u|E)P B (F k k−u |E) P b (k ′ |E) = U u=1 P b (k ′ + u|E)P B (F k ′ +u k ′ |E) P (F k ′ k |F, E, B) = P a (k|E)P B (F k ′ k |E)P b (k ′ |E).<label>(8)</label></formula><p>Eq. 7 can be rewritten (as in IBM model 2):</p><formula xml:id="formula_12">P B (f j |E) = I i=1 P * (i|j, I, J)P B (f j |e i ) (9) P * (i|j, I, J) = a:a j =i P (a j |, j, I, J)</formula><p>In order to maintain both speed and accuracy, the following window function is adopted</p><formula xml:id="formula_13">P * (i|j, I, J) ≈ P * (i|k, I, K) =    e −|i−kI/K| /σ |i − kI/K| δ b /2 λ φ e i is empty word 0 otherwise (10)</formula><p>where K is the number of characters in F, and the k-th character is the start of the word f j , since j and J are unknown during the computation of dynamic programming. δ b is the window size, λ φ is the prior probability of an empty English word, and σ ensures all the items sum to 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Maximization</head><p>Inspired by <ref type="bibr" target="#b21">(Teh, 2006;</ref><ref type="bibr" target="#b10">Mochihashi et al., 2009;</ref><ref type="bibr" target="#b12">Neubig et al., 2010;</ref><ref type="bibr" target="#b20">Teh and Jordan, 2010)</ref>, we employ a Pitman-Yor process model to build the segmentation model M or B. The monolingual model M is</p><formula xml:id="formula_14">P M (f j ) = max n(f j ) − d, 0 + (θ + d · n M )G 0 (f j ) f ′ j n(f ′ j ) + θ n M = {f j | n(f j ) d} ,<label>(11)</label></formula><p>where f j is a foreign language word, and n(f j ) is the observed counts of f j , θ is named the strength parameter, G 0 (f j ) is named the base distribution of f j , and d is the discount. The bilingual model is</p><formula xml:id="formula_15">P B (f j |e i ) = max n(f j , e i ) − d, 0 + (θ + d · n e i )G 0 (f j |e i ) f ′ j n(f ′ j , e i ) + θ n e i = {x | n(x, e i ) d} .<label>(12)</label></formula><p>In Eqs. 11 and 12,</p><formula xml:id="formula_16">n(f j ) = F ∈F P (f j |F, M)<label>(13)</label></formula><p>n(f j , e i ) =</p><formula xml:id="formula_17">(F ,E)∈B P (f j |F, E, B) P * (i|j, I, J)P B (f j |e i ) I i ′ =1 P * (i ′ |j, I, J)P B (f j |e i ′ ) .<label>(14)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Complexity Analysis</head><p>The computational complexity of our method is linear in the number of iterations, the size of the corpus, and the complexity of calculating the ex- pectations on each sentence or sentence pair. In practical applications, the size of the corpus is fixed, and we found empirically that the number of iterations required by the proposed method for convergence is usually small (less than five itera- tions). We now look in more detail at the complex- ity of the expectation calculation in monolingual and bilingual models.</p><p>The monolingual expectation is calculated ac- cording to Eq. 5; the complexity is linear in the length of sentences and the square of the prede- fined maximum length of words. Thus its overall complexity is</p><formula xml:id="formula_18">O unigram monoling = O(N i |F|KU 2 ),<label>(15)</label></formula><p>where N i is the number of iterations, K is the av- erage number of characters per sentence, and U is the predefined maximum length of words.</p><p>For the monolingual bigram model, the number of states in the HMM is U times more than that of the monolingual unigram model, as the states at specific position of F are not only related to the length of the current word, but also related to the length of the word before it. Thus its complexity is U 2 times the unigram model's complexity:</p><formula xml:id="formula_19">O bigram monoling = O(N i |F|KU 4 ).<label>(16)</label></formula><p>The bilingual expectation is given by Eq. 8, whose complexity is the same as the monolingual case. However, the complexity of calculating the transition probability, in Eqs. 9 and 10, is O(δ b ). Thus its overall complexity is:</p><formula xml:id="formula_20">O unigram biling = O(N i |F|KU 2 δ b ).<label>(17)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, the proposed method is first val- idated on monolingual segmentation tasks, and then evaluated in the context of SMT to study whether the translation quality, measured by BLEU, can be improved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Settings</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Experimental Corpora</head><p>Two monolingual corpora and two bilingual cor- pora are used <ref type="table" target="#tab_2">(Table 2)</ref>. CHILDES <ref type="bibr" target="#b9">(MacWhinney and Snow, 1985)</ref> is the most common test   <ref type="bibr" target="#b15">(Och, 2003)</ref>. This data set mainly consists of news text 3 . PatentMT9 is from the shared task of NTCIR-9 patent machine trans- lation . The training set consists of 1 million par- allel sentences extracted from patent documents, and the development set and test set both consist of 2000 sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Performance Measurement and</head><p>Baseline Methods For the monolingual tasks, the F 1 score against the gold annotation is adopted to measure the ac- curacy. The results reported in related papers are listed for comparison.</p><p>For the bilingual tasks, the publicly available system of Moses ( <ref type="bibr" target="#b8">Koehn et al., 2007</ref>) with default settings is employed to perform machine transla- tion, and BLEU ( <ref type="bibr" target="#b16">Papineni et al., 2002</ref>) was used to evaluate the quality. Character-based segmen- tation, LDC segmenter and Stanford Chinese seg- menters were used as the baseline methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Parameter settings</head><p>The parameters are tuned on held-out data sets. The maximum length of foreign language words is set to 4. For the PYP model, the base distri- bution adopts the formula in <ref type="bibr" target="#b3">(Chung and Gildea, 2009)</ref>, and the strength parameter is set to 1.0, and the discount is set to 1.0 × 10 −6 .</p><p>For bilingual segmentation,the size of the align- ment window is set to 6; the probability λ φ of for- eign language words being generated by an empty  <ref type="figure">(Mochihashi et al.,2009)</ref>; b by <ref type="bibr" target="#b6">(Goldwater et al.,2009)</ref>; c by <ref type="bibr" target="#b26">(Zhao and Kit, 2008)</ref>. <ref type="table">Table 3</ref>: Results on Monolingual Corpora.</p><p>English word, was set to 0.3.</p><p>The training was started from assuming that there was no previous segmentations on each sen- tence (pair), and the number of iterations was fixed. It was set to 3 for the monolingual unigram model, and 2 for the bilingual unigram model, which provided slightly higher BLEU scores on the development set than the other settings. The monolingual bigram model, however, was slower to converge, so we started it from the segmenta- tions of the unigram model, and using 10 itera- tions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Monolingual Segmentation Results</head><p>In monolingual segmentation, the proposed meth- ods with both unigram and bigram models were tested. Experimental results show that they are competitive to state-of-the-art baselines in both ac- curacy and speed ( <ref type="table">Table 3</ref>). Note that the com- parison of speed is only for reference because the times are obtained from their respective papers. <ref type="table" target="#tab_4">Table 4</ref> presents the BLEU scores for Moses using different segmentation methods. Each experiment was performed three times. The proposed method with monolingual bigram model performed poorly on the Chinese monolingual segmentation task; thus, it was not tested. We intended to test <ref type="bibr" target="#b10">(Mochihashi et al., 2009</ref>), but found it impracticable on large-scale corpora.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Bilingual Segmentation Results</head><p>The experimental results show that the proposed UWS methods are comparable to the Stanford seg- menters on the OpenMT06 corpus, while achieves a 0.96 BLEU increase on the PatentMT9 corpus. This is because this corpus is out-of-domain for the supervised segmenters. The CTB and PKU Stanford segmenter were both trained on anno- tated news text, which was the major domain of OpenMT06.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method BLEU OpenMT06</head><p>PatentMT9 Character 29.50 ± 0.03 28.36 ± 0.09 LDC 31.33 ± 0.10 30.22 ± 0.14 Stanford(CTB) 31.68 ± 0.25 30.77 ± 0.13 Stanford(PKU) 31.54 ± 0.13 30.86 ± 0.04 Prop. <ref type="table">(mono.)</ref> 31.47 ± 0.18 31.62 ± 0.06 Prop. <ref type="table">(biling.)</ref> 31.61 ± 0.14 31.73 ± 0.05   <ref type="table" target="#tab_5">Table 5</ref> presents the run times of the proposed methods on the bilingual corpora. The program is single threaded and implemented in C++. The time cost of the bilingual models is about 5 times that of the monolingual model, which is consistent with the complexity analysis in Section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>This paper is devoted to large-scale Chinese UWS for SMT. An efficient unified monolingual and bilingual UWS method is proposed and applied to large-scale bilingual corpora.</p><p>Complexity analysis shows that our method is capable of scaling to large-scale corpora. This was verified by experiments on a corpus of 1-million sentence pairs on which traditional MCMC ap- proaches would struggle ( <ref type="bibr" target="#b24">Xu et al., 2008)</ref>.</p><p>The proposed method does not require any annotated data, but the SMT system with it can achieve comparable performance compared to state-of-the-art supervised word segmenters trained on precious annotated data. Moreover, the proposed method yields 0.96 BLEU improve- ment relative to supervised word segmenters on an out-of-domain corpus. Thus, we believe that the proposed method would benefit SMT related to low-resource languages where annotated data are scare, and would also find application in domains that differ too greatly from the domains on which supervised word segmenters were trained.</p><p>In future research, we plan to improve the bilin- gual UWS through applying VB and integrating more accurate alignment models such as HMM models and IBM model 4.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 : Main Notation.</head><label>1</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 2 : Experimental Corpora</head><label>2</label><figDesc></figDesc><table>corpus for UWS methods. The SIGHAN-MSR 
corpus (Emerson, 2005) consists of manually seg-
mented simplified Chinese news text, released in 
the SIGHAN bakeoff 2005 shared tasks. 
The first bilingual corpus: OpenMT06 was used 
in the NIST open machine translation 2006 Eval-
uation 2 . We removed the United Nations cor-
pus and the traditional Chinese data sets from the 
constraint training resources. The data sets of 
NIST Eval 2002 to 2005 were used as the develop-
ment for MERT tuning </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 : Results on Bilingual Corpora.</head><label>4</label><figDesc></figDesc><table>Method 
Time 
OpenMT06 PatentMT9 
Prop.(mono.) 
28 m 
1 h 01 m 
Prop.(biling.) 
2 h 25 m 
5 h 02 m 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 5 : Time Costs on Bilingual Corpora.</head><label>5</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="1"> http://ntcir.nii.ac.jp/PatentMT</note>

			<note place="foot" n="2"> http://www.itl.nist.gov/iad/mig/ /tests/mt/2006/ 3 It also contains a small number of web blogs</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">An efficient, probabilistically sound algorithm for segmentation and word discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Michael R Brent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="71" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The mathematics of statistical machine translation: parameter estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent J Della</forename><surname>Peter F Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen A Della</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert L</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mercer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="263" to="311" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Optimizing Chinese word segmentation for machine translation performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pi-Chuan</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Workshop on Statistical Machine Translation</title>
		<meeting>the 3rd Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="224" to="232" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Unsupervised tokenization for machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tagyoung</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2009 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="718" to="726" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The second international chinese word segmentation bakeoff</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Emerson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th SIGHAN Workshop on Chinese Language Processing</title>
		<meeting>the 4th SIGHAN Workshop on Chinese Language Processing</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">133</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Contextual dependencies in unsupervised word segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Goldwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="673" to="680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">A Bayesian framework for word segmentation: exploring the effects of context. Cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Goldwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Johnson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page" from="21" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Overview of the patent machine translation task at the NTCIR-9 workshop</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isao</forename><surname>Goto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ka</forename><forename type="middle">Po</forename><surname>Chow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eiichiro</forename><surname>Sumita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin K</forename><surname>Tsou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NTCIR</title>
		<meeting>NTCIR</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="559" to="578" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Moses: open source toolkit for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brooke</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wade</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions</title>
		<meeting>the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="177" to="180" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The child language data exchange system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Macwhinney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catherine</forename><surname>Snow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of child language</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="271" to="296" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Bayesian unsupervised word segmentation with nested Pitman-Yor language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daichi</forename><surname>Mochihashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeshi</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naonori</forename><surname>Ueda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th</title>
		<meeting>the Joint Conference of the 47th</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<title level="m">Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="100" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning a language model from continuous speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masato</forename><surname>Mimura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinsuke</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatsuya</forename><surname>Kawahara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">InterSpeech</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1053" to="1056" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Nonparametric word segmentation for machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thuylinh</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Vogel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics</title>
		<meeting>the 23rd International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="815" to="823" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A Systematic Comparison of Various Statistical Alignment Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Franz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="19" to="51" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Minimum error rate training in statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz Josef</forename><surname>Och</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 41st Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="160" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">BLEU: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 40th Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Overview of the IWSLT 2008 evaluation campaign</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Paul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Workshop on Spoken Language Translation</title>
		<meeting>the International Workshop on Spoken Language Translation</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A tutorial on hidden Markov models and selected applications in speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lawrence R Rabiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="257" to="286" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Statistical learning by 8-month-old infants</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jenny R Saffran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elissa</forename><surname>Richard N Aslin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">274</biblScope>
			<biblScope unit="page" from="1926" to="1928" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Hierarchical Bayesian nonparametric models with applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee Whye</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Bayesian Nonparametrics: Principles and Practice</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="158" to="207" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A hierarchical Bayesian language model based on Pitman-Yor processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee Whye</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 21st International Conference on Computational Linguistics and the 44th Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="985" to="992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A conditional random field word segmenter for SIGHAN Bakeoff</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huihsin</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pichuan</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Galen</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th SIGHAN Workshop on Chinese Language Processing</title>
		<meeting>the 4th SIGHAN Workshop on Chinese Language Processing<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">171</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A statistical model for word discovery in transcribed speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anand</forename><surname>Venkataraman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="351" to="372" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Bayesian semi-supervised</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Chinese word segmentation for statistical machine translation</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Computational Linguistics</title>
		<meeting>the 22nd International Conference on Computational Linguistics</meeting>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1017" to="1024" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">An empirical comparison of goodness measures for unsupervised chinese word segmentation with a unified framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyu</forename><surname>Kit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Joint Conference on Natural Language Processing</title>
		<meeting>the 3rd International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
