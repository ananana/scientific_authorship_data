<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:11+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Pushing the Limits of Radiology with Joint Modeling of Visual and Textual Information</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 15-20, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sonit</forename><surname>Singh</surname></persName>
							<email>sonit.singh@hdr.mq.edu.au</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">Macquarie University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">DATA61</orgName>
								<address>
									<country>CSIRO</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<address>
									<settlement>Sydney</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Pushing the Limits of Radiology with Joint Modeling of Visual and Textual Information</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of ACL 2018, Student Research Workshop</title>
						<meeting>ACL 2018, Student Research Workshop <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="28" to="36"/>
							<date type="published">July 15-20, 2018</date>
						</imprint>
					</monogr>
					<note>28</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Recently, there has been increasing interest in the intersection of computer vision and natural language processing. Researchers have studied several interesting tasks, including generating text descriptions from images and videos and language embedding of images. More recent work has further extended the scope of this area to combine videos and language , learning to solve non-visual tasks using visual cues, visual question answering , and visual dialog. Despite a large body of research on the intersection of vision-language technology, its adaption to the medical domain is not fully explored. To address this research gap, we aim to develop machine learning models that can reason jointly on medical images and clinical text for advanced search, retrieval , annotation and description of medical images.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Integrating information from various modalities is deeply rooted in human lives. Humans com- bine vision, language, speech and touch to ac- quire knowledge about the world and comprehend the world ( <ref type="bibr" target="#b12">Hall and McKevitt, 1995)</ref>. Vision and Language are the most common ways of express- ing our knowledge about the world. Both Com- puter Vision (CV) and Natural Language Process- ing (NLP) demonstrated successful results on var- ious general purpose tasks such as image classi- fication, object detection, semantic segmentation, and machine translation. Although research at the intersection of CV and NLP is gaining pace, its applications to healthcare are still under-explored. The success of Artificial Intelligence (AI) tech- nologies in general purpose tasks is mainly at- tributed to publicly available large-scale datasets, enhanced compute power due to rise of Graph- ics Processing Units (GPUs), and due to advance- ments in Machine Learning (ML) algorithms and its various architectures. One of the biggest hur- dles in deploying ML (especially Deep Learning) models in healthcare is a lack of annotated data. Although it is easy to get annotated data for gen- eral purpose tasks by crowdsourcing, it is almost impossible for medical data because of limited ex- pertise, privacy and ethical issues. On the pos- itive side, a lot of medical data in the form of medical images and accompanying text reports is stored in hospitals' Picture Archival and Commu- nication Systems (PACS). For instance, Beth Is- rael Deaconnes Medical Center (Harvard) gener- ates approximately 20 terabytes of image data and one terabyte of text data per year <ref type="bibr" target="#b24">(Mastanduno, 2017)</ref>. Also, the drive toward structured reporting in radiology definitely enhance NLP accuracy <ref type="bibr" target="#b7">(Cai et al., 2016)</ref>. Interpreting medical images and summarising them in natural text is a challeng- ing, complex and tedious task. Various research studies show that the general rate of missed radi- ological findings can be as much as 30% <ref type="bibr" target="#b4">(Berlin, 2001;</ref><ref type="bibr" target="#b5">Berlin and Hendrix, 1998</ref>). These errors are mainly due to limited expertise, increasing patient volumes, the subjectivity of human perception, fa- tigue, and inability to locate critical and subtle findings <ref type="bibr" target="#b33">(Sohani, 2013)</ref>. Based on a recent esti- mate one billion radiology examinations are per- formed worldwide annually. This equates to about 40 million radiologist errors per annum <ref type="bibr" target="#b6">(Brady, 2017)</ref>. In order to reduce these errors, there is a need to develop automated clinical decision sup- port systems (CDSS) ( <ref type="bibr" target="#b19">Eickhoff et al., 2017</ref>) that can interpret medical images and generate written reports to augment radiologist's work.</p><p>Our research aims to develop machine learning models that reason jointly on medical images and clinical text for advanced search, retrieval, anno- tation and description of medical images. Specif- ically, we aim to automatically generate descrip- tion of medical images, to develop medical visual question answering system and to develop medical dialog agents that interact with patients to answer their queries based on their medical data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>Deep Neural Networks (DNNs) are a special class of machine learning algorithms that learn in multi- ple levels, corresponding to different levels of ab- straction. In this section, we provide an overview of two of the most common DNNs namely Con- volutional Neural Networks (CNNs) and Recur- rent Neural Networks (RNNs). Also, we provide a profile of architectures and various successful ap- plications in CV and NLP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Convolutional Neural Networks</head><p>In the past, problems such as image classifica- tion and object detection were approached using a traditional CV pipeline where hand-crafted fea- tures were first extracted, followed by learning algorithms ( <ref type="bibr" target="#b34">Srinivas et al., 2016</ref>). The perfor- mance of these systems highly depends upon the quality of the extracted features and the ability of the learning algorithms ( <ref type="bibr">Fu and Rui, 2017)</ref>. As CV progressed, extracting these complex features became a tedious task, giving rise to algorithms that can learn directly from the raw data with- out the need for hand-crafted feature engineering. The major breakthrough happened in 2012 when object classification on ImageNet ( <ref type="bibr" target="#b30">Russakovsky et al., 2015</ref>) improved vastly from top-5 error of 25% in 2011 to 16% in 2012. This was the result of shift from hand-engineered features to learned deep features <ref type="bibr">(Felsberg, 2017)</ref>. AlexNet was the first deep learning model that won the ILSVRC championship in 2012 by drastically re- ducing the top-5 error rate on the ImageNet Chal- lege compared to the previous shallow networks. Since AlexNet, a series of CNN models have been proposed that advanced state-of-the-art such as VGG-16 <ref type="bibr" target="#b32">(Simonyan and Zisserman, 2014</ref>), GoogleNet ( <ref type="bibr" target="#b37">Szegedy et al., 2015)</ref>, and Residual Networks (ResNet) ( <ref type="bibr" target="#b16">He et al., 2016)</ref>. All these models differ in terms of various structural decom- positions which led them to have better learning ability and high predictive performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Recurrent Neural Networks</head><p>Recurrent Neural Networks (RNNs) are special networks that process sequential or temporal data including language, speech, and handwriting. Learning sequential data requires memory of pre- vious states and a feedback mechanism. RNNs form an internal state of the network where con- nections between units form a cycle, which al- lows it to exhibit dynamic temporal behavior ( <ref type="bibr" target="#b22">Lee et al., 2017)</ref>. Simple RNNs suffer from the vanishing or exploding gradients problem when trained with gradient based techniques. To over- come these challenges, Long Short Term Memory (LSTM) <ref type="bibr" target="#b18">(Hochreiter and Schmidhuber, 1997)</ref> and Gated Recurrent Unit (GRU) ( <ref type="bibr" target="#b9">Cho et al., 2014)</ref> were introduced which are able to learn very deep RNNs and can successfully remember sequences having duration of varying lengths.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Joint Image and Language Modeling</head><p>Due to the success of deep learning techniques in individual domains of AI including vision, speech and language, researchers are aiming at problems at the intersection of vision, language, knowledge representation and common-sense reasoning. An ultimate goal of CV is to have comprehensive vi- sual understanding that involves not only naming the classes of objects present in a scene, but also describe their attributes and recognize relation- ship between objects ( <ref type="bibr" target="#b20">Krishna et al., 2017)</ref>. Much progress has been made towards this goal, includ- ing object classification ( <ref type="bibr" target="#b21">Krizhevsky et al., 2012)</ref>, object detection and localisation <ref type="bibr">(Girshick et al., 2014)</ref>, and object and instance segmentation <ref type="bibr" target="#b15">(He et al., 2017a</ref> Early work combining vision with language in- cludes image annotation, where the task is to as- sign labels to an image. However, image annota- tion only associates isolated words with the image content and ignores the relationships between ob- jects and their relation to the world. To generate a coherent interpretation of a scene and describe it in a natural way, the task of image caption- ing emerged within the language-vision commu- nity, together with large-scale captioning datasets including Flickr30k 1 and MSCOCO 2 . Caption- ing involves generating a textual description that verbalizes the most salient aspects (objects, at- tributes, scene properties) of the image by ana- lyzing it. In order to tackle more complex tasks that combine vision and language and to develop high-level reasoning, Visual Question Answer- ing (VQA) ( <ref type="bibr" target="#b35">Stanislaw et al., 2015</ref>) was proposed which is equivalent to Visual Turing Test. In VQA, the goal is to predict the answer correctly after rea- soning over the image and a question in natural text ( <ref type="bibr" target="#b38">Teney et al., 2017)</ref>. To further extend this task, Visual Dialog (Das et al., 2017a,b) was pro- posed that requires an AI agent to hold meaning- ful dialog with humans in natural language about visual content. Apart from this, research is mov- ing towards linking language to actions in the real world, also known as language grounding (Chen and Mooney, 2011), which finds applications in human-robot interaction, robotic navigation and manipulation. Although there has been language- vision research for these general purpose tasks, its progress has been underutilised in healthcare.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Related Work</head><p>Developing clinical decision support has long been a major research focus in medical image pro- cessing. In recent years, deep learning models have outperformed conventional machine learning approaches in tasks such as dermatologist level classification of skin lesions ( <ref type="bibr">Esteva et al., 2017)</ref>, detection of liver lesions <ref type="bibr" target="#b3">(Ben-Cohen et al., 2016)</ref>, detection of pathological-image findings (Zhang et al., 2017a), automated detection of pneumo- nia from chest X-rays ( <ref type="bibr" target="#b29">Rajpurkar et al., 2017)</ref>, and segmentation of brain MRI ( <ref type="bibr">Milletari et al., 2016)</ref>. Although there are many publicly available datasets for general purpose tasks <ref type="bibr">(Ferraro et al., 2015)</ref>, there are few publicly available datasets in the medical domain. Recently, ( <ref type="bibr" target="#b42">Wang et al., 2017</ref>) introduced a large-scale Chest X-ray dataset named ChestX-ray8 that is publicly available. The dataset consists of 112, 120 frontal-view chest X- rays images of 30, 805 patients. The labels of the images are automatically assigned by applying NLP techniques to the paired radiology reports.</p><p>( <ref type="bibr" target="#b47">Zhang et al., 2017b)</ref> proposed MD-Net, that can read pathology bladder cancer images, can gener- ate diagnostic reports, retrieve images by symp- tom descriptions, and provide justification of the decision process by highlighting image regions us- ing an attention mechanism. Moreover, ( <ref type="bibr" target="#b31">Shin et al., 2016)</ref> proposed CNN-RNN model that can efficiently detect a disease in medical image, find the context (e.g. location and severity of affected organ) and also correlate the salient regions of the image with Medical Subject Headings (MeSH) terms. They work on Open-i (U.S. NLM), a pub- licly available dataset that consists of 3955 radi- ology reports from the Indiana Network for Pa- tient Care, and 7, 470 associated chest X-rays from the hospitals' PACS. Evaluation in terms of BLEU score ( <ref type="bibr" target="#b26">Papineni et al., 2002</ref>) demonstrates that the model is able to locate diseases and able to gener- ate Medical Subject Headings (MeSH) terms with high precision. In addition, ImageCLEF challenges 3 have been leading advances in the medical field by promot- ing evaluation of technologies for annotation, in- dexing and retrieval of textual data and medical images ( <ref type="bibr" target="#b19">Ionescu et al., 2017)</ref>. Motivated by the need for automated image understanding meth- ods in the healthcare domain, ImageCLEF orga- nized its first concept detection and caption pre- diction tasks in 2017 ( <ref type="bibr" target="#b19">Eickhoff et al., 2017</ref>). The ImageCLEFcaption challenge consists of two sub tasks including Concept detection and Caption prediction. The concept detection task consists of identifying the UMLS Concept Unique Identifiers (CUIs). Majority of the submissions consider con- cept detection as a multi-label classification task. As both of these tasks are inter-related, there has been work where first concepts in the medical im- ages are identified and then captions are gener- ated based on the predicted concepts. ( <ref type="bibr" target="#b0">Abacha et al., 2017)</ref> consider CUIs in the training set as the labels to be assigned. Two methods namely CNN based approach and the Binary Relevance via Decision Trees (BR-DT) were used. In ( <ref type="bibr" target="#b13">Hasan et al., 2017)</ref>, an encoder-decoder based framework is used where image features are extracted using CNN and RNN-based architecture with attention mechanism is used to translate the image features to relevant captions. In <ref type="figure">(Rahman et al., 2017)</ref>, a Content Based Image Retrieval (CBIR) based ap- prroach is used where first images in both training and validation sets are indexed by extracting sev- eral low-level color, texture and edge-related vi- sual features. The similarity search is then used to find the closest matching image in the train (or validation</p><note type="other">set) for each each query (test) image for caption prediction. For similarity matching, each feature is concatenated to form a combined fea- ture vector and Euclidean distance is used for k- Nearest Neighbor image similarity. In the ImageCLEF challenge, submissions var- ried in their usage of external resources. For instance (Hasan et al., 2017) do semantic pre- processing of captions using MetaMap and UMLS meta-thesaurus. Pre-training CNN models on PubMed Central images helped in boosting effec- tiveness compared to training on general purpose ImageNet dataset. Although these challenges pro- vide labeled medical images for modality clas- sification and concept predictions, the datasets are still much smaller (thousands of images) than the ImageNet dataset (Russakovsky et al., 2015) which contains 1.2 million</note><p>natural images. More- over, there are issues with ImageCLEFcaption dataset as the UMLS concepts are extracted using probabilistic process which introduces errors. The analysis of dataset showed that some of the images had no concepts attached.</p><p>Learning image context from the correspond- ing clinical text and generating textual reports very similar to radiologists has not yet been achieved. With recent advancements in machine learning (specially deep learning), it is not hard to imagine an opportunity to aid radiologists by developing multimodal clinical decision support systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Proposed Research</head><p>We identify research gaps in the intersection of medical imaging, computer vision and natural lan- guage processing as listed in in the following re- search questions. Our work will address some of these gaps.</p><p>How to automatically generate a radiology report for a given medical image? In medical imaging, the accurate diagnosis or as- sessment of a disease depends on both image ac- quisition and image interpretation. While im- age acquisition has improved substantially due to faster rates and increased resolution of the acqui- sition devices, image interpretation is still per- formed by a radiologist, where the radiologist has only a few minutes with an imaging study to de- scribe the findings in the form of radiology report. Such reporting is a time-consuming task and of- ten represents a bottleneck in the clinical diagno- sis pipeline <ref type="bibr" target="#b19">(Ionescu et al., 2017</ref>). We will develop machine learning models that automatically gener- ate radiology reports by interpreting medical im- ages in order to augment the radiology practice.</p><p>How to develop a question answering system that can reason over medical images?</p><p>There has been growing interest in AI to support clinical decision making and in improving clini- cal work-flow by better patient engagement. Au- tomated systems that can interpret complex med- ical images and provide findings in natural lan- guage text can significantly enhance the produc- tivity of hospitals, reduce burden on radiologists and provide a "second opinion", leading to re- duced errors in radiology practice. VQA (Stanis- law et al., 2015) has been successful on generic images, but it has not been explored in the med- ical domain. We will develop machine learning models that combine NLP and CV techniques to answer clinically relevant questions based on med- ical images. Subsequently, clinical visual dialog systems could be developed based on the models for medical VQA. The dialog agent will respond to patient's queries in an interactive manner based on medical images, clinical text reports and past history of the patient.</p><p>How to annotate medical images from the accompanied radiology reports in a weakly supervised manner?</p><p>A large volume of medical imaging data and text is accumulated in hosptitals' PACS. To harness this data for advancing healthcare is challeng- ing. Manual annotation of medical data is almost impossible due to the complex nature of medi- cal images, requirement of domain expertise, pri- vacy, ethics and healthcare data regulations. The processing of clinical text is challenging due to combinations of ad-hoc formatting, eliding words which can be inferred from context, and liberal use of parenthetical expressions, jargon and acronyms to increase the information density. We will ex- plore NLP techniques to annotate medical images from the accompanying radiology reports.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>How to highlight the relevant area in a medical image based on the features extracted from radiology reports?</head><p>Although machine learning, especially deep learn- ing, models have been successful in various do- mains, they are often treated as black boxes. While this might not be a problem in other more deter- ministic domains such as image annotation (where the end user can objectively validate the tags as- signed to the images), in health care, not only the quantitative algorithmic performance is important, but also the reason why the algorithms works is relevant. In fact, model interpretability is crucial for convincing medical professionals of the valid- ity of actions recommended by predictive systems. We will develop models using CV, NLP and atten- tion mechanisms which highlight the relevant area in a medical image based on the feature extracted from the radiology reports.</p><p>How to train machine learning models when data is small or classes are imbalanced?</p><p>Obtaining datasets in the medical imaging domain that are as comprehensively annotated as Ima- geNet remains a challenge. When sufficient data is not available, transfer learning or fine tuning are the ways to proceed. In transfer learning, CNN models pre-trained from natural image dataset or from a different medical domain are used for a new medical task at hand. On the other hand, in fine-tuning, when a medium sized dataset does ex- ist for the task at hand, one suggested scheme is to use a pre-trained CNN as initialisation of the net- work, following which further supervised training is conducted, of selected network layers, using the new data for the task at hand. In this task, we will explore the effectiveness of transfer learning and fine-tuning in the medical domain.</p><p>How to incorporate the temporal nature of diseases in machine learning models?</p><p>Diseases evolve and change over time in a non- deterministic manner. The existing deep learning models assume static vector-based inputs, which do not take time factor into consideration. In or- der to understand the temporal nature of healthcare data, we need to develop deep learning models whose parameters gets incrementally updated with time. Considering that the time factor is impor- tant in all kinds of healthcare problems, training a time-sensitive machine learning model is critical for a better understanding of the patient condition and providing timely clinical decision support. We will work towards exploring ways of how to incor- porate temporal information in the machine learn- ing models to have temporal reasoning. This will help in understanding the progressive nature of diseases and to alert medical staff about the chang- ing conditions of patients at right time.</p><p>How to increase the number of features to improve performance and robustness of CDSS? Due to rise of Electronic Health Records (or EHR), hospitals store data in various forms in- cluding patient's medical history, demographics, progress notes, medications, vital signs, immu- nizations, laboratory data, genetics and genomics data, and radiology reports. Combining two or more modalities allows integration of the strengths of individual modalities. We will work towards combining various data sources in healthcare so that better decisions can be made, in turn re- sulting in achieving the overall goal of precision medicine.</p><p>How to develop bi-directional models for medical indexing and retrieval? With the widespread use of EHR and PACS tech- nology in hospitals, the size of medical data is growing rapidly, which in turn demands effective and efficient retrieval systems. Clinical and radi- ology practices heavily rely on processing stored medical data providing aid in decision making and increasing productivity. Existing medical retrieval systems have limitations in terms of the seman- tic gap (between the low level visual information captured by imaging devices and the high level semantics perceived by humans) <ref type="bibr" target="#b27">(Qayyum et al., 2017</ref>). We will develop bi-directional multimodal machine learning models that perform retrieval based on both textual and visual content. The pro- posed approach can retrieve medical images either based on the textual query as an input or by pro- viding sample query images. In addition, the de- veloped model can also align images and text in large medical data collections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Expermental Framework</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets</head><p>The proposed research work has approval from Macquarie University Human Research Ethics Committee to use medical data from Macquarie University Hospital. We will also use datasets that are publicly available such as ChestX-Ray8, Open-i 4 , and ImageCLEF 5 challenge datasets. These datasets comprise of medical images and their accompanied text in the form of disease la- bels or caption, mined from open source biomedi- cal literature and image collections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Evaluation Metrics</head><p>For medical captioning task, we will use standard image captioning metrics such as BLEU ( <ref type="bibr" target="#b26">Papineni et al., 2002</ref>), ROUGE <ref type="bibr" target="#b23">(Lin, 2004</ref>), METEOR (Banerjee and <ref type="bibr" target="#b2">Lavie, 2005</ref>), CIDEr ( <ref type="bibr" target="#b40">Vedantam et al., 2015)</ref>, and SPICE <ref type="bibr" target="#b1">(Anderson et al., 2016</ref>). For VQA in the medical do- main, we will use accuracy for multiple-choice questions, but to measure how much a predicted answer differs from ground truth based on differ- ences in their semantic meaning, Wu-Palmer Simi- larity ( <ref type="bibr" target="#b45">Wu and Palmer, 1994)</ref> will be used. For the Visual-Dialog task in the medical domain, an algo- rithm has to return candidate answers for a given medical image, dialog history, question, and a list of candidate answers. We will use two standard re- trieval metrics namely, recall@k and mean recip- rocal rank (MRR) ( <ref type="bibr" target="#b11">Das et al., 2017a</ref>). In the task of medical retrieval system, the evaluation task is to measure how effectively an algorithm is able to produce search results to satisfy the user's query in the form of sample image or complex textual query. For this task, standard information retrieval metrics such as Precision, Recall, and F-score will be used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Baseline Methods</head><p>There are three main approaches to generate im- age captions: (1) Using templates that rely on detectors and map the output to linguistic struc- tures; (2) Using language models that yield more expressive captions overcoming the limitations of template based approach; and, (3) Caption re- trieval and recombination that involves retrieving captions based on training data instead of gen- erating new captions. We will work on CNN- RNN framework and caption retrieval approaches. The model proposed by <ref type="bibr" target="#b13">Hasan et al. (2017)</ref> was ranked first in the caption prediction task in the ImageCLEF challenge, which was based on deep learning approach using language models. Apart from this, deep learning methods have demon-strated successful results in general purpose im- age captioning, therefore the first baseline method is to incorporate an encoder-decoder based archi- tecture. Specifically, initial image features will be extracted using a CNN model, namely VGG- 19, which is pre-trained on the ImageNet dataset and is fine-tuned on the given ImageCLEF train- ing dataset to extract the image features from a lower convolution layer such that the decoder can focus on the salient aspects of the image via an at- tention mechanism. Second, text features will be extracted and pre-processed. Two reserved words namely start and end are appended to indicate the start and end of the captions. While training, the output of the last hidden layer of the CNN model (Encoder) is given to the first time step of the LSTM (decoder). We set x1 = start and the de- sired label, y1 = first word of the caption. Simi- larly, we set the all the remaining words and finally the last target label y T = end token. The model will be trained with an adaptive learning rate op- timization algorithm, and dropout as a regulariza- tion mechanism. The model hyper-parameters are tuned based on the BLEU score on the validation set. Once the model is trained, captions are gen- erated on the test images by predicting one word at every time step based on the context vector, the previous hidden state, and the previously gener- ated words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We argue the need for language and vision re- search in the medical domain by showing its suc- cessful applications on general purpose tasks. We identify various research directions in the medi- cal imaging applications that have not been fully explored, and can be solved by combining vision and language processing. This research aims to develop machine learning models that jointly rea- son over medical images and accompanying clin- ical text in radiology. The proposed research is fruitful in advancing healthcare by building vari- ous clinical decision support systems to augment radiologist's work. </p></div>
			<note place="foot" n="1"> http://shannon.cs.illinois.edu/ DenotationGraph/ 2 http://cocodataset.org/</note>

			<note place="foot" n="3"> http://www.imageclef.org/</note>

			<note place="foot" n="4"> https://openi.nlm.nih.gov/ 5 http://www.imageclef.org/</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">NLM at ImageCLEF 2017 Caption Task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alba</forename><forename type="middle">G</forename><surname>Asma Ben Abacha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumya</forename><surname>Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dina</forename><surname>Gayen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Antani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF2017 Working Notes, CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">SPICE: Semantic Propositional Image Caption Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Basura</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Gould</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<meeting><address><addrLine>Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">METEOR: An automatic metric for MT evaluation with improved correlation with human judgments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satanjeev</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization</title>
		<meeting>the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization<address><addrLine>Ann Arbor, Michigan, United States</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="65" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Fully convolutional network for liver segmentation and lesions detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avi</forename><surname>Ben-Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Idit</forename><surname>Diamant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eyal</forename><surname>Klang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Amitai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hayit</forename><surname>Greenspan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Deep Learning and Data Labeling for Medical Applications</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="77" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Defending the &quot;missed&quot; radiographic diagnosis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonard</forename><surname>Berlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Journal of Roentgenology</title>
		<imprint>
			<biblScope unit="volume">176</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="863" to="867" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Perceptual errors and negligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonard</forename><surname>Berlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><forename type="middle">W</forename><surname>Hendrix</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Journal of Roentgenology</title>
		<imprint>
			<biblScope unit="volume">170</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="863" to="867" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrian</forename><forename type="middle">P</forename><surname>Brady</surname></persName>
		</author>
		<title level="m">Error and discrepancy in radiology: inevitable or avoidable? Insights into Imaging</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="171" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianrun</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><forename type="middle">A</forename><surname>Giannopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatiana</forename><surname>Kelil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beth</forename><surname>Ripley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kanako</forename><forename type="middle">K</forename><surname>Kumamaru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><forename type="middle">J</forename><surname>Rybicki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitrios</forename><surname>Mitsouras</surname></persName>
		</author>
		<title level="m">Natural language processing technologies in radiology research and clinical applications. RadioGraphics</title>
		<imprint>
			<publisher>PMID</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page">26761536</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning to interpret natural language navigation instructions from observations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th AAAI Conference on Artificial Intelligence</title>
		<meeting>the 25th AAAI Conference on Artificial Intelligence<address><addrLine>San Francisco, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="859" to="865" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning phrase representations using RNN encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1724" to="1734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Visual Dialog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satwik</forename><surname>Kottur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khushi</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avi</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deshraj</forename><surname>Yadav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>José</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Moura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition<address><addrLine>Hawaii, United States</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1080" to="1089" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Integrating vision processing and natural language processing with a clinical application</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Mckevitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 1995 2nd New Zealand International Two-Stream Conference on Artificial Neural Networks and Expert Systems</title>
		<meeting>1995 2nd New Zealand International Two-Stream Conference on Artificial Neural Networks and Expert Systems<address><addrLine>Dunedin, New Zealand</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="373" to="376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joey</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rithesh</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shreya</forename><surname>Sreenivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Anand</surname></persName>
		</author>
		<editor>Tilak Raj Arora, Vivek Datla, Kathy Lee, Ashequl Qadir, Christine Swisher, and Oladimeji Farri</editor>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">PRNA at ImageCLEF</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Caption Prediction and Concept Detection tasks</title>
	</analytic>
	<monogr>
		<title level="m">CLEF2017 Working Notes, CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Mask R-CNN</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgia</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Computer Vision</title>
		<meeting><address><addrLine>Venice, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2980" to="2988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Nevada, United States</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep semantic role labeling: What works and what&apos;s next</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="473" to="483" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Long Short-Term Memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Overview of ImageCLEF 2017: Information extraction from images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bogdan</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mauricio</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helbert</forename><surname>Arenas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giulia</forename><surname>Boato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yashin</forename><forename type="middle">Dicente</forename><surname>Duc-Tien Dangnguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Cid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alba</forename><forename type="middle">G</forename><surname>Eickhoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cathal</forename><surname>Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bayzidul</forename><surname>Gurrin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vassili</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vitali</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josiane</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Mothe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Piras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Experimental IR Meets Multilinguality, Multimodality, and Interaction</title>
		<meeting><address><addrLine>Michael Riegler, and Immanuel Schwall; Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="315" to="337" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Visual genome: Connecting language and vision using crowdsourced dense image annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ranjay</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuke</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Groth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Hata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Kravitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephanie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannis</forename><surname>Kalantidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">A</forename><surname>Shamma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="32" to="73" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">ImageNet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on Neural Information Processing Systems</title>
		<meeting>the 25th International Conference on Neural Information Processing Systems<address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
	<note>Hinton</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Deep learning in medical imaging: General overview</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Korean Journal of Radiology</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="570" to="584" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">ROUGE: A package for automatic evaluation of summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">42nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Survey of deep learning in radiology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Mastanduno</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017-01" />
			<biblScope unit="volume">19</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">V-Net: Fully convolutional neural networks for volumetric medical image segmentation</title>
		<idno>abs/1606.04797</idno>
		<editor>Fausto Milletari, Nassir Navab, and Seyed-Ahmad Ahmadi</editor>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">BLEU: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 40th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Philadelphia, Pennsylvania, United States</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Medical image retrieval using deep convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adnan</forename><surname>Qayyum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><surname>Syed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><surname>Anwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><surname>Awais</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Majid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">266</biblScope>
			<biblScope unit="page" from="8" to="20" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A cross-modal concept detection and caption prediction approach in ImageCLEFcaption track of ImageCLEF</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahmudur</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terrance</forename><surname>Lagree</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martina</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF2017 Working Notes, CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">CheXNet: Radiologist-level pneumonia detection on chest X-rays with deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Irvin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaylie</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brandon</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hershel</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tony</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daisy</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aarti</forename><surname>Bagul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Curtis</forename><surname>Langlotz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katie</forename><surname>Shpanskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">P</forename><surname>Lungren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<idno>abs/1711.05225</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ImageNet Large Scale Visual Recognition Challenge</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="211" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Learning to read chest X-rays: Recurrent neural cascade model for automated image annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoo-Chang</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kirk</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dina</forename><surname>Demnerfushman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianhua</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><forename type="middle">M</forename><surname>Summers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2497" to="2506" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<idno>abs/1409.1556</idno>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A difficult challenge for radiology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sohani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Indian Journal of Radiology and Imaging</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="110" to="112" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A taxonomy of deep convolutional neural nets for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suraj</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravi</forename><forename type="middle">Kiran</forename><surname>Sarvadevabhatla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konda</forename><surname>Reddy Mopuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikita</forename><surname>Prabhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinivas</forename><forename type="middle">S S</forename><surname>Kruthiventi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Babu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Robotics and AI</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">36</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">VQA: Visual Question Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antol</forename><surname>Stanislaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agrawal</forename><surname>Aishwarya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Jiasen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><surname>Margaret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Batra</forename><surname>Dhruv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parikh</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Devi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<meeting><address><addrLine>Santiago, Chile</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2425" to="2433" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Neural Information Processing Systems</title>
		<meeting>the 27th International Conference on Neural Information Processing Systems<address><addrLine>Cambridge, MA, United States</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Boston, Massachusetts, United States</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
	<note>Going deeper with convolutions</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Visual Question Answering: A tutorial</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Damien</forename><surname>Teney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Van Den Hengel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="63" to="75" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Open-i: An open access biomedical search engine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nih</forename><forename type="middle">U S</forename><surname>Nlm</surname></persName>
		</author>
		<ptr target="https://openi.nlm.nih.gov/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">CIDEr: Consensus-based image description evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lawrence</forename><surname>Ramakrishna Vedantam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Parikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Boston, Massachusetts, United States</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4566" to="4575" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Grammar as a foreign language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Neural Information Processing Systems</title>
		<meeting>the 28th International Conference on Neural Information Processing Systems<address><addrLine>Cambridge, MA, United States</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="2773" to="2781" />
		</imprint>
	</monogr>
	<note>NIPS&apos;15</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">ChestX-Ray8: Hospital-scale chest XRay database and benchmarks on weakly-supervised classification and localization of common thorax diseases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaosong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammadhadi</forename><surname>Bagheri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><forename type="middle">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Hawaii, United States</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3462" to="3471" />
		</imprint>
	</monogr>
	<note>Summers</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qin</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Klingner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apurva</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melvin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<imprint>
			<pubPlace>Stephan Gouws, Yoshikiyo Kato, Taku Kudo, Hideto</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Google&apos;s neural machine translation system: Bridging the gap between human and machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Kazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Stevens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nishant</forename><surname>Kurian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cliff</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Riesa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Rudnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Macduff</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dean</surname></persName>
		</author>
		<idno>abs/1609.08144</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Verb semantics and lexical selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhibiao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">32nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting><address><addrLine>Las Cruces, New Mexico</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="133" to="138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">TandemNet: Distilling knowledge from medical images using diagnostic reports as optional semantic references</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pingjun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manish</forename><surname>Sapkota</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer-Assisted Intervention MICCAI 2017</title>
		<meeting><address><addrLine>Quebec City, Quebec, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="320" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">MDNet: A semantically and visually interpretable medical image diagnosis network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanpu</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuyong</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mason</forename><surname>Mcgough</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Hawaii, United States</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3549" to="3557" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">End-to-end learning of semantic role labeling using recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1127" to="1137" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
