<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:32+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning Prototypical Goal Activities for Locations</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 15-20, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyu</forename><surname>Jiang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">University of Utah Salt Lake City</orgName>
								<address>
									<postCode>84112</postCode>
									<region>UT</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">University of Utah Salt Lake City</orgName>
								<address>
									<postCode>84112</postCode>
									<region>UT</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Learning Prototypical Goal Activities for Locations</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1297" to="1307"/>
							<date type="published">July 15-20, 2018. 2018</date>
						</imprint>
					</monogr>
					<note>1297</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>People go to different places to engage in activities that reflect their goals. For example, people go to restaurants to eat, libraries to study, and churches to pray. We refer to an activity that represents a common reason why people typically go to a location as a prototypical goal activity (goal-act). Our research aims to learn goal-acts for specific locations using a text corpus and semi-supervised learning. First, we extract activities and locations that co-occur in goal-oriented syntactic patterns. Next, we create an activity profile matrix and apply a semi-supervised label propagation algorithm to iteratively revise the activity strengths for different locations using a small set of labeled data. We show that this approach outperforms several baseline methods when judged against goal-acts identified by human annotators.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Every day, people go to different places to accom- plish goals. People go to stores to buy clothing, go to restaurants to eat, and go to the doctor for medical services. People travel to specific destina- tions to enjoy the beach, go skiing, or see historical sites. For most places, people typically go there for a common set of reasons, which we will re- fer to as prototypical goal activities (goal-acts) for a location. For example, a prototypical goal-act for restaurants would be "eat food" and for IKEA would be "buy furniture".</p><p>Previous research has established that recogniz- ing people's goals is essential for narrative text un- derstanding and story comprehension <ref type="bibr" target="#b23">(Schank and Abelson, 1977;</ref><ref type="bibr" target="#b25">Wilensky, 1978;</ref><ref type="bibr" target="#b15">Lehnert, 1981;</ref><ref type="bibr" target="#b8">Elson and McKeown, 2010;</ref><ref type="bibr" target="#b13">Goyal et al., 2013</ref>).</p><p>Goals and plans are essential to understand peo- ple's behavior and we use our knowledge of pro- totypical goals to make inferences when reading. For example, consider the following pair of sen- tences: "Mary went to the supermarket. She needed milk." Most people will infer that Mary purchased milk, unless told otherwise. But a pur- chase event is not explicitly mentioned. In con- trast, a similar sentence pair "Mary went to the theatre. She needed milk." feels incongruent and does not produce that inference. Recognizing goals is also critical for conversational dialogue systems. For example, if a friend tells you that they went to a restaurant, you might reply "What did you eat?", but if a friend says that they went to Yosemite, a more appropriate response might be "Did you hike?" or "Did you see the waterfalls?".</p><p>Our knowledge of prototypical goal activities also helps us resolve semantic ambiguity. For ex- ample, consider the following sentences:</p><p>(a) She went to the kitchen and got chicken. (b) She went to the supermarket and got chicken. (c) She went to the restaurant and got chicken.</p><p>In sentence (a), we infer that she retrieved chicken (e.g., from the refrigerator) but did not pay for it. In (b), we infer that she paid for the chicken but probably did not eat it at the supermarket. In (c), we infer that she ate the chicken at the restau- rant. Note how the verb "got" maps to different presumed events depending on the location.</p><p>Our research aims to learn the prototypical goal- acts for locations using a text corpus. First, we ex- tract activities that co-occur with locations in goal- oriented syntactic patterns. Next, we construct an activity profile matrix that consists of an activ- ity vector (profile) for each of the locations. We then apply a semi-supervised label propagation algorithm to iteratively revise the activity profile strengths based on a small set of labeled locations.  <ref type="figure">Figure 1</ref>: Dependency relation structure for "go to" pattern.</p><p>We also incorporate external resources to measure similarity between different activity expressions. Our results show that this semi-supervised learn- ing approach outperforms several baseline meth- ods in identifying the prototypical goal activities for locations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Recognizing plans and goals is fundamental to narrative story understanding <ref type="bibr" target="#b23">(Schank and Abelson, 1977;</ref><ref type="bibr" target="#b0">Bower, 1982)</ref>. Conceptual knowledge structures developed in prior work have shown the importance of this type of knowledge, includ- ing plans <ref type="bibr" target="#b25">(Wilensky, 1978)</ref>, goal trees <ref type="bibr" target="#b2">(Carbonell, 1979)</ref>, and plot units <ref type="bibr" target="#b15">(Lehnert, 1981)</ref>. Wilensky's research aimed to understand the actions of char- acters in stories by analyzing their goals, and their plans to accomplish those goals. For example, someone's goal might be to obtain food with a plan to go to a restaurant. Our work aims to learn proto- typical goals associated with a location, to support similar inference capabilities during story under- standing.</p><p>Goals and plans can also function to trigger scripts <ref type="bibr" target="#b6">(Cullingford, 1978)</ref>, such as the $RESTAU- RANT script. There has been growing interest in learning narrative event chains and script knowl- edge from large text corpora (e.g., <ref type="bibr">Jurafsky, 2008, 2009;</ref><ref type="bibr" target="#b14">Jans et al., 2012;</ref><ref type="bibr">Mooney, 2014, 2016)</ref>). In addition, <ref type="bibr" target="#b12">Goyal et al. (2010;</ref> developed a system to automat- ically produce plot unit representations for short stories. A manual analysis of their stories revealed that 61% of Positive/Negative Affect States orig- inated from completed plans and goals, and 46% of Mental Affect States originated from explicitly stated or inferred plans and goals. <ref type="bibr" target="#b8">Elson &amp; McKeown (2010)</ref> included plans and goals in their work on creating extensive story bank annotations that capture the knowledge needed to understand narrative structure. Re- searchers have also begun to explore NLP meth- ods for recognizing the goals, desires, and plans of characters in stories. Recent work has explored techniques to detect wishes (desires) in natural language text <ref type="bibr" target="#b10">(Goldberg et al., 2009</ref>) and identify desire fulfillment ( <ref type="bibr" target="#b5">Chaturvedi et al., 2016;</ref><ref type="bibr" target="#b21">Rahimtoroghi et al., 2017)</ref>.</p><p>Graph-based semi-supervised learning has been successfully used for many tasks, including senti- ment analysis <ref type="bibr" target="#b22">(Rao and Ravichandran, 2009;</ref><ref type="bibr" target="#b9">Feng et al., 2013)</ref>, affective event recognition <ref type="bibr" target="#b7">(Ding and Riloff, 2016)</ref> and class-instance extraction <ref type="bibr" target="#b24">(Talukdar and Pereira, 2010)</ref>. The semi-supervised learning algorithm used in this paper is modeled after a framework developed by <ref type="bibr" target="#b27">Zhu et al. (2003)</ref> based on harmonic energy minimization and a la- bel propagation algorithm described in ( <ref type="bibr" target="#b26">Zhu and Ghahramani, 2002</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Learning Prototypical Goal Activities</head><p>Our aim is to learn the most prototypical goal-acts for locations. To tackle this problem, we first ex- tract locations and related activities from a large text corpus. Then we use a semi-supervised learn- ing method to identify the goal activities for in- dividual locations. In the following sections we describe these processes in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Location and Activity Extraction</head><p>To collect information about locations and activ- ities, we use the 2011 Spinn3r dataset <ref type="bibr" target="#b1">(Burton et al., 2011</ref>). Since our interest is learning about the activities of ordinary people in their daily lives, we use the Weblog subset of the Spinn3r corpus, which contains over 133 million blog posts.</p><p>We use the text data to identify activities that are potential goal-acts for a location. However we also need to identify locations and want to include both proper names (e.g., Disneyland) as well as nomi- nals (e.g., store, beach), so Named Entity Recog- nition will not suffice. Consequently, we extract (Loc, Act) pairs using syntactic patterns.</p><p>First, we apply the Stanford dependency parser ( ). We then extract sentences that match the pattern "go to X to Y " with the following conditions: (1) there exists a subject connecting to "go", (2) X has an nmod (nominal modifier) relation to "go" (lemma), (3) X is a noun or noun compound, (4) Y has an xcomp relation (open clausal complement) with "go", and (5) Y is a verb. <ref type="figure">Figure 1</ref> depicts the intended syntactic structure, which we will informally call the "go to" pattern. For sentences that match this pattern, we extract X as a location and Y as an activity. If the verb is followed by a particle and/or noun phrase (NP), then we also include the particle and head noun of the NP. For example, we extract activities such as "pray", "clean up", and "buy sweater".</p><formula xml:id="formula_0">a 1 = buy book a 2 = eat burger ... a m = pray l 1 = McDonald's .</formula><p>This syntactic structure was chosen to identify activities that are described as being the reason why someone went to the location. However it is not perfect. In some cases, X is not a location (e.g., "go to great lengths to ..." yields "lengths" as a location), or Y is not a goal-act for X (e.g., "go to the office to retrieve my briefcase ..." yields "retrieve briefcase" which is not a prototypical goal for "office"). Interestingly, the pattern ex- tracts some nominals that are not locations in a strict sense, but behave as locations. For example, "go to the doctor" extracts "doctor" as a location. Literally a doctor is a person, but in this context it really refers to the doctor's office, which is a lo- cation. The pattern also extracts entities such as "roof", which are not generally thought of as loca- tions but do have a fixed physical location. Other extracted entities are virtual but function as loca- tions, such as "Internet". For the purposes of this work, we use the term location in a general sense to include any place or object that has a physical, virtual or implied location.</p><p>The "go to" pattern worked quite well at extract- ing (Loc, Act) pairs, but in relatively small quanti- ties due to the very specific nature of the syntactic structure. So we tried to find additional activities for those locations. Initially, we tried harvesting activities that occurred in close proximity (within 5 words) to a known location, but the results were too noisy. Instead, we used the pattern "Y in/at X" with the same syntactic constraints for Y (the extracted activity) and X (a location extracted by the "go to" pattern).</p><p>We discovered many sentences in the corpus that were exactly or nearly the same, differing only by a few words, which resulted in artificially high frequency counts for some (Loc, Act) pairs. So we filtered duplicate or near-duplicate sentences by computing the longest common substring of sentence pairs that extracted the same (Loc, Act). If the shared substring had length ≥ 5, then we discarded the "duplicate" sentence.</p><p>Finally, we applied three filters. To keep the size of the data manageable, we discarded loca- tions and activities that were each extracted with frequency &lt; 30 by our patterns. And we manu- ally filtered locations that are Named Entities cor- responding to cities or larger geo-political regions (e.g., provinces or countries). Large regions de- fined by government boundaries fall outside the scope of our task because the set of activities that typically occur in (say) a city or country is so broad. Finally, we added a filter to try to remove extremely general activities that can occur almost anywhere (e.g., visit). If an activity co-occurred with &gt; 20% of the extracted (distinct) locations, then we discarded it.</p><p>After these filters, we extracted 451 distinct lo- cations, 5143 distinct activities, roughly 200, 000 distinct (Loc, Act) pairs, and roughly 500, 000 in- stances of (Loc, Act) pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Activity Profiles for Locations</head><p>We define an activity profile matrix Y of size n × m, where n is the number of distinct locations and m is the number of distinct activities. Y i,j rep- resents the strength of the jth activity a j being a goal-act for l i . We use y i ∈ R m to denote the ith row of Y . <ref type="table">Table 1</ref> shows an illustration of (partial) activity profiles for four locations. <ref type="bibr">1</ref> Our goal is to learn the Y i,j values so that activities with high strength are truly goal-acts for location l i .</p><p>We could build the activity profile for location l i using the co-occurrence data extracted from the blog corpus. For example, we could estimate P (a j | l i ) directly from the frequency counts of the activities extracted for l i . However, a high co-occurrence frequency doesn't necessarily mean that the activity represents a prototypical goal. For example, the activity "have appointment" fre- quently co-occurs with "clinic" but doesn't re- veal the underlying reason for going to the clinic (e.g., probably to see a doctor or undergo a med- ical test). To appreciate the distinction, imagine that you asked a friend why she went to a health clinic, and she responded with "because I had an appointment". You would likely view her response as being snarky or evasive (i.e., she didn't want to tell you the reason). In Section 4, we will evaluate this approach as a baseline and show that it does not perform well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Semi-Supervised Learning of Goal-Act Probabilities</head><p>Our aim is to learn the activity profiles for lo- cations using a small amount of labeled data, so we frame this problem as a semi-supervised learn- ing task. Given a small number of "seed" loca- tions coupled with predefined goal-acts, we want to learn the goal-acts for new locations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Location Similarity Graph</head><p>We use l i ∈ L to represent location l i , where |L| = n. We define an undirected graph G = (V, E) with vertices representing locations (|V | = n) and edges E = V ×V , such that each pair of vertices v i and v k is connected with an edge e ik whose weight represents the similarity between l i and l k . We can then represent the edge weights as an n × n symmetric weight matrix W indicating the similarity between locations. There could be many ways to define the weights, but for now we use the following definition from ( <ref type="bibr" target="#b27">Zhu et al., 2003)</ref>, where σ 2 is a hyper-parameter 2 :</p><formula xml:id="formula_1">W i,k = exp − 1 σ 2 (1 − sim (l i , l k ))<label>(1)</label></formula><p>To assess the similarity between locations, we measure the cosine similarity between vectors of their co-occurrence frequencies with activi- ties. Specifically, let matrix</p><formula xml:id="formula_2">F n×m = [f 1 , ..., f n ] T</formula><p>where f i is a vector of length m capturing the co-occurrence frequencies between location l i and each activity a j in the extracted data (i.e., F i,j is the number of times that activity a j occurred with location l i ). We then define location similarity as:</p><formula xml:id="formula_3">sim(l i , l k ) = f T i f k f i f k (2)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Initializing Activity Profiles</head><p>We use semi-supervised learning with a set of "seed" locations from human annotations, and another set of locations that are unlabeled. So we subdivide the set of locations into S = {l 1 , ..., l s }, which are the seed locations, and U = {l s+1 , ..., l s+u }, which are the unlabeled loca- tions, such that s + u = n. For an unlabeled location l i ∈ U , the initial activity profile is the normalized co-occurrence frequency vector f i . For each seed location l i ∈ S, we first automat- ically construct an activity profile vector h i based on the gold goal-acts which were obtained from human annotators as described in Section 4.1. All activities not in the gold set are assigned a value of zero. Each activity a j in the gold set is assigned a probability P (a j | l i ) based on the gold answers. However, the gold goal-acts may not match the ac- tivity phrases found in the corpus (see discussion in Section 4.3), so we smooth the vector created with the gold goal-acts by averaging it with the normalized co-occurrence frequency vector f i ex- tracted from the corpus.</p><p>The activity profiles of seed locations stay con- stant through the learning process. We use y 0 i to denote the initial activity profiles. So when l i ∈ S,</p><formula xml:id="formula_4">y 0 i = (f i + h i )/2.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Learning Goal-Act Strengths</head><p>We apply a learning framework developed by ( <ref type="bibr" target="#b27">Zhu et al., 2003</ref>) based on harmonic energy minimiza- tion and extend it to multiple labels. Intuitively, we assume that similar locations should share sim- ilar activity profiles, 3 which motivates the follow- ing objective function over matrix Y :</p><formula xml:id="formula_5">arg min Y i,k W i,k y i − y k 2 , s.t. y i = y 0 i for each l i ∈ S<label>(3)</label></formula><formula xml:id="formula_6">Let D = (d i ) denote an n × n diagonal matrix where d i = n k=1 W i,k . Let's split Y by the sth row: Y = Y s Y u , then split W (similarly for D)</formula><p>into four blocks by the sth row and column:</p><formula xml:id="formula_7">W = W ss W su W us W uu<label>(4)</label></formula><p>From (Zhu et al., 2003), Eq (3) is given by:</p><formula xml:id="formula_8">Y u = (D uu − W uu ) −1 W us Y s<label>(5)</label></formula><p>We then use the label propagation algorithm de- scribed in ( <ref type="bibr" target="#b26">Zhu and Ghahramani, 2002</ref>) to com- pute Y :</p><formula xml:id="formula_9">Algorithm 1 repeat Y ← D −1 W Y Clamp y i = y 0 i for each l i ∈ S until convergence</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.4">Activity Similarity</head><p>One problem with the above algorithm is that it only takes advantage of relations between vertices (i.e., locations). If there are intrinsic relations between activities, they could be exploited as a complementary source of information to benefit the learning. Intuitively, different pairs of activi- ties share different similarities, e.g., "eat burgers" should be more similar to "have lunch" than "read books".</p><p>Under this idea, similar to the previous loca- tion similarity weight matrix W , we want to define an activity similarity weight matrix A m×m where A i,k indicates the similarity weight between activ- ity a i and a k :</p><formula xml:id="formula_10">A i,k = exp − 1 σ 2 (1 − sim (a i , a k ))<label>(6)</label></formula><p>where σ 2 is the same as in Eq (1). We explore 3 different similarity functions sim(a i , a k ) based on co-occurrence with loca- tions, word matching, and embedding similarities.</p><p>First, similar to Eq (2), we can use each activ- ity's co-occurrence frequency with all locations as its location profile and define a similarity score based on cosine values of location profile vectors:</p><formula xml:id="formula_11">sim L (a i , a k ) = g T i g k g i g k<label>(7)</label></formula><p>where the predefined co-occurrence frequency</p><formula xml:id="formula_12">matrix F = [f 1 , ..., f n ] T = [g 1 , ..., g m ].</formula><p>As a second option, the similarity between ac- tivities can often be implied by their lexical over- lap, e.g., two activities sharing the same verb or noun might be related. For each word belonging to any of our activities, we use WordNet <ref type="bibr" target="#b17">(Miller, 1995)</ref> to find its synonyms. We also include the word itself in the synonym set. If the synonym sets of two words overlap, we call these two words "match". Then we define the lexical overlap sim- ilarity function between a i and a k :</p><formula xml:id="formula_13">sim O (a i , a k ) =      1</formula><p>if verb and noun match 0.5 if verb or noun match 0 otherwise (8) As a third option, we can use 300-dimension word embedding vectors ( <ref type="bibr" target="#b18">Pennington et al., 2014</ref>) trained on 840 billion tokens of web data to com- pute semantic similarity. We compute an activity's embedding as the average of its words' embed- dings. Let sim E (a i , a k ) be the cosine value be- tween the embedding vectors of a i and a k :</p><formula xml:id="formula_14">sim E (a i , a k ) = cosEmbed(a i ), Embed(a k )<label>(9)</label></formula><p>Finally, we can plug these similarity functions into Eq (6). We use A L , A O , A E to denote the corresponding matrix. We can also plug in mul- tiple similarity metrics such as (sim L + sim E )/2 and use combination symbols A L+E to denote the matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.5">Injecting Activity Similarity</head><p>Once we have a similarity matrix for activities, the next question is how will it help with the activ- ity profile computation? Recall from Eq (5), we know that the activity profile of an unlabeled loca- tion can be represented by a linear combination of other locations' activity profiles. The activity pro- file matrix Y is an n × m matrix where each row is the activity profile for a location. We can also view Y as a matrix whose each column is the lo- cation profile for an activity. Using the same idea, we can make each column approximate a linear combination of its highly related columns (i.e., the location profile of an activity will become more similar to the location profiles of its similar activ- ities). Our expectation is that this approximation will help improve the quality of Y .</p><p>By being right multiplied by matrix A, Y gets updated from manipulating its columns (activities) as well. We modify the algorithm accordingly as below:  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Gold Standard Data</head><p>Since this is a new task and there is no existing dataset for evaluation, we use crowd-sourcing via Amazon Mechanical Turk (AMT) to acquire gold standard data. First, we released a qualification test containing 15 locations along with detailed an- notation guidelines. 25 AMT workers finished our assignment, and we chose 15 of them who did the best job following our guidelines to continue. We gave the 15 qualified workers 200 new locations, consisting of 152 nominals and 48 proper names, <ref type="bibr">4</ref> randomly selected from our extracted data and set aside as test data. For each location, we asked the AMT workers to complete the following sentence:</p><p>People go to LOC to</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VERB NOUN</head><p>LOC was replaced by one of the 200 locations. Annotators were asked to provide an activity that is the primary reason why a person would go to that location, in the form of just a VERB or a VERB NOUN pair. Annotators also had the option to la- bel a location as an "ERROR" if they felt that the provided term is not a location, since our location extraction was not perfect.</p><p>Only 10 annotators finished labeling our test cases, so we used their answers as the gold stan- dard. We discarded 12 locations that were labeled as an "ERROR" by ≥ 3 workers. <ref type="bibr">5</ref> This resulted in a test set of 188 locations paired with 10 manually defined goal-acts for each one.</p><p>A key question that we wanted to investigate through this manual annotation effort is to know whether people truly do associate the same pro- totypical goal activities with locations. To what extent do people agree when asked to list goal- acts? Also, some places clearly have a smaller set of goal-acts than others. For example, the primary reason to go to an airport is to catch a flight, but there's a larger set of common reasons why peo- ple go to Yosemite (e.g.,"hiking camping", "rock climbing", "see waterfalls", etc.).</p><p>Complicating matters, the AMT workers often described the same activity with different words (e.g., "buy book" vs. "purchase book"). Automat- ically recognizing synonymous event phrases is a difficult NLP problem in its own right. <ref type="bibr">6</ref> So solely for the purpose of analysis, we manually merged activities that have a nearly identical meaning. We were extremely conservative and did not merge similar or related phrases that were not synony- mous because the granularity of terms may matter for this task (e.g., we did not merge "eat burger" and "eat lunch" because one may apply to a spe- cific location while the other does not). <ref type="figure" target="#fig_0">Figure 2</ref> shows the results of our analysis. Only 1 location was assigned exactly the same goal-act by all 10 annotators. But at least half (5) of the annotators listed the same goal-act for 40% of the locations. And nearly 80% of locations had one or more goal-acts listed by ≥ 3 people. These re- sults show that people often do share the same as- sociations between prototypical goal-acts and lo- cations. These results are also very conservative because many different answers were also similar (e.g. "eat burger", "eat meal").</p><p>In <ref type="table">Table 2</ref> we show examples of locations and the goal-acts listed for them by the human an- notators. If multiple people gave the same an- swer, we show the number in parentheses. For example, given the location "Toys R Us", 9 peo- ple listed "buy toys" as a goal-act and 1 person listed "browse gifts". We see from <ref type="table">Table 2</ref> that</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Location</head><p>Gold Goal-Acts Toys R Us buy toys (9), browse gifts sink wash hands <ref type="formula" target="#formula_11">(7)</ref>, wash dishes (3) airport catch flight <ref type="formula" target="#formula_11">(7)</ref>, board planes, take air- plane, take trips bookstore buy books (6), browse books (2), browse bestsellers, read book lake go fishing (3), go swimming (3), drive boat (2), ride boat, see scenery chiropractor get treatment (3), adjust backs (3), al- leviate pain (2), get adjustment, get aligned Chinatown buy goods (2), buy duck, buy sou- venirs, eat dim sum, eat rice, eat won- tons, find Chinese, speak Chinese, visit restaurants <ref type="table">Table 2</ref>: Goal-acts provided by human annotators.</p><p>some locations yield very similar sets of goal-acts (e.g., sink, airport, bookstore), while other loca- tions show more diversity (e.g., lake, chiropractor, Chinatown).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Baselines</head><p>To assess the difficulty of this NLP task, we cre- ated 3 baseline systems for comparison with our learning approach. All of these methods take the list of activities that co-occurred with a location l i in our extracted data and rank them. The first baseline, FREQ, ranks the activities based on the co-occurrence frequency F i,j be- tween l i and a j in our patterns. The second base- line, PMI, ranks the activities using point-wise mutual information. The third baseline, EMBED, ranks the activities based on the cosine similar- ity of the semantic embedding vectors for l i and a j . We use GloVe ( <ref type="bibr" target="#b18">Pennington et al., 2014</ref>) 300- dimension embedding vectors pre-trained on 840 billion tokens of web data. For locations and ac- tivities with multiple words, we create an embed- ding by averaging the vectors of their constituent words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Matching Activities</head><p>The gold standard contains a set of goal-acts for each location. Since the same activity can be ex- pressed with many different phrases, the only way to truly know whether two phrases refer to the same activity is manual evaluation, which is ex- pensive. Furthermore, many activities are very similar or highly related, but not exactly the same. For example, "eat burger" and "eat food" both describe eating activities, but the latter is more general than the former. Considering them to be the same is not always warranted (e.g., "eat  burger" is a logical goal-act for McDonald's but not for Baskin-Robbins which primarily sells ice cream). As another example, "buy chicken" and "eat chicken" refer to different events (buying and eating) so they are clearly not the same semanti- cally. But at a place like KFC, buying chicken im- plies eating chicken, and vice versa, so they seem like equally good answers as goal-acts for KFC. Due to the complexities of determining which gold standard answers belong in equivalence classes, we considered all of the goal-acts provided by the human annotators to be acceptable answers.</p><note type="other">MRR E MRR P TOP1 TOP2 TOP3 EMBED 0.</note><p>To determine whether an activity a j produced by our system matches any of the gold goal-acts for a location l i , we report results using two types of matching criteria. Exact Match judges a j to be a correct answer for l i if (1) it exactly matches (af- ter lemmatization) any activity in l i 's gold set, or (2) a j 's verb and noun both appear in l i 's gold set, though possibly in different phrases. For example, if a gold set contains "buy novels" and "browse books", then "buy books" will be a match.</p><p>Since Exact Match is very conservative, we also define a Partial Match criterion to give 50% credit for answers that partially overlap with a gold answer. An activity a j is a partial match for l i if either its verb or noun matches any of the activi- ties in l i 's gold set of goal-acts. For example, "buy burger" would be a partial match with "buy food" because their verbs match.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Evaluation Metrics</head><p>All of our methods produce a ranked list of hy- pothesized goal-acts for a location. So we use Mean Reciprocal Rank (MRR) to judge the qual- ity of the top 10 activities in each ranked list. We report two types of MRR scores.</p><p>MRR based on the Exact Match criteria (MRR E ) is computed as follows, where n is the number of locations in the test set:</p><formula xml:id="formula_15">MRR E = 1 n n i=1 1 rank of 1 st Exact Match (10)</formula><p>We also compute MRR using both the Exact Match and Partial Match criteria. First, we need to identify the "best" answer among the 10 ac- tivities in the ranked list, which depends both on each activity's ranking and its matching score. The matching score for activity a j is defined as:</p><formula xml:id="formula_16">score(a j ) =      1 if a j is an Exact Match 0.5 if a j is a Partial Match 0 otherwise</formula><p>Given 10 ranked activities a 1 ... a 10 for l i , we then compute:</p><formula xml:id="formula_17">best score(l i ) = max j=1..10 score(a j ) rank(a j )</formula><p>And then finally define MRR P as follows:</p><formula xml:id="formula_18">MRR P = 1 n n i=1 best score(l i ) (11)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Experimental Results</head><p>Unless otherwise noted, all of our experiments re- port results using 4-fold cross-validation on the 200 locations in our test set. We used 4 folds to ensure 50 seed locations for each run (i.e., 1 fold for training and 3 folds for testing).</p><p>The first two columns of <ref type="table" target="#tab_3">Table 3</ref> show the MRR results under Exact Match and Partial Match con- ditions. The first 3 rows show the results for the baseline systems, and the remaining rows show re- sults for our Activity Profile (AP) semi-supervised learning method. We show results for 5 varia- tions of the algorithm: AP uses Algorithm 1, and the others use Algorithm 2 with different Activ- ity Similarity measures: AP+A L (location profile similarity), AP+A O (overlap similarity), AP+A E (embedding similarity), and AP+A L+E (location profiles plus embeddings). <ref type="table" target="#tab_3">Table 3</ref> shows that our AP algorithm outper- forms all 3 baseline methods. When adding Activ- ity Similarity into the algorithm, we find that A L slightly improves performance, but A O and A E do not. However, we also tried combining them and obtained improved results by using A L and A E to- gether, yielding an MRR P score of 0.42.</p><p>To gain more insight about the behavior of the models, <ref type="table" target="#tab_3">Table 3</ref> also shows results for the top- ranked 1, 2, and 3 answers. For these experiments, the system gets full credit if any of its top k an- swers exactly matches the gold standard, or 50% credit if a partial match is among its top k answers. These results show that our AP method produces more correct answers at the top of the list than the baseline methods. <ref type="table" target="#tab_5">Table 4</ref> shows six locations with their gold an- swers and the Top 3 goal-acts hypothesized by our best AP system and the PMI and FREQ base- lines. The activities in boldface were deemed correct (including Partial Match). For "book- store" and "pharmacy", all of the methods perform well. Note the challenge of recognizing that differ- ent phrases mean essentially the same thing (e.g., "fill prescription", "pick up prescription", "find medicine"). For "university" and "Meijer", the AP method produces more appropriate answers than the baseline methods. For "market" and "phone", all three methods struggle to produce good an- swers. Since "market" is polysemous, we see ac- tivities related to both stores and financial markets. And "phone" arguably is not a location at all, but most human annotators treated it as a virtual loca- tion, listing goal-acts related to telephones. How- ever our algorithm considered phones to be sim- ilar to computers, which makes sense for today's smartphones. In general, we also observed that In- ternet sites behave as virtual locations in language (e.g., "I went to YouTube...").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Discussion</head><p>The goal-acts learned by our system were ex- tracted from the Spinn3r dataset, while the gold standard answers were provided by human anno- tators, so the same (or very similar) activities are often expressed in different ways (see Section 4.3). This raises the question: what is the upper bound on system performance when evaluating against human-provided goal-acts? To answer this, we compared all of the activities that co-occurred with each location in the corpus against its gold goal- acts. Only 36% of locations had at least one gold goal-act among its extracted activities when matching identical strings (after lemmatization). Because of this issue, our Exact Match criteria also allowed for combining verbs and nouns from dif- ferent gold answers. Under this Exact Match crite- ria, 73% of locations had at least one gold goal-act  among the extracted activities, so this represents an upper bound on performance using this metric. Under the Partial Match criteria, 98% of locations had at least one gold goal-act among the extracted activities, but only 50% credit was awarded for these cases so the maximum score possible would be ∼86%.</p><p>We also manually inspected 200 gold loca- tions to analyze their types. We discovered some related groups, but substantial diversity overall. The largest group contains ∼20% of the loca- tions, which are many kinds of stores (e.g., Ikea, WalMart, Apple store, shoe store). Even within a group, different locations often have quite differ- ent sets of co-occurring activities. In fact, we dis- covered some spelling variants (e.g., "WalMart" and "wal mart"), but they also have substan- tially different activity vectors (e.g., because one spelling is much more frequent), so the model learns about them independently. 8 Other groups include restaurants (∼5%), home-related (e.g., bathroom) (∼5%), education (∼5%), virtual (e.g., Wikipedia) (∼3%), medical (∼3%) and landscape (e.g., hill) (∼3%). It is worth noting that our loca- tions were extracted by two syntactic patterns and it remains to be seen if this has brought in any bias -detecting location nouns (especially nominals)</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Percentage of locations that have at least one goal-act assigned by multiple annotators.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Scores for MRR and Top k results. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 :</head><label>4</label><figDesc>Examples of Top 3 hypothesized prototypical goal activities.</figDesc><table></table></figure>

			<note place="foot" n="1"> Not actual values, for illustration only.</note>

			<note place="foot" n="2"> We use the same value σ 2 = 0.03 as (Zhu et al., 2003).</note>

			<note place="foot" n="3"> This is a heuristic but is not always true.</note>

			<note place="foot" n="4"> Same distribution as in the whole location set.</note>

			<note place="foot" n="5"> We found that the workers rarely used the &quot;ERROR&quot; label, so setting this threshold to be 3 was a strong signal. 6 We tried using WordNet synsets to conflate phrases, but it didn&apos;t help much.</note>

			<note place="foot" n="7"> A lemmatization error for the verb &quot;enrolled&quot;. 8 Of course normalizing location names beforehand may be beneficial in future work.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We are grateful to Haibo Ding for valuable com-ments on preliminary versions of this work.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions and Future Work</head><p>We introduced the problem of learning prototypi- cal goal activities for locations. We obtained hu- man annotations and showed that people do as- sociate prototypical goal-acts with locations. We then created an activity profile framework and ap- plied a semi-supervised label propagation algo- rithm to iteratively update the activity strengths for locations. We demonstrated that our learning algo- rithm identifies goal-acts for locations more accu- rately than several baseline methods.</p><p>However, this problem is far from solved. Chal- lenges also remain in how to evaluate the accu- racy of goal knowledge extracted from text cor- pora. Nevertheless, our work represents a first step toward learning goal knowledge about lo- cations, and we believe that learning knowledge about plans and goals is an important direction for natural language understanding research. In future work, we hope to see if we can take advantage of more contextual information as well as other exter- nal knowledge to improve the recognition of goal- acts.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Plans and Goals in Understanding Episodes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bower</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Psychology</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="2" to="15" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The ICWSM 2011 Spinn3r Dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Burton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kasch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth Annual Conference on Weblogs and Social Media</title>
		<meeting>the Fifth Annual Conference on Weblogs and Social Media</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note>ICWSM-2011</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Subjective Understanding: Computer Models of Belief Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>Carbonell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979" />
		</imprint>
		<respStmt>
			<orgName>Yale University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Unsupervised Learning of Narrative Event Chains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL/HLT-2008)</title>
		<meeting>the 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL/HLT-2008)</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Unsupervised Learning of Narrative Schemas and Their Participants</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Ask, and Shall You Receive? Understanding Desire Fulfillment in Natural Language Text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Snigdha</forename><surname>Chaturvedi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Goldwasser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Processings of the 30th AAAI Conference on Artificial Intelligence (AAAI-2016)</title>
		<meeting>essings of the 30th AAAI Conference on Artificial Intelligence (AAAI-2016)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Script Application: Computer Understanding of Newspaper Stories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">Edward</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cullingford</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1978" />
		</imprint>
		<respStmt>
			<orgName>Yale University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Acquiring Knowledge of Affective Events from Blogs using Label Propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibo</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Processings of the 30th AAAI Conference on Artificial Intelligence (AAAI-2016)</title>
		<meeting>essings of the 30th AAAI Conference on Artificial Intelligence (AAAI-2016)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Building a Bank of Semantically Encoded Narratives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Elson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><surname>Mckeown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Conference on International Language Resources and Evaluation (LREC-2010)</title>
		<meeting>the Seventh Conference on International Language Resources and Evaluation (LREC-2010)</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Connotation Lexicon: A Dash of Sentiment Beneath the Surface Meaning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><forename type="middle">Seok</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Polina</forename><surname>Kuznetsova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL-2013)</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics (ACL-2013)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">May all your wishes come true: A study of wishes and how to recognize them</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Andrew B Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Fillmore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiting</forename><surname>Andrzejewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojin</forename><surname>Gibson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technologies</title>
		<meeting>Human Language Technologies</meeting>
		<imprint>
			<publisher>The</publisher>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<title level="m">Annual Conference of the North American Chapter of the Association for Computational Linguistics (HLT/NAACL-2009)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Automatically producing plot unit representations for narrative text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on Empirical Methods on Natural Language Processing (EMNLP-2010)</title>
		<meeting>the 2010 Conference on Empirical Methods on Natural Language Processing (EMNLP-2010)</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A Computational Model for Plot Units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Intelligence</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="466" to="488" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Skip n-grams and ranking functions for predicting script events</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bram</forename><surname>Jans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vuli´cvuli´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie</forename><forename type="middle">Francine</forename><surname>Moens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 13th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page">2012</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Plot Units and Narrative Summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wendy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lehnert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="293" to="331" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP Natural Language Processing Toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL-2014) System Demonstrations</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics (ACL-2014) System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">WordNet: A Lexical Database for English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">GloVe: Global Vectors for Word Representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods on Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page">2014</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Statistical script learning with multi-argument events</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Pichotta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics (EACL-2014)</title>
		<meeting>the 14th Conference of the European Chapter of the Association for Computational Linguistics (EACL-2014)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning Statistical Scripts with LSTM Recurrent Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Pichotta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Raymond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th AAAI Conference on Artificial Intelligence (AAAI-2016)</title>
		<meeting>the 30th AAAI Conference on Artificial Intelligence (AAAI-2016)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Modelling Protagonist Goals and Desires in First-Person Narrative</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elahe</forename><surname>Rahimtoroghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaqi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruimin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marilyn</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th Annual Meeting of the Special Interest Group on Discourse and Dialogue</title>
		<meeting>the 18th Annual Meeting of the Special Interest Group on Discourse and Dialogue</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">2017</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Semisupervised Polarity Lexicon Induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Delip</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepak</forename><surname>Ravichandran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 12th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Scripts, Plans, Goals and Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Roger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Schank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Abelson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1977" />
			<pubPlace>Lawrence Erlbaum</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Experiments in Graph-based Semi-supervised Learning Methods for Class-instance Acquisition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><forename type="middle">Pratim</forename><surname>Talukdar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL-2010)</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics (ACL-2010)</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Understanding Goal-based Stories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Wilensky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1978" />
		</imprint>
		<respStmt>
			<orgName>Yale University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Learning from Labeled and Unlabeled Data with Label Propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Semi-supervised Learning Using Gaussian Fields and Harmonic Functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John D</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th International Conference on Machine Learning (ICML-2003)</title>
		<meeting>the 20th International Conference on Machine Learning (ICML-2003)</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
