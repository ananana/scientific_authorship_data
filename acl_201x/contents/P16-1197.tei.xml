<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:02+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Evaluating Sentiment Analysis in the Context of Securities Trading</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>August 7-12, 2016. 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siavash</forename><surname>Kazemian</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Toronto</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shunan</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Toronto</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerald</forename><surname>Penn</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Toronto</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Evaluating Sentiment Analysis in the Context of Securities Trading</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2094" to="2103"/>
							<date type="published">August 7-12, 2016. 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>There are numerous studies suggesting that published news stories have an important effect on the direction of the stock market, its volatility, the volume of trades, and the value of individual stocks mentioned in the news. There is even some published research suggesting that automated sentiment analysis of news documents , quarterly reports, blogs and/or twit-ter data can be productively used as part of a trading strategy. This paper presents just such a family of trading strategies, and then uses this application to reexamine some of the tacit assumptions behind how sentiment analyzers are generally evaluated , in spite of the contexts of their application. This discrepancy comes at a cost.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The proliferation of opinion-rich text on the World Wide Web, which includes anything from product reviews to political blog posts, led to the growth of sentiment analysis as a research field more than a decade ago. The market need to quantify opinions expressed in social media and the blogosphere has provided a great opportunity for sentiment analy- sis technology to make an impact in many sectors, including the financial industry, in which interest in automatically detecting news sentiment in or- der to inform trading strategies extends back at least 10 years. In this case, sentiment takes on a slightly different meaning; positive sentiment is not the emotional and subjective use of laudatory language. Rather, a news article that contains pos- itive sentiment is optimistic about the future finan- cial prospects of a company. <ref type="bibr" target="#b25">Zhang and Skiena (2010)</ref> experimented with news sentiment to inform simple market neutral trading algorithms, and produced an impressive maximum yearly return of around 30% -even more when using sentiment from blogs and twitter data. They did so, however, without an appropri- ate baseline, making it very difficult to appreciate the significance of this number. Using a very stan- dard, and in fact somewhat dated sentiment ana- lyzer, we are regularly able to garner annualized returns over twice that percentage, and in a man- ner that highlights two of the better design deci- sions that <ref type="bibr" target="#b25">Zhang and Skiena (2010)</ref> made, viz., (1) their decision to trade based upon numerical SVM scores rather than upon discrete positive or nega- tive sentiment classes, and (2) their decision to go long (resp., short) in the n best-(worst-) ranking securities rather than to treat all positive (negative) securities equally.</p><p>On the other hand, we trade based upon the raw SVM score itself, rather than its relative rank within a basket of other securities as <ref type="bibr" target="#b25">Zhang and Skiena (2010)</ref> did, and we experimentally tune a threshold for that score that determines whether to go long, neutral or short. We sampled our stocks for both training and evaluation in two runs, one without survivor bias, the tendency for long po- sitions in stocks that are publicly traded as of the date of the experiment to pay better using histor- ical trading data than long positions in random stocks sampled on the trading days themselves. Most of the evaluations of sentiment-based trading either unwittingly adopt this bias, or do not need to address it because their returns are computed over very brief historical periods. We also provide ap- propriate trading baselines as well as Sharpe ratios <ref type="bibr" target="#b22">(Sharpe, 1966)</ref> to attempt to quantify the relative risk inherent to our experimental strategies. As tacitly assumed by most of the work on this sub- ject, our trading strategy is not portfolio-limited, and our returns are calculated on a percentage ba- sis with theoretical, commission-free trades.</p><p>It is important to understand at the outset, how- ever, that the purpose of this research was not to beat <ref type="bibr" target="#b25">Zhang and Skiena's (2010)</ref> returns (although we have), nor merely to conduct the first prop- erly controlled, sufficiently explicit, scientific test of the descriptive hypothesis that sentiment analy- sis is of benefit to securities trading (although, to our knowledge, we did). The main purpose of this study was in fact to reappraise the evaluation stan- dards used by the sentiment analysis community. It is not at all uncommon within this community to evaluate a sentiment analyzer with a variety of classification accuracy or hypothesis testing scores such as F-measures, SARs, kappas or Krippendorf alphas derived from human-subject annotations - even when more extensional measures are avail- able, such as actual market returns from historical data in the case of securities trading. With Holly- wood films, another popular domain for automatic sentiment analysis, one might refer to box-office returns or the number of award nominations that a film receives rather than to its star-rankings on review websites where pile-on and confirmation biases are widely known to be rampant. Are the opinions of human judges, paid or unpaid, a suf- ficient proxy for the business cases that actually drive the demand for sentiment analyzers?</p><p>We regret to report that they do not seem to be. As a case study to demonstrate this point (Sec- tion 4.3), we exhibit one particular modification to our experimental financial sentiment analyzer that, when evaluated against an evaluation test set sam- pled from the same pool of human-subject annota- tions as the analyzer's training data, returns poorer performance, but when evaluated against actual market returns, yields better performance. This should worry any researcher who relies on classifi- cation accuracies, because the improvements that they report, whether due to better feature selection or different pattern recognition algorithms, may in fact not be improvements at all. Differences in the amount or degree of improvement might arguably be rescalable, but Section 4.3 shows that such in- trinsic measures are not even accurate up to a de- termination of the delta's sign.</p><p>On the other hand, the results reported here should not be construed as an indictment of sen- timent analysis as a technology or its potential ap- plication. In fact, one of our baselines alterna- tively attempts to train the same classifier directly on market returns, and the experimental approach handily beats that, too. It is important to train on human-annotated sentiments, but then it is equally important to tune, and eventually evaluate, on an empirically grounded task-specific measure, such as market returns. This paper thus presents, to our knowledge, the first real proof that sentiment is worth analyzing in this or any other domain.</p><p>A likely machine-learning explanation for this experimental result is that whenever two unbiased estimators are pitted against each other, they often result in an improved combined performance be- cause each acts as a regularizer against the other. If true, this merely attests to the relative indepen- dence of task-based and human-annotated knowl- edge sources. A more HCI-oriented view, how- ever, would argue that direct human-subject anno- tations are highly problematic unless the annota- tions have been elicited in manner that is ecologi- cally valid. When human subjects are paid to an- notate quarterly reports or business news, they are paid regardless of the quality of their annotations, the quality of their training, or even their degree of comprehension of what they are supposed to be doing. When human subjects post film reviews on web-sites, they are participating in a cultural activ- ity in which the quality of the film under consider- ation is only one factor. These sources of annota- tion have not been properly controlled in previous experiments on sentiment analysis.</p><p>Regardless of the explanation, this is a lesson that applies to many more areas of NLP than just sentiment analysis, and to far more recent instances of sentiment analysis than the one that we based our experiments on here. Indeed, we chose sentiment analysis because this is an area that can set a higher standard; it has the right size for an NLP component to be embedded in real applications and to be evaluated properly. This is noteworthy because it is challenging to ex- plain why recent publications in sentiment anal- ysis research would so dramatically increase the value that they assign to sentence-level sentiment scoring algorithms based on syntactically compo- sitional derivations of "good-for/ bad-for" anno- tation <ref type="bibr" target="#b1">(Anand and Reschke, 2010;</ref><ref type="bibr" target="#b7">Deng et al., 2013)</ref>, when statistical parsing itself has spent the last twenty-five years staggering through a linguis- tically induced delirium as it attempts to document any of its putative advances without recourse to clear empirical evidence that PTB-style syntactic derivations are a reliable approximation of seman-tic content or structure.</p><p>We submit, in light of our experience with the present study, that the most crucial obstacle fac- ing the state of the art in sentiment analysis is not a granularity problem, nor a pattern recognition problem, but an evaluation problem. Those evalu- ations must be task-specific to be reliable, and sen- timent analysis, in spite of our careless use of the term in the NLP community, is not a task. Stock trading is a task -one of many in which a sen- timent analyzer is a potentially useful component. This paper provides an example of how to test that utility.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work in Financial Sentiment Analysis</head><p>Studies confirming the relationship between me- dia and market performance date back to at least <ref type="bibr" target="#b15">Niederhoffer (1971)</ref>, who looked at NY Times headlines and determined that large market changes were more likely following world events than on random days. Conversely, Tetlock (2007) looked at media pessimism and concluded that high media pessimism predicts downward prices. Tetlock (2007) also developed a trading strategy, achieving modest annualized returns of 7.3%. En- gle and Ng (1993) looked at the effects of news on volatility, showing that bad news introduces more volatility than good news. <ref type="bibr" target="#b5">Chan (2003)</ref> claimed that prices are slow to reflect bad news and stocks with news exhibit momentum. <ref type="bibr" target="#b2">Antweiler and Frank (2004)</ref> showed that there is a significant, but negative correlation between the number of mes- sages on financial discussion boards about a stock and its returns, but that this trend is economically insignificant. Aside from Tetlock (2007), none of this work evaluated the effectiveness of an actual sentiment-based trading strategy. There is, of course, a great deal of work on au- tomated sentiment analysis itself; see Pang and Lee (2008) for a survey. More recent develop- ments germane to our work include the use of in- formation retrieval weighting schemes ( <ref type="bibr" target="#b17">Paltoglou and Thelwall, 2010)</ref>, with which accuracies of up to 96.6% have models based upon Latent Dirichlet Allocation (LDA) ( <ref type="bibr" target="#b14">Lin and He, 2009)</ref>.</p><p>There has also been some work that analyzes the sentiment of financial documents without actu- ally using those results in trading strategies <ref type="bibr" target="#b13">(Koppel and Shtrimberg, 2004;</ref><ref type="bibr" target="#b0">Ahmad et al., 2006;</ref><ref type="bibr" target="#b11">Fu et al., 2008;</ref><ref type="bibr" target="#b16">O'Hare et al., 2009;</ref><ref type="bibr" target="#b8">Devitt and Ahmad, 2007;</ref><ref type="bibr" target="#b9">Drury and Almeida, 2011</ref>). As to the relationship between sentiment and stock price, <ref type="bibr" target="#b6">Das and Chen (2007)</ref> performed sentiment anal- ysis on discussion board posts. Using this, they built a "sentiment index" that computed the time- varying sentiment of the 24 stocks in the Morgan Stanley High-Tech Index (MSH), and tracked how well their index followed the aggregate price of the MSH itself. Their sentiment analyzer was based upon a voting algorithm, although they also dis- cussed a vector distance algorithm that performed better. Their baseline, the Rainbow algorithm, also came within 1 percentage point of their reported accuracy. This is one of the very few studies that has evaluated sentiment analysis itself (as opposed to a sentiment-based trading strategy) against mar- ket returns (versus gold-standard sentiment anno- tations). <ref type="bibr" target="#b6">Das and Chen (2007)</ref> focused exclusively on discussion board messages and their evaluation was limited to the stocks on the MSH, whereas we focus on Reuters newswire and evaluate over a wide range of NYSE-listed stocks and market capitalization levels. <ref type="bibr" target="#b4">Butler and Keselj (2009)</ref> try to determine sen- timent from corporate annual reports using both character n-gram profiles and readability scores. They also developed a sentiment-based trading strategy with high returns, but do not report how the strategy works or how they computed the re- turns, making the results difficult to compare to ours. Basing a trading strategy upon annual re- ports also calls into question the frequency with which the trading strategy could be exercised.</p><p>The work most similar to ours is <ref type="bibr" target="#b25">Zhang and Skiena's (2010)</ref>. They look at both financial blog posts and financial news, forming a market-neutral trading strategy whereby each day, companies are ranked by their reported sentiment. The strat- egy then goes long and short on equal numbers of positive-and negative-sentiment stocks, respec- tively. They conduct their trading evaluation over the period from 2005 to 2009, and report a yearly return of roughly 30% when using news data, and yearly returns of up to 80% when they use Twit- ter and blog data. Crucially, they trade based upon the ranked relative order of documents by senti- ment rather than upon the documents' raw senti- ment scores.</p><p>Zhang and Skiena (2010) compare their strategy to two baselines. The "Worst-sentiment" Strat- egy trades the opposite of their strategy: short on positive-sentiment stocks and long on negative sentiment stocks. The "Random-selection" Strat- egy randomly picks stocks to go long and short on. As trading strategies, these baselines set a very low standard. Our evaluation uses standard trading benchmarks such as momentum trading and hold- ing the S&amp;P, as well as oracle trading strategies over the same holding periods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method and Materials</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">News Data</head><p>Our dataset combines two collections of Reuters news documents. The first was obtained for a roughly evenly weighted collection of 22 small- , mid-and large-cap companies, randomly sam- pled from the list of all companies traded on the NYSE as of 10 th March, 1997. The second was obtained for a collection of 20 companies ran- domly sampled from those companies that were publicly traded in March, 1997 and still listed on 10 th March, 2013. For both collections of com- panies, we collected every chronologically third Reuters news document about them from the pe- riod March, 1997 to March, 2013. The news arti- cles prior to 10 th March, 2005 were used as train- ing data, and the news articles on or after 10 th March, 2005 were reserved as testing data. <ref type="bibr">1</ref> We split the dataset at a fixed date rather than ran- domly in order not to incorporate future news into the classifier through lexical choice.</p><p>In total, there were 1256 financial news docu- ments. Each was labelled by two human annota- tors as being negative, positive, or neutral in sen- timent. The annotators were instructed to gauge the author's belief about the company, rather than to make a personal assessment of the company's prospects. Only the 991 documents that were la- belled twice as negative or positive were used for training and evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Sentiment Analysis Algorithm</head><p>For each selected document, we first filter out all punctuation characters and the most common 429 stop words. Because this is a document- level sentiment scoring task, not sentence-level, <ref type="bibr">1</ref> An anonymous reviewer expressed concern about chronological bias in the training data relative to the test data because of this decision. While this may indeed influence our results, ecological validity requires us to situate all training data before some date, and all testing data after that date, be- cause traders only have access to historical data before mak- ing a future trade.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Representation Accuracy bm25 freq</head><p>81.143% term presence 80.164% bm25 freq sw 79.827% freq with sw 75.564% freq 79.276% <ref type="table">Table 1</ref>: Average 10-fold cross validation ac- curacy of the sentiment classifier using different term-frequency weighting schemes. The same folds were used in all feature sets.</p><p>our sentiment analyzer is a support-vector ma- chine with a linear kernel function implemented using SVM light (Joachims, 1999), using all of its default parameters. <ref type="bibr">2</ref> We have experimented with raw term frequencies, binary term-presence fea- tures, and term frequencies weighted by the BM25 scheme, which had the most resilience in the study of information-retrieval weighting schemes for sentiment analysis by <ref type="bibr" target="#b17">Paltoglou and Thelwall (2010)</ref>. We performed 10 fold cross-validation on the training data, constructing our folds so that each contains an approximately equal number of negative and positive examples. This ensures that we do not accidentally bias a fold. <ref type="bibr" target="#b20">Pang et al. (2002)</ref> use word presence features with no stop list, instead excluding all words with frequencies of 3 or less. <ref type="bibr" target="#b20">Pang et al. (2002)</ref> nor- malize their word presence feature vectors, rather than term weighting with an IR-based scheme like BM25, which also involves a normalization step. <ref type="bibr" target="#b20">Pang et al. (2002)</ref> also use an SVM with a linear kernel on their features, but they train and com- pute sentiment values on film reviews rather than financial texts, and their human judges also clas- sified the training films on a scale from 1 to 5, whereas ours used a scale that can be viewed as being from -1 to 1, with specific qualitative inter- pretations assigned to each number. <ref type="bibr" target="#b2">Antweiler and Frank (2004)</ref> use SVMs with a polynomial kernel (of unstated degree) to train on word frequencies relative to a three-valued classification, but they only count frequencies for the 1000 words with the highest mutual information scores relative to the classification labels. <ref type="bibr" target="#b4">Butler and Keselj (2009)</ref> also use an SVM trained upon a very different set of features, and with a polynomial kernel of degree 3.</p><p>As a sanity check, we measured our sentiment analyzer's accuracy on film reviews by training and evaluating on Pang and <ref type="bibr" target="#b18">Lee's (2004)</ref> film review dataset, which contains 1000 positively and 1000 negatively labelled reviews. Pang and Lee conveniently labelled the folds that they used when they ran their experiments. Using these same folds, we obtain an average accuracy of 86.85%, which is comparable to Pang and Lee's 86.4% score for subjectivity extraction. The pur- pose of this comparison is simply to demonstrate that our implementation is a faithful rendering of Pang and Lee's (2004) algorithm. <ref type="table">Table 1</ref> shows the performance of SVM with BM25 weighting on our Reuters evaluation set versus several baselines. All baselines are iden- tical except for the term weighting schemes used, and whether stop words were removed. As can be observed, SVM-BM25 has the highest sentiment classification accuracy: 80.164% on average over the 10 folds. This compares favourably with pre- vious reports of 70.3% average accuracy over 10 folds on financial news documents ( <ref type="bibr" target="#b13">Koppel and Shtrimberg, 2004</ref>). We will nevertheless adhere to normalized term presence for now, in order to stay close to Pang and Lee's (2004) implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Trading Algorithm</head><p>Overall, our trading strategy is simple: go long when the classifier reports positive sentiment in a news article about a company, and short when the classifier reports negative sentiment.</p><p>We will embed the aforementioned sentiment analyzer into three different trading algorithms. In Section 4.1, we use the discrete polarity re- turned by the classifier to decide whether go long/abstain/short a stock. In Section 4.2.1 we instead use the distance of the current document from the classifier's decision boundary reported by the SVM. These distances do have meaning- ful interpretations apart from their internal use in assigning class labels. Platt <ref type="bibr" target="#b21">(Platt, 1999</ref>) showed that they can be converted into posterior proba- bilities, for example, by fitting a sigmoid func- tion onto them, but we will simply use the raw distances. In Section 4.2.2, we impose a safety zone onto the interpretation of these raw distance scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In the experiments of this section, we will evaluate an entire trading strategy, which includes the senti- ment analyzer and the particulars of the trading al- gorithm itself. The purpose of these experiments is to refine the trading strategy itself and so the sentiment analyzer will be held constant. In Sec- tion 4.3, we will hold the trading strategy constant, and instead vary the document representation fea- tures in the underlying sentiment analyzer.</p><p>In all three experiments, we compare the per- position returns of the following four standard strategies, where the number of days for which a position is held remains constant:</p><p>1. The momentum strategy computes the price of the stock h days ago, where h is the hold- ing period. Then, it goes long for h days if the previous price is lower than the current price. It goes short otherwise.</p><p>2. The S&amp;P strategy simply goes long on the S&amp;P 500 for the holding period. This strat- egy completely ignores the stock in question and the news about it.</p><p>3. The oracle S&amp;P strategy computes the value of the S&amp;P 500 index h days into the future. If the future value is greater than the current day's value, then it goes long on the S&amp;P 500 index. Otherwise, it goes short.</p><p>4. The oracle strategy computes the value of the stock h days into the future. If the future value is greater than the current day's value, then it goes long on the stock. Otherwise, it goes short.</p><p>The oracle and oracle S&amp;P strategies are included as toplines to determine how close the experimen- tal strategies come to ones with perfect knowledge of the future. "Market-trained" is the same as "ex- perimental" at test time, but trains the sentiment analyzer on the market return of the stock in ques- tion for h days following a training article's publi- cation, rather than the article's annotation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experiment One: Utilizing Sentiment Labels</head><p>Given a news document for a publicly traded com- pany, the trading agent first computes the senti- ment class of the document. If the sentiment is positive, the agent goes long on the stock on the date the news is released; if negative, it goes short.  <ref type="table">Table 2</ref>: Returns and Sharpe ratios for the Experi- mental, baseline and topline trading strategies over 30, 5, 3, and 1 day(s) holding periods.</p><p>All trades are made based on the adjusted closing price on this date. We evaluate the performance of this strategy using four different holding periods: 30, 5, 3, and 1 day(s). The returns and Sharpe ratios are presented in <ref type="table">Table 2</ref> for the four different holding periods and the five different trading strategies. The Sharpe ratio is a return-to-risk ratio, with a high value in- dicating good return for relatively low risk. The Sharpe ratio is calculated as:</p><formula xml:id="formula_0">S = E[Ra−R b ] √ var(Ra−R b ) ,</formula><p>where R a is the return of a single asset and R b is the risk-free return of a 10-year U.S. Treasury note.</p><p>The returns from this experimental trading sys- tem are fairly low, although they do beat the base- lines. A one-way ANOVA test among the exper- imental, momentum and S&amp;P strategies using the percent returns from the individual trades yields p values of 0.06493, 0.08162, 0.1792, and 0.4164, respectively, thus failing to reject the null hypoth- esis that the returns are not significantly higher. 3 <ref type="figure">Figure 1</ref>: Percent returns for 1 day holding period versus market capitalization of the traded stocks.</p><p>Furthermore, the means and medians of all three trading strategies are approximately the same and centred around 0. The standard deviations of the experimental strategy and the momentum strategy are nearly identical, differing only in the thou- sandths digit. The standard deviations for the S&amp;P strategy differ from the other two strategies due to the fact that the strategy buys and sells the entire S&amp;P 500 index and not the individual stocks de- scribed in the news articles. There is, in fact, no convincing evidence that discrete sentiment class leads to an improved trading strategy from this or any other study with which we are familiar, based on their published details. One may note, how- ever, that the returns from the experimental strat- egy have slightly higher Sharpe ratios than either of the baselines.</p><p>One may also note that using a sentiment ana- lyzer mostly beats training directly on market data. This vindicates using sentiment annotation as an information source. <ref type="figure">Figure 1</ref> shows the market capitalizations of each individual trade's companies plotted against their percent return with a 1 day holding period. The correlation between the two variables is not significant. Returns for the other holding periods are similarly dispersed.</p><p>The importance of having good baselines is demonstrated by the fact that when we annualize our returns for the 3-day holding period, we get 70.086%. This number appears very high, but the annualized return from the momentum strategy is were unlikely to have been generated by chance from a nor- mal distribution centred at zero. 70.066% 4 , which is not significantly lower. <ref type="figure" target="#fig_0">Figure 2</ref> shows the percent change in share value plotted against the raw SVM score for the different holding periods. We can see a weak cor- relation between the two. For the 30 days, 5 days, 3 days, and 1 day holding periods, the correlations are 0.017, 0.16, 0.16, and 0.16, respectively. The line of best fit is shown. This prompts our next experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Utilizing SVM scores</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Experiment Two: Variable Single Threshold</head><p>Before, we labelled documents as positive (nega- tive) when the score was above (below) 0, because 0 was the decision boundary. But 0 might not be the best threshold, θ, for high returns. To deter- mine θ, we divided the evaluation dataset, i.e. the dataset with news articles dated on or after March 10, 2005, into two folds having an equal number of documents with positive and negative sentiment. We used the first fold to determine θ and traded using the data from the second fold and θ. For ev- ery news article, if the SVM score for that article is above (below) θ, then we go long (short) on the ap- propriate stock on the day the article was released. A separate theta was determined for each holding period. We varied θ from −1 to 1 in increments of 0.1. Using this method, we were able to obtain sig- nificantly higher returns. In order of 30, 5, 3, and 1 day holding periods, the returns were 0.057%, 1.107%, 1.238%, and 0.745% (p &lt; 0.001 in ev- ery case). This is a large improvement over the previous returns, as they are average per-position figures. <ref type="bibr">5</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Experiment Three: Safety Zones</head><p>For every news item classified, SVM outputs a score. For a binary SVM with a linear kernel func- tion f , given some feature vector x, f (x) can be viewed as the signed distance of x from the de- cision boundary <ref type="bibr" target="#b3">(Boser et al., 1992)</ref>. It is then possibly justified to interpret raw SVM scores as degrees to which an article is positive or negative.</p><p>As in the previous section, we separate the eval- uation set into the same two folds, only now we <ref type="bibr">4</ref> The momentum strategy has a different number of possi- ble trades in any actual calendar year because it is a function of the holding period. <ref type="bibr">5</ref> Training directly on market data, by comparison, yields -0.258%, -0.282%, -0.036% and -0.388%, respectively.  use two thresholds, θ ≥ ζ. We will go long when the SVM score is above θ, abstain when the SVM score is between θ and ζ, and go short when the SVM score is below ζ. This is a strict generaliza- tion of the above experiment, in which ζ = θ. For convenience, we will assume in this section that ζ = −θ, leaving us again with one parameter to estimate. We again vary θ from 0 to 1 in in- crements of 0.1. <ref type="figure" target="#fig_1">Figure 3</ref> shows the returns as a function of θ for each holding period on the devel- opment dataset. If we increased the upper bound on θ to be greater than 1, then there would be too few trading examples (less than 10) to reliably cal- culate the Sharpe ratio. Using this method with θ = 1, we were able to obtain even higher returns: 3.843%, 1.851%, 1.691, and 2.251% for the 30, 5, 3, and 1 day holding periods, versus 0.057%, 1.107%, 1.238%, and 0.745% in the second task- based experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Experiment Four: Feature Selection</head><p>In our final experiment, let us now hold the trad- ing strategy fixed (at the third one, with safety zones) and turn to the underlying sentiment ana- lyzer. With a good trading strategy in place, it is clearly possible to vary some aspect of the senti- ment analyzer in order to determine its best setting in this context. We will measure both market re- turn and classifier accuracy to determine whether they agree. Is the latter a suitable proxy for the for- mer? Indeed, we may hope that classifier accuracy will be more portable to other possible tasks, but then it must at least correlate well with task-based performance.</p><p>In addition to evaluating those feature sets at- tempted in Section 3.2, we now hypothesize that the passive voice may be useful to emphasize in our representations, as the existential passive can be used to evade responsibility. So we add to the   weighted vector the counts of word tokens ending in "n" or "d" as well as the total count of every conjugated form of the copular verb: "be", "is", "am", "are", "were", "was", and "been". These three features are superficial indicators of the passive voice. Clearly, we could have used a part-of-speech tagger to detect the passive voice more reliably, but we are more interested here in how well our task-based evaluation will cor- respond to a more customary classifier-accuracy evaluation, rather than finding the world's best in- dicators of the passive voice. <ref type="table" target="#tab_2">Table 3</ref> presents returns obtained from these 6 feature sets. The feature set with BM25-weighted term frequencies plus the number of copulars and tokens ending in "n", "d" (bm25 freq dnc) yields higher returns than any other representation at- tempted on the 5, 3, and 1 day holding periods, and the second-highest on the 30 days holding period. But it has the worst classification accuracy by far: a full 18 percentage points below term presence. This is a very compelling illustration of how mis- leading an intrinsic evaluation can be.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we examined sentiment analysis ap- plied to stock trading strategies. We built a bi- nary sentiment classifier that achieves high accu- racy when tested on movie data and financial news data from Reuters. In four task-based experiments, we evaluated the usefulness of sentiment analysis to simple trading strategies. Although high an- nual returns are achieved simply by utilizing sen- timent labels while trading, they can be increased by incorporating the output of the SVM's decision function. But classification accuracy alone is not an accurate predictor of task-based performance. This calls into question the suitability of intrinsic sentiment classification accuracy, particularly (as here) when the relative cost of a task-based eval- uation may be comparably low. We have also de- termined that training on human-annotated senti- ment does in fact perform better than training on market returns themselves. So sentiment analysis is an important component, but it must be tuned against task data.</p><p>Our price data only included adjusted opening and closing prices and most of our news data con- tain only the date of the article, with no specific time. This limits our ability to test much shorter- term trading strategies.</p><p>Deriving sentiment labels for supervised train- ing is an important topic for future study, as is inferring the sentiment of published news from stock price fluctuations instead of the reverse. We should also study how "sentiment" is defined in the financial world. This study has used a rather general definition of news sentiment, and a more precise definition may improve trading perfor- mance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Percent change of trade returns plotted against SVM values for the 1, 3, 5, and 30 day holding periods in Exp. 1. Graphs are cropped to zoom in.</figDesc><graphic url="image-6.png" coords="8,111.38,413.39,181.41,136.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Returns for different thresholds on the development data for 30, 5, 3, and 1 day holding periods in Exp. 2 with safety zone.</figDesc><graphic url="image-8.png" coords="8,111.38,553.51,181.41,136.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>BM25</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Sentiment classification accuracy (aver-
age 10-fold cross-validation) and trade returns of 
different feature sets and term frequency weight-
ing schemes in Exp. 3. The same folds were 
used for the different representations. The non-
annualized returns are presented in columns 3-6. 

</table></figure>

			<note place="foot" n="2"> There has been one important piece of work (Tang et al., 2015) on neural computing architectures for document-level sentiment scoring (most neural computing architectures for sentiment scoring are sentence-level), but the performance of this type of architecture is not mature enough to replace SVMs just yet.</note>

			<note place="foot" n="3"> An anonymous reviewer observed that Tetlock (2007) showed a statistically significant improvement from the use of sentiment, apparently contradicting this result. Tetlock&apos;s (2007) sentiment-based trading strategy used a safety zone (see Section 4.2.2), and was never compared to a realistic baseline or control strategy. Instead, Tetlock&apos;s (2007) significance test was conducted to demonstrate that his returns (positive in 12 of 15 calendar years of historical market data)</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research was supported by the Canadian Net-work Centre of Excellence in Graphics, Animation and New Media (GRAND).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Multi-lingual sentiment analysis of financial news streams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khurshid</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yousif</forename><surname>Almas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st International Conference on Grid in Finance</title>
		<meeting>the 1st International Conference on Grid in Finance</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Verb classes as evaluativity functor classes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Reschke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Interdisciplinary Workshop on Verbs: The Identification and Representation of Verb Features</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Is all that talk just noise? the information content of internet stock message boards</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Werner</forename><surname>Antweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Finance</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1259" to="1294" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A training algorithm for optimal margin classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><forename type="middle">E</forename><surname>Boser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><forename type="middle">M</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><forename type="middle">N</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fifth annual workshop on Computational learning theory, COLT &apos;92</title>
		<meeting>the fifth annual workshop on Computational learning theory, COLT &apos;92<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1992" />
			<biblScope unit="page" from="144" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Financial forecasting using character n-gram analysis and readability scores of annual reports</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Butler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vlado</forename><surname>Keselj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Canadian AI</title>
		<meeting>Canadian AI<address><addrLine>Kelowna, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Stock price reaction to news and no-news: Drift and reversal after headlines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wesley</forename><forename type="middle">S</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Financial Economics</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="223" to="260" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Yahoo! for amazon: Sentiment extraction from small talk on the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sanjiv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><forename type="middle">Y</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Science</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1375" to="1388" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Benefactive/malefactive event and writer attitude annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingjia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoonjung</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="120" to="125" />
		</imprint>
	</monogr>
	<note>Short Papers)</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Sentiment polarity identification in financial news: A cohesionbased approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ann</forename><surname>Devitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khurshid</forename><surname>Ahmad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL</title>
		<meeting>the ACL</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Identification of fine grained feature based event and sentiment phrases from business news stories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brett</forename><surname>Drury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Almeida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Web Intelligence, Mining and Semantics, WIMS &apos;11</title>
		<meeting>the International Conference on Web Intelligence, Mining and Semantics, WIMS &apos;11<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Measuring and testing the impact of news on volatility</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><forename type="middle">K</forename><surname>Engle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Finance</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1749" to="1778" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Discovering the correlation between stock time series and financial news</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tak-Chung</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ka</forename><forename type="middle">Ki</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fu-Lai</forename><surname>Sze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chak Man</forename><surname>Chak Man Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Web Intelligence</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="880" to="883" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Making large-scale svm learning practical. advances in kernel methodssupport vector learning, b. schölkopf and c. burges and a. smola</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><forename type="middle">Joachims</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Good news or bad news? let the market decide</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moshe</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Itai</forename><surname>Shtrimberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Spring Symposium on Exploring Attitude and Affect in Text</title>
		<imprint>
			<publisher>Press</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="86" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Joint sentiment/topic model for sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenghua</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th ACM conference on Information and knowledge management, CIKM &apos;09</title>
		<meeting>the 18th ACM conference on Information and knowledge management, CIKM &apos;09<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="375" to="384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The analysis of world events and stock prices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Niederhoffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Business</title>
		<imprint>
			<biblScope unit="page" from="193" to="219" />
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Topic-dependent sentiment analysis of financial blogs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Neil O&amp;apos;hare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Davy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Bermingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Páraic</forename><surname>Ferguson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cathal</forename><surname>Sheridan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">F</forename><surname>Gurrin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smeaton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st international CIKM workshop on Topicsentiment analysis for mass opinion measurement</title>
		<meeting>the 1st international CIKM workshop on Topicsentiment analysis for mass opinion measurement</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A study of information retrieval weighting schemes for sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Paltoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Thelwall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL</title>
		<meeting>the ACL</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1386" to="1395" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL</title>
		<meeting>the ACL</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="271" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Opinion mining and sentiment analysis. Foundations and trends in information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Thumbs up?: sentiment classification using machine learning techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shivakumar</forename><surname>Vaithyanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL-02 conference on Empirical methods in natural language processing</title>
		<meeting>the ACL-02 conference on Empirical methods in natural language processing<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
	<note>EMNLP &apos;02</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Platt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Large Margin Classifiers</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="61" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Mutual fund performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>William F Sharpe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of business</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="119" to="138" />
			<date type="published" when="1966" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Document modeling with gated recurrent neural network for sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1422" to="1432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Giving content to investor sentiment: The role of media in the stock market</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tetlock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Finance</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1139" to="1168" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Trading strategies to exploit blog and news sentiment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenbin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 4th International AAAI Conference on Weblogs and Social Media</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
