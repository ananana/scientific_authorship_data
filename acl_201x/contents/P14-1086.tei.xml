<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:45+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Query-Chain Focused Summarization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>June 23-25</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tal</forename><surname>Baumel</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="laboratory">Dept. of Computer Science Ben-Gurion University Beer-Sheva</orgName>
								<orgName type="institution">Ben-Gurion University Beer-Sheva</orgName>
								<address>
									<country>Israel, Israel, Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Cohen</surname></persName>
							<email>cohenrap@cs.bgu.ac.il</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="laboratory">Dept. of Computer Science Ben-Gurion University Beer-Sheva</orgName>
								<orgName type="institution">Ben-Gurion University Beer-Sheva</orgName>
								<address>
									<country>Israel, Israel, Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Elhadad</surname></persName>
							<email>elhadad@cs.bgu.ac.il</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="laboratory">Dept. of Computer Science Ben-Gurion University Beer-Sheva</orgName>
								<orgName type="institution">Ben-Gurion University Beer-Sheva</orgName>
								<address>
									<country>Israel, Israel, Israel</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Query-Chain Focused Summarization</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="913" to="922"/>
							<date type="published">June 23-25</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Update summarization is a form of multi-document summarization where a document set must be summarized in the context of other documents assumed to be known. Efficient update summarization must focus on identifying new information and avoiding repetition of known information. In Query-focused summa-rization, the task is to produce a summary as an answer to a given query. We introduce a new task, Query-Chain Summarization, which combines aspects of the two previous tasks: starting from a given document set, increasingly specific queries are considered, and a new summary is produced at each step. This process models exploratory search: a user explores a new topic by submitting a sequence of queries, inspecting a summary of the result set and phrasing a new query at each step. We present a novel dataset comprising 22 query-chains sessions of length up to 3 with 3 matching human summaries each in the consumer-health domain. Our analysis demonstrates that summaries produced in the context of such exploratory process are different from informative summaries. We present an algorithm for Query-Chain Summarization based on a new LDA topic model variant. Evaluation indicates the algorithm improves on strong base-lines.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In the past 10 years, the general objective of text summarization has been refined into more specific tasks. Such summarization tasks include: (i) Generic Multi Document Summarization: aims at summarizing a cluster of topically related documents, such as the top results of a search engine query; (ii) in Update Summarization, a set of documents is summarized while assuming the user has already read a summary of earlier doc- uments on the same topic; (iii) in Query-Focused Summarization, the summary of a documents set is produced to convey an informative answer in the context of a specific query. The importance of these specialized tasks is that they help us dis- tinguish criteria that lead to the selection of con- tent in a summary: centrality, novelty, relevance, and techniques to avoid redundancy.</p><p>We present in this paper a variant summariza- tion task which combines the two aspects of up- date and query-focused summarization. The task is related to exploratory search <ref type="bibr" target="#b16">(Marchionini, 2006</ref>). In contrast to classical information seek- ing, in exploratory search, the user is uncertain about the information available, and aims at learning and understanding a new topic <ref type="bibr" target="#b22">(White and Roth, 2009)</ref>. In typical exploratory search behavior, a user posts a series of queries, and based on information gathered at each step, de- cides how to further explore a set of documents. The metaphor of berrypicking introduced in <ref type="bibr" target="#b0">(Bates, 1989)</ref> captures this interactive process. At each step, the user may zoom in to a more specific information need, zoom out to a more general query, or pan sideways, in order to inves- tigate a new aspect of the topic.</p><p>We define Query-Chain Focused Summariza- tion as follows: for each query in an exploratory search session, we aim to extract a summary that answers the information need of the user, in a manner similar to Query-Focused Summariza- tion, while not repeating information already provided in previous steps, in a manner similar to Update Summarization. In contrast to query- focused summarization, the context of a sum-mary is not a single query, but the set of queries that led to the current step, their result sets and the corresponding summaries.</p><p>We have constructed a novel dataset of Query- Sets with matching manual summarizations in the consumer health domain <ref type="bibr" target="#b4">(Cline and Haynes, 2001</ref>). Queries are extracted from PubMed search logs ( <ref type="bibr" target="#b7">Dogan et al., 2009</ref>). We have ana- lyzed this manual dataset and confirm that sum- maries written in the context of berry-picking are markedly different from those written for similar queries on the same document set, but without the query-chain context.</p><p>We have adapted well-known multi-document algorithms to the task, and present baseline algo- rithms based on LexRank ( <ref type="bibr" target="#b8">Erkan and Radev, 2004</ref>), <ref type="bibr">KLSum and TopicSum (Haghighi and Vanderwende, 2009)</ref>. We introduce a new algo- rithm to address the task of Query-Chain Fo- cused Summarization, based on a new LDA topic model variant, and present an evaluation which demonstrates it improves on these baselines.</p><p>The paper is structured as follows. Section 2 formulates the task of Query-Chain Focused Summarization. Section 3 reviews related work. In Section 4, we describe the data collection pro- cess and the resulting dataset. We then present our algorithm, as well as the baseline algorithms used for evaluation. We conclude with evalua- tion and discussion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Query-Chain Summarization</head><p>In this work, we focus on the zoom in aspect of the exploratory search process described above. We formulate the Query-Chain Focused Summarization (QCFS) task as follows:</p><p>Given an ordered chain of queries Q and a set A typical example of query chain in the con- sumer health domain we investigate includes the following 3 successive queries: (Causes of asth- ma, Asthma and Allergy, Asthma and Mold Al- lergy). We consider a single set of documents relevant to the domain of Asthma as the refer- ence set D. The QCFS task consists of generat- ing one summary of D as an answer to each que- ry, so that the successive answers do not repeat information already provided in a previous an- swer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Previous Work</head><p>We first review the closely related tasks of Update Summarization and Query-Focused Summarization. We also review key summariza- tion algorithms that we have selected as baseline and adapted to the QCFS task.</p><p>Update Summarization focuses on identifying new information relative to a previous body of information, modeled as a set of documents. It has been introduced in shared tasks in <ref type="bibr">DUC 2007 and</ref><ref type="bibr">TAC 2008</ref>. This task consists of producing a multi-document summary for a document set on a specific topic, and then a multi-document summary for a different set of articles on the same topic published at later dates. This task helps us understand how update summaries iden- tified and focused on new information while re- ducing redundancy compared to the original summaries.</p><p>The TAC 2008 dataset includes 48 sets of 20 documents, each cluster split in two subsets of 10 documents (called A and B). Subset B docu- ments were more recent. Original summaries were generated for the A subsets and update summaries were then produced for the B subsets. Human summaries and candidate systems are evaluated using the Pyramid method ( <ref type="bibr" target="#b19">Nenkova and Passonneau, 2004</ref>). For automatic evaluation, ROUGE <ref type="bibr" target="#b13">(Lin, 2004</ref>) variants have been pro- posed <ref type="bibr" target="#b3">(Conroy et al., 2011</ref>). In contrast to this setup, QCFS distinguishes the subsets of docu- ments considered at each step of the process by facets of the underlying topic, and not by chro- nology. In addition, the document subsets are not identified as part of the task in QCFS (as op- posed to the explicit split in A and B subsets in Update Summarization).</p><p>Most systems working on Update Summariza- tion have focused on removing redundancy. <ref type="bibr">DualSum (Delort and Alfonseca, 2012</ref>) is notable in attempting to directly model novelty using a spe- cialized topic-model to distinguish words ex- pressing background information and those in- troducing new information in each document.</p><p>In Query-Focused Summarization (QFS), the task consists of identifying information in a doc- ument set that is most relevant to a given query. This differs from generic summarization, where one attempts to identify central information. QFS helps us distinguish models of relevance and centrality. Unfortunately, detailed analysis of the datasets produced for QFS indicates that these two notions are not strongly distinguished in practice: ( <ref type="bibr" target="#b9">Gupta et al., 2007)</ref> observed that in QFS datasets, up to 57% of the words in the doc- ument sets were closely related to the query (through simple query expansion). They note that as a consequence, a generic summarizer forms a strong baseline for such biased QFS tasks.</p><p>We address this limitation of existing QFS da- tasets in our definition of QCFS: we identify a chain of at least 3 related queries which focus on different facets of the same central topic and re- quire the generation of distinct summaries for each query, with little repetition across the steps.</p><p>A specific evaluation aspect of QFS measures responsiveness (how well the summary answers the specific query). QFS must rely on Infor- mation Retrieval techniques to overcome the scarceness of the query to establish relevance. As evidenced since ( <ref type="bibr" target="#b5">Daume and Marcu, 2006</ref>), Bayesian techniques have proven effective at this task: we construct a latent topic model on the basis of the document set and the query. This topic model effectively serves as a query expan- sion mechanism, which helps assess the rele- vance of individual sentences to the original que- ry.</p><p>In recent years, three major techniques have emerged to perform multi-document summariza- tion: graph-based methods such as LexRank <ref type="bibr" target="#b8">(Erkan and Radev, 2004</ref>) for multi document sum- marization and Biased-LexRank ( <ref type="bibr">Otterbacher et al., 2008</ref>) for query focused summarization, lan- guage model methods such as <ref type="bibr">KLSum (Haghighi and Vanderwende, 2009</ref>) and variants of KLSum based on topic models such as BayesSum <ref type="bibr" target="#b5">(Daume and Marcu, 2006</ref>) and TopicSum ( <ref type="bibr" target="#b10">Haghighi and Vanderwende, 2009</ref>).</p><p>LexRank is a stochastic graph-based method for computing the relative importance of textual units in a natural text. The LexRank algorithm builds a weighted graph í µí°º = (í µí±, í µí°¸) where each vertex in í µí± is a linguistic unit (in our case sen- tences) and each weighted edge in í µí°¸isµí°¸is a measure of similarity between the nodes. In our imple- mentation, we model similarity by computing the cosine distance between the í µí±í µí°¹ × í µí°¼í µí°·í µí°¹ vectors representing each node. After the graph is gener- ated, the PageRank algorithm ( <ref type="bibr" target="#b21">Page et al., 1999</ref>) is used to determine the most central linguistic units in the graph. To generate a summary we use the í µí± most central lexical units, until the length of the target summary is reached. This method has no explicit control to avoid redun- dancy among the selected sentences, and the original algorithm does not address update or query-focused variants. <ref type="bibr">Biased-LexRank (Otterbacher et al., 2008)</ref> makes LexRank sensitive to the query by introducing a prior belief about the ranking of the nodes in the graph, which reflects the similarity of sentences to the query. Pag- eRank spreads the query similarity of a vertex to its close neighbors, so that we rank higher sen- tences that are similar to other sentences which are similar to the query. As a result, Biased- LexRank overcomes the lexical sparseness of the query and obtained state of the art results on the DUC 2005 dataset.</p><p>KLSum adopts a language model approach to compute relevance: the documents in the input set are modeled as a distribution over words (the original algorithm uses a unigram distribution over the bag of words in documents D). KLSum is a sentence extraction algorithm: it searches for a subset of the sentences in D with a unigram distribution as similar as possible to that of the overall collection D, but with a limited length. The algorithm uses Kullback-Lieber (KL) diver- gence í µí°¾í µí°¿(í µí±||í µí±) = ∑ log í µí±¤ ( í µí±(í µí±¤) í µí±(í µí±¤) )í µí±(í µí±¤) to com- pute the similarity of the distributions. It searches for í µí± * = argmin |í µí±|&lt;í µí°¿ í µí°¾í µí°¿(í µí± í µí°· ||í µí± í µí± ). This search is performed in a greedy manner, adding sentences one by one to S until the length L is reached, and choosing the best sentence as measured by KL- divergence at each step. The original method has no update or query focusing capability, but as a general modeling framework it is easy to adapt to a wide range of specific tasks.</p><p>TopicSum uses an LDA-like topic model <ref type="bibr" target="#b1">(Blei et al. 2003</ref>) to classify words from a number of document sets (each set discussing a different topic) as either general non-content words, topic specific words and document specific word (this category refers to words that are specific to the writer and not shared across the document set). After the words are classified, the algorithm uses a KLSum variant to find the summary that best matches the unigram distribution of topic specif- ic words. This method improves the results of KLSum but it also has no update summary or query answering capabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Dataset Collection</head><p>We now describe how we have constructed a dataset to evaluate QCFS algorithms, which we are publishing freely. We selected to build our dataset in the Consumer Health domain, a popu- lar domain in the web <ref type="bibr" target="#b4">(Cline and Haynes 2001)</ref> providing medical information at various levels of complexity, ranging from layman and up to expert information, because consumer health il- lustrates the need for exploratory search.</p><p>The PubMed repository, while primarily serving the academic community, is also used by laymen to ask health related questions. The PubMed que- ry logs ( <ref type="bibr" target="#b7">Dogan et al., 2009</ref>) provide user queries with timestamps and anonymized user identifica- tion. They are publically available and include over 600K queries per day. In this dataset, Dogan and Murray found that query reformulation (typ- ical of exploratory search) is quite frequent: "In our dataset, 47% of all queries are followed by a new subsequent query. These users did not select any abstract or full text views from the result set. We make an operational assumption that these users' intent was to modify their search by re- formulating their query." We used these logs to extract laymen queries relating to four topics: Asthma, Lung Cancer, Obesity and Alzheimer's disease. We extracted a single day query log. From these, we extracted sessions which con- tained the terms "Asthma", "Lung Cancer", "Obesity" or "Alzheimer". Sessions containing search tags (such as " <ref type="bibr">[Author]</ref>") were removed to reduce the number of academic searches. The sessions were then manually examined and used to create zoom-in query chains of length 3 at most. The queries appear below:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Asthma:</head><p>Asthma causes→ asthma allergy→ asthma mold allergy;</p><p>Asthma treatment→asthma medication→corticosteroids;</p><p>Exercise induced asthma→ exercise for asthmatic;</p><p>Atopic dermatitis→ atopic dermatitis medications→ atopic dermatitis side effects;</p><p>Atopic dermatitis→ atopic dermatitis children→ atopic der- matitis treatment;</p><p>Atopic dermatitis → atopic dermatitis exercise activity → atopic dermatitis treatment;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cancer:</head><p>Lung cancer→ lung cancer causes→ lung cancer symptoms;</p><p>Lung cancer diagnosis→ lung cancer treatment→lung cancer treatment side effects;</p><p>Stage of lung cancer→ lung cancer staging tests→ lung can- cer TNM staging system;</p><p>Types of lung cancer→non-small cell lung cancer treat- ment→non-small cell lung cancer surgery;</p><p>Lung cancer in women→ risk factors for lung cancer in women→ treatment of lung cancer in women;</p><p>Lung cancer chemotherapy→ goals of lung cancer chemo- therapy→ palliative care for lung cancer;</p><p>Obesity:</p><p>Salt obesity→retaining fluid;</p><p>Obesity screening→body mass index→BMI Validity;</p><p>Childhood obesity→childhood obesity low income→chil- dren diet and exercise;</p><p>Causes of childhood obesity→obesity and nutrition→school lunch;</p><p>Obesity and lifestyle change→obesity metabolism→super- foods antioxidant;</p><p>Obesity and diabetes→emergence of type 2 diabetes→type 2 diabetes and obesity in children;</p><p>Alzheimer's disease:</p><p>Alzheimer memory→helping retrieve memory alzheimer →alzheimer memory impairment nursing;</p><p>Cognitive impairment→Vascular Dementia→Vascular De- mentia difference alzheimer;</p><p>Alzheimer's symptoms→alzheimer diagnosis→alzheimer medications;</p><p>Semantic dementia→first symptoms dementia→first symp- toms alzheimer; We asked medical experts to construct four document collections from well-known and reli- able consumer health websites relating to the four subjects (Wikipedia, WebMD, and the NHS), so that they would provide general infor- mation relevant to the queries.</p><p>We then asked medical students to manually produce summaries of these four document col- lections for each query-chain. The medical stu- dents were instructed construct a text of up to 250 words that provides a good answer to each query in the chain. For each query in a chain the summarizers should assume that the person read- ing the summaries is familiar with the previous summaries in the chain so they should avoid re- dundancy.</p><p>Three distinct human summaries were pro- duced for each chain. For each chain, one sum- mary was produced for each of the three queries, where the person producing the summary was not shown the next steps in the chain when an- swering the first query.</p><p>To simulate the exploratory search of the user we provided the annotators with a Solr 1 query interface for each document collection. The in- terface allowed querying the document set, read- ing the documents and choosing sentences which answer the query. After choosing the sentences, annotators can copy and edit the resulting sum- mary in order to create an answer of up to 250 words. After processing the first two query chain summaries, the annotators held a post-hoc dis- cussion about the different summaries in order to adjust their conception of the task. A key aspect of the dataset is that the same documents are summarized for each step of the chains, and we expect the summaries for each step to be different (that is, each answer is indeed responsive to the specific query it addresses). In addition, each answer is produced in the context of the previous steps, and only provides updated 1 http://lucene.apache.org/solr/ information with respect to previous answers. To ensure that the dataset indeed reflects these two aspects (responsiveness and freshness), we em- pirically verified that summaries created for ad- vanced queries are different from the summaries created for the same queries by summarizers who did not see the previous summaries in the chain. We asked from additional annotators to create manual summaries of advanced queries from the query chain without ever seeing the queries from the beginning of the chain. For example, given the chain (asthma causes → asthma allergy → asthma mold allergy), we asked summarizers to produce an answer for the second query (asthma allergy) without seeing the first step, on the same input documents.</p><p>We used ROUGE to perform this validation: ROUGE compares a summary with a set of ref- erence summaries and source documents. We first computed the mean ROUGE score of the second query summaries. The mean ROUGE score is the mean score of each manual summary vs. all other summaries about the same query. We got (í µí±1 = 0.52, í µí±2 = 0.22, í µí±í µí± 4 = 0.13). The mean ROUGE scores of the same second query summaries by people who did not see the previ- ous query were markedly lower: ( í µí±1 = 0.40, í µí±2 = 0.22, í µí±í µí± 4 = 0.01). We only verified the asthma dataset in this manner. The results, except for the R2 test, had statistically significant difference with 95% confidence interval. All the data, code and an annotated example can be found in our site 2 .</p><p>We show below slightly shortened manual summaries created in answer to the following query chain: "obesity screening -&gt; body mass index -&gt; BMI Validity". We manually annotated the summaries to highlight how the exploration process develops and indicate some of the infor- mation retrieval challenges faced when address- ing the task: underlined terms are directly rele- vant to the current query; bold italic terms have likely triggered the curiosity of the reader and led to asking the next query. In this example, a user asks about obesity screening, and reformulates his query using the technical term of BMI, which is prevalent in the produced answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Q1: obesity screening</head><p>Body mass index (BMI) is a measure used to determine childhood overweight and obesity. A child's weight status is determined using an age-and sex-specific percentile for BMI rather than the BMI categories used for adults because children's body composition varies as they age and varies between boys and girls. For children and ado- lescents (aged 2-19 years): Overweight is defined as a BMI at or above the 85th percentile and lower than the 95th percentile for children of the same age and sex. Obesity is defined as a BMI at or above the 95th percentile for children of the same age and sex. BMI is not a perfect measure, but rather a helpful indicator. It doesn't consider things like being muscular or having a larger than average body frame and because growth patterns vary greatly among children. As a result, doctors also factor a child's growth and development into consideration when screening for overweight and obesity. Obesity screening of adults using BMI may be less accurate for adults, due to the coarseness of the measurement: Heavily muscled athletes may have a high BMI, as many women who enter menopause, who tend to gain weight due to increased water retention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Q2: body mass index</head><p>The body mass index (BMI), or Quetelet index, is a meas- ure for human body shape based on an individu- al's mass and height. Devised in the mid-1800s by Adolphe Quetelet during the course of developing "social physics", it is defined as an individual's body mass divided by the square of their height, the units being kg/m^2. BMI was explicitly cited as being appropriate for population studies, and inappropriate for individual diagnosis. BMI provides a simple measure of a person's thickness, allowing health professionals to discuss over-weight and underweight problems more objectively with their patients. Howev- er, BMI has become controversial because many people, including physicians, have come to rely on its appar- ent authority for medical diagnosis. However, it was origi- nally meant to be used as a simple means of classifying sedentary individuals, or rather, populations, with an aver- age body composition. For these individuals, the current value settings are as follows: (...). Nick Korevaar (a mathe- matics lecturer from the University of Utah) suggests that instead of squaring the body height or cubing the body height, it would be more appropriate to use an exponent of between 2.3 and 2.7 (as originally noted by Quetelet).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Q3: BMI Validity</head><p>BMI has become controversial because many people, in- cluding physicians, have come to rely on its apparent nu- merical authority for medical diagnosis, but that was never the BMI's purpose; it is meant to be used as a simple means of classifying sedentary populations with an average body composition. In an article published in the July edi- tion of 1972 of the Journal of Chronic Diseases, Ancel Keys explicitly cited BMI as being appropriate for population studies, but inappropriate for individual diagnosis. These  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Algorithms</head><p>In this section, we first explain how we adapted the previously mentioned methods to the QCFS task, thus producing 3 strong baselines. We then describe our new algorithm for QCFS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Focused KLSum</head><p>We adapted KLSum to QCFS by introducing a simple document selection step in the algo- rithm. The method is: given a query step í µí±, we first select a focused subset of documents from í µí°·, í µí°·(í µí±). We then apply the usual KLSum algo- rithm over í µí°·(í µí±). This approach does not make any effort to reduce redundancy from step to step in the query chain. In our implementation, we compute í µí°·(í µí±) by selecting the top-10 documents in í µí°· ranked by í µí±í µí°¹ × í µí°¼í µí°·í µí°¹ scores to the query, as implemented in SolR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">KL-Chain-Update</head><p>KL-Chain-Update is a slightly more sophisti- cated variation of KLSum that answers a query chain (instead a single query). When construct- ing a summary, we update the unigram distribu- tion of the constructed summary so that it in- cludes a smoothed distribution of the previous summaries in order to eliminate redundancy be- tween the successive steps in the chain. For ex- ample, when we summarize the documents that were retrieved as a result to the first query, we calculate the unigram distribution in the same manner as we did in Focused KLSum; but for the second query, we calculate the unigram distribu- tion as if all the sentences we selected for the previous summary were selected for the current query too, with a damping factor. In this variant, the Unigram Distribution estimate of word X is computed as:</p><p>(Count(í µí±, í µí° ¶í µí±¢í µí±í µí±í µí±í µí±í µí±¡í µí±í µí±¢í µí±) + Count(í µí±, í µí±í µí±í µí±í µí±£í µí±í µí±í µí±¢í µí± í µí±í µí±¢í µí±) í µí±í µí±í µí±í µí±í µí±¡ℎí µí±í µí±í µí±í µí°¹í µí±í µí±í µí±¡í µí±í µí± )</p><p>Length(í µí° ¶í µí±¢í µí±í µí±í µí±í µí±í µí±¡í µí±í µí±¢í µí±) + Length(PreviousSum ∩ í µí° ¶í µí±¢í µí±í µí±í µí±í µí±í µí±¡í µí±í µí±¢í µí±) í µí±í µí±í µí±í µí±í µí±¡ℎí µí±í µí±í µí±í µí°¹í µí±í µí±í µí±¡í µí±í µí±</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">ChainSum</head><p>ChainSum is our adaptation of TopicSum to the QCFS task. We developed a novel Topic Model to identify words that are associated to the current query and not shared with the previous queries. We achieved this with the following model. For each query in a chain, we consider the documents í µí°· í µí± which are "good answers" to the query; and í µí°· í µí± which are the documents used to answer the previous steps of the chain. We assume in this model that these document subsets are observable (in our implementation, we select these subsets by ranking the documents for the query based on TFxIDF similarity).</p><p>1. í µí°º is the general words topic, it is intended to capture stop words and non-topic spe- cific vocabulary. Its distribution í µí¼ í µí°º is drawn for all the documents from í µí°·í µí±í µí±í µí±í µí±ℎí µí±í µí±í µí±¡(í µí±, í µí¼ í µí°º ).</p><p>2. í µí± í µí± is the document specific topic; it repre- sents words which are local for a specific document. í µí¼ í µí± í µí± is drawn for each docu- ment from í µí°·í µí±í µí±í µí±í µí±ℎí µí±í µí±í µí±¡(í µí±, í µí¼ í µí± í µí± ).</p><p>3. í µí± is the new content topic, which should capture words that are characteristic for í µí°· í µí± . í µí¼ í µí± is drawn for all the documents in í µí°· í µí± from í µí°·í µí±í µí±í µí±í µí±ℎí µí±í µí±í µí±¡(í µí±, í µí¼ í µí± ).</p><p>4. í µí± captures old content from í µí°· í µí± , í µí¼ í µí± is drawn for all the documents in í µí°· í µí± from í µí°·í µí±í µí±í µí±í µí±ℎí µí±í µí±í µí±¡(í µí±, í µí¼ í µí± ).</p><p>5. í µí± captures redundant information between í µí°· í µí± and í µí°· í µí± , í µí¼ í µí± is drawn for all the docu- ments in í µí°· í µí± ∪ í µí°· í µí± from í µí°·í µí±í µí±í µí±í µí±ℎí µí±í µí±í µí±¡(í µí±, í µí¼ í µí± ).</p><p>6. For documents from í µí°· í µí± we draw from the distribution í µí¼ í µí±¡ 1 over topics (í µí°º, í µí±, í µí± , í µí± í µí± ) from a Dirichlet prior with pseudo- counts (10.0,15.0,15.0,1.0) 3 . For each word in the document, we draw a topic í µí± from í µí¼ í µí±¡ , and a word í µí± from the topic in- dicated by í µí±.</p><p>3 All pseudo-counts were selected empirically 7. For documents from í µí°· í µí± , we draw from the distribution í µí¼ í µí±¡ 2 over topics (í µí°º, í µí±, í µí± , í µí± í µí± ) from a Dirichlet prior with pseudo- counts (10.0,15.0,15.0,1.0) . The words are drawn in the same manner as in í µí±¡ 1 .</p><p>8. For documents in í µí°· ∖ (í µí°· í µí± ∪ í µí°· í µí± ) we draw from the distribution í µí¼ í µí±¡ 3 over topics (í µí°º, í µí± í µí± ) from a Dirichlet prior with pseudo- counts (10.0,1.0) . The words are also drawn in the same manner as in í µí±¡ 1 .</p><p>The plate diagram of this generative model is shown in <ref type="figure" target="#fig_4">Fig.3</ref>. We implemented inference over this topic model using Gibbs Sampling (we distribute the code of the sampler together with our dataset). After the topic model is applied to the current query, we apply KLSum only on words that are assigned to the new content topic. <ref type="figure" target="#fig_5">Fig.4</ref> summa- rizes the algorithm data flow.</p><p>When running this topic model on our dataset, we observe: í µí°· í µí± mean size was 978 words and 375 unique words. í µí°· í µí± mean size was 1374 words and 436 unique words. í µí°· í µí± and í µí°· í µí± mean on average 159 words. These figures show there is high lexical overlap between the summaries answering query qi and qi+1 and highlight the need to distinguish new and previously exposed content.</p><p>In the ChainSum model, the topic R aims at modeling redundant information between the previous summaries and the new summary. We intend in the future to exploit this information to construct a contrastive model of content selec- tion. In the current version, R does not play an active role in content selection. We, therefore, tested a variant of ChainSum that did not in- clude í µí¼ í µí± and obtained results extremely similar to the full model, which we report below. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Adapted LexRank</head><p>In LexRank, the algorithm creates a graph where nodes represent the sentences from the text and weighted edges represent the cosine- distance of each sentence's TFxIDF vec- tors. After creating the graph, PageRank is run to rank sentences. We adapted LexRank to QCFS in two main ways: we extend the sentence represen- tation scheme to capture semantic information and refine the model of sentences similarity so that it captures query answering instead of cen- trality. We tagged each sentence with Wikipedia terms using the Illinois Wikifier <ref type="bibr">(Ratinov et al., 2011</ref>) and with UMLS <ref type="bibr" target="#b2">(Bodenreider, 2004</ref>) terms using HealthTermFinder <ref type="bibr" target="#b15">(Lipsky-Gorman and Elhadad, 2011</ref>). UMLS is a rich medical on- tology, which is appropriate to the consumer health domain.</p><p>We changed the edges scoring formula to use the sum of Lexical Semantic Similarity (LSS) functions ( <ref type="bibr" target="#b12">Li et al., 2007</ref>) on lexical terms, Wik- ipedia terms and UMLS terms: í µí±í µí±í µí±í µí±í µí±(í µí±, í µí±) = í µí°¿í µí±í µí± í µí±í µí±í µí±¥í µí±í µí±í µí±í µí± (í µí±, í µí±) + í µí± * í µí°¿í µí±í µí± í µí±¤í µí±í µí±í µí± (í µí±, í µí±) + í µí± * í µí°¿í µí±í µí± í µí±í µí±í µí°¿í µí± (í µí±, í µí±) Where: Instead of using the cosine distance, in order to incorporate advanced word/term similarity func- tions. For lexical terms, we used the identity function, for Wikipedia term we used Wikiminer <ref type="bibr" target="#b18">(Milne, 2007)</ref>, and for UMLS we used Ted Pedersen UMLS similarity function <ref type="bibr" target="#b17">(McInnes et al., 2009</ref>). Finally, instead of PageRank, we used SimRank <ref type="bibr">(Haveliwala, 2002</ref>) to identify the nodes most similar to the query node and not only the central sentences in the graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Evaluation Dataset</head><p>We worked on the dataset we created for QCFS and added semantic tags: 10% of the to- kens had Wikipedia annotations and 33% had a UMLS annotation. All of the modified ver- sions of our algorithm performed better than Fo- cused KLSum with more than 95% confidence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>We presented a new summarization task tai- lored for the needs of exploratory search system. This task combines elements of question answer- ing by sentence extraction with those of update summarization.</p><p>The main contribution of this paper is the def- inition of a new summarization task that corre- sponds to exploratory search behavior and the contribution of a novel dataset containing human summaries. This dataset is annotated with Wik- ipedia and UMLS terms for over 30% of the to- kens. We controlled that the summaries cover only part of the input document sets (and are, therefore, properly focused) and sensitive to the position of the queries in the chain. nificant improvement when penalizing redun- dancy with the previous summarization.</p><p>This paper concentrated on "zoom in" query chains, other user actions such as "zoom out" or "switch topic" were left to future work. This pa- per concentrated on "zoom in" query chains, oth- er user actions such as "zoom out" or "switch topic" were left to future work. The task remains extremely challenging, and we hope the dataset availability will allow further research to refine our understanding of topic-sensitive summariza- tion and redundancy control.</p><p>In future work, we will attempt to derive a task-specific evaluation metric that exploits the structure of the chains to better assess relevance, redundancy and contrast.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>of documents D , for each query Q q i  a sum- mary Si is generated from D answering i q under the assumption that the user has already read the summaries Si-1 for queries 1 0 ...  i q q .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Queries Used to Construct Dataset</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>ranges of BMI values are valid only as statistical categories While BMI is a simple, inexpensive method of screening for weight categories, it is not a good diagnostic tool: It does not take into account age, gender, or muscle mass. (...).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Query Chain Summary Annotated Example</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 Plate</head><label>3</label><figDesc>Figure 3 Plate Model for Our Topic Model</figDesc><graphic url="image-1.png" coords="7,306.10,250.36,224.04,133.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4</head><label>4</label><figDesc>Figure 4 ChainSum Architecture</figDesc><graphic url="image-2.png" coords="8,70.90,70.84,218.28,63.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: ROUGE Recall Scores (with stemming and stop-words) For Focused KLSum we received ROUGE scores of (r1 = 0.281, r2 = 0.061, su4 = 0.100), KL-Chain-Update (r1 = 0.424, r2 = 0.149, su4 = 0.193), ChainSum (r1 = 0.44988, r2 = 0.1587, su4 = 0.20594), ChainSum with t Simplified Topic model (r1 = 0.44992, r2 = 0.15814, su4 = 0.20507) and for Modified-LexRank (r1 = 0.444, r2 = 0.151, su4 = 0.201). All of the modified versions of our algorithm performed better than Focused KLSum with more than 95% confidence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Four</head><label></label><figDesc>methods were evaluated for the task. The baseline methods based on KL-Sum show a sig-</figDesc></figure>

			<note place="foot" n="2"> http://www.cs.bgu.ac.il/~nlpproj/QCFS/dataset.html</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported by the Israeli Minis-ter of Science (Grant #3-8705) and by the Lynn and William Frankel Center for Computer Sci-ences, Ben-Gurion University. We thank the reviewers for extremely helpful advice.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The design of browsing and berrypicking techniques for the online search interface</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcia</forename><forename type="middle">J</forename><surname>Bates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Online Information Review</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="407" to="424" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Latent dirichlet allocation, the</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine Learning research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The unified medical language system (UMLS): integrating biomedical terminology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Bodenreider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic acids research</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="267" to="270" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note>suppl 1</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Nouveau-rouge: A novelty metric for update summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">M</forename><surname>Conroy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judith</forename><forename type="middle">D</forename><surname>Schlesinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dianne</forename><forename type="middle">P</forename><surname>O&amp;apos;leary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Consumer health information seeking on the Internet: the state of the art</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Rebecca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katie</forename><forename type="middle">M</forename><surname>Cline</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Haynes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Health education research</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="671" to="692" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Bayesian queryfocused summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daume</forename><surname>Hal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics</title>
		<meeting>the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="305" to="312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">DualSum: a Topic-Model based approach for update summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Yves</forename><surname>Delort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enrique</forename><surname>Alfonseca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 13th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="214" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Understanding PubMed® user search behavior through log analysis, Database: The Journal of Biological Databases &amp; Curation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">Craig</forename><surname>Rezarta Islamaj Dogan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurélie</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyong</forename><surname>Névéol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">LexRank: Graph-based lexical centrality as salience in text summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Günes</forename><surname>Erkan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><forename type="middle">R</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Artif. Intell. Res.(JAIR)</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="457" to="479" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Measuring importance and query relevance in topic-focused multi-document summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Surabhi</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions</title>
		<meeting>the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="193" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Exploring content models for multi-document summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aria</forename><surname>Haghighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucy</forename><surname>Vanderwende</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="362" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">SimRank: a measure of structural-context similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Glen</forename><surname>Jeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Widom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the eighth ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="538" to="543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Machine learning based semantic inference: Experiments and Observations at RTE3</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoli</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Irwin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ernest</forename><forename type="middle">V</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashwin</forename><surname>Ram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing</title>
		<meeting>the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="159" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Rouge: A package for automatic evaluation of summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text Summarization Branches Out: Proceedings of the ACL-04</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Workshop</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="74" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">ClinNote and HealthTermFinder: a pipeline for processing clinical notes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Lipsky-Gorman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noémie</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
		<respStmt>
			<orgName>Columbia University Technical Report, Columbia University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Exploratory search: from finding to understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary</forename><surname>Marchionini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="41" to="46" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">UMLS-Interface and UMLSSimilarity: open source software for measuring paths and semantic similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bridget</forename><forename type="middle">T</forename><surname>Mcinnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ted</forename><surname>Pedersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Serguei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pakhomov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AMIA Annual Symposium Proceedings</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Computing semantic relatedness using wikipedia link structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Milne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the new zealand computer science research student conference</title>
		<meeting>the new zealand computer science research student conference</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Evaluating Content Selection in Summarization: The Pyramid Method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><forename type="middle">J</forename><surname>Passonneau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="145" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Biased LexRank: Passage retrieval using random walks with question-based priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jahna</forename><surname>Otterbacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gunes</forename><surname>Erkan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><forename type="middle">R</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="42" to="54" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Local and Global Algorithms for Disambiguation to Wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Brin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajeev</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Winograd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACL</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1375" to="1384" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
	<note>The PageRank citation ranking: bringing order to the web</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Exploratory search: Beyond the query-response paradigm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ryen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Resa</forename><forename type="middle">A</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthesis Lectures on Information Concepts, Retrieval, and Services</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="98" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
