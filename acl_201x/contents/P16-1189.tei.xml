<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:41+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Set-Theoretic Alignment for Comparable Corpora</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2009">2009-2018. August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thierry</forename><surname>Etchegoyhen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Vicomtech-IK4 Mikeletegi Pasalekua</orgName>
								<address>
									<addrLine>57 Donostia / San Sebastián</addrLine>
									<settlement>Gipuzkoa</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andoni</forename><surname>Azpeitia</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Vicomtech-IK4 Mikeletegi Pasalekua</orgName>
								<address>
									<addrLine>57 Donostia / San Sebastián</addrLine>
									<settlement>Gipuzkoa</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Set-Theoretic Alignment for Comparable Corpora</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<date type="published" when="2009">2009-2018. August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We describe and evaluate a simple method to extract parallel sentences from comparable corpora. The approach, termed STACC, is based on expanded lexical sets and the Jaccard similarity coefficient. We evaluate our system against state-of-the-art methods on a large range of datasets in different domains, for ten language pairs, showing that it either matches or outper-forms current methods across the board and gives significantly better results on the noisiest datasets. STACC is a portable method, requiring no particular adaptation for new domains or language pairs, thus enabling the efficient mining of parallel sentences in comparable corpora.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>With the rise of data-driven machine translation, be it statistical ( <ref type="bibr" target="#b2">Brown et al., 1990)</ref>, example- based <ref type="bibr" target="#b11">(Nagao, 1984)</ref>, or rooted in neural networks ( <ref type="bibr" target="#b1">Bahdanau et al., 2014</ref>), the need for large paral- lel corpora has increased accordingly. Although quality bitexts have been made available over the years ( <ref type="bibr" target="#b21">Tiedemann, 2012)</ref>, creating parallel corpora is a resource-consuming effort involving profes- sional human translation of large volumes of texts in multiple languages. As a consequence, there is still a lack of parallel data to properly model trans- lation across languages and domains.</p><p>To overcome this limitation, special emphasis has been placed in the last two decades on the exploitation of comparable corpora, with the de- velopment of a range of methods to mine paral- lel sentences from texts addressing similar topics in different languages. The work we present fol- lows this line of research, describing and evaluat- ing a simple method that allows parallel sentences to be efficiently mined in different languages and domains with minimal adaptation effort.</p><p>The method we describe, termed STACC, is based on expanded lexical sets and the Jaccard similarity coefficient <ref type="bibr" target="#b5">(Jaccard, 1901)</ref>, which is computed as the ratio of set intersection over union. We evaluate this simple approach against state-of-the-art methods for comparable sentence alignment on a variety of datasets for ten dif- ferent language pairs, showing that STACC either matches or outperforms competing approaches.</p><p>The paper is organised as follows: Section 2 de- scribes related work on parallel sentence mining in comparable corpora; Section 3 presents the STACC method; Section 4 describes the experiments in comparable sentence alignment, including the de- scription of test corpora and systems, and an anal- ysis of the results; Section 5 presents results ob- tained with an optimised version of the alignment process, beyond system comparison; finally, Sec- tion 6 draws conclusions from the work described in the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>A large variety of techniques have been proposed to mine parallel sentences in comparable cor- pora. One of the first approaches was proposed by <ref type="bibr" target="#b22">(Zhao and Vogel, 2002</ref>), who combined sen- tence length and bilingual lexicon models under a maximum likelihood criterion. ( <ref type="bibr" target="#b9">Munteanu and Marcu, 2002</ref>) explored the use of suffix trees, later opting for maximum entropy-based binary classi- fication using a modified version of IBM Model 1 word translation probabilities ( <ref type="bibr" target="#b3">Brown et al., 1993)</ref> and both general and alignment-specific features ( <ref type="bibr" target="#b10">Munteanu and Marcu, 2005)</ref>. ( <ref type="bibr" target="#b4">Fung and Cheung, 2004</ref>) describe the first approach to tackle paral- lel sentence mining in very non-parallel corpora, using cosine similarity as their sentence selection criterion.</p><p>Several approaches have employed full statisti- cal machine translation models instead of relying only on lexical tables. <ref type="bibr" target="#b0">(Abdul-Rauf and Schwenk, 2009)</ref>, for instance, apply the TER metric <ref type="bibr" target="#b19">(Snover et al., 2006</ref>) on fully machine translated output to identify parallel sentences; ( <ref type="bibr" target="#b16">Sarikaya et al., 2009</ref>) use a similar approach but with BLEU ( <ref type="bibr" target="#b13">Papineni et al., 2002</ref>) as their similarity metric. One of the noted advantages of including full machine trans- lation is the ability to better model the complex factors found in translation, e.g. fertility and con- textual information, as compared to lexicon-based approaches. The latter enable, in principle, the capture of a larger set of lexical translation vari- ants, and do not require the training of complete translation models.</p><p>Sophisticated feature-based approaches have been developed in recent years in order to provide a method that may apply to larger sets of language pairs and domains. <ref type="bibr" target="#b20">(Stef˘ anescu et al., 2012</ref>) re- port improvements over previous methods with a feature-based sentence similarity measure, an ap- proach which is described in more detail in Sec- tion 4.2.1. Another feature-rich approach is de- scribed in <ref type="bibr" target="#b18">(Smith et al., 2010)</ref>, showing improve- ments over standard and improved binary classi- fiers; we describe their model in more details in Section 4.2.2. Jaccard similarity, a core component of the ap- proach we describe, has been standardly used as a text similarity measure in information retrieval and text summarisation tasks, or to compute se- mantic similarity <ref type="bibr" target="#b15">(Pilehvar et al., 2013</ref>). For com- parable corpora, it has been notably employed by <ref type="bibr" target="#b14">(Paramita et al., 2013)</ref>, who estimate document comparability by computing the coefficient on a subset of translated source sentences, discarding those containing large amounts of named enti- ties or numbers, and taking the average of these sentence-level scores. The method we present in the next section builds on a related similarity mea- sure as a direct indicator of comparable sentence similarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">STACC</head><p>STACC is an approach to sentence similarity based on expanded lexical sets, whose main goal is to provide a simple yet effective procedure that can be applied across domains and corpora with mini- mal adaptation and deployment costs.</p><p>We start with the minimal set of bilingual infor- mation that can be automatically extracted from a seed parallel corpus, using lexical translations determined and ranked according to IBM models; word translations are computed in both directions using the GIZA++ toolkit <ref type="bibr" target="#b12">(Och and Ney, 2003)</ref>.</p><p>STACC relies on the Jaccard index, which de- fines set similarity as the ratio of set intersection over union. We base our comparable sentence similarity measure strictly on this index, applying it to expanded lexical sets as described below.</p><p>Let s i and s j be two tokenised and truecased sentences in languages l 1 and l 2 , respectively, S i the set of tokens in s i , S j the set of tokens in s j , T ij the set of expanded translations into l 2 for all tokens in S i , and T ji the set of expanded transla- tions into l 1 for all tokens in S j . The STACC simi- larity score is then computed as in Equation 1:</p><formula xml:id="formula_0">sim stacc = |T ij ∩S j | |T ij ∪S j | + |T ji ∩S i | |T ji ∪S i | 2 (1)</formula><p>That is, the score is defined as the average of the Jaccard similarity coefficients obtained between sentence token sets and expanded lexical transla- tions in both directions.</p><p>The translation sets T ij and T ji are initially computed from sentences s i and s j by retain- ing the k-best lexical translations found in GIZA tables, if any. Lexical translations are selected according to the ranking provided by the pre- computed lexical probabilities but the specific probability values are not used any further to compute similarity: 1 all potential translations are members of the translation set as tokens. Discard- ing this source of potentially exploitable informa- tion is mostly motivated by the relative reliabil- ity of lexical translation probabilities across do- mains. Lexical translations are usually extracted from a different domain than that of the compa- rable corpora at hand, typically using profession- ally created institutional corpora such as Europarl ( <ref type="bibr" target="#b6">Koehn, 2005)</ref>, and lexical distributions across domains can be expected to be quite different. This casts doubt on the usefulness of using pre- computed translation probabilities and simple set membership was favoured in our approach.</p><p>The initial lexical translation sets undergo a first expansion step to capture morphological variation, using longest common prefix matching (hereafter, LCP). To apply prefix matching to the minimal set of elements necessary, we compute the following two set differences:</p><p>• Set of elements in the source to target trans- lation set that are not members of the target token set: T ij = T ij − S j • Set of elements in the target to source trans- lation set that are not members of the source token set:</p><formula xml:id="formula_1">T ji = T ji − S i For each element in T ij (respectively T ji )</formula><p>and each element in S j (respectively S i ), if a common prefix is found with a minimal length of more than n characters, the prefix is added to both translation sets. <ref type="bibr">2</ref> This simplified approach to stemming removes the need to rely on manually constructed endings lists to compute similarity or on a complete mor- phological analyser, which might not be avail- able at all for under-resourced languages. It is also computationally more efficient as it exploits the nature of the alignment problem to reduce the search space: instead of matching each source and target word against every potential ending, with hundreds of possible endings in some languages, only the prefixes of word pairs within the sub- sets created through set difference need to be com- pared using LCP.</p><p>Another set expansion operation is defined to handle named entities, which are strong indicators of potential alignment, given their low relative fre- quency, and are likely to be missing from transla- tion tables trained on a different domain. While creating the previously defined lexical translation sets from truecased sentences, capitalised tokens that are not found in the translation tables are added to the translation sets. Numbers are simi- larly handled and added to the expanded sets, as they can also act as alignment indicators, in par- ticular when they denote dates.</p><p>These two expansions steps are essential to a successful use of Jaccard similarity for compara- ble sentence alignment. For instance, LCP gives a 2.9 points improvement in F1 measure on the initial Basque-Spanish test set described in Sec- tion 4.1, whereas the NE/Number expansion re- sulted in a 1.3 points gain; the two expansions combined gave a 4.3 points increase in terms of F1 measure. For the English-Bulgarian pair on the initial Wikipedia test set, the gains were 3.7, 2.6 and 5.5, respectively. Combining the two oper- ations thus contributed to the improvements over the state of the art described in Section 4.3.</p><p>No additional operations are performed on the created sets, and in particular no filtering is ap- plied, with punctuation and functional words kept alongside content words in the final sets. This no- tably eliminates the use of stop word lists from the computation of similarity.</p><p>Although it builds on fairly standard ideas, such as the use of GIZA tables or the Jaccard index, the approach is original in its conjoined use of these elements with surface-based information and sim- ple set-theoretic operations to form a similarity as- sessment mechanism that proved efficient on com- parable corpora, as shown in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Comparable sentence alignment</head><p>We performed a systematic comparison be- tween different approaches to comparable sen- tence alignment on a variety of comparable cor- pora and language pairs. This section describes the components of the experimental setup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Corpora</head><p>Three core sets of corpora were used in the evalu- ation, which we describe in turn. The selected test sets, all manually aligned, were used in different settings with gradual amounts of alignment noise added to the original sets. The goal of noisification is to assess the behavior of each approach in differ- ent scenarios and evaluate their ability to properly align data from ideal conditions to gradually nois- ier environments, the latter being a more realistic case when dealing with comparable corpora.</p><p>The first corpus consists in the public datasets created within the Accurat project. <ref type="bibr">3</ref> The corpus covers 7 language pairs, each one composed of English and an under-resourced language. The datasets contain manually verified alignments that were created from news articles. We noisi- fied these datasets by adding sentences from the  1000-1500 <ref type="table">Table 3</ref>: EITB evaluation sets original comparable corpora collected within the project, creating the following additional variants: (i) a 2:1 noisified version, where for each sentence in the original sets, 2 additional sentences without corresponding alignments were added; and (ii) a 100:1 noisified version with 100 sentences added for each sentence in the test sets. For each lan- guage pair, the additional sentences were taken from the initial portion of the selected additional corpora in one language and the final portion in the other language. For the 2:1 datasets, and the 100:1 variants in some language pairs, the original comparable corpora were used as additional data. For other language pairs, creating the 100:1 vari- ant required adding sentences from different cor- pora to reach the required amount of data. <ref type="table">Table 1</ref> describes the final datasets used in the evaluation. <ref type="bibr">4</ref> As a second corpus, we used the data described in ( <ref type="bibr" target="#b18">Smith et al., 2010)</ref>. <ref type="bibr">5</ref> The texts were ex- tracted from Wikipedia articles in 3 language pairs (English-German, English-Spanish and English- Bulgarian) and manually annotated for paral- lelism. We used the provided test sets (here- after, WTS) and added a 100:1 noisified variant us- ing sentences from the News Crawl corpus 6 for English-German and English-Spanish, and from Europarl for the English-Bulgarian pair. describes these datasets, to which we will refer collectively as the Wikipedia corpus.</p><note type="other">TEST SETS EN-DE EN-EL EN-ET EN-LT EN-LV EN-RO EN-</note><p>Finally, we used the EITB corpus, composed of news generated by the Basque Country's public broadcasting service. <ref type="bibr">7</ref> The news are written in- dependently in Basque and Spanish but refer to the same specific events and the corpus can thus be categorized as strongly comparable. We de- fined initial test sets of 500 manually aligned sen- tences in each language, and created two noisified variants: (i) a test set with 500 additional sen- tences in both languages, and (ii) a test set with 500 additional sentences in Spanish and 1000 in Basque. All additional sentences were taken from unaligned portions of the same EITB corpus. Ta- ble 3 summarises the EITB test sets.</p><p>The selected corpora thus cover 10 different lan- guage pairs and different domains, with varying degrees of noisification, and provide for a large and diverse comparison set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Systems</head><p>Three approaches were evaluated against the pre- viously described corpora: LEXACC (Stef˘ anescu et al., 2012), the STACC method described in Sec- tion 3, and the approach based on Conditional Random Fields described in ( <ref type="bibr" target="#b18">Smith et al., 2010</ref>), to which we will refer as CRF. The latter was only evaluated on the Wikipedia corpus, using the re-sults reported in the aforementioned article, as the tools to apply this method were not available to us; both LEXACC and STACC were evaluated on all test sets.</p><p>LEXACC was selected given its reported perfor- mance and its aim at portability across domains and language pairs; the system is also available as part of the Accurat toolkit, <ref type="bibr">8</ref> which allowed for a direct comparison with STACC on all datasets.</p><p>The CRF approach has proven more effec- tive than standard classifier-based methods on the Wikipedia datasets, with published results on pub- lically available test sets, and was thus selected as an alternative approach to comparable sentence alignment.</p><p>Both approaches are based on sophisticated methods with demonstrated improvements over the state-of-the-art, thus providing strong base- lines for system comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">LEXACC</head><p>LEXACC is a fast parallel sentence mining system based on a cross-linguistic information retrieval (CLIR) approach. It uses the Lucene search en- gine 9 in two major steps: target sentences are first indexed by the search engine, and a search query is built from a translation of content words in the source sentence to retrieve alignment candidates. The query is constructed using IBM Model 1 lexi- cal translation tables, extracted from seed parallel corpora</p><p>The alignment metric in LEXACC is a transla- tion similarity measure based on 5 feature func- tions briefly described here (see <ref type="bibr" target="#b20">(Stef˘ anescu et al., 2012</ref>) for a detailed description):</p><p>• f 1 measures source-target candidate pairs strength in terms of content word translation and string similarity;</p><p>• f 2 is similar to f 1 but applies to functional words, as identified in manually created stop word lists;</p><p>• f 3 measures content word alignment oblique- ness defined as a discounted correlation mea- sure;</p><p>• f 4 is a binary feature that compares the num- ber of initial/final aligned word translations over a pre-defined threshold;</p><p>• f 5 is a second binary feature which evaluates if the source and target sentences end with the same punctuation.</p><p>The similarity measure is then computed ac- cording to the sum of weighted feature functions, with optimal weights determined by means of lo- gistic regression. We used the optimal feature weights described in <ref type="figure">(Stef˘ anescu et al., 2012)</ref> for the language pairs in the Accurat corpus and the provided default weights for English-Spanish and English-Bulgarian; for Basque-Spanish, optimal weights were estimated through logistic regression on a training set formed with 9500 positive paral- lel examples from the IVAP corpus <ref type="bibr">10</ref> and an equal amount of non-parallel negative examples.</p><p>For the experiments, all lexical translation ta- bles were created with GIZA++ on the JRC-Acquis Communautaire corpus. 11 Lucene searches were set to return a maximum of 100 candidates for each source sentence. We used the default setup for LEXACC, except for two minor changes. First, we removed the initial Lucene search constraint which was set to discard identical source and tar- get sentences, a setting which prevented the re- trieval of valid news candidates such as sports re- sults. Secondly, we increased the length ratio filter from 1.5 to 7.5, as the initial value was too restric- tive for the Basque-Spanish corpus. Both changes were thus meant to retrieve the most accurate set of alignment candidates, in order to get meaning- ful results on the test sets with both methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Conditional Random Fields</head><p>The model we refer to as CRF ( <ref type="bibr" target="#b18">Smith et al., 2010</ref>) is a first order linear chain Conditional Random Field ( <ref type="bibr" target="#b7">Lafferty et al., 2001</ref>), where for each source sentence a hidden variable indicates the corre- sponding target sentence to which it is aligned, or null if there is no such target sentence. This sys- tem was compared to the standard binary classifier of (Munteanu and <ref type="bibr" target="#b10">Marcu, 2005</ref>) and to a ranking variant designed by the authors to avoid class im- balance issues that arise with binary classification. On the Wikipedia test sets, the CRF approach gave the best results overall and was thus selected for our system comparison.</p><p>The sequence model comprises the following features:</p><p>• A word alignment feature set, based on IBM Model 1 and HMM alignments, which in- cludes: log probability of the alignment; number of aligned/unaligned words; longest aligned/unaligned sequence of words; and number of words for different degrees of fer- tility.</p><p>• Two sentence-related features: source and target length ratio modeled through a Pois- son distribution <ref type="bibr" target="#b8">(Moore, 2002)</ref>, and relative position of source and target sentences in the document.</p><p>• A set of distortion features measuring the dif- ference in position between the previous and current aligned sentences.</p><p>• A set of features based on Wikipedia markup, including matching and non-matching links for alignment candidates.</p><p>• A set of lexicon features based on a prob- abilistic model of word pair alignments, trained on a set of annotated Wikipedia ar- ticles. The lexicon-based feature set includes the HMM translation probability, word-based positional differences, orthographic similar- ity, context translation similarity and distri- butional similarity.</p><p>The seed parallel data were based on the Eu- roparl corpus for Spanish and German and the JRC-Aquis corpus for Bulgarian. The authors also included article titles of parallel Wikipedia doc- uments and Wiktionary translations as additional seed data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">STACC</head><p>In order to establish a fair comparison between LEXACC and STACC, all shared settings were iden- tical. Thus, lexical translations were based on the same previously described GIZA tables extracted from the JRC corpus, and STACC alignment was performed on the same sets of candidates retrieved from the Lucene searches by LEXACC for each language pair.</p><p>As described in Section 3, STACC is based on the k-best translations provided by lexical transla- tion tables. For the experiments, k was set to 5, a value arbitrarily determined to be an optimal com- promise between overcrowding the sets with un- likely translations and limiting translation candi- dates to minimal translation variants. Experiment- ing with different values on the test sets showed that this value for k was not actually the optimal one for some language pairs, with e.g. a 2.9 point gain in F1 measure when setting k to 2 for English- Greek on the initial Accurat test set. <ref type="bibr">12</ref> The results we present in the next section are thus not the best achievable ones using the STACC approach. Nonetheless, we maintained the use of a default value because of the lack of in-domain development sets on which an optimal value could be fairly computed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results</head><p>To evaluate the accuracy of the tested methods, precision was taken as the ratio of correct align- ments over predicted alignments, and recall as the ratio of correct alignments over true alignments. We present results in terms of F1 measure, as we seek an optimal balance between alignment preci- sion and recall. <ref type="table" target="#tab_4">Table 4</ref> presents the results on the Accurat test sets for LEXACC and STACC using their respec- tive optimal similarity thresholds. <ref type="bibr">13</ref> On the 21 test sets, the two systems were tied on two oc- casions, with STACC obtaining better results in 89.5% of the remaining cases. On the noisiest datasets, STACC was consistently and markedly better across language pairs.</p><p>The results on the Wikipedia test sets are shown in <ref type="table" target="#tab_5">Table 5</ref>. For English-Spanish and English- German, both approaches performed quite simi- larily on the initial test sets, with STACC obtaining the best results on the noisier sets.</p><p>The results for English-Bulgarian are interest- ing, as this is the only case where LEXACC outper- forms STACC on both the clean and noisy datasets. The data used for noisification in this case may have had an effect on the results. Data extracted from Europarl, which compose the entire noisifi- <ref type="table">EN-DE  EN-EL  EN-ET  EN-LT  EN-LV  EN-RO  EN-SL   LEXACC   1:1</ref>     79.5  <ref type="figure">Figure 1</ref>: STACC optimisation results on the Accurat 100:1 test sets cation set for this language pair, is closer to the JRC vocabulary than the original comparable data on which the alignment process would take place in real-world conditions. Although we have not thoroughly tested the impact of this variable, it is possible that those datasets are more confusing for an approach such as STACC, which is based mostly on lexical information extracted from seed paral- lel data, than for a feature-based approach where some features, like the boolean punctuation-based ones in LEXACC, may compensate for erroneous alignments due to artificial domain vocabulary overlap. Determining if this hypothesis is indeed correct would require further experiments beyond the scope of this paper To include the CRF approach in the comparison, we used two of the provided measures, namely re- call obtained at precisions of 80 and 90 percent on the 1:1 test sets. <ref type="bibr">14</ref> We report results obtained with the best variant of CRF, namely the model which includes Wikipedia and lexicon features, with in- tersected results from both directions. Results are reported in <ref type="table" target="#tab_6">Table 6</ref>. Although the comparison was limited in this case, results were in favour of LEX- ACC and STACC on targeted recall measures for the Wikipedia datasets.</p><p>Finally, both LEXACC and STACC were com- pared against the EITB test sets, with results shown in <ref type="table" target="#tab_7">Table 7</ref>. For this language pair, STACC per- formed markedly better with differences of up to 25 points. A likely explanation for these results is the nature of the features that compose the LEX- ACC model. In particular the features related to alignment obliqueness and number of initial/final aligned words might be detrimental in the case of Basque, which exhibits free word order. Given the poor results obtained with feature weights op- timised on the IVAP corpus, we also checked the results using the provided default weights. This resulted in slightly better performance, as shown in the rows named LEXACC DF in <ref type="table" target="#tab_7">Table 7</ref>, though still far from the results achieved with STACC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Discussion</head><p>Overall, STACC provided the best results across domains and language pairs, in particular for nois- ier datasets. Additionally, the approach has several <ref type="bibr">14</ref> Note that, for both LEXACC and STACC, in some sce- narios even the lowest thresholds gave precisions higher than 90, rendering the comparison moot. We indicate these cases with a ↑ sign next to the highest recall obtained at the closest precision to the arbitrary 80 and 90 precision points. advantages over existing methods and systems for comparable segment alignment.</p><p>First, it is undoubtedly simpler, as it requires but minimal information to reach optimal results. Lexical tables and simple set expansion operations based on surface properties of the tokens are the only components of the approach, as compared to the more sophisticated feature-based approaches which rely on larger sets of components for which optimal weights need to be computed prior to ap- plying the models.</p><p>Secondly, because of its simplicity, STACC is a more portable method, as is it is not necessary to perform any type of adaptation for new domains and language pairs, nor to rely on domain-specific information such as link structure in Wikipedia. In actual practice, portability is an important issue which hinders on the exploitation of comparable corpora. An efficient yet easily deployable method is therefore a welcome addition to the toolset for parallel data extraction.</p><p>Finally, STACC results in fewer computational steps when compared to more complex feature- based methods. First, it involves simple binary set intersection and union operations for the com- putation of similarity, instead of conjoined fea- ture computation on larger component sets. Sec- ondly, the approach relies on tractable set differ- ences for its most computationally expensive op- eration of longest common prefix matching, com- pared to matching all tokens against lists of word endings which can be quite large, notably in the case of agglutinative languages.</p><p>Although promising, the approach could be fur- ther evaluated, and potentially improved, along two main lines.</p><p>It might be worth exploring for instance the im- pact of filtering alignment candidates according to the relative position of sentence pairs in the original source and target documents, a document- level property notably exploited by <ref type="bibr" target="#b18">(Smith et al., 2010)</ref>. As the STACC approach is featureless, and meant to remain as such in order to main- tain its portability and ease of deployment, filter- ing distant sentence pairs would need to take place prior to the computation of alignment scores. A simple approach compatible with STACC would consist in constraining candidate sets by includ- ing sentence position information when perform- ing indexing and candidate querying in a CLIR ap- proach. This would provide an additional evalua-tion of the accuracy of the approach in scenarios where document-level information is exploitable.</p><p>Additionally, given the importance of k-best lexical translations in computing STACC similarity, variations in lexical coverage obtained with dif- ferent translation tables can be expected to impact alignment accuracy. Although mining comparable corpora usually requires the use of seed translation knowledge extracted from a domain that differs from the one being mined, default tables with wide lexical coverage can be built from existing parallel corpora in different domains. Thus, improvements might be obtained with larger and more diverse ta- bles than the ones used in the experiments reported here, which were based on translations extracted from a single domain. A precise assessment of the evolution of alignment accuracy given variations in lexical translation coverage is left for future re- search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Alignment optimisation</head><p>As previously mentioned, for both LEXACC and STACC, alignments were computed for every source sentence against candidate translations re- trieved by Lucene and all cases where a given tar- get sentence has more than one source alignment were left as is.</p><p>Although this methodology enabled a fair com- parison between the two systems, it evidently im- pacts alignment accuracy. One simple optimisa- tion is to retain only the best overall source-target alignments, discarding all alignments established between a given source sentence and a target sen- tence if the latter is linked to better scoring source sentences.</p><p>The net effect of this procedure is the promotion of better alignments, as some correct alignments would not be hidden anymore by other better scor- ing shared alignments. This is most likely to occur with source-target pairs that are close variants of each other, with close similarity scores.</p><p>We applied this simple optimisation to the Ac- curat test sets and observed improvements across the board, as shown in <ref type="figure">Figure 1</ref>. Depending on ac- tual usage, this optimised version of STACC align- ment can constitute the best alternative for the extraction of parallel sentences from comparable corpora.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>We described a simple approach to comparable sentence alignment, termed STACC, which is based on automatically extracted seed lexical transla- tions, the Jaccard similarity coefficient, and sim- ple set expansion operations that target named en- tities, numbers, and morphological variation using longest common prefixes. Building on fairly stan- dard components for the computation of similar- ity, this method is shown to perform better than current alternatives.</p><p>The approach was evaluated on a large range of datasets from various domains for ten language pairs, giving the best results overall when com- pared to sophisticated state-of-the-art methods. STACC also performed better than competing ap- proaches on noisier corpora, showing promises for the exploitation of the typically noisy data found when mining comparable corpora. STACC is a highly portable method which re- quires no adaptation for its application to new do- mains and language pairs. It thus allows for the fast deployment of a crucial component in compa- rable corpora alignment, which opens the path for an increase in the amount of such corpora that can be exploited in the future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 : Wikipedia evaluation sets</head><label>2</label><figDesc></figDesc><table>TEST SETS 
ES-EU 

1:1 
500-500 

EITB NOISE1 

1000-1000 

EITB NOISE2 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 4</head><label>2</label><figDesc></figDesc><table>In the table, ATS refers to the Accurat test sets, AOC to 
the Accurat original corpora, and EUP to the Europarl corpus. 
5 Available 
at: 
http://research.microsoft.com/en-
us/people/chrisq/wikidownload.aspx. 
6 Refered to as NC here and available from: 
http://www.statmt.org/wmt13/translation-task.html. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Best F1 measures on the Accurat evaluation sets 

SYSTEM 
TEST SETS 
EN-BG 
EN-DE 
EN-ES 

LEXACC 

1:1 
87.1 
82.7 
98.2 

STACC 

1:1 
84.9 
82.0 
99.7 

LEXACC 

100:1 
27.6 
31.0 
66.2 

STACC 

100:1 
16.6 
35.8 
73.3 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><head>Table 5 : Best F1 measures on the Wikipedia evaluation sets</head><label>5</label><figDesc></figDesc><table>CRF 
LEXACC 
STACC 

LANGUAGE PAIR R@90 R@80 R@90 R@80 R@90 R@80 

EN-BG 

72.0 
81.8 
80.4↑ 
80.4↑ 
80.2 
81.6↑ 

EN-DE 

58.7 
68.8 
75.2 
78.7 
68.8 
81.8↑ 

EN-ES 

90.4 
93.7 
97.0↑ 
97.0↑ 
99.6↑ 
99.6↑ 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="true"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Targeted recall on the Wikipedia evaluation sets 

SYSTEM 
TEST SETS 
ES-EU 

LEXACC 

1:1 
77.2 

LEXACC DF 

1:1 
80.2 

STACC 

1:1 
90.9 

LEXACC 
EITB NOISE1 

59.2 

LEXACC DF 
EITB NOISE1 

62.2 

STACC 
EITB NOISE1 

82.8 

LEXACC 
EITB NOISE2 

54.5 

LEXACC DF 
EITB NOISE2 

57.4 

STACC 
EITB NOISE2 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table>Best F1 measures on the EITB evaluation sets 

33.7 
37.3 
42.5 

56.0 
56.2 

75.7 

35.3 
38.5 
42.2 
43.6 

59.2 
57.9 

78.3 

37.8 

en-de 
en-el 
en-et 
en-lt 
en-lv 
en-ro 
en-sl 

F1 

stacc 
stacc_opt 

</table></figure>

			<note place="foot" n="1"> This differs from (Skadin¸aSkadin¸a et al., 2012), who include a lexical translation feature where actual probabilities are used to compute the final score.</note>

			<note place="foot" n="2"> Throughout the experiments we describe, n was set to 3.</note>

			<note place="foot" n="3"> http://www.accurat-project.eu/. The corpus is available from: http://metashare.elda.org/repository/search/?q=accurat</note>

			<note place="foot" n="7"> Euskal Irrati Telebista (EITB): http://www.eitb.eus. The corpus was provided courtesy of EITB and will be made available to the research community.</note>

			<note place="foot" n="8"> http://www.accurat-project.eu/index.php?p=accurattoolkit 9 http://lucenenet.apache.org/</note>

			<note place="foot" n="10"> Extracted from the translation memories released by the Basque Public Administration Institute (http://opendata.euskadi.eus/catalogo/-/memorias-detraduccion-del-servicio-oficial-de-traductores-del-ivap/), which consist of professional translations of public administration texts. 11 We used the latest available version of the corpus, as of November 2015, in the OPUS repository: http://opus.lingfil.uu.se/JRC-Acquis.php.</note>

			<note place="foot" n="12"> Note that similar issues would arise if the selected translations were determined based on thresholds over translation probabilities, as the thresholds would need to be empirically set as well. 13 The optimal thresholds were determined as the values providing the best results on the test sets. This would obviously not be an available threshold selection method when mining comparable corpora, where a default value would have to be used instead. Such a default value would however not allow for a fair comparison of the systems.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was partially funded by the Spanish Ministry of Economy and Competitiveness and the Department of Economic Development and Com-petitiveness of the Basque Government through the AdapTA (RTC-2015-3627-7), PLATA (IG-2014/00037) and TRADIN (IG-2015/0000347) projects. We would like to thank MondragonLin-gua Translation &amp; Communication as coordinator of these projects and the three anonymous review-ers for their helpful feedback and suggestions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">On the use of comparable corpora to improve SMT performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadaf</forename><surname>Abdul-Rauf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics, EACL &apos;09</title>
		<meeting>the 12th Conference of the European Chapter of the Association for Computational Linguistics, EACL &apos;09<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="16" to="23" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.0473</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A statistical approach to machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Peter F Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen A Della</forename><surname>Cocke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent J Della</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fredrick</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">D</forename><surname>Jelinek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">L</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mercer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Paul S Roossin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="79" to="85" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The mathematics of statistical machine translation: Parameter estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent J Della</forename><surname>Peter F Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen A Della</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert L</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mercer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="263" to="311" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Mining Very Non-Parallel Corpora: Parallel Sentence and Lexicon Extraction via Bootstrapping and E.M</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Cheung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Empirical Methods in Natural Language Processing</title>
		<meeting>Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="57" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Distribution de la flore alpine dans le bassin des Dranses et dans quelques régions voisines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Jaccard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bulletin de la Société Vaudoise des Sciences Naturelles</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="241" to="272" />
			<date type="published" when="1901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Europarl: A Parallel Corpus for Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th Machine Translation Summit</title>
		<meeting>the 10th Machine Translation Summit</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">D</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><forename type="middle">C N</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighteenth International Conference on Machine Learning, ICML &apos;01</title>
		<meeting>the Eighteenth International Conference on Machine Learning, ICML &apos;01<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="282" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fast and accurate sentence alignment of bilingual corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th Conference of the Association for Machine Translation in the Americas on Machine Translation: From Research to Real Users, AMTA &apos;02</title>
		<meeting>the 5th Conference of the Association for Machine Translation in the Americas on Machine Translation: From Research to Real Users, AMTA &apos;02<address><addrLine>London, UK, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="135" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Processing Comparable Corpora With Bilingual Suffix Trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Dragos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Munteanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="289" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Improving machine translation performance by exploiting non-parallel corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Dragos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Munteanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="477" to="504" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A Framework for a Mechanical Translation Between Japanese and English by Analogy Principle</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makoto</forename><surname>Nagao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International NATO Symposium on Artificial and Human Intelligence</title>
		<meeting>the International NATO Symposium on Artificial and Human Intelligence<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Elsevier North-Holland, Inc</publisher>
			<date type="published" when="1984" />
			<biblScope unit="page" from="173" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A systematic comparison of various statistical alignment models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Franz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="19" to="51" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">BLEU: A Method for Automatic Evaluation of Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 40th Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Methods for collection and evaluation of comparable documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Monica</forename><forename type="middle">Lestari</forename><surname>Paramita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Guthrie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evangelos</forename><surname>Kanoulas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Gaizauskas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sanderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Building and Using Comparable Corpora</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="93" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Align, disambiguate and walk: A unified approach for measuring semantic similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Taher Pilehvar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Jurgens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1341" to="1351" />
		</imprint>
	</monogr>
	<note>The Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Iterative sentence-pair extraction from quasi-parallel corpora for machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Maskey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ea-Ee</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhuvana</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Ramabhadran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Roukos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of InterSpeech</title>
		<meeting>InterSpeech</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="432" to="435" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Collecting and using comparable corpora for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inguna</forename><surname>Skadin¸askadin¸a</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmet</forename><surname>Aker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Mastropavlos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangzhong</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Tufis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateja</forename><surname>Verlic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrejs</forename><surname>Vasil¸jevsvasil¸jevs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bogdan</forename><surname>Babych</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Gaizauskas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Conference on Language Resources and Evaluation</title>
		<meeting>the 8th International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Extracting parallel sentences from comparable corpora using document level alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><forename type="middle">R</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Quirk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, HLT &apos;10</title>
		<meeting><address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="403" to="411" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A study of translation edit rate with targeted human annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Snover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Dorr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linnea</forename><surname>Micciulla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Makhoul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Association for Machine Translation in the Americas</title>
		<meeting>Association for Machine Translation in the Americas</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="223" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Hybrid parallel sentence mining from comparable corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Stef˘ Anescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Ion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabine</forename><surname>Hunsicker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference of the European Association for Machine Translation</title>
		<meeting>the 16th Conference of the European Association for Machine Translation</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="137" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Parallel data, tools and interfaces in OPUS</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jörg</forename><surname>Tiedemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th Language Resources and Evaluation Conference</title>
		<meeting>the 8th Language Resources and Evaluation Conference</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2214" to="2218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Adaptive parallel sentences mining from web bilingual news collection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Vogel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2002 IEEE International Conference on Data Mining</title>
		<meeting>the 2002 IEEE International Conference on Data Mining</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="745" to="748" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
