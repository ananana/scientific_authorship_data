<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T13:03+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Marrying Up Regular Expressions with Neural Networks: A Case Study for Spoken Language Understanding</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 15-20, 2018. 2018. 2083</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingfeng</forename><surname>Luo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">ICST</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yansong</forename><surname>Feng</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">ICST</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">MetaLab</orgName>
								<orgName type="institution">Lancaster University</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songfang</forename><surname>Huang</surname></persName>
							<affiliation key="aff2">
								<orgName type="laboratory">IBM China Research Lab</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">ICST</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">ICST</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Marrying Up Regular Expressions with Neural Networks: A Case Study for Spoken Language Understanding</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2083" to="2093"/>
							<date type="published">July 15-20, 2018. 2018. 2083</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The success of many natural language processing (NLP) tasks is bound by the number and quality of annotated data, but there is often a shortage of such training data. In this paper, we ask the question: &quot;Can we combine a neural network (NN) with regular expressions (RE) to improve supervised learning for NLP?&quot;. In answer, we develop novel methods to exploit the rich expres-siveness of REs at different levels within a NN, showing that the combination significantly enhances the learning effectiveness when a small number of training examples are available. We evaluate our approach by applying it to spoken language understanding for intent detection and slot filling. Experimental results show that our approach is highly effective in exploiting the available training data, giving a clear boost to the RE-unaware NN.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Regular expressions (REs) are widely used in various natural language processing (NLP) tasks like pattern matching, sentence classification, se- quence labeling, etc. ( <ref type="bibr" target="#b1">Chang and Manning, 2014)</ref>. As a technique based on human-crafted rules, it is concise, interpretable, tunable, and does not rely on much training data to generate. As such, it is commonly used in industry, especially when the available training examples are limited -a prob- lem known as few-shot learning <ref type="bibr" target="#b3">(GC et al., 2015)</ref>.</p><p>While powerful, REs have a poor generaliza- tion ability because all synonyms and variations in a RE must be explicitly specified. As a re- sult, REs are often ensembled with data-driven methods, such as neural network (NN) based tech- niques, where a set of carefully-written REs are used to handle certain cases with high precision, leaving the rest for data-driven methods.</p><p>We believe the use of REs can go beyond sim- ple pattern matching. In addition to being a sepa- rate classifier to be ensembled, a RE also encodes a developer's knowledge for the problem domain. The knowledge could be, for example, the infor- mative words (clue words) within a RE's surface form. We argue that such information can be uti- lized by data-driven methods to achieve better pre- diction results, especially in few-shot learning.</p><p>This work investigates the use of REs to im- prove NNs -a learning framework that is widely used in many NLP tasks <ref type="bibr" target="#b4">(Goldberg, 2017)</ref>. The combination of REs and a NN allows us to ex- ploit the conciseness and effectiveness of REs and the strong generalization ability of NNs. This also provides us an opportunity to learn from various kinds of REs, since NNs are known to be good at tolerating noises ( <ref type="bibr" target="#b26">Xie et al., 2016)</ref>. This paper presents novel approaches to com- bine REs with a NN at different levels. At the input layer, we propose to use the evaluation outcome of REs as the input features of a NN (Sec.3.2). At the network module level, we show how to exploit the knowledge encoded in REs to guide the attention mechanism of a NN (Sec. 3.3). At the output layer, we combine the evaluation outcome of a RE with the NN output in a learnable manner <ref type="bibr">(Sec. 3.4)</ref>.</p><p>We evaluate our approach by applying it to two spoken language understanding (SLU) tasks, namely intent detection and slot filling, which re- spectively correspond to two fundamental NLP tasks: sentence classification and sequence label- ing. To demonstrate the usefulness of REs in real- world scenarios where the available number of an- notated data can vary, we explore both the few- shot learning setting and the one with full train- ing data. Experimental results show that our ap- proach is highly effective in utilizing the available   <ref type="figure">Figure 1</ref>: A sentence from the ATIS dataset. REs can be used to detect the intent and label slots. annotated data, yielding significantly better learn- ing performance over the RE-unaware method.</p><p>Our contributions are as follows. <ref type="formula" target="#formula_0">(1)</ref> We present the first work to systematically investigate meth- ods for combining REs with NNs. (2) The pro- posed methods are shown to clearly improve the NN performance in both the few-shot learning and the full annotation settings. (3) We provide a set of guidance on how to combine REs with NNs and RE annotation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Typesetting</head><p>In this paper, we use italic for emphasis like intent detection, the Courier typeface for ab- breviations like RE, bold italic for the first ap- pearance of a concept like clue words, Courier surrounded by / for regular expressions like /list( the)? AIRLINE/, and underlined italic for words of sentences in our dataset like Boston.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Problem Definition</head><p>Our work targets two SLU tasks: intent detection and slot filling. The former is a sentence classifi- cation task where we learn a function to map an input sentence of n words, x = [x 1 , ..., x n ], to a corresponding intent label, c. The latter is a se- quence labeling task for which we learn a func- tion to take in an input query sentence of n words, x = [x 1 , ..., x n ], to produce a corresponding label- ing sequence, y = [y 1 , ..., y n ], where y i is the slot label of the corresponding word, x i .</p><p>Take the sentence in <ref type="figure">Fig. 1</ref> as an example. A successful intent detector would suggest the in- tent of the sentence as flight, i.e., querying about flight-related information. A slot filler, on the other hand, should identify the slots fromloc.city and toloc.city by labeling Boston and Miami, re- spectively, using the begin-inside-outside (BIO) scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">The Use of Regular Expressions</head><p>In this work, a RE defines a mapping from a text pattern to several REtags which are the same as or related to the target labels (i.e., intent and slot labels). A search function takes in a RE, applies it to all sentences, and returns any texts that match the pattern. We then assign the REtag (s) (that are associated with the matching RE) to either the matched sentence (for intent detection) or some matched phrases (for slot filling).</p><p>Specifically, our REtags for intent detection are the same as the intent labels. For example, in <ref type="figure">Fig. 1</ref>, we get a REtag of flight that is the same as the intent label flight.</p><p>For slot filling, we use two different sets of REs. Given the group functionality of RE, we can assign REtags to our interested RE groups (i.e., the ex- pressions defined inside parentheses). The transla- tion from REtags to slot labels depends on how the corresponding REs are used. (1) When REs are used at the network module level (Sec. 3.3), the corresponding REtags are the same as the tar- get slot labels. For instance, the slot RE in <ref type="figure">Fig. 1</ref> will assign fromloc.city to the first RE group and toloc.city to the second one. Here, CITY is a list of city names, which can be replaced with a RE string like /Boston|Miami|LA|.../. (2) If REs are used in the input (Sec. 3.2) and the output lay- ers (Sec. 3.4) of a NN, the corresponding REtag would be different from the target slot labels. In this context, the two RE groups in <ref type="figure">Fig. 1</ref> would be simply tagged as city to capture the commonal- ity of three related target slot labels: fromloc.city, toloc.city, stoploc.city. Note that we could use the target slot labels as REtags for all the settings. The purpose of abstracting REtags to a simpli- fied version of the target slot labels here is to show that REs can still be useful when their evaluation outcome does not exactly match our learning ob- jective. Further, as shown in Sec. 4.2, using sim- plified REtags can also make the development of REs easier in our tasks.</p><p>Intuitively, complicated REs can lead to bet- ter performance but require more efforts to gen- erate. Generally, there are two aspects affecting RE complexity most: the number of RE groups 1 and or clauses (i.e., expressions separated by the disjunction operator |) in a RE group. Having a larger number of RE groups often leads to better precision but lower coverage on pattern matching, while a larger number of or clauses usually gives a higher coverage but slightly lower precision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Our Approach</head><p>As depicted in <ref type="figure" target="#fig_1">Fig. 2</ref>, we propose to combine NNs and REs from three different angles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Base Models</head><p>We use the Bi-directional LSTM (BLSTM) as our base NN model because it is effective in both intent detection and slot filling ( <ref type="bibr" target="#b14">Liu and Lane, 2016</ref>).</p><p>Intent Detection. As shown in <ref type="figure" target="#fig_1">Fig. 2</ref>, the BLSTM takes as input the word embeddings [x 1 , ..., x n ] of a n-word sentence, and produces a vector h i for each word i. A self-attention layer then takes in the vectors produced by the BLSTM to compute the sentence embedding s:</p><formula xml:id="formula_0">s = i α i h i , α i = exp(h i Wc) i exp(h i Wc)<label>(1)</label></formula><p>where α i is the attention for word i, c is a ran- domly initialized trainable vector used to select informative words for classification, and W is a weight matrix. Finally, s is fed to a softmax clas- sifier for intent classification.</p><p>Slot Filling. The model for slot filling is straight- forward -the slot label prediction is generated by a softmax classier which takes in the BLSTM's out- put h i and produces the slot label of word i. Note that attention aggregation in <ref type="figure" target="#fig_1">Fig. 2</ref> is only em- ployed by the network module level method pre- sented in Sec. 3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Using REs at the Input Level</head><p>At the input level, we use the evaluation outcomes of REs as features which are fed to NN models.</p><p>Intent Detection. Our REtag for intent detec- tion is the same as our target intent label. Be- cause real-world REs are unlikely to be perfect, one sentence may be matched by more than one RE. This may result in several REtags that are conflict with each other. For instance, the sentence list the Delta airlines flights to Miami can match a RE: /list( the)? AIRLINE/ that outputs tag airline, and another RE: /list( \w+){0,3} flights?/ that outputs tag flight.</p><p>To resolve the conflicting situations illustrated above, we average the randomly initialized train- able tag embeddings to form an aggregated em- bedding as the NN input. There are two ways to use the aggregated embedding. We can append the aggregated embedding to either the embedding of every input word, or the input of the softmax clas- sifier (see 1 in <ref type="figure" target="#fig_1">Fig. 2(a)</ref>). To determine which strategy works best, we perform a pilot study. We found that the first method causes the tag embed- ding to be copied many times; consequently, the NN tends to heavily rely on the REtags, and the resulting performance is similar to the one given by using REs alone in few-shot settings. Thus, we adopt the second approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Slot Filling. Since the evaluation outcomes of slot</head><p>REs are word-level tags, we can simply embed and average the REtags into a vector f i for each word, and append it to the corresponding word embedding w i (as shown in 1 in <ref type="figure" target="#fig_1">Fig. 2(b)</ref>). Note that we also extend the slot REtags into the BIO format, e.g., the REtags of phrase New York are B-city and I-city if its original tag is city.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Using REs at the Network Module Level</head><p>At the network module level, we explore ways to utilize the clue words in the surface form of a RE (bold blue arrows and words in 2 of <ref type="figure" target="#fig_1">Fig. 2</ref>) to guide the attention module in NNs.</p><p>Intent Detection. Taking the sentence in <ref type="figure">Fig. 1</ref> for example, the RE: /ˆflights? from/ that leads to intent flight means that flights from are the key words to decide the intent flight. Therefore, the attention module in NNs should leverage these two words to get the correct prediction. To this end, we extend the base intent model by making two changes to incorporate the guidance from REs.</p><p>First, since each intent has its own clue words, using a single sentence embedding for all intent la- bels would make the attention less focused. There- fore, we let each intent label k use different atten- tion a k , which is then used to generate the sentence embedding s k for that intent:</p><formula xml:id="formula_1">s k = i α ki h i , α ki = exp(h i W a c k ) i exp(h i W a c k ) (2)</formula><p>where c k is a trainable vector for intent k which is used to compute attention a k , h i is the BLSTM output for word i, and W a is a weight matrix. The probability p k that the input sentence ex- presses intent k is computed by:  where w k , logit k , b k are weight vector, logit, and bias for intent k, respectively.</p><formula xml:id="formula_2">p k = exp(logit k ) k exp(logit k ) , logit k = w k s k + b k (3) x 1 x 2 h 1 h 2 x 3 h</formula><p>Second, apart from indicating a sentence for intent k (positive REs), a RE can also indicate that a sentence does not express intent k (negative REs). We thus use a new set of attention (negative attentions, in contrast to positive attentions), to compute another set of logits for each intent with Eqs. 2 and 3. We denote the logits computed by positive attentions as logit pk , and those by nega- tive attentions as logit nk , the final logit for intent k can then be calculated as:</p><formula xml:id="formula_3">logit k = logit pk − logit nk<label>(4)</label></formula><p>To use REs to guide attention, we add an atten- tion loss to the final loss:</p><formula xml:id="formula_4">loss att = k i t ki log(α ki )<label>(5)</label></formula><p>where t ki is set to 0 when none of the matched REs (that leads to intent k) marks word i as a clue word -otherwise t ki is set to 1/l k , where l k is the number of clue words for intent k (if no matched RE leads to intent k, then t k * = 0). We use Eq. 5 to compute the positive attention loss, loss att p , for positive REs and negative attention loss, loss att n , for negative ones. The final loss is computed as:</p><formula xml:id="formula_5">loss = loss c + β p loss att p + β n loss att n (6)</formula><p>where loss c is the original classification loss, β p and β n are weights for the two attention losses.</p><p>Slot Filling. The two-side attention (positive and negative attention) mechanism introduced for in- tent prediction is unsuitable for slot filling. Be- cause for slot filling, we need to compute atten- tion for each word, which demands more compu- tational and memory resources than doing that for intent detection 2 .</p><p>Because of the aforementioned reason, we use a simplified version of the two-side attention, where all the slot labels share the same set of positive and negative attention. Specifically, to predict the slot label of word i, we use the following equations, which are similar to Eq. 1, to generate a sentence embedding s pi with regard to word i from positive attention:</p><formula xml:id="formula_6">s pi = j α pij h j , α pij = exp(h j W sp h i ) j exp(h j W sp h i )<label>(7)</label></formula><p>where h i and h j are the BLSTM outputs for word i and j respectively, W sp is a weight matrix, and α pij is the positive attention value for word j with respect to word i. Further, by replacing W sp with W sn , we use Eq. 7 again to compute negative at- tention and generate the corresponding sentence embedding s ni .</p><p>Finally, the prediction p i for word i can be cal- culated as:</p><formula xml:id="formula_7">p i = softmax((W p [s pi ; h i ] + b p ) −(W n [s ni ; h i ] + b n ))<label>(8)</label></formula><p>where W p , W n , b p , b n are weight matrices and bias vectors for positive and negative attention, re- spectively. Here we append the BLSTM output h i to s pi and s ni because the word i itself also plays a crucial part in identifying its slot label.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Using REs at the Output Level</head><p>At the output level, REs are used to amend the output of NNs. At this level, we take the same approach used for intent detection and slot filling (see 3 in <ref type="figure" target="#fig_1">Fig. 2</ref>). As mentioned in Sec. 2.3, the slot REs used in the output level only produce a simplified version of target slot labels, for which we can further an- notate their corresponding target slot labels. For instance, a RE that outputs city can lead to three slot labels: fromloc.city, toloc.city, stoploc.city.</p><p>Let z k be a 0-1 indicator of whether there is at least one matched RE that leads to target label k (intent or slot label), the final logits of label k for a sentence (or a specific word for slot filling) is:</p><formula xml:id="formula_8">logit k = logit k + w k z k<label>(9)</label></formula><p>where logit k is the logit produced by the origi- nal NN, and w k is a trainable weight indicating the overall confidence for REs that lead to target la- bel k. Here we do not assign a trainable weight for each RE because it is often that only a few sen- tences match a RE.</p><p>We modify the logit instead of the final prob- ability because a logit is an unconstrained real value, which matches the property of w k z k bet- ter than probability. Actually, when performing model ensemble, ensembling with logits is often empirically better than with the final probability <ref type="bibr">3</ref> . This is also the reason why we choose to operate on logits in Sec. 3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation Methodology</head><p>Our experiments aim to answer three questions: Q1: Does the use of REs enhance the learning quality when the number of annotated instances is small? Q2: Does the use of REs still help when using the full training data? Q3: How can we choose from different combination methods?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>We use the ATIS dataset ( <ref type="bibr" target="#b6">Hemphill et al., 1990</ref>) to evaluate our approach. This dataset is widely used in SLU research. It includes queries of flights, meal, etc. We follow the setup of Liu and Lane (2016) by using 4,978 queries for training and 893 for testing, with 18 intent labels and 127 slot labels. We also split words like Miami's into Miami 's during the tokenization phase to reduce the number of words that do not have a pre-trained word embedding. This strategy is useful for few- shot learning.</p><p>To answer Q1 , we also exploit the full few-shot learning setting. Specifically, for intent detection, we randomly select 5, 10, 20 training instances for each intent to form the few-shot training set; and for slot filling, we also explore 5, 10, 20 shots settings. However, since a sentence typically con- tains multiple slots, the number of mentions of fre- quent slot labels may inevitably exceeds the target shot count. To better approximate the target shot count, we select sentences for each slot label in as- cending order of label frequencies. That is k 1 -shot dataset will contain k 2 -shot dataset if k 1 &gt; k 2 . All settings use the original test set.</p><p>Since most existing few-shot learning meth- ods require either many few-shot classes or some classes with enough data for training, we also ex- plore the partial few-shot learning setting for in- tent detection to provide a fair comparison for ex- isting few-shot learning methods. Specifically, we let the 3 most frequent intents have 300 training instances, and the rest remains untouched. This is also a common scenario in real world, where we often have several frequent classes and many classes with limited data. As for slot filling, how- ever, since the number of mentions of frequent slot labels already exceeds the target shot count, the original slot filling few-shot dataset can be directly used to train existing few-shot learning methods. Therefore, we do not distinguish full and partial few-shot learning for slot filling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Preparing REs</head><p>We use the syntax of REs in Perl in this work. Our REs are written by a paid annotator who is famil- iar with the domain. It took the annotator in total less than 10 hours to develop all the REs, while a domain expert can accomplish the task faster. We use the 20-shot training data to develop the REs, but word lists like cities are obtained from the full training set. The development of REs is considered completed when the REs can cover most of the cases in the 20-shot training data with resonable precision. After that, the REs are fixed throughout the experiments.</p><p>The majority of the time for writing the REs is proportional to the number of RE groups. It took about 1.5 hours to write the 54 intent REs with on average 2.2 groups per RE. It is straightforward to write the slot REs for the input and output level methods, for which it took around 1 hour to write the 60 REs with 1.7 groups on average. By con-trast, writing slot REs to guide attention requires more efforts as the annotator needs to carefully se- lect clue words and annotate the full slot label. As a result, it took about 5.5 hours to generate 115 REs with on average 3.3 groups. The performance of the REs can be found in the last line of <ref type="table">Table 1.</ref> In practice, a positive RE for intent (or slot) k can often be treated as negative REs for other in- tents (or slots). As such, we use the positive REs for intent (or slot) k as the negative REs for other intents (or slots) in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Experimental Setup</head><p>Hyper-parameters. Our hyper-parameters for the BLSTM are similar to the ones used by <ref type="bibr" target="#b14">Liu and Lane (2016)</ref>. Specifically, we use batch size 16, dropout probability 0.5, and BLSTM cell size 100. The attention loss weight is 16 (both positive and negative) for full few-shot learning settings and 1 for other settings. We use the 100d GloVe word vectors ( <ref type="bibr" target="#b18">Pennington et al., 2014</ref>) pre-trained on <ref type="bibr">Wikipedia and Gigaword (Parker et al., 2011)</ref>, and the Adam optimizer ( <ref type="bibr" target="#b11">Kingma and Ba, 2014</ref>) with learning rate 0.001.</p><p>Evaluation Metrics. We report accuracy and macro-F1 for intent detection, and micro/macro- F1 for slot filling. Micro/macro-F1 are the har- monic mean of micro/macro precision and re- call. Macro-precision/recall are calculated by av- eraging precision/recall of each label, and micro- precision/recall are averaged over each prediction.</p><p>Competitors and Naming Conventions. Here, a bold Courier typeface like BLSTM denotes the notations of the models that we will compare in Sec. 5.</p><p>Specifically, we compare our methods with the baseline BLSTM model (Sec. 3.1). Since our atten- tion loss method (Sec. 3.3) uses two-side attention, we include the raw two-side attention model with- out attention loss (+two) for comparison as well. Besides, we also evaluate the RE output (REO), which uses the REtags as prediction directly, to show the quality of the REs that we will use in the experiments. <ref type="bibr">4</ref> As for our methods for combinging REs with NN, +feat refers to using REtag as input fea- tures (Sec. 3.2), +posi and +neg refer to using positive and negative attention loss respectively, +both refers to using both postive and negative attention losses (Sec. 3.3), and +logit means us- ing REtag to modify NN output (Sec. 3.4).</p><p>Moverover, since the REs can also be format- ted as first-order-logic (FOL) rules, we also com- pare our methods with the teacher-student frame- work proposed by <ref type="bibr" target="#b7">Hu et al. (2016a)</ref>, which is a general framework for distilling knowledge from FOL rules into NN (+hu16). Besides, since we consider few-short learning, we also include the memory module proposed by <ref type="bibr" target="#b10">Kaiser et al. (2017)</ref>, which performs well in various few-shot datasets (+mem) <ref type="bibr">5</ref> . Finally, the state-of-art model on the ATIS dataset is also included (L&amp;L16), which jointly models the intent detection and slot filling in a single network ( <ref type="bibr" target="#b14">Liu and Lane, 2016)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Full Few-Shot Learning</head><p>To answer Q1 , we first explore the full few-shot learning scenario.</p><p>Intent Detection. As shown in <ref type="table">Table 1</ref>, except for 5-shot, all approaches improve the baseline BLSTM. Our network-module-level methods give the best performance because our attention mod- ule directly receives signals from the clue words in REs that contain more meaningful information than the REtag itself used by other methods. We also observe that since negative REs are derived from positive REs with some noises, posi per- forms better than neg when the amount of avail- able data is limited. However, neg is slightly bet- ter in 20-shot, possibly because negative REs sig- nificantly outnumbers the positive ones. Besides, two alone works better than the BLSTM when there are sufficient data, confirming the advantage of our two-side attention architecture.</p><p>As for other proposed methods, the output level method (logit) works generally better than the input level method (feat), except for the 5-shot case. We believe this is due to the fewer number of RE related parameters and the shorter distance that the gradient needs to travel from the loss to these parameters -both make logit easier to train. However, since logit directly modifies the output, the final prediction is more sensitive to the insufficiently trained weights in logit, leading to the inferior results in the 5-shot setting.  To compare with existing methods of combin- ing NN and rules, we also implement the teacher- student network ( <ref type="bibr" target="#b7">Hu et al., 2016a</ref>). This method lets the NN learn from the posterior label distribu- tion produced by FOL rules in a teacher-student framework, but requires considerable amounts of data. Therefore, although both hu16 and logit operate at the output level, logit still performs better than hu16 in these few-shot settings, since logit is easier to train.</p><p>It can also be seen that starting from 10-shot, two+both significantly outperforms pure REO. This suggests that by using our attention loss to connect the distributional representation of the NN and the clue words of REs, we can generalize RE patterns within a NN architecture by using a small amount of annotated data.</p><p>Slot Filling. Different from intent detection, as shown in <ref type="table">Table 1</ref>, our attention loss does not work for slot filling. The reason is that the slot label of a target word (the word for which we are trying to predict a slot label) is decided mainly by the se- mantic meaning of the word itself, together with 0- 3 phrases in the context to provide supplementary information. However, our attention mechanism can only help in recognizing clue words in the con- text, which is less important than the word itself and have already been captured by the BLSTM, to some extent. Therefore, the attention loss and the attention related parameters are more of a burden than a benefit. As is shown in <ref type="figure">Fig. 1</ref>, the model recognizes Boston as fromloc.city mainly because Boston itself is a city, and its context word from may have already been captured by the BLSTM and our attention mechanism does not help much. By examining the attention values of +two trained on the full dataset, we find that instead of mark- ing informative context words, the attention tends to concentrate on the target word itself. This ob- servation further reinforces our hypothesis on the attention loss.</p><p>On the other hand, since the REtags provide extra information, such as type, about words in the sentence, logit and feat generally work better. However, different from intent detection, feat only outperforms logit by a margin. This is because feat can use the REtags of all words to generate better context representations through the NN, while logit can only utilize the REtag of the target word before the final output layer. As a result, feat actually gathers more information from REs and can make better use of them than logit. Again, hu16 is still outperformed by logit, possibly due to the insufficient data sup- port in this few-shot scenario. We also see that even the BLSTM outperforms REO in 5-shot, in- dicating while it is hard to write high-quality RE patterns, using REs to boost NNs is still feasible.</p><p>Summary. The amount of extra information that a NN can utilize from the combined REs signifi- cantly affects the resulting performance. Thus, the attention loss methods work best for intent detec- tion and feat works best for slot filling. We also see that the improvements from REs decreases as having more training data. This is not surprising because the implicit knowledge embedded in the REs are likely to have already been captured by a sufficient large annotated dataset and in this sce- nario using the REs will bring in fewer benefits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Partial Few-Shot Learning</head><p>To better understand the relationship between our approach and existing few-shot learning methods, we also implement the memory network method    to our BLSTM model. Since the memory module requires to be trained on either many few-shot classes or several classes with extra data, we expand our full few-shot dataset for intent detection, so that the top 3 intent labels have 300 sentences (partial few-shot).</p><p>As shown in <ref type="table" target="#tab_4">Table 2</ref>, mem works better than BLSTM, and our attention loss can be further com- bined with the memory module (mem+posi), with even better performance. hu16 also works here, but worse than two+both. Note that, the memory module requires the input sentence to have only one embedding, thus we only use one set of positive attention for combination.</p><p>As for slot filling, since we already have ex- tra data for frequent tags in the original few-shot data (see Sec. 4.1), we use them directly to run the memory module. As shown in the bottom of <ref type="table">Table  1</ref>, mem also improves the base BLSTM, and gains further boost when it is combined with feat 6 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Full Dataset</head><p>To answer Q2, we also evaluate our methods on the full dataset. As seen in <ref type="table" target="#tab_5">Table 3</ref>, for intent de- tection, while two+both still works, feat and logit no longer give improvements. This shows <ref type="bibr">6</ref> For compactness, we only combine the best method in each task with mem, but others can also be combined.   <ref type="table">Table 4</ref>: Results on 20-Shot Data with Simple REs. +both refers to +two +both for short.</p><p>that since both REtag and annotated data provide intent labels for the input sentence, the value of the extra noisy tag from RE become limited as we have more annotated data. However, as there is no guidance on attention in the annotations, the clue words from REs are still useful. Further, since feat concatenates REtags at the input level, the powerful NN makes it more likely to overfit than logit, therefore feat performs even worse when compared to the BLSTM. As for slot filling, introducing feat and logit can still bring further improvements. This shows that the word type information contained in the REtags is still hard to be fully learned even when we have more annotated data. Moreover, different from few-shot settings, two+both has a better macro-F1 score than the BLSTM for this task, suggesting that better attention is still useful when the base model is properly trained.</p><p>Again, hu16 outperforms the BLSTM in both tasks, showing that although the REtags are noisy, their teacher-student network can still dis- till useful information. However, hu16 is a gen- eral framework to combine FOL rules, which is more indirect in transferring knowledge from rules to NN than our methods. Therefore, it is still infe- rior to attention loss in intent detection and feat in slot filling, which are designed to combine REs.</p><p>Further, mem generally works in this setting, and can receive further improvement by combin- ing our fusion methods. We can also see that two+both works clearly better than the state- of-art method (L&amp;L16) in intent detection, which jointly models the two tasks. And mem+feat is comparative to L&amp;L16 in slot filling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Impact of the RE Complexity</head><p>We now discuss how the RE complexity affects the performance of the combination. We choose to control the RE complexity by modifying the num- ber of groups. Specifically, we reduce the number of groups for existing REs to decrease RE com- plexity. To mimic the process of writing simple REs from scratch, we try our best to keep the key RE groups. For intent detection, all the REs are reduced to at most 2 groups. As for slot filling, we also reduce the REs to at most 2 groups, and for some simples case, we further reduce them into word-list patterns, e.g., ( CITY).</p><p>As shown in <ref type="table">Table 4</ref>, the simple REs already deliver clear improvements to the base NN mod- els, which shows the effectiveness of our meth- ods, and indicates that simple REs are quite cost- efficient since these simple REs only contain 1-2 RE groups and thus very easy to produce. We can also see that using complex REs generally leads to better results compared to using simple REs. This indicates that when considering using REs to im- prove a NN model, we can start with simple REs, and gradually increase the RE complexity to im- prove the performance over time 7 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Our work builds upon the following techniques, while qualitatively differing from each NN with Rules. On the initialization side,  uses important n-grams to initialize the convolution filters. On the input side, <ref type="bibr" target="#b23">Wang et al. (2017a)</ref> uses knowledge base rules to find rele- vant concepts for short texts to augment input. On the output side, <ref type="bibr" target="#b7">Hu et al. (2016a;</ref><ref type="bibr" target="#b8">2016b)</ref> and <ref type="bibr" target="#b5">Guo et al. (2017)</ref> use FOL rules to rectify the output probability of NN, and then let NN learn from the rectified distribution in a teacher-student frame- work. <ref type="bibr" target="#b25">Xiao et al. (2017)</ref>, on the other hand, mod- ifies the decoding score of NN by multiplying a weight derived from rules. On the loss function side, people modify the loss function to model the relationship between premise and conclusion <ref type="bibr" target="#b2">(Demeester et al., 2016)</ref>, and fit both human-annotated and rule-annotated labels <ref type="bibr" target="#b0">(Alashkar et al., 2017)</ref>. Since fusing in initialization or in loss function of- ten require special properties of the task, these ap- proaches are not applicable to our problem. Our work thus offers new ways to exploit RE rules at different levels of a NN.</p><p>NNs and REs. As for NNs and REs, previous work has tried to use RE to speed up the decoding phase of a NN ( <ref type="bibr" target="#b21">Strauß et al., 2016</ref>) and generating REs from natural language specifications of the <ref type="bibr">7</ref> We do not include results of both for slot filling since its REs are different from feat and logit, and we have already shown that the attention loss method does not work for slot filling. RE ( <ref type="bibr" target="#b15">Locascio et al., 2016)</ref>. By contrast, our work aims to use REs to improve the prediction ability of a NN.</p><p>Few-Shot Learning. Prior work either consid- ers few-shot learning in a metric learning frame- work ( <ref type="bibr" target="#b12">Koch et al., 2015;</ref><ref type="bibr" target="#b22">Vinyals et al., 2016)</ref>, or stores instances in a memory ( <ref type="bibr" target="#b20">Santoro et al., 2016;</ref><ref type="bibr" target="#b10">Kaiser et al., 2017)</ref> to match similar instances in the future. <ref type="bibr" target="#b24">Wang et al. (2017b)</ref> further uses the se- mantic meaning of the class name itself to provide extra information for few-shot learning. Unlike these previous studies, we seek to use the human- generated REs to provide additional information.</p><p>Natural Language Understanding. Recurrent neural networks are proven to be effective in both intent detection <ref type="bibr" target="#b19">(Ravuri and Stoicke, 2015)</ref> and slot filling <ref type="bibr" target="#b16">(Mesnil et al., 2015)</ref>. Researchers also find ways to jointly model the two tasks ( <ref type="bibr" target="#b14">Liu and Lane, 2016;</ref><ref type="bibr" target="#b27">Zhang and Wang, 2016)</ref>. However, no work so far has combined REs and NNs to im- prove intent detection and slot filling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>In this paper, we investigate different ways to com- bine NNs and REs for solving typical SLU tasks. Our experiments demonstrate that the combina- tion clearly improves the NN performance in both the few-shot learning and the full dataset settings. We show that by exploiting the implicit knowl- edge encoded within REs, one can significantly improve the learning performance. Specifically, we observe that using REs to guide the attention module works best for intent detection, and us- ing REtags as features is an effective approach for slot filling. We provide interesting insights on how REs of various forms can be employed to im- prove NNs, showing that while simple REs are very cost-effective, complex REs generally yield better results.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Overview of our methods. 1 , 2 , 3 refers to the methods in Sec. 3.2, 3.3, 3.4 respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Model</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Model</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Model</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>from Boston to Miami Intent RE: Intent Label: flight</head><label></label><figDesc></figDesc><table>/from (__CITY) to (__CITY)/ 

O 
O B-fromloc.city O B-toloc.city 

Sentence: 

Slot Labels: 

Slot RE: 

/^flights? from/ 

REtag: flight 

city / toloc.city 
REtag: city / fromloc.city 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Intent Detection Results on Partial Few-
Shot Learning Setting. 

Model 
Intent 
Slot 

Macro-F1/Accuracy Macro-F1/Micro-F1 

BLSTM 
92.50 / 98.77 
85.01 / 95.47 
+feat 
91.86 / 97.65 
86.7 / 95.55 
+logit 
92.48 / 98.77 
86.94 / 95.42 
+hu16 
93.09 / 98.77 
85.74 / 95.33 
+two 
93.64 / 98.88 
84.45 / 95.05 
+two+both 
96.20 / 98.99 
85.44 / 95.27 
+mem 
93.42 / 98.77 
85.72 / 95.37 
+mem+posi/feat 94.36 / 98.99 
87.82 / 95.90 
L&amp;L16 
-/ 98.43 
-/ 95.98 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Results on Full Dataset. The left side of 
'/' applies for intent, and the right side for slot. 

(Kaiser et al., 2017) which achieves good results 
in various few-shot datasets. We adapt their open-
source code, and add their memory module (mem) 
</table></figure>

			<note place="foot" n="1"> When discussing complexity, we consider each semantically independent consecutive word sequence as a RE group (excluding clauses, such as \w+, that can match any word). For instance, the RE: /how long( \w+){1,2}? (it take|flight)/ has two RE groups: (how long) and (it take|flight).</note>

			<note place="foot" n="2"> Since we need to assign a label to each word, if we still compute attention for each slot label, we will have to compute 2 × L × n 2 attention values for one sentence. Here, L is the number of tags and n is the sentence length. The BIO tagging format will further double the number of tags.</note>

			<note place="foot" n="3"> An example can be found in the ensemble version that Juan et al. (2016) used in the Avazu Kaggle competition.</note>

			<note place="foot" n="4"> For slot filling, we evaluate the REs that use the target slot labels as REtags.</note>

			<note place="foot" n="5"> We tune C and π0 of hu16, and choose (0.1, 0.3) for intent, and (1, 0.3) for slot. We tune memory-size and k of mem, and choose (1024, 64) for intent, and (2048, 64) for slot.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>This work is supported by the National High Technology R&amp;D Program of China (Grant No. 2015AA015403), the National Natural Science Foundation of China (Grant Nos. 61672057 and 61672058); the UK Engineering and Physical Sci-ences Research Council (EPSRC) under grants EP/M01567X/1 (SANDeRs) and EP/M015793/1 (DIVIDEND); and the Royal Society International Collaboration Grant (IE161012). For any corre-spondence, please contact Yansong Feng.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Examples-rules guided deep neural network for makeup recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taleb</forename><surname>Alashkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songyao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuyang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="941" to="947" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Tokensregex: Defining cascaded regular expressions over tokens</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Angel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
		<idno>CSTR 2014-02</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Lifted rule injection for relation embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Demeester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rocktäschel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.08359</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Why big data industrial systems need rules and what we can do about it</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">C</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haojun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Narasimhan</forename><surname>Rampalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shishir</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esteban</forename><surname>Arcaute</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ganesh</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohit</forename><surname>Deep</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Raghavendra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the 2015 ACM SIGMOD International Conference on Management of Data</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="265" to="276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Neural network methods for natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthesis Lectures on Human Language Technologies</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="309" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Knowledge graph embedding with iterative guidance from soft rules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Guo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.11231</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The atis spoken language systems pilot corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">J</forename><surname>Hemphill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Godfrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>George R Doddington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the DARPA speech and natural language workshop</title>
		<meeting>the DARPA speech and natural language workshop</meeting>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="page" from="96" to="101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiting</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengzhong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Xing</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.06318</idno>
		<title level="m">Harnessing deep neural networks with logic rules</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deep neural networks with massive learned knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiting</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zichao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1670" to="1679" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Field-aware factorization machines for ctr prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchin</forename><surname>Juan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Sheng</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Jen</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th ACM Conference on Recommender Systems</title>
		<meeting>the 10th ACM Conference on Recommender Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="43" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ofir</forename><surname>Nachum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurko</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.03129</idno>
		<title level="m">Learning to remember rare events</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Siamese neural networks for one-shot image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML Deep Learning Workshop</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Initializing convolutional filters with semantic features for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renfen</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyong</forename><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1885" to="1890" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Attention-based recurrent neural network models for joint intent detection and slot filling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Lane</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.01454</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Neural generation of regular expressions from natural language with minimal domain knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Locascio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduardo</forename><surname>Deleon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nate</forename><surname>Kushman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.03000</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Using recurrent neural networks for slot filling in spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grégoire</forename><surname>Mesnil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaisheng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Heck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gokhan</forename><surname>Tur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on Audio, Speech and Language Processing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="530" to="539" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>TASLP)</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">English gigaword fifth edition, linguistic data consortium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Parker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Graff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junbo</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuaki</forename><surname>Maeda</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Google Scholar</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</title>
		<meeting>the 2014 conference on empirical methods in natural language processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A comparative study of neural network models for lexical intent classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suman</forename><surname>Ravuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Stoicke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automatic Speech Recognition and Understanding (ASRU)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="368" to="374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Metalearning with memory-augmented neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Bartunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1842" to="1850" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Regular expressions for decoding of neural network outputs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Strauß</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gundram</forename><surname>Leifert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Grüning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Labahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3630" to="3638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Combining knowledge with deep convolutional neural networks for short text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongyuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 26th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2915" to="2921" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Multi-attention network for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingqiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zi</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE conference on computer vision and pattern recognition, CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="22" to="25" />
		</imprint>
	</monogr>
	<note>Anton van den Hengel, and Heng Tao Shen</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Symbolic priors for rnn-based semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyang</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Dymetman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Gardent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">wenty-sixth International Joint Conference on Artificial Intelligence (IJCAI-17)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4186" to="4192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Disturblabel: Regularizing cnn on the loss layer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4753" to="4762" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A joint model of intent determination and slot filling for spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houfeng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2993" to="2999" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
