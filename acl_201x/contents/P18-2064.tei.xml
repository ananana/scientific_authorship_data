<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:15+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Judicious Selection of Training Data in Assisting Language for Multilingual Neural NER</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 15-20, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rudra</forename><surname>Murthy</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering IIT Bombay</orgName>
								<orgName type="laboratory">Center for Indian Language Technology (CFILT)</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">†</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anoop</forename><surname>Kunchukuttan</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft AI &amp; Research</orgName>
								<address>
									<region>Hyderabad</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushpak</forename><surname>Bhattacharyya</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering IIT Bombay</orgName>
								<orgName type="laboratory">Center for Indian Language Technology (CFILT)</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Judicious Selection of Training Data in Assisting Language for Multilingual Neural NER</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="401" to="406"/>
							<date type="published">July 15-20, 2018</date>
						</imprint>
					</monogr>
					<note>401</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Multilingual learning for Neural Named Entity Recognition (NNER) involves jointly training a neural network for multiple languages. Typically, the goal is improving the NER performance of one of the languages (the primary language) using the other assisting languages. We show that the divergence in the tag distributions of the common named entities between the primary and assisting languages can reduce the effectiveness of multilingual learning. To alleviate this problem, we propose a metric based on symmetric KL divergence to filter out the highly divergent training instances in the assisting language. We empirically show that our data selection strategy improves NER performance in many languages, including those with very limited training data.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Neural NER trains a deep neural network for the NER task and has become quite popular as they minimize the need for hand-crafted features and, learn feature representations from the training data itself. Recently, multilingual learning has been shown to benefit Neural NER in a resource-rich language setting ( <ref type="bibr" target="#b5">Gillick et al., 2016;</ref><ref type="bibr" target="#b18">Yang et al., 2017)</ref>. Multilingual learning aims to improve the NER performance on the language under consid- eration (primary language) by adding training data from one or more assisting languages. The neural network is trained on the combined data of the pri- mary (D P ) and the assisting languages (D A ). The neural network has a combination of language- dependent and language-independent layers, and, the network learns better cross-lingual features via these language-independent layers. * This work began when the second author was a research scholar at IIT Bombay Existing approaches add all training sentences from the assisting language to the primary language and train the neural network on the combined data. However, data from assisting languages can introduce a drift in the tag distribu- tion for named entities, since the common named entities from the two languages may have vastly divergent tag distributions. For example, the entity China appears in training split of Spanish (pri- mary) and English (assisting) <ref type="bibr" target="#b15">(Tjong Kim Sang, 2002;</ref><ref type="bibr" target="#b16">Tjong Kim Sang and De Meulder, 2003)</ref> with the corresponding tag frequencies, Spanish = { Loc : 20, Org : 49, Misc : 1 } and English = { Loc : 91, Org : 7 }. By adding English data to Spanish, the tag distribution of China is skewed towards Location entity in Spanish. This leads to a drop in named entity recognition performance. In this work, we address this problem of drift in tag distribution owing to adding training data from a supporting language.</p><p>The problem is similar to the problem of data selection for domain adaptation of various NLP tasks, except that additional complexity is introduced due to the multilingual nature of the learning task. For domain adaptation in various NLP tasks, several approaches have been proposed to address drift in data distribution <ref type="bibr" target="#b11">(Moore and Lewis, 2010;</ref><ref type="bibr" target="#b0">Axelrod et al., 2011;</ref><ref type="bibr" target="#b13">Ruder and Plank, 2017)</ref>. For instance, in machine translation, sentences from out-of-domain data are selected based on a suitably defined metric <ref type="bibr" target="#b11">(Moore and Lewis, 2010;</ref><ref type="bibr" target="#b0">Axelrod et al., 2011</ref>). The metric attempts to capture similarity of the out-of-domain sentences with the in-domain data. Out-of-domain sentences most similar to the in-domain data are added.</p><p>Like the domain adaptation techniques summa- rized above, we propose to judiciously add sen- tences from the assisting language to the primary language data based on the divergence between the tag distributions of named entities in the train- Following are the contributions of the paper: (a) We present a simple approach to select assist- ing language sentences based on symmetric KL- Divergence of overlapping entities (b) We demon- strate the benefits of multilingual Neural NER on low-resource languages. We compare the pro- posed data selection approach with monolingual Neural NER system, and the multilingual Neural NER system trained using all assisting language sentences. To the best of our knowledge, ours is the first work for judiciously selecting a subset of sentences from an assisting language for multilin- gual Neural NER.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Judicious Selection of Assisting Language Sentences</head><p>For every assisting language sentence, we calcu- late the sentence score based on the average sym- metric KL-Divergence score of overlapping enti- ties present in that sentence. By overlapping enti- ties, we mean entities whose surface form appears in both the languages' training data. The symmet- ric KL-Divergence SKL(x), of a named entity x, is defined as follows,</p><formula xml:id="formula_0">SKL(x) = KL( P p (x) || P a (x) ) + KL( P a (x) || P p (x) ) /2 (1)</formula><p>where P p (x) and P a (x) are the probability dis- tributions for entity x in the primary (p) and the assisting (a) languages respectively. KL refers to the standard KL-Divergence score between the two probability distributions.</p><p>KL-Divergence calculates the distance between the two probability distributions. Lower the KL- Divergence score, higher is the tag agreement for an entity in both the languages thereby, reducing the possibility of entity drift in multilingual learn- ing. Assisting language sentences with the sen- tence score below a threshold value are added to the primary language data for multilingual learn- ing. If an assisting language sentence contains no overlapping entities, the corresponding sentence score is zero resulting in its selection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Network Architecture</head><p>Several deep learning models <ref type="bibr" target="#b2">(Collobert et al., 2011;</ref><ref type="bibr" target="#b10">Ma and Hovy, 2016;</ref><ref type="bibr" target="#b12">Murthy and Bhattacharyya, 2016;</ref><ref type="bibr" target="#b9">Lample et al., 2016;</ref><ref type="bibr" target="#b18">Yang et al., 2017</ref>) have been proposed for monolingual NER in the literature. Apart from the model by <ref type="bibr" target="#b2">Collobert et al. (2011)</ref>, remaining approaches ex- tract sub-word features using either Convolution Neural Networks (CNNs) or Bi-LSTMs. The proposed data selection strategy for multilingual Neural NER can be used with any of the existing models. We choose the model by <ref type="bibr" target="#b12">Murthy and Bhattacharyya (2016)</ref>  <ref type="bibr">1</ref> in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multilingual Learning</head><p>We consider two parameter sharing configurations for multilingual learning (i) sub-word feature extractors shared across languages ( <ref type="bibr" target="#b18">Yang et al., 2017</ref>) (Sub-word) (ii) the entire network trained in a language independent way (All). As Murthy and Bhattacharyya (2016) use CNNs to extract sub-word features, only the character-level CNNs are shared for the Sub-word configuration.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Setup</head><p>In this section we list the datasets used and the net- work configurations used in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets</head><p>The  <ref type="figure" target="#fig_1">(Kunchukuttan et al., 2015)</ref> thereby, allow- ing sharing of sub-word features across the Indian languages. For Indian languages, the annotated data followed the IOB format.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Network Hyper-parameters</head><p>With the exception of English, Spanish and Dutch, remaining language datasets did not have official train and development splits provided. We randomly select 70% of the train split for training the model and remaining as development split. The threshold for sentence score SKL, is selected based on cross-validation for every language pair. The dimensions of the Bi-LSTM hidden layer are 200 and 400 for the monolingual and multilingual experiments respectively. We extract 20 features per convolution filter, with width varying from 1 to 9. The initial learning rate is 0.4 and multiplied by 0.7 when validation error increases. The train- ing is stopped when the learning rate drops below 0.002. We assign a weight of 0.1 to assisting language sentences and oversample primary lan- guage sentences to match the assisting language sentence count in all multilingual experiments.</p><p>For European languages, we have performed hyper-parameter tuning for both the monolingual and multilingual learning (with all assisting lan- guage sentences) configurations. The best hyper- parameter values for the language pair involved were observed to be within similar range. Hence, we chose the same set of hyper-parameter values for all languages. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>We now present the results on both resource-rich and resource-poor languages. <ref type="table" target="#tab_2">Table 2</ref> presents the results for German and Ital- ian NER. We consistently observe improvements for German and Italian NER using our data se- lection strategy, irrespective of whether only sub- word features are shared (Sub-word) or the entire network (All) is shared across languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Resource-Rich Languages</head><p>Adding all Spanish/Dutch sentences to Italian data leads to drop in Italian NER performance when all layers are shared. Label drift from overlapping entities is one of the reasons for the poor results. This can be observed by compar- ing the histograms of English and Spanish sen- tences ranked by the SKL scores for Italian mul- tilingual learning <ref type="figure">(Figure 1</ref>). Most English sen- tences have lower SKL scores indicating higher tag agreement for overlapping entities and lower drift in tag distribution. Hence, adding all En- glish sentences improves Italian NER accuracy. In contrast, most Spanish sentences have larger SKL scores and adding these sentences adversely im- pacts Italian NER performance. By judiciously se- lecting assisting language sentences, we eliminate sentences which are responsible for drift occurring during multilingual learning.</p><p>To understand how overlapping entities im- pact the NER performance, we study the statis- tics of overlapping named entities between Italian- English and Italian-Spanish pairs. 911 and 916 unique entities out of 4061 unique Italian entities appear in the English and Spanish data respec- tively. We had hypothesized that entities with di- vergent tag distribution are responsible for hinder- ing the performance in multilingual learning. If we sort the common entities based on their SKL divergence value. We observe that 484 out of 911 common entities in English and 535 out of 916 common entities in Spanish have an SKL score greater than 1.0. 162 out of 484 common enti- ties in English-Italian data having SKL divergence value greater than 1.0 also appear more than 10 times in the English corpus. Similarly, 123 out of 535 common entities in Spanish-Italian data hav- ing SKL divergence value greater than 1.0 also appear more than 10 times in the Spanish cor- pus. However, these common 162 entities have a combined frequency of 12893 in English, mean- while the 123 common entities have a combined frequency of 34945 in Spanish. To summarize, al- though the number of overlapping entities is com- parable in English and Spanish sentences, entities with larger SKL divergence score appears more frequently in Spanish sentences compared to En- glish sentences. As a consequence, adding all Spanish sentences leads to significant drop in Ital- ian NER performance which is not the case when all English sentences are added.   <ref type="table" target="#tab_5">Table 3</ref>: Test set F-Score from monolingual and multilingual learning on Indian languages. Result from monolingual training on the primary language is underlined. † indicates SKL results statistically significant compared to adding all assisting language data with p-value &lt; 0.05 using two-sided Welch t-test.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Resource-Poor Languages</head><p>As Indian languages exhibit high lexical overlap <ref type="bibr" target="#b6">(Kunchukuttan and Bhattacharyya, 2016)</ref> and syntactic relatedness (V Subbãrão, 2012), we share all layers of the network across languages. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Influence of SKL Threshold</head><p>Here, we study the influence of SKL score threshold on the NER performance. We run experiments for Italian NER by adding Spanish training sentences and sharing all layers except for output layer across languages. We vary the threshold value from 1.0 to 9.0 in steps of 1, and select sentences with score less than the threshold. A threshold of 0.0 indicates monolingual training and threshold greater than 9.0 indicates all assist- ing language sentences considered. The plot of Italian test F-Score against SKL score is shown in the <ref type="figure" target="#fig_1">Figure 2</ref>. Italian test F-Score increases initially as we add more and more Spanish sentences and then drops due to influence of drift becoming significant. Finding the right SKL threshold is important, hence we use a validation set to tune the SKL threshold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we address the problem of diver- gence in tag distribution between primary and as- sisting languages for multilingual Neural NER. We show that filtering out the assisting language sentences exhibiting significant divergence in the tag distribution can improve NER accuracy. We propose to use the symmetric KL-Divergence met- ric to measure the tag distribution divergence. We observe consistent improvements in multilingual Neural NER performance using our data selec- tion strategy. The strategy shows benefits for ex- tremely low resource primary languages too.</p><p>This problem of drift in data distribution may not be unique to multilingual NER, and we plan to study the influence of data selection for mul- tilingual learning on other NLP tasks like sen- timent analysis, question answering, neural ma- chine translation, etc. We also plan to explore more metrics for multilingual learning, specifi- cally for morphologically rich languages.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>(</head><label></label><figDesc>Figure 1: Histogram of assisting language sentences ranked by their sentence scores</figDesc><graphic url="image-2.png" coords="4,83.34,215.81,204.09,136.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Spanish-Italian Multilingual Learning: Influence of Sentence score (SKL) on Italian NER</figDesc><graphic url="image-3.png" coords="4,307.28,580.39,218.27,145.51" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>F-Score for German and Italian Test data using Monolingual and Multilingual learning strate-
gies.  † indicates that the SKL results are statistically significant compared to adding all assisting language 
data with p-value &lt; 0.05 using two-sided Welch t-test. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 1 lists</head><label>1</label><figDesc>low-resource languages. We consider only Person, Location and Organization tags. Though the scripts of these languages are differ- ent, they share the same set of phonemes mak- ing script mapping across languages easier. We convert Tamil, Bengali and Malayalam data to the Devanagari script using the Indic NLP li- 2 Data is available here: http://www.cfilt.iitb. ac.in/ner/annotated_corpus/ brary 3</figDesc><table>the datasets used in our exper-
iments along with pre-trained word embeddings 
used and other dataset statistics. For German 
NER, we use ep-96-04-16.conll to create train and 
development splits, and use ep-96-04-15.conll 
as test split. As Italian has a different tag set 
compared to English, Spanish and Dutch, we do 
not share output layer for All configuration in 
multilingual experiments involving Italian. Even 
though the languages considered are resource-rich 
languages, we consider German and Italian as 
primary languages due to their relatively lower 
number of train tokens. The German NER data 
followed IO notation and for all experiments 
involving German, we converted other language 
data to IO notation. Similarly, the Italian NER 
data followed IOBES notation and for all ex-
periments involving Italian, we converted other 
language data to IOBES notation. 
For low-resource language setup, we consider 
the following Indian languages: Hindi, Marathi 2 , 
Bengali, Tamil and Malayalam. Except for Hindi 
all are </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 presents</head><label>3</label><figDesc></figDesc><table>the results. Bengali, Malayalam, 
and Tamil (low-resource languages) benefits from 
our data selection strategy. Hindi and Marathi 
NER performance improves when the other is 
used as assisting language. 
Bengali, Malayalam, and Tamil have weaker 
baselines compared to Hindi and Marathi, and are 
benefited from our approach irrespective of the 
assisting language chosen. However, Hindi and 
Marathi are not benefited from multilingual learn-
ing with Bengali, Malayalam and Tamil. Malay-
alam and Tamil being morphologically rich have 
low entity overlap (surface level) with Hindi and 
Marathi. As a result, only 2-3% of Malayalam and 
Tamil sentences are eliminated from our approach, 
leading to no gains from multilingual learning. 
Hindi and Marathi are negatively impacted by 
noisy Bengali data. Bengali has less training sen-
tences compared to other languages and, choosing 
a low SKL threshold results in selecting very few 
Bengali sentences for multilingual learning. 

</table></figure>

			<note place="foot" n="1"> The code is available here: https://github.com/ murthyrudra/NeuralNER</note>

			<note place="foot" n="3"> https://github.com/anoopkunchukuttan/ indic_nlp_library</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank Gajanan Rane and Geetanjali Rane for annotating the Marathi data, which was created as part of the CLIA project.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Domain adaptation via pseudo in-domain data selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amittai</forename><surname>Axelrod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Edinburgh, United Kingdom</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Enriching word vectors with subword information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Eigenwords: Spectral word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Paramveer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dean</forename><forename type="middle">P</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lyle</forename><forename type="middle">H</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ungar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Training and evaluating a German Named Entity Recognizer with semantic generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Padó</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of KONVENS</title>
		<meeting>KONVENS</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Multilingual language processing from bytes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Gillick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cliff</forename><surname>Brunk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amarnag</forename><surname>Subramanya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics<address><addrLine>San Diego, US</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Orthographic syllable as basic unit for SMT between related languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anoop</forename><surname>Kunchukuttan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushpak</forename><surname>Bhattacharyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Texas, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Brahmi-net: A transliteration and script conversion system for languages of the Indian subcontinent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anoop</forename><surname>Kunchukuttan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ratish</forename><surname>Puduppully</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushpak</forename><surname>Bhattacharyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations<address><addrLine>Colorado, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Indian language NER annotated FIRE 2014 corpus (FIRE 2014 NER Corpus)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shobha Lalitha Devi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Pattabhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malarkodi</forename><forename type="middle">C S</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R Vijay Sundar</forename><surname>Ram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Named-Entity Recognition Indian Languages FIRE 2014 Evaluation Track</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Neural architectures for Named Entity Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuya</forename><surname>Kawakami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandeep</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics<address><addrLine>San Diego, US</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">End-to-end sequence labeling via Bi-directional LSTM-CNNsCRF</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Intelligent selection of language model training data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Uppsala</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note>Sweden</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A deep learning solution to Named Entity Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Rudra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushpak</forename><surname>Murthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bhattacharyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CICLing</title>
		<meeting><address><addrLine>Konya, Turkey</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning to select data for transfer learning with Bayesian Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Plank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The Named Entity Recognition task at EVALITA</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuela</forename><surname>Speranza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop Evalita</title>
		<meeting>the Workshop Evalita</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Introduction to the conll-2002 shared task: Language-independent Named Entity Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><forename type="middle">F</forename><surname>Tjong Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th Conference on Natural Language Learning at COLING-02</title>
		<meeting>the 6th Conference on Natural Language Learning at COLING-02<address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Introduction to the conll-2003 shared task: Language-independent Named Entity Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><forename type="middle">F</forename><surname>Tjong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kim</forename><surname>Sang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fien De</forename><surname>Meulder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003</title>
		<meeting>the Seventh Conference on Natural Language Learning at HLT-NAACL 2003<address><addrLine>Edmonton, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kãrum˜kãrum˜uri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Subbãrão</surname></persName>
		</author>
		<title level="m">South Asian Languages: A Syntactic Typology</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Multi-task cross-lingual sequence tagging from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<meeting><address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
