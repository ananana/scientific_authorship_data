<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:04+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning Word Reorderings for Hierarchical Phrase-based Statistical Machine Translation</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingyi</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">National Institute of Information and Communications Technology</orgName>
								<address>
									<addrLine>3-5Hikaridai</addrLine>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Keihanna Science City</orgName>
								<address>
									<postCode>619-0289</postCode>
									<settlement>Kyoto</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Graduate School of Information Science</orgName>
								<orgName type="institution">Nara Institute of Science and Technology</orgName>
								<address>
									<postCode>630-0192</postCode>
									<settlement>Takayama</settlement>
									<region>Ikoma, Nara</region>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masao</forename><surname>Utiyama</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">National Institute of Information and Communications Technology</orgName>
								<address>
									<addrLine>3-5Hikaridai</addrLine>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Keihanna Science City</orgName>
								<address>
									<postCode>619-0289</postCode>
									<settlement>Kyoto</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eiichro</forename><surname>Sumita</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">National Institute of Information and Communications Technology</orgName>
								<address>
									<addrLine>3-5Hikaridai</addrLine>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Keihanna Science City</orgName>
								<address>
									<postCode>619-0289</postCode>
									<settlement>Kyoto</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
							<email>zhaohai@cs.sjtu.edu.cn</email>
							<affiliation key="aff3">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<postCode>200240</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="laboratory">Key Laboratory of Shanghai Education Commission for Intelligent Interaction and Cognitive Engineering</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<postCode>200240</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Learning Word Reorderings for Hierarchical Phrase-based Statistical Machine Translation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="542" to="548"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Statistical models for reordering source words have been used to enhance the hierarchical phrase-based statistical machine translation system. Existing word reordering models learn the reordering for any two source words in a sentence or only for two continuous words. This paper proposes a series of separate sub-models to learn reorderings for word pairs with different distances. Our experiments demonstrate that reordering sub-models for word pairs with distance less than a specific threshold are useful to improve translation quality. Compared with previous work, our method may more effectively and efficiently exploit helpful word reordering information .</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The hierarchical phrase-based model <ref type="bibr" target="#b1">(Chiang, 2005</ref>) is capable of capturing rich translation knowledge with the synchronous context-free grammar. But selecting proper translation rules during decoding is a challenge as a huge number of hierarchical rules can be applied to one source sentence. <ref type="bibr" target="#b1">Chiang (2005)</ref> used a log-linear model to com- pute rule weights with features similar to Pharaoh ( <ref type="bibr" target="#b7">Koehn et al., 2003)</ref>. However, to select appropri- ate rules, more effective criteria are required. A lot of work has been done for better rule selection.  and  used maximum entropy approaches to integrate rich contextual in- formation for target side rule selection. <ref type="bibr" target="#b2">Cui et al. (2010)</ref> proposed a joint model to select hierarchi- cal rules for both source and target sides. <ref type="bibr" target="#b5">Hayashi et al. (2010)</ref> demonstrated the ef- fectiveness of using word reordering information within hierarchical phrase-based SMT by integrat- ing <ref type="bibr" target="#b17">Tromble and Eisner (2009)</ref>'s word reordering model into decoder as a feature, which estimates the probability of any two source words in a sen- tence being reordered during translating. <ref type="bibr" target="#b3">Feng et al. (2013)</ref> proposed a word reordering model to learn reorderings only for continuous words, which reduced computation cost a lot compared with <ref type="bibr" target="#b17">Tromble and Eisner (2009)</ref>'s model and still achieved significant reordering improvement over the baseline system.</p><p>In this paper, we incorporate word reordering information into hierarchical phrase-based SMT by training a series of separate reordering sub- models for word pairs with different distances. We will demonstrate that the translation perfor- mance achieves consistent improvement as more sub-models for longer distance reorderings being integrated, but the improvement levels off quickly. That means sub-models for reordering distance longer than a given threshold do not improve trans- lation quality significantly. Compared with previ- ous models <ref type="bibr" target="#b17">(Tromble and Eisner, 2009;</ref><ref type="bibr" target="#b3">Feng et al., 2013)</ref>, our method makes full use of helpful word reordering information and also avoids unneces- sary computation cost for long distance reorder- ings. Besides, our reordering model is learned by feed-forward neural network (FNN) for better performance and uses efficient caching strategy to further reduce time cost.</p><p>Phrase reordering models have also been inte- grated into hierarchical phrase-based SMT. Phrase reordering models were originally developed for phrase-based SMT ( <ref type="bibr" target="#b8">Koehn et al., 2005;</ref><ref type="bibr" target="#b19">Zens and Ney, 2006;</ref><ref type="bibr" target="#b14">Ni et al., 2009;</ref>) and could not be used in hierarchical phrase-based model directly. <ref type="bibr" target="#b13">Nguyen and Vogel (2013)</ref> and <ref type="bibr" target="#b0">Cao et al. (2014)</ref> proposed to integrate phrase- based reordering features into hierarchical phrase- based SMT. However, their work limited to learn- ing the reordering of continuous phrases. For short phrases, in extreme cases, when phrase length is one, their model only learned reordering for con- tinuous word pairs like <ref type="bibr" target="#b3">Feng et al. (2013)</ref>'s work, while our model can be applied to word pairs with longer distances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Our Approach</head><p>Let e m 1 = e 1 , . . . , e m be a target translation of f l 1 = f 1 , . . . , f l and A be word alignments be- tween e m 1 and f l 1 , our model estimates the reorder- ing probability of the source sentence as follows:</p><formula xml:id="formula_0">Pr f l 1 , e m 1 , A ≈ N n=1 i,j:1≤i&lt;j≤l,j−i=n Pr f l 1 , e m 1 , A, i, j<label>(1)</label></formula><p>where Pr</p><formula xml:id="formula_1">f l 1 , e m 1 , A, i, j</formula><p>is the reordering prob- ability of the word pair f i , f j during translat- ing; N is the maximum distance for source word reordering, which is empirically determined by supposing that estimating reorderings longer than N does not improve translation performance any more.</p><p>Previous word reordering models <ref type="bibr" target="#b17">(Tromble and Eisner, 2009;</ref><ref type="bibr" target="#b3">Feng et al., 2013</ref>) consider the re- ordering of a source word pair to be reversed or not. When a source word is aligned to several uncontinuous target words, it can be hard to de- termine if a word pair is reversed or not. They solved this problem by only using one alignment from multiple alignments and ignoring the others. In contrast, our model handles all alignments as shown below.</p><p>Suppose that f i is aligned to π i (π i ≥ 0) target words. When π i &gt; 0, {a ik |1 ≤ k ≤ π i } stands for the positions of target words aligned to f i . If π i = 0 or π j = 0, Pr</p><formula xml:id="formula_2">f l 1 , e m 1 , A, i, j = 1, otherwise, Pr f l 1 , e m 1 , A, i, j = π i u=1 π j v=1 Pr oijuv|fi−3, ..., fj+3, ea iu , ea jv where oijuv = 0 (aiu ≤ ajv) 1 (aiu &gt; ajv)<label>(2)</label></formula><p>We train a series of sub-models,</p><formula xml:id="formula_3">M 1 , M 2 , . . . , M N Algorithm 1 Extract training instances.</formula><p>Require: A pair of parallel sentence f l 1 and e m 1 with word alignments. Ensure: Training examples for M1, M2, . . . , MN . to learn reorderings for word pairs with different distances. That means, for the word pair f i , f j with distance j − i = n, its reordering proba- bility Pr</p><formula xml:id="formula_4">for i = 1 to l − 1 do for j = i + 1 to l do if j − i ≤ N then for u = 1 to πi do for v = 1 to πj do if aiu ≤ ajv then fi−3, ...,</formula><formula xml:id="formula_5">o ijuv |f i−3 , ..., f j+3 , e a iu , e a jv</formula><p>is esti- mated by M n . Different sub-models are trained and integrated into the translation system sepa- rately.</p><p>Each sub-model M n is implemented by an FNN, which has the same structure with the neu- ral language model in ( <ref type="bibr" target="#b18">Vaswani et al., 2013)</ref>. The input to M n is a sequence of n + 9 words: f i−3 , ..., f j+3 , e a iu , e a jv . The input layer projects each word into a high dimensional vector using a matrix of input word embed- dings. Two hidden layers can combine all in- put data <ref type="bibr">1</ref>   The backpropagation algorithm is used to train these reordering sub-models. The training in- stances for each sub-model are extracted from the word-aligned parallel corpus according to Algo- rithm 1. For example, the word pair "(wears) (guy)" in <ref type="figure" target="#fig_0">Figure 1</ref> will be extracted as a pos- itive instance for M 3 . The input of this instance is as follows: "&lt;s&gt; &lt;s&gt; &lt;/s&gt; wears guy", where &lt;s&gt; and &lt;/s&gt; represent the beginning and ending of a sentence. If a word never occurs or only occurs once in train- ing corpus, we replace it with a special symbol &lt;unk&gt;.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Integration into the Decoder</head><p>In the hierarchical phrase-based model, a transla- tion rule r is like:</p><formula xml:id="formula_6">X → γ, α, ∼∼</formula><p>where X is a nonterminal, γ and α are re- spectively source and target strings of terminals and nonterminals, and ∼ is the alignment between nonterminals and terminals in γ and α.</p><p>Each rule has several features and the feature weights are tuned by the minimum error rate train- ing (MERT) algorithm <ref type="bibr" target="#b16">(Och, 2003)</ref>. To integrate our model into the hierarchical phrase-based trans- lation system, a new feature score n (r) is added to each rule r for each M n . The score of this fea- ture is calculated during decoding. Note that these scores are correspondingly calculated for differ- ent sub-models M n and the sub-model weights are tuned separately.</p><p>Suppose that r is applied to the input sentence f l 1 , where</p><formula xml:id="formula_7">• r covers the source span [f ϕ , f ϑ ] • γ contains nonterminals {X k |1 ≤ k ≤ K} • X k covers the span [f ϕ k , f ϑ k ] Then scoren (r) = i,j∈S− K k=1 S k ∧j−i=n log Pr f l 1 , e m 1 , A, i, j where S : {{i, j |ϕ ≤ i &lt; j ≤ ϑ} S k : {{i, j |ϕ k ≤ i &lt; j ≤ ϑ k }</formula><p>For example, if a rule "X1 X2 → X1 guy X2" is applied to the input sentence in <ref type="figure" target="#fig_0">Figure 1</ref>, then</p><formula xml:id="formula_8">[fϕ, f ϑ ] = [1, 5] ; [fϕ 1 , f ϑ 1 ] = [1, 1] ; [fϕ 2 , f ϑ 2 ] = [2, 4] S − K k=1 S k = 1, 2 , 1, 3 , 1, 4 , 1, 5 , 2, 5 , 3, 5 , 4, 5</formula><p>One concern in using target features is the com- putational efficiency, because reordering probabil- ities have to be calculated during decoding. So we cache probabilities to reduce the expensive neural network computation in experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We evaluated the proposed approach for Chinese- to-English (CE) and Japanese-to-English (JE) translation tasks. The official datasets for the patent machine translation task at NTCIR-9 ( <ref type="bibr" target="#b4">Goto et al., 2011</ref>) were used. The detailed statistics for training, development and test sets are given in <ref type="table">Ta- ble</ref>   In NTCIR-9, the development and test sets were both provided for CE task while only the test set was provided for the JE task. Therefore, we used the sentences from the NTCIR-8 JE test set as the development set for JE task. The word segmenta- tion was done by BaseSeg ( <ref type="bibr" target="#b22">Zhao et al., 2006;</ref><ref type="bibr" target="#b20">Zhao and Kit, 2008;</ref><ref type="bibr" target="#b21">Zhao and Kit, 2011;</ref><ref type="bibr" target="#b18">Zhao et al., 2013</ref>) for Chinese and Mecab 2 for Japanese.</p><p>To learn neural reordering models, the train- ing and development sets were put together to ob- tain symmetric word alignments using GIZA++ <ref type="bibr" target="#b15">(Och and Ney, 2003)</ref> and the grow-diag-final- and heuristic ( <ref type="bibr" target="#b7">Koehn et al., 2003</ref>). The reorder- ing instances extracted from the aligned training and development sets were used as the training and validation data respectively for learning neu- ral reordering models. Neural reordering models were trained by the toolkit NPLM ( <ref type="bibr" target="#b18">Vaswani et al., 2013)</ref>. For CE task, training instances extracted from all the 1M sentence pairs were used to train neural reordering models. For JE task, training instances were from 1M sentence pairs that were randomly selected from all the 3.14M sentence pairs. We also implemented <ref type="bibr" target="#b5">Hayashi et al. (2010)</ref>'s model for comparison. The training instances for their model were extracted from the same sentence pairs as ours.  For each translation task, the recent version of the Moses hierarchical phrase-based decoder ( <ref type="bibr" target="#b9">Koehn et al., 2007</ref>) with the training scripts was used as the baseline system Base. We used the default parameters for Moses. A 5-gram language model was trained on the target side of the training corpus by IRST LM Toolkit 3 with the improved Kneser-Ney smoothing.</p><note type="other">Base Hayashi M 1 1 M 2 1 M 3 1 M 4 1 model CE</note><p>We integrated our reordering models into Base. <ref type="table" target="#tab_5">Table 2</ref> gives detailed translation results. "Hayashi model" represents the method of ( <ref type="bibr" target="#b5">Hayashi et al., 2010)</ref>. "M j 1 (j = 1, 2, 3, 4)" means that Base was augmented with the reordering scores calcuated from a series of sub-models M 1 to M j .</p><p>As shown in <ref type="table" target="#tab_5">Table 2</ref>, integrating only M 1 , which predicts reordering for two continuous source words, has already given BLEU improve- ment 1.8% and 1.2% over baseline on CE and JE, respectively. As more sub-models for longer distance reordering being integrated, the transla- tion performance improved consistently, though the improvement leveled off quickly. For CE and JE tasks, M n with n ≥ 3 and n ≥ 4, respectively, cannot give further performance improvement at any significant level.</p><p>Why did the improvement level off quickly?  <ref type="table">Table 3</ref>: Classification accuracy (%).</p><p>In other words, why do long distance reordering models have a much less leverage over translation performance than short ones? First, the prediction accuracy decreases as the reordering distance increasing. <ref type="table">Table 3a</ref> gives classification accuracies on the validation data for each sub-model. The reason for accuracy decreas- ing is that the input size of sub-model grows as reordering distance increasing. Namely, long dis- tance reordering needs to consider more compli- cated context.</p><p>Second, we attribute the influence decrease of the longer reordering models to the redundancy of the predictions among different reordering mod- els. For example, in <ref type="figure" target="#fig_0">Figure 1</ref>, when word pairs "(guy) (is)" and "(is) (James)" are both predicted to be not reversed, the reorder- ing for "(guy) (James)" can be logi- cally determined to be not reversed without further reordering model prediction. That means, some- times, a long distance word reordering can be de- termined by a series of shorter word reordering pairs. But still, some predictions for longer reorder- ing are useful. For example, the reordering of "(wears) (guy)" cannot be determined when "(wears) (glasses)" is predicted to be not reversed and "(glasses) (guy)" is re- versed. This is the reason why translation perfor- mance improves as more sub-models being inte- grated.</p><p>As shown in <ref type="table" target="#tab_5">Table 2</ref>, with 4 sub-models be- ing integrated, our model improved baseline sys- tem significantly and also outperformed Hayashi model clearly. It is easy to understand, since our model was trained by feed-forward neural network on a high dimensional space and incorporated rich context information, while Hayashi model used the averaged perceptron algorithm and simple fea- tures. <ref type="table">Table 3b</ref> shows the prediction accuracies of Hayashi model. Note that Hayashi model pre- dicts reorderings for all word pairs, but only pre- diction accuracies for word pairs with distance 4 or less are shown. Compared with <ref type="table">Table 3a</ref>, the prediction accuracy of our model is much higher than Hayashi model. Actually, FNN is not suitable for Hayashi model since the computation cost for Hayashi model is quite expensive. Using FNN to reorder all word pairs could cost nearly one minute to translate one sentence according to our experi- ments, while integrating 4 sub-models only cost 10 seconds <ref type="bibr">4</ref> .</p><p>Compared with Hayashi model, our model not only speeds up decoding time but also reduces the training time. Training for Hayashi model is much slower since word pairs with all differ- ent distances are used as training data. By using separate sub-models, we can train each sub-model one by one and stop when translation performance cannot be improved any more. However, despite of efficiency, one unified model will theoretically have better performance than separate sub-models since separate sub-models do not share training in- stances and the unified model will suffer less from data sparsity. So, we did some extra experiments and trained a neural network which had the same structure as M 4 to learn reorderings for all word pairs with distance 4 or less, instead of using 4 separate neural networks. A specific word null was used since word pairs with distance 1,2,3 do not have enough inputs for M 4 . The significance test results showed that translation performance had no significant difference between one unified model and multiple sub-models. This is because the training corpus for our model is quite large, so separate training sets are sufficient for each sub- model to learn the reorderings well. Besides, us- ing neural networks to learn these sub-models on a continuous space can relieve the data sparsity problem to some extent.</p><p>Note that if we only integrate M 4 into Base, the translation quality of Base can be improved in our preliminary experiments. But M 4 cannot predict reorderings for word pairs with distance less than 4. So M 3 1 will be still needed for predicting re- orderings of word pairs with distance 1,2,3. But after M 3 1 being integrated, M 4 will not be needed due to the redundancy of the predictions among <ref type="bibr">4</ref> Note that cache was used in all our experiments to reduce the expensive neural network computation cost and turned out to be very useful. Without caching, integrating 4 sub-models could cost nearly 7 minutes to translate a sentence. different reordering models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we propose to enhance hierarchi- cal phrase-based SMT by training a series of sep- arate sub-models to learn reorderings for word pairs with distances less than a specific thresh- old, based on the experimental fact that longer dis- tance reordering models are not quite helpful for translation quality. Compared with <ref type="bibr" target="#b5">Hayashi et al. (2010)</ref>'s work, our model is much more efficient and keeps all helpful word reordering informa- tion. Besides, our reordering model is learned by feed-forward neural network and incorporates rich context information for better performance. On both Chinese-to-English and Japanese-to-English translation tasks, the proposed model outperforms the previous model significantly. <ref type="bibr">Hai Zhao, Masao Utiyama, Eiichiro Sumita, and BaoLiang Lu. 2013</ref>. An empirical study on word seg- mentation for chinese machine translation. In Com- putational Linguistics and Intelligent Text Process- ing, pages 248-263.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: A Chinese-English sentence pair.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>.</head><label></label><figDesc></figDesc><table>The output layer has two neurons that 
give Pr 

o ijuv = 1|f i−3 , ..., f j+3 , e a iu , e a jv 

and 

Pr 

o ijuv = 0|f i−3 , ..., f j+3 , e a iu , e a jv 

. 

那个 
戴 
眼镜 
的 
男生 
是 
詹姆士 

That guy 
who wears glasses 
is James 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>1 .</head><label>1</label><figDesc></figDesc><table>SOURCE TARGET 

CE 

TRAINING #Sents 
954K 
#Words 37.2M 
40.4M 
#Vocab 288K 
504K 
DEV 
#Sents 
2K 
TEST 
#Sents 
2K 

JE 

TRAINING #Sents 
3.14M 
#Words 118M 
104M 
#Vocab 150K 
273K 
DEV 
#Sents 
2K 
TEST 
#Sents 
2K 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 1 : Data sets.</head><label>1</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 2 : Translation results.</head><label>2</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="1"> If we choose the averaged perceptron algorithm to learn reordering task as used in (Hayashi et al., 2010), we need to artificially select n-gram features, which is not necessary for FNN.</note>

			<note place="foot" n="2"> http://sourceforge.net/projects/mecab/files/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>Masao Utiyama and Hai Zhao are corresponding authors. This work was done when the first au-thor was a master's student at Shanghai Jiao Tong University. Hai Zhao was supported by the Na-tional Natural Science Foundation of China un-der Grants 60903119, 61170114 and 61272248, the National Basic Research Program of China un-der Grant 2013CB329401, the Science and Tech-nology Commission of Shanghai Municipality un-der Grant 13511500200, the European Union Sev-enth Framework Program under <ref type="bibr">Grant 247619, the Cai Yuanpei Program (CSC fund 201304490199, 201304490171)</ref>, and the art and science interdisci-pline funds of Shanghai Jiao Tong University un-der Grant 14X190040031(14JCRZ04).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A lexicalized reordering model for hierarchical phrase-based translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hailong</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongdong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiejun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers</title>
		<meeting>COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1144" to="1153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A hierarchical phrase-based model for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL&apos;05)</title>
		<meeting>the 43rd Annual Meeting of the Association for Computational Linguistics (ACL&apos;05)</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="263" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A joint rule selection model for hierarchical phrase-based translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongdong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiejun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2010 Conference Short Papers</title>
		<meeting>the ACL 2010 Conference Short Papers</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="6" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Advancements in reordering models for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minwei</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan-Thorsten</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="322" to="332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Overview of the patent machine translation task at the NTCIR-9 workshop</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isao</forename><surname>Goto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ka</forename><forename type="middle">Po</forename><surname>Chow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eiichiro</forename><surname>Sumita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin K</forename><surname>Tsou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 9th NII Test Collection for IR Systems Workshop Meeting</title>
		<meeting>The 9th NII Test Collection for IR Systems Workshop Meeting</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="559" to="578" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Hierarchical phrase-based machine translation with word-based reordering model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katsuhiko</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hajime</forename><surname>Tsukada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katsuhito</forename><surname>Sudoh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seiichi</forename><surname>Yamamoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics</title>
		<meeting>the 23rd International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="439" to="446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Improving statistical machine translation using lexicalized rule selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongjun</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shouxun</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Computational Linguistics</title>
		<meeting>the 22nd International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="321" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Statistical phrase-based translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz</forename><forename type="middle">Josef</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology</title>
		<meeting>the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="48" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Edinburgh system description for the 2005 IWSLT speech translation evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amittai</forename><surname>Axelrod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miles</forename><surname>Osborne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Talbot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The International Workshop on Spoken Language Translation</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="68" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Moses: Open source toolkit for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brooke</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wade</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Herbst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions</title>
		<meeting>the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume the Demo and Poster Sessions</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="177" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Statistical significance tests for machine translation evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2004</title>
		<meeting>EMNLP 2004</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="388" to="395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A neural reordering model for phrase-based translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatsuya</forename><surname>Izuha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dakun</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers</title>
		<meeting>COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1897" to="1907" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Maximum entropy based rule selection model for syntax-based statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongjun</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shouxun</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2008 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="89" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Integrating phrase-based reordering features into a chartbased decoder for machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thuylinh</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Vogel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1587" to="1596" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Handling phrase reorderings for machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhao</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Craig</forename><surname>Saunders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandor</forename><surname>Szedmak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahesan</forename><surname>Niranjan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACLIJCNLP 2009 Conference Short Papers</title>
		<meeting>the ACLIJCNLP 2009 Conference Short Papers</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="241" to="244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A systematic comparison of various statistical alignment models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Franz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="19" to="51" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Minimum error rate training in statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz Josef</forename><surname>Och</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 41st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="160" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning linear ordering problems for better translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Tromble</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2009 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1007" to="1016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Decoding with largescale neural language models improves translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinggong</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victoria</forename><surname>Fossum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1387" to="1392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Discriminative reordering models for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings on the Workshop on Statistical Machine Translation</title>
		<meeting>on the Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="55" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Exploiting unlabeled text with different unsupervised segmentation criteria for chinese word segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyu</forename><surname>Kit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Research in Computing Science</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="93" to="104" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Integrating unsupervised and supervised word segmentation: The role of goodness measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyu</forename><surname>Kit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">181</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="163" to="183" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">An improved chinese word segmentation system with conditional random field</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang-Ning</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing</title>
		<meeting>the Fifth SIGHAN Workshop on Chinese Language Processing</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="162" to="165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A unified character-based tagging framework for chinese word segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang-Ning</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bao-Liang</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Asian Language Information Processing (TALIP)</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
