<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:09+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Edge-Linear First-Order Dependency Parsing with Undirected Minimum Spanning Tree Inference</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Effi</forename><surname>Levi</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Reichart</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Faculty of Industrial Engineering and Management</orgName>
								<address>
									<settlement>Technion</settlement>
									<region>IIT</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Rappoport</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computer Science</orgName>
								<orgName type="institution">The Hebrew Univeristy</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Edge-Linear First-Order Dependency Parsing with Undirected Minimum Spanning Tree Inference</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="2104" to="2113"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The run time complexity of state-of-the-art inference algorithms in graph-based dependency parsing is super-linear in the number of input words (n). Recently, pruning algorithms for these models have shown to cut a large portion of the graph edges, with minimal damage to the resulting parse trees. Solving the inference problem in run time complexity determined solely by the number of edges (m) is hence of obvious importance. We propose such an inference algorithm for first-order models, which encodes the problem as a minimum spanning tree (MST) problem in an undirected graph. This allows us to utilize state-of-the-art undirected MST algorithms whose run time is O(m) at expectation and with a very high probability. A directed parse tree is then inferred from the undirected MST and is subsequently improved with respect to the directed parsing model through local greedy updates, both steps running in O(n) time. In experiments with 18 languages, a variant of the first-order MSTParser (McDonald et al., 2005b) that employs our algorithm performs very similarly to the original parser that runs an O(n 2) directed MST inference.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Dependency parsers are major components of a large number of NLP applications. As application models are applied to constantly growing amounts of data, efficiency becomes a major consideration.</p><p>In graph-based dependency parsing models <ref type="bibr" target="#b9">(Eisner, 2000;</ref><ref type="bibr" target="#b26">McDonald et al., 2005a;</ref><ref type="bibr" target="#b27">McDonald et al., 2005b;</ref><ref type="bibr" target="#b2">Carreras, 2007;</ref><ref type="bibr" target="#b18">Koo and Collins, 2010b)</ref>, given an n word sentence and a model or- der k, the run time of exact inference is O(n 3 ) for k = 1 and O(n k+1 ) for k &gt; 1 in the projective case <ref type="bibr" target="#b8">(Eisner, 1996;</ref><ref type="bibr" target="#b24">McDonald and Pereira, 2006</ref>). In the non-projective case it is O(n 2 ) for k = 1 and NP-hard for k ≥ 2 ( <ref type="bibr" target="#b25">McDonald and Satta, 2007)</ref>. <ref type="bibr">1</ref> Consequently, a number of approximated parsers have been introduced, utilizing a variety of techniques: the Eisner algorithm <ref type="bibr" target="#b24">(McDonald and Pereira, 2006</ref>), belief propagation ( <ref type="bibr" target="#b35">Smith and Eisner, 2008)</ref>, dual decomposition ( <ref type="bibr" target="#b18">Koo and Collins, 2010b;</ref><ref type="bibr" target="#b23">Martins et al., 2013</ref>) and multi-commodity flows <ref type="bibr" target="#b21">(Martins et al., 2009;</ref><ref type="bibr" target="#b22">Martins et al., 2011</ref>). The run time of all these approximations is super- linear in n.</p><p>Recent pruning algorithms for graph-based de- pendency parsing <ref type="bibr" target="#b33">(Rush and Petrov, 2012;</ref><ref type="bibr" target="#b32">Riedel et al., 2012;</ref><ref type="bibr" target="#b38">Zhang and McDonald, 2012</ref>) have shown to cut a very large portion of the graph edges, with minimal damage to the resulting parse trees. For example, <ref type="bibr" target="#b33">Rush and Petrov (2012)</ref> demonstrated that a single O(n) pass of vine- pruning (Eisner and <ref type="bibr" target="#b7">Smith, 2005</ref>) can preserve &gt; 98% of the correct edges, while ruling out &gt; 86% of all possible edges. Such results give strong motivation to solving the inference problem in a run time complexity that is determined solely by the number of edges (m). <ref type="bibr">2</ref> In this paper we propose to formulate the infer- ence problem in first-order (arc-factored) depen- dency parsing as a minimum spanning tree (MST) problem in an undirected graph. Our formulation allows us to employ state-of-the-art algorithms for the MST problem in undirected graphs, whose run time depends solely on the number of edges in the graph. Importantly, a parser that employs our undirected inference algorithm can generate all possible trees, projective and non-projective.</p><p>Particularly, the undirected MST problem ( § 2) has a randomized algorithm which is O(m) at expectation and with a very high probability <ref type="bibr" target="#b16">((Karger et al., 1995)</ref>), as well as an O(m · α(m, n)) worst-case deterministic algorithm <ref type="bibr" target="#b31">(Pettie and Ramachandran, 2002)</ref>, where α(m, n) is a certain natural inverse of Ackermann's func- tion <ref type="bibr" target="#b14">(Hazewinkel, 2001)</ref>. As the inverse of Ack- ermann's function grows extremely slowly 3 the deterministic algorithm is in practice linear in m ( § 3). In the rest of the paper we hence refer to the run time of these two algorithms as practically linear in the number of edges m.</p><p>Our algorithm has four steps ( § 4). First, it encodes the first-order dependency parsing infer- ence problem as an undirected MST problem, in up to O(m) time. Then, it computes the MST of the resulting undirected graph. Next, it infers a unique directed parse tree from the undirected MST. Finally, the resulting directed tree is greed- ily improved with respect to the directed parsing model. Importantly, the last two steps take O(n) time, which makes the total run time of our al- gorithm O(m) at expectation and with very high probability. <ref type="bibr">4</ref> We integrated our inference algorithm into the first-order parser of <ref type="bibr" target="#b27">(McDonald et al., 2005b</ref>) and compared the resulting parser to the original parser which employs the Chu-Liu-Edmonds algorithm <ref type="bibr">(CLE, (Chu and Liu, 1965;</ref><ref type="bibr" target="#b6">Edmonds, 1967)</ref>) for inference. CLE is the most efficient exact in- ference algorithm for graph-based first-order non- projective parsers, running at O(n 2 ) time. <ref type="bibr">5</ref> jointly performed in O(n) steps. We therefore do not include initial graph construction and pruning in our complexity com- putations.</p><p>3 α(m, n) is less than 5 for any practical input sizes (m, n). <ref type="bibr">4</ref> The output dependency tree contains exactly n−1 edges, therefore m ≥ n − 1, which makes O(m) + O(n) = O(m).</p><p>5 CLE has faster implementations: O(m+nlogn) ( <ref type="bibr" target="#b10">Gabow et al., 1986)</ref> as well as O(mlogn) for sparse graphs <ref type="bibr" target="#b36">(Tarjan, 1977)</ref>, both are super-linear in n for connected graphs. We re- We experimented ( § 5) with 17 languages from the CoNLL 2006 and 2007 shared tasks on multi- lingual dependency parsing ( <ref type="bibr" target="#b1">Buchholz and Marsi, 2006;</ref><ref type="bibr" target="#b29">Nilsson et al., 2007)</ref> and in three English setups. Our results reveal that the two algorithms perform very similarly. While the averaged un- labeled attachment accuracy score (UAS) of the original parser is 0.97% higher than ours, in 11 of 20 test setups the number of sentences that are bet- ter parsed by our parser is larger than the number of sentences that are better parsed by the original parser.</p><p>Importantly, in this work we present an edge-linear first-order dependency parser which achieves similar accuracy to the existing one, mak- ing it an excellent candidate to be used for effi- cient MST computation in k-best trees methods, or to be utilized as an inference/initialization sub- routine as a part of more complex approximation frameworks such as belief propagation. In addi- tion, our model produces a different solution com- pared to the existing one (see <ref type="table" target="#tab_1">Table 2</ref>), paving the way for using methods such as dual decomposi- tion to combine these two models into a superior one.</p><p>Undirected inference has been recently ex- plored in the context of transition based pars- ing <ref type="bibr">(Gómez-Rodríguez and Fernández-González, 2012;</ref><ref type="bibr" target="#b12">Gómez-Rodríguez et al., 2015)</ref>, with the motivation of preventing the propagation of erro- neous early edge directionality decisions to sub- sequent parsing decisions. Yet, to the best of our knowledge this is the first paper to address undi- rected inference for graph based dependency pars- ing. Our motivation and algorithmic challenges are substantially different from those of the earlier transition based work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Undirected MST with the Boruvka Algorithm</head><p>In this section we define the MST problem in undi- rected graphs. We then discuss the Burovka al- gorithm <ref type="bibr">(Boruvka, 1926;</ref><ref type="bibr" target="#b28">Nesetril et al., 2001</ref>) which forms the basis for the randomized algo- rithm of <ref type="bibr" target="#b16">(Karger et al., 1995</ref>) we employ in this pa- per. In the next section we will describe the <ref type="bibr" target="#b16">Karger et al. (1995)</ref> algorithm in more details.</p><p>Problem Definition. For a connected undirected graph G(V, E), where V is the set of n vertices fer here to the classical implementation employed by modern parsers (e.g. ( <ref type="bibr" target="#b27">McDonald et al., 2005b;</ref><ref type="bibr" target="#b23">Martins et al., 2013)</ref>).</p><p>and E the set of m weighted edges, the MST prob- lem is defined as finding the sub-graph of G which is the tree (a connected acyclic graph) with the lowest sum of edge weights. The opposite prob- lem -finding the maximum spanning tree -can be solved by the same algorithms used for the mini- mum variant by simply negating the graph's edge weights.</p><p>Graph Contraction. In order to understand the Boruvka algorithm, let us first define the Graph Contraction operation. For a given undirected graph G(V, E) and a subset˜Esubset˜ subset˜E ⊆ E, this oper- ation creates a new graph, G C (V C , E C ). In this new graph, V C consists of a vertex for each con- nected component iñ G(V, ˜ E) (these vertices are referred to as super-vertices). E C , in turn, consists of one edge,</p><formula xml:id="formula_0">(ˆ u, ˆ v), for each edge (u, v) ∈ E \ ˜ E, wherê u, ˆ v ∈ V C correspond tõ G'</formula><p>s connected components to which u and v respectively belong. Note that this definition may result in multiple edges between two vertices in V C (denoted repeti- tive edges) as well as in edges from a vertex in V C to itself (denoted self edges).</p><p>Algorithm 1 The basic step of the Boruvka algo- rithm for the undirected MST problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contract graph</head><formula xml:id="formula_1">Input: a graph G(V, E), a subset˜Esubset˜ subset˜E ⊆ E C ← connected components of˜Gof˜ of˜G(V, ˜ E) return G C (C, E \ ˜ E) Boruvka-step Input: a graph G(V, E) 1: for all (u, v) ∈ E do 2:</formula><p>if w(u, v) &lt; w(u.minEdge) then 3:</p><formula xml:id="formula_2">u.minEdge ← (u, v) 4:</formula><p>end if</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>if w(u, v) &lt; w(v.minEdge) then 6:</p><formula xml:id="formula_3">v.minEdge ← (u, v) 7:</formula><p>end if 8: end for 9: for all v ∈ V do 10:  <ref type="formula">(13)</ref>). The set E m created in each such step is guaranteed to consist only of edges that belong to G's MST and is therefore also returned by the Boruvka step. The Boruvka algorithm runs successive Boruvka-steps until it is left with a single super- vertex. The MST of the original graph G is given by the unification of the E m sets returned in each step. The resulting computational complexity is O(m log n) <ref type="bibr" target="#b28">(Nesetril et al., 2001</ref>). We now turn to describe how the undirected MST problem can be solved in a time practically linear in the number of graph edges.</p><formula xml:id="formula_4">E m ← E m ∪ {v.minEdge} 11: end for 12: G B (V B , E B ) ← Contract graph(G(V, E),E m</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Undirected MST in Edge Linear Time</head><p>There are two algorithms that solve the undirected MST problem in time practically linear in the number of edges in the input graph. These al- gorithms are based on substantially different ap- proaches: one is deterministic and the other is ran- domized 6 .</p><p>The complexity of the first, deterministic, algo- rithm <ref type="bibr" target="#b3">(Chazelle, 2000;</ref><ref type="bibr" target="#b31">Pettie and Ramachandran, 2002</ref>) is O(m · α(m, n)), where α(m, n) is a natu- ral inverse of Ackermann's function, whose value for any practical values of n and m is lower than 5. As this algorithm employs very complex data- structures, we do not implement it in this paper.</p><p>The second, randomized, algorithm <ref type="bibr" target="#b16">(Karger et al., 1995)</ref> has an expected run time of O(m + n) (which for connected graphs is O(m)), and this run time is achieved with a high probability of 1 − exp(−Ω(m)). <ref type="bibr">7</ref> In this paper we employ only this algorithm for first-order graph-based parsing inference, and hence describe it in details in this section.</p><p>Definitions and Properties. We first quote two properties of undirected graphs <ref type="bibr" target="#b37">(Tarjan, 1983)</ref>: <ref type="formula">(1)</ref> The cycle property: The heaviest edge in a cycle in a graph does not appear in the MSF; and (2) The cut property: For any proper nonempty subset V of the graph vertices, the lightest edge with exactly one endpoint in V is included in the MSF.</p><p>We continue with a number of definitions and observations. Given an undirected graph G(V, E) with weighted edges, and a forest F in that graph, F (u, v) is the path in that forest between u and v (if such a path exists), and s F (u, v) is the maxi- mum weight of an edge in F (u, v) (if the path does not exist then</p><formula xml:id="formula_5">s F (u, v) = ∞). An edge (u, v) ∈ E is called F-heavy if s(u, v) &gt; s F (u, v), otherwise it is called F-light.</formula><p>An alternative equivalent def- inition is that an edge is F-heavy if adding it to F creates a cycle in which it is the heaviest edge. An important observation (derived from the cycle property) is that for any forest F , no F-heavy edge can possibly be a part of an MSF for G. It has been shown that given a forest F , all the F-heavy edges in G can be found in O(m) time ( <ref type="bibr" target="#b5">Dixon et al., 1992;</ref><ref type="bibr" target="#b17">King, 1995)</ref>.</p><p>Algorithm. The randomized algorithm can be outlined as follows (see pseudocode in algo- rithm 2): first, two successive Boruvka-steps are applied to the graph (line 4, Boruvka-step2 stands for two successive Boruvka-steps), reducing the number of vertices by (at least) a factor of 4 to receive a contracted graph G C and an edge set E m ( § 2). Then, a subgraph G s is randomly con- structed, such that each edge in G C , along with Algorithm 2 Pseudocode for the Randomized MSF algorithm of <ref type="bibr" target="#b16">(Karger et al., 1995</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Randomized MSF Input: a graph G(V, E)</head><p>1: if E is empty then 2:</p><formula xml:id="formula_6">return ∅ 3: end if 4: G C (V C , E C ), E m ← Boruvka-step2(G) 5: for all (u, v) ∈ E C do 6:</formula><p>if coin-flip == head then 7:</p><formula xml:id="formula_7">E s ← E s ∪ {(u, v)} 8: V s ← V s ∪ {u, v} 9: end if 10: end for 11: F ← Randomized MSF(G s (V s , E s )) 12: remove all F-heavy edges from G C (V C , E C ) 13: F C ← Randomized MSF(G C (V C , E C )) 14: return F C ∪ E m</formula><p>the vertices which it connects, is included in G s with probability 1 2 (lines 5-10). Next, the algo- rithm is recursively applied to G s to obtain its min- imum spanning forest F (line 11). Then, all F- heavy edges are removed from G C (line 12), and the algorithm is recursively applied to the result- ing graph to obtain a spanning forest F C (line 13). The union of that forest with the edges E m forms the requested spanning forest (line 14).</p><p>Correctness. The correctness of the algorithm is proved by induction. By the cut property, every edge returned by the Boruvka step (line 4), is part of the MSF. Therefore, the rest of the edges in the original graph's MSF form an MSF for the con- tracted graph. The removed F-heavy edges are, by the cycle property, not part of the MSF (line 12). By the induction assumption, the MSF of the re- maining graph is then given by the second recur- sive call (line 13).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Undirected MST Inference for Dependency Parsing</head><p>There are several challenges in the construction of an undirected MST parser: an MST parser that employs an undirected MST algorithm for infer- ence. 8 These challenges stem from the mismatch between the undirected nature of the inference al- gorithm and the directed nature of the resulting parse tree. The first problem is that of undirected encod- ing. Unlike directed MST parsers that explicitly encode the directed nature of dependency parsing into a directed input graph to which an MST al- gorithm is applied ( <ref type="bibr" target="#b27">McDonald et al., 2005b</ref>), an undirected MST parser needs to encode direction- ality information into an undirected graph. In this section we consider two solutions to this problem.</p><p>The second problem is that of scheme conver- sion. The output of an undirected MST algorithm is an undirected tree while the dependency pars- ing problem requires finding a directed parse tree. In this section we show that for rooted undirected spanning trees there is only one way to define the edge directions under the constraint that the root vertex has no incoming edges and that each non- root vertex has exactly one incoming edge in the resulting directed spanning tree. As dependency parse trees obey the first constraint and the sec- ond constraint is a definitive property of directed trees, the output of an undirected MST parser can be transformed into a directed tree using a simple O(n) time procedure.</p><p>Unfortunately, as we will see in § 5, even with our best undirected encoding method, an undi- rected MST parser does not produce directed trees of the same quality as its directed counterpart. At the last part of this section we therefore present a simple, O(n) time, local enhancement proce- dure, that improves the score of the directed tree generated from the output of the undirected MST parser with respect to the edge scores of a stan- dard directed MST parser. That is, our procedure improves the output of the undirected MST parser with respect to a directed model without having to compute the MST of the latter, which would take O(n 2 ) time.</p><p>We conclude this section with a final remark stating that the output class of our inference algo- rithm is non-projective. That is, it can generate all possible parse trees, projective and non-projective.</p><p>Undirected Encoding Our challenge here is to design an encoding scheme that encodes direc- tionality information into the graph of the undi- rected MST problem. One approach would be to compute directed edge weights according to a fea- ture representation scheme for directed edges (e.g. one of the schemes employed by existing directed MST parsers) and then transform these directed weights into undirected ones. Specifically, given two vertices u and v with directed edges (u, v) and (v, u), weighted with s d (u, v) and s d (v, u) respectively, the goal is to compute the weight s u ( ˆ u, v) of the undirected edge ( ˆ u, v) connecting them in the undirected graph. We do this using a pre-determined function</p><formula xml:id="formula_8">f : R × R → R, such that f (s d (u, v), s d (v, u)) = s u ( ˆ u, v)</formula><p>. f can take several forms including mean, product and so on. In our experiments the mean proved to be the best choice.</p><p>Training with the above approach is imple- mented as follows. w, the parameter vector of the parser, consists of the weights of directed fea- tures. At each training iteration, w is used for the computation of s d (u, v) = w · φ(u, v) and s d (v, u) = w · φ(v, u) (where φ(u, v) and φ(v, u) are the feature representations of these directed edges). Then, f is applied to compute the undi- rected edge score s u ( ˆ u, v). Next, the undirected MST algorithm is run on the resulting weighted undirected graph, and its output MST is trans- formed into a directed tree (see below). Finally, this directed tree is used for the update of w with respect to the gold standard (directed) tree.</p><p>At test time, the vector w which resulted from the training process is used for s d computations. Undirected graph construction, undirected MST computation and the undirected to directed tree conversion process are conducted exactly as in training. <ref type="bibr">9</ref> Unfortunately, preliminary experiments in our development setup revealed that this approach yields parse trees of much lower quality compared to the trees generated by the directed MST parser that employed the original directed feature set. In § 5 we discuss these results in details.</p><p>An alternative approach is to employ an undi- rected feature set. To implement this approach, we employed the feature set of the MST parser ( <ref type="bibr" target="#b26">(McDonald et al., 2005a</ref>), <ref type="table" target="#tab_0">Table 1</ref>) with one differ- ence: some of the features are directional, distin- guishing between the properties of the source (par- ent) and the target (child) vertices. We stripped those features from that information, which re- sulted in an undirected version of the feature set.</p><p>Under this feature representation, training with undirected inference is simple. w, the parameter vector of the parser, now consists of the weights of undirected features. Once the undirected MST is computed by an undirected MST algorithm, w can be updated with respect to an undirected vari- ant of the gold parse trees. At test time, the al- gorithm constructs an undirected graph using the vector w resulted from the training process. This graph's undirected MST is computed and then transformed into a directed tree. Interestingly, although this approach does not explicitly encode edge directionality information into the undirected model, it performed very well in our experiments ( § 5), especially when com- bined with the local enhancement procedure de- scribed below.</p><p>Scheme Conversion Once the undirected MST is found, we need to direct its edges in order for the end result to be a directed dependency parse tree. Following a standard practice in graph-based de- pendency parsing (e.g. <ref type="figure">(McDonald et al., 2005b)</ref>), before inference is performed we add a dummy root vertex to the initial input graph with edges connecting it to all of the other vertices in the graph. Consequently, the final undirected tree will have a designated root vertex. In the resulting directed tree, this vertex is constrained to have only outgoing edges. As observed by <ref type="bibr">GómezRodríguez and Fernández-González (2012)</ref>, this effectively forces the direction for the rest of the edges in the tree.</p><p>Given a root vertex that follows the above con- straint, and together with the definitive property of directed trees stating that each non-root vertex in the graph has exactly one incoming edge, we can direct the edges of the undirected tree using a sim- ple BFS-like algorithm <ref type="figure">(Figure 2)</ref>. Starting with the root vertex, we mark its undirected edges as outgoing, mark the vertex itself as done and its de- scendants as open. We then recursively repeat the same procedure for each open vertex until there are no such vertices left in the tree, at which point we have a directed tree. Note that given the con- straints on the root vertex, there is no other way to direct the undirected tree edges. This procedure runs in O(n) time, as it requires a constant num- ber of operations for each of the n − 1 edges of the undirected spanning tree.</p><p>In the rest of the paper we refer to the directed tree generated by the undirected and directed MST parsers as du-tree and dd-tree respectively.</p><p>Local Enhancement Procedure As noted above, experiments in our development setup ( § 5) revealed that the directed parser performs somewhat better than the undirected one. This motivated us to develop a local enhancement procedure that improves the tree produced by the undirected model with respect to the directed model without compromising our O(m) run time. Our enhancement procedure is motivated by development experiments, revealing the much smaller gap between the quality of the du-tree and dd-tree of the same sentence under undirected evaluation compared to directed evaluation ( § 5 demonstrates this for test results).</p><p>For a du-tree that contains the vertex u and the edges (t, u) and (u, v), we therefore consider the replacement of (u, v) with (v, u). Note that after this change our graph would no longer be a di- rected tree, since it would cause u to have two par- ents, v and t, and v to have no parent. This, how- ever, can be rectified by replacing the edge (t, u) with the edge (t, v).</p><p>It is easy to infer whether this change results in a better (lower weight) spanning tree under the di- rected model by computing the equation: <ref type="figure">y)</ref> is the score of the edge (x, y) according to the directed model. This is illustrated in <ref type="figure">Figure 3</ref>.</p><formula xml:id="formula_9">gain = s d (t, u) + s d (u, v) − (s d (t, v) + s d (v, u)), where s d (x,</formula><p>Given the du-tree, we traverse its edges and compute the above gain for each. We then choose the edge with the maximal positive gain, as this forms the maximal possible decrease in the di- rected model score using modifications of the type we consider, and perform the corresponding mod- ification. In our experiments we performed this procedure five times per inference problem. <ref type="bibr">10</ref> This procedure performs a constant number of opera- tions for each of the n − 1 edges of the du-tree, resulting in O(n) run time.</p><p>Output Class. Our undirected MST parser is non-projective. This stems from the fact that the undirected MST algorithms we discuss in § 3 do not enforce any structural constraint, and particu- larly the non-crossing constraint, on the resulting undirected MST. As the scheme conversion (edge directing) and the local enhancement procedures described in this section do not enforce any such constraint as well, the resulting tree can take any possible structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments and Results</head><p>Experimental setup We evaluate four models: (a) The original directed parser (D-MST, <ref type="bibr" target="#b27">(McDonald et al., 2005b)</ref>); (b) Our undirected MST parser with undirected features and with the local en- hancement procedure (U-MST-uf-lep); 11 (c) Our undirected MST parser with undirected features but without the local enhancement procedure (U- MST-uf); and (d) Our undirected MST parser with directed features (U-MST-df). All models are im- plemented within the MSTParser code <ref type="bibr">12</ref> .</p><p>The MSTParser does not prune its input graphs. To demonstrate the value of undirected parsing for sparse input graphs, we implemented the length- dictionary pruning strategy which eliminates all edges longer than the maximum length observed for each directed head-modifier POS pair in the training data. An undirected edgê (u, v) is pruned if f both directed edges (u, v) and (v, u) are to be pruned according to the pruning method. To esti- mate the accuracy/graph-size tradeoff provided by undirected parsing (models (b)-(d)), we apply the pruning strategy only to these models leaving the the D-MST model (model (a)) untouched. This way D-MST runs on a complete directed graph with n 2 edges.</p><p>Our models were developed in a monolin- gual setup: training on sections 2-21 of WSJ PTB ( <ref type="bibr" target="#b20">Marcus et al., 1993</ref>) and testing on section 22. The development phase was devoted to the various decisions detailed throughout this paper and to the tuning of the single hyperparameter: the number of times the local enhancement procedure is executed.</p><p>We tested the models in 3 English and 17 mul- tilingual setups. The English setups are: (a) PTB: training on sections 2-21 of the WSJ PTB and test- ing on its section 23; (b) GENIA: training with a random sample of 90% of the 4661 GENIA cor- pus ( <ref type="bibr" target="#b30">Ohta et al., 2002</ref>) sentences and testing on the other 10%; and (c) QBank: a setup identi- cal to (b) for the 3987 QuestionBank ( <ref type="bibr" target="#b15">Judge et al., 2006</ref>) sentences. Multilingual parsing was performed with the multilingual datasets of the CoNLL 2006 ( <ref type="bibr" target="#b1">Buchholz and Marsi, 2006</ref>) and <ref type="bibr" target="#b2">2007</ref><ref type="bibr" target="#b29">(Nilsson et al., 2007</ref>) shared tasks on multi- lingual dependency parsing, following their stan- dard train/test split. Following previous work, punctuation was excluded from the evaluation.</p><p>Length-dictionary pruning reduces the number of undirected edges by 27.02% on average across our 20 setups (std = 11.02%, median = 23.85%), leaving an average of 73.98% of the edges in the undirected graph. In 17 of 20 setups the reduction is above 20%. Note that the number of edges in a complete directed graph is twice the number in its undirected counterpart. Therefore, on average, the number of input edges in the pruned undirected models amounts to 73.98% 2 = 36.49% of the num- ber of edges in the complete directed graphs. In fact, every edge-related operation (such as feature extraction) in the undirected model is actually per- formed on half of the number of edges compared to the directed model, saving run-time not only in the MST-inference stage but in every stage involv- ing these operations. In addition, some pruning methods, such as length-dictionary pruning (used  in this work) perform feature extraction only for existing (un-pruned) edges, meaning that any re- duction in the number of edges also reduces fea- ture extraction operations. For each model we report the standard directed unlabeled attachment accuracy score (D-UAS). In addition, since this paper explores the value of undirected inference for a problem that is directed in nature, we also report the undirected unlabeled attachment accuracy score (U-UAS), hoping that these results will shed light on the differences be- tween the trees generated by the different models. <ref type="table" target="#tab_0">Table 1</ref> presents our main results. While the directed MST parser (D-MST) is the best per- forming model across almost all test sets and eval- uation measures, it outperforms our best model, U-MST-uf-lep, by a very small margin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Particularly, for D-UAS, D-MST outperforms U-MST-uf-lep by up to 1% in 14 out of 20 setups (in 6 setups the difference is up to 0.5%). In 5 other setups the difference between the models is between 1% and 2%, and only in one setup it is above 2% (2.6%). Similarly, for U-UAS, in 2 se- tups the models achieve the same performance, in 15 setups the difference is less than 1% and in the other setups the differences is 1.1% -1.5%. The average differences are 0.97% and 0.67% for D- UAS and U-UAS respectively.</p><p>The table further demonstrates the value of the local enhancement procedure. Indeed, U-MST- uf-lep outperforms U-MST in all 20 setups in D- UAS evaluation and in 15 out of 20 setups in U- UAS evaluation (in one setup there is a tie). How- ever, the improvement this procedure provides is much more noticeable for D-UAS, with an aver- aged improvement of 2.35% across setups, com- pared to an averaged U-UAS improvement of only 0.26% across setups. While half of the changes performed by the local enhancement procedure are in edge directions, its marginal U-UAS improve- ment indicates that almost all of its power comes from edge direction changes. This calls for an im- proved enhancement procedure.</p><p>Finally, moving to directed features (the U- MST-df model), both D-UAS and U-UAS substan- tially degrade, with more noticeable degradation in the former. We hypothesize that this stems from the idiosyncrasy between the directed parameter update and the undirected inference in this model. <ref type="table" target="#tab_1">Table 2</ref>  The results demonstrate the power of first-order graph-based dependency parsing with undirected inference. Although using a substantially different inference algorithm, our U-MST-uf-lep model per- forms very similarly to the standard MST parser which employs directed MST inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>We present a first-order graph-based dependency parsing model which runs in edge linear time at expectation and with very high probability. In ex- tensive multilingual experiments our model per- forms very similarly to a standard directed first- order parser. Moreover, our results demonstrate the complementary nature of the models, with our model outperforming its directed counterpart on an average of 22.2% of the test sentences.</p><p>Beyond its practical implications, our work pro- vides a novel intellectual contribution in demon- strating the power of undirected graph based meth- ods in solving an NLP problem that is directed in nature. We believe this contribution has the po- tential to affect future research on additional NLP problems.</p><p>The potential embodied in this work extends to a number of promising research directions:</p><p>• Our algorithm may be used for efficient MST computation in k-best trees methods which are instrumental in margin-based training al- gorithms. For example, <ref type="bibr" target="#b27">McDonald et al. (2005b)</ref> observed that k calls to the CLU algorithm might prove to be too inefficient; our more efficient algorithm may provide the remedy.</p><p>• It may also be utilized as an infer- ence/initialization subroutine as a part of more complex approximation frameworks such as belief propagation (e.g. <ref type="bibr" target="#b35">Smith and Eisner (2008)</ref>, <ref type="bibr" target="#b13">Gormley et al. (2015)</ref>).</p><p>• Finally, the complementary nature of the di- rected and undirected parsers motivates the development of methods for their combina- tion, such as dual decomposition (e.g. <ref type="bibr" target="#b34">Rush et al. (2010)</ref>, <ref type="bibr" target="#b19">Koo et al. (2010a)</ref>). Partic- ularly, we have shown that our undirected inference algorithm converges to a different solution than the standard directed solution while still maintaining high quality <ref type="table" target="#tab_1">(Table 2)</ref>. Such techniques can exploit this diversity to produce a higher quality unified solution.</p><p>We intend to investigate all of these directions in future work. In addition, we are currently ex- ploring potential extensions of the techniques pre- sented in this paper to higher order, projective and non-projective, dependency parsing.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An illustration of a Boruvka step: (a) The original graph; (b) Choosing the minimal edge for each vertex (marked in red); (c) The contracted graph; (d) The contracted graph after removing one self edge and two non-minimal repetitive edges.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>Figure 2: An illustration of directing an undirected tree, given a constrained root vertex: (a) The initial undirected tree; (b) Directing the root's outgoing edge; (c) Directing the root's child's outgoing edges; (d) Directing the last remaining edge, resulting in a directed tree.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>reveals the complementary nature of our U-MST-uf-lep model and the classical D-MST: each of the models outperforms the other on an av- erage of 22.2% of the sentences across test setups. An oracle model that selects the parse tree of the best model for each sentence would improve D- UAS by an average of 1.2% over D-MST across the test setups.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 : Directed/undirected UAS for the various parsing models of this paper.</head><label>1</label><figDesc></figDesc><table>Swedish 
Danish 
Bulgarian 
Slovene 
Chinese 
Hungarian 
Turkish 
German 
Czech 
Dutch 
D-MST 
20.6 
20.8 
15.1 
25.4 
15.5 
26.4 
22.3 
21.3 
29.7 
27.7 
U-MST-uf-lep 
18.0 
24.5 
22.1 
29.6 
16.7 
27.2 
19.3 
17.9 
26.2 
24.4 
Oracle 
88.9 
89.7 
91.6 
81.9 
87.8 
83.9 
77.1 
90.6 
82.8 
82.8 
(+1.2) 
(+1.4) 
(+1.2) 
(+1.5) 
(+1.7) 
(+1) 
(+1.9) 
(+1) 
(+1.1) 
(+1.5) 
Japanese 
Spanish 
Catalan 
Greek 
Basque 
Portuguese 
Italian 
PTB 
QBank 
GENIA 
D-MST 
5.7 
26.7 
23.4 
28.9 
23.4 
22.6 
22.5 
27.8 
5.3 
33.7 
U-MST-uf-lep 
4.0 
30.1 
26.3 
30.5 
30.8 
21.9 
24.9 
20.9 
6.0 
23.8 
Oracle 
93.1 
84.8 
92.6 
83.9 
74.1 
89.9 
84.4 
92.8 
96.4 
89.7 
(+0.6) 
(+1) 
(+0.8) 
(+1.2) 
(+2) 
(+0.7) 
(+1) 
(+0.7) 
(+0.8) 
(+0.8) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Top two lines (per language): percentage of sentences for which each of the models performs better than the other 
according to the directed UAS. Bottom line (Oracle): Directed UAS of an oracle model that selects the parse tree of the best 
performing model for each sentence. Improvement over the directed UAS score of D-MST is given in parenthesis. 

</table></figure>

			<note place="foot" n="1"> We refer to parsing approaches that produce only projective dependency trees as projective parsing and to approaches that produce all types of dependency trees as non-projective parsing. 2 Some pruning algorithms require initial construction of the full graph, which requires exactly n(n − 1) edge weight computations. Utilizing other techniques, such as lengthdictionary pruning, graph construction and pruning can be</note>

			<note place="foot" n="6"> Both these algorithms deal with a slightly more general case where the graph is not necessarily connected, in which case the minimum spanning forest (MSF) is computed. In our case, where the graph is connected, the MSF reduces to an MST.</note>

			<note place="foot" n="7"> This complexity analysis is beyond the scope of this paper.</note>

			<note place="foot" n="8"> Henceforth, we refer to an MST parser that employs a directed MST algorithm for inference as directed MST parser.</note>

			<note place="foot" n="9"> In evaluation setup experiments we also considered a variant of this model where the training process utilized directed MST inference. As this variant performed poorly, we exclude it from our discussion in the rest of the paper.</note>

			<note place="foot" n="10"> This hyperparameter was estimated once on our English development setup, and used for all 20 multilingual test setups. 11 The directed edge weights for the local enhancement procedure (s d in § 4) were computed using the trained DMST parser. 12 http://www.seas.upenn.edu/ ˜ strctlrn/ MSTParser/MSTParser.html</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The second author was partly supported by a GIF Young Scientists' Program grant <ref type="bibr">No. I-2388</ref><ref type="bibr">-407.6/2015</ref> </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">About a Certain Minimal Problem) (in Czech, German summary)</title>
	</analytic>
	<monogr>
		<title level="j">Práce Mor. Prírodoved. Spol. v Brne III</title>
		<editor>References Otakar Boruvka. 1926. O Jistém Problému Minimálním</editor>
		<imprint>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Conll-x shared task on multilingual dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabine</forename><surname>Buchholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erwin</forename><surname>Marsi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth Conference on Computational Natural Language Learning</title>
		<meeting>the Tenth Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="149" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Experiments with a higherorder projective dependency parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Carreras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CoNLL</title>
		<meeting>of CoNLL</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A minimum spanning tree algorithm with inverse-ackermann type complexity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernard</forename><surname>Chazelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1028" to="1047" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">On the shortest arborescence of a directed graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">J</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science Sinica</title>
		<imprint>
			<biblScope unit="page">14</biblScope>
			<date type="published" when="1965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Verification and sensitivity analysis of minimum spanning trees in linear time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brandon</forename><surname>Dixon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Monika</forename><surname>Rauch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">E</forename><surname>Tarjan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Comput</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1184" to="1192" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Optimum branchings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Edmonds</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Research of the National Bureau of Standards</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="233" to="240" />
			<date type="published" when="1967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Parsing with soft and hard constraints on dependency length</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Eisner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IWPT</title>
		<meeting>IWPT</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Three new probabilistic models for dependency parsing: An exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of COLING</title>
		<meeting>of COLING</meeting>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Bilexical grammars and their cubic-time parsing algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Probabilistic and Other Parsing Technologies</title>
		<editor>Harry Bunt and Anton Nijholt</editor>
		<imprint>
			<publisher>Kluwer Academic Publishers</publisher>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Efficient algorithms for finding minimum spanning trees in undirected and directed graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zvi</forename><surname>Harold N Gabow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Galil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">E</forename><surname>Spencer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tarjan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Combinatorica</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="109" to="122" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Dependency parsing with undirected graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Gómez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Rodríguez</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Fernándezgonzález</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 13th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="66" to="76" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Undirected dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Gómez-Rodríguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Fernándezgonzález</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Víctor Manuel Darriba</forename><surname>Bilbao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Intelligence</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="348" to="384" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Approximation-aware dependency parsing by belief propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Gormley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="489" to="501" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Ackermann function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michiel</forename><surname>Hazewinkel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Encyclopedia of Mathematics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Questionbank: Creating a corpus of parseannotated questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Judge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aoife</forename><surname>Cahill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Van Genabith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACLCOLING</title>
		<meeting>ACLCOLING</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="497" to="504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A randomized linear-time algorithm to find minimum spanning trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Karger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Tarjan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="321" to="328" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A simpler minimum spanning tree verification algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valerie</forename><surname>King</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Algorithmica</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="263" to="270" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Efficient thirdorder dependency parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Dual decomposition for parsing with non-projective head automata</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sontag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Building a large annotated corpus of english: The penn treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><forename type="middle">Ann</forename><surname>Marcinkiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatrice</forename><surname>Santorini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="313" to="330" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Concise integer linear programming formulations for dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">F T</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Dual decomposition with many overlapping components</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">F T</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M Q</forename><surname>Aguiar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A T</forename><surname>Figueiredo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Turning on the turbo: Fast third-order nonprojective turbo parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">F T</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Online learning of approximate dependency parsing algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EACL</title>
		<meeting>of EACL</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">On the complexity of non-projective data-driven dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgio</forename><surname>Satta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IWPT</title>
		<meeting>of IWPT</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Online large-margin training of dependency parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgio</forename><surname>Satta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Non-projective dependency parsing using spanning tree algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiril</forename><surname>Ribarov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of HLTEMNLP</title>
		<meeting>of HLTEMNLP</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Otakar boruvka on minimum spanning tree problem translation of both the 1926 papers, comments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaroslav</forename><surname>Nesetril</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eva</forename><surname>Milková</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helena</forename><surname>Nesetrilová</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">history. Discrete Mathematics</title>
		<imprint>
			<biblScope unit="volume">233</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="3" to="36" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The conll 2007 shared task on dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Nilsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deniz</forename><surname>Yuret</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL shared task session of EMNLP-CoNLL</title>
		<meeting>the CoNLL shared task session of EMNLP-CoNLL</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="915" to="932" />
		</imprint>
	</monogr>
	<note>sn</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The genia corpus: An annotated research abstract corpus in molecular biology domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoko</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuka</forename><surname>Tateisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin-Dong</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the second international conference on Human Language Technology Research</title>
		<meeting>the second international conference on Human Language Technology Research</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="82" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">An optimal minimum spanning tree algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seth</forename><surname>Pettie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijaya</forename><surname>Ramachandran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="16" to="34" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Parse, price and cut-delayed column and row generation for graph based parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP-CoNLL</title>
		<meeting>of EMNLP-CoNLL</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Vine pruning for efficient multi-pass dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL</title>
		<meeting>of NAACL</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">On dual decomposition and linear programming relaxations for natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Sontag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommi</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;10</title>
		<meeting>the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;10<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Dependency parsing by belief propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Finding optimum branchings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Robert Endre Tarjan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1977" />
			<publisher>Networks</publisher>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="25" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Data Structures and Network Algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Robert Endre Tarjan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Society for Industrial and Applied Mathematics</title>
		<imprint>
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Generalized higher-order dependency parsing with cube pruning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP-CoNLL</title>
		<meeting>of EMNLP-CoNLL</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
