<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:43+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Obligation and Prohibition Extraction Using Hierarchical RNNs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 15-20, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilias</forename><surname>Chalkidis</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Informatics</orgName>
								<orgName type="institution">Athens University of Economics and Business</orgName>
								<address>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Cognitiv+ Ltd</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ion</forename><surname>Androutsopoulos</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Informatics</orgName>
								<orgName type="institution">Athens University of Economics and Business</orgName>
								<address>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Achilleas</forename><surname>Michos</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Cognitiv+ Ltd</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Obligation and Prohibition Extraction Using Hierarchical RNNs</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="254" to="259"/>
							<date type="published">July 15-20, 2018</date>
						</imprint>
					</monogr>
					<note>254</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We consider the task of detecting contractual obligations and prohibitions. We show that a self-attention mechanism improves the performance of a BILSTM clas-sifier, the previous state of the art for this task, by allowing it to focus on indicative tokens. We also introduce a hierarchical BILSTM, which converts each sentence to an embedding, and processes the sentence embeddings to classify each sentence. Apart from being faster to train, the hierarchical BILSTM outperforms the flat one, even when the latter considers surrounding sentences, because the hierarchical model has a broader discourse view.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Legal text processing <ref type="bibr" target="#b1">(Ashley, 2017</ref>) is a growing research area, comprising tasks such as legal ques- tion answering <ref type="bibr" target="#b10">(Kim and Goebel, 2017)</ref>, contract element extraction ( , and le- gal text generation <ref type="bibr" target="#b0">(Alschnerd and Skougarevskiy, 2017)</ref>. We consider obligation and prohibition ex- traction from contracts, i.e., detecting sentences (or clauses) that specify what should or should not happen <ref type="table" target="#tab_0">(Table 1</ref>). This task is important for le- gal firms and legal departments, especially when they process large numbers of contracts to mon- itor the compliance of each party. Methods that would automatically identify (e.g., highlight) sen- tences (or clauses) specifying obligations and pro- hibitions would allow lawyers and paralegals to in- spect contracts more quickly. They would also be a step towards populating databases with informa- tion extracted from contracts, along with methods that extract contractors, particular dates (e.g., start and end dates), applicable law, legislation refer- ences etc. ( ). Obligation and prohibition extraction is a kind of deontic sentence (or clause) classification (O' <ref type="bibr">Neill et al., 2017</ref>). Different firms may use different or finer deontic classes (e.g., distinguish- ing between payment and delivery obligations), but obligations and prohibitions are the most com- mon coarse deontic classes. Using similar classes, O' <ref type="bibr">Neill et al. (2017)</ref> reported that a bidirectional LSTM (BILSTM) classifier ( <ref type="bibr" target="#b7">Graves et al., 2013)</ref> outperformed several others (including logistic re- gression, SVM, AdaBoost, Random Forests) in le- gal sentence classification, possibly because long- term dependencies (e.g., modal verbs or negations interacting with distant dependents) are common and crucial in legal texts, and LSTMs can cope with long-term dependencies better than methods rely- ing on fixed-size context windows.</p><p>We improve upon the work of O' <ref type="bibr">Neill et al. (2017)</ref> in four ways. First, we show that self- attention ( <ref type="bibr" target="#b22">Yang et al., 2016</ref>) improves the perfor- mance of the BILSTM classifier, by allowing the system to focus on indicative words <ref type="figure" target="#fig_0">(Fig 1)</ref>. Sec- ond, we introduce a hierarchical BILSTM, where a first BILSTM processes each sentence word by <ref type="table" target="#tab_0">1  Obligation  The Supplier is obliged to meet and comply with the Approved Requirements.  None  Details shall be determined in the individual contracts.  2</ref> Prohibition No Provider staff will provide services to any Customer Competitor. Obligation</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>No. Gold Class Sentences/Clauses</head><p>Provider will take such measures to prevent these actions. 3</p><p>Prohibition Provider is not entitled to suspend this Agreement prior to the lapse of the fifth year. 4</p><p>Oblig./Prohib. List Intro The Supplier shall: Obligation List Item (a) only process the Personal Data in accordance with Client's written instructions; Prohibition List Item (b) not transfer any Personal Data to any other third parties; 5</p><p>Oblig./Prohib. List Intro The Receiving Party will: Obligation List Item (i) keep the Confidential Information secret and confidential; Prohibition List Item (ii) not disclose the Confidential Information to any person other than in accordance with Clauses 13.3; and Prohibition List Item (iii) not use the Confidential Information other than for the purposes of this Agreement. 6</p><p>Oblig./Prohib. List Intro A Party shall not directly solicit the employment of: Prohibition List Item (i) in the case of Client, Supplier's employees engaged in the provision of the Services, Prohibition List Item (ii) in the case of Supplier, Client's employees engaged. None Nothing in this section will restrict either Party's right to recruit.   <ref type="table" target="#tab_0">(Tables 1-2)</ref>, which fit better the tar- get task, where nested clauses are frequent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data</head><p>We experimented with a dataset containing 6,385 training, 1,595 development, and 1,420 test sec- tions (articles) from the main bodies (excluding in- troductions, covers, recitals) of 100 randomly se- lected English service agreements. <ref type="bibr">1</ref> The sections were preprocessed by a sentence splitter, which in clause lists (Examples 4-6 in <ref type="table" target="#tab_0">Table 1</ref>) treats the introductory clause and each nested clause as sep- arate sentences, since each nested clause may be- long in a different class. <ref type="bibr">2</ref> The splitter produced 31,545 training, 8,036 de- velopment, and 5,563 test sentences/clauses. 3 Ta- ble 2 shows their distribution in the six gold (cor- rect) classes. Each section was annotated by a sin- gle law student (5 students in total). All the an- notations were checked and corrected by a single paralegal expert, who produces annotations of this kind on a daily basis, based on strict guidelines of the firm that provided the data.</p><p>We used pre-trained 200-dimensional word em- beddings and pre-trained 25-dimensional POS tag embeddings, obtained by applying WORD2VEC <ref type="bibr" target="#b15">(Mikolov et al., 2013</ref>) to approx. 750k and 50k English contracts, respectively, as in our previous work ). We also pre-trained 5-dimensional token shape embeddings (e.g., all capitals, first letter capital, all digits), obtained as in our previous work . Each token is represented by the concatenation of its word, POS, shape embeddings <ref type="figure" target="#fig_1">(Fig. 2, bottom)</ref>. Unknown tokens are mapped to and then assigning entire clusters to the training, develop- ment, or test subset, to avoid having similar sections (e.g., based on boilerplate clauses) in different subsets. <ref type="bibr">2</ref> We use NLTK's splitter (http://www.nltk.org/), with additional post-processing based on regular expressions.pre-trained POS-specific 'unk' embeddings (e.g., 'unk-n', 'unk-vb'). The dataset of <ref type="table" target="#tab_1">Table 2</ref> has no overlap with the corpus of contracts that was used to pre-train the embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BILSTM:</head><p>The first classifier we considered pro- cesses a single sentence (or clause) at a time. It feeds the concatenated word, POS, shape embeddings (e 1 , . . . , e n ∈ R 230 ) of the tokens w 1 , w 2 , . . . , w n of the sentence to a forward LSTM, and (in reverse order) to a backward LSTM, ob- taining the forward and backward hidden states (</p><formula xml:id="formula_0">− → h 1 , . . . , − → h n ∈ R 300 and ← − h 1 , . . . ← − h n ∈ R 300 ). The concatenation of the last states (h = [ − → h n ; ← − h 1 ])</formula><p>is fed to a multinomial Logistic Regression (LR) layer, which produces a probability per class.  <ref type="figure" target="#fig_2">Fig. 3</ref>). In X-BILSTM-ATT, the two LSTM chains also consider the words of surrounding sen- tences. The red dashed line is a drop-out layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BILSTM-ATT:</head><p>When self-attention is added <ref type="figure" target="#fig_1">(Fig. 2)</ref>, the sentence (or clause) is represented by the weighted sum (h) of the hidden states</p><formula xml:id="formula_1">(h t = [ − → h t ; ← − h t ] ∈ R 600</formula><p>) of the BILSTM, where a 1 , . . . , a n ∈ R are attention scores, v ∈ R 600 , b ∈ R:</p><formula xml:id="formula_2">h = a 1 h 1 + · · · + a t h t + · · · + a n h n (1) a ′ t = tanh(v T h t + b)<label>(2)</label></formula><formula xml:id="formula_3">a t = softmax(a ′ t ; a ′ 1 , . . . , a ′ n )<label>(3)</label></formula><p>Again, h is then fed to a multinomial LR layer. <ref type="figure" target="#fig_0">Figure 1</ref> visualizes the attention scores (a 1 , . . . , a n ) of BILSTM-ATT when reading some of the sen- tences (or clauses) of <ref type="table" target="#tab_0">Table 1</ref>. The attention scores are higher for modals, negations, words that in- dicate obligations or prohibitions (e.g., 'obliged', 'only'), and tokens indicating nested clauses (e.g., '(a)', ':', ';'), which allows BILSTM-ATT to focus more on these tokens (the corresponding states) when computing the sentence representation (h).</p><p>X-BILSTM-ATT: In an extension of BILSTM-ATT, called X-BILSTM-ATT, the BILSTM chain is fed with the token embeddings (e t ) not only of the sen- tence being classified, but also of the previous (and following) tokens (faded parts of <ref type="figure" target="#fig_1">Fig. 2</ref>), up to 150 previous (and 150 following) tokens, 150 be- ing the maximum sentence length in the dataset. <ref type="bibr">4</ref> This might allow the BILSTM chain to 'remember' key parts of the surrounding sentences (e.g., a pre- vious clause ending with 'shall not:') when pro- ducing the context-aware embeddings (states h t ) of the current sentence. The self-attention mecha- nism still considers the states (h t ) of the tokens of the current sentence only, and the sentence repre- sentation (h) is still computed as in Eq. 1.</p><p>H-BILSTM-ATT: The hierarchical BILSTM clas- sifier, H-BILSTM-ATT, considers all the sentences (or clauses) of an entire section. Each sentence (or clause) is first turned into a sentence embed- ding (h ∈ R 600 ), as in BILSTM-ATT <ref type="figure" target="#fig_1">(Fig. 2)</ref>. The sequence of sentence embeddings is then fed to a second BILSTM <ref type="figure" target="#fig_2">(Fig. 3)</ref>, whose hidden states (h</p><formula xml:id="formula_4">t = [ − → h<label>(2)</label></formula><p>t ;</p><formula xml:id="formula_6">← − h<label>(2)</label></formula><p>t ] ∈ R 600 ) are treated as context- aware sentence embeddings. The latter are passed on to a multinomial LR layer, producing a prob- ability per class, for each sentence (or clause) of the section. We hypothesized that H-BILSTM-ATT would perform better, because it considers an en- tire section at a time, and salient information about a sentence or clause (e.g., that the opening clause of a list contains a negation or modal) can be 'con- densed' in its sentence embedding and interact with the sentence embeddings of distant sentences or clauses (e.g., a nested clause several clauses af- ter the opening one) in the upper BILSTM <ref type="figure" target="#fig_2">(Fig. 3)</ref>. <ref type="table" target="#tab_0">P  R  F1  AUC  P  R  F1  AUC  P  R  F1  AUC  P  R  F1</ref>    </p><formula xml:id="formula_7">BILSTM BILSTM-ATT X-BILSTM-ATT H-BILSTM-ATT</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gold Class</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Results</head><p>Hyper-parameters were tuned by grid-searching the following sets, and selecting the values with the best validation loss: LSTM hidden units {100, 200, 300}, batch size {8, 16, 32}, drop-out rate {0.4, 0.5, 0.6}. The red dashed lines of <ref type="figure" target="#fig_1">Fig. 2-3</ref> are drop-out layers. <ref type="bibr">5</ref> We used categorical cross- entropy loss, Glorot initialization (Glorot and Ben- gio, 2010), Adam (Kingma and Ba, 2015), learn- ing rate 0.001, and early stopping on the valida- tion loss. <ref type="table" target="#tab_3">Table 3</ref> reports the precision, recall, F1 score, area under the precision-recall curve (AUC) per class, as well as micro-and macro-averages. The self-attention mechanism (BILSTM-ATT) leads to clear overall improvements (in macro and micro F1 and AUC, <ref type="table" target="#tab_3">Table 3</ref>) comparing to the plain BILSTM, supporting the hypothesis that self- attention allows the classifier to focus on indica- tive tokens. Allowing the BILSTM to consider to- kens of neighboring sentences (X-BILSTM-ATT) does not lead to any clear overall improvements. <ref type="bibr">5</ref> We resample the drop-out mask at each time-step.</p><p>The hierarchical H-BILSTM-ATT clearly outper- forms the other three methods, supporting the hy- pothesis that considering entire sections and al- lowing the sentence embeddings to interact in the upper BILSTM <ref type="figure" target="#fig_2">(Fig. 3)</ref> is beneficial.</p><p>Notice that the three flat methods (BILSTM, BILSTM-ATT, X-BILSTM-ATT) obtain particularly lower F1 and AUC scores, compared to H-BILSTM- ATT, in the classes that correspond to nested clauses (obligation list item, prohibition list item). This is due to the fact that the flat methods have no (or only limited, in the case of X-BILSTM-ATT) view of the previous sentences, which often indi- cate if a nested clause is an obligation or prohibi- tion (see, for example, examples 4-6 in <ref type="table" target="#tab_0">Table 1</ref>).</p><p>H-BILSTM-ATT is also much faster to train than BILSTM and BILSTM-ATT <ref type="table">(Table 4)</ref>, even though it has more parameters, because it converges faster (5-7 epochs vs. 12-15). X-BILSTM-ATT is particu- larly slow, because its BILSTM processes the same sentences multiple times, when they are classified and when they are neighboring sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Network</head><p>Training Time Parameters <ref type="table">Table 4</ref>: Training times and parameters to learn.</p><formula xml:id="formula_8">BILSTM 5h 30m 1,278M BILSTM-ATT 8h 30m 1,279M X-BILSTM-ATT 25h 40m 1,279M H-BILSTM-ATT 2h 30m 1,837M</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>As already noted, we built upon the work of O' <ref type="bibr">Neill et al. (2017)</ref>. The dataset of O'Neill et al. contained financial legislation, not contracts, and was an order of magnitude smaller (obligations, prohibitions, permissions had 1,297 training, 622 test sentences in total, cf. <ref type="table" target="#tab_1">Table 2</ref>), but also in- cluded permissions, which we did not consider. <ref type="bibr" target="#b20">Waltl et al. (2017)</ref> classified statements from German tenancy law into 22 classes (including prohibition, permission, consequence), using ac- tive learning with Naive Bayes, LR, MLP classi- fiers, experimenting with 504 sentences. <ref type="bibr" target="#b12">Kiyavitskaya et al. (2008)</ref> used grammars, word lists, and heuristics to extract rights, obligations, exceptions, and other constraints from US and Ital- ian regulations. <ref type="bibr" target="#b2">Asooja et al. (2015)</ref> employed SVMs with n- gram and manually crafted features to classify paragraphs of money laundering regulations into five classes (e.g., enforcement, monitoring, report- ing), experimenting with 212 paragraphs.</p><p>In previous work  we focused on extracting contract elements (e.g., contractor names, legislation references, start and end dates, amounts), a task which is similar to named en- tity recognition. The best results were obtained by stacked <ref type="bibr">BILSTMs (Irsoy and Cardie, 2014)</ref> or stacked BILSTM-CRF models <ref type="bibr" target="#b14">(Ma and Hovy, 2016)</ref>; hierarchical BILSTMs were not considered. By contrast, in this paper we considered obliga- tion and prohibition extraction, treating it as a sen- tence (or clause) classification task, and showing the benefits of employing a hierarchical BILSTM model that considers both the sequence of words in each sentence and the sequence of sentences. <ref type="bibr" target="#b22">Yang et al. (2016)</ref> proposed a hierarchical RNN with self-attention to classify texts. A first bidi- rectional RNN turns the words of each sentence to a sentence embedding, and a second one turns the sentence embeddings to a document embedding, which is fed to an LR layer. Yang et al. use self- attention in both RNNs, to assign attention scores to words and sentences. We classify sentences (or clauses), not entire texts, hence our second BIL- STM does not produce a document embedding and does not use self-attention. Also, Yang et al. ex- perimented with reviews and community question answering logs, whereas we considered legal texts.</p><p>Hierarchical RNNs have also been developed for multilingual text classification (Pappas and Popescu-Belis, 2017), language modeling ( <ref type="bibr" target="#b13">Lin et al., 2015)</ref>, and dialogue breakdown detection <ref type="bibr" target="#b21">(Xie and Ling, 2017</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions and Future Work</head><p>We presented the legal text analytics task of de- tecting contractual obligations and prohibitions. We showed that self-attention improves the perfor- mance of a BILSTM classifier, the previous state of the art in this task, by allowing the BILSTM to focus on indicative tokens. We also intro- duced a hierarchical BILSTM (also using atten- tion), which converts each sentence to an em- bedding, and then processes the sentence embed- dings to classify each sentence. Apart from be- ing faster to train, the hierarchical BILSTM outper- forms the flat one, even when the latter considers the surrounding sentences, because the hierarchi- cal model has a broader view of the discourse. Further performance improvements may be possible by considering deeper self-attention mechanisms ( <ref type="bibr" target="#b18">Pavlopoulos et al., 2017)</ref>, stacking <ref type="bibr">BILSTMs (Irsoy and Cardie, 2014)</ref>, or pre-training the BILSTMs with auxiliary tasks <ref type="bibr" target="#b19">(Ramachandran et al., 2017)</ref>. The hierarchical BILSTM with atten- tion of this paper may also be useful in other sen- tence, clause, or utterance classification tasks, for example in dialogue turn classification <ref type="bibr" target="#b21">(Xie and Ling, 2017</ref>), detecting abusive user comments in on-line discussions ( <ref type="bibr" target="#b18">Pavlopoulos et al., 2017)</ref>, and discourse segmentation <ref type="bibr" target="#b8">(Hearst, 1997)</ref>. We would also like to investigate replacing its BILSTMs with sequence-labeling <ref type="bibr">CNNs (Bai et al., 2018)</ref>, which may lead to efficiency improvements.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Heatmap visualizing the attention scores of BILSTM-ATT for some examples of Table 1.</figDesc><graphic url="image-1.png" coords="1,312.73,225.92,207.35,163.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: BILSTM with self-attention (ATT nodes) used on its own (BILSTM-ATT) or as the sentence encoder of the hierarchical BILSTM (H-BILSTMATT, Fig. 3). In X-BILSTM-ATT, the two LSTM chains also consider the words of surrounding sentences. The red dashed line is a drop-out layer.</figDesc><graphic url="image-2.png" coords="3,77.46,311.10,207.35,222.09" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Upper part of the hierarchical BILSTM (H-BILSTM-ATT). The sentence embeddings (SE i ) are generated by the encoder of Fig. 2.</figDesc><graphic url="image-3.png" coords="4,77.46,191.33,207.36,184.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Examples of sentences and clauses, with human annotations of classes. Terms that are highly 
indicative of the classes are shown in bold and underlined here, but are not marked by the annotators. 

Gold Class 
Train 
Dev 
Test 
None 
15,401 3,905 4,141 
Obligation 
11,005 2,860 
970 
Prohibition 
1,172 
314 
108 
Obligation List Intro 
828 
203 
70 
Obligation List Item 
2888 
726 
255 
Prohibition List Item 
251 
28 
19 
Total 
31,545 8,036 5,563 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Sentences/clauses after sentence splitting. 

word producing a sentence embedding, and a sec-
ond BILSTM processes the sentence embeddings 
to classify each sentence. The hierarchical BIL-
STM is similar to Yang et al.'s (2016), but classi-
fies sentences, not entire texts (e.g., news articles 
or product reviews). It outperforms a flat BILSTM 
that classifies each sentence independently, even 
when the latter considers neighbouring sentences, 
because the hierarchical BILSTM has a broader 
view of the discourse. Third, we experiment with 
a dataset an order of magnitude larger than the 
dataset of O' Neill et al. Fourth, we introduce 
finer classes </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Precision, recall, F1, and AUC scores, with the best results in bold and gray background. 

</table></figure>

			<note place="foot" n="1"> The splitting of the dataset into training, development, and test subsets was performed by first agglomeratively clustering all sections (articles) based on Levenshtein distance,</note>

			<note place="foot" n="3"> There are at most 15 sentences/clauses per section in the training set. We hope to make the dataset, or a similar anonymized one, publicly available in the near future, but the dataset is currently not available due to confidentiality issues.</note>

			<note place="foot" n="4"> Memory constraints did not allow including more tokens. We used a single NVIDIA 1080 GPU. All methods were implemented using KERAS (https://keras.io/) with a TENSORFLOW backend (https://www.tensorflow. org/). We padded each sentence to the maximum length.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We are grateful to the members of AUEB's Natural Language Processing Group, for several sugges-tions that helped significantly improve this paper.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Towards an automated production of legal texts using recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Alschnerd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Skougarevskiy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of the 16th International Conference on Artificial Intelligence and Law</title>
		<meeting>eeding of the 16th International Conference on Artificial Intelligence and Law<address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="159" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">D</forename><surname>Ashley</surname></persName>
		</author>
		<title level="m">Artificial Intelligence and Legal Analytics: New Tools for Law Practice in the Digital Age</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Semantic annotation of finance regulatory text using multilabel classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Asooja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bordea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Vulcu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>O&amp;apos;brien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Espinoza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Abi-Lahoud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Buitelaar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Butler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Workshop on Legal Domain and Semantic Web Applications</title>
		<meeting>the International Workshop on Legal Domain and Semantic Web Applications<address><addrLine>Portoroz, Slovenia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">An empirical evaluation of generic convolutional and recurrent networks for sequence modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Z</forename><surname>Kolter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
		<idno>abs/1803.01271</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A deep learning approach to contract element extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Chalkidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Androutsopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Conference on Legal Knowledge and Information Systems</title>
		<meeting>the 30th International Conference on Legal Knowledge and Information Systems<address><addrLine>Luxembourg</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="155" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Extracting contract elements</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Chalkidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Androutsopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Michos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th International Conference on Artificial Intelligence and Law</title>
		<meeting>the 16th International Conference on Artificial Intelligence and Law<address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="19" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Artificial Intelligence and Statistics</title>
		<meeting>the International Conference on Artificial Intelligence and Statistics<address><addrLine>Sardinia, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="249" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Hybrid speech recognition with deep bidirectional LSTM</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Workshop on Automatic Speech Recognition and Understanding</title>
		<meeting><address><addrLine>Olomouc, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="273" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Texttiling: Segmenting text into multi-paragraph subtopic passages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marti</forename><forename type="middle">A</forename><surname>Hearst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="33" to="64" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep recursive neural networks for compositionality in language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Irsoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Neural Information Processing Systems</title>
		<meeting>the 27th International Conference on Neural Information Processing Systems<address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2096" to="2104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Two-step cascaded textual entailment for legal bar exam question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Goebel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Competition on Legal Information Extraction/Entailment</title>
		<meeting>the 4th Competition on Legal Information Extraction/Entailment<address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Conference on Learning Representations</title>
		<meeting>the 5th International Conference on Learning Representations<address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Automating the extraction of rights and obligations for regulatory compliance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kiyavitskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zeni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Travis</forename><forename type="middle">D</forename><surname>Breaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Annie</forename><forename type="middle">I</forename><surname>Antón</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">R</forename><surname>Cordy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mylopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Conceptual Modeling</title>
		<meeting>the 27th International Conference on Conceptual Modeling<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="154" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Hierarchical recurrent neural network for document modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="899" to="907" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">End-to-end sequence labeling via bi-directional LSTM-CNNs-CRF</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the ACL</title>
		<meeting>the 54th Annual Meeting of the ACL<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1064" to="1074" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Distributed Representations of Words and Phrases and their Compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on Neural Information Processing Systems</title>
		<meeting>the 26th International Conference on Neural Information Processing Systems<address><addrLine>Stateline, NV</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Classifying Sentential Modality in Legal Language: A Use Case in Financial Regulations, Acts and Directives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>O&amp;apos;neill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Buitelaar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Robin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>O&amp;apos; Brien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th International Conference on Artificial Intelligence and Law</title>
		<meeting>the 16th International Conference on Artificial Intelligence and Law<address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="159" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multilingual hierarchical attention networks for document classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Pappas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Popescu-Belis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Joint Conference on Natural Language Processing</title>
		<meeting>the 8th International Joint Conference on Natural Language Processing<address><addrLine>Tapei, Taiwan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deeper attention to abusive user content moderation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pavlopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Malakasiotis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Androutsopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1125" to="1135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Unsupervised pretraining for sequence to sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ramachandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="383" to="391" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Classifying legal norms with active machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Waltl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Muhr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Glaser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bonczek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Scepankova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Matthes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Conference on Legal Knowledge and Information Systems</title>
		<meeting>the 30th International Conference on Legal Knowledge and Information Systems<address><addrLine>Luxembourg City Luxembourg</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="11" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Dialogue breakdown detection using hierarchical bi-directional LSTMs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th Dialog System Technology Challenges (Track 3: Dialog Breakdown Detection)</title>
		<meeting>the 6th Dialog System Technology Challenges (Track 3: Dialog Breakdown Detection)<address><addrLine>Long Beach, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Hierarchical attention networks for document classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 15th Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1480" to="1489" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
