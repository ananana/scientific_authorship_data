<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:02+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Zara Returns: Improved Personality Induction and Adaptation by an Empathetic Virtual Agent</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Farhad</forename><forename type="middle">Bin</forename><surname>Siddique</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Onno</forename><surname>Kampman</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Yang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anik</forename><surname>Dey</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascale</forename><surname>Fung</surname></persName>
						</author>
						<title level="a" type="main">Zara Returns: Improved Personality Induction and Adaptation by an Empathetic Virtual Agent</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of ACL 2017, System Demonstrations</title>
						<meeting>ACL 2017, System Demonstrations <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="121" to="126"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-4021</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Virtual agents need to adapt their personality to the user in order to become more em-pathetic. To this end, we developed Zara the Supergirl, an interactive empathetic agent, using a modular approach. In this paper, we describe the enhanced personality module with improved recognition from speech and text using deep learning frameworks. From raw audio, an average F-score of 69.6 was obtained from real-time personality assessment using a Con-volutional Neural Network (CNN) model. From text, we improved personality recognition results with a CNN model on top of pre-trained word embeddings and obtained an average F-score of 71.0. Results from our Human-Agent Interaction study confirmed our assumption that people have different agent personality preferences. We use insights from this study to adapt our agent to user personality.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>According to Miner et. al's research ( <ref type="bibr">Miner et al., 2016)</ref>, various world renowned virtual assistants respond inconsistently and impersonally to affect- sensitive topics such as mental health, domestic vi- olence, and emergencies. This situation calls for a need in empathy and adaptive personality in the virtual agents (VA). In human-human interactions (HHI), personality compatibility is important for relationship satisfaction and interpersonal close- ness <ref type="bibr">(Long and Martin, 2000;</ref><ref type="bibr">Berry et al., 2000</ref>). With the rising number of interactive products in the market these days, it is important to emphasize machine adaptability to different users of varying needs. Here we propose an adaptive personality module that can be embedded in interactive dia- <ref type="figure">Figure 1</ref>: System UI design log systems. In our new version of Zara, we start with recognizing user personality through speech and text based on the Big Five traits of person- ality ( <ref type="bibr">Gosling et al., 2003;</ref><ref type="bibr">Barrick and Mount, 1991)</ref>. Our module includes two separate Convo- lutional Neural Network (CNN) models, one with real-time raw audio analysis and the other trained on text with pre-trained word embeddings. To jus- tify our concept of adaptive personality, we did a user study after developing three virtual agents (two with distinct personalities and a robotic ver- sion as a control).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Description</head><p>We are building our current work on top of our previous interactive system of Zara the Supergirl ( <ref type="bibr">Fung et al., 2015)</ref>, with an updated user inter- face (see <ref type="figure">Figure 1</ref>). Zara assesses user personality based on the answers users provide at each turn. The entire conversation lasts around five minutes. The dialog is system-initiated when the user's face is detected. Zara asks a series of personal ques- tions with increasing intimacy, including topics like childhood memory, travel, work-life, and affil- iation towards human-agent interactions. At every <ref type="figure">Figure 2</ref>: System architecture utterance, the system gives an empathetic response based on the user's sentiment and emotion scores ( <ref type="bibr">Bertero et al., 2016;</ref><ref type="bibr">Fung et al., 2016)</ref>. A sepa- rate module handles user-initiated queries, which chats with the user until the user desires to go back and finish the test. Abusive language -such as swearing, explicit sexist, or racist remarks -are also handled by a separate module. A simplified system architecture diagram is given in <ref type="figure">Figure 2</ref>. Zara is a web application, run on a server, and can be rendered on a browser.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Big Five Personality Induction</head><p>Personality is the complex pattern of individ- ual differences, behavior, and thinking style. It is predominantly described with the Big Five model of personality <ref type="bibr">(Goldberg, 1993)</ref>, which defines five personality traits and rates a per- son along them. The traits are (abbreviations used in this paper are bolded): Extraversion vs. introversion, Agreeableness vs. detachment, Conscientiousness vs. carelessness, Neuroticism vs. emotional stability, and Openness to Expe- rience vs. cautiousness. Big Five personalities can be determined by self-reported assessments, such as the NEO-PI-R ( <ref type="bibr">Costa and McCrae, 2008</ref>). An automatic system of personality recognition is useful for situations where this is not practical.</p><p>Early work on automatic personality recogni- tion was mostly concerned with text and audio- visual features. Argamon et al. focused on text- based personality recognition ( <ref type="bibr">Argamon et al., 2005)</ref>, and used four sets of lexical features to determine a document's author's Extraversion and Neuroticism levels. In 2007, Mairesse et al. ex- tracted lexical features from text, and prosodic fea- tures from speech clips ( <ref type="bibr">Mairesse et al., 2007)</ref>. These were then mapped to the Big Five traits using different algorithms. Researchers using prosodic features commonly extract them using a pre-existing toolkit such as openSMILE <ref type="bibr">(Eyben et al., 2010)</ref>, after which they use classifiers such as SVMs to classify personality traits. More re- cently, in the ChaLearn Looking at People work- shop of 2016, Gucluturk et al. experimented with a CNN approach on video snapshots and raw au- dio to train their model <ref type="bibr">(Güçlütürk et al., 2016</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Personality perception from raw audio</head><p>We propose a method for automatically detecting someone's personality without the need for com- plex feature extraction upfront, as in <ref type="bibr" target="#b0">(Mohammadi and Vinciarelli, 2012)</ref>. This speeds up the compu- tation, which is essential for dialog systems. Raw audio is inserted straight into a CNN. These ar- chitectures have been applied very successfully in speech recognition tasks recently ( <ref type="bibr" target="#b2">Palaz et al., 2015)</ref>.</p><p>Our CNN architecture is shown in <ref type="figure" target="#fig_0">Figure 3</ref>. The audio input has sampling rate 8 kHz. The first con- volutional layer is applied directly on a raw audio sample x:</p><formula xml:id="formula_0">x C i = ReLU(W C x [i,i+v] + b C ) (1)</formula><p>where v is the convolution window size. We ap- ply a window size of 25ms and move the convo- lution window with a step of 2.5ms. The layer The dataset used a pre-defined split of a Train- ing set of 6,000 videos, a Validation set of 2,000 videos, and a Test set of 2,000 videos. In our ex- periment we use the Training set for training (us- ing cross-validation), and the Validation set for testing performance.</p><p>We implement our model using Tensorflow on a GPU setting. The model is iteratively trained to minimize the Mean Squared Error (MSE) be- tween trait predictions and corresponding training set ground truths, using Adam ( <ref type="bibr">Kingma and Ba, 2014</ref>) as optimizer and Dropout ( <ref type="bibr">Srivastava et al., 2014</ref>) in between the two fully connected layers to prevent model overfitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Personality induction from text</head><p>CNNs have also gained popularity recently in ef- ficiently carrying out the task of text classification <ref type="bibr">(Kalchbrenner et al., 2014;</ref><ref type="bibr">Kim, 2014)</ref>. In par- ticular, using pre-trained word embeddings like word2vec ( <ref type="bibr">Mikolov et al., 2013</ref>) to represent the text has proved to be useful in classifying text from different domains. We have trained a model that takes as input text represented with the pre- trained word embeddings, followed by a single CNN layer, and then a max pooling, and a fully connected layer with softmax at the end to map the features to the binary classification task.</p><p>The convolution window sizes of 3, 4 and 5 were used in order to represent the n-gram fea- tures, and a total of 128 filters were trained in parallel. For regularization, the L2 regulariza- tion with lambda 0.01, and Dropout of 0.5 was used. We used rectified linear (ReLu) to add non- linearity, and the Adam optimizer was used for the training update at each step.</p><p>The datasets used for the training are taken from the Workshop on Computational Personal- ity Recognition (WCPR) ( <ref type="bibr">Kosinski and Stillwell, 2012;</ref><ref type="bibr">Celli et al., 2014</ref>). The Facebook and Youtube personality datasets were combined and used for training. The Facebook dataset consists of status updates taken from 250 users with their per- sonality labeled via a form the users filled up, and the Youtube dataset has 404 different transcrip- tions of vloggers which are labeled via perceived personality with the help of mechanical turk. A median split of the scores is done to divide each of the big five personality groups into two classes, and so the task was five different binary classifica- tions, one for each trait.</p><p>We trained a SVM classifier using LIWC <ref type="bibr" target="#b3">(Pennebaker et al., 2001</ref>) lexical features to treat as baseline ( <ref type="bibr">Verhoeven et al., 2013</ref>) in order to com- pare with our own model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results</head><p>For personality perception from audio, our model outputs a continuous score between 0 and 1 for each of the five traits for any given sample. We evaluate its performance by turning the continu- ous labels and outputs into binary classes using median splits. Our classification performance is good when comparing, for instance, to the winner of the 2012 INTERSPEECH Speaker Trait sub- Challenge on Personality ( <ref type="bibr">Ivanov and Chen, 2012;</ref><ref type="bibr">Schuller et al., 2012</ref>  For personality induction from text, the CNN model for text beats the F-score performance of the SVM baseline by a large margin (see <ref type="table" target="#tab_1">Table  2</ref>). Our immediate future work will focus on com- bining the two models described in this paper and adding facial expression data to the input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Adaptive Virtual Agent</head><p>Past research has shown the importance of VAs adapting to users in terms of culture (Al-Saleh and Romano, 2015), learning style ( <ref type="bibr">Liew and Tan, 2016)</ref>, and social constructs ( <ref type="bibr">Youssef et al., 2015</ref>). These scenarios show improvement in user satis- faction and also better collaboration between the user and the VA ( <ref type="bibr">Hu et al., 2015;</ref><ref type="bibr">Liew and Tan, 2016)</ref>. In addition, users prefer adaptive agents to non-adaptive VAs when completing a task ( <ref type="bibr">Hu et al., 2015)</ref>. However, whether and how users would prefer adaptive personality in virtual agents has not yet been explored. To this end, we con- ducted a counter-balanced, three-by-three factorial within-subject study with 36 participants recruited from a local university.</p><p>Each participant filled in a big-five question- naire and was shown three different virtual agents in random order. A Robotic VA was devel- oped as control; it replies to affect-sensitive com- ments with impersonal responses like "I don't understand" and "No answer detected." The two personality-driven VAs were based on Clifford Nass' work on computers with personalities ( <ref type="bibr" target="#b1">Nass et al., 1995)</ref>. The Tough VA (TVA) and the Gen- tle VA (GVA) embody the traits of dominance and submissiveness dimension of interpersonal behav- ior <ref type="bibr">(Kiesler, 1983)</ref> respectively. Below, adjectives that signify each dimension are listed:</p><p>• Dominance: able to give orders, assumes re- sponsibilities, controlling, self-assertive</p><p>• Submissive: easily led, lets others make de- cisions, and avoids responsibilities</p><p>After interacting with each VA, the participants filled out a survey to indicate and explain their VA preference and user satisfaction. We looked at the correlations between users' Big Five scores and their VA personality preference. Especially the Openness trait correlates with Submissive prefer- ence, where higher scores indicate an increased preference for submissiveness in an agent (see <ref type="figure" target="#fig_1">Fig- ure 4)</ref>. Our results also show that 77.78% of the participants found GVA more desirable to con- verse with, 16.67% with TVA, and only 5% pre- ferred the Robotic version. This is in line with human interactions, where empathy in physicians directly improves patient satisfaction and recovery <ref type="bibr">(Derksen et al., 2013)</ref>. Therefore, our preliminary results broadly showed that users prefer personal- ity adaptation in VAs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Future Work</head><p>Our future work would involve improving Zara's adaptation to user personality. To increase VA's personality flexibility, we can do a modelling of different personalities from movie and TV se- ries characters using machine learning techniques. An adaptive personality module may also require some form of personality compatibility matching between users and the VA. To improve, we can seek works in psychology on friendship and rela- tionship compatibility based on personality <ref type="bibr">(Huston and Houts, 1998</ref>) to extract and match features between the user and the VA. We are also design- ing more user experiments with more subjects and additional VA preference scales (apart from the Dominant-Submissive axis).</p><p>Furthermore, we have collected larger datasets to train our text model. One dataset contains 22 million status updates from 154,000 Facebook users, labeled with Big Five scores ( <ref type="bibr">Kosinski and Stillwell, 2012)</ref>. Another way to improve the per- sonality identification results is to train a separate ensemble model, which would take as input text, speech audio and facial features, and return the Big Five classifications as output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We have described Zara the Supergirl, a multi- modal interactive system that shows empathy to users and tries to assess their personality in the form of the Big Five traits, and have explained the personality modules used in detail. Training the classifier from raw audio directly without feature extraction enables real-time processing and hence makes it more suitable for applications like dia- logue systems. We have also shown that our CNN classifier from text gives a much better perfor- mance when compared to the conventional SVM approach with lexical features. Our user study shows some interesting insights about the signifi- cance of personality adaptation in human-agent in- teractions. As we continue to build conversational systems that can detect and adapt to user personal- ity, the interaction between user and machine can be more personal and human-like. This will in turn make it easier for people to consider virtual agents as their friends and counselors.  Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor- rado, and Jeff Dean. 2013. Distributed representa- tions of words and phrases and their compositional- ity. In Advances in neural information processing systems. pages 3111-3119.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head><p>Adam S Miner, Arnold Milstein, Stephen Schueller, Roshini Hegde, Christina Mangurian, and Eleni Linos. 2016. Smartphone-based conversational agents and responses to questions about mental health, interpersonal violence, and physical health. JAMA internal medicine 176(5):619-625.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: CNN to extract personality features from raw audio, mapped to Big Five personality traits</figDesc><graphic url="image-3.png" coords="3,83.66,62.81,194.95,162.09" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Correlation between user Big Five personality dimensions and VA personality</figDesc><graphic url="image-4.png" coords="5,76.14,62.81,210.00,220.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Donald J Kiesler. 1983 .</head><label>1983</label><figDesc>The 1982 interpersonal circle: A taxonomy for complementarity in human transac- tions. Psychological review 90(3):185. Yoon Kim. 2014. Convolutional neural net- works for sentence classification. arXiv preprint arXiv:1408.5882 . Diederik Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 . Michal Kosinski and David Stillwell. 2012. myperson- ality research wiki. Tze Wei Liew and Su-Mae Tan. 2016. Virtual agents with personality: Adaptation of learner-agent per- sonality in a virtual learning environment. In Digital Information Management (ICDIM), 2016 Eleventh International Conference on. IEEE, pages 157-162. M Valora Long and Peter Martin. 2000. Personality, relationship closeness, and loneliness of oldest old adults and their children. The Journals of Geron- tology Series B: Psychological Sciences and Social Sciences 55(5):P311-P319. François Mairesse, Marilyn A Walker, Matthias R Mehl, and Roger K Moore. 2007. Using linguis- tic cues for the automatic recognition of personality in conversation and text. Journal of artificial intelli- gence research 30:457-500.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>) . Table 1 shows</head><label>.1</label><figDesc></figDesc><table>the model 
performance on the ChaLearn Validation set for 
this 2-class problem. The average of the mean ab-% 

Average Extr Agre Cons Neur Open 

Accuracy 
62.3 
63.2 61.5 60.1 
64.2 
62.5 
P recision 
60.6 
60.5 60.6 58.4 
62.7 
60.8 
Recall 
81.8 
83.7 83.2 86.3 
78.3 
77.6 
F − Score 
69.6 
70.2 70.1 69.6 
69.7 
68.2 

Table 1: Classification performance on ChaLearn Validation dataset using CNN on raw audio 

Average Extr Agre Cons Neur Open 

CNN model 
71.0 
70.8 72.7 70.8 
72.9 
67.9 
Baseline SVM 
59.4 
59.6 57.7 60.1 
63.4 
56.0 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 : F-Score results of CNN model on text compared to the baseline SVM with LIWC features</head><label>2</label><figDesc></figDesc><table>solute error over the traits is 0.1075. 
</table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Automatic personality perception: Prediction of trait attribution based on prosodic features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gelareh</forename><surname>Mohammadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Vinciarelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Affective Computing</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="273" to="284" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Can computer personalities be human personalities?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clifford</forename><surname>Nass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngme</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Byron</forename><surname>Fogg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Reeves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dryer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference companion on Human factors in computing systems</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1995" />
			<biblScope unit="page" from="228" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Analysis of cnn-based speech recognition system using raw speech as input</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitri</forename><surname>Palaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
	<note>Idiap</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Linguistic inquiry and word count: Liwc</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><forename type="middle">E</forename><surname>James W Pennebaker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger J</forename><surname>Francis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Booth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mahway: Lawrence Erlbaum Associates</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
