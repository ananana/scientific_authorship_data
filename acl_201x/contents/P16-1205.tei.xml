<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:11+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Modeling Stance in Student Essays</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>August 7-12, 2016. 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isaac</forename><surname>Persing</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Human Language Technology Research Institute University of Texas at Dallas Richardson</orgName>
								<address>
									<postCode>75083-0688</postCode>
									<region>TX</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Human Language Technology Research Institute University of Texas at Dallas Richardson</orgName>
								<address>
									<postCode>75083-0688</postCode>
									<region>TX</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Modeling Stance in Student Essays</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2174" to="2184"/>
							<date type="published">August 7-12, 2016. 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Essay stance classification, the task of determining how much an essay&apos;s author agrees with a given proposition, is an important yet under-investigated subtask in understanding an argumentative essay&apos;s overall content. We introduce a new corpus of argumentative student essays annotated with stance information and propose a computational model for automatically predicting essay stance. In an evaluation on 826 essays, our approach significantly outperforms four baselines, one of which relies on features previously developed specifically for stance classification in student essays, yielding relative error reductions of at least 11.3% and 5.3%, in micro and macro F-score, respectively.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>State-of-the-art automated essay scoring engines such as E-rater ( <ref type="bibr" target="#b2">Attali and Burstein, 2006</ref>) do not grade essay content, focusing instead on pro- viding diagnostic trait feedback on categories such as grammar, usage, mechanics, style and organization. Hence, persuasiveness and other content-dependent dimensions of argumentative essay quality are largely ignored in existing auto- mated essay scoring research. While full-fledged content-based essay scoring is still beyond the reach of state-of-the-art essay scoring engines, re- cent work has enabled us to move one step closer to this ambitious goal by analyzing essay content, attempting to determine the argumentative struc- ture of student essays <ref type="bibr" target="#b21">(Stab and Gurevych, 2014)</ref> and the persuasiveness of the arguments made in these essays <ref type="bibr" target="#b17">(Persing and Ng, 2015)</ref>.</p><p>Stance classification is an important first step in determining how persuasive an argumentative stu- dent essay is because persuasiveness depends on how well the author argues w.r.t. the stance she takes using the supporting evidence she provides. For instance, if her stance is Agree Somewhat, a persuasive argument would involve explaining what reservations she has about the given propo- sition. As another example, an argumentative es- say in which the author takes a neutral stance or the author presents evidence that does not support the stance she claims to take should receive a low persuasiveness score.</p><p>Given the important role played by stance classification in determining an essay's persua- siveness, our goal in this paper is to examine stance classification in argumentative student es- says. While there is a large body of work on stance classification 1 , stance classification in argumen- tative essays is largely under-investigated and is different from previous work in several respects. First, in automated essay grading, the majority of the essays to be assessed are written by students who are learners of English. Hence our stance classification task could be complicated by the au- thors' lack of fluency in English. Second, essays are longer and more formally written than the text typically used in previous stance classification re- search (e.g., debate posts). In particular, a student essay writer typically expresses her stance on the essay's topic in a thesis sentence/clause, while a debate post's author may never even explicitly ex- press her stance. Although the explicit expression of stance in essays seems to make our task easier, Prompt Prompt Parts Most university degrees are theoretical and do not prepare students for the real world. They are therefore of very little value. 1) Most university degrees are theoretical. 2) Most university degrees do not prepare students for the real world. 3) Most university degrees are of very little value. The prison system is outdated. No civilized society should punish its criminals: it should rehabilitate them.</p><p>1) The prison system is outdated. 2) No civilized society should punish its criminals. 3) Civilized societies should rehabilitate criminals. <ref type="table" target="#tab_0">Table 1</ref>: Some examples of essay prompts and their associated parts.</p><p>identifying stancetaking text in the midst of non- stancetaking sentences in a potentially long essay, as we will see, is by no means a trivial task.</p><p>To our knowledge, the essay stance classifica- tion task has only been attempted by <ref type="bibr" target="#b10">Faulkner (2014)</ref>. However, the version of the task we address is different from his. First, Faulkner only performed two-class stance classification: while his corpus contains essays labeled with For (Agree), Against (Disagree), and Neither, he simplified the task by leaving out the arguably most difficult-to-identify stance, Neither. In con- trast, we perform fine-grained stance classifica- tion, where we allow essay stance to take one of six values: Agree Strongly, Agree Somewhat, Neutral, Disagree Somewhat, Disagree Strongly, and Never Addressed, given the practical need to perform fine-grained stance classification in stu- dent essays, as discussed above. Second, given that many essay prompts are composed of multiple simpler propositions (e.g., the prompt "Most uni- versity degrees are theoretical and do not prepare students for the real world" has two parts, "Most university degrees are theoretical" and "Most uni- versity degrees do not prepare students for the real world."), we manually split such prompts into prompt parts and determine the stance of the au- thor w.r.t. each part, whereas Faulkner assigned an overall stance to a given prompt regardless of whether it is composed of multiple propositions. The distinction is important because an analysis of our annotations described in Section 2 shows that essay authors take different stances w.r.t. dif- ferent prompt parts in 49% of essays, and in 39% of essays, authors even take stances with different polarities w.r.t. different prompt parts.</p><p>In sum, our contributions in this paper are two- fold. First, we propose a computational model for essay stance classification that outperforms four baselines, including our re-implementation of Faulkner's approach. Second, in order to stimulate further research on this task, we make our anno- tations publicly available. Since progress on this task is hindered in part by the lack of a publicly annotated corpus, we believe that our data set will be a valuable resource for the NLP community.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Corpus</head><p>We use as our corpus the 4.5 million word Interna- tional Corpus of Learner English (ICLE) ( <ref type="bibr" target="#b11">Granger et al., 2009)</ref>, which consists of more than 6000 essays on a variety of different topics written by university undergraduates from 16 countries and 16 native languages who are learners of English as a Foreign Language. 91% of the ICLE texts are written in response to prompts that trigger argu- mentative essays, and thus are expected to take a stance on some issue. We select 11 such prompts, and from the subset of argumentative essays writ- ten in response to them, we select 826 essays to annotate for training and testing our stance clas- sification system. 2 <ref type="table" target="#tab_0">Table 1</ref> shows two of the 11 topics selected for annotation.</p><p>We pair each of the 826 essays with each of the prompt parts to which it responds, resulting in 1,593 instances. <ref type="bibr">3</ref> We then familiarize two human annotators, both of whom are native speakers of English, with the stance definitions in <ref type="table" target="#tab_1">Table 2</ref> and ask them to assign each instance the stance label they believe the essay's author would have chosen if asked how strongly she agrees with the prompt part. We additionally furnish the annotators with descriptions of situations that might cause an au- thor to select the more ambiguous classes. For ex- ample, an author might choose Agree Somewhat if she appears to mostly agree with the prompt part, but qualifies her opinion in a way that is not cap- tured by the prompt part's bluntness (e.g. an au- thor who claims the prison system in a lot of coun- tries is outdated would Agree Somewhat with the first part of The author seems to agree with and care about the claim.</p><formula xml:id="formula_0">Agree Somewhat (148)</formula><p>The author generally agrees with the claim, but might be hesitant to choose "Agree Strongly". Neutral <ref type="formula">(28)</ref> The author agrees with the claim as much as s/he disagrees with it. Disagree Somewhat (91)</p><p>The author generally disagrees with the claim, but might be hesitant to choose "Disagree Strongly". Disagree Strongly (416)</p><p>The author seems to disagree with and care about the claim. Never Addressed (25) A stance cannot be inferred be- cause the proposition was never ad- dressed. agree with the prompt part, but mentions the dis- agreement only in passing because she does not care much about the topic.</p><p>To ensure consistency in annotation, we ran- domly select 100 essays (187 instances) for anno- tation by both annotators. Their labels agree in 84.5% of the instances, yielding a Cohen's (1960) Kappa of 0.76. Each case of disagreement is re- solved through discussion between the annotators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Baseline Stance Classification Systems</head><p>In this section, we describe four baseline systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Agree Strongly Baseline</head><p>Given the imbalanced stance distribution shown in <ref type="table" target="#tab_1">Table 2</ref>, we create a simple but by no means weak baseline, which predicts that every instance has most frequent class label (Agree Strongly), re- gardless of the prompt part or the essay's contents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">N-Gram Baseline</head><p>Previous work on stance classification, which as- sumes that stance-annotated training data is avail- able for every topic for which stance classifica- tion is performed, has shown that the N-Gram baseline is a strong baseline. Not only is this assumption unrealistic in practice, but it has led to undesirable consequences. For instance, the proposition "feminists have done more harm to the cause of women than good" elicits much more disagreement than normal. So, if instances from this proposition appeared in both the training and test sets, the unigram feature "feminist" would be strongly correlated with the disagreement classes even though intuitively it tells us nothing about stance. This partly explains why the N-Gram base- line was strong in previous work <ref type="bibr" target="#b19">(Somasundaran and Wiebe, 2010)</ref>. In light of this problem, we perform leave-one-out cross validation where we partition the instances by prompt, leaving the in- stances created for one prompt out in each test set.</p><p>To understand how strong n-grams are when evaluated in our leave-one-prompt-out cross- validation setting, we employ them as features in our second baseline. Specifically, we train a mul- ticlass classifier on our data set using a feature set composed solely of unigram, bigram, and trigram features, each of which indicates the number of times the corresponding n-gram is present in the associated essay.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Duplicated Faulkner Baseline</head><p>While it is true that no system exists for solv- ing our exact problem, the system proposed by Faulkner (2014) comes fairly close. Hence, as our third baseline, we train a multiclass classifier on our data set for fine-grained essay stance classifi- cation using the two types of features proposed by Faulkner, as described below.</p><p>Part-of-speech (POS) generalized dependency subtrees. Faulkner first constructs a lexicon of stance words in the style of <ref type="bibr" target="#b19">Somasundaran and Wiebe (2010)</ref>. The lexicon consists of (1) the set of stemmed first unigrams appearing in all stance- annotated text spans in the Multi-Perspective Question Answering (MPQA) corpus <ref type="bibr" target="#b25">(Wiebe et al., 2005</ref>), and (2) the set of boosters (clearly, de- cidedly), hedges (claim, estimate), and engage- ment markers (demonstrate, evaluate) from the ap- pendix of <ref type="bibr" target="#b13">Hyland (2005)</ref>. He then manually re- moves from this list any words that appear not to be stancetaking, resulting in a 453 word lexicon.</p><p>Stance words target propositions, which Faulkner notes, usually contain some opinion- bearing language that can serve as a proxy for the targeted proposition. In order to find the locations in an essay where a stance is being taken, he first finds each stance word in the essay. Then he finds the shortest path from the stance word to an opinion word in the sentence's dependency tree, using the MPQA subjectivity lexicon of opinion words ( <ref type="bibr" target="#b25">Wiebe et al., 2005</ref>). If this nearest opinion word appears in the stance word's immediate or embedded clause, he creates a binary feature by concatenating all the words in the dependency path, POS generalizing all words other than the stance and opinion word, and finally prepending "not" if the stance word is adjacent to a negator in the dependency tree. Thus given the sentence "I can only say that this statement is completely true." he would add the feature can-V-true, which suggests agreement with the prompt.</p><p>Prompt topic words. Recall that for the previ- ous feature type, a feature was generated whenever an opinion word occurred in a stance word's im- mediate or embedded clause. Each content word in this clause is used as a binary feature if its similarity with one of the prompt's content words meets an empirically determined threshold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">N-Gram+Duplicated Faulkner Baseline</head><p>To build a stronger baseline, we employ as our fourth baseline a classifier trained on both n-gram features and duplicated Faulkner's features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Our Approach</head><p>Our approach to stance classification is a learning- based approach where we train a multiclass clas- sifier using four types of features: n-gram fea- tures (Section 3.2), duplicated Faulkner's features (Section 3.3), and two novel types of features, stancetaking path-based features (Section 4.1) and knowledge-based features (Section 4.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Stancetaking Path-Based Features</head><p>Recall that, in order to identify his POS general- ized dependency subtrees, Faulkner relies on two lexica, a lexicon of stancetaking words and a lex- icon of opinion-bearing words. He then extracts a feature any time words from the two lexica are syntactically close enough. A major problem with this approach is that the lexica are so broad that nearly 80% of sentences in our corpus contain text that can be identified as stancetaking using this method. Intuitively, an essay may state its stance w.r.t. a prompt part in a thesis or conclusion sen- tence, but most of essay's text will be at most tan- gentially related to any particular prompt part. For this reason, we propose to identifying stancetaking text to target only text that appears directly related to the prompt part. Below we first show how we identify and stance-labeling relevant stancetaking dependency paths, and then describe the features we derive from these paths.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Identifying relevant stancetaking paths</head><p>As noted above, we first identify stancetaking text that appears directly related to the prompt part. To begin, we note that the prompt parts them- selves must express a stance on a topic if they can be agreed or disagreed with. By examining the de- pendency parses <ref type="bibr">4</ref> of the prompt parts, we can rec- ognize elements of how stancetaking text is struc- tured. From the prompt part shown in <ref type="figure" target="#fig_0">Figure 1</ref>, for example, we notice that the important words that express a stance in the sentence are "money", "root", and "evil". By analyzing the dependency structure in this and other prompt parts, we dis- covered that stancetaking text often consists of <ref type="formula">(1)</ref> a subject word, which is the child in an nsubj or nsubjpass relation, (2) a governor word which is the subject's parent, and (3) an object, which is a content word from which there is a (not always direct) dependency path from the governor. We therefore abstract a stance in an essay as a depen- dency path from a subject to an object that passes through the governor. Thus, the stancetaking de- pendency path we identify from the prompt part shown in <ref type="figure" target="#fig_0">Figure 1</ref> could be represented as money- root-evil.</p><p>The obvious problem with identifying stanc- etaking text in this way is that nearly all sentences contain this kind of stancetaking structure, and just as with Faulkner's dependency paths, there is lit- tle reason to believe that any particular path is relevant to an instance's prompt part. Does this mean that nearly all sentences are stancetaking? We would argue that they can be, as even sen- tences that appear on their face to be mere state- ments of fact with no apparent value judgment can be viewed as taking a stance on the factuality of the statement, and people often disagree about the factuality of statements. For this reason, after we have identified a stancetaking path, we must de- termine whether the stance being expressed is rel- evant to the prompt part before extracting features from it. For this reason, we ignore all stancetaking paths that do not meet the following three relevance con- ditions. First, the lemma of the path's governor must match the lemma of a governor in the prompt part. Second, the lemma of the path's object must match the lemma of some content word 5 in the prompt part. Finally, the containing sentence must not contain a question mark or a quotation, as such sentences are usually rhetorical in nature. We do not require that the subject word match the prompt part's subject word because this substantially re- duces coverage for various reasons. For one, of the three words (subject, governor, object), the sub- ject is the word most likely to be replaced with some other word like a pronoun, and possibly be- cause the essays were written by non-native En- glish speakers, automatic coreference resolution cannot reliably identify these cases. We also do not fully trust that the subject identified by the de- pendency parser will reliably match the subject we are looking for. Given these constraints, we can automatically identify the "itself-root-of-evil" de- pendency path in <ref type="figure" target="#fig_1">Figure 2</ref> as a relevant stancetak- ing path.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Stance-labeling the paths</head><p>Next, we determine whether a stancetaking path identified in the previous step appears to agree or disagree with the prompt part.</p><p>To begin, we count the number of negations oc- curring in the prompt part. Any word like "no", "not", or "none" counts as a negation unless it be- gins a non-negation phrase like "no doubt" or "not only". 6 Thus, the count of negations in the prompt part in <ref type="figure" target="#fig_0">Figure 1</ref> is 0.</p><p>After that, we count the number of times the identified stancetaking path is negated. Because <ref type="bibr">5</ref> For our purpose, a content word (1) is a noun, pronoun, verb, adjective, or adverb, (2) is not a stopword, and (3) is at the root, is a child in a dobj or pobj relation, or is the child in a conj relation whose parent is the child in a dobj or pobj relation in the dependency tree. <ref type="bibr">6</ref> See our website at http://www.hlt.utdallas. edu/ ˜ persingq/ICLE/ for our list of manually con- structed negation words and non-negation phrases. these paths occur in student essays and are there- fore often not as simply-stated as the prompt parts, this is a little bit more complicated than just count- ing the containing sentence's negations since the sentence may contain a lot of additional material. To do this, we construct a list of all the depen- dency nodes in the stancetaking path as well as all of their dependency tree children. We then remove from this list any node that, in the sentence, occurs after the last node in the stancetaking path. The to- tal negation count we are looking for is the num- ber of nodes in this list that correspond to negation words (unless the negation word begins a negation phrase). Thus, because the word "not" is the child of "root" in the path "itself-root-of-evil" we iden- tified in <ref type="figure" target="#fig_1">Figure 2</ref>, we consider this path to have been negated one time.</p><p>Finally, we sum the prompt part negations and the stancetaking path negations. If this sum is even, we believe that the relevant stancetaking path agrees with the prompt part in the instance. If it is odd, however (as in the case of the prompt part and stancetaking text in the dependency tree <ref type="figure">fig- ures)</ref>, we believe that it disagrees with the prompt part. To illustrate why we are concerned with whether this sum is even, consider the following examples. If both the prompt part and the stanc- etaking text are negated, both disagree with the opposite of the prompt part's stance. Thus, they agree with each other, and their negation sum is even (2). If the stancetaking path was negated twice, however, the sum would be odd (3) due to the stance path's double negations canceling each other out, and the stancetaking path would dis- agree with the prompt part.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Deriving path-based features</head><p>We extract four features from the relevant stanc- etaking dependency paths identified and stance- labeled so far, as described below.</p><p>The first feature encodes the count of relevant stancetaking paths that appear to agree with the prompt part. The second feature encodes the count of relevant stancetaking paths that appear to dis- agree with the prompt part. While we expect these first two features to be correlated with the agreement and disagreement classes, respectively, they may not be sufficient to distinguish between agreeing and disagreeing instances. It is possi- ble, for example, that both features may be greater than zero in a single instance if we have identi- fied one stancetaking path that appears to agree with the prompt part and another stancetaking path that appears to disagree with the prompt part. It is not clear whether this situation is indicative of only the Neutral class, or perhaps it indicates par- tial (Somewhat) (Dis)Agreement, or maybe our method of detecting disagreement is not reliable enough, and it therefore makes sense, when we get these conflicting signals, to ignore them entirely and just assign the instance to the most frequent (Agree Strongly) class. For that matter, if neither feature is greater than zero, does this mean that the instance Never Addressed the prompt part, or does it instead mean that our method for identify- ing stancetaking paths doesn't have high enough recall to work on all instances? We let our learner sort these problems out by adding two more binary features to our instances, one which indicates that both of the first two features are zero, and one that indicates whether both are greater than zero.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Knowledge-Based Features</head><p>Our second feature type is composed of five lin- guistically informed binary features that corre- spond to five of the six classes in our fine-grained stance classification task. Intuitively, if an instance has one of these features turned on, it should be as- signed to the feature's corresponding class.</p><p>1. Neutral. Stancetaking text indicating neutral- ity tends to be phrased somewhat differently than stancetaking text indicating any other class. In particular, neutral text often makes claims that are about the prompt part's subject, but which are tan- gential to the proposition expressed in the prompt part. For this reason, we search the essay for words that match the prompt part's subject lem- matically.</p><p>After identifying a sentence that is about the prompt part's subject in this way, we check whether the sentence begins with any neutral indi- cating phrase. <ref type="bibr">7</ref> If we find a sentence that both be- gins with a neutral phrase and is about the prompt part's subject, we turn the Neutral feature on. Thus, sentences like the following can be cap- tured: "In all probability university students won- der whether or not they spend their time uselessly in studying through four or five years in order to take their degree." 2. (Dis)Agree Somewhat. In order to set the values of the features associated with the Some- what classes, we first identify relevant stancetak- ing paths as described above. We then trim the list of paths by removing any path whose governor or subject does not have a hedge word as an adverb modifier child in the dependency tree. 8 Thus, we are able to determine that the essay containing the sentence "There is nearly no place left for dream and imagination" is likely to belong to one of the Somewhat classes w.r.t. the prompt part "There is no longer a place for dreaming and imagination."</p><p>The question now is how to determine which (if any) of the Somewhat classes it should belong to. We analyze all the paths from the list for nega- tion in much the same way we described above, but with one major difference. We hypothesize that when taking a Somewhat stance, students are more likely to explicitly state that the stance being taken is their opinion rather than stating the stance bluntly without attribution. For example, one Dis- agree Somewhat essay includes the sentence, "I never believed these people were honest if saying that money is just the root of all evil." In order to determine that this sentence contains an indication of the Disagree Somewhat class, we need to ac- count for the negation that occurs at the beginning, far away from the stancetaking path (money-root- of-evil). To do this, we semantically parse the sen- tence using SEMAFOR ( <ref type="bibr" target="#b9">Das et al., 2010)</ref>. Each of the semantic frames detected by SEMAFOR de- scribes an event that occurs in a sentence, and the event's frame elements may be the people or other entities that participate in the event. One of the semantic frames detected in this example sentence describes a Believer (I) and the content of his or her belief (all the text after "believed"). Because the sentence includes a semantic frame that (1) contains a first person (I, we) Cognizer, Speaker, Perceiver, or Believer element, (2) contains an el- ement that covers all the text in the dependency path (a Content frame element, in this case), and (3) the word that triggers the frame ("believed") has a negator child in the dependency tree, we add one to this relevant stancetaking path's negation count. This makes this hedged stancetaking path's negation count odd, so we believe that this sen- tence likely disagrees with its instance's prompt part somewhat. If we find a hedged stancetaking path with an odd negation count, we turn on the Disagree Somewhat feature. Similarly, if we find a hedged stancetaking path with an even negation count, we turn on the Agree Somewhat feature. 3. (Dis)Agree Strongly. When we believe there is strong evidence that an instance should belong to one of the Strongly classes, we turn on the cor- responding (Dis)Agree Strongly feature. In par- ticular, if we find a relevant stancetaking path that appears to agree with the prompt part (as described in Section 4.1.2), but do not find any such path that appears to disagree with it, we turn on the Agree Strongly feature. Similarly, if we find a relevant stancetaking path that appears to disagree with the prompt part, but do not find a relevant stancetak- ing path that appears to agree with it, we turn on the Disagree Strongly feature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Setup</head><p>Data partition. All our results are obtained via leave-one-prompt-out cross-validation experi- ments. So, in each fold experiment, we partition the instances from our 11 prompts into a training set (10 prompts) and a test set (1 prompt). Evaluation metrics. We employ two metrics to evaluate our systems: (1) micro F-score, which treats each instance as having equal weight; and (2) macro F-score, which treats each class as hav- ing equal weight. <ref type="bibr">9</ref> To gain insights into how dif- ferent systems perform on different classes, we ad- ditionally report per-class F-scores. Training. We train the baselines and our ap- proach using two learning algorithms, MAL- LET's <ref type="bibr" target="#b14">(McCallum, 2002</ref>) implementation of max- imum entropy (MaxEnt) classification and our own implementation of the one nearest neighbor (1NN) algorithm using the cosine similarity met- ric. Note that these two learners have their own strengths and weaknesses: in comparison to 1NN, MaxEnt is better at exploiting high-dimensional features but less robust to skewed class distri- butions. For the baseline systems, we select the learner by performing cross validation on the training folds to maximize the average of micro and macro F-scores in each fold experiment.</p><p>When training our approach, we perform ex- haustive feature selection to determine which sub-set of the four sets of features (i.e., n-gram, dupli- cated Faulkner, path-based, and knowledge-based features) should be used. Specifically, we select the feature groups and learner jointly by perform- ing cross validation on the training folds, choos- ing the combination yielding the highest average of micro and macro F-scores in each fold experi- ment. To prevent any feature type from dominat- ing the others, to each feature we apply a weight of one divided by the number of features having its type.</p><p>Testing. In case of a tie when applying 1NN, the tie is broken by selecting the class appearing higher in <ref type="table" target="#tab_1">Table 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results and Discussion</head><p>Results on fine-grained essay stance classification are shown in <ref type="table" target="#tab_3">Table 3</ref>. The first four rows show our baselines' performances. Among the four baselines, Always Agree Strongly performs best w.r.t. micro F-score, obtaining a score of 55.6%, whereas Duplicated Faulkner performs best w.r.t. macro F-score, obtaining a score of 15.6%. De- spite its poor performance, Duplicated Faulkner is a state-of-the-art approach on this task. Its poor performance can be attributed to three major fac- tors. First, it was intended to identify only Agree and Disagree instances (note that Faulkner simply removed neutral instances from his experimental setup), which should not prevent them from per- forming well w.r.t. micro F-score. Second, it is far too permissive, generating features from a large majority of sentences while relevant sentences are far rarer. Third, while it does succeed at predicting Disagree Strongly far more frequently than either of the other baselines that excludes the Faulkner feature set, the problem's class skewness means that a learner is much more likely to be punished for predicting minority classes, which are more difficult to predict with high precision.</p><p>The fact that it makes an attempt to solve the problem rather than relying on class skewness for good performance makes Duplicated Faulkner a more interesting baseline than either N-Gram or Always Agree Strongly, even though both tech- nically outperform it w.r.t. micro F-score. Simi- larly, the statistically significant improvements in micro and macro F-score our approach achieves over the best baselines are more impressive when taking the skewness problem into consideration.</p><p>The results of our approach, which has access  to all four feature groups, are shown in row 5 of the table. It obtains micro and macro F-scores of 60.6% and 20.1%, which correspond to statisti- cally significant relative error reductions over the best baselines of 11.3% and 5.3%, respectively. <ref type="bibr">10</ref> Recall that we turned on one of our knowledge- based features only when we believed there was strong evidence that an instance belonged to its associated class. To get an idea of how use- ful these features are, we calculate the preci- sion, recall, and F-score that would be obtained for each class if we treated our knowledge-based features as heuristic classifiers. Since the rule predictions are encoded as features for the learner, they may not necessarily be used by the learner even if the un- derlying rules are precise. For instance, despite the rule's high precision on the Agree Somewhat class, the learner did not make use of its predic- tions due to its low coverage.</p><formula xml:id="formula_1">System Micro-F Macro-F A+ A− Neu D− D+</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Additional Experiments</head><p>Since all the systems we examined fared poorly on identifying Somewhat classes, one may won- der how these systems would perform if we con- sidered a simplified version of the task where we merged each Somewhat class with the correspond- ing Strongly class. In particular, since Faulkner's approach was originally not designed to distin- guish between Strongly and Somewhat classes, it may seem fairer to compare our approach against Duplicated Faulkner on the four-class essay stance classification task, where stance can take one of four values: Agree (created by merging Agree <ref type="bibr">10</ref> All significance tests are approximate randomization tests with p &lt; 0.01. Boldfaced results are significant w.r.t. micro F-score for the Always Agree Strongly baseline, and macro F-score w.r.t. the Duplicated Faulkner baseline.</p><p>Strongly and Agree Somewhat), Disagree (cre- ated by merging Disagree Strongly and Disagree Somewhat), Neutral, and Never Addressed.</p><p>In the results for the different systems on this four-class stance classification task, shown in Ta- ble 4, we see that the same patterns we noticed in the six-class version of the task persist. The ap- proaches' relative order w.r.t. micro and macro F- score remains the same, though they are adjusted upwards due to the problem's increased simplicity. Our approach's performance on Agree increases (compared to Agree Strongly) because Agree is a bigger class, making predictions of the class safer. Our approach's performance decreases on Disagree (compared to Disagree Strongly) since it is not good at predicting Disagree Somewhat in- stances which are part of the class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Error Analysis</head><p>To gain additional insights into our approach, we analyze its six major sources of error below.</p><p>Stances not presented in a straightforward manner. As an example, consider "To my opin- ion this technological progress triggers off the imagination in a certain way." To identify this sentence as strongly disagreeing with the propo- sition "there is no longer a place for dreaming and imagination", we need to understand (1) the world knowledge that technological progress is occur- ring, (2) that "triggers off the imagination in a cer- tain way" means that the technological progress coincides with imagination occurring, (3) that if imagination is occurring, there must be "a place for dreaming and imagination", and (4) that the prompt part is negated. In general, in order to con- struct reliable features to increase our coverage of essays that express their stance like this, we would need additional world knowledge and a deeper un- derstanding of the text.  for identifying stancetaking paths misidentifies "I am going to discuss the topic that television is the opium of the masses in modern society" as stanc- etaking. To handle this, we need to incorporate more sophisticated methods for detecting rhetori- cal statements than those we are using (e.g., ignor- ing sentences ending in question marks). Negation expressed without negation words.</p><p>Our techniques for capturing negation are un- able to detect when negation is expressed with- out the use of simple negation words. For ex- ample, "In this sense money is the root of life" should strongly disagree with "money is the root of all evil". The author replaced "life" with "evil", and detecting that this constitutes something like negation would require semantic knowledge about words that are somehow opposite of each other. Insufficient feature/heuristic coverage of the Disagree Strongly class. Our stancetaking path- based features that we identified as intuitively hav- ing a connection to the Disagree Strongly class to- gether cover only 51% of Disagree Strongly in- stances, meaning that it is in principle impossi- ble for our system to identify the remaining 49%. However, our decision to incorporate only fea- tures that are expected to have fairly high preci- sion for some class was intentional, as the lesson we learned from the Faulkner-based system is that it is difficult to learn a good classifier for stance classification using a large number of weakly or non-predictive features. To solve this problem, we would therefore need to exploit other aspects of strongly disagreeing essays that act as reliable pre- dictors of the class. Rarity of minority class instances. It is per- haps not surprising that our learning-based ap- proach performs poorly on the minority classes. Even though the knowledge-based features were designed in part to improve the prediction of mi- nority classes, our results suggest that the result- ing features were not effectively exploited by the learners. To address this problem, one could em- ploy a hybrid rule-based and learning-based ap- proach where we use our machine-learned clas- sifier to classify an instance only if it cannot be classified by any of these rules. Lack of obvious similarity between instances of the same class. For example, if the most straightforward stancetaking sentence in an Agree Somewhat instance reads something like this, "In conclusion, I will not go to such extremes as to declare nihilistically that university does not pre- pare me for the real world in the least", (given the prompt part "Most university degrees do not pre- pare us for real life"), and we somehow managed to identify the instance's class as Agree Some- what, what would the instance have in common with other Agree Somewhat instances? Given the numerous ways of expressing a stance, we believe a deeper understanding of essay text is required in order automatically detect how instances like this are similar to instances of the same class, and such similarities are required for learning in general.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We examined the new task of fine-grained es- say stance classification, in which we determine stance for each prompt part and allow stance to take one of six values. We addressed this task by proposing two novel types of features, stanc- etaking path-based features and knowledge-based features. In an evaluation on 826 argumentative essays, our learning-based approach, which com- bines our novel features with n-gram features and Faulkner's features, significantly outperformed four baselines, including our re-implementation of Faulkner's system. Compared to the best base- lines, our approach yielded relative error reduc- tions of 11.3% and 5.3%, in micro and macro F- score, respectively. Nevertheless, accurately pre- dicting the Somewhat, Neutral, and Never Ad- dressed stances remains a challenging task. To stimulate further research on this task, we make all of our stance annotations publicly available.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Automatic dependency parse of a prompt part.</figDesc><graphic url="image-1.png" coords="4,307.28,62.81,212.60,77.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Automatic dependency parse of an essay sentence.</figDesc><graphic url="image-2.png" coords="5,72.00,62.81,212.61,69.59" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 's second prompt). Or she may choose Disagree Somewhat if she appears to dis-</head><label>1</label><figDesc></figDesc><table>Stance 

Definition 
Agree 
Strongly 
(885) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 : Stance label counts and definitions.</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Cross-validation results for fine-grained essay stance classification, including per-class F-scores 
for Agree Strongly (A+), Agree Somewhat (A−), Neutral (Neu), Disagree Somewhat (D−), Disagree 
Strongly (D+), and Never Addressed (Nev). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Cross-validation results for four-class essay stance classification for Agree (A), Neutral (Neu), 
Disagree (D), and Never Addressed (Nev). 

</table></figure>

			<note place="foot" n="2"> See our website at http://www.hlt.utdallas. edu/ ˜ persingq/ICLE/ for the complete list of essay stance annotations. 3 We do not segment the essays&apos; texts according to which prompt part is being responded to. Each (entire) essay is viewed as a response to all of its associated prompt parts.</note>

			<note place="foot" n="4"> Dependency parsing, POS tagging, and lemmatization are performed automatically using the Stanford CoreNLP system (Manning et al., 2014)</note>

			<note place="foot" n="7"> We construct a list of neutral phrases for introducing another person&apos;s ideas from a writing skills website (http://www.myenglishteacher.eu/question/ other-ways-to-say-according-to/).</note>

			<note place="foot" n="8"> See our website at http://www.hlt.utdallas. edu/ ˜ persingq/ICLE/ for our manually constructed list of hedge words.</note>

			<note place="foot" n="9"> Since stance classification is a multiclass, single-label task, micro F-score, precision, recall, and accuracy are all equivalent.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the three anonymous reviewers for their detailed comments. This work was supported in part by NSF Grants IIS-1219142 and IIS-1528037. Any opinions, findings, conclusions or recommen-dations expressed in this paper are those of the au-thors and do not necessarily reflect the views or of-ficial policies, either expressed or implied, of NSF.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Identifying opinion subgroups in arabic online discussions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amjad</forename><surname>Abu-Jbara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="829" to="835" />
		</imprint>
	</monogr>
	<note>Short Papers)</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Mining newsgroups using networks arising from social behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rakesh</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramakrishnan</forename><surname>Sridhar Rajagopalan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yirong</forename><surname>Srikant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th International Conference on World Wide Web</title>
		<meeting>the 12th International Conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="529" to="535" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Automated essay scoring with E-rater v.2.0</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yigal</forename><surname>Attali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jill</forename><surname>Burstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Learning, and Assessment</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note>Journal of Technology</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Determining the polarity and source of opinions expressed in political debates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Balahur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zornitsa</forename><surname>Kozareva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrés</forename><surname>Montoyo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Conference on Computational Linguistics and Intelligent Text Processing</title>
		<meeting>the 10th International Conference on Computational Linguistics and Intelligent Text Processing</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="468" to="480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The power of negative thinking: Exploiting label disagreement in the min-cut classification framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Computational Linguistics: Companion volume: Posters</title>
		<meeting>the 22nd International Conference on Computational Linguistics: Companion volume: Posters</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="15" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Identifying justifications in written dialogs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Or</forename><surname>Biran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Owen</forename><surname>Rambow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 IEEE Fifth International Conference on Semantic Computing</title>
		<meeting>the 2011 IEEE Fifth International Conference on Semantic Computing</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="162" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Back up your stance: Recognizing arguments in online discussions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Boltuži´boltuži´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaň</forename><surname>Snajder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Argumentation Mining</title>
		<meeting>the First Workshop on Argumentation Mining</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="49" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Collective classification of congressional floor-debate transcripts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clinton</forename><surname>Burfoot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1506" to="1515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A coefficient of agreement for nominal scales</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Educational and Psychological Measurement</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">37</biblScope>
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Probabilistic frame-semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Desai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="948" to="956" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Automated classification of stance in student essays: An approach using stance target information and the Wikipedia link-based measure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Faulkner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Seventh International Florida Artificial Intelligence Research Society Conference</title>
		<meeting>the Twenty-Seventh International Florida Artificial Intelligence Research Society Conference</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">International Corpus of Learner English (Version 2). Presses universitaires de Louvain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylviane</forename><surname>Granger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Estelle</forename><surname>Dagneaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fanny</forename><surname>Meunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Magali</forename><surname>Paquot</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Stance classification of ideological debates: Data, models, features, and constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saidul</forename><surname>Kazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth International Joint Conference on Natural Language Processing</title>
		<meeting>the Sixth International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1348" to="1356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Metadiscourse: Exploring interaction in writing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ken</forename><surname>Hyland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Continuum Discourse. Continuum</title>
		<meeting><address><addrLine>London</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Kachites</forename><surname>Mccallum</surname></persName>
		</author>
		<ptr target="http://mallet.cs.umass.edu" />
		<title level="m">MALLET: A Machine Learning for Language Toolkit</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Support or oppose? classifying positions in online debates from reply activities and opinion expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akiko</forename><surname>Murakami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rudy</forename><surname>Raymond</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics: Posters</title>
		<meeting>the 23rd International Conference on Computational Linguistics: Posters</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="869" to="875" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Modeling argument strength in student essays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isaac</forename><surname>Persing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="543" to="552" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">From argumentation mining to stance classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parinaz</forename><surname>Sobhani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Inkpen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><surname>Matwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Argumentation Mining</title>
		<meeting>the 2nd Workshop on Argumentation Mining</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="67" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Recognizing stances in ideological on-line debates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swapna</forename><surname>Somasundaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text</title>
		<meeting>the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="116" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Joint models of disagreement and stance in online debate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhanya</forename><surname>Sridhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Foulds</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bert</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lise</forename><surname>Getoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marilyn</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="116" to="125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Identifying argumentative discourse structures in persuasive essays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Stab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="46" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Get out the vote: Determining support or opposition from congressional floor-debate transcripts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2006 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="327" to="335" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Stance classification using dialogic properties of persuasion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marilyn</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Abbott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricky</forename><surname>Grant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="592" to="596" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Making conversational structure explicit: Identification of initiation-response pairs within online discussions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chia</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carolyn</forename><forename type="middle">P</forename><surname>Rosé</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="673" to="676" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Annotating expressions of opinions and emotions in language. Language Resources and Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="165" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Multi-level structured models for documentlevel sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ainur</forename><surname>Yessenalina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yisong</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2010 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1046" to="1056" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
