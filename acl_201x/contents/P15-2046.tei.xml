<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:58+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Lexicalized Tree Kernel for Open Information Extraction</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computing Science</orgName>
								<orgName type="department" key="dep2">National Institute of Informatics / JST, PRESTO †</orgName>
								<orgName type="institution">University of Alberta</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Ringlstetter</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computing Science</orgName>
								<orgName type="department" key="dep2">National Institute of Informatics / JST, PRESTO †</orgName>
								<orgName type="institution">University of Alberta</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mi-Young</forename><surname>Kim</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computing Science</orgName>
								<orgName type="department" key="dep2">National Institute of Informatics / JST, PRESTO †</orgName>
								<orgName type="institution">University of Alberta</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Randy</forename><surname>Goebel</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computing Science</orgName>
								<orgName type="department" key="dep2">National Institute of Informatics / JST, PRESTO †</orgName>
								<orgName type="institution">University of Alberta</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Kondrak</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computing Science</orgName>
								<orgName type="department" key="dep2">National Institute of Informatics / JST, PRESTO †</orgName>
								<orgName type="institution">University of Alberta</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuke</forename><surname>Miyao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computing Science</orgName>
								<orgName type="department" key="dep2">National Institute of Informatics / JST, PRESTO †</orgName>
								<orgName type="institution">University of Alberta</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Muenchen</roleName><surname>Gini</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computing Science</orgName>
								<orgName type="department" key="dep2">National Institute of Informatics / JST, PRESTO †</orgName>
								<orgName type="institution">University of Alberta</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A Lexicalized Tree Kernel for Open Information Extraction</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="279" to="284"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In contrast with traditional relation extraction , which only considers a fixed set of relations, Open Information Extraction (Open IE) aims at extracting all types of relations from text. Because of data sparseness, Open IE systems typically ignore lexical information, and instead employ parse trees and Part-of-Speech (POS) tags. However, the same syntactic structure may correspond to different relations. In this paper, we propose to use a lexical-ized tree kernel based on the word embed-dings created by a neural network model. We show that the lexicalized tree kernel model surpasses the unlexicalized model. Experiments on three datasets indicate that our Open IE system performs better on the task of relation extraction than the state-of-the-art Open IE systems of Xu et al. (2013) and Mesquita et al. (2013).</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Relation Extraction (RE) is the task of recognizing relationships between entities mentioned in text. In contrast with traditional relation extraction, for which a target set of relations is fixed a priori, Open Information Extraction (Open IE) is a gen- eralization of RE that attempts to extract all re- lations ( <ref type="bibr" target="#b0">Banko et al., 2007)</ref>. Although Open IE models that extract N-ary relations have been pro- posed, here we concentrate on binary relations.</p><p>Most Open IE systems employ syntactic infor- mation such as parse trees and part of speech (POS) tags, but ignore lexical information. How- ever, previous work suggests that Open IE would benefit from lexical information because the same syntactic structure may correspond to different re- lations. For instance, the relation &lt;Annacone, coach of, Federer&gt; is correct for the sentence "Federer hired Annacone as a coach", but not for the sentence "Federer considered Annacone as a coach," even though they have the same depen- dency path structure ( <ref type="bibr" target="#b8">Mausam et al., 2012</ref>). Lex- ical information is required to distinguish the two cases.</p><p>Here we propose a lexicalized tree kernel model that combines both syntactic and lexical informa- tion. In order to avoid lexical sparsity issues, we investigate two smoothing methods that use word vector representations: Brown clustering ( <ref type="bibr" target="#b2">Brown et al., 1992</ref>) and word embeddings created by a neural network model <ref type="bibr" target="#b4">(Collobert and Weston, 2008)</ref>. To our knowledge, we are the first to ap- ply word embeddings and to use lexicalized tree kernel models for Open IE.</p><p>Experiments on three datasets demonstrate that our Open IE system achieves absolute improve- ments in F-measure of up to 16% over the cur- rent state-of-the-art systems of <ref type="bibr" target="#b16">Xu et al. (2013)</ref> and <ref type="bibr" target="#b9">Mesquita et al. (2013)</ref>. In addition, we ex- amine alternative approaches for including lexical information, and find that excluding named enti- ties from the lexical information results in an im- proved F-score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Architecture</head><p>The goal of the Open IE task is to extract from text a set of triples {&lt; E 1 , R, E 2 &gt;}, where E 1 and E 2 are two named entities, and R is a textual fragment that indicates the semantic relation be- tween the two entities. We concentrate on binary, single-word relations between named entities. The candidate relation words are extracted from depen- dency structures, and then filtered by a supervised tree kernel model.</p><p>Our system consists of three modules: entity extraction, relation candidate extraction, and tree kernel filtering. The system structure is outlined in <ref type="figure" target="#fig_0">Figure 1</ref>. We identify named entities, parse sen- tences, and convert constituency trees into depen- dency structures using the Stanford tools <ref type="bibr" target="#b7">(Manning et al., 2014</ref>). Entities within a fixed token dis- tance (set to 20 according to development results) are extracted as pairs {&lt; E 1 , E 2 &gt;}. We then identify relation candidates R for each entity pair in a sentence, using dependency paths. Finally, the candidate triples {&lt; E 1 , R, E 2 &gt;} are paired with their corresponding tree structures, and pro- vided as input to the SVM tree kernel. Our Open IE system outputs the triples that are classified as positive. In the following sections, we describe the components of the system in more detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Relation Candidates</head><p>Relation candidates are words that may repre- sent a relation between two entities. We consider only lemmatized nouns, verbs and adjectives that are within two dependency links from either of the entities. Following <ref type="bibr" target="#b15">Wu and Weld (2010)</ref> and <ref type="bibr" target="#b8">Mausam et al. (2012)</ref>, we use dependency pat- terns rather than POS patterns, which allows us to identify relation candidates which are farther away from entities in terms of token distance.</p><p>We extract the first two content words along the dependency path between E 1 and E 2 . In the fol- lowing example, the path is E 1 → encounter → build → E 2 , and the two relation word candidates between "Mr. Wathen" and "Plant Security Ser- vice" are encounter and build, of which the latter is the correct one.</p><p>If there are no content words on the dependency path between the two entities, we instead consider words that are directly linked to either of them. In the following example, the only relation candi- date is the word battle, which is directly linked to "Edelman."</p><p>The relation candidates are manually annotated as correct/incorrect in the training data for the tree kernel models described in the following section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Lexicalized Tree Kernel</head><p>We use a supervised lexicalized tree kernel to filter negative relation candidates from the results of the candidate extraction module. For semantic tasks, the design of input structures to tree kernels is as important as the design of the tree kernels them- selves. In this section, we introduce our tree struc- ture, describe the prior basic tree kernel, and fi- nally present our lexicalized tree kernel function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Tree Structure</head><p>In order to formulate the input for tree kernel models, we need to convert the dependency path to a tree-like structure with unlabelled edges. The target dependency path is the shortest path that includes the triple and other content words along the path. Consider the following example, which is a simplified representation of the sen- tence "Georgia-Pacific Corp.'s unsolicited $3.9 billion bid for Great Northern Nekoosa Corp. was hailed by Wall Street." The candidate triple iden- tified by the relation candidate extraction module is &lt;Georgia-Pacific Corp., bid, Great Northern Nekoosa Corp.&gt;.</p><p>Our unlexicalized tree representation model is similar to the unlexicalized representations of <ref type="bibr" target="#b16">Xu et al. (2013)</ref>, except that instead of using the POS tag of the path's head word as the root, we cre- ate an abstract Root node. We preserve the depen- dency labels, POS tags, and entity information as tree nodes: (a) the top dependency labels are in-  cluded as children of the abstract Root node, other labels are attached to the corresponding parent la- bels; (b) the POS tag of the head word of the de- pendence path is a child of the Root; (c) other POS tags are attached as children of the dependency la- bels; and (d) the relation tag 'R' and the entity tags 'NE' are the terminal nodes attached to their re- spective POS tags. <ref type="figure" target="#fig_2">Figure 2</ref>(a) shows the unlexi- calized dependency tree for our example sentence.</p><p>Our lexicalized tree representation is derived from the unlexicalized representation by attaching words as terminal nodes. In order to reduce the number of nodes, we collapse the relation and en- tity tags with their corresponding POS tags. <ref type="figure" target="#fig_2">Fig- ure 2(b)</ref> shows the resulting tree for the example sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Tree Kernels</head><p>Tree kernel models extract features from parse trees by comparing pairs of tree structures. The essential distinction between different tree kernel functions is the ∆ function that calculates simi- larity of subtrees. Our modified kernel is based on the SubSet Tree (SST) Kernel proposed by <ref type="bibr" target="#b3">Collins and Duffy (2002)</ref>. What follows is a simplified de- scription of the kernel; a more detailed description can be found in the original paper.</p><p>The general function for a tree kernel model over trees T 1 and T 2 is:</p><formula xml:id="formula_0">K(T 1 , T 2 ) = ∑ n 1 ∈T 1 ∑ n 2 ∈T 2 ∆(n 1 , n 2 ),<label>(1)</label></formula><p>where n 1 and n 2 are tree nodes. The ∆ function of SST kernel is defined recursively:</p><p>1. ∆(n 1 , n 2 ) = 0 if the productions (context- free rules) of n 1 and n 2 are different.</p><p>2. Otherwise, ∆(n 1 , n 2 ) = 1 if n 1 and n 2 are matching pre-terminals (POS tags).</p><p>3. Otherwise, ∆(n 1 , n 2 ) = ∏ j (1 + ∆(c(n 1 , j), c(n 2 , j)), where c(n, j) is the jth child of n.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Lexicalized Tree Kernel</head><p>Since simply adding words to lexicalize a tree ker- nel leads to sparsity problems, a type of smoothing must be applied. <ref type="bibr" target="#b1">Bloehdorn and Moschitti (2007)</ref> measure the similarity of words using WordNet. We propose using word embeddings created by a neural network model <ref type="bibr" target="#b4">(Collobert and Weston, 2008)</ref>, in which words are represented by n-dimensional real valued vectors. Each dimen- sion represents a latent feature of the word that re- flects its semantic and syntactic properties. Next, we describe how we embed these vectors into tree kernels.</p><p>Our lexicalized tree kernel model is the same as SST, except in the following case: if n 1 and n 2 are matching pre-terminals (POS tags), then</p><formula xml:id="formula_1">∆(n 1 , n 2 ) = 1 + G(c(n 1 ), c(n 2 )),<label>(2)</label></formula><p>where c(n) denotes the word w that is the unique child of n, and</p><formula xml:id="formula_2">G(w 1 , w 2 ) = exp(−γ∥w 1 −w 2 ∥ 2 )</formula><p>is a Gaussian function for two word vectors, which is a valid kernel. We examine the contribution of different types of words by comparing three methods of including lexical information: (1) relation words only; (2) all words (relation words, named entities, and other words along the dependency path fragment); and (3) all words, except named entities. The words that are excluded are assumed to be different; for example, in the third method, G(E 1 , E 2 ) is always zero, even if the entities, E 1 and E 2 , are the same.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>281</head><p>Here we evaluate alternative tree kernel configura- tions, and compare our Open IE system to previ- ous work.</p><p>We perform experiments on three datasets (Ta- ble 1): the Penn Treebank set ( <ref type="bibr" target="#b16">Xu et al., 2013)</ref>, the New York Times set ( <ref type="bibr" target="#b9">Mesquita et al., 2013)</ref>, and the ClueWeb set which we created for this project from a large collection of web pages. <ref type="bibr">1</ref> The models are trained on the Penn Treebank training set and tested on the three test sets, of which the Penn Treebank set is in-domain, and the other two sets are out-of-domain. For word embedding and Brown clustering representations, we use the data provided by <ref type="bibr" target="#b14">Turian et al. (2010)</ref>. The SVM param- eters, as well as the Brown cluster size and code length, are tuned on the development set.  <ref type="table">Table 1</ref>: Data sets and their size (number of sen- tences). <ref type="table">Table 2</ref> shows the effect of different smooth- ing and lexicalization techniques on the tree ker- nels. In order to focus on tree kernel functions, we use the relation candidate extraction (Section 3) and tree structure (Section 4.1) proposed in this paper. The results in the first two rows indi- cate that adding unsmoothed lexical information to the method of <ref type="bibr" target="#b16">Xu et al. (2013)</ref> is not help- ful, which we attribute to data sparsity. On the other hand, smoothed word representations do im- prove F-measure. Surprisingly, a neural network approach of creating word embeddings actually achieves a lower recall than the method of Plank and Moschitti (2013) that uses Brown clustering; the difference in F-measure is not statistically sig- nificant according to compute-intensive random- ization test <ref type="bibr" target="#b10">(Padó, 2006</ref>).</p><p>With regards to lexicalization, the inclusion of relation words is important. However, unlike <ref type="bibr" target="#b11">Plank and Moschitti (2013)</ref>, we found that it is better to exclude the lexical information of entities themselves, which confirms the findings of <ref type="bibr" target="#b12">Riedel et al. (2013)</ref>. We hypothesize that the correctness of a relation triple in Open IE is not closely re- <ref type="bibr">1</ref> The Treebank set of ( <ref type="bibr" target="#b16">Xu et al., 2013)</ref>, with minor correc- tions, and the ClueWeb set are appended to this publication.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Smoothing</head><p>Lexical info P R F1 none <ref type="formula" target="#formula_0">(Xu13</ref>  <ref type="table">Table 2</ref>: The results of relation extraction with al- ternative smoothing and lexicalization techniques on the Penn Treebank set (with our relation candi- date extraction and tree structure).</p><p>lated to entities. Consider the example mentioned in ( <ref type="bibr" target="#b12">Riedel et al., 2013)</ref>: for relations like "X vis- its Y", X could be a person or organization, and Y could be a location, organization, or person.</p><p>Our final set of experiments evaluates the best- performing version of our system (the last row in <ref type="table">Table 2</ref>) against two state-of-the-art Open IE systems: <ref type="bibr" target="#b9">Mesquita et al. (2013)</ref>, which is based on several hand-crafted dependency patterns; and <ref type="bibr" target="#b16">Xu et al. (2013)</ref>, which uses POS-based relation candidate extraction and an unlexicalized tree ker- nel. Tree kernel systems are all trained on the Penn Treebank training set, and tuned on the cor- responding development sets.</p><p>The results in <ref type="table" target="#tab_3">Table 3</ref> show that our system con- sistently outperforms the other two systems, with absolute gains in F-score between 4 and 16%. We include the reported results of ( <ref type="bibr" target="#b16">Xu et al., 2013)</ref> on the Penn Treebank set, and of ( <ref type="bibr" target="#b9">Mesquita et al., 2013</ref>) on the New York Times set. The ClueWeb results were obtained by running the respective systems on the test set, except that we used our relation candidate extraction method for the tree kernel of ( <ref type="bibr" target="#b16">Xu et al., 2013</ref>). We conclude that the substantial improvement on the Penn Treebank set can be partly attributed to a superior tree kernel, and not only to a better relation candidate extrac- tion method. We also note that word embeddings statistically outperform Brown clustering on the ClueWeb set, but not on the other two sets.</p><p>The ClueWeb set is quite challenging because it contains web pages which can be quite noisy. As a result we've found that a number of Open IE errors are caused by parsing. Conjunction struc- tures are especially difficult for both parsing and relation extraction. For example, our system ex- tracts the relation triple &lt;Scotland, base, Scott&gt; from the sentence "Set in 17th century Scotland  → Scott. In the future, we will investigate whether adding information from context words that are not on the dependency path between two entities may alleviate this problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We have proposed a lexicalized tree kernel model for Open IE, which incorporates word embeddings learned from a neural network model. Our sys- tem combines a dependency-based relation candi- date extraction method with a lexicalized tree ker- nel, and achieves state-of-the-art results on three datasets. Our experiments on different configu- rations of the smoothing and lexicalization tech- niques show that excluding named entity informa- tion is a better strategy for Open IE.</p><p>In the future, we plan to mitigate the perfor- mance drop on the ClueWeb set by adding in- formation about context words around relation words. We will also investigate other ways of col- lapsing different types of tags in the lexicalized tree representation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Our Open IE system structure.</figDesc><graphic url="image-3.png" coords="2,283.94,148.57,307.16,397.51" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: An unlexicalized tree and the corresponding lexicalized tree.</figDesc><graphic url="image-5.png" coords="3,99.26,43.98,307.16,397.51" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Croce et al.</head><label></label><figDesc>(2011) employ word vectors created by Singular Value Decomposition (Golub and Ka- han., 1965) from a word co-occurrence matrix. Plank and Moschitti (2013) use word vectors cre- ated by Brown clustering algorithm (Brown et al., 1992), which is another smoothed word represen- tation that represents words as binary vectors. Sri- vastava et al. (2013) use word embeddings of Col- lobert and Weston (2008), but their tree kernel does not incorporate POS tags or dependency la- bels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Comparison of complete Open IE sys-
tems. The asterisks denote results reported in pre-
vious work. 

and based on a novel by Sir Walter Scott, its high 
drama..." with the wrong dependency path Scot-

land 

conj and 

→ based 

prep by 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank the anonymous review-ers for their helpful suggestions. This work was </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Open information extraction from the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michele</forename><surname>Banko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Cafarella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Soderl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Broadhead</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="2670" to="2676" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Structure and semantics for expressive text kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Bloehdorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixteenth ACM Conference on Conference on Information and Knowledge Management, CIKM &apos;07</title>
		<meeting>the Sixteenth ACM Conference on Conference on Information and Knowledge Management, CIKM &apos;07<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="861" to="864" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Class-based n-gram models of natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">V</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">L</forename><surname>Desouza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><forename type="middle">J</forename><surname>Mercer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenifer</forename><forename type="middle">C</forename><surname>Della Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Linguist</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="467" to="479" />
			<date type="published" when="1992" />
			<publisher>December</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">New ranking algorithms for parsing and tagging: kernels over discrete structures, and the voted perceptron</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nigel</forename><surname>Duffy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL &apos;02</title>
		<meeting>the 40th Annual Meeting on Association for Computational Linguistics, ACL &apos;02<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="263" to="270" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A unified architecture for natural language processing: Deep neural networks with multitask learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning, ICML</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Structured lexical similarity via convolution kernels on dependency trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Croce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Basili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;11</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;11<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1034" to="1046" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Calculating the singular values and pseudo-inverse of a matrix</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Golub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Society for Industrial and Applied Mathematics: Series B</title>
		<imprint>
			<biblScope unit="page">205224</biblScope>
			<date type="published" when="1965" />
		</imprint>
	</monogr>
	<note>Numerical Analysis</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Open language learning for information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mausam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Schmitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Bart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="523" to="534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Effectiveness and efficiency of open relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filipe</forename><surname>Mesquita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Schmidek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denilson</forename><surname>Barbosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="447" to="457" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">User&apos;s guide to sigf: Significance testing by approximate randomisation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Padó</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Embedding semantic similarity in tree kernels for domain adaptation of relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Plank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-08" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1498" to="1507" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Relation extraction with matrix factorization and universal schemas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><forename type="middle">M</forename><surname>Marlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint Human Language Technology Conference/Annual Meeting of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL &apos;13)</title>
		<imprint>
			<date type="published" when="2013-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A walk-based semantically enriched tree kernel over distributed word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shashank</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Seattle, Washington, USA,</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1411" to="1416" />
		</imprint>
	</monogr>
	<note>October. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Word representations: a simple and general method for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Turian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL &apos;10</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics, ACL &apos;10<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="384" to="394" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Open information extraction using wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL &apos;10</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics, ACL &apos;10<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="118" to="127" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Open information extraction with tree kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mi-Young</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Quinn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Randy</forename><surname>Goebel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denilson</forename><surname>Barbosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Georgia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-06" />
			<biblScope unit="page" from="868" to="877" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
