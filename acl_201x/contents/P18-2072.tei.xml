<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:15+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Predicting accuracy on large datasets from smaller pilot data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 15-20, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
							<email>Mark.Johnson@MQ.edu.au</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Macquarie University</orgName>
								<orgName type="institution" key="instit2">Australian National University</orgName>
								<orgName type="institution" key="instit3">Macquarie University</orgName>
								<orgName type="institution" key="instit4">University of Edinburgh</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Anderson</surname></persName>
							<email>Peter.Anderson@ANU.edu.au</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Macquarie University</orgName>
								<orgName type="institution" key="instit2">Australian National University</orgName>
								<orgName type="institution" key="instit3">Macquarie University</orgName>
								<orgName type="institution" key="instit4">University of Edinburgh</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dras</surname></persName>
							<email>Mark.Dras@MQ.edu.au</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Macquarie University</orgName>
								<orgName type="institution" key="instit2">Australian National University</orgName>
								<orgName type="institution" key="instit3">Macquarie University</orgName>
								<orgName type="institution" key="instit4">University of Edinburgh</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
							<email>steedman@inf.ed.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Macquarie University</orgName>
								<orgName type="institution" key="instit2">Australian National University</orgName>
								<orgName type="institution" key="instit3">Macquarie University</orgName>
								<orgName type="institution" key="instit4">University of Edinburgh</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Predicting accuracy on large datasets from smaller pilot data</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="450" to="455"/>
							<date type="published">July 15-20, 2018</date>
						</imprint>
					</monogr>
					<note>450</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Because obtaining training data is often the most difficult part of an NLP or ML project, we develop methods for predicting how much data is required to achieve a desired test accuracy by extrapolating results from systems trained on a small pilot training dataset. We model how accuracy varies as a function of training size on subsets of the pilot data, and use that model to predict how much training data would be required to achieve the desired accuracy. We introduce a new performance ex-trapolation task to evaluate how well different extrapolations predict system accuracy on larger training sets. We show that details of hyperparameter optimisa-tion and the extrapolation models can have dramatic effects in a document classification task. We believe this is an important first step in developing methods for estimating the resources required to meet specific engineering performance targets.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>An engineering discipline should be able to predict the cost of a project before the project is started. Because training data is often the most expen- sive part of an NLP or ML project, it is impor- tant to estimate how much training data required for a system to achieve a target accuracy. Un- fortunately our field only offers fairly impracti- cal advice, e.g., that more data increases accu- racy ( <ref type="bibr" target="#b0">Banko and Brill, 2001</ref>); we currently have no practical methods for estimating how much data or what quality of data is required to achieve a target accuracy goal. Imagine if bridge construction was planned the way we build our systems! Our long-term goal is to develop practical meth- ods for designing systems that achieve target per- formance specifications, including identifying the amount of training data that the system will re- quire. This paper starts to address this goal by in- troducing an extrapolation methodology that pre- dicts a system's accuracy on a larger dataset from its performance on subsets of much smaller pilot data. These extrapolations allow us to estimate how much training data a system will require to achieve a target accuracy. We focus on a specific task (document classification) using a specific sys- tem (the fastText classifier of <ref type="bibr" target="#b13">Joulin et al. (2016)</ref>), and leave to future work to determine if our ap- proach and results generalise to other tasks and systems.</p><p>We introduce an accuracy extrapolation task that can be used to evaluate different extrapolation models. We describe three well-known extrapo- lation models and evaluate them on a document classification dataset. On our development data the biased power-law method with binomial item weighting performs best, so we propose it should be a baseline for future research. We demon- strate the importance of hyperparameter optimi- sation on each different-sized data subset (rather than just optimising on the largest data subset) and item weighting, and show that these can have a dramatic impact on extrapolation, especially from small pilot data sets. The data and code for all experiments in this paper, including the R code for the graphics, is available from http://web. science.mq.edu.au/ ˜ mjohnson.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>Power analysis <ref type="bibr" target="#b4">(Cohen, 1992</ref>) is widely-used sta- tistical technique (e.g., in biomedical trials) for predicting the number of measurements required in an experimental design; we aim to develop sim-ilar techniques for NLP and ML systems. There is a large body of research on the relationship be- tween training data size and system performance. <ref type="bibr">Geman et al. (1992)</ref> decompose the squared error of a model into a bias term (due to model errors) and a variance term (due to statistical noise). Bias does not vary with training data size n, but the er- ror due to variance should decrease as O( 1 / √ n) if the training observations are independent (Domin- gos, 2000a,b). The power-law models used in this paper have been investigated many times in prior literature ( <ref type="bibr" target="#b11">Haussler et al., 1996;</ref><ref type="bibr" target="#b14">Mukherjee et al., 2003;</ref><ref type="bibr" target="#b8">Figueroa et al., 2012;</ref><ref type="bibr" target="#b2">Beleites et al., 2013;</ref><ref type="bibr" target="#b10">Hajian-Tilaki, 2014;</ref><ref type="bibr" target="#b3">Cho et al., 2015)</ref>. <ref type="bibr" target="#b15">Sun et al. (2017)</ref>, <ref type="bibr" target="#b1">Barone et al. (2017)</ref> and the concurrent un- published work by <ref type="bibr" target="#b12">Hestness et al. (2017)</ref> point out that these power-law models describe modern ML and NLP systems quite well, including complex deep-learning systems, so we expect our results to generalise to these systems. This paper differs from prior work in that we explicitly focus on the task of extrapolating sys- tem performance from small pilot data. We in- troduce a new evaluation task to compare the ef- fectiveness of different models for this extrapola- tion, and demonstrate the importance of per-subset hyperparameter optimisation and item weighting, which prior work did not investigate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Models for extrapolating pilot data</head><p>We are given a system whose accuracy on a large dataset we wish to predict, but only a smaller pi- lot dataset is available. We train the system on different-sized subsets of the pilot dataset, and use the results of those training runs to estimate how the system's accuracy varies as a function of train- ing data size.</p><p>We focus on predicting the minimum error rate e(n) that the system can achieve on a dataset of size n after hyperparameter optimisation (where the error rate is 1−accuracy for a classifier) given a pilot dataset of size m n (in the task below, m = n /2 or m = n /10). We investigate three dif- ferent extrapolation models of e(n) in this paper:</p><formula xml:id="formula_0">• Power law: ˆ e(n) = bn c • Inverse square-root: ˆ e(n) = a + bn − 1 /2 • Biased power law: ˆ e(n) = a + bn c</formula><p>Herê e(n) is the estimate of e(n), and a, b and c are adjustable parameters that are estimated based on the system's performance on the pilot dataset. Figure 1: An extrapolation run from pilot data consisting of either 0.1 or 0.5 of the ag news corpus. The x-axis is the size of the subset of pilot data, while the y-axis is the classification error rate. The shapes/colors show the maxi- mum fraction of the corpus used in the pilot data, and whether hyperparameters were optimised only once on all of the pilot data (e.g., = 0.1 and = 0.5) or at each smaller subset of the pilot data (e.g., ≤ 0.1 and ≤ 0.5). The lines are least-squares fits of biased power-law models (ˆ e(n) = a + bn c ) to the corresponding pilot data. The red star shows minimum error rate when all the training data is used to train the classifier (this is the value we are trying to predict).</p><p>The inverse square-root curve is what one would expect if the error is distributed according to a Bias-Variance decomposition <ref type="bibr">(Geman et al., 1992</ref>) with a constant bias term a and a variance term that asymptotically follows the Central Limit The- orem. We fit these models using weighted least squares regression. Each data point or item in the regression is the result of a run of the system on a subset of the pilot dataset.</p><p>Assuming that the underlying system has ad- justable hyperparameters, the question arises: how should the hyperparameters be set? The com- putationally least demanding approach is to opti- mise the system's hyperparameters on the full pilot dataset, and use these hyperparameters for all the runs on subsets of the pilot dataset. An alternative, computationally more demanding approach is to optimise the system's hyperparameters separately on each of the subsets of the pilot dataset. <ref type="figure">Figure 1</ref> shows an example where optimising the hyperpa- rameters just on the full pilot dataset is clearly in-ferior to optimising the hyperparameters on each subset of the pilot dataset. We show below that the more demanding approach of optimising on each subset is superior, especially when extrapolating from small pilot datasets.</p><p>We also investigate how details of the regression fit affect the regression accuracyêaccuracyˆaccuracyê(n). We exper- imented with several link functions (we used the default Gaussian link here), but found that these had less impact than adjusting the item weights in the regression. Runs with smaller training sets pre- sumably have higher variance, and since our goal is to extrapolate to larger datasets, it is reasonable to place more weight on items corresponding to larger datasets. We investigated three item weight- ing functions in regression:</p><p>• constant weights (1), • linear weights (n), and • binomial weights ( n /e(1 − e)) Linear weights are motivated by the assumption that the item variance follows the Central Limit Theorem, while the binomial weights are moti- vated by the assumption that item variance follows a binomial distribution (see the Supplemental Ma- terials for further discussion). As <ref type="figure" target="#fig_1">Figure 2</ref> makes clear, linear weights and binomial weights gen- erally produce more accurate extrapolations than constant weights, so we use binomial weights in our evaluation in <ref type="table">Table 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">A performance extrapolation task</head><p>We used the fastText document classifier and the document classification corpora distributed with it; see <ref type="bibr" target="#b13">Joulin et al. (2016)</ref> for full details. Fast- Text's speed and evaluation scripts make it easy to do the experiments described below. We fit- ted our extrapolation models to the fastText docu- ment classifier results on the 8 corpora distributed with the fastText classifier. These corpora contain labelled documents for a document classification task, and come randomised and divided into train- ing and test sections. All our results are on these test sections.</p><p>The corpora were divided into development and evaluation corpora (each with train and test splits) as shown in table 1.</p><p>We use the amazon review polarity, sogou news, yahoo answers and yelp review full corpora as our test set (so these are only used in the final evaluation), while the ag news, dbpedia, amazon review full and yelp review polarity were used as development cor- pora. The development and evaluation sets contain document collections of roughly similar sizes and complexities, but no attempt was made to accu- rately "balance" the development and evaluation corpora.</p><p>We trained the fastText classifier on 13 differently-sized prefixes of each training set that are approximately logarithmically spaced over two orders of magnitude (i.e., varying from 1 ⁄100 to all of the training corpus). To explore the effect of hyperparameter tuning on extrapolation, for each prefix of each training set we trained a classifier on each of 1,079 different hyperparameter settings, varying the n-gram length, learning rate, dimen- sionality of the hidden units and the loss function (the fastText classifier crashed on 17 hyperparam- eter combinations; we did not investigate why). We re-ran the entire process 8 times on randomly- shuffled versions of each training corpus.</p><p>As expected, the minimum error configuration invariably requires the full training data. When extrapolating from subsets of a smaller pilot set (we explored pilot sets consisting of 0.1 and 0.5 of the full training data) there are two plausible ways of performing hyperparameter optimisation. Ide- ally, one would optimise the hyperparameters for each subset of the pilot data considered (we se- lected the best-performing hyperparameters using grid search). However, if one is not working with computationally efficient algorithms like fastText, one might be tempted to only optimise the hy- perparameters once on all the pilot data, and use the hyperparameters optimised on all the pilot data when calculating the error rate on subsets of that pilot data. As figure 2 and table 2 make clear, se- lecting the optimal hyperparameters for each sub- set of the pilot data generally produces better ex- trapolation results. <ref type="figure">Figure 1</ref> shows how different ways of choosing hyperparameters can affect ex- trapolation. As that figure shows, hyperparame- ters optimised on 50% of the training data perform very badly on 1% of the training data. As <ref type="figure" target="#fig_1">figure 2</ref> shows, this can lead simpler extrapolation models such as the power-law to dramatically underesti- mate the error on the full dataset. Interestingly, more complex extrapolation models, such as the extended power-law model, often do much better.</p><p>Based on the development corpora results pre- sented in <ref type="figure" target="#fig_1">Figures 1 and 2</ref>, we choose the biased power law model (ˆ e(n) = a + bn c ) with binomial   <ref type="table">Table 1</ref>: Summary statistics of the development corpora (above line) and evaluation corpora (be- low line).</p><p>item weights ( n /e(1 − e)) as the model to evaluate on the evaluation corpora.</p><p>We evaluate an extrapolation by calculating the root-mean-square (RMS) of the relative residualsê residualsˆresidualsê/e − 1, where e is the minimum error achieved by the classifier with any hyperparameter setting when trained on the full training set, andêandˆandê is the predicted error made by the extrapolation model  <ref type="table">Table 2</ref>: RMS relative residuals (ˆ e/e − 1) on the four evaluation corpora over all runs for the biased power law model (ˆ e(n) = a + bn c ) with binomial item weights ( n /e(1 − e)). Lower scores are better.</p><p>from the pilot dataset. 1 Unsurprisingly, <ref type="table">Table 2</ref> shows that extrapola- tion is more accurate from larger pilot datasets; increasing the size of the pilot dataset 5 times re-duces the RMS relative residuals by a factor of 10. It also clearly shows that it valuable to per- form hyperparameter optimisation on all subsets of the pilot dataset, not just on the whole pilot data. Interestingly, <ref type="table">Table 2</ref> shows that the RMS difference between the two approaches to hyper- parameter setting is greater when the pilot data is larger. This makes sense; the hyperparameters that are optimal on a large pilot dataset may be far from optimal on a very small subset (this is clearly visi- ble in <ref type="figure">Figure 1</ref>, where the items deviating most are those for the = 0.5 pilot data and hyperparameter choice).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions and Future Work</head><p>This paper introduced an extrapolation methodol- ogy for predicting accuracy on large dataset from a small pilot dataset, applied it to a document clas- sification system, and identified the biased power- law model with binomial weights as a good base- line extrapolation model. This only scratches the surface of performance extrapolation tasks. We hope that teams with greater computational re- sources will study the extrapolation task for com- putationally more-demanding systems, including popular deep learning models. The power-law models should be considered baselines for more sophisticated extrapolation models, which might exploit more information than just accuracy on subsets of the pilot data.</p><p>We hope this work will spur the development of better methods for estimating the resources needed to build an NLP or ML system to meet a specifica- tion, as we believe this is essential for any mature engineering field.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Residuals on 8 runs when extrapolating from pilot data consisting of 0.1 or 0.5 of each development training corpus. The y-axis shows the residual error (the difference between the predicted error and the minimum error when the classifier is trained on all the training data), and the x-axis indicates the weight function used in extrapolation. Colours indicate the model fitted, (i.e., power-law (ˆ e(n) = bn c ), inverse square-root (ˆ e(n) = a + bn − 1 /2 ), or biased power-law (ˆ e(n) = a + bn c ) models). Facets indicate the development corpus used, and whether hyperparameters were optimised only once on all of the pilot data (e.g., = 0.5 and = 0.1) or on each subset of the pilot data (e.g., ≤ 0.5 and ≤ 0.1).</figDesc></figure>

			<note place="foot">sets of the pilot data, and use that model to predict how much training data would be required to achieve the desired accuracy. We introduce a new performance extrapolation task to evaluate how well different extrapolations predict system accuracy on larger training sets. We show that details of hyperparameter optimisation and the extrapolation models can have dramatic effects in a document classification task. We believe this is an important first step in developing methods for estimating the resources required to meet specific engineering performance targets.</note>

			<note place="foot" n="1"> We use relative residuals because the residuals themselves vary greatly from corpus to corpus, and we use RMS to penalise large extrapolation errors. We admit that RMS relative residuals is probably not a close approximation to the extrapolation loss in real applications, and we hope future work will develop more realistic loss functions.</note>

			<note place="foot">Journal of computational biology 10(2):119-142.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank the anonymous review-ers for their insightful comments and sugges-tions. This research was supported by a Google award through the Natural Language Understand-ing Focused Program, and under the Australian Research Council's Discovery Projects funding scheme (project number DP160102156).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Mitigating the paucityof-data problem: Exploring the effect of training corpus size on classifier performance for natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Banko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Brill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technology Conference : Proceedings of HLT 2001 : First International Conference on Human Language Technology Research</title>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Regularization techniques for fine-tuning in neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Valerio Miceli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Barone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Germann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sennrich</surname></persName>
		</author>
		<idno>CoRR abs/1707.09920</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Sample size planning for classification models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudia</forename><surname>Beleites</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ute</forename><surname>Neugebauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Bocklitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Krafft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Popp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Analytica chimica acta</title>
		<imprint>
			<biblScope unit="volume">760</biblScope>
			<biblScope unit="page" from="25" to="33" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">How much data is needed to train a medical image deep learning system to achieve necessary high accuracy?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Choy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Do</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06348</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A power primer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological bulletin</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">155</biblScope>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A unified bias-variance decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro</forename><surname>Domingos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 17th International Conference on Machine Learning</title>
		<meeting>17th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="231" to="238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">A unified bias-variance decomposition for zero-one and squared loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro</forename><surname>Domingos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaai/</forename><surname>Iaai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="564" to="569" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Predicting sample size required for classification performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Rosa L Figueroa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sasikiran</forename><surname>Zeng-Treitler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long H</forename><surname>Kandula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ngo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC medical informatics and decision making</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">8</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">and René Doursat. 1992. Neural networks and the bias/variance dilemma</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stuart</forename><surname>Geman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elie</forename><surname>Bienenstock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Sample size estimation in diagnostic test studies of biomedical informatics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karimollah</forename><surname>Hajian-Tilaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of biomedical informatics</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="193" to="204" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Rigorous learning curve bounds from statistical mechanics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Haussler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Kearns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sebastian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naftali</forename><surname>Seung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tishby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Hestness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Newsha</forename><surname>Ardalani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Diamos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heewoo</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hassan</forename><surname>Kianinejad</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.00409</idno>
		<title level="m">Deep learning scaling is predictable, empirically</title>
		<editor>Md. Mostofa Ali Patwary, Yang Yang, and Yanqi Zhou</editor>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Bag of tricks for efficient text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.01759</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Estimating dataset size requirements for classifying DNA microarray data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sayan</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Tamayo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Rifkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Engle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Todd R Golub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mesirov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Revisiting unreasonable effectiveness of data in deep learning era</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.02968</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
