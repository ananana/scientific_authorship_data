<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:55+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Extracting token-level signals of syntactic processing from fMRI-with an application to PoS induction</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>August 7-12, 2016. 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><surname>Bingel</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Centre for Language Technology</orgName>
								<orgName type="institution">University of Copenhagen Njalsgade 140</orgName>
								<address>
									<postCode>2300</postCode>
									<settlement>Copenhagen S</settlement>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Barrett</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Centre for Language Technology</orgName>
								<orgName type="institution">University of Copenhagen Njalsgade 140</orgName>
								<address>
									<postCode>2300</postCode>
									<settlement>Copenhagen S</settlement>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Centre for Language Technology</orgName>
								<orgName type="institution">University of Copenhagen Njalsgade 140</orgName>
								<address>
									<postCode>2300</postCode>
									<settlement>Copenhagen S</settlement>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Extracting token-level signals of syntactic processing from fMRI-with an application to PoS induction</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="747" to="755"/>
							<date type="published">August 7-12, 2016. 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Neuro-imaging studies on reading different parts of speech (PoS) report somewhat mixed results, yet some of them indicate different activations with different PoS. This paper addresses the difficulty of using fMRI to discriminate between linguistic tokens in reading of running text because of low temporal resolution. We show that once we solve this problem, fMRI data contains a signal of PoS distinctions to the extent that it improves PoS induction with error reductions of more than 4%.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A few recent studies have tried to extract mor- phosyntactic signals from measurements of human sentence processing and used this information to improve NLP models. <ref type="bibr" target="#b8">Klerke et al. (2016)</ref>, for ex- ample, used eye-tracking recordings to regularize a sentence compression model. More related to this work, <ref type="bibr" target="#b0">Barrett et al. (2016)</ref> recently used eye- tracking recordings to induce PoS models. How- ever, a weakness of eye-tracking data is that while eye movement surely does reflect the temporal as- pect of cognitive processing, it is only a proxy of the latter and does not directly represent which processes take place in the brain.</p><p>A recent neuro-imaging study suggests that concrete nouns and verbs elicit different brain sig- natures in the frontocentral cortex, and that con- crete and abstract nouns elicit different brain acti- vation patterns <ref type="bibr" target="#b12">(Moseley and Pulvermüller, 2014</ref>). Also, for example, concrete verbs activate motor and premotor cortex more strongly than concrete nouns, and concrete nouns activate inferior frontal areas more strongly than concrete verbs. A decade earlier, <ref type="bibr" target="#b19">Tyler et al. (2004)</ref> showed that the left in- ferior frontal gyrus was more strongly activated in processing regularly inflected verbs compared to regularly inflected nouns.</p><p>Such studies suggest that different parts of our brains are activated when reading different parts of speech (PoS). This would in turn mean that neuro-images of readers carry information about the grammatical structure of what they read. In other words, neuro-imaging provides a partial, noisy annotation of the data with respect to mor- phosyntactic category.</p><p>Say neuro-imaging data of readers was readily available. Would it be of any use to, for exam- ple, engineers interested in PoS taggers for low- resource languages? This is far from obvious. In fact, it is well-known that neuro-imaging data from reading is noisy, in part because the reading signal is not always very distinguishable <ref type="bibr" target="#b17">(Tagamets et al., 2000</ref>), and also because the content of what we read may elicit certain activation in brain regions e.g. related to sensory processing ( <ref type="bibr" target="#b4">Boulenger et al., 2006;</ref><ref type="bibr" target="#b5">González et al., 2006</ref>).</p><p>Other researchers such as <ref type="bibr" target="#b3">Borowsky et al. (2013)</ref> have also questioned that there are differ- ences, claiming to show that the majority of acti- vation is shared between nouns and verbs -includ- ing in regions suggested by previous researchers as unique to either nouns or verbs. <ref type="bibr" target="#b2">Berlingeri et al. (2008)</ref> argue that only verbs could be associ- ated with unique regions, not nouns.</p><p>In this paper we nevertheless explore this ques- tion. The paper should be seen as a proof of con- cept that interesting linguistic signals can be ex- tracted from brain imaging data, and an attempt to show that learning NLP models from such data could be a way of pushing the boundaries of both fields.</p><p>Contributions (a) We present a novel technique for extracting syntactic processing signal at the to- ken level from neuro-imaging data that is charac- <ref type="figure">Figure 1</ref>: Neural activity by brain region and type of information processed, as measured and ren- dered by <ref type="bibr" target="#b21">Wehbe et al. (2014)</ref>. terized by low temporal resolution. (b) We demon- strate that the fMRI data improves performance of a type-constrained, second order hidden Markov model for PoS induction. Our model leads to an error reduction of more than 4% in tagging accu- racy despite very little training data, which to the best of our knowledge is the first positive result on weakly supervised part-of-speech induction from fMRI data in the literature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">fMRI</head><p>Functional Magnetic Resonance Imaging (fMRI) is a technology for spatial visualization of brain activity. It measures the changes in oxygenation of the blood in the brain, often by use of the blood oxygenation level-dependent contrast <ref type="bibr" target="#b13">(Ogawa et al., 1992)</ref>, which correlates with neural activity. While the spatial resolution of fMRI is very high, its temporal resolution is low compared to other brain imaging technologies like EEG, which usu- ally returns millisecond records of brain activity, but on the contrary have low spatial resolution. The temporal resolution of fMRI is usually be- tween 0.5Hz and 1Hz. fMRI data contains rep- resentations of neural activity of millimeter-sized cubes called voxels.</p><p>The high spatial resolution may enable us to de- tect fine differences in brain activation patterns, such as between processing nouns and verbs, but the low temporal resolution is a real challenge when the different tokens are processed serially and quickly after each other, as is the case in read- ing.</p><p>Another inherent challenge when working with fMRI data is the lag between the the reaction to a stimulus and the point when it becomes visi- ble through fMRI. This lag is called the hemo- dynamic response latency. While we know from brain imaging technologies with higher tempo- ral resolution that the neural response to a stim- uli happens within milliseconds, it only shows in fMRI data after a certain period of time, which further blurs the low temporal dimension of se- rial fMRI recordings. This latency has been stud- ied as long as fMRI technology itself. It depends on the blood vessels and varies between e.g. vox- els, brain regions, subjects, and tasks. A meta study of the hemodynamic response report laten- cies between 4 and 14 seconds in healthy adults, though latencies above 11 seconds are less typi- cally reported <ref type="bibr" target="#b6">(Handwerker et al., 2012)</ref>. Accord- ing to <ref type="bibr" target="#b6">Handwerker et al. (2012)</ref>, the precise re- sponse shape for a given stimulus and voxel region is hard to predict and remains a challenge when modeling temporal aspects of fMRI data. <ref type="figure">Figure 1</ref> visualizes the neural activations in different brain regions as a reaction to the type of information that is processed during reading. See Price (2012) for a thorough review of fMRI language studies. <ref type="bibr" target="#b21">Wehbe et al. (2014)</ref> presented a novel approach to fMRI studies of linguistic processing by study- ing a more naturalistic reading scenario, and mod- eling the entire process of reading and story un- derstanding. They used data from 8 subjects read- ing contextualized, running text: a chapter from a Harry Potter book. The central benefit of this approach is that it allows studies of complex text processing closer to a real-life reading experi- ence. <ref type="bibr" target="#b21">Wehbe et al. (2014)</ref> used this data to train a comprehensive, generative model that-given a text passage-could predict the fMRI-recorded activity during the reading of this passage. Us- ing the same data, our goal is to model a specific aspect of the story understanding process, i.e. the grammatical processing of words.</p><p>Figure 2: Computation of token-level fMRI vectors from the original fMRI data for the first token "Harry" while accounting for hemodynamic response latency using a Gaussian sliding window over a certain time window (indicated by red horizontal line). The final fMRI vector for "Harry" (red box) is computed as specified in Equation 1. In this example, the time stamp t for the token is 20s and the time window stretches from t + 1s to t + 2.5s.</p><p>arated from the tokens at the end of clauses and sentences. As the temporal alignment between to- kens and fMRI recordings (see below) forbids us to detach punctuation marks from their preceding tokens and introduce them as new tokens, we opt to remove all punctuation from the data. In the same process, we use simple heuristics to detect sentence boundaries. Finally, we correct errors in sentence splitting manually.</p><p>The chapter counts 4,898 tokens (excluding punctuation) and 1,411 types in 408 sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">fMRI data</head><p>The fMRI data from the same data set is available as high-dimensional vectors of flattened third- order tensors, in which each component represents the blood-oxygen-level dependent contrast for a certain voxel in the three-dimensional fMRI im- age. The resolution of the image is at 3×3×3 mm, such that the brain activity for the eight subjects is represented by approximately 31,400 voxels on average (standard deviation is 3,607) depending on the size of their brain.</p><p>This data is recorded every two seconds during the reading process, in which each token is con- secutively displayed for 0.5 seconds on a screen inside the fMRI scanner. Prior to reading, the sub- jects are asked to focus on a cross displayed at the center of the screen in a warm-up phase of 20 seconds. The chapter is divided into four blocks, separated by additional concentration phases of 20 seconds. Furthermore, paragraphs are separated by a 0.5-seconds display of a cross at the center of the screen.</p><p>As mentioned in the preceding section, punc- tuation marks were not displayed separately, but instead attached to the preceding token. This is arguably motivated through the attempt to create a reading scenario that is as natural as possible within the limitations of an fMRI recording. In similar fashion, contractions such as don't or he's were represented as one token, just as they appear in the original text.</p><p>In order to make the data feasible for our HMM approach (see Section 4), we apply Principal Com- ponent Analysis (PCA) to the high-dimensional fMRI vectors. We initially tune the number of principal components, which we describe in Sec- tion 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Computing token-level fMRI vectors</head><p>As outlined above, the time resolution of the fMRI recordings means that every block of four consecutive tokens is time-aligned with a single fMRI image. Naturally, this shared representa- tion of consecutive tokens complicates any lan- guage learning at the token level. Furthermore, the hemodynamic response latency inherent to fMRI recordings entails that the image recorded while reading a certain token most probably does not give any clues about the mental state elicited by this stimulus.</p><p>We therefore face the dual challenge of 1. inferring token-level information from supra- token recordings, and 2. identifying the lag after which the perceptual effects of reading a given token are visible. We address this problem through the follow- ing procedure that we illustrate in <ref type="figure">Figure 2</ref>. First, we copy the number of fMRI recordings fourfold, such that every fMRI vector is aligned to exactly one token (excluding the vectors that are recorded while no token was displayed). The representation for a given token is then computed as a weighted average over all fMRI vectors that lie within a cer- tain time window in relation to the token in ques- tion. Two consecutive tokens that originally lie within the same block of four thus receive differ- ent representations, provided that the window is large enough to transcend the border between two blocks.</p><p>The fMRI representation for the token at time stamp t is given by</p><formula xml:id="formula_0">v t = 1 |V | |V | k=1 V k · w k (1)</formula><p>where V is the series of fMRI vectors within the time window [t + s, t + e], and w is a Gaussian window of |V | points, with a standard deviation of 1. In factoring the Gaussian weight vector into the equation, we lend less weight to the fMRI record- ings at the outset and at the end of the time window specified through s (start) and e (end).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Model</head><p>We use a second-order hidden Markov model (HMM) with Wiktionary-derived type con- straints ( <ref type="bibr" target="#b9">Li et al., 2012</ref>) as our baseline for weakly supervised PoS induction. We use the original implementation by <ref type="bibr" target="#b9">Li et al. (2012)</ref>. The model is a type-constrained, second order version of the first-order featurized HMM previously introduced by <ref type="bibr" target="#b1">Berg-Kirkpatrick et al. (2010)</ref>. In each state z i , a PoS HMM generates a se- quence of words by consecutively generating word emissions x i and successor states z i+1 . The emis- sion probabilities and state transition probabilities are multinomial distributions over words and PoS. The joint probability of a word sequence and a tag sequence is</p><formula xml:id="formula_1">P θ (x, z) = P θ (z 1 ) i=1 P θ (x i |z i ) i=2 P θ (z i |z i−1 )</formula><p>(2) Following Berg- <ref type="bibr" target="#b1">Kirkpatrick et al. (2010)</ref>, the model calculates the probability distribution θ that parameterizes the emission probabilities as the output of a maximum entropy model, which en- ables unsupervised learning with a rich set of fea- tures. We thus let</p><formula xml:id="formula_2">θ x i ,z i = exp(w f (x i , z i )) x exp(w f (x , z i ))<label>(3)</label></formula><p>where w is a weight vector and f (x i , z i ) is a feature function that will, in our case, consider the fMRI vectors v t that we computed in section 3.2.1 and a number of basic features that we adopt from the original model ( <ref type="bibr" target="#b9">Li et al., 2012)</ref>. See Section 5 for details.</p><p>In addition, we use a second-order HMM, first introduced for PoS tagging in <ref type="bibr" target="#b18">Thede and Harper (1999)</ref>, in which transitional probabilities are also considered for second-degree subsequent states (cf. <ref type="figure" target="#fig_0">figure 3)</ref>. Here, the joint probability becomes</p><formula xml:id="formula_3">P θ (x, z) = P θ (z 1 )P θ (x 1 |z 1 )P θ (z 2 |z 1 ) i=2 P θ (x i |z i ) i=3 P θ (z i |z i−2 , z i−1 )<label>(4)</label></formula><p>In order to optimize the HMM (including the weight vector w), the model uses the EM algo- rithm as applied for feature-rich, locally normal- ized models introduced in <ref type="bibr" target="#b1">Berg-Kirkpatrick et al. (2010)</ref>, with the important modification that we use type constraints in the E-step, following <ref type="bibr" target="#b9">Li et al. (2012)</ref>. Specifically, for each state z i , the emission probability P (x i |z i ) is initialized ran- domly for every word type associated with z i in our tag dictionary (the type constraints). This weakly supervised setup allows us to predict the actual PoS tags instead of abstract states. The M- step is solved using L-BFGS ( <ref type="bibr" target="#b10">Liu and Nocedal, 1989</ref>  <ref type="figure">Figure 4</ref>: Accuracy on the development set for the different subjects when trained and tested on fMRI data from only this one subject. Dashed line is the development set baseline. Only in one out of eight cases does adding fMRI features lead to worse per- formance.</p><p>EM-HMM Parameters We use the same set- ting as <ref type="bibr" target="#b9">Li et al. (2012)</ref> for the number of EM iterations, fixing this parameter to 30 for all ex- periments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>Experimental setup From the neuro-imaging dataset described above, we use 41 sentences (720 tokens) as a development set and 41 sentences (529 tokens) as a test set, and the remaining 326 sentences (corresponding to 80%) for training our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Basic features</head><p>The basic features of all the mod- els (except when explicitly stated otherwise) are based on seven features that we adopt from <ref type="bibr" target="#b9">Li et al. (2012)</ref>, capturing word form, hyphenation, suf- fix patterns, capitalization and digits in the token.</p><p>Wiktionary Of the 1,411 word types in the cor- pus, we find that 1,381 (97.84%) are covered by the Wiktionary dump made available by <ref type="bibr" target="#b9">Li et al. (2012)</ref>, <ref type="bibr">1</ref> which we use as our type constraints when inducing our models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Part-of-speech annotation</head><p>Though Wehbe et al. (2014) also provide syntac- tic information, these are automatic parses that are not suitable for the evaluation of our model. The development and test data are therefore manually annotated for universal part-of-speech tags <ref type="bibr" target="#b15">(Petrov et al., 2011</ref>) by two linguistically trained annota- tors. The development set was annotated by both annotators, who reached an inter-annotator agree- ment of 0.926 in accuracy and 0.928 in weighted F 1 . For the final development and test data, dis- agreements were resolved by the annotators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Non-fMRI baselines</head><p>Our first baseline is a second-order HMM with type constraints from Wiktionary; this in all re- spects the model proposed by <ref type="bibr" target="#b11">Liu et al. (2012)</ref>, ex- cept trained on our small Harry Potter corpus. In a second baseline model, we also incorporate 300- dimensional GloVe word embeddings trained on Wikipedia and the Gigaword corpus ( <ref type="bibr" target="#b14">Pennington et al., 2014</ref>). We also test a version of the baseline without the basic features to get an estimate of the contribution of this aspect of the setup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Token-level fMRI</head><p>We run a series of experiments with token-level fMRI vectors that we obtain as described in Sec- tion 3.2.1. Initially, we train separate models for each of the eight individual subjects, whose per- formance on the development data are illustrated in <ref type="figure">Figure 4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Tuning hyperparameters</head><p>We tune the following hyperparameters on the token-level development set in the following or- der: the number of subjects to use, the number of principal components per subject, and the time window. For the earlier tuning processes we fix the later hyperparameters to values we consider rea- sonable, but once we have tuned a hyperparameter, we use the best value from this tuning process for later tuning steps. The initial values are: 10 prin- cipal components and a time window of [t + 0s, t + 6s].</p><p>Number of subjects To reduce the chance of overfitting, we use fMRI data from several read- ers in our model. The data from <ref type="bibr" target="#b21">Wehbe et al. (2014)</ref> would in theory allow us to average the three-dimensional image space for any number of readers, but this is not feasible if only for the dif- ference in brain sizes between the subjects. It is not feasible, either, to average over the eigenvec- tors that we obtain from PCA, as the eigenvectors between subjects do not share the same (or any concrete) feature space. We therefore concatenate   the eigenvectors that we obtain for different sub- jects, such that the feature vectors grow in length as the number of included subjects increases.</p><p>As <ref type="figure" target="#fig_3">Figure 5a</ref> shows, exploring an increasing number of subjects in the model does not seem to a have consistent effect on development set accu- racy. However, we expect an increased robustness from a model that incorporates a greater number of subjects. In all following experiments we there- fore use data from all eight readers, but we would also expect a model with fewer subjects to perform reasonably.</p><p>Principal components Fixing the number of subjects to eight, we then perform experiments to determine the number of principal components per subject to consider in our model, whose results are visualized in <ref type="figure" target="#fig_3">Figure 5b</ref>. We observe the first eigen- vectors carry a strong signal, while a great number of principal components tends to water down the signal and lead to worse performance. We choose to continue using 10 dimensions in all further ex- periments.</p><p>Time window for token vectors We next run experiments to determine the optimal time win- dow for the computation of the token vectors, us- ing different combinations of start and end times in relation to the token time stamps, but keeping the number of subjects and principal components constant at eight and ten, respectively. These ex- periments yield three different time windows with an equally good performance on the development set: [t − 4s, t + 10s], [t + 2s, t + 8s] and [t + 0s, t + 6s]. Note that due to the Gaussian weighting the centre of the interval gets more weight than the edges and that [t − 4s, t + 10s] and [t + 0s, t + 6s] have the same centre, t + 3. While [t + 2s, t + 8s] and [t + 0, t + 6] align better with psycholinguistic expectations, [t − 4s, t + 10s] makes our model less prone to overfitting. We therefore select the model averaging over the largest time window.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Type-level fMRI aggregates</head><p>Next, we aggregate token vectors to compute their type-level averages, in an effort to explore to which degree neural activity is dependent on the read word type rather than the concrete grammat- ical environment, and whether this can allow our model to draw conclusions about the grammatical class of a token. We compute the type-level aggre- gates as the component-wise arithmetic mean of the token vectors that we extract using the param- eter settings optimized above. Note, however, that out of the 4,898 tokens in the text, 823 (16.9%) occur only once. <ref type="table">Table 1</ref> reports the results that we obtain with our final hyper-parameter settings, which are as fol- lows:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head><p>Number of subjects 8 Principal components 10 Start of time window t − 4s End of time window t + 10s</p><p>The results show that our model leads to a consid-Accuracy Baseline ( <ref type="bibr" target="#b9">Li et al., 2012)</ref> 69.57   <ref type="table" target="#tab_2">Table 2</ref> we present the performance on the individual PoS classes under our best model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Analysis and Discussion</head><p>7.1 What's in the fMRI vectors?</p><p>t-SNE (Van der Maaten and Hinton, 2008) is a powerful supervised dimensionality reduction tool for visualizing high-dimensional data in two- dimensional space using Stochastic Neighbor Em- bedding. In <ref type="figure" target="#fig_4">Figure 6</ref>, we visualize pairs of PoS classes of the test data in a two-dimensional re- duction of the embedding space obtained when us- ing the settings of the best fMRI model. The fact that we can discriminate reasonably well between, e.g., nouns and pronouns, verbs and adpositions, as well as adpositions and adjectives on the basis of fMRI data is to the best of our knowledge a new finding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Discussion of the results</head><p>We showed that by careful model tuning and de- sign it is possible to extract a signal of grammati- cal processing in the brain from fMRI. The figures that we present in <ref type="table">Table 1</ref> reflect, to our knowl- edge, the first successful results in inferring gram- matical function at the token level from fMRI data.</p><p>Our best model, which we train on the ten princi- pal components from the fMRI recordings of eight readers, achieves an error reduction of over 4% de- spite a very small amount of training data. We find that our best model uses a very wide window of fMRI recordings to compute the representations for individual tokens, considering all recordings from 4 seconds before the token is displayed until 10 seconds after the token is displayed. Our best explanation for why the incorporation of preced- ing fMRI measurements is beneficial to our model, is that the grammatical function of a token may be predictable from a reader's cognitive state while reading preceding tokens. However, note that the measurements at the far ends of the time window only factor into the token vector to a small degree as a consequence of the Gaussian weighting. Our experiments further suggest that using token-level information instead of type-level features, such as word embeddings or type averages of fMRI vec- tors, is helpful for PoS induction that already is type-constrained. Recently, <ref type="bibr" target="#b7">Huth et al. (2016)</ref> found that semanti- cally related words are processed in the same area of the brain. Open questions for future work in- clude whether there is a bigger potential for using fMRI data for semantic rather than syntactic NLP tasks, and whether the signal we find mainly stems from semantic processing differences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>This paper presents the first experiments induc- ing part of speech from fMRI reading data. Cog- nitive psychologists have debated whether gram- matical differences lead to different brain activa- tion patterns. Somewhat surprisingly, we find that the fMRI data contains a strong signal, enabling a 4% error reduction over a state-of-the-art unsu- pervised PoS tagger. While our approach may not be readily applicable for developing NLP models today, we believe that the presented results may inspire NLP researchers to consider learning mod- els from combinations of linguistic resources and auxiliary, behavioral data that reflects human cog- nition.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Second-order HMM incorporating transitional probabilities from first and second-degree preceding states.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Learning curve for increasing number of subjects in the model. Fixed hyper-parameters: 10 principal components and a time window of [t + 0s, t + 6s].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Learning curve for increasing number of principal com- ponents per subject in the model. Number of principal components ∈ {1, 2, 3, 4, 5, 10, 15, 20, 50} Fixed hyper- parameters: 8 subjects, a time window of [t + 0s, t + 6s].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Exploring two individual hyper-parameters of the model on development set. Dashed lines indicate the development set baseline.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Selected t-SNE visualizations of fMRI vectors for all tokens of a class of the test set. The visualizations show that datapoints of a PoS class tend to cluster in the fMRI vector space.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Learning curve of tagging accuracy on the development set as a function of different number of EM iterations for baseline model and the full model for iteration numbers ∈ [1, 30]. Fixed hyper-parameters: 8 subjects, 10 principal components, and a time window of t − 4s to t + 10s</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Test data tagging performance by part-of-
speech class for the best fMRI model. The right-
most column displays the difference in F 1 com-
pared to the baseline model. 

erable error reduction over the baseline model as 
well as the embeddings-enriched baseline model. 
It also outperforms the model which uses type-
level averages over the fMRI recordings. Leaving 
out the basic features hurts performance, but even 
without the basic features the fMRI data can re-
duce error with 3.28% on the test set. In </table></figure>

			<note place="foot" n="3"> Data 3.1 Textual data We use the available fMRI recordings from Wehbe et al. (2014), where 8 adult, native English speakers read chapter 9 from Harry Potter and the Sorcerer&apos;s Stone in English. The textual data as provided in the data set does not explicitly mark sentence boundaries, neither is punctuation sep</note>

			<note place="foot" n="1"> https://code.google.com/archive/p/ wikily-supervised-pos-tagger/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This research was partially funded by the ERC Starting Grant LOWLANDS No. 313695, as well as by Trygfonden.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary material</head><p>Number of EM iterations As supplementary material, we present the EM learning curve in <ref type="figure">Fig-ure 7</ref>, which shows a steep learning curve at the beginning and relatively stable performance fig-ures after 15 iterations for the full model and 10 iterations for the baseline model.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Weakly supervised part-ofspeech induction using eye-tracking data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><surname>Bingel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Painless unsupervised learning with features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Bouchard-Cote</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Denero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="582" to="590" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Nouns and verbs in the brain: Grammatical class and task specific effects as revealed by fMRI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuela</forename><surname>Berlingeri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davide</forename><surname>Crepaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rossella</forename><surname>Roberti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Scialfa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudio</forename><surname>Luzzatti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eraldo</forename><surname>Paulesu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Neuropsychology</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="528" to="558" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Localisation of function for noun and verb reading: converging evidence for shared processing from fmri activation and reaction time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><surname>Borowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carrie</forename><surname>Esopenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Layla</forename><surname>Gould</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naila</forename><surname>Kuhlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gordon</forename><surname>Sarty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacqueline</forename><surname>Cummine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language and Cognitive Processes</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="789" to="809" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Cross-talk between language processes and overt motor behavior in the first 200 msec of processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Véronique</forename><surname>Boulenger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alice</forename><forename type="middle">C</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yves</forename><surname>Paulignan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viviane</forename><surname>Deprez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Jeannerod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nazir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of cognitive neuroscience</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1607" to="1615" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Reading cinnamon activates olfactory brain regions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julio</forename><surname>González</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alfonso</forename><surname>Barros-Loscertales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Friedemann</forename><surname>Pulvermüller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vanessa</forename><surname>Meseguer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ana</forename><surname>Sanjuán</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vicente</forename><surname>Belloch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Césarcésar´</forename><surname>César´avila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="906" to="912" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The continuing challenge of understanding and modeling hemodynamic variation in fmri</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Daniel A Handwerker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gonzalez-Castillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D&amp;apos;</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter A</forename><surname>Esposito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bandettini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1017" to="1023" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Natural speech reveals the semantic maps that tile human cerebral cortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wendy</forename><forename type="middle">A</forename><surname>Alexander G Huth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>De Heer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack L</forename><surname>Frédéric E Theunissen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gallant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">532</biblScope>
			<biblScope unit="issue">7600</biblScope>
			<biblScope unit="page" from="453" to="458" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Improving sentence compression by learning to predict gaze</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sigrid</forename><surname>Klerke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Wikily supervised part-of-speech tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">João</forename><surname>Graça</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Taskar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1389" to="1398" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">On the limited memory bfgs method for large scale optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jorge</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nocedal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical programming</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="503" to="528" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Joint inference of named entity recognition and normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongyang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyang</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="526" to="535" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Nouns, verbs, objects, actions, and abstractions: local fmri activity indexes semantics, not lexical categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Rachel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Friedemann</forename><surname>Moseley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pulvermüller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brain and language</title>
		<imprint>
			<biblScope unit="volume">132</biblScope>
			<biblScope unit="page" from="28" to="42" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Intrinsic signal changes accompanying sensory stimulation: functional brain mapping with magnetic resonance imaging. Proceedings of the National Academy of Sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seiji</forename><surname>Ogawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravi</forename><surname>Tank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jutta</forename><forename type="middle">M</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ellermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Seong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helmut</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kamil</forename><surname>Merkle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ugurbil</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="page" from="5951" to="5955" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">A universal part-of-speech tagset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<idno>CoRR abs/1104.2086</idno>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A review and synthesis of the first 20years of pet and fmri studies of heard speech, spoken language and reading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Price</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="816" to="847" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A parametric approach to orthographic processing in the brain: an fmri study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M-A</forename><surname>Tagamets</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jared</forename><forename type="middle">M</forename><surname>Novick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><forename type="middle">L</forename><surname>Chalmers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rhonda</forename><forename type="middle">B</forename><surname>Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Neuroscience</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="281" to="297" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
	<note>Journal of</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A second-order hidden markov model for part-of-speech tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Thede</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><surname>Harper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="175" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Neural processing of nouns and verbs: The role of inflectional morphology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorraine</forename><surname>Tyler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Bright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Fletcher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emmanuel</forename><surname>Stamatakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuropsychologia</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="512" to="523" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">85</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Simultaneously uncovering the patterns of brain regions involved in different story reading subprocesses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leila</forename><surname>Wehbe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><surname>Talukdar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alona</forename><surname>Fyshe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaditya</forename><surname>Ramdas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">112575</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
