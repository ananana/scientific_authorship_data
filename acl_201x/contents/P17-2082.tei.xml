<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:23+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Self-Crowdsourcing Training for Relation Extraction</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Azad</forename><surname>Abad</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moin</forename><surname>Nabi</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of Trento</orgName>
								<address>
									<postCode>38123</postCode>
									<settlement>Povo</settlement>
									<region>TN</region>
									<country>Italy Qatar</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Computing Research Institute</orgName>
								<orgName type="institution" key="instit2">HBKU</orgName>
								<address>
									<postCode>34110</postCode>
									<region>Doha</region>
									<country key="QA">Qatar</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Self-Crowdsourcing Training for Relation Extraction</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</title>
						<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="518" to="523"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-2082</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>One expensive step when defining crowd-sourcing tasks is to define the examples and control questions for instructing the crowd workers. In this paper, we introduce a self-training strategy for crowd-sourcing. The main idea is to use an automatic classifier, trained on weakly supervised data, to select examples associated with high confidence. These are used by our automatic agent to explain the task to crowd workers with a question answering approach. We compared our relation extraction system trained with data annotated (i) with distant supervision and (ii) by workers instructed with our approach. The analysis shows that our method relatively improves the relation extraction system by about 11% in F1.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recently, the Relation Extraction (RE) task has at- tracted the attention of many researchers due to its wide range of applications such as question an- swering, text summarization and bio-medical text mining. The aim of this task is to identify the type of relation between two entities in a given text. Most work on RE has mainly regarded the applica- tion of supervised methods, which require costly annotation, especially for large-scale datasets.</p><p>To overcome the annotation problem, <ref type="bibr" target="#b2">Craven et al. (1999)</ref> firstly proposed to collect automatic annotation through Distant Supervision (DS). In the DS setting, the training data for RE is of- ten automatically annotated utilizing an external Knowledge-Base (KB) such as Wikipedia or Free- base ( <ref type="bibr" target="#b4">Hoffmann et al., 2010;</ref><ref type="bibr" target="#b10">Riedel et al., 2010;</ref><ref type="bibr" target="#b7">Nguyen and Moschitti, 2011)</ref>. Although DS has shown to be promising for RE, it also produces many noisy labels in the automatic annotated data, which deteriorate the performance of the system trained on it. <ref type="bibr" target="#b3">Hoffmann et al. (2011)</ref> showed that by simply adding a small set of high quality labeled instances (i.e., human-annotated training data) to a larger set of instances annotated by DS, makes the over- all precision of the system significantly increases. Such level of quality of the labels usually can be obtained at low cost via crowdsourcing.</p><p>However, this finding does not hold for more complex tasks, where the annotators 1 need to have some expertise on them. For instance in RE, sev- eral works have shown that only a marginal im- provement can be achieved via crowdsourcing the data ( <ref type="bibr" target="#b0">Angeli et al., 2014;</ref><ref type="bibr" target="#b15">Zhang et al., 2012;</ref><ref type="bibr" target="#b9">Pershina et al., 2014</ref>). In such papers, the well- known Gold Standard quality control mechanism was used without annotators being trained.</p><p>Very recently, despite the previous results, <ref type="bibr" target="#b5">Liu et al. (2016)</ref> showed a larger improvement for the RE task when training crowd workers in an in- teractive tutorial procedure called "Gated Instruc- tion". This approach, however, requires a set of high-quality labeled data (i.e., the Gold Standard) for providing the instruction and feedback to the crowd workers. However, acquiring such data re- quires a considerable amount of human effort.</p><p>In this paper, we propose to alternatively use Silver Standard, i.e., a high-quality auto- matic annotated data, to train the crowd workers. Specifically, we introduce a self-training strategy for crowd-sourcing, where the workers are first trained with simpler examples (which we assume to be less noisy) and then gradually presented with more difficult ones. This is biologically inspired by the common human process of gradual learn- Moreover, we propose an iterative human- machine co-training framework for the task of RE. The main idea is (i) to automatically select a subset of less-noisy examples applying an automatic clas- sifier, (ii) training the annotators with such subset, and (iii) iterating this process after retraining the classifiers using the annotated data. That is, the educated crowd workers can provide higher qual- ity annotations, which can be used by the system in the next iteration to improve the quality of its classification. In other words, this cycle gradually improves both system and human annotators. This is in line with the studies in human-based compu- tational approaches, which showed that the crowd intelligence can effectively alleviate the drifting problem in auto-annotation systems ( <ref type="bibr" target="#b12">Sun et al., 2014;</ref><ref type="bibr" target="#b11">Russakovsky et al., 2015)</ref>.</p><p>Our study shows that even without using any gold standard, we can still train workers and their annotations can achieve results comparable with the more costly state-of-the-art methods. In sum- mary our contributions are the following:</p><p>• we introduce a self-training strategy for crowdsourcing;</p><p>• we propose an iterative human-machine co- training framework for the task of RE; and</p><p>• we test our approach on a standard bench- mark, obtaining a slightly lower perfor- mance compared to the state-of-the-art meth- ods based on Gold Standard data.</p><p>This study opens up avenues for exploiting in- expensive crowdsourcing solutions similar to ours to achieve performance gain in NLP tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background Work</head><p>There is a large body of work on DS for RE, but we only discuss the most related to our work and re- fer the reader to other recent work ( <ref type="bibr" target="#b14">Wu and Weld, 2007;</ref><ref type="bibr" target="#b6">Mintz et al., 2009;</ref><ref type="bibr" target="#b1">Bunescu, 2007;</ref><ref type="bibr" target="#b4">Hoffmann et al., 2010;</ref><ref type="bibr" target="#b10">Riedel et al., 2010;</ref><ref type="bibr" target="#b13">Surdeanu et al., 2012;</ref><ref type="bibr" target="#b7">Nguyen and Moschitti, 2011</ref>).</p><p>Many researchers have exploited the techniques of combining the DS data with small human anno- tated data collected via crowdsourcing, to improve the relation extractor accuracy ( <ref type="bibr" target="#b5">Liu et al., 2016;</ref><ref type="bibr" target="#b0">Angeli et al., 2014;</ref><ref type="bibr" target="#b15">Zhang et al., 2012</ref>). <ref type="bibr" target="#b0">Angeli et al. (2014)</ref> reported a minor improvement using active learning methods to select the best instances to be crowdsourced.</p><p>In the same direction, Zhang et al. (2012) stud- ied the effect of providing human feedback in crowdsourcing tasks and observed a minor im- provement in terms of F1. At high level, our work may be viewed as employing crowdsourcing for RE. In that spirit, we are similar to these works, but with the main difference of training crowd workers to obtain higher quality annotations.</p><p>The most related paper to our work is by <ref type="bibr" target="#b5">Liu et al. (2016)</ref>, who trained the crowd workers via "Gated Instruction". They also showed that col- lecting higher-quality annotations can be achieved through training the workers. The produced data also improved the performance of the RE systems trained on it. Our study confirms their finding. However, unlike them, we do not employ any Gold Standard (annotated by experts) for training the annotators and instead we propose a self-training strategy to select a set of high-quality automatic annotated data (namely, Silver Standard). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Self-Crowdsourcing Training</head><p>In this section we first explain, our proposed method for automatically identifying high-quality examples (i.e., Silver Standard) to train the crowd workers and collect annotations for the lower- quality examples. We then explain the scheme de- signed for crowd worker training and annotation collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Silver Standard Mining</head><p>The main idea of our approach to Self- Crowdsourcing training is to use the classifier's score for gradually training the crowd workers, such that the examples and labels associated with the highest prediction values (i.e., the most reli- able) will be used as Silver Standard.</p><p>More in detail, our approach is based on a noisy-label dataset, DS, whose labels are ex- tracted in a distant supervision fashion and CS a dataset to be labeled by the crowd. The first step is to divide CS into three parts: CS I , which is used to create the instructions for the crowd workers; CS Q , which is used for asking questions about sentence annotations; and CS A , which is used to collect the labels from annotators, after they have been trained.</p><p>To select CS I , we train a classifier C on DS, and then used it to label CS examples. In partic- ular, we used MultiR framework ( <ref type="bibr" target="#b3">Hoffmann et al., 2011</ref>) to train C, as it is a widely used framework for RE. Then, we sort CS in a descending order according to the classifier prediction scores and se- lect the first N i elements, obtaining CS I .</p><p>Next, we select the N q examples of CS \ CS I with the highest score to create the set CS Q . Note that the latter contains highly-reliable classifier an- notations but since the scores are lower than for CS I examples, we conjecture that they may be more difficult to be annotated by the crowd work- ers.</p><p>Finally, CS A is assigned with the remaining ex- amples, i.e., CS \ CS I \ CS Q . These have the lowest confidence and should therefore be anno- tated by crowd workers. N i and N q can be tuned on the task, we set both to 10% of the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Training Schema</head><p>We conducted crowd worker training and annota- tion collection using the well-known Crowdflower platform 2 . Given CS I and CS Q (see Section 3.1), we train the annotators in two steps:</p><p>(i) User Instruction: first, a definition of each relation type (borrowed from TAC-KBP official guideline) is shown to the annotators. This ini- tial training step provides the crowd workers with a big picture of the task. We then train the anno- tators showing them a set of examples from CS I (see <ref type="figure" target="#fig_0">Fig. 1</ref>). The latter are presented in the reverse order of difficulty. The ranked list of examples provided by our self-training strategy facilitates the gradual education of the annotators (Nosof- sky, 2011). This gives us the benefit of training the annotators with any level of expertise, which is a crucial property of crowdsourcing when there is no clue about the workers' expertise in advance.</p><p>(ii) Interactive QA: after the initial step, we challenge the workers in an interactive QA task with multiple-choice questions over the sentence annotation (see <ref type="figure" target="#fig_1">Fig. 2</ref>). To accomplish that, we designed an artificial agent that interacts with the crowd workers: it corrects their mistakes and makes them reasoning on why their answer was wrong. Note that, to have a better control of the worker training, we perform a selection of the sen- tences in CS Q to be used for questioning in a category-wise fashion. Meaning that, we select the subsets of examples for each class of relation sep- arately. We observed in practice that initially a lot of examples are classified as "No Relation". This is due to a difficulty of the task for the DS-based model. Thus, we used them in CS A .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Setup</head><p>In this section, we first introduce the details of the used corpora, then explain the feature extrac- tion and RE pipeline and finally present the exper- iments and discuss the results in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Corpora</head><p>We used TAC-KBP newswires, one of the most well-known corpora for RE task. As DS, we se- lected 700K sentences automatically annotated us- ing Freebase as an external KB. We used the ac- tive learning framework proposed by <ref type="bibr" target="#b0">Angeli et al. (2014)</ref> to select CS. This allowed us to select the best sentences to be annotated by humans (sam- pleJS). As a result, we obtained 4,388 sentences. We divided the CS sentences in CS I , CS Q and CS A , with 10%, 10% and 80% split, respectively. We requested at least 5 annotations for each sen- tence.</p><p>Similarly to <ref type="bibr" target="#b5">Liu et al. (2016)</ref>, we restricted our attention to 5 relations between person and loca- tion 3 . For both DS and CS, we used the publicly available data provided by <ref type="bibr" target="#b5">Liu et al. (2016)</ref>. Ulti- mately, 221 crowd workers participated to the task with minimum 2 and maximum 400 annotations per crowd worker. To evaluate our model, we ran- domly selected 200 sentences as test set and had</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Pr. Rec. F1 DS-only 0.43 0.52 0.47 Our Method 0.50 0.54 0.52 Gated Instruction 0.53 0.57 0.55 <ref type="table">Table 1</ref>: Evaluation of the impact of the CS A label quality in the RE task.</p><p>a domain expert to manually tag them using the TAC-KBP annotation guidelines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Relation Extraction Pipeline</head><p>We used the relation extractor, MultiR ( <ref type="bibr" target="#b4">Hoffmann et al., 2010</ref>) along with lexical and syntactic fea- tures proposed by <ref type="bibr" target="#b6">Mintz et al. (2009)</ref> such as: (i) Part of Speech (POS); (ii) windows of k words around the matched entities; (iii) the sequences of words between them; and (iv) finally, dependency structure patterns between entity pairs. These yield low-Recall as they appear in conjunctive forms but at the same time they produce a high Precision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Experimental Results</head><p>In the first set of experiments, we verified the qual- ity of our Silver Standard set used in our self- training methods. For this purpose, we trained MultiR on CS I , CS Q and CS A and evaluate them on our test set. <ref type="figure" target="#fig_2">Figure 3</ref> illustrates the results in terms of Precision, Recall and F1 for each parti- tion separately. They suggest that, the extractors trained on CS I and CS Q are significantly better than the extractor trained on the lower part of CS, i.e., CS A , even if the latter is much larger than the other two (80% vs. 10%).</p><p>In the next set of experiments, we evaluated the impact of adding a small set of crowdsourced data to a large set of instances annotated by Distant Su- pervision. We conducted the RE experiments in this setting, as this allowed us to directly compare with <ref type="bibr" target="#b5">Liu et al. (2016)</ref>. Thus, we used CS A anno- tated by our proposed method along with the noisy annotated DS to train the extractor.</p><p>We compared our method with (i) the DS-only baseline and (ii) the state of the art, Gated Instruc- tion (GI) strategy ( <ref type="bibr" target="#b5">Liu et al., 2016)</ref>. We empha- size that the same set of examples (both DS and CS) are used in this experiment and just replaced the GI annotations with the annotations collected using our proposed framework. Models DS-only Our Model GI Accuracy 56% 82% 91% <ref type="table">Table 2</ref>: Annotation Accuracy of crowd workers</p><p>The results are shown in <ref type="table">Table 1</ref>. Our method improves the DS-only baseline by 7%, 5% and 2% (absolute) in Precision, Recall and F1, re- spectively. This improvement clearly confirms the benefit of our fully automatic approach to crowd- sourcing in RE task.</p><p>Additionally, our model is just 3% lower than the GI method in terms of F1. In both our method and GI, the crowd workers are trained before en- rolling in the main task. However, GI trains an- notators using Gold Standard data, which involves a higher level of supervision with respect to our method. Thus our self-training method is poten- tially effective and an inexpensive alternative to GI.</p><p>We also analyzed the accuracy of the crowd workers in terms of the quality of their annota- tions. For this purpose, we randomly selected 100 sentences from CS A and then had them manually annotated by an expert. We compared the accuracy of the annotations collected with our proposed ap- proach with those provided by DS-only baseline and the GI method. <ref type="table">Table 2</ref> shows the results: the annotations performed by workers trained with our method are just slightly less accurate than the annotations produced by annotators trained with GI. This outcome is inline with the positive impact of our good quality annotation on the RE perfor- mance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we have proposed a self-training strategy for crowdsourcing as an effective alterna- tive to train annotators with Gold Standard. Our experimental results show that the annotations of workers trained with our method are accurate and produce a good performance when used in learn- ing algorithms for RE. Our study suggests that automatically training annotators can replace the popular consensus-based filtering scheme. Our method achieves this goal through an inexpensive training procedure.</p><p>In the future, it would be interesting to study if our method generalizes to other difficult or even simpler tasks. In particular, our approach opens up many research directions on how to best train workers or best select data for them, similarly to what active learning methods have been doing for training machines.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: User Interface of crowd worker training: instruction phase</figDesc><graphic url="image-1.png" coords="2,72.00,62.81,453.56,131.34" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: User Interface of crowd worker training: interactive QA phase</figDesc><graphic url="image-2.png" coords="3,84.81,62.81,425.20,140.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Accuracy of different CS partitions</figDesc></figure>

			<note place="foot" n="1"> From now, the both entities annotators and crowd workers refer to the same concept.</note>

			<note place="foot" n="2"> www.crowdflower.com</note>

			<note place="foot" n="3"> Nationality, Place-of-birth, Place-of-resident, Place-ofdeath, Traveled-to</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>This work has been partially supported by the EC project CogNet, 671625 (H2020-ICT-2014-2, Re-search and Innovation action). Many thanks to the anonymous reviewers for their valuable sug-gestions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Combining distant and partial supervision for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julie</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><forename type="middle">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1556" to="1567" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning to extract relations from the web using minimal supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Razvan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bunescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL07)</title>
		<meeting>the 45th Annual Meeting of the Association for Computational Linguistics (ACL07)</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Constructing biological knowledge bases by extracting information from text sources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Craven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Kumlien</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=645634.663209" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh International Conference on Intelligent Systems for Molecular Biology</title>
		<meeting>the Seventh International Conference on Intelligent Systems for Molecular Biology</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="77" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Knowledge-based weak supervision for information extraction of overlapping relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Congle</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning 5000 relational extractors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Congle</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Stroudsburg, PA, USA, ACL &apos;10</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="286" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Effective crowd annotation for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angli</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan Bragg Xiao Ling Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics. NAACL-HLT</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction without labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Mintz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bills</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rion</forename><surname>Snow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">End-to-end relation extraction using distant supervision from external semantic repositories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Truc-Vien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: Short Papers</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: Short Papers<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="277" to="282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">The generalized context model: An exemplar model of classification. Formal approaches in categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Robert M Nosofsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="18" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Infusion of labeled data into distant supervision for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Pershina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonan</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference of the Association for Computational Linguistics (ACL 2014)</title>
		<meeting>the 2014 Conference of the Association for Computational Linguistics (ACL 2014)<address><addrLine>Baltimore, US</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Modeling relations and their mentions without labeled text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 European Conference on Machine Learning and Knowledge Discovery in Databases: Part III</title>
		<meeting>the 2010 European Conference on Machine Learning and Knowledge Discovery in Databases: Part III<address><addrLine>Berlin, Heidelberg, ECML PKDD&apos;10</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="148" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Best of both worlds: Human-machine collaboration for object annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Chimera: Large-scale classification using machine learning, rules, and crowdsourcing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Narasimhan</forename><surname>Rampalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anhai</forename><surname>Doan</surname></persName>
		</author>
		<idno type="doi">10.14778/2733004.2733024</idno>
		<ptr target="https://doi.org/10.14778/2733004.2733024" />
	</analytic>
	<monogr>
		<title level="m">Proc. VLDB Endow</title>
		<meeting>VLDB Endow</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1529" to="1540" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Multi-instance multi-label learning for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julie</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning. Association for Computational Linguistics</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning. Association for Computational Linguistics<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="455" to="465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Autonomously semantifying wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
		<idno type="doi">10.1145/1321440.1321449</idno>
		<ptr target="https://doi.org/10.1145/1321440.1321449" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixteenth ACM Conference on Conference on Information and Knowledge Management</title>
		<meeting>the Sixteenth ACM Conference on Conference on Information and Knowledge Management<address><addrLine>New York, NY, USA, CIKM &apos;07</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="41" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Big data versus the crowd: Looking for relationships in all the right places</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ce</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Ré</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jude</forename><surname>Shavlik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="825" to="834" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
