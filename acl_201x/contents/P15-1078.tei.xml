<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:05+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Pairwise Neural Machine Translation Evaluation</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Guzmán</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">ALT Research Group</orgName>
								<orgName type="institution">Qatar Computing Research Institute -HBKU</orgName>
								<address>
									<country>Qatar Foundation</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shafiq</forename><forename type="middle">Joty</forename><surname>Lluís</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">ALT Research Group</orgName>
								<orgName type="institution">Qatar Computing Research Institute -HBKU</orgName>
								<address>
									<country>Qatar Foundation</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">`</forename><surname>Arquez</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">ALT Research Group</orgName>
								<orgName type="institution">Qatar Computing Research Institute -HBKU</orgName>
								<address>
									<country>Qatar Foundation</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">ALT Research Group</orgName>
								<orgName type="institution">Qatar Computing Research Institute -HBKU</orgName>
								<address>
									<country>Qatar Foundation</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Pairwise Neural Machine Translation Evaluation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="805" to="814"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present a novel framework for machine translation evaluation using neural networks in a pairwise setting, where the goal is to select the better translation from a pair of hypotheses, given the reference translation. In this framework, lexical, syntactic and semantic information from the reference and the two hypotheses is compacted into relatively small distributed vector representations, and fed into a multi-layer neural network that models the interaction between each of the hypotheses and the reference, as well as between the two hypotheses. These compact representations are in turn based on word and sentence embeddings, which are learned using neural networks. The framework is flexible, allows for efficient learning and classification, and yields correlation with humans that rivals the state of the art.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Automatic machine translation (MT) evaluation is a necessary step when developing or comparing MT systems. Reference-based MT evaluation, i.e., comparing the system output to one or more hu- man reference translations, is the most common approach. Existing MT evaluation measures typ- ically output an absolute quality score by com- puting the similarity between the machine and the human translations. In the simplest case, the similarity is computed by counting word n-gram matches between the translation and the reference. This is the case of BLEU ( <ref type="bibr" target="#b31">Papineni et al., 2002</ref>), which has been the standard for MT evaluation for years. Nonetheless, more recent evaluation mea- sures take into account various aspects of linguis- tic similarity, and achieve better correlation with human judgments.</p><p>Having absolute quality scores at the sentence level allows to rank alternative translations for a given source sentence. This is useful, for instance, for statistical machine translation (SMT) parame- ter tuning, for system comparison, and for assess- ing the progress during MT system development. The quality of automatic MT evaluation metrics is usually assessed by computing their correlation with human judgments. To that end, quality rank- ings of alternative translations have been created by human judges. It is known that assigning an absolute score to a translation is a difficult task for humans. Hence, ranking-based evaluations, where judges are asked to rank the output of 2 to 5 systems, have been used in recent years, which has yielded much higher inter-annotator agree- ment <ref type="bibr" target="#b6">(Callison-Burch et al., 2007)</ref>.</p><p>These human quality judgments can be used to train automatic metrics. This supervised learning can be oriented to predict absolute scores, e.g., us- ing regression <ref type="bibr" target="#b0">(Albrecht and Hwa, 2008)</ref>, or rank- ings <ref type="bibr" target="#b16">(Duh, 2008;</ref><ref type="bibr" target="#b37">Song and Cohn, 2011)</ref>. A partic- ular case of the latter is used to learn in a pair- wise setting, i.e., given a reference and two al- ternative translations (or hypotheses), the task is to decide which one is better. This setting em- ulates closely how human judges perform evalu- ation assessments in reality, and can be used to produce rankings for an arbitrarily large number of hypotheses. In this pairwise setting, the chal- lenge is to learn, from a pair of hypotheses, which are the features that help to discriminate the better from the worse translation. Although the pairwise setting does not produce absolute quality scores (i.e., it is not an evaluation metric applicable to a single translation), it is useful and arguably suf- ficient for most evaluation and MT development scenarios. <ref type="bibr">1</ref> Recently, <ref type="bibr" target="#b18">Guzmán et al. (2014a)</ref> presented a learning framework for this pairwise setting, based on preference kernels and support vector ma- chines (SVM). They obtained promising results using syntactic and discourse-based structures. However, using convolution kernels over complex structures comes at a high computational cost both at training and at testing time because the use of kernels requires that the SVM operate in the much slower dual space. Thus, some simplification is needed to make it practical. While there are some solutions in the kernel-based learning framework to alleviate the computational burden, in this pa- per we explore an entirely different direction.</p><p>We present a novel neural-based architecture for learning in the pairwise setting for MT evalua- tion. Lexical, syntactic and semantic information from the reference and the two hypotheses is com- pacted into relatively small distributed vector rep- resentations and fed into the input layer, together with a set of individual real-valued features com- ing from simple pre-existing MT evaluation met- rics. A hidden layer, motivated by our intuitions on the pairwise ranking problem, is used to cap- ture interactions between the relevant input com- ponents. Finally, we present a task-oriented cost function, specifically tailored for this problem.</p><p>Our evaluation results on the WMT12 metrics task benchmark datasets <ref type="bibr" target="#b8">(Callison-Burch et al., 2012)</ref> show very high correlation with human judgments. These results clearly surpass <ref type="bibr" target="#b18">(Guzmán et al., 2014a</ref>) and are comparable to the best pre- viously reported results for this dataset, achieved by <ref type="bibr">DiscoTK (Joty et al., 2014</ref>), which is a much heavier combination-based metric.</p><p>Another advantage of the proposed architecture is efficiency. Due to the vector-based compres- sion of the linguistic structure and the relatively reduced size of the network, testing is fast, which would greatly facilitate the practical use of this ap- proach in real MT evaluation and development. Finally, we empirically show that syntactically- and semantically-oriented embeddings can be in- corporated to produce sizeable and cumulative gains in performance over a strong combination of pre-existing MT evaluation measures (BLEU, NIST, METEOR, and TER). This is promising ev- idence towards our longer-term goal of defining a general platform for integrating varied linguistic information and for producing more informed MT evaluation measures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Contemporary MT evaluation measures have evolved beyond simple lexical matching, and now take into account various aspects of lin- guistic structures, including synonymy and para- phrasing ( <ref type="bibr" target="#b22">Lavie and Denkowski, 2009)</ref>, syn- tax ( <ref type="bibr" target="#b17">Giménez and M` arquez, 2007;</ref><ref type="bibr" target="#b33">Popovi´cPopovi´c and Ney, 2007;</ref><ref type="bibr" target="#b23">Liu and Gildea, 2005</ref>), seman- tics ( <ref type="bibr" target="#b17">Giménez and M` arquez, 2007;</ref><ref type="bibr" target="#b24">Lo et al., 2012)</ref>, and even discourse ( <ref type="bibr" target="#b10">Comelles et al., 2010;</ref><ref type="bibr" target="#b39">Wong and Kit, 2012;</ref><ref type="bibr" target="#b19">Guzmán et al., 2014b;</ref><ref type="bibr" target="#b20">Joty et al., 2014</ref>). The combination of several of these aspects has led to improved results in metric evaluation campaigns, such as the WMT metrics task ( .</p><p>In this paper, we present a general framework for learning to rank translations in the pairwise setting, using information from several linguistic representations of the translations and references. This work has connections with the ranking-based approaches for learning to reproduce human judg- ments of MT quality. In particular, our setting is similar to that of Duh (2008), but differs from it both in terms of the feature representation and of the learning framework. For instance, we integrate several layers of linguistic information, while <ref type="bibr" target="#b16">Duh (2008)</ref> only used lexical and POS matches as fea- tures. Secondly, we use information about both the reference and the two alternative translations simultaneously in a neural-based learning frame- work capable of modeling complex interactions between the features.</p><p>Another related work is that of <ref type="bibr" target="#b21">Kulesza and Shieber (2004)</ref>, in which lexical and syntactic fea- tures, together with other metrics, e.g., BLEU and NIST, are used in an SVM classifier to discrimi- nate good from bad translations. However, their setting is not pairwise comparison, but a classifi- cation task to distinguish human-from machine- produced translations. Moreover, in their work, using syntactic features decreased the correla- tion with human judgments dramatically (although classification accuracy improved), while in our case the effect is positive.</p><p>In our previous work <ref type="bibr" target="#b18">(Guzmán et al., 2014a</ref>), we introduced a learning framework for the pair- wise setting, based on preference kernels and SVMs. We used lexical, POS, syntactic and discourse-based information in the form of tree- like structures to learn to differentiate better from worse translations.</p><p>However, in that work we used convolution ker- nels, which is computationally expensive and does not scale well to large datasets and complex struc- tures such as graphs and enriched trees. This in- efficiency arises both at training and testing time. Thus, here we use neural embeddings and multi- layer neural networks, which yields an efficient learning framework that works significantly better on the same datasets (although we are not using exactly the same information for learning).</p><p>To the best of our knowledge, the application of structured neural embeddings and a neural net- work learning architecture for MT evaluation is completely novel. This is despite the growing in- terest in recent years for deep neural nets (NNs) and word embeddings with application to a myr- iad of NLP problems. For example, in SMT we have observed an increased use of neural nets for language modeling ( <ref type="bibr" target="#b3">Bengio et al., 2003;</ref><ref type="bibr" target="#b27">Mikolov et al., 2010</ref>) as well as for improving the transla- tion model <ref type="bibr" target="#b13">(Devlin et al., 2014;</ref><ref type="bibr" target="#b38">Sutskever et al., 2014)</ref>.</p><p>Deep learning has spread beyond language modeling. For example, recursive NNs have been used for syntactic parsing <ref type="bibr" target="#b35">(Socher et al., 2013a</ref>) and sentiment analysis <ref type="bibr" target="#b36">(Socher et al., 2013b</ref>). The increased use of NNs by the NLP community is in part due to (i) the emergence of tools such as word2vec ( <ref type="bibr" target="#b28">Mikolov et al., 2013a</ref>) and GloVe <ref type="bibr" target="#b32">(Pennington et al., 2014</ref>), which have enabled NLP re- searchers to learn word embeddings, and (ii) uni- fied learning frameworks, e.g., <ref type="bibr" target="#b9">(Collobert et al., 2011</ref>), which cover a variety of NLP tasks such as part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. While in this work we make use of widely avail- able pre-computed structured embeddings, the novelty of our work goes beyond the type of infor- mation considered as input, and resides on the way it is integrated to a neural network architecture that is inspired by our intuitions about MT evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Neural Ranking Model</head><p>Our motivation for using neural networks for MT evaluation is twofold. First, to take advantage of their ability to model complex non-linear relation- ships efficiently. Second, to have a framework that allows for easy incorporation of rich syntac- tic and semantic representations captured by word embeddings, which are in turn learned using deep learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Learning Task</head><p>Given two translation hypotheses t 1 and t 2 (and a reference translation r), we want to tell which of the two is better. <ref type="bibr">2</ref> Thus, we have a binary classifi- cation task, which is modeled by the class variable y, defined as follows: y = 1 if t 1 is better than t 2 given r 0 if t 1 is worse than t 2 given r (1)</p><p>We model this task using a feed-forward neural network (NN) of the form:</p><formula xml:id="formula_0">p(y|t 1 , t 2 , r) = Ber(y|f (t 1 , t 2 , r))<label>(2)</label></formula><p>which is a Bernoulli distribution of y with param- eter σ = f (t 1 , t 2 , r), defined as follows:</p><formula xml:id="formula_1">f (t 1 , t 2 , r) = sig(w T v φ(t 1 , t 2 , r) + b v ) (3)</formula><p>where sig is the sigmoid function, φ(x) defines the transformations of the input x through the hidden layer, w v are the weights from the hidden layer to the output layer, and b v is a bias term.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Network Architecture</head><p>In order to decide which hypothesis is better given the tuple (t 1 , t 2 , r) as input, we first map the hy- potheses and the reference to a fixed-length vec- tor [x t 1 , x t 2 , x r ], using syntactic and semantic em- beddings. Then, we feed this vector as input to our neural network, whose architecture is shown in <ref type="figure" target="#fig_0">Figure 1</ref>. In our architecture, we model three types of in- teractions, using different groups of nodes in the hidden layer. We have two evaluation groups h 1r and h 2r that model how similar each hypothesis t i is to the reference r.</p><p>The vector representations of the hypothesis (i.e., x t1 or x t2 ) together with the reference (i.e., x r ) constitute the input to the hidden nodes in these two groups. The third group of hidden nodes h 12 , which we call similarity group, mod- els how close t 1 and t 2 are. This might be useful as highly similar hypotheses are likely to be com- parable in quality, irrespective of whether they are good or bad in absolute terms.</p><p>The input to each of these groups is repre- sented by concatenating the vector representations of the two components participating in the inter- action, i.e.,</p><formula xml:id="formula_2">x 1r = [x t 1 , x r ], x 2r = [x t 2 , x r ], x 12 = [x t 1 , x t 2 ]</formula><p>. In summary, the transformation φ(t 1 , t 2 , r) = [h 12 , h 1r , h 2r ] in our NN architec- ture can be written as follows:</p><formula xml:id="formula_3">h 1r = g(W 1r x 1r + b 1r ) h 2r = g(W 2r x 2r + b 2r ) h 12 = g(W 12 x 12 + b 12 )</formula><p>where g(.) is a non-linear activation function (ap- plied component-wise), W ∈ R H×N are the asso- ciated weights between the input layer and the hid- den layer, and b are the corresponding bias terms.</p><p>In our experiments, we used tanh as an activation function, rather than sig, to be consistent with how parts of our input vectors were generated. <ref type="bibr">3</ref> In addition, our model allows to incorporate ex- ternal sources of information by enabling skip arcs that go directly from the input to the output, skip- ping the hidden layer. In our setting, these arcs represent pairwise similarity features between the translation hypotheses and the reference (e.g., the BLEU scores of the translations). We denote these pairwise external feature sets as ψ 1r = ψ(t 1 , r) and ψ 2r = ψ(t 2 , r). When we include the external features in our architecture, the activation at the output, i.e., eq. (3), can be rewritten as follows:</p><formula xml:id="formula_4">f (t 1 , t 2 , r) = sig(w T v [φ(t 1 , t 2 , r), ψ 1r , ψ 2r ] + b v ) 3</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>.3 Network Training</head><p>The negative log likelihood of the train- ing data for the model parameters</p><formula xml:id="formula_5">θ = (W 12 , W 1r , W 2r , w v , b 12 , b 1r , b 2r , b v )</formula><p>can be written as follows:</p><formula xml:id="formula_6">J θ = − n y n logˆylogˆ logˆy nθ + (1 − y n ) log (1 − ˆ y nθ )<label>(4)</label></formula><p>In the above formula, ˆ y nθ = f n (t 1 , t 2 , r) is the activation at the output layer for the n-th data instance. It is also common to use a reg- ularized cost function by adding a weight decay penalty (e.g., L 2 or L 1 regularization) and to per- form maximum aposteriori (MAP) estimation of the parameters. We trained our network with stochastic gradient descent (SGD), mini-batches and adagrad updates <ref type="bibr" target="#b15">(Duchi et al., 2011</ref>), using Theano ( <ref type="bibr" target="#b4">Bergstra et al., 2010</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Setup</head><p>In this section, we describe the different aspects of our general experimental setup (we will discuss some extensions thereof in Section 6), starting with a description of the input representations we use to capture the syntactic and semantic charac- teristics of the two hypothesis translations and the corresponding reference, as well as the datasets used to evaluate the performance of our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Word Embedding Vectors</head><p>Word embeddings play a crucial role in our model, since they allow us to model complex relations between the translations and the reference using syntactic and semantic vector representations.</p><p>Syntactic vectors. We generate a syntactic vector for each sentence using the Stanford neural parser <ref type="bibr" target="#b35">(Socher et al., 2013a</ref>), which generates a 25- dimensional vector as a by-product of syntactic parsing using a recursive NN. Below we will refer to these vectors as SYNTAX25.</p><p>Semantic vectors. We compose a semantic vector for a given sentence using the average of the em- bedding vectors for the words it contains <ref type="bibr" target="#b30">(Mitchell and Lapata, 2010)</ref>. We use pre-trained, fixed- length word embedding vectors produced by (i) GloVe ( <ref type="bibr" target="#b32">Pennington et al., 2014</ref>), (ii) COM- POSES ( <ref type="bibr" target="#b1">Baroni et al., 2014</ref>), and (iii) word2vec <ref type="bibr" target="#b29">(Mikolov et al., 2013b</ref>).</p><p>Our primary representation is based on 50- dimensional GloVe vectors, trained on Wikipedia 2014+Gigaword 5 (6B tokens), to which below we will refer as WIKI-GW25.</p><p>Furthermore, we experiment with WIKI- GW300, the 300-dimensional GloVe vectors trained on the same data, as well as with the CC- 300-42B and CC-300-840B, 300-dimensional GloVe vectors trained on 42B and on 840B tokens from Common Crawl.</p><p>We also experiment with the pre-trained, 300- dimensional word2vec embedding vectors, or WORD2VEC300, trained on 100B words from Google News. Finally, we use COMPOSES400, the 400-dimensional COMPOSES vectors trained on 2.8 billion tokens from ukWaC, the English Wikipedia, and the British National Corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Tuning and Evaluation Datasets</head><p>We experiment with datasets of segment-level human rankings of system outputs from the WMT11, WMT12 and WMT13 Metrics shared tasks <ref type="bibr" target="#b7">(Callison-Burch et al., 2011;</ref><ref type="bibr" target="#b8">Callison-Burch et al., 2012;</ref><ref type="bibr" target="#b25">Macháček and Bojar, 2013)</ref>. We focus on translating into English, for which the WMT11 and WMT12 datasets can be split by source lan- guage: Czech (cs), German (de), Spanish (es), and French (fr); WMT13 also has Russian (ru).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluation Score</head><p>We evaluate our metrics in terms of correlation with human judgments measured using Kendall's τ . We report τ for the individual languages as well as macro-averaged across all languages.</p><p>Note that there were different versions of τ at WMT over the years. Prior to 2013, WMT used a strict version, which was later relaxed at WMT13 and further revised at WMT14. See <ref type="bibr" target="#b26">(Macháček and Bojar, 2014</ref>) for a discussion. Here we use the strict version used at WMT11 and WMT12.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Experimental Settings</head><p>Datasets: We train our neural models on WMT11 and we evaluate them on WMT12. We further use a random subset of 5,000 examples from WMT13 as a validation set to implement early stopping. Early stopping: We train on WMT11 for up to 10,000 epochs, and we calculate Kendall's τ on the development set after each epoch. We then se- lect the model that achieves the highest τ on the validation set; in case of ties for the best τ , we select the latest epoch that achieved the highest τ . Network parameters: We train our neural net- work using SGD with adagrad, an initial learning rate of η = 0.01, mini-batches of size 30, and L 2 regularization with a decay parameter λ = 1e −4 . We initialize the weights for our matrices by sam- pling from a uniform distribution following <ref type="bibr" target="#b2">(Bengio and Glorot, 2010)</ref>. We further set the size of each of our pairwise hidden layers H to four nodes, and we normalize the input data using min- max to map the feature values to the range [−1, 1].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments and Results</head><p>The main findings of our experiments are shown in <ref type="table">Table 1</ref>. Section I of <ref type="table">Table 1</ref> shows the re- sults for four commonly-used metrics for MT eval- uation that compare a translation hypothesis to the reference(s) using primarily lexical informa- tion like word and n-gram overlap (even though some allow paraphrases): BLEU, NIST, TER, and METEOR ( <ref type="bibr" target="#b31">Papineni et al., 2002;</ref><ref type="bibr" target="#b14">Doddington, 2002;</ref><ref type="bibr" target="#b34">Snover et al., 2006;</ref><ref type="bibr" target="#b12">Denkowski and Lavie, 2011</ref>). We will refer to the set of these four met- rics as 4METRICS. These metrics are not tuned and achieve Kendall's τ between 18.5 and 23.5.</p><p>Section II of <ref type="table">Table 1</ref> shows the results for multi- layer neural networks trained on vectors from word embeddings only: SYNTAX25 and WIKI- GW25. These networks achieve modest τ values around 10, which should not be surprising: they use very general vector representations and have no access to word or n-gram overlap or to length information, which are very important features to compute similarity against the reference. How- ever, as will be discussed below, their contribution is complementary to the four previous evaluation metrics and will lead to significant improvements in combination with them.</p><p>Section III of <ref type="table">Table 1</ref> shows the results for neu- ral networks that combine the four metrics from 4METRICS with SYNTAX25 and WIKI-GW25. We can see that just combining the four metrics in a flat neural net (i.e., no hidden layer), which is equivalent to a logistic regression, yields a τ of 27.06, which is better than the best of the four met- rics by 3.5 points absolute, and also better by over 1.5 points absolute than the best metric that par- ticipated at the WMT12 metrics task competition (SPEDE07PP with τ = 25.4). Indeed, 4METRICS is a strong mix that involves not only simple lex- ical overlap but also approximate matching, para- phrases, edit distance, lengths, etc. Yet, adding to 4METRICS the embedding vectors yields sizeable further improvements: +1.5 and +2.0 points abso- lute when adding SYNTAX25 and WIKI-GW25, respectively. Finally, adding both yields even further improvements close to τ of 30 (+2.64 τ points), showing that lexical semantics and syn- tactic representations are complementary.</p><p>Section IV of <ref type="table">Table 1</ref> puts these numbers in per- spective: it lists the τ for the top three systems that participated at WMT12, whose scores ranged be- tween 22.9 and 25.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Details</head><p>Kendall's τ We can see that 4METRICS is much stronger than the winner at WMT12, and thus arguably a baseline hard to improve upon. While our results are slightly behind those of DiscoTK ( <ref type="bibr" target="#b20">Joty et al., 2014</ref>), we should note that we only combine four metrics, plus the vectors, while DiscoTK com- bines over 20 metrics, many of which are costly to compute.</p><p>On the other hand, we work in a ranking frame- work, i.e., we are not interested in producing an absolute score, but in making pairwise decisions only. Mapping these pairwise decisions into an ab- solute score is challenging and in our experiments it leads to a slight drop in τ (results omitted here to save space).</p><p>The only other result on WMT12 by authors working with our pairwise framework is our own previous work <ref type="figure" target="#fig_0">(Guzmán et al., 2014a)</ref>, where we used a preference kernel approach to combine syn- tactic and discourse trees with lexical information; as we can see, our earlier results are 6 absolute points lower than those we achieve here. More- over, our NN approach offers advantages over SVMs in terms of computational cost.</p><p>Based on these results, we can conclude that word embeddings, whether syntactic or semantic, offer generalizations that efficiently complement very strong metric combinations, and thus should be considered when designing future MT evalua- tion metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>In this section, we explore how different parts of our framework can be modified to improve its per- formance, or how it can be extended for further generalization. First, we explore variations of the feature sets from the perspective of both the pair- wise features and the embeddings. Then, we ana- lyze the role of the network architecture and of the cost function used for learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Fine-Grained Pairwise Features</head><p>We have shown that our NN can integrate syntactic and semantic vectors with scores from other met- rics. In fact, ours is a more general framework, where one can integrate the components of a met- ric instead of its score, which could yield better learning. Below, we demonstrate this for BLEU.</p><p>BLEU has different components: the n-gram precisions, the n-gram matches, the total num- ber of n-grams <ref type="figure" target="#fig_0">(n=1,2,3,4)</ref>, the lengths of the hy- potheses and of the reference, the length ratio be- tween them, and BLEU's brevity penalty. We will refer to this decomposed BLEU as BLEUCOMP. Some of these features were previously used in SIMPBLEU ( <ref type="bibr" target="#b37">Song and Cohn, 2011)</ref>.</p><p>The results of using the components of BLEUCOMP as features are shown in <ref type="table" target="#tab_2">Table 2</ref>. We see that using a single-layer neural network, which is equivalent to logistic regression, outperforms BLEU by more than +1 τ points absolute.   As before, adding SYNTAX25 and WIKI- GW25 improves the results, but now by a more sizable margin: +4 for the former and +5 for the latter. Adding both yields +6.5 improvement over BLEUCOMP, and almost 8 points over BLEU.</p><p>We see once again that the syntactic and seman- tic word embeddings are complementary to the in- formation sources used by metrics such as BLEU, and that our framework can learn from richer pair- wise feature sets such as BLEUCOMP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Larger Semantic Vectors</head><p>One interesting aspect to explore is the effect of the dimensionality of the input embeddings. Here, we studied the impact of using semantic vectors of bigger sizes, trained on different and larger text collections. The results are shown in <ref type="table" target="#tab_3">Table 3</ref>. We can see that, compared to the 50-dimensional WIKI-GW25, 300-400 dimensional vectors are generally better by 1-2 τ points absolute when used in isolation; however, when used in combina- tion with 4METRICS+SYNTAX25, they do not of- fer much gain (up to +0.2), and in some cases, we observe a slight drop in performance. We suspect that the variability across the different collections is due to a domain mismatch. Yet, we defer this question for future work.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Deep vs. Flat Neural Network</head><p>One interesting question is how much of the learn- ing is due to the rich input representations, and how much happens because of the architecture of the neural network. To answer this, we exper- imented with two settings: a single-layer neural network, where all input features are fed directly to the output layer (which is logistic regression), and our proposed multi-layer neural network.</p><p>The results are shown in <ref type="table" target="#tab_5">Table 4</ref>. We can see that switching from our multi-layer architecture to a single-layer one yields an absolute drop of 0.6 τ . This suggests that there is value in using the deeper, pairwise layer architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Task-Specific Cost Function</head><p>Another question is whether the log-likelihood cost function J(θ) (see Section 3.3) is the most appropriate for our ranking task, provided that it is evaluated using Kendall's τ as defined below:</p><formula xml:id="formula_7">τ = concord. − disc. − ties concord + disc. + ties (5)</formula><p>where concord., disc. and ties are the number of concordant, disconcordant and tied pairs. Given an input tuple (t 1 , t 2 , r), the logistic cost function yields larger values of σ = f (t 1 , t 2 , r) if y = 1, and smaller if y = 0, where 0 ≤ σ ≤ 1 is the parameter of the Bernoulli distribution. How- ever, it does not model directly the probability when the order of the hypotheses in the tuple is reversed, i.e., σ = f (t 2 , t 1 , r).  For our specific task, given an input tuple (t 1 , t 2 , r), we want to make sure that the difference between the two output activations ∆ = σ − σ is positive when y = 1, and negative when y = 0. Ensuring this would take us closer to the actual objective, which is Kendall's τ . One possible way to do this is to introduce a task-specific cost func- tion that penalizes the disagreements similarly to the way Kendall's τ does. <ref type="bibr">4</ref> In particular, we de- fine a new Kendall cost as follows:</p><formula xml:id="formula_8">J θ = − n y n sig(−γ∆ n ) + (1 − y n ) sig(γ∆ n ) (6)</formula><p>where we use the sigmoid function sig as a differ- entiable approximation to the step function.</p><p>The above cost function penalizes disconcor- dances, i.e., cases where (i) y = 1 but ∆ &lt; 0, or (ii) when y = 0 but ∆ &gt; 0. However, we also need to make sure that we discourage ties. We do so by adding a zero-mean Gaussian regularization term exp(−β∆ 2 /2) that penalizes the value of ∆ getting close to zero. Note that the specific val- ues for γ and β are not really important, as long as they are large. In particular, in our experiments, we used γ = β = 100. <ref type="table" target="#tab_7">Table 5</ref> shows a comparison of the two cost functions: (i) the standard logistic cost, and (ii) our Kendall cost. We can see that using the Kendall cost enables effective learning, although it is even- tually outperformed by the logistic cost. Our in- vestigation revealed that this was due to a combi- nation of slower convergence and poor initializa- tion. Therefore, we further experimented with a setup where we first used the logistic cost to pre- train the neural network, and then we switched to the Kendall cost in order to perform some finer tuning. As we can see in <ref type="table" target="#tab_7">Table 5</ref> (last row), do- ing so yielded a sizable improvement over using the Kendall cost only; it also improved over using the logistic cost only.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions and Future Work</head><p>We have presented a novel framework for learn- ing a tunable MT evaluation metric in a pairwise ranking setting, given pre-existing pairwise human preference judgments.</p><p>In particular, we used a neural network, where the input layer encodes lexical, syntactic and se- mantic information from the reference and the two translation hypotheses, which is efficiently com- pacted into relatively small embeddings. The net- work has a hidden layer, motivated by our intuition about the problem, which captures the interactions between the relevant input components. Unlike previously proposed kernel-based approaches, our framework allows us to do both training and in- ference efficiently. Moreover, we have shown that it can be trained to optimize a task-specific cost function, which is more appropriate for the pair- wise MT evaluation setting.</p><p>The evaluation results have shown that our NN model yields state-of-the-art results when using lexical, syntactic and semantic features (the latter two based on compact embeddings). Moreover, we have shown that the contribution of the differ- ent information sources is additive, thus demon- strating that the framework can effectively inte- grate complementary information. Furthermore, the framework is flexible enough to exploit dif- ferent granularities of features such as n-gram matches and other components of BLEU (which individually work better than using the aggregated BLEU score). Finally, we have presented evidence suggesting that using the pairwise hidden layers is advantageous over simpler flat models.</p><p>In future work, we would like to experiment with an extension that allows for multiple refer- ences. We further plan to incorporate features from the source sentence. We believe that our framework can support learning similarities be- tween the two translations and the source, for an improved MT evaluation. Variations of this ar- chitecture might be useful for related tasks such as Quality Estimation and hypothesis re-ranking for Machine Translation, where no references are available.</p><p>Other aspects worth studying as a complement to the present work include (i) the impact of the quality of the syntactic analysis (translations are often just a "word salad"), (ii) differences across language pairs, and (iii) the relevance of the do- main the semantic representations are trained on.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Overall architecture of the neural network.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Kendall's τ on WMT12 for neural networks using BLEUCOMP, a decomposed version of BLEU. For comparison, 

the last line shows a combination using BLEU instead of BLEUCOMP. 

Source 
Alone 
Comb. 

WIKI-GW25 
10.01 
29.70 
WIKI-GW300 
9.66 
29.90 
CC-300-42B 
12.16 
29.68 
CC-300-840B 
11.41 
29.88 

WORD2VEC300 

7.72 
29.13 

COMPOSES400 
12.35 
28.54 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Average Kendall's τ on WMT12 for semantic vec-

tors trained on different text collections. Shown are results 

(i) when using the semantic vectors alone, and (ii) when com-

bining them with 4METRICS and SYNTAX25. The improve-

ments over WIKI-GW25 are marked in bold. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Kendall's tau (τ ) on the WMT12 dataset for al-

ternative architectures using 4METRICS+SYNTAX25+WIKI-

GW25 as input. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 5 : Kendall's tau (τ ) on WMT12 for alternative cost functions using 4METRICS+SYNTAX25+WIKI-GW25.</head><label>5</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="1"> We do not argue that the pairwise approach is better than the direct estimation of human quality scores. Both approaches have pros and cons; we see them as complementary.</note>

			<note place="foot" n="2"> In this work, we do not learn to predict ties, and ties are excluded from our training data.</note>

			<note place="foot" n="3"> Many of our input representations consist of word embeddings trained with neural networks that used tanh as an activation function.</note>

			<note place="foot" n="4"> Other variations for ranking tasks are possible, e.g., (Yih et al., 2011).</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Regression for machine translation evaluation at the sentence level. Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Albrecht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Hwa</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Don&apos;t count, predict! A systematic comparison of context-counting vs. context-predicting semantic vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgiana</forename><surname>Dinu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Germán</forename><surname>Kruszewski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, ACL &apos;14</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics, ACL &apos;14<address><addrLine>Baltimore, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="238" to="247" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AI &amp; Statistics</title>
		<meeting>AI &amp; Statistics<address><addrLine>Sardinia, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="249" to="256" />
		</imprint>
		<respStmt>
			<orgName>Chia Laguna Resort</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A neural probabilistic language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Réjean</forename><surname>Ducharme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Janvin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1137" to="1155" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Theano: a CPU and GPU math expression compiler</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Breuleux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frédéric</forename><surname>Bastien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Desjardins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Turian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Python for Scientific Computing Conference, SciPy &apos;10</title>
		<meeting>the Python for Scientific Computing Conference, SciPy &apos;10<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Findings of the 2014 workshop on statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Buck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Leveling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Pecina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herve</forename><surname>Saint-Amand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleš</forename><surname>Tamchyna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth Workshop on Statistical Machine Translation, WMT &apos;14</title>
		<meeting>the Ninth Workshop on Statistical Machine Translation, WMT &apos;14<address><addrLine>Baltimore, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="12" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Meta-) evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cameron</forename><surname>Fordyce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josh</forename><surname>Schroeder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Workshop on Statistical Machine Translation, WMT &apos;07</title>
		<meeting>the Second Workshop on Statistical Machine Translation, WMT &apos;07<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="136" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Findings of the 2011 workshop on statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omar</forename><surname>Zaidan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Workshop on Statistical Machine Translation, WMT &apos;11</title>
		<meeting>the Sixth Workshop on Statistical Machine Translation, WMT &apos;11<address><addrLine>Edinburgh, Scotland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="22" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Findings of the 2012 Workshop on Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Workshop on Statistical Machine Translation, WMT &apos;12</title>
		<meeting>the Seventh Workshop on Statistical Machine Translation, WMT &apos;12<address><addrLine>Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="10" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisabet</forename><surname>Comelles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesús</forename><surname>Giménez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lluís</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irene</forename><surname>Castellón</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victoria</forename><surname>Arranz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Document-level automatic MT evaluation based on discourse representations</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR, WMT &apos;10</title>
		<meeting>the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR, WMT &apos;10<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="333" to="338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Meteor 1.3: Automatic metric for reliable optimization and evaluation of machine translation systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Denkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Workshop on Statistical Machine Translation</title>
		<meeting>the Sixth Workshop on Statistical Machine Translation<address><addrLine>Edinburgh, Scotland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="85" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Fast and robust neural network joint models for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rabih</forename><surname>Zbib</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongqiang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Lamar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Makhoul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, ACL &apos;14</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics, ACL &apos;14<address><addrLine>Baltimore, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1370" to="1380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Automatic evaluation of machine translation quality using n-gram cooccurrence statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Doddington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second International Conference on Human Language Technology Research, HLT &apos;02</title>
		<meeting>the Second International Conference on Human Language Technology Research, HLT &apos;02<address><addrLine>San Francisco, California, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="138" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Adaptive subgradient methods for online learning and stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2121" to="2159" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Ranking vs. regression in machine translation evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Workshop on Statistical Machine Translation, WMT &apos;08</title>
		<meeting>the Third Workshop on Statistical Machine Translation, WMT &apos;08<address><addrLine>Columbus, Ohio, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="191" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Linguistic features for automatic evaluation of heterogenous MT systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesús</forename><surname>Giménez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lluís</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Workshop on Statistical Machine Translation, WMT &apos;07</title>
		<meeting>the Second Workshop on Statistical Machine Translation, WMT &apos;07<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="256" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning to differentiate better from worse translations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Guzmán</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shafiq</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lluís</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimo</forename><surname>Nicosia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;14</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;14<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="214" to="220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Using discourse structure improves machine translation evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Guzmán</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shafiq</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lluís</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics, ACL &apos;14</title>
		<meeting>52nd Annual Meeting of the Association for Computational Linguistics, ACL &apos;14<address><addrLine>Baltimore, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="687" to="698" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">DiscoTK: Using discourse structure for machine translation evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shafiq</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Guzmán</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lluís</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth Workshop on Statistical Machine Translation, WMT &apos;14</title>
		<meeting>the Ninth Workshop on Statistical Machine Translation, WMT &apos;14<address><addrLine>Baltimore, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="402" to="408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A learning approach to improving sentence-level MT evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stuart</forename><forename type="middle">M</forename><surname>Shieber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Conference on Theoretical and Methodological Issues in Machine Translation</title>
		<meeting>the 10th International Conference on Theoretical and Methodological Issues in Machine Translation</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">The METEOR metric for automatic evaluation of machine translation. Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Denkowski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="105" to="115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Syntactic features for evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ding</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization</title>
		<meeting>the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization<address><addrLine>Ann Arbor, Michigan, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="25" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Fully automatic semantic MT evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Kiu</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anand</forename><forename type="middle">Karthik</forename><surname>Tumuluru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekai</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Workshop on Statistical Machine Translation, WMT &apos;12</title>
		<meeting>the Seventh Workshop on Statistical Machine Translation, WMT &apos;12<address><addrLine>Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="243" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Results of the WMT13 metrics shared task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matouš</forename><surname>Macháček</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth Workshop on Statistical Machine Translation, WMT &apos;13</title>
		<meeting>the Eighth Workshop on Statistical Machine Translation, WMT &apos;13<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="45" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Results of the WMT14 metrics shared task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matouš</forename><surname>Macháček</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth Workshop on Statistical Machine Translation, WMT &apos;14</title>
		<meeting>the Ninth Workshop on Statistical Machine Translation, WMT &apos;14<address><addrLine>Baltimore, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="293" to="301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Recurrent neural network based language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Karafiát</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Burget</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Cernock´ycernock´y</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Khudanpur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">11th Annual Conference of the International Speech Communication Association</title>
		<meeting><address><addrLine>Makuhari, Chiba, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1045" to="1048" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 26, NIPS &apos;13</title>
		<meeting><address><addrLine>Lake Tahoe, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Linguistic regularities in continuous space word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT &apos;13</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT &apos;13<address><addrLine>Atlanta, Georgia, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="746" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Composition in distributional models of semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1388" to="1439" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">BLEU: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 40th Annual Meting of the Association for Computational Linguistics, ACL &apos;02</title>
		<meeting>40th Annual Meting of the Association for Computational Linguistics, ACL &apos;02<address><addrLine>Philadelphia, Pennsylvania, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;14</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;14<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Word error rates: Decomposition over POS classes and applications for error analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maja</forename><surname>Popovi´cpopovi´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Workshop on Statistical Machine Translation, WMT &apos;07</title>
		<meeting>the Second Workshop on Statistical Machine Translation, WMT &apos;07<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="48" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A study of translation edit rate with targeted human annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Snover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Dorr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linnea</forename><surname>Micciulla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Makhoul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Biennial Conference of the Association for Machine Translation in the Americas, AMTA &apos;06</title>
		<meeting>the 7th Biennial Conference of the Association for Machine Translation in the Americas, AMTA &apos;06<address><addrLine>Cambridge, Massachusetts, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Parsing with compositional vector grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ng</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="455" to="465" />
		</imprint>
	</monogr>
	<note>Long Papers), ACL &apos;13</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Recursive deep models for semantic compositionality over a sentiment treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Perelygin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;13</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;13<address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1631" to="1642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Regression and ranking based optimisation for sentence-level MT evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyi</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Workshop on Statistical Machine Translation, WMT &apos;11</title>
		<meeting>the Sixth Workshop on Statistical Machine Translation, WMT &apos;11<address><addrLine>Edinburgh, Scotland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="123" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Neural Information Processing Systems, NIPS &apos;14</title>
		<meeting>the Neural Information Processing Systems, NIPS &apos;14<address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Extending machine translation evaluation metrics with lexical cohesion to document level</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Billy</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyu</forename><surname>Kit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1060" to="1068" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Learning discriminative projections for text similarity measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">C</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Platt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Meek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifteenth Conference on Computational Natural Language Learning, CoNLL &apos;11</title>
		<meeting>the Fifteenth Conference on Computational Natural Language Learning, CoNLL &apos;11<address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="247" to="256" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
