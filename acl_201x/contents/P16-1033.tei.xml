<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:51+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Active Learning for Dependency Parsing with Partial Annotation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenghua</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Soochow University</orgName>
								<address>
									<settlement>Suzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Baidu Inc</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">†</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Soochow University</orgName>
								<address>
									<settlement>Suzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Baidu Inc</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanyi</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Soochow University</orgName>
								<address>
									<settlement>Suzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Baidu Inc</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenliang</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Soochow University</orgName>
								<address>
									<settlement>Suzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Baidu Inc</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Wu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
						</author>
						<title level="a" type="main">Active Learning for Dependency Parsing with Partial Annotation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="344" to="354"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Different from traditional active learning based on sentence-wise full annotation (FA), this paper proposes active learning with dependency-wise partial annotation (PA) as a finer-grained unit for dependency parsing. At each iteration, we select a few most uncertain words from an unlabeled data pool, manually annotate their syntactic heads, and add the partial trees into labeled data for parser retraining. Compared with sentence-wise FA, dependency-wise PA gives us more flexibility in task selection and avoids wasting time on annotating trivial tasks in a sentence. Our work makes the following contributions. First, we are the first to apply a probabilistic model to active learning for dependency parsing, which can 1) provide tree probabilities and dependency marginal probabilities as principled uncertainty metrics, and 2) directly learn parameters from PA based on a forest-based training objective. Second, we propose and compare several uncertainty metrics through simulation experiments on both Chinese and English. Finally, we conduct human annotation experiments to compare FA and PA on real annotation time and quality.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>During the past decade, supervised dependency parsing has gained extensive progress in boosting parsing performance on canonical texts, especially on texts from domains or genres similar to exist- ing manually labeled treebanks ( <ref type="bibr" target="#b13">Koo and Collins, 2010;</ref><ref type="bibr" target="#b44">Zhang and Nivre, 2011</ref>). However, the * Correspondence author. $ 0 I 1 saw 2 Sarah 3 with 4 a 5 telescope 6</p><p>Figure 1: A partially annotated sentence, where only the heads of "saw" and "with" are decided.</p><p>upsurge of web data (e.g., tweets, blogs, and product comments) imposes great challenges to existing parsing techniques. Meanwhile, previous research on out-of-domain dependency parsing gains little success ( <ref type="bibr" target="#b4">Dredze et al., 2007;</ref><ref type="bibr" target="#b34">Petrov and McDonald, 2012)</ref>. A more feasible way for open-domain parsing is to manually annotate a certain amount of texts from the target domain or genre. Recently, several small-scale treebanks on web texts have been built for study and evaluation <ref type="bibr" target="#b8">(Foster et al., 2011;</ref><ref type="bibr" target="#b34">Petrov and McDonald, 2012;</ref><ref type="bibr" target="#b43">Wang et al., 2014</ref>).</p><p>Meanwhile, active learning (AL) aims to reduce annotation effort by choosing and manually an- notating unlabeled instances that are most valu- able for training statistical models <ref type="bibr" target="#b32">(Olsson, 2009)</ref>. Traditionally, AL utilizes full annotation (FA) for parsing ( <ref type="bibr" target="#b41">Tang et al., 2002;</ref><ref type="bibr" target="#b11">Hwa, 2004;</ref><ref type="bibr">Lynn et al., 2012)</ref>, where a whole syntactic tree is annotated for a given sentence at a time. However, as commented by <ref type="bibr" target="#b29">Mejer and Crammer (2012)</ref>, the annotation process is complex, slow, and prone to mistakes when FA is required. Particularly, annotators waste a lot of effort on labeling trivial dependencies which can be well handled by cur- rent statistical models <ref type="bibr" target="#b6">(Flannery and Mori, 2015)</ref>.</p><p>Recently, researchers report promising results with AL based on partial annotation (PA) for de- pendency parsing <ref type="bibr" target="#b37">(Sassano and Kurohashi, 2010;</ref><ref type="bibr" target="#b31">Mirroshandel and Nasr, 2011;</ref><ref type="bibr" target="#b22">Majidi and Crane, 2013;</ref><ref type="bibr" target="#b6">Flannery and Mori, 2015)</ref>. They find that smaller units rather than sentences provide more flexibility in choosing potentially informa- tive structures to annotate.</p><p>Beyond previous work, this paper endeavors to more thoroughly study this issue, and has made substantial progress from the following perspec- tives.</p><p>(1) This is the first work that applies a state- of-the-art probabilistic parsing model to AL for dependency parsing. The CRF-based dependency parser on the one hand allows us to use probabilities of trees or marginal probabilities of single dependencies for un- certainty measurement, and on the other hand can directly learn parameters from partially annotated trees. Using probabilistic models may be ubiquitous in AL for relatively sim- pler tasks like classification and sequence la- beling, but is definitely novel for dependency parsing which is dominated by linear models with perceptron-like training.</p><p>(2) Based on the CRF-based parser, we make systematic comparison among several uncer- tainty metrics for both FA and PA. Simulation experiments show that compared with using FA, AL with PA can greatly reduce annota- tion effort in terms of dependency number by 62.2% on Chinese and by 74.2% on English.</p><p>(3) We build a visualized annotation platform and conduct human annotation experiments to compare FA and PA on real annotation time and quality, where we obtain several interesting observations and conclusions.</p><p>All codes, along with the data from human annotation experiments, are released at http: //hlt.suda.edu.cn/ ˜ zhli for future re- search study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Probabilistic Dependency Parsing</head><p>Given an input sentence x = w 1 ...w n , the goal of dependency parsing is to build a directed depen- dency tree d = {h ↷ m : 0 ≤ h ≤ n, 1 ≤ m ≤ n}, where |d| = n and h ↷ m represents a dependency from a head word h to a modifier word m. <ref type="figure">Figure 1</ref> depicts a partial tree containing two dependencies. <ref type="bibr">1</ref> In this work, we for the first time apply a proba- bilistic CRF-based parsing model to AL for depen- dency parsing. We adopt the second-order graph- based model of <ref type="bibr" target="#b26">McDonald and Pereira (2006)</ref>, which casts the problem as finding an optimal tree from a fully-connect directed graph and factors the score of a dependency tree into scores of pairs of sibling dependencies.</p><formula xml:id="formula_0">d * = arg max d∈Y(x) Score(x, d; w) Score(x, d; w) = ∑ (h,s,m):h↷s∈d, h↷m∈d w · f (x, h, s, m)<label>(1)</label></formula><p>where s and m are adjacent siblings both modify- ing h; f (x, h, s, m) are the corresponding feature vector; w is the feature weight vector; Y(x) is the set of all legal trees for x according to the dependency grammar in hand; d * is the 1-best parse tree which can be gained efficiently via a dynamic programming algorithm <ref type="bibr" target="#b5">(Eisner, 2000</ref>). We use the state-of-the-art feature set listed in <ref type="bibr">Bohnet (2010)</ref>. Under the log-linear CRF-based model, the probability of a dependency tree is:</p><formula xml:id="formula_1">p(d|x; w) = e Score(x,d;w) ∑ d ′ ∈Y(x) e Score(x,d ′ ;w) (2)</formula><p>Ma and Zhao (2015) give a very detailed and thorough introduction to CRFs for dependency parsing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Learning from FA</head><p>Under the supervised learning scenario, a labeled training data</p><formula xml:id="formula_2">D = {(x i , d i )} N i=1</formula><p>is provided to learn w. The objective is to maximize the log likelihood of D:</p><formula xml:id="formula_3">L(D; w) = ∑ N i=1 log p(d i |x i ; w)<label>(3)</label></formula><p>which can be solved by standard gradient descent algorithms. In this work, we adopt stochastic gra- dient descent (SGD) with L2-norm regularization for all CRF-based parsing models. <ref type="bibr">2</ref> explored in this paper can be easily extended to the case of labeled dependency parsing. <ref type="bibr">2</ref> We borrow the implementation of SGD in CRFsuite (http://www.chokkan.org/software/ crfsuite/), and use 100 sentences for a batch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Marginal Probability of Dependencies</head><p>Marcheggiani andArtì eres <ref type="bibr">(2014)</ref> shows that marginal probabilities of local labels can be used as an effective uncertain metric for AL for sequence labeling problems. In the case of dependency parsing, the marginal probability of a dependency is the sum of probabilities of all legal trees that contain the dependency.</p><formula xml:id="formula_4">p(h ↷ m|x; w) = ∑ d∈Y(x):h↷m∈d p(d|x; w) (4)</formula><p>Intuitively, marginal probability is a more princi- pled metric for measuring reliability of a depen- dency since it considers all legal parses in the search space, compared to previous methods based on scores of local classifiers <ref type="bibr" target="#b37">(Sassano and Kurohashi, 2010;</ref><ref type="bibr" target="#b6">Flannery and Mori, 2015</ref>) or votes of n-best parses (Mirroshandel and Nasr, 2011). Moreover, <ref type="bibr" target="#b17">Li et al. (2014)</ref> find strong correlation between marginal probability and correctness of a dependency in cross-lingual syntax projection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Active Learning for Dependency Parsing</head><p>This work adopts the standard pool-based AL framework ( <ref type="bibr" target="#b15">Lewis and Gale, 1994;</ref><ref type="bibr" target="#b24">McCallum and Nigam, 1998</ref>). Initially, we have a small set of labeled seed data L, and a large-scale unlabeled data pool U. Then the procedure works as follows.</p><p>(1) Train a new parser on the current L.</p><p>(2) Parse all sentences in U, and select a set of the most informative tasks U ′ (3) Manually annotate:</p><formula xml:id="formula_5">U ′ → L ′ (4) Expand labeled data: L ∪ L ′ → L</formula><p>The above steps loop for many iterations until a predefined stopping criterion is met.</p><p>The key challenge for AL is how to measure the informativeness of structures in concern. Follow- ing previous work on AL for dependency parsing, we make a simplifying assumption that if the current model is most uncertain about an output (sub)structure, the structure is most informative in terms of boosting model performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Sentence-wise FA</head><p>Sentence-wise FA selects K most uncertain sen- tences in Step (2), and annotates their whole tree structures in <ref type="bibr">Step (3)</ref>. In the following, we de- scribe several uncertainty metrics and investigate their practical effects through experiments. Given an unlabeled sentence x = w 1 ...w n , we use d * to denote the 1-best parse tree produced by the current model as in Eq. (1). For brevity, we omit the feature weight vector w in the equations.</p><p>Normalized tree score. Following previous works that use scores of local classifiers for uncertainty measurement <ref type="bibr" target="#b37">(Sassano and Kurohashi, 2010;</ref><ref type="bibr" target="#b6">Flannery and Mori, 2015)</ref>, we use Score(x, d * ) to measure the uncertainty of x, assuming that the model is more uncertain about x if d * gets a smaller score. However, we find that directly using Score(x, d * ) always selects very short sentences due to the definition in Eq. (1). Thus we normalize the score with the sentence length n as follows. 3</p><formula xml:id="formula_6">Conf i(x) = Score(x, d * ) n 1.5 (5)</formula><p>Normalized tree probability. The CRF-based parser allows us, for the first time in AL for de- pendency parsing, to directly use tree probabilities for uncertainty measurement. Unlike previous approximate methods based on k-best parses <ref type="bibr" target="#b31">(Mirroshandel and Nasr, 2011</ref>), tree probabilities glob- ally consider all parse trees in the search space, and thus are intuitively more consistent and proper for measuring the reliability of a tree. Our initial assumption is that the model is more uncertain about x if d * gets a smaller probability. However, we find that directly using p(d * |x) would select very long sentences because the solution space grows exponentially with sentence length. We find that the normalization strategy below works well. 4</p><formula xml:id="formula_7">Conf i(x) = n √ p(d * |x)<label>(6)</label></formula><p>Averaged marginal probability. As discussed in Section 2.2, the marginal probability of a de- pendency directly reflects its reliability, and thus can be regarded as another global measurement besides tree probabilities.In fact, we find that the effect of sentence length is naturally handled with the following metric. 5</p><formula xml:id="formula_8">Conf i(x) = ∑ h↷m∈d * p(h ↷ m|x) n (7)</formula><p>3.2 Single Dependency-wise PA AL with single dependency-wise PA selects M most uncertain words from U in</p><p>Step <ref type="formula">(2)</ref>, and an- notates the heads of the selected words in Step (3). After annotation, the newly annotated sentences with partial trees L ′ are added into L. Different from the case of sentence-wise FA, L ′ are also put back to U, so that new tasks can be further chosen from them. Marcheggiani andArtì eres (2014) make sys- tematic comparison among a dozen uncertainty metrics for AL with PA for several sequence labeling tasks. We borrow three effective metrics according to their results.</p><p>Marginal probability max. Suppose h 0 = arg max h p(h ↷ i|x) is the most likely head for i. The intuition is that the lower p(h 0 ↷ i) is, the more uncertain the model is on deciding the head of the token i.</p><formula xml:id="formula_9">Conf i(x, i) = p(h 0 ↷ i|x) (8)</formula><p>Marginal probability gap. Suppose h 1 = arg max h̸ =h 0 p(h ↷ i|x) is the second most likely head for i. The intuition is that the smaller the probability gap is, the more uncertain the model is about i.</p><formula xml:id="formula_10">Conf i(x, i) = p(h 0 ↷ i|x) − p(h 1 ↷ i|x) (9)</formula><p>Marginal probability entropy. This metric considers the entropy of all possible heads for i.</p><p>The assumption is that the smaller the negative entropy is, the more uncertain the model is about i.</p><formula xml:id="formula_11">Conf i(x, i) = ∑ h p(h ↷ i|x) log p(h ↷ i|x)<label>(10)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Batch Dependency-wise PA</head><p>In the framework of single dependency-wise PA, we assume that the selection and annotation of dependencies in the same sentence are strictly independent. In other words, annotators may be asked to annotate the head of one selected word af- ter reading and understanding a whole (sometimes partial) sentence, and may be asked to annotate another selected word in the same sentence in next AL iteration. Obviously, frequently switching sentences incurs great waste of cognitive effort, $ 0 I 1 saw 2 Sarah 3 with 4 a 5 telescope 6</p><p>Figure 2: An example parse forest converted from the partial tree in <ref type="figure">Figure 1</ref>. and annotating one dependency can certainly help decide another dependency in practice.</p><p>Inspired by the work of Flannery and Mori (2015), we propose AL with batch dependency- wise PA, which is a compromise between sentence-wise FA and single dependency-wise PA. In Step 2, AL with batch dependency-wise PA selects K most uncertain sentences from U, and also determines r% most uncertain words from each sentence at the same time. In Step 3, annotators are asked to label the heads of the selected words in the selected sentences. We propose and experiment with the following three strategies based on experimental results of sentence-wise FA and single dependency-wise PA.</p><p>Averaged marginal probability &amp; gap. First, select K sentences from U using averaged marginal probability. Second, select r% words using marginal probability gap for each selected sentence.</p><p>Marginal probability gap. First, for each sentence in U, select r% most uncertain words according to marginal probability gap. Second, select K sentences from U using the averaged marginal probability gap of the selected r% words in a sentence as the uncertainty metric.</p><p>Averaged marginal probability. This strategy is the same with the above strategy, except it measures the uncertainty of a word i according to the marginal probability of the dependency</p><formula xml:id="formula_12">pointing to i in d * , i.e., p(j ↷ i|x), where j ↷ i ∈ d * .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Learning from PA</head><p>A major challenge for AL with PA is how to learn from partially labeled sentences, as depicted in <ref type="figure">Figure 1</ref>. <ref type="bibr" target="#b17">Li et al. (2014)</ref> show that a probabilistic CRF-based parser can naturally and effectively learn from PA. The basic idea is converting a partial tree into a forest as shown in <ref type="figure">Figure 2</ref>, and using the forest as the gold-standard reference during training, also known as ambiguous labeling ( <ref type="bibr" target="#b36">Riezler et al., 2002;</ref><ref type="bibr" target="#b40">Täckström et al., 2013)</ref>.</p><p>For each remaining word without head, we add all dependencies linking to it as long as the new dependency does not violate the existing dependencies. We denote the resulting forest as Fj, whose probability is naturally the sum of probabilities of each tree d in F.</p><formula xml:id="formula_13">p(F|x; w) = ∑ d∈F p(d|x; w) = ∑ d∈F e Score(x,d;w) ∑ d ′ ∈Y(x) e Score(x,d ′ ;w)<label>(11)</label></formula><p>Suppose the partially labeled training data is</p><formula xml:id="formula_14">D = {(x i , F i )} N i=1</formula><p>. Then its log likelihood is:</p><formula xml:id="formula_15">L(D; w) = ∑ N i=1 log p(F i |x i ; w)<label>(12)</label></formula><p>Täckström et al. <ref type="formula" target="#formula_0">(2013)</ref> show that the partial derivative of the L(D; w) with regard to w (a.k.a the gradient) in both Equation <ref type="formula" target="#formula_3">(3)</ref> and <ref type="formula" target="#formula_0">(12)</ref> can be efficiently solved with the classic Inside-Outside algorithm. <ref type="bibr">6</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Simulation Experiments</head><p>We use Chinese Penn Treebank 5.1 (CTB ) for Chinese and Penn Treebank (PTB ) for English. For both datasets, we follow the standard data split, and convert original bracketed structures into dependency structures using Penn2Malt with its default head-finding rules. To be more realis- tic, we use automatic part-of-speech (POS) tags produced by a state-of-the-art CRF-based tagger (94.1% on CTB -test, and 97.2% on PTB -test, n- fold jackknifing on training data), since POS tags encode much syntactic annotation. Because AL experiments need to train many parsing models, we throw out all training sentences longer than 50 to speed up our experiments. <ref type="table">Table 1</ref> shows the data statistics.</p><p>Following previous practice on AL with PA ( <ref type="bibr" target="#b37">Sassano and Kurohashi, 2010;</ref><ref type="bibr" target="#b6">Flannery and Mori, 2015)</ref>, we adopt the following AL settings for both Chinese and English . The first 500 training sentences are used as the seed labeled data L. In the case of FA, K = 500 new sentences are selected and annotated at each iteration. In the case of single dependency-wise PA, we select and annotate M = 10, 000 dependencies, which roughly correspond to 500 sentences considering that the averaged sentence length is about 22.3 in CTB -train and 23.2 in PTB -train. In the case of batch dependency-wise PA, we set K = 500, and r = 20% for Chinese and r = 10% for English, considering that the parser trained on all data achieves about 80% and 90% accuracies. We measure parsing performance using the standard unlabeled attachment score (UAS) including punctuation marks. Please note that we always treat punctuation marks as ordinary words when selecting annotation tasks and calculating UAS, in order to make fair comparison between FA and PA. <ref type="bibr">7</ref> 4.1 FA vs. Single Dependency-wise PA First, we make comparison on the performance of AL with FA and with single dependency-wise PA.</p><p>Results on Chinese are shown in <ref type="figure" target="#fig_0">Figure 3</ref>. Following previous work, we use the number of annotated dependencies (x-axis) as the annotation cost in order to fairly compare FA and PA. We use FA with random selection as a baseline. We also draw the accuracy of the CRF-based parser trained on all training data, which can be regarded as the upper bound.</p><p>For FA, the curve of the normalized tree score intertwines with that of random selection. Mean- while, the performance of normalized tree prob- ability is very close to that of averaged marginal probability, and both are clearly superior to the baseline with random selection.</p><p>For PA, the difference among the three uncer- tainty metrics is small. The marginal probability gap clearly outperforms the other two metrics be- fore 50, 000 annotated dependencies, and remains   very competitive at all other points. The marginal probability max achieves best peak UAS, and even outperforms the parser trained on all data, which can be explained by small disturbance during complex model training. The marginal probability entropy, although being the most complex metric among the three, seems inferior all the time. It is clear that using PA can greatly reduce annotation effort compared with using FA in terms of annotated dependencies.</p><p>Results on English are shown in <ref type="figure" target="#fig_2">Figure 4</ref>. The overall findings are similar to those in <ref type="figure" target="#fig_0">Figure 3</ref>, ex- cept that the distinction among different methods is more clear. For FA, normalized tree score is consistently better than the random baseline. Normalized tree probability always outperforms normalized tree score. Averaged marginal proba- bility performs best, except being slightly inferior to normalized tree probability in earlier stages.</p><p>For PA, it is consistent that marginal probability gap is better than marginal probability max, and marginal probability entropy is the worst.</p><p>In summary, based on the results on the de-   908,154 = 10% on English, to reach the same per- formance with parsers trained on all data. More- over, the PA methods converges much faster than the FA ones, since for the same x-axis number, much more sentences (with partial trees) are used as training data for AL with PA than FA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Single vs. Batch Dependency-wise PA</head><p>Then we make comparison on AL with single dependency-wise PA and with the more practical batch dependency-wise PA.</p><p>Results on Chinese are shown in <ref type="figure" target="#fig_3">Figure 5</ref>. We can see that the three strategies achieve very sim- ilar performance and are also very close to single dependency-wise PA. AL with batch dependency- wise PA even achieves higher accuracy before 20, 000 annotated dependencies, which should be caused by the smaller active learning steps (about 2, 000 dependencies at each iteration, contrasting 10, 000 for single dependency-wise PA). When the training data runs out at about 7, 300 dependen- cies, AL with batch dependency-wise PA only lags behind with single dependency-wise PA by about 0.3%, which we suppose can be reduced if larger training data is available.</p><p>Results on English are shown in <ref type="figure" target="#fig_5">Figure 6</ref>, and are very similar to those on Chinese. One tiny difference is that the marginal probability gap is slightly worse that the other two metrics. The three uncertainty metrics have very similar accuracy curves, which are also very close to the curve of single dependency-wise PA. In addition, we also try r = 20% and find that results are inferior to r = 10%, indicating that the extra 10% annotation tasks are less valuable and contributive. <ref type="table" target="#tab_3">Table 2</ref> shows the results on test data. We compare our CRF-based parser with ZPar v6.0 8 , a state-of- the-art transition-based dependency parser ( <ref type="bibr" target="#b44">Zhang and Nivre, 2011</ref>). We train ZPar with default parameter settings for 50 iterations, and choose the model that performs best on dev data. We can see that when trained on all data, our CRF- based parser outperforms ZPar on both Chinese and English.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Main Results on Test Data</head><p>To compare FA and PA, we report the number of annotated dependencies needed under each AL strategy to achieve an accuracy lower by about 1% than the parser trained on all data. <ref type="bibr">9</ref> FA (best) refers to FA with averaged marginal probability, and it needs <ref type="bibr">187,123−149,051 187,123</ref> = 20.3% less annotated dependencies than FA with ran- dom selection on Chinese, and <ref type="bibr">395,199−197,907 395,199</ref> = 50.0% less on English.</p><p>PA (single) with marginal probability gap needs 149,051−50,958 149,051 = 65.8% less annotated dependencies than FA (best) on <ref type="bibr">Chinese, and 197,907−61,448 197,907</ref> = 69.0% less on English. PA (batch) with marginal probability gap needs slightly more annotation than PA (single) on Chi- nese but slightly less annotation on English, and can reduce the amount of annotated dependencies by <ref type="bibr">149</ref>  <ref type="bibr">9</ref> The gap 1% is chosen based on the curves on development data <ref type="figure" target="#fig_0">(Figure 3 and 4)</ref> with the following two considerations: 1) larger gap may lead to wrong impression that AL is weak; 2) smaller gap (e.g., 0.5%) cannot be reached for the worst AL method (FA: random).  = 74.2% on English.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Human Annotation Experiments</head><p>So far, we measure annotation effort in terms of the number of annotated dependencies and assume that it takes the same amount of time to annotate different words, which is obviously unrealistic. To understand whether active learning based on PA can really reduce annotation time over based on FA in practice, we build a web browser based annotation system, 10 and conduct human annotation experiments on Chinese.</p><p>In this part, we use CTB 7.0 which is a newer and larger version and covers more genres, and adopt the newly proposed Stanford dependencies ( <ref type="bibr" target="#b3">de Marneffe and Manning, 2008;</ref><ref type="bibr" target="#b1">Chang et al., 2009</ref>) which are more understandable for anno- tators. <ref type="bibr">11</ref> Since manual syntactic annotation is very difficult and time-consuming, we only keep sentences with length <ref type="bibr">[10,</ref><ref type="bibr">20]</ref> in order to better measure annotation time by focusing on sentences of reasonable length, which leave us 12, 912 train- ing sentences under the official data split. Then, we use a random half of training sentences to train a CRF-based parser, and select 20% most uncertain words with marginal probability gap for each sentence of the left half.</p><p>We employ 6 postgraduate students as our an- notators who are at different levels of familiarity in syntactic annotation. Before annotation, the annotators are trained for about two hours by introducing the basic concepts, guidelines, and il- lustrating examples. Then, they are asked to prac- tice on the annotation system for about another two hours. Finally, all annotators are required to  formally annotate the same 100 sentences. The system is programed that each sentence has 3 FA submissions and 3 PA submissions. During formal annotation, the annotators are not allowed to discuss with each other or look up any guide- line or documents, which may incur unnecessary inaccuracy in timing. Instead, the annotators can only decide the syntactic structures based on the basic knowledge of dependency grammar and one's understanding of the sentence structure. The annotation process lasts for about 5 hours. On average, each annotator completes 50 sentences with FA (763 dependencies) and 50 sentences with PA (178 dependencies). <ref type="table" target="#tab_5">Table 3</ref> lists the results in descending order of an annotator's experience in syntactic annotation. The first two columns compare the time needed for annotating a dependency in seconds. On average, annotating a dependency in PA takes about twice as much time as in FA, which is reasonable con- sidering the words to be annotated in PA may be more difficult for annotators while the annotation of some tasks in FA may be very trivial and easy. Combined with the results in <ref type="table" target="#tab_3">Table 2</ref>, we may infer that to achieve 77.3% accuracy on CTB -test, AL with FA requires 149, 051 × 6.7 = 998, 641.7 seconds of annotation, whereas AL with batch dependency-wise PA needs 56, 389 × 13.6 = 766, 890.4 seconds. Thus, we may roughly say that AL with PA can reduce annotation time over FA by <ref type="bibr">998,641.7−766,890.4</ref> 998,641.7 = 23.2%. We also report annotation accuracy according to the gold-standard Stanford dependencies con- verted from bracketed structures. <ref type="bibr">12</ref> Overall, the accuracy of FA is 70.36 − 59.06 = 11.30% higher <ref type="bibr">12</ref> An anonymous reviewer commented that the direct comparison between an annotator's performance on PA and FA based on accuracy may be misleading since the FA and PA sentences for one annotator are mutually exclusive. than that of PA, which should be due to the trivial tasks in FA. To be more fair, we compare the accuracies of FA and PA on the same 20% selected difficult words, and find that annotators exhibit different responses to the switch. Annotator #4 achieve 12.58% higher accuracy when under PA than under FA. The reason may be that under PA, annotators can be more focused and therefore per- form better on the few selected tasks. In contrast, some annotators may perform better under FA. For example, annotation accuracy of annotator #2 increases by 10.04% when switching from PA to FA, which may be due to that FA allows annotators to spend more time on the same sentence and gain help from annotating easier tasks. Overall, we find that the accuracy of PA is 59.06 − 57.28 = 1.78% higher than that of FA, indicating that PA actually can improve annotation quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Recently, AL with PA attracts much attention in sentence-wise natural language processing such as sequence labeling and parsing. For sequence labeling, Marcheggiani andArtì eres (2014) sys- tematically compare a dozen uncertainty metrics in token-wise AL with PA (without comparison with FA), whereas <ref type="bibr" target="#b38">Settles and Craven (2008)</ref> in- vestigate different uncertainty metrics in AL with FA. <ref type="bibr" target="#b16">Li et al. (2012)</ref> propose to only annotate the most uncertain word boundaries in a sentence for Chinese word segmentation and show promising results on both simulation and human annotation experiments. All above works are based on CRFs and make extensive use of sequence probabilities and token marginal probability.</p><p>In parsing community, <ref type="bibr" target="#b37">Sassano and Kurohashi (2010)</ref> select bunsetsu (similar to phrases) pairs with smallest scores from a local classifier, and let annotators decide whether the pair composes a dependency. They convert partially annotated instances into local dependency/non-dependency classification instances to help a simple shift- reduce parser. Mirroshandel and Nasr (2011) select most uncertain words based on votes of n- best parsers, and convert partial trees into full trees by letting a baseline parser perform constrained decoding in order to preserve partial annotation. Under a different query-by-committee AL frame- work, Majidi and Crane (2013) select most uncer- tain words using a committee of diverse parsers, and convert partial trees into full trees by letting the parsers of committee to decide the heads of remaining tokens. Based on a first-order (point- wise) Japanese parser, <ref type="bibr" target="#b6">Flannery and Mori (2015)</ref> use scores of a local classifier for task selection, and treat PA as dependency/non-dependency in- stances <ref type="bibr" target="#b7">(Flannery et al., 2011</ref>). Different from above works, this work adopts a state-of-the-art probabilistic dependency parser, uses more prin- cipled tree probabilities and dependency marginal probabilities for uncertainty measurement, and learns from PA based on a forest-based training objective which is more theoretically sound.</p><p>Most previous works on AL with PA only con- duct simulation experiments. <ref type="bibr" target="#b6">Flannery and Mori (2015)</ref> perform human annotation to measure true annotation time. A single annotator is employed to annotate for two hours alternating FA and PA (33% batch) every fifteen minutes. Beyond their initial expectation, they find that the annotation time per dependency is nearly the same for FA and PA (different from our findings) and gives a few interesting explanations.</p><p>Under a non-AL framework, <ref type="bibr" target="#b29">Mejer and Crammer (2012)</ref> propose an interesting light feedback scheme for dependency parsing by letting annota- tors decide the better one from top-2 parse trees produced by the current parsing model. <ref type="bibr" target="#b10">Hwa (1999)</ref> pioneers the idea of using PA to reduce manual labeling effort for constituent grammar induction. She uses a variant Inside- Outside re-estimation algorithm <ref type="bibr" target="#b33">(Pereira and Schabes, 1992</ref>) to induce a grammar from PA. <ref type="bibr" target="#b2">Clark and Curran (2006)</ref> propose to train a Combina- torial Categorial Grammar parser using partially labeled data only containing predicate-argument dependencies. <ref type="bibr" target="#b42">Tsuboi et al. (2008)</ref> extend CRF- based sequence labeling models to learn from incomplete annotations, which is the same with <ref type="bibr">Marcheggiani andArtì eres (2014)</ref>. <ref type="bibr" target="#b17">Li et al. (2014)</ref> propose a CRF-based dependency parser that can learn from partial tree projected from source- language structures in the cross-lingual parsing scenario. <ref type="bibr" target="#b30">Mielens et al. (2015)</ref> propose to impute missing dependencies based on Gibbs sampling in order to enable traditional parsers to learn from partial trees.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>This paper for the first time applies a state-of- the-art probabilistic model to AL with PA for dependency parsing. It is shown that the CRF- based parser can on the one hand provide tree probabilities and dependency marginal probabili- ties as principled uncertainty metrics and on the other hand elegantly learn from partially annotated data. We have proposed and compared several un- certainty metrics through simulation experiments, and show that AL with PA can greatly reduce the amount of annotated dependencies by 62.2% on Chinese 74.2% on English. Finally, we con- duct human annotation experiments on Chinese to compare PA and FA on real annotation time and quality. We find that annotating a dependency in PA takes about 2 times long as in FA. This sug- gests that AL with PA can reduce annotation time by 23.2% over with FA on Chinese. Moreover, the results also indicate that annotators tend to perform better under PA than FA.</p><p>For future work, we would like to advance this study in the following directions. The first idea is to combine uncertainty and representativeness for measuring informativeness of annotation targets in concern. Intuitively, it would be more profitable to annotate instances that are both difficult for the current model and representative in capturing common language phenomena. Second, we so far assume that the selected tasks are equally difficult and take the same amount of effort for human annotators. However, it is more reasonable that human are good at resolving some ambiguities but bad at others. Our plan is to study which syntactic structures are more suitable for human annotation, and balance informativeness of a candidate task and its suitability for human annotation. Finally, one anonymous reviewer comments that we may use automatically projected trees <ref type="bibr" target="#b35">(Rasooli and Collins, 2015;</ref><ref type="bibr" target="#b9">Guo et al., 2015;</ref><ref type="bibr" target="#b20">Ma and Xia, 2014)</ref> as the initial seed labeled data, which is cheap and interesting.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: FA vs. PA on CTB-dev.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: FA vs. PA on PTB-dev.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Single vs. batch dependency-wise PA on CTB-dev.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Number of Annotated Dependencies Parser trained on all data PA (single): marginal probability gap PA (batch 10%): marginal probability gap PA (batch 10%): averaged marginal probability PA (batch 10%): averaged marginal probability &amp; gap PA (batch 20%): marginal probability gap</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Single vs. batch dependency-wise PA on PTB-dev.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Results on test data. 

nese and by 197,907−51,016 

197,907 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 : Statistics of human annotation.</head><label>3</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="1"> In this work, we follow many previous works to focus on unlabeled dependency parsing (constructing the skeleton dependency structure). However, the proposed techniques</note>

			<note place="foot" n="3"> We have also tried replacing n 1.5 with n (still prefer short sentences) and n 2 (bias to long sentences). 4 We have also tried p(d * |x) × f (n), where f (n) = log n or f (n) = √ n, but both work badly. 5 We have also tried n √ ∏ h↷m∈d * p(h ↷ m|x), leading to slightly inferior results.</note>

			<note place="foot" n="6"> This work focuses on projective dependency parsing. Please refer to Koo et al. (2007), McDonald and Satta (2007), and Smith and Smith (2007) for building a probabilistic nonprojective parser.</note>

			<note place="foot" n="7"> Alternatively, we can exclude punctuation marks for task selection in AL with PA. Then, to be fair, we have to discard all dependencies pointing to punctuation marks in the case of FA. This makes the experiment setting more complicated.</note>

			<note place="foot" n="10"> http://hlt-service.suda.edu.cn/ syn-dep-batch. Please try. 11 We use Stanford Parser 3.4 (2014-06-16) for constituentto-dependency structure conversion.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors would like to thank the anonymous reviewers for the helpful comments. We also thank Junhui Li and Chunyu Kit for reading our paper and giving many good suggestions. Particularly, Zhenghua is very grateful to many of his students: Fangli Lu, Qiuyi Yan, and Yue Zhang build the an-notation system; Jiayuan Chao, Wei Chen, Ziwei Fan, Die Hu, Qingrong Xia, and Yue Zhang partic-ipate in data annotation. This work was supported by National Natural Science Foundation of China <ref type="bibr">(Grant No. 61502325, 61525205, 61572338</ref>).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<title level="m">Proceedings of COLING</title>
		<meeting>COLING</meeting>
		<imprint>
			<biblScope unit="page" from="89" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Discriminative reordering with Chinese grammatical relations features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pi-Chuan</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huihsin</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Workshop on Syntax and Structure in Statistical Translation (SSST-3) at NAACL HLT 2009</title>
		<meeting>the Third Workshop on Syntax and Structure in Statistical Translation (SSST-3) at NAACL HLT 2009</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="51" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Partial training for a lexicalized-grammar parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Curran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Human Language Technology Conference of the NAACL</title>
		<meeting>the Human Language Technology Conference of the NAACL</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="144" to="151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The Stanford typed dependencies representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Catherine</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Coling 2008: Proceedings of the workshop on Cross-Framework and Cross-Domain Parser Evaluation</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Frustratingly hard domain adaptation for dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><forename type="middle">Pratim</forename><surname>Talukdar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuzman</forename><surname>Ganchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">João</forename><surname>Graca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL</title>
		<meeting>the CoNLL Shared Task Session of EMNLP-CoNLL</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Bilexical grammars and their cubic-time parsing algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Probabilistic and Other Parsing Technologies</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="29" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Combining active learning and partial annotation for domain adaptation of a japanese dependency parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Flannery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinsuke</forename><surname>Mori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International Conference on Parsing Technologies</title>
		<meeting>the 14th International Conference on Parsing Technologies</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="11" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Training dependency parsers from partially annotated corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Flannery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuke</forename><surname>Miayo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinsuke</forename><surname>Mori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCNLP</title>
		<meeting>IJCNLP</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="776" to="784" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">From news to comment: Resources and benchmarks for parsing the language of web 2.0</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozlem</forename><surname>Cetinoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">Le</forename><surname>Roux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deirdre</forename><surname>Hogan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Van Genabith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCNLP</title>
		<meeting>IJCNLP</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="893" to="901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Cross-lingual dependency parsing based on distributed representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1234" to="1244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Supervised grammar induction using training data with limited constituent information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Hwa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="73" to="79" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Sample selection for statistical parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Hwa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computional Linguistics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="253" to="276" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A dependency parser for tweets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingpeng</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swabha</forename><surname>Swayamdipta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Archna</forename><surname>Bhatia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1001" to="1012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Efficient thirdorder dependency parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Structured prediction models via the matrix-tree theorem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Globerson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Carreras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-CoNLL</title>
		<meeting>EMNLP-CoNLL</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="141" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A sequential algorithm for training text classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">A</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="3" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Active learning for Chinese word segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shoushan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chu-Ren</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2012: Posters</title>
		<meeting>COLING 2012: Posters</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="683" to="692" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Soft cross-lingual syntax projection for dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenghua</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenliang</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="783" to="793" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teresa</forename><surname>Lynn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Foster</surname></persName>
		</author>
		<imprint>
			<pubPlace>Mark Dras, and Elaine U ´ 1</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Active learning and the irish treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dhonnchadha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ALTA</title>
		<meeting>ALTA</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Unsupervised dependency parsing with transferring distribution via parallel guidance and entropy regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1337" to="1348" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Probabilistic models for high-order projective dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<idno>abs/1502.04174</idno>
	</analytic>
	<monogr>
		<title level="j">Arxiv</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Active learning for dependency parsing by a committee of parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saeed</forename><surname>Majidi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Crane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IWPT</title>
		<meeting>IWPT</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="98" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">An experimental comparison of active learning strategies for partially labeled sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Marcheggiani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thierryartì</forename><surname>Eres</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="898" to="906" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kamal</forename><surname>Nigam</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Employing EM and pool-based active learning for text classification</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<biblScope unit="page" from="350" to="358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Online learning of approximate dependency parsing algorithms</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EACL</title>
		<meeting>EACL</meeting>
		<imprint>
			<biblScope unit="page" from="81" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">On the complexity of non-projective data-driven dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgio</forename><surname>Satta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Conference on Parsing Technologies</title>
		<meeting>the Tenth International Conference on Parsing Technologies</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="121" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Training dependency parser using light feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avihai</forename><surname>Mejer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Parse imputation for dependency annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Mielens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Baldridge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-IJCNLP</title>
		<meeting>ACL-IJCNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1385" to="1394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Active learning for dependency parsing using partially annotated sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abolghasem</forename><surname>Seyed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Mirroshandel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nasr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th International Conference on Parsing Technologies</title>
		<meeting>the 12th International Conference on Parsing Technologies</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="140" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">A literature survey of active machine learning in the context of natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fredrik</forename><surname>Olsson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
		<respStmt>
			<orgName>Swedish Institute of Computer Science</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Insideoutside reestimation from partially bracketed corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yves</forename><surname>Schabes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Speech and Natural Language (HLT)</title>
		<meeting>the Workshop on Speech and Natural Language (HLT)</meeting>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="122" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Overview of the 2012 shared task on parsing the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Notes of the First Workshop on Syntactic Analysis of NonCanonical Language (SANCL)</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Density-driven cross-lingual transfer of dependency parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Sadegh Rasooli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="328" to="338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Parsing the wall street journal using a lexical-functional grammar and discriminative estimation techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Riezler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tracy</forename><forename type="middle">H</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><forename type="middle">M</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Crouch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">T</forename><surname>Maxwell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 40th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>40th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="271" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Using smaller constituents rather than sentences in active learning for japanese dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manabu</forename><surname>Sassano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="356" to="365" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">An analysis of active learning strategies for sequence labeling tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Burr</forename><surname>Settles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Craven</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1070" to="1079" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Probabilistic models of nonprojective dependency trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-CoNLL</title>
		<meeting>EMNLP-CoNLL</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="132" to="140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Target language adaptation of discriminative transfer parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Täckström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1061" to="1071" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Active learning for statistical natural language parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoqiang</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="120" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Training conditional random fields using incomplete annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuta</forename><surname>Tsuboi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hisashi</forename><surname>Kashima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroki</forename><surname>Oda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinsuke</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING</title>
		<meeting>COLING</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="897" to="904" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Dependency parsing for weibo: An efficient probabilistic logic programming approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William Yang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingpeng</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathryn</forename><surname>Mazaitis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William W</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1152" to="1158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Transition-based dependency parsing with rich non-local features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="188" to="193" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
