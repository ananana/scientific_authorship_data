<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:01+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Adaptive HTER Estimation for Document-Specific MT Post-Editing</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>June 23-25 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Huang</surname></persName>
							<email>feihuang@fb.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">IBM T.J. Watson Research Center Yorktown Heights</orgName>
								<orgName type="institution">Facebook Inc</orgName>
								<address>
									<settlement>Menlo Park</settlement>
									<region>CA, NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Ming</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">IBM T.J. Watson Research Center Yorktown Heights</orgName>
								<orgName type="institution">Facebook Inc</orgName>
								<address>
									<settlement>Menlo Park</settlement>
									<region>CA, NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abraham</forename><surname>Ittycheriah</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">IBM T.J. Watson Research Center Yorktown Heights</orgName>
								<orgName type="institution">Facebook Inc</orgName>
								<address>
									<settlement>Menlo Park</settlement>
									<region>CA, NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">IBM T.J. Watson Research Center Yorktown Heights</orgName>
								<orgName type="institution">Facebook Inc</orgName>
								<address>
									<settlement>Menlo Park</settlement>
									<region>CA, NY</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Adaptive HTER Estimation for Document-Specific MT Post-Editing</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="861" to="870"/>
							<date type="published">June 23-25 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present an adaptive translation quality estimation (QE) method to predict the human-targeted translation error rate (HTER) for a document-specific machine translation model. We first introduce features derived internal to the translation decoding process as well as externally from the source sentence analysis. We show the effectiveness of such features in both classification and regression of MT quality. By dynamically training the QE model for the document-specific MT model, we are able to achieve consistency and prediction quality across multiple documents, demonstrated by the higher correlation coefficient and F-scores in finding Good sentences. Additionally, the proposed method is applied to IBM English-to-Japanese MT post editing field study and we observe strong correlation with human preference, with a 10% increase in human translators&apos; productivity.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Machine translation (MT) systems suffer from an inconsistent and unstable translation quality. De- pending on the difficulty of the input sentences (sentence length, OOV words, complex sentence structures and the coverage of the MT system's training data), some translation outputs can be per- fect, while others are ungrammatical, missing im- portant words or even totally garbled. As a result, users do not know whether they can trust the trans- lation output unless they spend time to analyze * This work was done when the author was with IBM Re- search.</p><p>the MT output. This shortcoming is one of the main obstacles for the adoption of MT systems, especially in machine assisted human translation: MT post-editing, where human translators have an option to edit MT proposals or translate from scratch. It has been observed that human trans- lators often discard MT proposals even if some are very accurate. If MT proposals are used prop- erly, post-editing can increase translators produc- tivity and lead to significant cost savings. There- fore, it is beneficial to provide MT confidence es- timation, to help the translators to decide whether to accept MT proposals, making minor modifica- tions on MT proposals when the quality is high or translating from scratching when the quality is low. This will save the time of reading and parsing low quality MT and improve user experience.</p><p>In this paper we propose an adaptive qual- ity estimation that predicts sentence-level human- targeted translation error rate (HTER) <ref type="bibr" target="#b18">(Snover et al., 2006</ref>) for a document-specific MT post-editing system. HTER is an ideal quality measurement for MT post editing since the reference is ob- tained from human correction of the MT output. Document-specific MT model is an MT model that is specifically built for the given input document. It is demonstrated in <ref type="bibr" target="#b16">(Roukos et al., 2012</ref>) that document-specific MT models significantly im- prove the translation quality. However, this raises two issues for quality estimation. First, existing approaches to MT quality estimation rely on lex- ical and syntactical features defined over parallel sentence pairs, which includes source sentences, MT outputs and references, and translation models ( <ref type="bibr" target="#b2">Blatz et al., 2004;</ref><ref type="bibr" target="#b23">Ueffing and Ney, 2007;</ref><ref type="bibr" target="#b21">Specia et al., 2009a;</ref><ref type="bibr" target="#b25">Xiong et al., 2010;</ref><ref type="bibr" target="#b19">Soricut and Echihabi, 2010a;</ref><ref type="bibr" target="#b0">Bach et al., 2011</ref>). Therefore, when the MT quality estimation model is trained, it can not be adapted to provide accurate estimates on the outputs of document-specific MT models. Second, the MT quality estimation might be in- consistent across different document-specific MT models, thus the confidence score is unreliable and not very helpful to users.</p><p>In contrast to traditional static MT quality es- timation methods, our approach not only trains the MT quality estimator dynamically for each document-specific MT model to obtain higher pre- diction accuracy, but also achieves consistency over different document-specific MT models. The experiments show that our MT quality estima- tion is highly correlated with human judgment and helps translators to increase the MT proposal adoption rate in post-editing.</p><p>We will review related work on MT quality es- timation in section 2. In section 3 we will intro- duce the document-specific MT system built for post-editing. We describe the static quality estima- tion method in section 4, and propose the adaptive quality estimation method in section 5. In section 6 we demonstrate the improvement of MT quality estimation with our method, followed by discus- sion and conclusion in section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>There has been a long history of study in con- fidence estimation of machine translation. The work of <ref type="bibr" target="#b2">(Blatz et al., 2004</ref>) is among the best known study of sentence and word level features for translation error prediction. Along this line of research, improvements can be obtained by incor- porating more features as shown in <ref type="bibr" target="#b14">(Quirk, 2004;</ref><ref type="bibr" target="#b17">Sanchis et al., 2007;</ref><ref type="bibr" target="#b15">Raybaud et al., 2009;</ref><ref type="bibr" target="#b22">Specia et al., 2009b</ref>). Soricut and Echihabi (2010b) pro- posed various regression models to predict the ex- pected BLEU score of a given sentence translation hypothesis. <ref type="bibr">Ueffing and Hey (2007)</ref> introduced word posterior probabilities (WPP) features and applied them in the n-best list reranking. Target part-of-speech and null dependency link are ex- ploited in a MaxEnt classifier to improve the MT quality estimation ( <ref type="bibr" target="#b25">Xiong et al., 2010)</ref>.</p><p>Quality estimation focusing on MT post-editing has been an active research topic, especially after the WMT 2012 <ref type="bibr" target="#b4">(Callison-Burch et al., 2012</ref>) and WMT2013 ( <ref type="bibr" target="#b3">Bojar et al., 2013</ref>) workshops with the "Quality Estimation" shared task. <ref type="bibr" target="#b1">Biçici et al. (2013)</ref> proposes a number of features mea- suring the similarity of the source sentence to the source side of the MT training corpus, which, combined with features from translation output, achieved significantly superior performance in the MT QE evaluation. <ref type="bibr" target="#b5">Felice and Specia (2012)</ref> in- vestigates the impact of a large set of linguisti- cally inspired features on quality estimation accu- racy, which are not able to outperform the shal- lower features based on word statistics. <ref type="bibr">GonzálezRubio et al. (2013)</ref> proposed a principled method for performing regression for quality estimation using dimensionality reduction techniques based on partial least squares regression. Given the fea- ture redundancy in MT QE, their approach is able to improve prediction accuracy while significantly reducing the size of the feature sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Document-specific MT System</head><p>In our MT post-editing setup, we are given docu- ments in the domain of software manuals, techni- cal outlook or customer support materials. Each translation request comes as a document with sev- eral thousand sentences, focusing on a specific topic, such as the user manual of some software.</p><p>The input documents are automatically seg- mented into sentences, which are also called seg- ments. Thus in the rest of the paper we will use sentences and segments interchangeably. Our par- allel corpora includes tens of millions of sentence pairs covering a wide range of topics. Building a general MT system using all the parallel data not only produces a huge translation model (unless with very aggressive pruning), the performance on the given input document is suboptimal due to the unwanted dominance of out-of-domain data. Past research suggests using weighted sentences or cor- pora for domain adaptation ( <ref type="bibr" target="#b12">Lu et al., 2007;</ref><ref type="bibr" target="#b13">Matsoukas et al., 2009;</ref><ref type="bibr" target="#b6">Foster et al., 2010</ref>). Here we adopt the same strategy, building a document- specific translation model for each input docu- ment.</p><p>The document-specific system is built based on sub-sampling: from the parallel corpora we se- lect sentence pairs that are the most similar to the sentences from the input document, then build the MT system with the sub-sampled sentence pairs. The similarity is defined as the number of n-grams that appear in both source sentences, di- vided by the input sentence's length, with higher weights assigned to longer n-grams. From the extracted sentence pairs, we utilize the standard pipeline in SMT system building: word align- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">MT Decoder</head><p>The MT decoder <ref type="bibr" target="#b11">(Ittycheriah and Roukos, 2007)</ref> employed in our study extracts various features (source words, morphemes and POS tags, target words and POS tags, etc.) with their weights trained in a maximum entropy framework. These features are combined with other features used in a typical phrase-based translation system. Alto- gether the decoder incorporates 17 features with weights estimated by PRO ( <ref type="bibr" target="#b9">Hopkins and May, 2011</ref>) in the decoding process, and achieves state-of-the-art translation performance in vari- ous Arabic-English translation evaluations (NIST MT2008, GALE and BOLT projects).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Static MT Quality Estimation</head><p>MT quality estimation is typically formulated as a prediction problem: estimating the confidence score or translation error rate of the translated sen- tences or documents based on a set of features. In this work, we adopt HTER in <ref type="bibr" target="#b18">(Snover et al., 2006</ref>) as our prediction output. HTER measures the per- centage of insertions, deletions, substitutions and shifts needed to correct the MT outputs. In the rest of the paper, we use TER and HTER inter- changably.</p><p>In this section we will first introduce the set of features, and then discuss MT QE problem from classification and regression point of views.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Features for MT QE</head><p>The features for quality estimation should reflect the complexity of the source sentence and the de- coding process. Therefore we conduct syntactic analysis on the source sentences, extract features from the decoding process and select the follow- ing 26 features:</p><p>• 17 decoding features, including phrase translation probabilities (source-to-target and target-to-source), word translation probabil- ities (also in both directions), maxent prob- abilities 1 , word count, phrase count, distor- <ref type="bibr">1</ref> The maxent probability is the translation probability tion probabilities, as well as a set of language model scores.</p><p>• Sentence length, i.e., the number of words in the source sentence.</p><p>• Source sentence syntactic features, including the number of noun phrases, verb phrases, adjective phrases, adverb phrases, as in- spired by <ref type="bibr" target="#b8">(Green et al., 2013</ref>).</p><p>• The length of verb phrases, because verbs are typically the roots in dependency structure and they have more varieties during transla- tion.</p><p>• The maximum length of source phrases in the final translation, since longer matching source phrase indicates better coverage of the input sentence with possibly better transla- tions.</p><p>• The number of phrase pairs with high fuzzy match (FM) score. The high FM phrases are selected from sentence pairs which are clos- est in terms of n-gram overlap to the input sentence. These sentences are often found in previous translations of the software manual, and thus are very helpful for translating the current sentence.</p><p>• The average translation probability of the phrase translation pairs in the final transla- tion, which provides the overall translation quality on the phrase level.</p><p>The first 17 features come from the decod- ing process, which are called "decoding features". The remaining 9 features not related to the de- coder are called "external features". To evaluate the effectiveness of the proposed features, we train various classifiers with different feature configura- tions to predict whether a translation output is use- ful (with lower TER) as described in the following section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">MT QE as Classification</head><p>Predicting TER with various input features can be treated as a regression problem. However for the post-editing task, we argue that it could also be cast as a classification problem: MT system derived from a Maximum Entropy translation model <ref type="bibr" target="#b10">(Ittycheriah and Roukos, 2005</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Configuration</head><p>Training set Test set Baseline <ref type="table" target="#tab_1">(All negative)  80%  77%  17 decoding features only  89%  79%  9 external features only  85%  81%  total 26 features  92%  83%   Table 1</ref>: QE classification accuracy with different feature configurations users (including the translators) are often inter- ested to know whether a given translation is rea- sonably good or not. If useful, they can quickly look through the translation and make minor mod- ifications. On the other hand, they will just skip reading and parsing the bad translation, and prefer to translate by themselves from scratch. Therefore we also develop algorithms that classify the trans- lation at different levels, depending on whether the TER is less than a given threshold. In our experi- ments, we set TER=0.1 as the threshold.</p><p>We randomly select one input document with 2067 sentences for the experiment. We build a document-specific MT system to translate this document, then ask human translator to correct the translation output. We compute TER for each sentence using the human correction as the refer- ence. The TER of the whole document is 0.31, which means about 30% errors should be cor- rected. In the classification task, our goal is to pre- dict whether a sentence is a Good translation (with TER ≤ 0.1), and label them for human correction. We adopt a decision tree-based classifier, experi- menting with different feature configurations. We select the top 1867 sentences for training and the bottom 200 sentences for test. In the test set, there are 46 sentences with TER ≤ 0.1. <ref type="table">Table 1</ref> shows the classification accuracy.</p><p>First we can see that as the overall TER is around 0.3, predicting all the sentences being neg- ative already has a strong baseline: 77%. How- ever this is not helpful for the human translators, because that means they have to translate every sentence from scratch, and consequently there is no productivity gain from MT post-editing. If we only use the 17 decoding features, it improves the classification accuracy by 9% on the training set, but only 2% on the test set. This is probably due to the overfitting when training the decision tree clas- sifier. While using the 7 external features, the gain on training set is less but the gain on the test set is greater (4% improvement), because the trans- lation output is generated based on the log-linear combination of these decoding features, which are biased towards the final translations. The exter- nal features capture the syntactic structure of the source sentence, as well as the coverage of the training data with regard to the input sentence, which are good indicators of the translation qual- ity. Combining both the decoding features and the external features, we observed the best accuracy on both the training and test set. We will use the combined 26 features in the following work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">MT QE as Regression</head><p>For the QE regression task, we predict the TER for each sentence translation using the above 26 fea- tures. We experiment with several classifiers: lin- ear regression model, decision tree based regres- sion model and SVM model. With the same train- ing and test data set up, we predict the TER for each sentence in the test set, and compute the cor- relation coefficient (r) and root mean square error (RMSE). Our experiments show that the decision tree-based regression model obtains the highest correlation coefficients (0.53) and lowest RMSE (0.23) in both the training and test sets. We will use this model for the adaptive MT QE in the fol- lowing work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Adaptive MT Quality Estimation</head><p>The above QE regression model is trained on a portion of the sentences from the input document, and evaluated on the remaining sentences from the same document. One would like to know whether the trained model can achieve consistent TER pre- diction accuracy on other documents. When we use the cross-document models for prediction, the correlation is significantly worse (the details are discussed in section 6.1). Therefore it is neces- sary to build a QE regression model that's robust to different document-specific translation models. To deal with this problem, we propose this adap- tive MT QE method described below.</p><p>Our proposed method is as follows: we select a fixed set of sentence pairs (S q , R q ) to train the QE model. The source side of the QE training data S q is combined with the input document S d for MT system training data subsampling. Once the document-specific MT system is trained, we use it to translate both the input document and the source QE training data, obtaining the translation T d and T q . We compute the TER of T q using R q as the reference, and train a QE regression model with the 26 features proposed in section 4.1. Then we use this document-specific QE model to predict the TER of the document translation T d . As the QE model is adaptively re-trained for each document- specific MT system, its prediction is more accurate and consistent. <ref type="figure" target="#fig_0">Figure 1</ref> shows the flow of our MT system with the adaptive QE training integrated as part of the built.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head><p>In this section, we first discuss experiments that compare adaptive QE method and static QE method on a few documents, and then present results we obtained after deploying the adaptive QE method in an English-to-Japanese MT Post- Editing project. As mentioned before, the main motivation for us to develop MT QE classification scheme is that translators often discard good MT proposals and translate the segments from scratch. We would like to provide translators with some guidance on reasonably good MT proposals-the sentences with low TERs-to help them increase the leverage on MT proposals to achieve improved productivity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Evaluation on Test Set</head><p>Our experiment and evaluation is conducted over three documents, each with about 2000 segments. We first build document-specific MT model for each document, then ask human translators to cor- rect the MT outputs and obtain the reference trans- lation. In a typical MT QE scenario, the QE model is pre-trained and applied to various MT outputs, even though the QE training data and MT out- puts are generated from different translation mod- els. To evaluate whether such model mismatch matters, we compare the cross-model QE with the same-model QE, where the QE training data and the MT outputs are generated from the same MT model.</p><p>We select one document LZA with 2067 sen- tences. We use the first 1867 sentences to train the static QE model and the remaining 200 sentences are used as test set for TER prediction. We com- pute the correlation coefficient (r) between each predicted TER and true TER, as shown in <ref type="figure" target="#fig_1">Figure  2</ref>. We find that the TER predictions are reason- ably correct when the training and test sentences are from the same MT model (the top <ref type="figure">figure)</ref>, with correlation coefficients around 0.5. For the cross- model QE, we train a static QE model with 1867 sentences from another document RTW, and use it to predict the TER of the same 200 sentences from document LZA (the bottom <ref type="figure">figure)</ref>. We observe significant degradation of correlation coefficient, dropping from 0.5 to 0.1. This degradation and unstable nature is the prime motivation to develop a more robust MT quality estimation model. We select 1700 sentences from multiple pre- viously translated documents as the QE training data, which are independent of the test documents. We train the static QE model with this training set, including the source sentences, references and MT outputs (from multiple translation models). To train the adaptive QE model for each test docu- ment, we build a translation model whose subsam- pling data includes source sentences from both the test document and the QE training data. We trans- late the QE source sentences with this newly built MT model, and the translation output is used to train the QE model specific to each test document. We compare these two QE models on three doc- uments, LZA, RTW and WC7, measuring r and RMSE for each QE model. The result is shown in <ref type="table" target="#tab_1">Table 2</ref>. We find that the adaptive QE model demonstrates higher r and lower RMSE than the static QE model for all the test documents.</p><p>Besides the general correlation with human judgment, we particularly focus on those reason- ably good translations, i.e., the sentences with low TERs which can help improve the translator's pro- ductivity most. Here we report the precision, re- call and F-score of finding such "Good" sentences (with TER ≤ 0.1) on the three documents in <ref type="table">Ta- ble 3</ref>. Again, the adaptive QE model produces higher recall, mostly higher precision, and signif- icantly improved F-score. The overall F-score of the adaptive QE model is 0.28 2 . Compared with the static QE model's 0.17 F-score, this is rela- tively 64% improvement.</p><p>In the adaptive QE model, the source side QE training data is included in the subsampling pro- cess to build the document-specific MT model. It would be interesting to know whether this process will negatively affect the MT quality. We evaluate the TER of MT outputs with and without the adap- tive QE training on the same three documents. As seen in <ref type="table">Table 4</ref>, we do not notice translation qual- ity degradation. Instead, we observe slightly im- provement on two document, with TERs reduction by 0.1-0.4 pt. As our MT model training data in- clude proprietary data, the MT performance is sig- nificantly better than publicly available MT soft- ware.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Impact on Human Translators</head><p>We apply the proposed adaptive QE model to large scale English-to-Japanese MT Post-Editing project on 36 documents with 562K words. Each English sentence can be categorized into 3 classes:</p><p>• Exact Match (EM): the source sentence is completely covered in the bilingual training corpora thus the corresponding target sen- tence is returned as the translation;</p><p>• Fuzzy Match (FM): the source sentence is similar to some sentence in the training data (similarity measured by string editing dis- tance), the corresponding fuzzy match target sentence (FM proposal) as well as the MT translation output (MT proposal) are returned for human translators to select and correct;</p><p>• No Proposal (NP): there is no close match source sentences in the training data (the FM   <ref type="table">Table 3</ref>: Performance on predicting Good sentences with static and adaptive models similarity score of 70% is used as the thresh- old), therefore only the MT output is re- turned.</p><p>EM sentences are excluded from the study be- cause in general they do not require editing. We focus on the FM and NP sentences <ref type="bibr">3</ref> . In <ref type="table">Table 5</ref> we present the precision, recall and F-score of the "Good" sentences in the FM and NP categories, similar to those shown in <ref type="table">Table 3</ref>. We consistently observe higher performance on the FM sentences, in terms of precision, recall and F-score. This is expected because these sentences are well covered in the training data. The overall F-score is in line with the test set results shown in <ref type="table">Table 3</ref>.</p><p>We are also interested to know whether the pro- posed adaptive QE method is helpful to human translators in the MT post-editing task. Based on the TERs predicted by the adaptive QE model, we assign each MT proposal with a confidence label: High (0 ≤ TER ≤ 0.2), Medium (0.2 &lt; TER ≤ 0.3), or Low (TER &gt; 0.3). We present the MT pro- posals with confidence labels to human translators, then measure the percentage of sentences whose MT proposals are used. From <ref type="table" target="#tab_4">Table 6</ref> and 7, we can see that sentences with High and Medium confidence labels are more frequently used by the translators than those with Low labels, for both the FM and NP categories. The MT usage for the FM category is less than that for the NP category be- cause translators can choose FM proposals instead of the MT proposals for correction.</p><p>We also measure the translator's productivity gain for MT proposals with different confidence <ref type="bibr">3</ref> The word count distribution of EM, FM and NP is 21%, 38% and 41%, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Document</head><p>LZA  <ref type="table">Table 4</ref>: MT Quality with and without Adaptive QE measured by TER labels. The productivity of a translator is defined as the number of source words translated per unit time. The post editing tool, IBM TranslationMan- ager, records the time that a translator spends on a segment and computes the number of characters that a translator types on the segment so that we can compute how many words the translator has finished in a given time.</p><p>We choose the overall productivity of NP0 as the base unit 1, where there is no proposal presents and the translator has to translate the segments from scratch. Measured with this unit, for exam- ple, the overall productivity of FM0 being 1.14 implies a relative gain of 14% over that of NP0, which demonstrates the effectiveness of FM pro- posals. <ref type="table" target="#tab_4">Table 6</ref> and 7 also show the productivity gain on sentences with High, Medium and Low labels from FM and NP categories. Again, the produc- tivity gain is consistent with the confidence labels from the adaptive QE model's prediction. The overall productivity gain with confidence-labeled MT proposals is about 10% (comparing FM1 vs. FM0 and NP1 vs. NP0). These results clearly demonstrate the effectiveness of the adaptive QE model in aiding the translators to make use of MT proposals and improve productivity.   <ref type="table">Table 7</ref>: MT proposal usage and productivity gain in NP category. In NP1, MT is the only proposal available, while in control NP0, there presents no proposal at all and the translator has to translate from scratch. Strong correlation is observed between predicted "High" , "Medium" and "Low" sentences with MT usage and post editing productivity  <ref type="table">Table 5</ref>: Performance on predicting Good sen- tences (TER ≤ 0.1) by adaptive QE model</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Category</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Discussion and Conclusion</head><p>In this paper we proposed a method to adaptively train a quality estimation model for document- specific MT post editing. With the 26 pro- posed features derived from decoding process and source sentence syntactic analysis, the proposed QE model achieved better TER prediction, higher correlation with human correction of MT output and higher F-score in finding good translations.</p><p>The proposed adaptive QE model is deployed to a large scale English-to-Japanese MT post edit- ing project, showing strong correlation with hu- man preference and leading to about 10% gain in human translator productivity. The training data for QE model can be selected independent of the input document. With such fixed QE training data, it is possible to measure the consistency of the trained QE models, and to al- low the sanity check of the document-specific MT models. However, adding such data in the sub- sampling process extracts more bilingual data for building the MT models, which slightly increase the model building time but increased the transla- tion quality. Another option is to select the sen- tence pairs from the MT system subsampled train- ing data, which is more similar to the input docu- ment thus the trained QE model could be a better match to the input document. However, the QE model training data is no longer constant. The model consistency is no longer guaranteed, and the QE training data must be removed from the MT system training data to avoid data contamina- tion.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Adaptive QE for document-specific MT system.</figDesc><graphic url="image-1.png" coords="3,72.00,62.81,453.55,306.51" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Correlation coefficient r between predicted TER (x-axis) and true TER (y-axis) for QE models trained from the same document (top figure) or different document (bottom figure).</figDesc><graphic url="image-2.png" coords="5,307.28,62.81,226.78,242.83" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 2 : QE regression with static and adaptive models</head><label>2</label><figDesc></figDesc><table>Document 
LZA 
RTW 
WC7 
Num. of Sents 
2067 
2003 
2405 
P/R/F-score 
P/R/F-score 
P/R/F-score 
Static QE 
0.73/0.08/0.14 0.69/ 0.11/ 0.19 0.74/ 0.10/ 0.18 
Adaptive QE 0.69/0.14/0.24 0.84/ 0.16/ 0.26 0.80/ 0.23/ 0.35 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>MT proposal usage and productivity gain in FM category. 
In FM1, both Fuzzy Match and MT proposals present. In control class FM0, only Fuzzy Match proposals 
present, and therefore, MT usage is not available for FM0. Strong correlation is observed between 
predicted "High" , "Medium" and "Low" sentences with MT usage and post editing productivity. 

Category 
Class 
MT usage 
Productivity 
High 
50% 
1.25 
NP1 
Medium 
42% 
1.08 
Low 
27% 
1.00 
Overall 
38% 
1.09 
High 
-
1.08 
NP0 
Medium 
-
1.00 
Low 
-
0.96 
Overall 
-
1.00 

</table></figure>

			<note place="foot" n="2"> The adaptive QE model obtains much higher F-score (80%) on the rest of the sentences (with TER &gt; 0.1).</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Goodness: A method for measuring machine translation confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nguyen</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaser</forename><surname>Al-Onaizan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="211" to="219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Predicting sentence translation quality using extrinsic and language independent features. Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ergun</forename><surname>Biçici</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Declan</forename><surname>Groves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Van Genabith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Confidence estimation for machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blatz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erin</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simona</forename><surname>Gandrabur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cyril</forename><surname>Goutte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kulesza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th international conference on Computational Linguistics, COLING &apos;04</title>
		<meeting>the 20th international conference on Computational Linguistics, COLING &apos;04<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note>Alberto Sanchis, and Nicola Ueffing</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Buck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<title level="m">Findings of the 2013 Workshop on Statistical Machine Translation</title>
		<meeting><address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1" to="44" />
		</imprint>
	</monogr>
	<note>Eighth Workshop on Statistical Machine Translation, WMT-2013</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Findings of the 2012 workshop on statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Seventh Workshop on Statistical Machine Translation</title>
		<meeting><address><addrLine>Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="10" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Linguistic features for quality estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mariano</forename><surname>Felice</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Seventh Workshop on Statistical Machine Translation</title>
		<meeting><address><addrLine>Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="96" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Discriminative instance weighting for domain adaptation in statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cyril</forename><surname>Goutte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Kuhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;10</title>
		<meeting>the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;10<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="451" to="459" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Dimensionality reduction methods for machine translation quality estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesús</forename><surname>González-Rubio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><forename type="middle">Ramón</forename><surname>Navarro-Cerdán</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Casacuberta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Translation</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="281" to="301" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The efficacy of human post-editing for language translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spence</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Heer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI &apos;13</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems, CHI &apos;13<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="439" to="448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Tuning as ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Hopkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Edinburgh, Scotland, UK.</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011-05" />
			<biblScope unit="page" from="1352" to="1362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A maximum entropy word aligner for arabic-english machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abraham</forename><surname>Ittycheriah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of HLTEMNLP</title>
		<meeting>HLTEMNLP</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="89" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Direct translation model 2</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abraham</forename><surname>Ittycheriah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL 2007: Main Conference</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="57" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Improving statistical machine translation performance by 869 training data selection and optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yajuan</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL)</title>
		<meeting>the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL)<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007-06" />
			<biblScope unit="page" from="343" to="350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Discriminative corpus weight estimation for machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyros</forename><surname>Matsoukas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Antti-Veikko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Rosti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2009 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="708" to="717" />
		</imprint>
	</monogr>
	<note>EMNLP &apos;09</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Training a sentence-level machine translation confidence measure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">B</forename><surname>Quirk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC</title>
		<meeting>LREC</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">New confidence measures for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caroline</forename><surname>Sylvain Raybaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lavecchia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kamel</forename><surname>Langlois</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sma¨ılisma¨ıli</surname></persName>
		</author>
		<idno>abs/0902.1033</idno>
		<imprint>
			<date type="published" when="2009" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Document-specific statistical machine translation for improving human translation productivity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abraham</forename><surname>Ittycheriah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Ming</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th international conference on Computational Linguistics and Intelligent Text Processing-Volume Part II, CICLing&apos;12</title>
		<meeting>the 13th international conference on Computational Linguistics and Intelligent Text Processing-Volume Part II, CICLing&apos;12<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="25" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Estimation of confidence measures for machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Sanchis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alfons</forename><surname>Juan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Procedings of Machine Translation Summit XI</title>
		<meeting>edings of Machine Translation Summit XI</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>Enrique Vidal, and Departament De Sistemes Informtics</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A study of translation edit rate with targeted human annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Snover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Dorr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linnea</forename><surname>Micciulla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Makhoul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Association for Machine Translation in the Americas</title>
		<meeting>Association for Machine Translation in the Americas</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="223" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Trustrank: inducing trust in automatic translations via ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdessamad</forename><surname>Echihabi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL &apos;10</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics, ACL &apos;10<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="612" to="621" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Trustrank: Inducing trust in automatic translations via ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdessamad</forename><surname>Echihabi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="612" to="621" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Improving the confidence of machine translation quality estimates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Craig</forename><surname>Saunders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Turchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuoran</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Shawe-Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of MT Summit XII</title>
		<meeting>MT Summit XII</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Improving the confidence of machine translation quality estimates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Turchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuoran</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Shawe-Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Craig</forename><surname>Saunders</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Wordlevel confidence estimation for machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Ueffing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="9" to="40" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Hmm-based word alignment in statistical translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Vogel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Tillmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference on Computational Linguistics</title>
		<meeting>the 16th Conference on Computational Linguistics<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1996" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="836" to="841" />
		</imprint>
	</monogr>
	<note>COLING &apos;96</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Error detection for statistical machine translation using linguistic features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyi</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haizhou</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL &apos;10</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics, ACL &apos;10<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="604" to="611" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
