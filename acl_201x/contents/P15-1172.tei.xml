<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:18+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Coupled Sequence Labeling on Heterogeneous Annotations: POS Tagging as a Case Study</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenghua</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayuan</forename><surname>Chao</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenliang</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Soochow University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Collaborative Innovation Center of Novel Software Technology and Industrialization Jiangsu Province</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Coupled Sequence Labeling on Heterogeneous Annotations: POS Tagging as a Case Study</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1783" to="1792"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
					<note>* Correspondence author. 1 http://hlt.suda.edu.cn/ ˜ zhli</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In order to effectively utilize multiple datasets with heterogeneous annotations, this paper proposes a coupled sequence labeling model that can directly learn and infer two heterogeneous annotations simultaneously, and to facilitate discussion we use Chinese part-of-speech (POS) tagging as our case study. The key idea is to bundle two sets of POS tags together (e.g. &quot;[NN, n]&quot;), and build a conditional random field (CRF) based tagging model in the enlarged space of bundled tags with the help of ambiguous labelings. To train our model on two non-overlapping datasets that each has only one-side tags, we transform a one-side tag into a set of bundled tags by considering all possible mappings at the missing side and derive an objective function based on ambiguous labelings. The key advantage of our coupled model is to provide us with the flexibility of 1) incorporating joint features on the bundled tags to implicitly learn the loose mapping between heterogeneous annotations, and 2) exploring separate features on one-side tags to overcome the data sparseness problem of using only bundled tags. Experiments on benchmark datasets show that our coupled model significantly outperforms the state-of-the-art baselines on both one-side POS tagging and annotation conversion tasks. The codes and newly annotated data are released for non-commercial usage. 1</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Coupled Sequence Labeling on Heterogeneous Annotations: POS Tagging as a Case Study</head><p>Zhenghua Li, Jiayuan Chao, Min Zhang * , Wenliang Chen</p><p>(1) Soochow University</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(2) Collaborative Innovation Center of Novel Software Technology and Industrialization</head><p>Jiangsu Province, China {zhli13,minzhang,wlchen}@suda.edu.cn; china cjy@163.com</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>In order to effectively utilize multiple datasets with heterogeneous annotations, this paper proposes a coupled sequence labeling model that can directly learn and infer two heterogeneous annotations simultaneously, and to facilitate discussion we use Chinese part-of- speech (POS) tagging as our case study.</p><p>The key idea is to bundle two sets of POS tags together (e.g. " <ref type="bibr">[NN,</ref> n]"), and build a conditional random field (CRF) based tagging model in the enlarged space of bundled tags with the help of ambiguous labelings. To train our model on two non-overlapping datasets that each has only one-side tags, we transform a one-side tag into a set of bundled tags by considering all possible mappings at the missing side and derive an objective function based on ambiguous labelings. The key advantage of our coupled model is to provide us with the flexibility of 1) incorporating joint features on the bundled tags to implicitly learn the loose mapping between heterogeneous annotations, and 2) exploring separate features on one-side tags to overcome the data sparseness problem of using only bundled tags. Experiments on benchmark datasets show that our coupled model significantly outperforms the state-of- the-art baselines on both one-side POS tagging and annotation conversion tasks. The codes and newly annotated data are released for non-commercial usage. <ref type="bibr">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The scale of available labeled data significantly affects the performance of statistical data-driven models. As a widely-used structural classification problem, sequence labeling is prone to suffer from the data sparseness issue. However, the heavy cost of manual annotation typically limits one labeled resource in both scale and genre. As a promising research line, semi-supervised learning for sequence labeling has been exten- sively studied.  show that standard self-training can boost the performance of a simple hidden Markov model (HMM) based part-of-speech (POS) tagger. Søgaard (2011) ap- ply tri-training to English POS tagging, boost- ing accuracy from 97.27% to 97.50%. Sun and Uszkoreit (2012) derive word clusters from large- scale unlabeled data as extra features for Chi- nese POS tagging. Recently, the use of natural annotation has becomes a hot topic in Chinese word segmentation <ref type="bibr" target="#b5">(Jiang et al., 2013;</ref><ref type="bibr" target="#b27">Yang and Vozila, 2014</ref>). The idea is to derive segmentation boundaries from implicit information encoded in web texts, such as anchor texts and punctuation marks, and use them as partially labeled training data in sequence labeling models.</p><p>The existence of multiple annotated resources opens another door for alleviating data sparse- ness. For example, Penn Chinese Treebank (CTB) contains about 20 thousand sentences annotated with word boundaries, POS tags, and syntactic structures ( <ref type="bibr" target="#b26">Xue et al., 2005</ref>), which is widely used for research on Chinese word segmentation and POS tagging. People's Daily corpus (PD) 2 is a large-scale corpus annotated with word segments and POS tags, containing about 300 thousand sentences from the first half of 1998 of People's China focuses on economic development Our nation strongly develops education <ref type="bibr">[VV,v]</ref> </p><formula xml:id="formula_0">[VE,v] [VC,v] [VA,v]</formula><p>Bundled tags <ref type="bibr">[NN,n]</ref> [NN,Ng] <ref type="bibr">[NN,vn]</ref> Figure 1: An example to illustrate the annotation differences between CTB (above) and PD (below), and how to transform a one-side tag into a set of bundled tags. "NN" and "n" represent nouns; "VV"and "v" represent verbs.</p><p>Daily newspaper (see <ref type="table" target="#tab_2">Table 2</ref>). The two resources were independently built for different purposes. CTB was designed to serve syntactic analysis, whereas PD was developed to support information extraction systems. However, the key challenge of exploiting the two resources is that they adopt different sets of POS tags which are impossible to be precisely converted from one to another based on heuristic rules. <ref type="figure">Figure 1</ref> shows two example sentences from CTB and PD. Please refer to <ref type="table">Table  B</ref>.3 in Xia (2000) for detailed comparison of the two guidelines. Previous work on exploiting heterogeneous data (CTB and PD) mainly focuses on indirect guide- feature based methods. The basic idea is to use one resource to generate extra guide features on another resource ( <ref type="bibr" target="#b4">Jiang et al., 2009;</ref><ref type="bibr" target="#b21">Sun and Wan, 2012)</ref>, which is similar to stacked learning <ref type="bibr" target="#b12">(Nivre and McDonald, 2008)</ref>. First, PD is used as source data to train a source model Tagger PD . Then, Tagger PD generates automatic POS tags on the target data CTB, called source annota- tions. Finally, a target model Tagger CTB-guided is trained on CTB, using source annotations as extra guide features. Although the guide-feature based method is effective in boosting performance of the target model, we argue that it may have two potential drawbacks. First, the target model Tagger CTB-guided does not directly use PD as train- ing data, and therefore fails to make full use of rich language phenomena in PD. Second, the method is more complicated in real applications since it needs to parse a test sentence twice to get the final results.</p><p>This paper proposes a coupled sequence label- ing model that can directly learn and infer two heterogeneous annotations simultaneously. We use Chinese part-of-speech (POS) tagging as our case study. <ref type="bibr">3</ref> The key idea is to bundle two sets of POS tags together (e.g. " <ref type="bibr">[NN,</ref> n]"), and build a conditional random field (CRF) based tagging model in the enlarged space of bundled tags. To make use of two non-overlapping datasets that each has only one-side tags, we transform a one- side tag into a set of bundled tags by considering all possible mappings at the missing side and derive an objective function based on ambiguous labelings. During training, the CRF-based cou- pled model is supervised by such ambiguous label- ings. The advantages of our coupled model are to provide us the flexibility of 1) incorporating joint features on the bundled tags to implicitly learn the loose mapping between two sets of annotations, and 2) exploring separate features on one-side tags to overcome the data sparseness problem of using bundled tags. In summary, this work makes two major contributions:</p><p>1. We propose a coupled model which can more effectively make use of multiple resources with heterogeneous annotations, compared with both the baseline and guide-feature based method. Experiments show our approach can significantly improve POS tagging accuracy from 94.10% to 95.00% on CTB.</p><p>2. We have manually annotated CTB tags for 1, 000 PD sentences, which is the first dataset with two-side annotations and can be used for annotation-conversion evaluation. Exper- iments on the newly annotated data show that our coupled model also works effectively on the annotation conversion task, improving conversion accuracy from 90.59% to 93.90% (+3.31%).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Traditional POS Tagging (Tagger CTB )</head><p>Given an input sentence of n words, denoted by x = w 1 ...w n , POS tagging aims to find an optimal tag sequence t = t 1 ...t n , where t i ∈ T (1 ≤ i ≤ n) and T is a predefined tag set. As a log-linear probabilistic model ( <ref type="bibr" target="#b7">Lafferty et al., 2001</ref>), CRF 01: <ref type="table">Table 1</ref>: POS tagging features f (x, i, t i−1 , t i ).</p><formula xml:id="formula_1">ti • ti−1 02: ti • wi 03: ti • wi−1 04: ti • wi+1 05: ti • wi • ci−1,−1 06: ti • wi • ci+1,0 07: ti • ci,0 08: ti • ci,−1 09: ti • c i,k , 0 &lt; k &lt; #ci − 1 10: ti • ci,0 • c i,k , 0 &lt; k &lt; #ci − 1 11: ti • ci,−1 • c i,k , 0 &lt; k &lt; #ci − 1 12: if #ci = 1 then ti • wi • ci−1,−1 • ci+1,0 13: if c i,k = c i,k+1 then ti • c i,k • "consecutive" 14: ti • prefix(wi, k), 1 ≤ k ≤ 4, k ≤ #ci 15: ti • suffix(wi, k), 1 ≤ k ≤ 4, k ≤ #ci</formula><p>• means string concatenation; c i,k denotes the k th Chinese character of w i ; c i,0 is the first Chinese character; c i,−1 is the last Chinese character; #c i is the total number of Chinese characters</p><formula xml:id="formula_2">contained in w i ; prefix/suffix(w i , k) denote the k- Character prefix/suffix of w i .</formula><p>defines the probability of a tag sequence as:</p><formula xml:id="formula_3">P (t|x; θ) = exp(Score(x, t; θ)) t ′ exp(Score(x, t ′ ; θ)) Score(x, t; θ) = 1≤i≤n θ · f (x, i, t i−1 , t i ) (1)</formula><p>where f (x, i, t i−1 , t i ) is the feature vector at the i th word and θ is the weight vector. We adopt the state-of-the-art tagging features in <ref type="table">Table 1</ref> ( <ref type="bibr" target="#b28">Zhang and Clark, 2008</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Coupled POS Tagging (Tagger CTB&amp;PD )</head><p>In this section, we introduce our coupled model, which is able to learn and predict two heteroge- neous annotations simultaneously. The idea is to bundle two sets of POS tags together and let the CRF-based model work in the enlarged tag space. For example, a CTB tag "NN" and a PD tag "n" would be bundled into "[NN,n]". <ref type="figure">Figure 2</ref> shows the graphical structure of our model. Different from the traditional model in Eq. (1), our coupled model defines the score of a bundled tag sequence as follows:</p><formula xml:id="formula_4">Score(x, [t a , t b ]; θ) = 1≤i≤n θ ·    f (x, i, [t a i−1 , t b i−1 ], [t a i , t b i ]) f (x, i, t a i−1 , t a i ) f (x, i, t b i−1 , t b i )    (2)</formula><p>where the first item of the enlarged feature vector is called joint features, which can be obtained by</p><formula xml:id="formula_5">w 1 w i-1 w i w n ... ...</formula><p>Figure 2: Graphical structure of our coupled CRF model. instantiating <ref type="table">Table 1</ref> by replacing t i with bundled tags [t a i , t b i ]; the second and third items are called separate features, which are based on single-side tags. The advantages of our coupled model over the traditional model are to provide us with the flexibility of using both kinds of features, which significantly contributes to the accuracy improve- ment as shown in the following experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Mapping Functions</head><p>The key challenge of our idea is that both CTB and PD are non-overlapping and each contains only one-side POS tags. Therefore, the problem is how to construct training data for our coupled model. We denote the tag set of CTB as T a , and that of PD as T b , and the bundled tag set as T a&amp;b . Since the full Cartetian T a × T b would lead to a very large number of bundled tags, making the model very slow, we would like to come up with a much smaller T a&amp;b ⊆ T a × T b , based on linguistic insights of the annotation guidelines of the two datasets.</p><p>To obtain a proper T a&amp;b , we introduce a map- ping function between the two sets of tags as m : T a × T b → {0, 1}, which only allow specific tag pairs to be bundled together. Then, based on the mapping function, we can map a single-side POS tag into a set of bundled tags by considering all possible tags at the missing side, as illustrated in <ref type="figure">Figure 1</ref>. The word "Í 4 " is tagged as "NN" at the CTB side. Suppose that the mapping function m tells that "NN" can be mapped into three tags at the PD side, i.e., "n", "Ng", and "vn". Then, we create three bundled tags for the word, i.e., "[NN, n]", "[NN, Ng]", " <ref type="bibr">[NN, vn]</ref>" as its gold-standard references during training. It is known as ambiguous labelings when a training instance has multiple gold-standard la- bels. Similarly, we can obtain bundled tags for all other words in sentences of CTB and PD. After such transformation, the two datasets are now in the same tag space.</p><p>At the beginning of this work, our intuition is that the coupled model would achieve the best performance if we build a tight and linguistical- ly motivated mapping function. However, our preliminary experiments show that our intuitive assumption is actually incorrect. Therefore, we experiment with the following four mapping func- tions to manage to figure out the reasons behind and to better understand our coupled model.</p><p>• The tight mapping function produces 145</p><p>tags, and is constructed by strictly following linguistic principles and our careful study of the two guidelines and datasets.</p><p>• The relaxed mapping function results in 179 tags, which is an looser version of the tight mapping function by including extra 34 weak mapping relationships.</p><p>• The automatic mapping function generates 346 tags. We use the baseline Tagger CTB to parse PD, and collect all automatic mapping relationships.</p><p>• The complete mapping function obtains 1, 254 tags (|T a | × |T b | = 33 × 38).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Training Objective with Ambiguous Labelings</head><p>So far, we have formally defined a coupled model and prepared both CTB and PD in the same bundled tag space. The next problem is how to learn the model parameters θ. Note that after our transformation, a sentence in CTB or PD have many tag sequences as gold-standard references due to the loose mapping function, known as ambiguous labelings. Here, we derive a training objective based on ambiguous labelings. For simplicity, we illustrate the idea based on the notations of the baseline CRF model in Eq. (1). Given a sentence x, we denote a set of ambigu- ous tag sequences as V. Then, the probability of V is the sum of probabilities of all tag sequences contained in V:</p><formula xml:id="formula_6">p(V|x; θ) = t∈V p(t|x; θ)<label>(4)</label></formula><p>Algorithm 1 SGD training with two labeled datasets. 1: Input: Two labeled datasets: </p><formula xml:id="formula_7">D (1) = {(x (1) i , V (1) i } N i=1 , D (2) = {(x (2) i , V (2) i )} M i=1 ; Parameters: I, N ′ , M ′ , b 2: Output: θ 3: Initialization: θ 0 = 0, k = 0</formula><formula xml:id="formula_8">θ k+1 = θ k + η k 1 b ∇L(D b k ; θ k ) 8: k = k + 1 9: end for Suppose the training data is D = {(x i , V i )} N i=1</formula><p>. Then the log likelihood is:</p><formula xml:id="formula_9">L(D; θ) = N i=1 log p(V i |x i ; θ)<label>(5)</label></formula><p>After derivation, the gradient is: This function can be efficiently solved by the forward-backward algorithm. Please note that the training objective of a traditional CRF model can be understood as a special case where V i contains one sequence.</p><formula xml:id="formula_10">∂L(D; θ) ∂θ = N i=1 (E t∈V i [f (x i , t)] − E t [f (x i , t)])<label>(6)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">SGD Training with Two Datasets</head><p>We adopt stochastic gradient descent (SGD) to iteratively learn θ for our baseline and coupled models. However, we have two separate training data, and CTB may be overwhelmed by PD if directly merging the two datasets into one, since PD is 15 times larger than CTB (see <ref type="table" target="#tab_2">Table 2</ref>), Therefore, we propose a simple corpus-weighting strategy, as shown in Algorithm 1, where D b k is a subset of training data used in k th step update; b is the batch size; η k is a update step. The idea is to randomly sample instances from each training data in a certain proportion before each iteration.</p><p>The sampled data is then used for one-iteration training. Later experiments will investigate the effect of the weighting proportion. In this work, we use b = 30, and follow the implementation in CRFsuite <ref type="bibr">4</ref> to decide η k .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Manually Annotating PD Sentences with CTB Tags</head><p>To evaluate different methods on annotation con- version, we build the first dataset that contains 1, 000 sentences with POS tags on both sides of CTB and PD. The sentences are randomly sam- pled from PD. To save annotation effort, we only select 20% most difficult tokens to manually anno- tate. The difficulty of a word w i is measured based on marginal probabilities produced by the baseline Tagger CTB . p(t i |x, w i ; θ) denotes the marginal probability of tagging w i as t i . The basic assump- tion is that w i is more difficult to annotate if its most likely tag candidate (arg max t p(t|x, w i ; θ)) gets lower marginal probability. We build a visualized online annotation system to facilitate manual labeling. The annotation task is designed in such way that at a time an annotator is provided with a sentence and one focus word, and is required to decide the CTB POS tag of the word. To further simplify annotation, we provide two or three most likely tag candidates as well, so that annotators can choose one either among the candidates or from a full list. We employ 8 undergraduate students as our annotators. Anno- tators are trained on simulated tasks from CTB data for several hours, and and start real annotation once reaching certain accuracy. To guarantee annotation quality, we adopt multiple annotation. Initially, one task is randomly assigned to two annotators. Later, if the two annotators submit different results, the system will assign the task to two more annotators. To aggregate annotation results, we only retain annotation tasks that the first two annotators agree (91.0%) or three anno- tators among four agree (5.6%), and discard other tasks (3.4%). Finally, we obtain 5, 769 words with both CTB and PD tags, with each annotator's detailed submissions, and could be used as a non-synthesized dataset for studying aggregating submissions from non-expert annotators in crowd- sourcing platforms ( <ref type="bibr" target="#b15">Qing et al., 2014</ref>). The data is also fully released for non-commercial usage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>In this section, we conduct experiments to verify the effectiveness of our approach. We adopt CTB (version 5.1) with the standard data split, and randomly split PD into four sets, among which one set is 20% partially annotated with CTB tags. The data statistics is shown in <ref type="table" target="#tab_2">Table 2</ref>. The main concern of this work is to improve accuracy on CTB by exploring large-scale PD, since CTB is relatively small, but is widely-used benchmark data in the research community.</p><p>We use the standard token-wise tagging accu- racy as the evaluation metric. For significance test, we adopt Dan Bikel's randomized parsing evaluation comparator <ref type="bibr" target="#b13">(Noreen, 1989)</ref>. <ref type="bibr">5</ref> .</p><p>The baseline CRF is trained on either CTB training data with 33 tags, or PD training data with 38 tags. The coupled CRF is trained on both two separate training datasets with bundled tags (179 tags for the relaxed mapping function). During evaluation, the coupled CRF is not directly evaluated on bundled tags, since bundled tags are unavailable in either CTB or PD test data. Instead, the coupled and baseline CRFs are both evaluated on one-side tags.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Model Development</head><p>Our coupled model has two major parameters to be decided. The first parameter is to determine the mapping function between CTB and PD an- notations, and the second parameter is the relative weights of the two datasets during training (N ′ vs. M ′ : number of sentences in each dataset used for training at one iteration).</p><p>Effect of mapping functions (described in Subsection 3.1) is illustrated in <ref type="figure" target="#fig_2">Figure 3</ref>. Empirically, we adopt N ′ = 5K vs. M ′ = 20K to merge the two training datasets at each iteration. Our intuition is that using this proportion, CTB should not be overwhelmed by PD, and both training data can be used up in relatively similar speed. Specifically, all training data of CTB can be consumed in about 3 iterations, whereas PD can be consumed in about 14 iterations. We also present the results of the baseline model trained using 5K sentences in one iteration for better comparison.</p><p>Contrary to our intuitive assumption, it actually leads to very bad performance when using the   tight mapping function that is carefully created based on linguistic insights, which is even inferior to the baseline model. The relaxed mapping function outperforms the tight function by large margin. The automatic function works slightly better than the relaxed one. The complete function achieves similar accuracy with the automatic one. In summary, we can conclude that our coupled model achieves much better performance when the mapping function becomes looser. In other words, this suggests that our coupled model can effectively learn the implicit mapping between heterogeneous annotations, and does not rely on a carefully designed mapping function.</p><p>Since a looser mapping function leads to a larger number of bundled tags and makes the model slower, we implement a paralleled training procedure based on Algorithm 1, and run each experiment with five threads. However, it still takes about 20 hours for one iteration when using the complete mapping function; whereas the other three mapping functions need about 6, 2, and 1 hours respectively. Therefore, as a compromise, we adopt the relaxed mapping function in the fol- lowing experiments, which achieves slightly lower accuracy than the complete mapping function, but is much faster. Effect of weighting CTB and PD is investi- gated in <ref type="figure" target="#fig_3">Figure 4</ref> and 5. Since the scale of PD is much larger than CTB, we adopt Algorithm 1 to merge the training data in a certain proportion (N ′ CTB sentences and M ′ PD sentences) at each iteration. We use N ′ = 5K, and vary M ′ = 1K/5K/20K/100K. <ref type="figure" target="#fig_3">Figure 4</ref> shows the accuracy curves on CTB development data. We find that when M ′ = 100K, our coupled model achieve very low accuracy, which is even worse than the baseline model. The reason should be that the training instances in CTB are overwhelmed by those in PD when M ′ is large. In contrast, when M ′ = 1K, the accuracy is also inferior to the case of M ′ = 5K, which indicates that PD is not effectively utilized in this setting. Our model works best when M ′ = 5K, which is slightly better than the case of M ′ = 1K/20K. <ref type="figure">Figure 5</ref> shows the accuracy curves on PD development data. The baseline model is trained using 100K sentences in one iteration. We find  <ref type="formula">(100K)</ref> CTB(5K)+PD(20K) CTB(5K)+PD(5K) CTB(5K)+PD(1K) Baseline:PD(100K) <ref type="figure">Figure 5</ref>: Accuracy on PD-dev with different weighting settings.</p><p>that when M ′ = 100K, our coupled model achieves similar accuracy with the baseline model. When M ′ becomes smaller, our coupled model becomes inferior to the baseline model. Particu- larly, when M ′ = 1K, the model converges very slowly. However, from the trend of the curves, we expect that the accuracy gap between our coupled model with M ′ = 5K/20K and the baseline model should be much smaller when reaching convergence. Based on the above observation, we adopt N ′ = 5K and M ′ = 5K in the following experiments. Moreover, we select the best iteration on the development data, and use the corresponding model to parse the test data. <ref type="table" target="#tab_4">Table 3</ref> shows the final results on the CTB test data. We re-implement the guide-feature based method of <ref type="bibr" target="#b4">Jiang et al. (2009)</ref>, referred to as two- stage CRF. <ref type="bibr" target="#b8">Li et al. (2012)</ref> jointly models Chinese POS tagging and dependency parsing, and report the best tagging accuracy on CTB. The results show that our coupled model outperforms the baseline model by large margin, and also achieves slightly higher accuracy than the guide-feature based method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Final Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Feature Study</head><p>We conduct more experiments to measure individ- ual contribution of each feature set, namely the joint features based on bundled tags and separate features based on single-side tags, as defined in Eq. (2). <ref type="table" target="#tab_5">Table 4</ref> shows the results. We can see that when only using separate features, our coupled model achieves only slightly better accuracy than the baseline model. This is because there is Accuracy Baseline CRF 94.10 Two-stage CRF (guide-feature) 94.81 (+0.71) † Coupled CRF 95.00 (+0.90) † ‡ Best result ( <ref type="bibr" target="#b8">Li et al., 2012)</ref> 94.60  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Results on Annotation Conversion</head><p>In this subsection, we evaluate different methods on the annotation conversion task using our newly annotated 1, 000 sentences. The gold-standard   <ref type="table">Table 6</ref>: Accuracy on CTB: using converted PD. † means the corresponding approach significantly outperforms the baseline at confidence level of p &lt; 10 −5 ; whereas ‡ means the accuracy difference between the coupled CRF and the baseline CRF with converted PD is significant at confidence level of p &lt; 10 −2 .</p><p>PD-side tags are provided, and the goal is to obtain the CTB-side tags via annotation conversion. We evaluate accuracy on the 5, 769 words having manually annotated CTB-side tags.</p><p>Our coupled model can be naturally used for annotation conversion. The idea is to perform constrained decoding on the test data, using the PD-side tags as hard constraints. The guide- feature based method can also perform annotation conversion by using the gold-standard PD-side tags to compose guide features. <ref type="table" target="#tab_7">Table 5</ref> shows the results. The accuracy is much lower than those in <ref type="table" target="#tab_4">Table 3</ref>, because the 5, 769 words used for evaluation are 20% most ambiguous tokens in the 1, 000 test sentence (partial annotation to save annotation effort). From <ref type="table" target="#tab_7">Table 5</ref>, we can see that our coupled model outperforms both the baseline and guide-feature based methods by large margin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Results of Training with Converted Data</head><p>One weakness of our coupled model is the in- efficiency problem due to the large bundled tag set. In practice, we usually only need results following one annotation style. Therefore, we employ our coupled model to convert PD into the style of CTB, and train our baseline model with two training data with homogeneous annotations. Again, Algorithm 1 is used to merge the two data with N ′ = 5K and M ′ = 5K. The results are shown in the bottom row in <ref type="table">Table 6</ref>. We can see that with the extra converted data, the baseline model can achieve slightly lower accuracy with the coupled model and avoid the inefficiency problem at the meantime.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>This work is partially inspired by <ref type="bibr" target="#b17">Qiu et al. (2013)</ref>, who propose a model that performs heterogeneous Chinese word segmentation and POS tagging and produces two sets of results following CTB and PD styles respectively. Different from our CRF- based coupled model, their approach adopts a lin- ear model, which directly combines two separate sets of features based on single-side tags, without considering the interacting joint features between the two annotations. They adopt an approximate decoding algorithm which tries to find the best single-side tag sequence with reference to tags at the other side. In contrast, our approach is a direct extension of traditional CRF, and is more theoretically simple from the perspective of mod- elling. The use of both joint and separate features is proven to be crucial for the success of our coupled model. In addition, their work indicates that their model relies on a hand-crafted loose mapping between annotations, which is opposite to our findings. The naming of the "coupled" CRF is borrowed from the work of <ref type="bibr" target="#b16">Qiu et al. (2012)</ref>, which treats the joint task of Chinese word segmentation and POS tagging as two coupled sequence labeling problems.  propose a shift-reduce de- pendency parsing model which can simultaneous- ly learn and produce two heterogeneous parse trees. However, their approach assumes the ex- istence of data with annotations at both sides, which is obtained by converting phrase-structure trees into dependency trees with different heuristic rules.</p><p>This work is also closely related with multi- task learning, which aims to jointly learn multiple related tasks with the benefit of using interac- tive features under a share representation <ref type="bibr">(BenDavid and Schuller, 2003;</ref><ref type="bibr" target="#b0">Ando and Zhang, 2005;</ref><ref type="bibr" target="#b14">Parameswaran and Weinberger, 2010)</ref>. However, according to our knowledge, multi-task learning typically assumes the existence of data with labels for multiple tasks at the same time, which is unavailable in our situation.</p><p>As one reviewer kindly pointed out that our model is a factorial CRF ( <ref type="bibr" target="#b23">Sutton et al., 2004</ref>), in the sense that the bundled tags can be factorized two connected latent variables. Initially, factorial CRFs are designed to jointly model two relat- ed (and typically hierarchical) sequential labeling tasks, such as POS tagging and chunking. In this work, our coupled CRF jointly models two same tasks which have different annotation schemes. Moreover, this work provides a natural way to learn from incomplete annotations where one sen- tence only contains one-side labels. The reviewer also suggests that our objective can be optimized with the latent variable structured perceptron of <ref type="bibr" target="#b22">Sun et al. (2009)</ref>, which we leave as future work.</p><p>Learning with ambiguous labelings are previ- ously explored for classification <ref type="bibr" target="#b6">(Jin and Ghahramani, 2002</ref>), sequence labeling ( <ref type="bibr" target="#b2">Dredze et al., 2009</ref>), parsing ( <ref type="bibr" target="#b18">Riezler et al., 2002;</ref><ref type="bibr" target="#b24">Täckström et al., 2013;</ref><ref type="bibr" target="#b9">Li et al., 2014a;</ref><ref type="bibr" target="#b10">Li et al., 2014b)</ref>. Recently, researchers derive natural annotations from web data, transform them into ambiguous labelings to supervise Chinese word segmentation models ( <ref type="bibr" target="#b5">Jiang et al., 2013;</ref><ref type="bibr" target="#b27">Yang and Vozila, 2014</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>This paper proposes an effective coupled sequence labeling model for exploiting multiple non-overlapping datasets with heterogeneous annotations. Please note that our model can also be naturally trained on datasets with both-side annotations if such data exists. Experimental results demonstrate that our model work better than the baseline and guide-feature based methods on both one-side POS tagging and annotation conversion.</p><p>Specifically, detailed analysis shows several interesting findings. First, both the separate features and joint features are indispensable components for the success of our coupled model. Second, our coupled model does not rely on a carefully hand-crafted mapping function. Our linguistically motivated mapping function is only used to reduce the size of the bundled tag set for the sake of efficiency. Finally, using the extra training data converted with our coupled model, the baseline tagging model achieves similar accuracy improvement. In this way, we can avoid the inefficiency problem of our coupled model in real application.</p><p>For future, our immediate plan is to annotate more data with both CTB and PD tags (a few t- housand sentences), and to investigate our coupled model with small amount of such annotation as extra training data. Meanwhile, Algorithm 1 is empirically effective in merging two training data, but still needs manual tuning of the weighting factor on held-out data. Thus, we would like to find a more principled and theoretically sound method to merge multiple training data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>m</head><label></label><figDesc>(t a , t b ) = 1 if the two tags can be bundled 0 otherwise (3) where one mapping function m corresponds to one T a&amp;b . When the mapping function becomes looser, the tag set size |T a&amp;b | becomes larger.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>where f (x i , t) is an aggregated feature vector for tagging x i as t; E t∈V i [.] means model expectation of the features in the constrained space of V i ; E t [.] is model expectation with no constraint.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Accuracy on CTB-dev regarding to mapping functions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Accuracy on CTB-dev with different weighting settings.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>#sentences #tokens with CTB tags #tokens with PD tags</head><label>#sentences</label><figDesc></figDesc><table>CTB 

train 
16,091 
437,991 
-
dev 
803 
20,454 
-
test 
1,910 
50,319 
-

PD 

train 
273,883 
-
6,488,208 
dev 
1,000 
-
23,427 
test 
2,500 
-
58,301 
newly labeled 
1,000 
5,769 
27,942 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Data statistics. Please kindly note that the 1, 000 sentences originally from PD are only partially 
annotated with CTB tags (about 20% most ambiguous tokens). 

92 

92.5 

93 

93.5 

94 

94.5 

95 

95.5 

1 
11 21 31 41 51 61 71 81 91 
Accuracy on CTB-dev (%) 

Iteration Number 

Complete 
Automatic 
Relaxed 
Tight 
Baseline:CTB(5K) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Final results on CTB test data.  † 
means the corresponding approach significantly 
outperforms the baseline at confidence level of 
p &lt; 10 −5 ; whereas  ‡ means the accuracy 

difference between the two-stage CRF and the 
coupled CRF is significant at confidence level of 
p &lt; 10 −2 . 

dev 
test 
Baseline CRF 
94.28 94.10 
Coupled CRF (w/ separate feat) 94.36 94.43 (+0.33) 
Coupled CRF (w/ joint feat) 
92.92 92.90 (-1.20) 
Coupled CRF (full) 
95.10 95.00 (+0.90) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Accuracy on CTB: feature study. 

little connection and help between the two sets 
annotations. When only using joint features, 
our coupled model becomes largely inferior to 
the baseline, which is due to the data sparseness 
problem for the joint features. However, when 
the two sets of features are combined, the coupled 
model largely outperforms the baseline model. 
These results indicate that both joint features and 
separate features are indispensable components 
and complementary to each other for the success 
of our coupled model. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Conversion accuracy on our annotated 
data.  † means the corresponding approach sig-
nificantly outperforms the baseline at confidence 
level of p &lt; 10 −5 ; whereas  ‡ means the accuracy 
difference between the two-stage CRF and the 
coupled CRF is significant at confidence level of 
p &lt; 10 −2 . </table></figure>

			<note place="foot" n="2"> http://icl.pku.edu.cn/icl_groups/ corpustagging.asp</note>

			<note place="foot" n="3"> There are some slight differences in the word segmentation guidelines between CTB and PD, which are ignored in this work for simplicity.</note>

			<note place="foot" n="4"> http://www.chokkan.org/software/ crfsuite/</note>

			<note place="foot" n="5"> http://www.cis.upenn.edu/ ˜ dbikel/ software.html</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors would like to thank the undergraduate students Fangli Lu and Xiaojing Wang for building our annotation system, and Le Lu, Die Hu, Yue Zhang, Jian Zhang, Qiuyi Yan, Xinzhou Jiang for data annotation. We are also grateful that Yu Ding kindly shared her earlier codes on which our annotation system was built. We also thank the helpful comments from our anonymous reviewers. This work was supported by National Natural Sci-ence Foundation of China <ref type="bibr">(Grant No. 61432013, 61203314)</ref> and Jiangsu Planned Projects for Post-doctoral Research Funds (No. 1401075B), and was also partially supported by Collaborative In-novation Center of Novel Software Technology and Industrialization of Jiangsu Province.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A framework for learning predictive structures from multiple tasks and unlabeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kubota</forename><surname>Rie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Ando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learn Research</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1817" to="1853" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Exploiting task relatedness for multiple task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shai</forename><surname>Ben</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-David</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reba</forename><surname>Schuller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLT</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Sequence learning from data with multiple labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><forename type="middle">Pratim</forename><surname>Talukdar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECML/PKDD Workshop on Learning from Multi-Label Data</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Improving a simple bigram hmm part-of-speech tagger by latent annotation and selftraining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongqiang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Eidelman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><surname>Harper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="213" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Automatic adaptation of annotation standards: Chinese word segmentation and POS tagging-a case study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenbin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="522" to="530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Discriminative learning with natural annotations: Word segmentation as a case study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenbin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yajuan</forename><surname>Lü</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yating</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="761" to="769" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning with multiple labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML 2001</title>
		<meeting>ICML 2001</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="282" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A separately passive-aggressive training algorithm for joint POS tagging and dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenghua</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1681" to="1698" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Ambiguity-aware ensemble training for semi-supervised dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenghua</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenliang</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="457" to="467" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Soft cross-lingual syntax projection for dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenghua</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenliang</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="783" to="793" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Domain adaptation for CRF-based Chinese word segmentation using free annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yijia</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="864" to="874" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Integrating graph-based and transition-based dependency parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="950" to="958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Computer-intensive methods for testing hypotheses: An introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">W</forename><surname>Noreen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989" />
			<publisher>John Wiley &amp; Sons, Inc</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Large margin multi-task metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Parameswaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>J. Lafferty, C. K. I. Williams, J. Shawe-Taylor, R.S. Zemel, and A. Culotta</editor>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="1867" to="1875" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Empirical analysis of aggregation methods for collective annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ciyang</forename><surname>Qing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulle</forename><surname>Endriss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Kruger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1533" to="1542" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Joint segmentation and tagging with coupled sequences labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayi</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2012: Posters</title>
		<meeting>COLING 2012: Posters<address><addrLine>Mumbai, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="951" to="964" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Joint Chinese word segmentation and POS tagging on heterogeneous annotated corpora with multiple task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayi</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="658" to="668" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Parsing the wall street journal using a lexical-functional grammar and discriminative estimation techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Riezler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tracy</forename><forename type="middle">H</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><forename type="middle">M</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Crouch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">T</forename><surname>Maxwell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="271" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Semi-supervised condensed nearest neighbor for part-of-speech tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="48" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Capturing paradigmatic and syntagmatic lexical relations: Towards accurate Chinese part-of-speech tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans</forename><surname>Uszkoreit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="242" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Reducing approximation and estimation errors for Chinese lexical processing with heterogeneous annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="232" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Latent variable perceptron algorithm for structured classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takuya</forename><surname>Matsuzaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daisuke</forename><surname>Okanohara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun&amp;apos;ichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Joint Conference on Artificial Intelligence (IJCAI 2009)</title>
		<meeting>the 21st International Joint Conference on Artificial Intelligence (IJCAI 2009)</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1236" to="1242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Dynamic conditional random fields: Factorized probabilistic models for labeling and segmenting sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khashayar</forename><surname>Rohanimanesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Target language adaptation of discriminative transfer parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Täckström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1061" to="1071" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The part-of-speech tagging guidelines for the penn Chinese treebank 3.0</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Technical Report, Linguistic Data Consortium</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The Penn Chinese Treebank: Phrase structure annotation of a large corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fu-Dong</forename><surname>Chiou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Natural Language Engineering</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="207" to="238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Semi-supervised Chinese word segmentation using partial-label learning with conditional random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Vozila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="90" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Joint word segmentation and POS tagging using a single perceptron</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-08: HLT</title>
		<meeting>ACL-08: HLT</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="888" to="896" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Jointly or separately: Which is better for parsing heterogeneous dependencies?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meishan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanqiu</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING</title>
		<meeting>COLING</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="530" to="540" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
