<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:29+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Data-Driven, Factorization Parser for CCG Dependency Structures</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yantao</forename><surname>Du</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computer Science and Technology</orgName>
								<orgName type="laboratory">The MOE Key Laboratory of Computational Linguistics</orgName>
								<orgName type="institution" key="instit1">Peking University</orgName>
								<orgName type="institution" key="instit2">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Sun</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computer Science and Technology</orgName>
								<orgName type="laboratory">The MOE Key Laboratory of Computational Linguistics</orgName>
								<orgName type="institution" key="instit1">Peking University</orgName>
								<orgName type="institution" key="instit2">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computer Science and Technology</orgName>
								<orgName type="laboratory">The MOE Key Laboratory of Computational Linguistics</orgName>
								<orgName type="institution" key="instit1">Peking University</orgName>
								<orgName type="institution" key="instit2">Peking University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A Data-Driven, Factorization Parser for CCG Dependency Structures</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper is concerned with building CCG-grounded, semantics-oriented deep dependency structures with a data-driven, factorization model. Three types of fac-torization together with different higher-order features are designed to capture different syntacto-semantic properties of functor-argument dependencies. Integrating heterogeneous factorizations results in intractability in decoding. We propose a principled method to obtain optimal graphs based on dual decomposition. Our parser obtains an unlabeled f-score of 93.23 on the CCGBank data, resulting in an error reduction of 6.5% over the best published result. which yields a significant improvement over the best published result in the literature. Our implementation is available at http://www.icst. pku.edu.cn/lcwm/grass.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Combinatory Categorial <ref type="bibr">Grammar (CCG;</ref><ref type="bibr" target="#b35">Steedman, 2000</ref>) is a linguistically expressive gram- mar formalism which has a transparent yet el- egant interface between syntax and semantics. By assigning each lexical category a dependency interpretation, we can derive typed dependency structures from CCG derivations ( <ref type="bibr" target="#b8">Clark et al., 2002</ref>), providing a useful approximation to the underlying meaning representations. To date, CCG parsers are among the most competitive sys- tems for generating such deep bi-lexical depen- dencies that appropriately encode a wide range of local and non-local syntacto-semantic infor- mation <ref type="bibr" target="#b4">(Clark and Curran, 2007a;</ref><ref type="bibr" target="#b2">Bender et al., 2011</ref>). Such semantic-oriented dependency struc- tures have been shown very helpful for NLP ap- * Email correspondence. plications e.g. Question Answering ( <ref type="bibr" target="#b29">Reddy et al., 2014</ref>).</p><p>Traditionally, CCG graphs are generated as a by-product by grammar-guided parsers <ref type="bibr" target="#b7">(Clark and Curran, 2007b;</ref><ref type="bibr" target="#b11">Fowler and Penn, 2010)</ref>. The main challenge is that a deep-grammar-guided model usually can only produce limited coverage and corresponding parsing algorithms is of relatively high complexity. Robustness and efficiency, thus, are two major problems for handling practical tasks. To increase the applicability of such parsers, lexical or syntactic pruning has been shown nec- essary ( <ref type="bibr" target="#b6">Clark and Curran, 2004;</ref><ref type="bibr" target="#b21">Matsuzaki et al., 2007;</ref><ref type="bibr" target="#b32">Sagae et al., 2007;</ref><ref type="bibr" target="#b39">Zhang and Clark, 2011</ref>).</p><p>In the past decade, the techniques for data- driven dependency parsing has made a great progress ( <ref type="bibr">McDonald et al., 2005a,b;</ref><ref type="bibr" target="#b26">Nivre et al., 2004;</ref><ref type="bibr" target="#b36">Torres Martins et al., 2009;</ref>. The major advantage of the data-driven architecture is complementary to the grammar- driven one. On one hand, data-driven approaches make essential uses of machine learning from lin- guistic annotations and are flexible to produce analysis for arbitrary sentences. On the other hand, without hard constraints, parsing algorithms for spanning specific types of graphs, e.g. projec- tive <ref type="bibr" target="#b10">(Eisner, 1996)</ref> and 1-endpoint-crossing trees <ref type="bibr" target="#b28">(Pitler et al., 2013)</ref>, can be of low complexity.</p><p>This paper proposes a new data-driven depen- dency parser that efficiently produces globally op- timal CCG dependency graphs according to a dis- criminative, factorization model. The design of the factorization is motivated by three essential properties of the CCG dependencies. First, all ar- guments associated with the same predicate are highly correlated due to the nature that they ap- proximates type-logical semantics. Second, all predicates govern the same argument exhibit the hybrid syntactic/semantic, i.e. head-complement- adjunct, relationships. Finally, the CCG depen- dency graphs are not but look very much like trees, which have many good computational prop- erties. Simultaneously modeling the three prop- erties yields intrinsically heterogeneous factoriza- tions over the same graph, and hence results in in- tractability in decoding. Inspired by ( , we employ dual decom- position to perform principled decoding. Though not always, we can obtain the optimal solution most of time. The time complexity of our parser is O(n 3 ) when various 1st-and 2nd-order features are incorporated.</p><p>We conduct experiments on English CCGBank <ref type="bibr" target="#b12">(Hockenmaier and Steedman, 2007)</ref>. Though our parser does not use any grammar informa- tion, including both lexical categories and syntac- tic derivations, it produces very accurate CCG de- pendency graphs with respect to both token and complete matching. Our parser obtains an unla- beled f-score of 93.23, resulting in, perhaps sur- prisingly, an error reduction of up to 6.5% over the best published performance reported in (Auli and <ref type="bibr" target="#b0">Lopez, 2011</ref>). Our work indicates that high- quality data-driven parsers can be built for produc- ing more general dependency graphs, rather than trees. Nevertheless, empirical evaluation indicates that explicitly or implicitly using tree-structured information plays an essential role. The result also suggests that a wider range of complicated linguis- tic phenomena beyond surface syntax can be well modeled even without explicitly using grammars. Our algorithm is also applicable to other graph- structured representations, e.g. HPSG predicate- argument analysis <ref type="bibr" target="#b25">(Miyao et al., 2004</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Hockenmaier and Steedman (2007) developed lin- guistic resources, namely CCGBank, from the Penn Treebank (PTB; <ref type="bibr" target="#b19">Marcus et al., 1993)</ref>. In CCGBank, PTB phrase-structure trees have been transformed into normal-form CCG derivations, and deep bi-lexical dependency graphs that encode functor-argument strcutures have been extracted from these derivations using coindexation infor- mation. The typed dependency analysis provides a useful approximation to the underlying meaning representations, and has been shown very help- ful for NLP applications e.g. Question Answering ( <ref type="bibr" target="#b29">Reddy et al., 2014</ref>).</p><p>Traditionally, CCG graphs are generated as a by-product by deep parsers with a core gram- mar ( <ref type="bibr" target="#b8">Clark et al., 2002;</ref><ref type="bibr" target="#b7">Clark and Curran, 2007b;</ref><ref type="bibr" target="#b11">Fowler and Penn, 2010)</ref>. On the other hand, mod- eling these dependencies within a CCG parser has been shown very effective to improve the pars- ing accuracy <ref type="bibr" target="#b7">(Clark and Curran, 2007b;</ref><ref type="bibr" target="#b38">Xu et al., 2014</ref>). Besides CCG, similar deep dependency structures can be also extracted from parsers under other deep grammar formalisms, e.g. LFG ( <ref type="bibr" target="#b14">King et al., 2003) and</ref><ref type="bibr">HPSG (Miyao et al., 2004</ref>).</p><p>In recent years, data-driven dependency pars- ing has been well studied and widely applied to many NLP tasks. Research on data-driven ap- proach to producing dependency graphs that are not limited to tree or forest structures has also been initialized. <ref type="bibr" target="#b34">Sagae and Tsujii (2008)</ref> introduced a transition-based parser that is able to handle projective directed dependency graphs for HPSG- style predicate-argument analysis. <ref type="bibr" target="#b23">McDonald and Pereira (2006)</ref> presented a graph-based parser that can generate graphs in which a word may depend on multiple heads, and evaluated it on the Danish Treebank. Encouraged by their work, we study factorization models as well as principled decod- ing for CCG-grounded, graph-structured represen- tations.</p><p>Dual decomposition, and more generally La- grangian relaxation, is a classical method for solv- ing combinatorial optimization problems. It has been successfully applied to several NLP tasks, including parsing (  and machine translation ( <ref type="bibr" target="#b30">Rush and Collins, 2011</ref>). To provide principled decoding for our fac- torization parser, we employ the dual decomposi- tion technique. Our work directly follows ( ). The two basic factorizations are similar to the model introduced in <ref type="bibr" target="#b20">(Martins and Almeida, 2014)</ref>. <ref type="bibr" target="#b17">Lluís et al. (2013)</ref> introduced a dual decomposition based joint model for joint syntactic and semantic parsing. They are con- cerned with shallow semantic representation, i.e. Semantic Role Labeling, whose graphs are sparse. Different from their concern on integrating syntac- tic parsing and semantic role labeling under 1st- order factorization, we are interested in designing higher-order factorization models for more dense and general linguistic graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Graph Factorization</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Background Notations</head><p>Consider a sentence s = w, p with words w = w 1 w 2 · · · w n and POS-tags p = p 1 p 2 · · · p n . First we add one more virtual word w 0 = #W root # changes would exempt ... executives from (S\NP)/(S\NP) ((S\NP)/PP)NP with POS-tag p 0 = #P root # which is convention- ally considered as the root node of trees or graphs on the sentence. Then we denote the index set of all possible dependencies as I = {(i, j)|i ∈ {0, · · · , n}, j ∈ {1, · · · , n}, i = j}. A depen- dency parse then can be represented as a vector</p><formula xml:id="formula_0">y = {y(i, j) : (i, j) ∈ I},</formula><p>where y(i, j) = 1 if a dependency with predicate i and argument j is in the graph, 0 otherwise. Note that y is not a matrix but a long vector though we use two indexes to index it. In this paper, we only consider the unlabeled parsing task. Nevertheless, it is quite straightforward to extend our models to labeled parsing. Let Y denote the set of all possi- ble y. Given a function f : Y → R that assigns scores to parse graphs, the optimal parse is</p><formula xml:id="formula_1">y * = arg max y∈Y f (y).</formula><p>Following recent advances in discriminative de- pendency parsing, we build disambiguation mod- els based on global linear models, as in <ref type="bibr" target="#b22">(McDonald et al., 2005a)</ref>. In this framework, we score a dependency graph using a linear model:</p><formula xml:id="formula_2">f θ (y) = θ Φ(s, y),</formula><p>where Φ(s, y) produces a d-dimensional vector representation of the event that a CCG graph y is assigned to sentence s. In order to perform the decoding efficiently, we assume that the depen- dency graphs can be factored into smaller pieces. The main goal of this paper is to design ap- propriate factorization models, namely different types of f θ 's, to reflect essential properties of the semantics-oriented CCG dependency graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Predicate-Centric Factorization</head><p>The very fundamental view of the CCG de- pendency graphs is based on their lexicalized, predicate-centric nature. Every word is assigned a lexical category, which directly encodes its sub- categorization information. Due to the type- transparency nature of the formalism, this lexi- cal category provides sufficient information for not only syntactic derivation but also semantic composition. It is important to capture functor- argument relations by putting all arguments of one particular predicate together. <ref type="figure" target="#fig_0">Figure 1</ref> gives an example. The predicate "exempt" is of type "((S\NP)/PP)/NP," indicating that it takes three semantic dependents. This part of information is very similar to Semantic Role Labeling (SRL), whose goal is to find semantic roles for ver- bal predicates as well as their normalization. However, functor-argument analysis grounded in CCG is approximation of underlying logic forms and thus provides bi-lexical relations for almost all words. For instance, the second word in focus- "would"-captures structural information to orga- nize other predicates yet entities.</p><p>In order to perform maximization efficiently in this view, we treat each predicate separately. Given a vector y p , we define</p><formula xml:id="formula_3">y p i = {y(i, j) : j ∈ {1, · · · , n}, j = i}</formula><p>and assume that f (y p ) takes the form</p><formula xml:id="formula_4">f p (y p ) = n i=0 f p i (y p i )</formula><p>To capture the relationships of all arguments to one particular predicate as a whole, we employ a Markov model. Let a 1 , · · · , a m be the sequence of the arguments of the word w i under y p i . To keep the arguments in order, we constrain 1 ≤ a j 1 &lt; a j 2 ≤ n if j 1 &lt; j 2 . In a k-th order predicate- centric model, we define</p><formula xml:id="formula_5">f p i (y p i ) = m+k−1 j=1 θ p Φ p (a j−(k−1) , ..., a j , i, w, p)</formula><p>where a j (j ≤ 0 or j ≥ m + 1) are treated as specific initial or end state. Higher-order rather than arc-factored features can be conveniently extracted from adjacent argu- ments. This is similar to the sibling factorization defined by a number of syntactic tree parsers, e.g. ( <ref type="bibr" target="#b23">McDonald and Pereira, 2006</ref>), (  and <ref type="bibr" target="#b18">(Ma and Zhao, 2012)</ref>.</p><formula xml:id="formula_6">In an Oct. 19 review of ... (S/S)/N NP/N N/N N/N N (NP\NP)/NP arg2 arg1 arg1 arg1 arg1</formula><p>Figure 2: An example to illustrate the argument- centric view.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Argument-Centric Factorization</head><p>The syntactic principle for tree annotation treats the dependency relations between two words as syntactic projection. In another word, the head de- termines the syntactic category of the whole struc- ture. The (type-logical) semantic principle deter- mines a dependency according the types of the two words. The two kinds of dependency are coherent but not necessarily the same. In particular, an ad- junct is a syntactic dependent but usually a seman- tic predicate of its syntactic head. <ref type="figure">Figure 2</ref> gives an example to illustrate the idea. The argument in focus is "review" that is the complement of the preposition "in." The direction of this semantic de- pendency is the same to its corresponding syntac- tic dependency. Other predicates that semantically govern "review" are actually its modifiers, so the direction of these semantic dependencies are the opposite of their syntactic counterparts. It is im- portant to capture head-complement-adjunct rela- tions by putting all predicates of one particular ar- gument together. Similar to the predicate-centric model, we treat the graph fragment involved by each argument as independent, and capture the relationships among all predicates that governs the same argument us- ing a Markov model. In the definition of predicate- centric model, if we exchange predicates and ar- guments, then we get our argument-centric model. Formally, we define</p><formula xml:id="formula_7">y a j = {y(i, j) : i ∈ {0, · · · , n}, j = i}.</formula><p>Let p 1 , · · · , p m be the sequence of the predicates (in linear word order) that semantically governs the word j under y a j . A k-th order argument- centric model scores the dependency graph as</p><formula xml:id="formula_8">f a (y) = n j=1 f a j (y a j ) = n j=1 m+k−1 i=1 θ a Φ a (p i−(k−1) , ..., p i , j, w, p)</formula><p>Similarly, we define the initial and end states for p i (i &lt; 0 or i ≥ m + 1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Tree Approximation Model</head><p>Tree structures exhibit many computationally- good properties, and have been widely applied to model linguistic, especially syntactic, structures. Tree-structured representation is an essential pre- requisite for both the parsing algorithms and the machine learning methods in state-of-the-art syn- tactic dependency parsers. The CCG dependency graphs are not but look very much like trees. We thus argue that a tree-centric model can on one hand capture some topologically essential charac- teristics and on the other hand benefit from mature tree parsing techniques.</p><p>To this end, we propose tree approximation to obtain CCG sub-graphs under the factorization us- ing tree parsing algorithms. In particular, we introduce an algorithm to associate every graph with a projective dependency tree, which we call weighted conversion. The tree reflects partial in- formation about the corresponding graph. In this algorithm, we assign heuristic weights to all pos- sible edges, and then find the tree with maxi- mum weights. The key idea behind is to find a tree frame of a given graph. Given an arbitrary CCG graph, the conversion is perhaps imperfect in the sense that information about a small portion of edges is "lost." As a result, our tree approximation model can only generate partial graphs. Neverthe- less, we will show (in Section 3.5 and 4.2) that such a model can be combined with predicate-and argument-centric factorization models in an ele- gant way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Weighted Conversion</head><p>We assign weights to all the possible edges, i.e. all pairs of words, and then determine which edges to be kept by finding the maximum spanning tree. More formally, given a graph y = {y(i, j)}, each possible edge (i, j) is assigned a heuristic weight ω(i, j). The maximum spanning tree t = {t(i, j)} contains the maximum sum of values of edges:</p><formula xml:id="formula_9">t max = arg max t (i,j) t(i, j)ω(i, j)</formula><p>We separate the ω(i, j) into three parts (ω(i, j) = A(i, j) + B(i, j) + C(i, j)) that are defined as below.</p><p>• A(i, j) = a · max{y(i, j), y(j, i)}: a is the weight for the existing edges on graph ignor- ing direction.</p><p>• B(i, j) = b · y(i, j): b is the weight for the forward edges on the graph.</p><p>• C(i, j) = n − |i − j|: This term estimates the importance of an edge where n is the length of the given sentence. For dependency pars- ing, we consider edges with short distance to be more important because those edges can be predicted more accurately in future pars- ing process.</p><p>• a b n or a &gt; bn &gt; n 2 : The converted tree should contain arcs in original graph as many as possible, and the direction of the arcs should not be changed if possible. The rela- tionship of a, b, and c guarantees this.</p><p>After all edges are weighted, we can use max- imum spanning tree (MST) algorithms to get the converted tree. To get the projective tree, we choose Eisner's algorithm. However, the obtained tree must be labeled in order to encode the origi- nal graph. Here we introduce a label vector l = {l(i, j)}. For each (i, j) ∈ I, we assign a label l(i, j) to edge (i, j) as follows.</p><p>Case y(i, j) = 1: label "X";</p><p>Case y(i, j) = 0 ∧ y(j, i) = 1: label "X∼R";</p><p>Case y(i, j) = 0 ∧ y(j, i) = 0: label "None".</p><p>We can convert the labeled tree back to graph and obtain y t . Tough some edges are lost during the conversion, a lot more are kept. In fact, according to our evaluation, 92.74% of edges in the training set are retained after conversion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Factorizing Trees</head><p>We use the tree parsing model proposed in <ref type="bibr" target="#b3">(Bohnet, 2010)</ref> to score the converted trees. The model factorizes a tree into 1st-order and 2nd- order factors. When decoding, the model searches for a tree with the best score. The score defined for graphs as well as trees is</p><formula xml:id="formula_10">f t (y t ) = g t (t, l) = θ t Φ t (s, t, l) = θ 1 t Φ 1 t (s, t, l) + θ 2 t Φ 2 t (s, t, l) = (i,j)∈I t(i, j)θ 1 t Φ 1 t (l(i, j), w, p) +θ 2 t Φ 2 t (s, t, l),</formula><p>where Φ 1 t is the 1st-order features and Φ 2 t is the 2nd-order features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Parsing as Optimization</head><p>Motivated by linguistic properties of the semantics-oriented CCG dependencies, we have designed three single factorization models from heterogeneous views. Our single models exhibit different predictive strengths considering that they are designed to capture different prop- erties separately. Integrating them can generate better graphs, but is provably hard. To this end, we formulate the parsing problem as the following constrained optimization problem.</p><formula xml:id="formula_11">maximize f p (y p ) + f a (y a ) + f t (y t ) subject to y p (i, j) = y a (i, j), y p (i, j) ≥ y t (i, j), y a (i, j) ≥ y t (i, j) for all (i, j)</formula><p>The equality constraint says that the graph given by the predicate-and the argument-centric model must be identical, while the inequality constraints say that the frame of graph given by the tree ap- proximation model must be a subgraph of what is given by the first two models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Decoding</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Easiness and Hardness of Decoding</head><p>The three factorization models are all solvable in polynomial time. The predicate-centric model and the argument-centric model can be decoded us- ing dynamic programming. We provide the de- tailed description of such an algorithm in our sup- plementary note. The decoding method for k-th (k ≥ 2) order model costs time of O(n k+1 ) where n is the length of the sentence. The tree approxi- mation model can re-use existing dependency tree parsing algorithms.</p><p>Unfortunately, the exact joint decoding of 2nd- order predicate-and argument-centric models is already NP-hard, not to mention other model com- binations. The following gives a brief proof for the problem of combining the 2nd-order predicate- and argument-centric models.</p><p>Proof. Formally, we want to find a graph y which maximizes F (y) = f p (y)+f a (y). We can design the feature function Φ a and the parameter θ a , such that for all 1 ≤ i 1 ≤ i 2 ≤ n,</p><formula xml:id="formula_12">       θ a Φ a (0, i 1 , j, w, p) = 0 θ a Φ a (i 1 , n + 1, j, w, p) = 0 θ a Φ a (i 1 , i 2 , j, w, p) = −∞ θ</formula><p>a Φ a (0, n + 1, j, w, p) = −∞ where n is the length of the sentence. Note that those 4 equations make the nodes except the root node in the optimal graph each have exactly one incoming edge. So the problem of finding a tree t maximizing f p (t) is reduced to this problem. Moreover, the NP-hard problem 3DM can be re- duced to the problem of finding a tree t maxi- mizing f p (t) (see <ref type="bibr" target="#b23">McDonald and Pereira (2006)</ref>), leading to the NP-hardness of both of the prob- lems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Decoding via Dual Decomposition</head><p>To solve the joint decoding problem, optimization techniques based on decomposition with coupling variables are applicable. In this paper, we propose to solve it via dual decomposition. The experiment results show that though not always, we can obtain the optimal solution most of time. To simplify the description, we only consider the 2nd-order case for all three models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Lagrangian Relaxation</head><p>Notice that y p (i, j) ≥ y t (i, j) can be written as</p><formula xml:id="formula_13">y p (i, j) = 1, if y t (i, j) = 1; arbitrary, if y t (i, j) = 0.</formula><p>So the constraint can be written as A p y p +A a y a + A t y t = 0, where</p><formula xml:id="formula_14">A p =   I D y t 0   A a =   −I 0 D y t   A t =   0 −D y t −D y t  </formula><p>I is the identity matrix and D y t is a diagonal ma- trix whose main diagonal is the vector y t .</p><p>The Lagrangian of the optimization problem is</p><formula xml:id="formula_15">L(y p , y a , y t ; u) = f p (y p ) + f a (y a ) + f t (y t ) +u (A p y p + A a y a + A t y t ),</formula><p>where u is the Lagrangian multiplier. Omitting the constraints, the dual objective is</p><formula xml:id="formula_16">L(u) = max y p ,y a ,y t L(y p , y a , y t ; u) = max y p (f p (y p ) + u A p y p ) + max y a (f a (y a ) + u A a y a ) + max y t (f t (y t ) + u A t y t )</formula><p>Let L * be the maximized value of L(y p , y a , y t ; u) subjected to the constraints, then L * = min u L(u), according to the duality principle.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Decoding Algorithm</head><p>There are two challenges in solving the dual prob- lem. One challenge is to find the minimum value of the dual objective. For this, we can use subgra- dient method, as is demonstrated in Algorithm 1. The other is the evaluation of L(u). For this, we decompose the dual objective into three optimiza- tion problems. Let B p = u A p , B a = u A a , B t = u A t , and</p><formula xml:id="formula_17">C t l (i, j) = B t (i, j), if l(i, j) = X; B t (j, i), if l(i, j) = X ∼ R;</formula><p>we can just redefine</p><formula xml:id="formula_18">f p i (y i ) = m+1 j=1 θ p Φ p (a j−1 , a j , i, w, p) +B p (i, j) f a j (y j ) = m+1 i=1 θ a Φ a (p i−1 , p i , j, w, p) +B a (i, j) f t (y) = (i,j)∈I t(i, j) θ 1 t Φ 1 t (l(i, j), w, p) +C t l (i, j) + θ 2 t Φ 2 t (s, t, l),</formula><p>and decode according to the new scores. In fact, this equals to attach some new weights to 1st-order factors, without changing the decoding algorithms for the subproblems. This nice property also al- lows using higher-order models for subproblems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1: Joint decoding algorithm</head><p>Initialization: set u (0) to 0</p><formula xml:id="formula_19">for k = 1 to K do y p (k) ← arg max y f p (y) + u (k) A p y y a (k) ← arg max y f a (y) + u (k) A a y y t (k) ← arg max y f t (y) + u (k) A t y if A p y p (k) + A a y a (k) + A t y t (k) = 0 then return y a u (k) ← u (k−1) −α k (A p y p (k) + A a y a (k) + A t y t (k) )</formula><p>Algorithm 1 is our decoding algorithm. In ev- ery iteration, we first compute the optimal y's of the three subproblems. If the y's satisfies the con- straints, then we've find the optimal solution for the original problem. If not, we update the La- grangian multiplier u, towards the negative sub- gradient. We initialized u to be a zero vector, and use α k to be the step length of each iteration. When we decode the subproblems, the D y c in A p and A a is derived from the y c obtained in the cur- rent iteration.</p><p>We can also assign weights to different factor- ization models. If we choose to do so, the La- grangian becomes</p><formula xml:id="formula_20">L(y p , y a , y c ; u) = w p f p (y p ) + w a f a (y a ) +w c f t (y t ) + u (A p y p + A a y a + A t y t ).</formula><p>And the decoding of subproblems in our algorithm becomes</p><formula xml:id="formula_21">y p (k) ← arg max y f p (y) + 1 w p u (k) A p y; y a (k) ← arg max y f a (y) + 1 w a u (k) A a y; y t (k) ← arg max y f t (y) + 1 w c u (k) A t y.</formula><p>The algorithm we give here is the joint decod- ing for all the three models. We can also decode using any two of them, and it is trivial to adapt the algorithm to the decoding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Pruning</head><p>In order to improve the efficiency of the algorithm, we also do some pruning. One idea is that, in predicate-centric model, different type of predi- cates has different number of arguments. For ex- ample, the predicates POS-tagged "DT" each has only one argument in most cases. Therefore, we assign each POS-tag a max number of arguments. When decoding, we search at most those number of arguments instead of all the words in the sen- tence. This pruning method can also be applied to the argument-centric model. The other idea is that, some pairs of types never form a predicate- argument relation. So we can skip extracting fea- ture of those POS-tag pairs, just take −∞ to be their scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation and Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Setup</head><p>CCGbank is a translation of the Penn Treebank into a corpus of CCG derivations (Hockenmaier Devel.</p><p>Test HMM Tagger 96.74% 97.23% Transition-based Parser 93.48% 93.09% Graph-based Parser 93.47% 93.19% <ref type="table">Table 1</ref>: The accuracy of the POS tagger and the UAS of the syntax tree parsers.</p><p>and <ref type="bibr" target="#b12">Steedman, 2007)</ref>. CCGbank pairs syntac- tic derivations with sets of word-word dependen- cies which approximate the underlying functor- argument structure. Our experiments were per- formed using CCGBank which was split into three subsets for training (Sections 02-21), development testing (Section 00) and the final test (Section 23). We also use the syntactic dependency trees pro- vided by the CCGBank to obtain necessary in- formation for graph parsing. However, different from experiments in the CCG parsing literature, we use no grammar information. Neither lexical cate- gories nor CCG derivations are utilized. All experiments were performed using automat- ically assigned POS-tags that are generated by a symbol-refined generative HMM tagger <ref type="bibr">1 (Huang et al., 2010)</ref>, and automatically parsed dependency trees that are generated by our in-house implemen- tation of the transition-based model presented in ( <ref type="bibr" target="#b40">Zhang and Nivre, 2011</ref>) as well as a 2nd-order graph-based parser 2 <ref type="bibr" target="#b3">(Bohnet, 2010)</ref>. The accu- racy of these preprocessors is shown in <ref type="table">Table 1</ref>. We ran 5-fold jack-knifing on the gold-standard training data to obtain imperfect dependency trees, splitting off 4 of 5 sentences for training and the other 1/5 for testing, 5 times. For each split, we re-trained the tree parsers on the training portion and applied the resulting model to the test portion.</p><p>Previous research on dependency parsing shows that structured perceptron <ref type="bibr" target="#b9">(Collins, 2002</ref>) is one of the strongest discriminative learning algorithms. To estimate θ's of different models, we utilize the averaged perceptron algorithm. We implement our own the predicate-and argument-centric models. To perform tree parsing, we re-use the open-source implementation provided by the mate-tool. See the source code attached for details. We set it- eration 5 to train predicate-and argument-centric models and 10 for the tree approximation model. To perform dual decomposition, we set the maxi- mum iteration 200.  <ref type="table">Table 2</ref>: Parsing performance on the development data. The column "Tree" denotes the parsers that give dependency tree of development set: no tree (No), transition-based (Tr) or graph-based (Gr). "PC," "AC" and "TA" in the second column de- notes the predicate-centric, the argument-centric and the tree approximation models, respectively. <ref type="table">Table 2</ref> summarizes parsing performance on de- velopment set with different configurations. We report unlabeled precision (UP), recall (UR), f- score (UF) as well as complete match (UEM). It can be clearly seen that the data-driven models obtains high-quality graphs with respect to token match. Even without any syntactic information (see the top block associated with "No Tree"), our parser with all three factorization models obtains an f-score of 92.5. when assisted by a syntac- tic parser, this figure goes up to over 93.1. If the predicate-or argument-centric model is applied by itself, either one can achieve a competitive accu- racy, especially when syntactic features are uti- lized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Effectiveness of Data-driven Models</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Effectiveness of Multiple Factorization</head><p>We use dual decomposition to perform joint de- coding. First we combine the predicate-centric model and the argument-centric model. Compared to each single model, an error reduction of about 7% on f-score (UF) on average is achieved. Fur- thermore, we ensemble all the three models. If no syntactic features are extracted, the "TA" model brings in a remarkable further absolute gain of 1.02 with respect to token match. If syntactic features are used, the "PC" and "AC" models al- ready achieves relatively good performance, and the "TA" model does not contribute much consid- ering token match. The join of the tree approxi- mation model lowers the precision, it increases the recall further, resulting in a modest improvement of the f-score. Nonetheless, the "TA" model still significantly improve the complete match metric. It is noticeable that in all setting, the "TA" model result in very significant boost in complete match.</p><p>The dual decomposition does not guarantee to find an exact solution (in a limited number of it- erations) in theory but usually works very well in practice. We calculate the percentage of finding exact decoding below k iterations, and the result is show in <ref type="figure" target="#fig_1">Figure 3</ref>. The transition-based tree parser is utilized here. We can see that for most sen- tences, dual decomposition practically gives the exact solutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Importance of Tree Structures</head><p>Our factorization parser (with best experimental setting) does not utilize a grammar but do use syntactic information in the dependency formal- ism. In particular, the parser extracts the so-called path features from dependency trees. The syntac- tic trees is very importance to our parser, which provide a critical set of features for the predicate- centric and the argument-centric models. With- out the syntactic trees, their performances de- crease significantly. We try two different parsers to obtain the syntax tree parses. One is of the transition-based architecture, and the other graph-  <ref type="table">Table 3</ref>: Comparing the state-of-art with our mod- els on test set.</p><p>based. The architecture of the syntactic tree parser does not affect the results much. The two tree parsers give identical attachment scores, and lead to similar graph parsing accuracy. This result is somehow non-obvious given that the combination of a graph-based and transition-based parser usu- ally gives significantly better parsing performance <ref type="bibr" target="#b27">(Nivre and McDonald, 2008;</ref><ref type="bibr" target="#b37">Torres Martins et al., 2008)</ref>. Although the target representation of our parser is general graphs rather trees, implicitly or explic- itly using tree-structured information plays an es- sential role. Syntactic features are able to im- prove the f-score achieved by the "PC+AC" model from 90.9 to 92.8, while the "TA" model can bring in an absolute gain of 1.6. Note that the "TA" model does not utilize any syntactic tree infor- mation. The converted trees are automatically in- duced from the CCG graphs. Even when syntactic trees are available, the automatically induced trees can still significantly improve the complete match with respect to the whole sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Comparison to the State-of-the-art</head><p>We compare our results with the best published CCG parsing performance obtained by the models presented in (Auli and Lopez, 2011) and ( <ref type="bibr" target="#b38">Xu et al., 2014)</ref> 3 . Auli and Lopez (2011) reported best nu- meric performance. The performance is evaluated on sentences that can be parsed by their model. <ref type="bibr" target="#b38">Xu et al. (2014)</ref> reported the best published results for sentences with full coverage. All results on the test set is shown in <ref type="table">Table 3</ref>. Even without any syn- tactic features, our parser achieves accuracies that are superior to Xu et al.'s parser and comparable to Auli and Lopez's system. When unlabeled syn- tactic trees are provided, our parser outperform the state-of-the-art.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we have presented a factoriza- tion parser for building CCG-grounded depen- dency graphs. It achieves substantial improvement over the state-of-the-art. Perhaps surprisingly, our data-driven, grammar-free parser yields a supe- rior accuracy to all CCG parsers in the literature. Our work indicates that high-quality data-driven parsers can be built for producing more general dependency graphs, rather than trees. Our method is also applicable to other deep dependency struc- tures, e.g. HPSG predicate-argument analysis ( <ref type="bibr" target="#b25">Miyao et al., 2004</ref>), as well as other graph- structured semantic representations, e.g. Abstract Meaning Representations ( <ref type="bibr" target="#b1">Banarescu et al., 2013</ref>).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Examples to illustrate the predicatecentric view.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The exact decoding rate.</figDesc></figure>

			<note place="foot" n="1"> www.code.google.com/p/ umd-featured-parser/ 2 www.code.google.com/p/mate-tools/</note>

			<note place="foot" n="3"> The unlabeled parsing results are not reported in the original paper. The figures presented in are provided by Wenduan Xu.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>The work was supported by NSFC (61300064), National High-Tech R&amp;D Pro-gram (2015AA015403), NSFC (61331011) and NSFC (61170166).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Training a log-linear parser with loss functions via softmax-margin</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lopez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP<address><addrLine>Edinburgh, Scotland, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="333" to="343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Abstract meaning representation for sembanking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Banarescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Bonial</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Madalina</forename><surname>Georgescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kira</forename><surname>Griffitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulf</forename><surname>Hermjakob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Schneider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse</title>
		<meeting>the 7th Linguistic Annotation Workshop and Interoperability with Discourse<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="178" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Parser evaluation over local and non-local deep dependencies in a large corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><forename type="middle">M</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Flickinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Oepen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics</title>
		<meeting><address><addrLine>Edinburgh, Scotland, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="397" to="408" />
		</imprint>
	</monogr>
	<note>Proceedings of EMNLP</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Top accuracy and fast dependency parsing is not a contradiction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernd</forename><surname>Bohnet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics</title>
		<meeting>the 23rd International Conference on Computational Linguistics<address><addrLine>Coling; Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="89" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Formalism-independent parser evaluation with ccg and depbank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Curran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th</title>
		<meeting>the 45th</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<title level="m">Annual Meeting of the Association of Computational Linguistics</title>
		<meeting><address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The importance of supertagging for wide-coverage CCG parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">R</forename><surname>Curran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Coling</title>
		<meeting>Coling<address><addrLine>Geneva, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="282" to="288" />
		</imprint>
		<respStmt>
			<orgName>COLING</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Widecoverage efficient statistical parsing with CCG and log-linear models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">R</forename><surname>Curran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Linguist</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="493" to="552" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Building deep dependency structures using a wide-coverage CCG parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hockenmaier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 40th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Philadelphia, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-07-06" />
			<biblScope unit="page" from="327" to="334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Three new probabilistic models for dependency parsing: an exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><forename type="middle">M</forename><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th conference on Computational linguistics</title>
		<meeting>the 16th conference on Computational linguistics<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="340" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Accurate context-free parsing with combinatory categorial grammar</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Timothy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerald</forename><surname>Fowler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Penn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="335" to="344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">CCGbank: A corpus of CCG derivations and dependency structures extracted from the penn treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hockenmaier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="355" to="396" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Self-training with products of latent variable grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongqiang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><surname>Harper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="12" to="22" />
		</imprint>
	</monogr>
	<note>Proceedings of EMNLP</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The PARC 700 dependency bank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tracy Holloway</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Crouch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Riezler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><surname>Dalrymple</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><forename type="middle">M</forename><surname>Kaplan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th International Workshop on Linguistically Interpreted Corpora (LINC-03)</title>
		<meeting>the 4th International Workshop on Linguistically Interpreted Corpora (LINC-03)</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Efficient third-order dependency parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics</title>
		<meeting><address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
	<note>Proceedings of ACL</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Dual decomposition for parsing with non-projective head automata</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommi</forename><surname>Jaakkola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Sontag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1288" to="1298" />
		</imprint>
	</monogr>
	<note>Proceedings of EMNLP</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Joint arc-factored parsing of syntactic and semantic dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Lluís</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Carreras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lluís</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TACL</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="219" to="230" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Fourth-order dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The COLING 2012 Organizing Committee</title>
		<meeting><address><addrLine>Mumbai, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="785" to="796" />
		</imprint>
	</monogr>
	<note>Proceedings of COLING 2012: Posters</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Building a large annotated corpus of english: the penn treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><forename type="middle">P</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><forename type="middle">Ann</forename><surname>Marcinkiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatrice</forename><surname>Santorini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Linguist</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="313" to="330" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Priberam: A turbo semantic parser with second order features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">T</forename><surname>André</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mariana</forename><forename type="middle">S C</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Almeida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SemEval 2014</title>
		<meeting>SemEval 2014</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="471" to="476" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Efficient hpsg parsing with supertagging and cfg-filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takuya</forename><surname>Matsuzaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuke</forename><surname>Miyao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun&amp;apos;ichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th international joint conference on Artifical intelligence</title>
		<meeting>the 20th international joint conference on Artifical intelligence<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann publishers Inc</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1671" to="1676" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Online large-margin training of dependency parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL&apos;05)</title>
		<meeting>the 43rd Annual Meeting of the Association for Computational Linguistics (ACL&apos;05)<address><addrLine>Ann Arbor, Michigan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="91" to="98" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Online learning of approximate dependency parsing algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 11th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>11th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="81" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Non-projective dependency parsing using spanning tree algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiril</forename><surname>Ribarov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP<address><addrLine>British Columbia, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="523" to="530" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics, Vancouver</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Corpus-oriented grammar development for acquiring a head-driven phrase structure grammar from the penn treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuke</forename><surname>Miyao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takashi</forename><surname>Ninomiya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCNLP</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="684" to="693" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Memory-based dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Nilsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLTNAACL 2004 Workshop: Eighth Conference on Computational Natural Language Learning (CoNLL-2004)</title>
		<editor>Hwee Tou Ng and Ellen Riloff</editor>
		<meeting><address><addrLine>Boston, Massachusetts, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="49" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Integrating graph-based and transition-based dependency parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-08: HLT, pages 950-958. Association for Computational Linguistics</title>
		<meeting>ACL-08: HLT, pages 950-958. Association for Computational Linguistics<address><addrLine>Columbus, Ohio</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Finding optimal 1-endpoint-crossing trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Pitler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sampath</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TACL</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="13" to="24" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Large-scale semantic parsing without question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siva</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2014" />
			<publisher>TACL</publisher>
		</imprint>
	</monogr>
	<note>and Mark Steedman</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Exact decoding of syntactic translation models through lagrangian relaxation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Conference</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="19" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">On dual decomposition and linear programming relaxations for natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Alexander M Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Sontag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommi</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
	<note>Proceedings of EMNLP</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Hpsg parsing with shallow dependency constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Sagae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuke</forename><surname>Miyao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun&amp;apos;ichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th</title>
		<meeting>the 45th</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<title level="m">Annual Meeting of the Association of Computational Linguistics</title>
		<meeting><address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="624" to="631" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Shiftreduce dependency DAG parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Sagae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun&amp;apos;ichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Computational Linguistics</title>
		<meeting>the 22nd International Conference on Computational Linguistics<address><addrLine>UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="753" to="760" />
		</imprint>
	</monogr>
	<note>Coling</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">The syntactic process</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Concise integer linear programming formulations for dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andre Torres</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="342" to="350" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics. Suntec</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Stacking dependency parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">André Filipe Torres</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics</title>
		<meeting><address><addrLine>Honolulu, Hawaii</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="157" to="166" />
		</imprint>
	</monogr>
	<note>Proceedings of EMNLP</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Shift-reduce ccg parsing with a dependency model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenduan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="218" to="227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Shift-reduce CCG parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="683" to="692" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Transitionbased dependency parsing with rich non-local features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="188" to="193" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
