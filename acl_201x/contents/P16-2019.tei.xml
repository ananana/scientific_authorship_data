<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:43+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Leveraging Lexical Resources for Learning Entity Embeddings in Multi-Relational Data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teng</forename><surname>Long</surname></persName>
							<email>teng.long@mail.mcgill.ca</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">McGill University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">McGill University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jackie</forename><surname>Chi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">McGill University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kit</forename><surname>Cheung</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">McGill University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doina</forename><surname>Precup</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">McGill University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Leveraging Lexical Resources for Learning Entity Embeddings in Multi-Relational Data</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="112" to="117"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Recent work in learning vector-space em-beddings for multi-relational data has fo-cused on combining relational information derived from knowledge bases with dis-tributional information derived from large text corpora. We propose a simple approach that leverages the descriptions of entities or phrases available in lexical resources , in conjunction with distributional semantics, in order to derive a better ini-tialization for training relational models. Applying this initialization to the TransE model results in significant new state-of-the-art performances on the WordNet dataset, decreasing the mean rank from the previous best of 212 to 51. It also results in faster convergence of the entity representations. We find that there is a trade-off between improving the mean rank and the hits@10 with this approach. This illustrates that much remains to be understood regarding performance improvements in relational models.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A surprising result of work on vector-space word embeddings is that word representations that are learned from a large training corpus display se- mantic regularities in the form of linear vector translations. For example, <ref type="bibr" target="#b13">Mikolov et al. (2013b)</ref> show that using their induced word vector repre- sentations, king − man + woman ≈ queen. Such a structure is appealing because it provides an inter- pretation to the distributional vector space through lexical-semantic analogical inferences.</p><p>Concurrent to that work, <ref type="bibr" target="#b2">Bordes et al. (2013)</ref> proposed translating embeddings (TransE), which takes a pre-existing semantic hierarchy as in-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>W2V</head><p>GloVe Dataset Total found% found% WN 40943 9.7% 51.3% FB15k 14951 4.0% 20.3% <ref type="table">Table 1</ref>: The percentage of WN and FB15k enti- ties that can be found in the pre-trained word2vec (W2V) and GloVe vectors. This does not include the W2V embeddings trained with the FB15k vo- cabulary 2 , which covers 93% of the FB15k enti- ties.</p><p>put and embeds its structure into a vector space.</p><p>In their model, the linear relationship between two entities that are in some semantic relation to each other is an explicit part of the model's objective function. For example, given a rela- tion such as won(Germany, FIFA Worldcup), the TransE model learns vector representations for won, Germany, and FIFA Worldcup such that Germany + won ≈ FIFA Worldcup. A natural next step is to attempt to integrate the two approaches in order to develop a representa- tion that is informed by both unstructured text and a structured knowledge base <ref type="bibr" target="#b4">(Faruqui et al., 2015;</ref><ref type="bibr" target="#b23">Xu et al., 2014;</ref><ref type="bibr" target="#b5">Fried and Duh, 2015;</ref><ref type="bibr" target="#b24">Yang et al., 2015)</ref>. However, existing work makes a cru- cial assumption-that reliable distributional vec- tors are available for all of the entities in the hier- archy being modeled. Unfortunately, this assump- tion does not hold in practice; when moving to a new domain with a new knowledge base, for ex- ample, there will likely be many entities or phrases for which there is no distributional information in the training corpus. This important problem is il- lustrated in <ref type="table">Table 1</ref>, where most of the entities from WordNet and Freebase are seen to be miss- ing from the distributional vectors derived using Word2Vec and GloVe trained on the Google News corpus. Even when the entities are found, they may not have occurred enough times in the train- ing corpus for their vector representation to be re- liable. What is needed is a method to derive entity representations that works well for both common and rare entities.</p><p>Fortunately, knowledge bases typically con- tain a short description or definition for each of the entities or phrases they contain. For ex- ample, in a medical dataset with many techni- cal words, the Wikipedia pages, dictionary def- initions, or medical descriptions via a site such as medilexicon.com could be leveraged as lexical resources. Similarly, when building lan- guage models for social media, resources such as urbandicionary.com could be used for in- formation about slang words. For the WordNet and Freebase datasets, we use entity descriptions which are readily available (see <ref type="table" target="#tab_0">Table 2</ref>).</p><p>In this paper, we propose a simple and efficient procedure to convert these short descriptions into a vector space representation, with the help of ex- isting word embedding models. These vectors are then used as the input to further training with the TransE model, in order to incorporate structural information. Our method provides a better initial- ization for the TransE model, not just for the enti- ties that do not appear in the data, but in fact for all entities. This is demonstrated by achieving state- of-the-art mean rank on an entity ranking task on two very different data sets: WordNet synsets with lexical semantic relations <ref type="bibr" target="#b14">(Miller, 1995)</ref>, and Free- base named entities with general semantic rela- tions ( <ref type="bibr" target="#b0">Bollacker et al., 2008</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Dictionary definitions were the core component of early methods in word sense disambiguation (WSD), such as the Lesk algorithm (1986). <ref type="bibr" target="#b3">Chen et al. (2014)</ref> build on the use of synset glosses for WSD by leveraging lexical resources. Our work goes further to tie these glosses together with rela- tional semantics, a connection that has not been drawn in the literature before. The integration of lexical resources into distributional semantics has been studied in other lexical semantic tasks,  the occupation of taking and printing photographs or making movies transmutation#2 a qualitative change Freebase Descriptions</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stephen Harper</head><p>Stephen Joseph Harper is a Canadian politician who is the 22nd and current Prime Minister of Canada and the Leader of the Conservative Party...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>El Paso</head><p>El Paso is the county seat of El Paso County, Texas, United States, and lies in far West Texas... such as synonym expansion <ref type="bibr" target="#b18">(Sinha and Mihalcea, 2009)</ref>, relation extraction <ref type="bibr" target="#b7">(Kambhatla, 2004)</ref>, and calculating the semantic distance between con- cepts <ref type="bibr" target="#b15">(Mohammad, 2008;</ref><ref type="bibr" target="#b11">Marton et al., 2009</ref>). We aim to combine lexical resources and other seman- tic knowledge, but we do so in the context of neu- ral network-based word embeddings, rather than in specific lexical semantic tasks. Bordes et al. <ref type="formula">(2011)</ref> propose the Structured Em- beddings (SE) model, which embeds entities into vectors and relations into matrices. The relation connection between two entities is modeled by the projection of their embeddings into a different vec- tor space. <ref type="bibr" target="#b17">Rothe and Schütze (2015)</ref> use Word- net as a lexical resource to learn embeddings for synsets and lexemes. Perhaps most related to our work are previous relational models that initialize their embeddings via distributional semantics cal- culated from a larger corpus. <ref type="bibr" target="#b19">Socher et al. (2013)</ref> propose the Neural Tensor Network (NTN), and <ref type="bibr" target="#b24">Yang et al. (2015)</ref> the Bilinear model using this technique. Other approaches modify the objective function or change the structure of the model in order to integrate distributional and relational in- formation ( <ref type="bibr" target="#b23">Xu et al., 2014;</ref><ref type="bibr" target="#b5">Fried and Duh, 2015;</ref><ref type="bibr" target="#b21">Toutanova and Chen, 2015)</ref>. <ref type="bibr" target="#b4">Faruqui et al. (2015)</ref> retrofit word vectors after they are trained accord- ing to distributional criteria. We propose a method that does not necessitate post-processing of the embeddings, and can be applied orthogonally to the previously mentioned improvements.</p><p>3 Architecture of the Approach</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The TransE Model</head><p>The Translating Embedding (TransE) model <ref type="bibr" target="#b2">(Bordes et al., 2013</ref>) has become one of the most popu-lar multi-relational models due to its relative sim- plicity, scalability to large datasets, and (until re- cently) state-of-the-art results. It assumes a sim- ple additive interaction between vector represen- tations of entities and relations. More precisely, assume a given relationship triplet (h, l, t) is valid; then, the embedding of the object t should be very close to the embedding of the subject h plus some vector in R k that depends on the relation l 3 .</p><p>For each positive triplet (h, l, t) ∈ S, a nega- tive triplet (h , l, t ) ∈ S is constructed by ran- domly sampling an entity from E to replace either the subject h or the object t of the relationship. The training objective of TransE is to minimize the dissimilarity measure d(h + l, t) of a positive triplet while ensuring that d(h + l, t ) for the cor- rupted triplet remains large. This is accomplished by minimizing the hinge loss over the training set:</p><formula xml:id="formula_0">L = (h,l,t)∈S (h ,l,t )∈S [γ+d(h+l, t)−d(h +l, t )] +</formula><p>where γ is the hinge loss margin and <ref type="bibr">[x]</ref> + repre- sents the positive portion of x. There is an ad- ditional constraint that the L 2 -norm of entity em- beddings (but not relation embeddings) must be 1, which prevents the training process to trivially minimize L by artificially increasing the norms of entity embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Initializing Representations with Entity Descriptions</head><p>We propose to leverage some external lexical re- source to improve the quality of the entity vector representations. In general, this could consist of product descriptions in a product database, or in- formation from a web resource. For the WordNet and Freebase datasets, we use entity descriptions which are readily available. Although there are many ways to incorporate this, we propose a simple method whereby the entity descriptions are used to initialize the en- tity representations of the model, which we show to have empirical benefits. In particular, we first decompose the description of a given en- tity into a sequence of word vectors, and com- bine them into a single embedding by averaging. We then reduce the dimensionality using princi- ple component analysis (PCA), which we found experimentally to reduce overfitting. We obtain these word vectors using distributed representa- tions computed using word2vec <ref type="bibr" target="#b12">(Mikolov et al., 2013a</ref>) and GloVe ( <ref type="bibr" target="#b16">Pennington et al., 2014</ref>). Ap- proximating compositionality by averaging vector representations is simple, yet has some theoretical justification ( <ref type="bibr" target="#b20">Tian et al., 2015)</ref> and can work well in practice <ref type="figure" target="#fig_3">(Wieting et al., 2015)</ref>.</p><p>Additional decisions need to be made concern- ing which parts of the entity description to include. In particular, if an entity description or word def- inition is longer than several sentences, using the entire description could cause a 'dilution' of the desired embedding, as not all sentences will be equally pertinent. We solve this by only consid- ering the first sentence of any entity description, which is often the most relevant one. This is nec- essary for Freebase, where the description length can be several paragraphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Training and Testing Setup</head><p>We perform experiments on the WordNet (WN) <ref type="bibr" target="#b14">(Miller, 1995)</ref> and Freebase (FB15k) <ref type="bibr" target="#b0">(Bollacker et al., 2008</ref>) datasets used by the original TransE model. TransE hyperparameters include the learning rate λ for stochastic gradient descent, the margin γ for the hinge loss, the dimension of the embeddings k, and the dissimilarity metric d. For the TransE model with random initialization, we use the optimal hyperparameters from ( <ref type="bibr" target="#b2">Bordes et al., 2013)</ref>: for WN, λ = 0.01, γ = 2, k = 20, and d = L 1 -norm; for FB15k, λ = 0.01, γ = 0.5, k = 50, and d = L 2 -norm. The values of k were further tested to ensure that k = 20 and k = 50 were optimal. For the TransE model with strategic initialization, we used different embedding dimensions. The distributional vectors used in the entity descriptions are of dimension 1000 for the word2vec vectors with Freebase vocabulary, and dimension 300 in all other cases. Dimensionality reduction with PCA was then applied to reduce this to k = 30 for WN, and k = 55 for FB15k, which were empirically found to be optimal. PCA was necessary in this case as pre-trained vectors from word2vec and GloVe are not available for all dimension values.</p><p>We use the same train/test/validation split and evaluation procedure as ( <ref type="bibr" target="#b2">Bordes et al., 2013)</ref>: for each test triplet (h, l, t), we remove entity h and t in turn, and rank each entity in the dictionary   <ref type="table">Table 3</ref>: Comparison between random initialization and using the entity descriptions. 'NS' tag indicates stopword removal from the entity descriptions'TransE Freebase W2V init' model uses word2vec pre- trained with the Freebase vocabulary, and thus was not tested on WN. by similarity according to the model. We evalu- ate using the original and most common metrics for relational models: i) the mean of the predicted ranks, and ii) hits@10, which represents the per- centage of correct entities found in the top 10 list; however, other metrics are possible, such as mean reciprocal rank (MRR). We evaluate in both the filtered setting, where other correct responses are removed from the lists ranked by the model, and the raw setting, where no changes are made. We compare against the TransE model with ran- dom initialization, and the SE model <ref type="bibr" target="#b1">(Bordes et al., 2011</ref>). We also compare against the state-of- the-art TransD model ( <ref type="bibr" target="#b6">Ji et al., 2015)</ref>. This model uses two vectors to represent each entity and re- lation; one to represent the meaning of the entity, and one to construct a mapping matrix dynami- cally. This allows for the representation of more diverse entities. <ref type="table">Table 3</ref> summarizes the experimental results, com- pared to baseline and state-of-the-art relational models. We see that the mean rank is greatly im- proved for the TransE model with strategic ini- tialization over random initialization. More sur- prisingly, all of our models achieve state-of-the-art performance for both raw and filtered data, com- pared to the recently developed TransD model. These results are highly significant with p &lt; 10 −3 according to the Mann-Whitney U test. Thus, even though our method is simple and straightfor- ward to apply, it can still beat all attempts at more complicated structural modifications to the TransE model on this dataset. Further, the fact that our op- timal embedding dimensions are larger (30 and 55 vs. 20 and 50) suggests that our initialization ap- proach helps avoid overfitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results and Analysis</head><p>For Freebase, our models slightly outperform the TransE model with random initialization, with p-values of 0.173 and 0.410 for initialization with descriptions (including stopwords) using GloVe and word2vec, respectively. We also see improve- ments over the case of direct initialization with word2vec. Further, we set a new state-of-the-art for mean rank on the raw data, though the im- provement is marginal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>WordNet Relations hyponym derivationally related form member holonym</head><p>Freebase Relations /award/award nominee/award nominations./award/ award nomination/nominated for /broadcast/radio station owner/ radio stations /medicine/disease/notable people with this condition <ref type="table">Table 4</ref>: Sample relations from WordNet and Free- base. The relations from Freebase are clearly much more specific as they relate named entities.</p><p>Finally, we see in <ref type="figure" target="#fig_3">Figure 1</ref> that the TransE model converges more quickly during training when initialized with our approach, compared to random initialization. This is particularly true on WordNet.</p><p>Mean rank and hits@10 discrepancy It is in- teresting to note the relationship between the mean rank and hits@10. By changing our model, we are able to increase one at the expense of the other. For example, using word2vec without stopwords gives similar hits@10 to TransD with better mean rank, while using GloVe further improves the mean rank at a cost to hits@10. The exact nature of this trade- off isn't clear, and is an interesting avenue for fu- ture work.</p><p>However, there are potential reasons for the results discrepancy betweeen mean rank and hits@10. We conjecture that our model helps avoid 'disasters' where some correct entities are ranked very low. For TransE with random initial- ization, these disasters cause a large decrease in mean rank, which is significantly improved by our model. On the other hand, reducing the number of correct entities that are poorly ranked may not sig- nificantly affect the hits@10, since this only con- siders entities near the top of the ranking.</p><p>Note also that using hits@10 to evaluate rela- tional models is not ideal; a model can rank rea- sonable alternative entities highly, but be penal- ized because the target entity is not in the top 10. For example, given "rabbit IS-A", both "animal" and "mammal" fit as target entities. This is al- leviated by filtering, but is not completely elimi- nated due to the sparsity of relations in the dataset (which is the reason we require the link prediction task). Thus, we believe the mean rank is a more accurate measure of the performance of a model, particularly on raw data.</p><p>Dataset differences It is also interesting to note the discrepancy between the results on the Word- Net and Freebase datasets. Although using the entity descriptions leads to a significantly lower mean rank for the WordNet dataset, it only results in a faster convergence rate for Freebase. How- ever, the relations presented in these two datasets are significantly different: WordNet relations are quite general and are meant to provide links be- tween concepts, while the Freebase relations are very specific, and denote relationships between named entities. This is shown in <ref type="table">Table 4</ref>. It seems that incorporating the definition of these named entities does not improve the ability of the algo- rithm to answer very specific relation questions. This would be the case if the optimization land- scape for the TransE model had fewer local min- ima for Freebase than for WordNet, thus rendering it less sensitive to the initial condition. It is also possible that the TransE model is simply not pow- erful enough to achieve a filtered mean rank lower than 90, no matter the initialization strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>We have shown that leveraging external lexical re- sources, along with distributional semantics, can lead to both a significantly improved optimum and a faster rate of convergence when applied with the TransE model for relational data. We established new state-of-the-art results on WordNet, and ob- tain small improvements to the state-of-the-art on raw relational data for Freebase. Our method is quite simple and could be applied in a straight- forward manner to other models that take entity vector representations as input. Further research is needed to investigate whether performance on other NLP tasks can be improved by leveraging available lexical resources in a similar manner.</p><p>More complex methods initialization methods could easily be devised, e.g. by using inverse doc- ument frequency (idf) weighted averaging, or by applying the work of <ref type="bibr" target="#b9">Le et al. (2014)</ref> on para- graph vectors. Alternatively, distributional seman- tics could be used as a regularizer, similar to <ref type="bibr" target="#b8">(Labutov and Lipson, 2013)</ref>, with learned embeddings being penalized for how far they stray from the pre-trained GloVe embeddings. However, even with intuitive and straightforward methodology, leveraging lexical resources can have a significant impact on the results of models for multi-relational data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Learning curves for the mean ranks on the training set for WordNet (left) and Freebase (right).</figDesc><graphic url="image-1.png" coords="4,102.39,248.75,195.02,146.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Sample entity descriptions from Word-
Net and Freebase. As Freebase descriptions are 
lengthy paragraphs, only the first sentence is 
shown. 

</table></figure>

			<note place="foot" n="2"> This means that word2vec was trained in the usual way on a large textual corpus, but the vocabulary was truncated to include as many entities from Freebase as possible. Indeed, this is the reason for the small overlap between W2V, GloVe, and the relational databases: after training the word embeddings, the vocabulary must be truncated to a reasonable size, which leaves out many entities from these datasets.</note>

			<note place="foot" n="3"> Note that we use h, l, t ∈ R k to denote both the entities and relations, in addition to the vector representations of the entities and relations</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Freebase: a collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGMOD</title>
		<meeting>SIGMOD</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning structured embeddings of knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multirelational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Garciaduran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oksana</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A unified model for word sense representation and disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinxiong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1025" to="1035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Retrofitting word vectors to semantic lexicons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sujay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Jauhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Incorporating both distributional and relational semantics in word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Fried</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Knowledge graph embedding via dynamic mapping matrix</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoliang</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shizhu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Combining lexical, syntactic, and semantic features with maximum entropy models for extracting relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanda</forename><surname>Kambhatla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL on Interactive Poster and Demonstration Sessions</title>
		<meeting>ACL on Interactive Poster and Demonstration Sessions</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Re-embedding words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><surname>Labutov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hod</forename><surname>Lipson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Distributed representations of sentences and documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Automatic sense disambiguation using machine readable dictionaries: How to tell a pine cone from an ice cream cone</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Lesk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGDOC</title>
		<meeting>SIGDOC</meeting>
		<imprint>
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Estimating semantic distance using soft semantic constraints in knowledge-source-corpus hybrid models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuval</forename><surname>Marton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saif</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Linguistic regularities in continuous space word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACLHLT</title>
		<meeting>NAACLHLT</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Wordnet: a lexical database for english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Measuring semantic distance using distributional profiles of concepts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saif</forename><surname>Mohammad</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
		<respStmt>
			<orgName>University of Toronto</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Autoextend: Extending word embeddings to embeddings for synsets and lexemes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sascha</forename><surname>Rothe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Combining lexical resources for contextual synonym expansion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravi</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of RANLP</title>
		<meeting>RANLP</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Reasoning with neural tensor networks for knowledge base completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ran</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naoaki</forename><surname>Okazaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kentaro</forename><surname>Inui</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.08407</idno>
		<title level="m">The mechanism of additive composition</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Observed versus latent features for knowledge base and text inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Workshop on Continuous Vector Space Models and their Compositionality</title>
		<meeting>the 3rd Workshop on Continuous Vector Space Models and their Compositionality</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Towards universal paraphrastic sentence embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Wieting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Livescu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.08198</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Rcnet: A general framework for incorporating knowledge into word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yalong</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoguang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CIKM</title>
		<meeting>CIKM</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Embedding entities and relations for learning and inference in knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bishan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
