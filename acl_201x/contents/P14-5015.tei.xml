<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:25+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">kLogNLP: Graph Kernel-based Relational Learning of Natural Language</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>June 23-24, 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathias</forename><surname>Verbeke</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science</orgName>
								<orgName type="department" key="dep2">Dipartimento di Sistemi e Informatica, Università degli Studi di Firenze</orgName>
								<orgName type="department" key="dep3">Institut für Informatik</orgName>
								<orgName type="department" key="dep4">Albert-Ludwigs-Universität</orgName>
								<orgName type="institution">KU Leuven</orgName>
								<address>
									<country>Belgium, Italy, Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Frasconi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science</orgName>
								<orgName type="department" key="dep2">Dipartimento di Sistemi e Informatica, Università degli Studi di Firenze</orgName>
								<orgName type="department" key="dep3">Institut für Informatik</orgName>
								<orgName type="department" key="dep4">Albert-Ludwigs-Universität</orgName>
								<orgName type="institution">KU Leuven</orgName>
								<address>
									<country>Belgium, Italy, Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>De Grave</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science</orgName>
								<orgName type="department" key="dep2">Dipartimento di Sistemi e Informatica, Università degli Studi di Firenze</orgName>
								<orgName type="department" key="dep3">Institut für Informatik</orgName>
								<orgName type="department" key="dep4">Albert-Ludwigs-Universität</orgName>
								<orgName type="institution">KU Leuven</orgName>
								<address>
									<country>Belgium, Italy, Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">♦</forename><surname>Fabrizio</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science</orgName>
								<orgName type="department" key="dep2">Dipartimento di Sistemi e Informatica, Università degli Studi di Firenze</orgName>
								<orgName type="department" key="dep3">Institut für Informatik</orgName>
								<orgName type="department" key="dep4">Albert-Ludwigs-Universität</orgName>
								<orgName type="institution">KU Leuven</orgName>
								<address>
									<country>Belgium, Italy, Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Costa</forename><forename type="middle">♣</forename><surname>Luc</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science</orgName>
								<orgName type="department" key="dep2">Dipartimento di Sistemi e Informatica, Università degli Studi di Firenze</orgName>
								<orgName type="department" key="dep3">Institut für Informatik</orgName>
								<orgName type="department" key="dep4">Albert-Ludwigs-Universität</orgName>
								<orgName type="institution">KU Leuven</orgName>
								<address>
									<country>Belgium, Italy, Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">De</forename><surname>Raedt</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science</orgName>
								<orgName type="department" key="dep2">Dipartimento di Sistemi e Informatica, Università degli Studi di Firenze</orgName>
								<orgName type="department" key="dep3">Institut für Informatik</orgName>
								<orgName type="department" key="dep4">Albert-Ludwigs-Universität</orgName>
								<orgName type="institution">KU Leuven</orgName>
								<address>
									<country>Belgium, Italy, Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">kLogNLP: Graph Kernel-based Relational Learning of Natural Language</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
						<meeting>52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations <address><addrLine>Baltimore, Maryland USA</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="85" to="90"/>
							<date type="published">June 23-24, 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>kLog is a framework for kernel-based learning that has already proven successful in solving a number of relational tasks in natural language processing. In this paper , we present kLogNLP, a natural language processing module for kLog. This module enriches kLog with NLP-specific preprocessors, enabling the use of existing libraries and toolkits within an elegant and powerful declarative machine learning framework. The resulting relational model of the domain can be extended by specifying additional relational features in a declarative way using a logic programming language. This declarative approach offers a flexible way of experimentation and a way to insert domain knowledge.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>kLog ( ) is a logical and re- lational language for kernel-based learning. It has already proven successful for several tasks in com- puter vision ( <ref type="bibr" target="#b4">Antanas et al., 2012;</ref><ref type="bibr" target="#b5">Antanas et al., 2013</ref>) and natural language processing. For ex- ample, in the case of binary sentence classifica- tion, we have shown an increase of 1.2 percent in F1-score on the best performing system in the CoNLL 2010 Shared Task on hedge cue detec- tion (Wikipedia dataset) ( <ref type="bibr" target="#b17">Verbeke et al., 2012a</ref>). On a sentence labeling task for evidence-based medicine, a multi-class multi-label classification problem, kLog showed improved results over both the state-of-the-art CRF-based system of <ref type="bibr" target="#b13">Kim et al. (2011)</ref> and a memory-based benchmark <ref type="bibr" target="#b18">(Verbeke et al., 2012b</ref>). Also for spatial relation ex- traction from natural language, kLog has shown to provide a flexible relational representation to model the task domain ( <ref type="bibr" target="#b14">Kordjamshidi et al., 2012)</ref>.</p><p>kLog has two distinguishing features. First, it is able to transform relational into graph-based rep- resentations, which allows to incorporate struc- tural features into the learning process. Subse- quently, kernel methods are used to work in an ex- tended high-dimensional feature space, which is much richer than most of the direct proposition- alisation approaches. Second, it uses the logic programming language Prolog for defining and using (additional) background knowledge, which renders the model very interpretable and provides more insights into the importance of individual (structural) features.</p><p>These properties prove especially advantageous in the case of NLP. The graphical approach of kLog is able to exploit the full relational represen- tation that is often a natural way to express lan- guage structures, and in this way allows to fully exploit contextual features. On top of this rela- tional learning approach, the declarative feature specification allows to include additional back- ground knowledge, which is often essential for solving NLP problems.</p><p>In this paper, we present kLogNLP 1 , an NLP module for kLog. Starting from a dataset and a declaratively specified model of the domain (based on entity-relationship modeling from database the- ory), it transforms the dataset into a graph-based relational format. We propose a general model that fits most tasks in NLP, which can be extended by specifying additional relational features in a declarative way. The resulting relational represen- tation then serves as input for kLog, and thus re- sults in a full relational learning pipeline for NLP. kLogNLP is most related to Learning-Based Java (LBJ) ( <ref type="bibr" target="#b16">Rizzolo and Roth, 2010)</ref> in that it of- fers a declarative pipeline for modeling and learn- ing tasks in NLP. The aims are similar, namely ab- stracting away the technical details from the pro- grammer, and leaving him to reason about the modeling. However, whereas LBJ focuses more on the learning side (by the specification of con- straints on features which are reconciled at in- ference time, using the constrained conditional  <ref type="figure">Figure 1</ref>: General kLog workflow extended with the kLogNLP module model framework), due to its embedding in kLog, kLogNLP focuses on the relational modeling, in addition to declarative feature construction and feature generation using graph kernels. kLog in it- self is related to several frameworks for relational learning, for which we refer the reader to .</p><p>The remainder of this paper is organized ac- cording to the general kLog workflow, preceded with the kLogNLP module, as outlined in <ref type="figure">Fig- ure 1</ref>. In Section 2, we discuss the modeling of the data, and present a general relational data model for NLP tasks. Also the option to declaratively construct new features using logic programming is outlined. In the subsequent parts, we will illustrate the remaining steps in the kLog pipeline, namely graphicalization and feature generation (Section 3), and learning (Section 4) in an NLP setting. The last section draws conclusions and presents ideas for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data Modeling</head><p>kLog employs a learning from interpretations set- ting <ref type="bibr" target="#b11">(De Raedt et al., 2008)</ref>. In learning from interpretations, each interpretation is a set of tu- ples that are true in the example, and can be seen as a small relational database. Listing 3, to be discussed later, shows a concise example. In the NLP setting, an interpretation most commonly corresponds to a document or a sentence. The scope of an interpretation is either determined by the task (e.g., for document classification, the in- terpretations will at least need to comprise a sin- gle document), or by the amount of context that is taken into account (e.g., in case the task is sen- tence classification, the interpretation can either be a single sentence, or a full document, depending on the scope of the context that you want to take into account).</p><p>Since kLog is rooted in database theory, the modeling of the problem domain is done using an entity-relationship (E/R) model <ref type="bibr" target="#b9">(Chen, 1976)</ref>. It gives an abstract representation of the interpreta- tions. E/R models can be seen as a tool that is tai- Key attributes (green ovals) uniquely identify an instance of an entity. We will now discuss the E/R model we propose as a starting point in the kLogNLP pipeline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">kLogNLP model</head><p>Since in NLP, most tasks are situated at either the document, sentence, or token level, we pro- pose the E/R model in <ref type="figure" target="#fig_0">Figure 2</ref> as a general do- main model suitable for most settings. It is able to represent interpretations of documents as a se- quence (nextS) of sentence entities, which are composed of a sequence (nextW) of word entities. Next to the sequence relations, also the dependency relations between words (depRel) are taken into account, where each relation has its type (depType) as a property. Furthermore, also the coreference relationship between words or phrases (coref) and possibly synonymy re- lations (synonymous) are taken into account.</p><p>The entities in our model also have a primary key, namely wordID and sentID for words and sen- tences respectively. Additional properties can be attached to words such as the wordString it- self, its lemma and POS-tag, and an indication whether the word is a namedEntity. This E/R model of <ref type="figure" target="#fig_0">Figure 2</ref> is coded declara- tively in kLog as shown in Listing 1. The kLog syntax is an extension of the logical programming language Prolog. In the next step this script will be used for feature extraction and generation. Ev-ery entity or relationship is declared with the key- word signature. Each signature is of a certain type; either extensional or intensional. kLogNLP only acts at the extensional level. Each signature is characterized by a name and a list of typed arguments. There are three possible ar- gument types. First of all, the type can be the name of an entity set which has been declared in another signature (e.g., line 4 in Listing 1; the nextS signature represents the sequence relation between two entities of type sentence, namely sent 1 and sent 2). The type self is used to denote the primary key of an entity. An example is word id (line 6), which denotes the unique iden- tifier of a certain word in the interpretation. The last possible type is property, in case the argu- ment is neither a reference to another entity nor a primary key (e.g., postag, line 9).</p><p>We will first discuss extensional signatures, and the automated extensional feature extraction pro- vided by kLogNLP, before illustrating how the user can further enrich the model with intensional predicates.        Listing 1: Declarative representation of the kLogNLP model</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Extensional Feature Extraction</head><p>kLog assumes a closed-world, which means that atoms that are not known to be true, are assumed to be false. For extensional signatures, this en- tails that all ground atoms need to be listed ex- plicitly in the relational database of interpreta- tions. These atoms are generated automatically by the kLogNLP module based on the kLog script and the input dataset. Considering the defined at- tributes and relations in the model presented in Listing 1, the module interfaces with NLP toolk- its to preprocess the data to the relational format. The user can remove unnecessary extensional sig- natures or modify the number of attributes given in the standard kLogNLP script as given in Listing 1 according to the needs of the task under consider- ation. An important choice is the inclusion of the sentence signature. By inclusion, the gran- ularity of the interpretation is set to the docu- ment level, which implies that more context can be taken into account. By excluding this signa- ture, the granularity of the interpretation is set to the sentence level.</p><p>Currently, kLogNLP interfaces with the follow- ing NLP toolkits: The preprocessing toolkit to be used can be set using the kLogNLP flags mechanism, as il- lustrated by line 3 of Listing 2. Subsequently, the dataset predicate (illustrated in line 4 of Listing 2) calls kLogNLP to preprocess a given dataset <ref type="bibr" target="#b0">3</ref> . This is done according to the speci- fied kLogNLP model, i.e., the necessary prepro- cessing modules to be called in the preprocess- ing toolkit are determined based on the presence of the entities, relationships, and their attributes in the kLogNLP script. For example, the presence of namedentity as a property of word results in the addition of a named entity recognizer in the preprocessing toolkit. The resulting set of inter- pretations is output to a given file. In case sev- eral instantiations of a preprocessing module are available in the toolkit, the preferred one can be chosen by setting the name of the property accord- ingly. The names as given in Listing 1 outline the standard settings for each module. For instance, in case the Snowball stemmer is preferred above the standard (Wordnet) lemmatizer in NLTK, it can be selected by changing lemma into snowball as name for the word lemma property (line 8). </p><formula xml:id="formula_0">NLTK</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Listing 2: Full predicate for 10-fold classification experiment</head><p>Each interpretation can be regarded as a small relational database. We will illustrate the exten- sional feature extraction step on the CoNLL-2010 dataset on hedge cue detection, a binary classifi- cation task where the goal is to detect uncertainty in sentences. This task is situated at the sentence level, so we left out the sentence and nextS signatures, as no context from other sentences was taken into account. A part of a resulting interpre- tation is shown in Listing 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Listing 3: Part of an interpretation</head><p>Optionally, additional extensional signatures can easily be added to the knowledge base by the user, as deemed suitable for the task under consid- eration. At each level of granularity (document, sentence, or word level), the user is given the corresponding interpretation and entity IDs, with which additional extensional facts can be added using the dedicated Python classes. We will now turn to declarative feature construction. The fol- lowing steps are inherently part of the kLog frame- work. We will briefly illustrate their use in the context of NLP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Declarative Feature Construction</head><p>The kLog script presented in Listing 1 can now be extended using declarative feature construction with intensional signatures. In contrast to ex- tensional signatures, intensional signatures intro- duce novel relations using a mechanism resem- bling deductive databases. This type of signatures is mostly used to add domain knowledge about the task at hand. The ground atoms are defined implic- itly using Prolog definite clauses.</p><p>For example, in case of sentence labeling for evidence-based medicine, the lemma of the root word proved to be a distinguishing feature <ref type="bibr" target="#b18">(Verbeke et al., 2012b</ref>), which can be expressed as Also more complex features can be constructed. For example, section headers in documents (again in the case of sentence labeling using document context) can be identified as follows:</p><p>1 hasHeaderWord(S,X) :-   In this case, first the sentences that contain a header word are identified using the helper pred- icate hasHeaderWord, where a header word is defined as an upper case string that has more than four letters (lines 1-7). Next, all sentences that rep- resent a section header are identified using the in- tensional signature isHeaderSentence (lines 9-11), and each sentence in the paragraphs follow- ing a particular section header is labeled with this header, using the hasSectionHeader predi- cate (lines <ref type="bibr">[13]</ref><ref type="bibr">[14]</ref><ref type="bibr">[15]</ref><ref type="bibr">[16]</ref><ref type="bibr">[17]</ref><ref type="bibr">[18]</ref><ref type="bibr">[19]</ref><ref type="bibr">[20]</ref>.</p><p>Due to the relational approach, the span can be very large. Furthermore, since these features are defined declaratively, there is no need to reprocess the dataset each time a new feature is introduced, which renders experimentation very flexible 4 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Graphicalization and Feature Generation</head><p>In this step, a technique called graphicalization transforms the relational representations from the previous step into graph-based ones and derives features from a grounded entity/relationship dia- gram using graph kernels. This can be interpreted as unfolding the E/R diagram over the data. An ex- ample of the graphicalization of the interpretation part in Listing 3 can be found in <ref type="figure" target="#fig_2">Figure 3</ref>. From the resulting graphs, features can be ex- tracted using a feature generation technique that is based on Neighborhood Subgraph Pairwise Dis-tance Kernel (NSPDK) <ref type="bibr" target="#b10">(Costa and De Grave, 2010</ref>), a particular type of graph kernel. Infor- mally the idea of this kernel is to decompose a graph into small neighborhood subgraphs of in- creasing radii r ≤ r max . Then, all pairs of such subgraphs whose roots are at a distance not greater than d ≤ d max are considered as individual fea- tures. The kernel notion is finally given as the frac- tion of features in common between two graphs. Formally, the kernel is defined as:</p><formula xml:id="formula_1">κ r,d (G, G ) = A,B∈R −1 r,d (G) A ,B ∈R −1 r,d (G ) 1 A ∼ =A · 1 B ∼ =B (1)</formula><p>where R −1 r,d (G) indicates the multiset of all pairs of neighborhoods of radius r with roots at distance d that exist in G, and where 1 denotes the indicator function and ∼ = the isomorphism between graphs. For the full details, we refer the reader to <ref type="bibr" target="#b10">(Costa and De Grave, 2010)</ref>. The neighborhood pairs are illustrated in <ref type="figure">Figure 4</ref> for a distance of 2 between two arbitrary roots (v and u).</p><p>In kLog, the feature set is generated in a combi- natorial fashion by explicitly enumerating all pairs of neighborhood subgraphs; this yields a high- dimensional feature space that is much richer than most of the direct propositionalization approaches. The result is an extended high-dimensional fea- ture space on which a statistical learning algorithm can be applied. The feature generator is initialized using the new feature generator predicate and hyperparameters (e.g., maximum distance and radius, and match type) can be set using the kLog flags mechanism (Listing 2, lines 6-10).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Learning</head><p>In the last step, different learning tasks can be per- formed on the resulting extended feature space. To this end, kLog interfaces with several solvers, in- cluding <ref type="bibr">LibSVM (Chang and Lin, 2011</ref>) and SVM SGD <ref type="bibr" target="#b7">(Bottou, 2010)</ref>. Lines 11-15 (Listing 2) illus- trate the initialization of LibSVM and its use for 10-fold cross-validation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions and Future Work</head><p>In this paper, we presented kLogNLP, a natu- ral language processing module for kLog. Based on an entity-relationship representation of the do- main, it transforms a dataset into the graph-based relational format of kLog. The basic kLogNLP model can be easily extended with additional background knowledge by adding relations us- ing the declarative programming language Prolog. This offers a more flexible way of experimenta- tion, as new features can be constructed on top of existing ones without the need to reprocess the dataset. In future work, interfaces will be added to other (domain-specific) NLP frameworks (e.g., the BLLIP parser with the self-trained biomedical parsing model <ref type="bibr" target="#b15">(McClosky, 2010)</ref>) and additional dataset formats will be supported.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Entity-relationship diagram of the kLogNLP model lored to model the domain at hand. As the name indicates, E/R models consist of entities, which we will represent as purple rectangles, and relations, represented as orange diamonds. Both entities and relations can have several attributes (yellow ovals). Key attributes (green ovals) uniquely identify an instance of an entity. We will now discuss the E/R model we propose as a starting point in the kLogNLP pipeline.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>3 4</head><label>3</label><figDesc>signature nextS(sent_1::sentence, sent_2 ::sentence)::extensional.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>12 13 signature nextW(word_1::word, word_2:: word)::extensional.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>14 15 signature corefPhrase(coref_id::self):: extensional. 16 signature isPartOfCorefPhrase( coref_phrase::corefPhrase, word:: word)::extensional. 17 signature coref(coref_phrase_1:: corefPhrase, coref_phrase_2:: corefPhrase)::extensional.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>25 26 kernel_points([word]). 27 end_domain.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>%</head><label></label><figDesc>Kernel parametrization 7 new_feature_generator(my_fg,nspdk), 8 klog_flag(my_fg,radius,1), 9 klog_flag(my_fg,distance,1), 10 klog_flag(my_fg,match_type, hard), 11 % Learner parametrization 12 new_model(my_model,libsvm_c_svc), 13 klog_flag(my_model,c,0.1), 14 kfold(target, 10, my_model, my_fg).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>2 word(W,X,_,_,_,_), 3 hasWord(S,W), 4 (atom(X) -&gt; name(X,C) ; C = X), 5 length(C,Len), 6 Len &gt; 4, 7 all_upper(C).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>17 hasSectionHeader(S,X) :- 18 nextS(S1,S), 19 not isHeaderSentence(S), 20 once(hasSectionHeader(S1,X)).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 3 :Figure 4 :</head><label>34</label><figDesc>Figure 3: Graphicalization of the (partial) interpretation in Listing 3. For the sake of clarity, attributes of entities and relationships are depicted inside the respective entity or relationship. r=0 d=2</figDesc></figure>

			<note place="foot" n="2"> http://nlp.stanford.edu/software/ corenlp.shtml 3 Currently supported dataset formats are directories consisting of (one or more) plain text files or XML files consisting of sentence and/or document elements.</note>

			<note place="foot" n="1"> word(w1,often,often,rb,0,1).</note>

			<note place="foot" n="4"> Note that changes in the extensional signatures do require reprocessing the dataset. However, for different runs of an experiment with varying parameters for the feature generator or the learner, kLogNLP uses a caching mechanism to check if the extensional signatures have changed, when calling the dataset predicate.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research is funded by the Research Founda-tion Flanders (FWO project G.0478.10-Statistical Relational Learning of Natural Language). KDG was supported by ERC StG 240186 "MiGraNT".</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">nextW(w1,w2)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">nextW(w2,w3)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">nextW(w3,w4)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">nextW(w4,w5)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A relational kernel-based framework for hierarchical image understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Antanas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Frasconi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabrizio</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tinne</forename><surname>Tuytelaars</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc De</forename><surname>Raedt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012-11" />
			<biblScope unit="page" from="171" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A relational kernel-based approach to scene classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Antanas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mcelory</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Frasconi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tinne</forename><surname>Tuytelaars</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc De</forename><surname>Raedt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Workshop on Applications of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">0</biblScope>
			<biblScope unit="page" from="133" to="139" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Natural Language Processing with Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ewan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Loper</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Reilly Media, Inc</publisher>
		</imprint>
	</monogr>
	<note>1st edition</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Large-scale machine learning with stochastic gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 19th International Conference on Computational Statistics (COMPSTAT&apos;2010)</title>
		<meeting>of the 19th International Conference on Computational Statistics (COMPSTAT&apos;2010)</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="177" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">LIBSVM: A library for support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chung</forename><surname>Chih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Jen</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
		<ptr target="http://www.csie.ntu.edu.tw/˜cjlin/libsvm" />
	</analytic>
	<monogr>
		<title level="m">27. Software available at</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The entity-relationship model-toward a unified view of data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter Pin-Shan</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Database Syst</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="9" to="36" />
			<date type="published" when="1976-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fast neighborhood subgraph pairwise distance kernel</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabrizio</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>De Grave</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 26th International Conference on Machine Learning</title>
		<meeting>of the 26th International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>Omnipress</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="255" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Probabilistic Inductive Logic Programming-Theory and Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Luc De Raedt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Frasconi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lecture Notes in Computer Science</title>
		<editor>Kristian Kersting, and Stephen Muggleton</editor>
		<imprint>
			<biblScope unit="volume">4911</biblScope>
			<date type="published" when="2008" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">klog: A language for logical and relational learning with kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Frasconi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabrizio</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>De Raedt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><forename type="middle">De</forename><surname>Grave</surname></persName>
		</author>
		<idno>abs/1205.3981</idno>
		<imprint>
			<date type="published" when="2012" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Automatic classification of sentences to support evidence based medicine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Su</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Cavedon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Yencken</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note>Suppl</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Relational learning for spatial relation extraction from natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parisa</forename><surname>Kordjamshidi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Frasconi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Francine</forename><surname>Martijn Van Otterlo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc De</forename><surname>Moens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Raedt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Inductive Logic Programming</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="204" to="220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Any Domain Parsing: Automatic Domain Adaptation for Natural Language Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">3430199</biblScope>
			<pubPlace>Providence, RI, USA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Brown University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning based java for rapid development of nlp systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rizzolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC, Valletta</title>
		<meeting><address><addrLine>Malta</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Kernel-based logical and relational learning with kLog for hedge cue detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathias</forename><surname>Verbeke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Frasconi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Van Asch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roser</forename><surname>Morante</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walter</forename><surname>Daelemans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc De</forename><surname>Raedt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 21st International Conference on Inductive Logic Programming</title>
		<meeting>of the 21st International Conference on Inductive Logic Programming</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012-03" />
			<biblScope unit="page" from="347" to="357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A statistical relational learning approach to identifying evidence based medicine categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathias</forename><surname>Verbeke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Van Asch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roser</forename><surname>Morante</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Frasconi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walter</forename><surname>Daelemans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc De</forename><surname>Raedt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>of the 2012 Joint Conference on Empirical Methods in Natural Language essing and Computational Natural Language Learning</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="579" to="589" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
