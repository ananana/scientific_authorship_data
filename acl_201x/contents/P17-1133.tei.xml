<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:08+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Prerequisite Relation Learning for Concepts in MOOCs</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangming</forename><surname>Pan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengjiang</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juanzi</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Tang</surname></persName>
						</author>
						<title level="a" type="main">Prerequisite Relation Learning for Concepts in MOOCs</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</title>
						<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1447" to="1456"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-1133</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>What prerequisite knowledge should students achieve a level of mastery before moving forward to learn subsequent coursewares? We study the extent to which the prerequisite relation between knowledge concepts in Massive Open On-line Courses (MOOCs) can be inferred automatically. In particular, what kinds of information can be leveraged to uncover the potential prerequisite relation between knowledge concepts. We first propose a representation learning-based method for learning latent representations of course concepts, and then investigate how different features capture the prerequisite relations between concepts. Our experiments on three datasets form Coursera show that the proposed method achieves significant improvements (+5.9-48.0% by F1-score) comparing with existing methods.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Mastery learning was first formally proposed by <ref type="bibr">Benjamin Bloom in 1968</ref><ref type="bibr" target="#b0">(Bloom, 1981</ref>, suggest- ing that students must achieve a level of mastery (e.g., 90% on a knowledge test) in prerequisite knowledge before moving forward to learn sub- sequent knowledge concepts. From then on, pre- requisite relations between knowledge concepts become a cornerstone for designing curriculum in schools and universities. Prerequisite relations essentially can be considered as the dependency among knowledge concepts. It is crucial for peo- ple to learn, organize, apply, and generate knowl- edge ( <ref type="bibr" target="#b9">Laurence and Margolis, 1999</ref>). <ref type="figure" target="#fig_0">Figure 1</ref> shows a real example from Coursera. The student wants to learn "Conditional Random Field" (in video18 of CS229). The prerequisite knowledge might be "Hidden Markov Model" (in video25 of ), whose prerequisite knowledge is "Maxi- mum Likelihood" (in video12 of Math112).</p><p>Organizing the knowledge structure with pre- requisite relations in education improves tasks such as curriculum planning , automatic reading list generation <ref type="bibr" target="#b7">(Jardine, 2014)</ref>, and improving education quality <ref type="bibr" target="#b20">(Rouly et al., 2015</ref>). For example, as shown in <ref type="figure" target="#fig_0">Figure 1</ref>, with explicit prerequisite relations among concepts (in red), a coherent and reasonable learning sequence can be recommended to the student (in blue). Before, the prerequisite relationships were pro- vided by teachers or teaching assistants <ref type="bibr" target="#b16">(Novak, 1990)</ref>; however in the era of MOOCs, it is becoming infeasible as the teachers would find that they are facing with hundreds of thousands of students with various background. Meanwhile, the rapid growth of Massive Open Online Courses has offered thousands of courses, and students are free to choose any course from the thousands of candidates. Therefore, there is a clear need for methods to automatically dig out the prerequisite relationships among knowledge concepts from the large course space, so that the students from differ- ent background can easily explore the knowledge space and better design their personalized learning schedule.</p><p>There are a few efforts aiming to automati- cally detect prerequisite relations for knowledge base. For example, <ref type="bibr" target="#b23">Talukdar and Cohen (2012)</ref> proposed a method for inferring prerequisite rela- tionships between entities in Wikipedia and <ref type="bibr" target="#b10">Liang et al. (2015)</ref> presented a more general approach to predict prerequisite relationships. A few other works intend to extract prerequisite relationships from textbooks <ref type="bibr" target="#b28">(Yosef et al., 2011;</ref><ref type="bibr" target="#b25">Wang et al., 2016)</ref>. However, it is far from sufficient to directly apply these methods to the MOOC environments due to the following reasons. First, the focus of most previous attempts has been on prereq- uisite inference of Wikipedia concepts (either Wikipedia articles or Wikipedia concepts in text- books). Many course concepts are not included in Wikipedia <ref type="bibr" target="#b22">(Schweitzer, 2008;</ref><ref type="bibr" target="#b17">Okoli et al., 2014</ref>). We can leverage Wikipedia, in particular the exist- ing entity relationships in Wikipedia, but cannot only rely on Wikipedia for detecting prerequisite relations in MOOCs. Second, with the thousands of courses from different universities and also very different disciplinaries, the MOOC scenario is much more complicated -there are not only inter-course concept relationships, but also intra- course and even intra-disciplinary relationships. Moreover, user interactions with the MOOC sys- tem might be also helpful to identify the prerequi- site relations. How to fully leverage the different information to obtain a better performance for inferring prerequisite relations in MOOCs is a challenging issue.</p><p>In this paper, we attempt to figure out what kinds of information in MOOCs can be used to uncover the prerequisite relations among concepts. Specifically, we consider it from three aspects, including course concept semantics, course video context and course structure. First, semantic relatedness plays an important role in prerequisite relations between concepts. If two concepts have very different semantic meanings (e.g., "matrix" and "anthropology"), it is unlikely that they have prerequisite relations. However, statistical fea- tures in MOOCs do not provide sufficient in- formation for capturing the concept semantics because of the short length of course videos in MOOCs, we propose an embedding-based method to incorporate external knowledge from Wikipedia to learn semantic representations of concepts in MOOCs. Based on it, we propose one seman- tic feature to calculate the semantic relatedness between concepts. Second, motivated by the reference distance (RefD) ( <ref type="bibr" target="#b10">Liang et al., 2015)</ref>, we propose three new contextual features, i.e., Video Reference Distance, Sentence Reference Distance and Wikipedia Reference Distance, to infer prerequisite relations in MOOCs based on context information from different aspects, which are more general and informative than RefD and overcome its sparsity problem. Third, we examine different distributional patterns for concepts in MOOCs, including appearing position, distribu- tional asymmetry, video coverage and survival time. We further propose three structural fea- tures to utilize these patterns to help prerequisite inference in MOOCs.</p><p>To evaluate the proposed method, we construct three datasets, each of which consists of multiple real courses in a specific domain from Coursera 1 , the largest MOOC platform in the world. We also compare our method with the representative works of prerequisite learning and make a deep analysis of the feature contribution proposed in the paper. The experimental results show that our method achieves the state-of-the-art results in the prerequisite relation discovery in MOOCs. In summary, our contributions include: a) the first attempt, to the best of our knowledge, to detect prerequisite relations among concepts in MOOCs; b) proposal of a set of novel features that utilize contextual, structural and semantic information in MOOCs to identify prerequisite relations; c) design of three useful datasets based on real courses of Coursera to evaluate our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Problem Formulation</head><p>In this section, we first give some necessary definitions and then formulate the problem of prerequisite relation learning in MOOCs.</p><p>A MOOC corpus is composed by n courses in the same subject area, denoted as</p><formula xml:id="formula_0">D = {C 1 , · · · , C i , · · · , C n }, where C i is one course. Each course C can be further represented as a video sequence C = (V 1 , · · · , V i , · · · , V |C| ),</formula><p>where V i denotes the i-th teaching video of course C. Finally, we view each video V as a document of its video texts (video subtitles or speech script), i.e.,</p><formula xml:id="formula_1">V = (s 1 · · · s i · · · s |V| )</formula><p>, where s i is the i-th sentence of the video texts.</p><p>Course concepts are subjects taught in the course, i.e., the concepts not only mentioned but also discussed and taught in the course. Let us denote the course concept set of D as K = K 1 ∪ · · · ∪ K n , where K i is the set of course concepts in C i .</p><p>Prerequisite relation learning in MOOCs is formally defined as follows. Given a MOOC corpus D and its corresponding course concepts K, the objective is to learn a function P : K 2 → {0, 1} that maps a concept pair a, b, where a, b ∈ K, to a binary class that predicts whether a is a prerequisite concept of b.</p><p>In order to learn this mapping, we need to answer two crucial questions. How could we represent a course concept? What information regarding a concept pair is helpful to capture their prerequisite relation? We first propose an embedding-based method to learn appropriate semantic representations for each course concept in K. Based on the learned representations, we propose 7 novel features to capture whether a concept pair has prerequisite relation. These features utilize different aspects of information and can be classified into 1 semantic feature, 3 contextual features and 3 structural features. In the following section, we first describe the semantic representations in detail, and then formally intro- duce our proposed features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Concept Representation &amp; Semantic Relatedness</head><p>We first learn appropriate representations for course concepts. Given the course concepts K as input, we utilize a Wikipedia corpus to learn semantic representations for concepts in K. A Wikipedia corpus W is a set of Wikipedia articles and can be represented as a sequence of words W = w 1 · · · w i · · · w m , where w i denotes a word and m is the length of the word sequence. Our method consists of two steps: (1) entity annotation, and (2) representation learning. Entity Annotation. We first automatically annotate the entities in W to obtain an entity set E and an entity-annotated Wikipedia corpus</p><formula xml:id="formula_2">W = x 1 · · · x i · · · x m</formula><p>, where x i corresponds to a word w ∈ W or an entity e ∈ E. Note that m &lt; m because multiple adjacent words could be labeled as one entity. Many entity linking tools are available for entity annotation, e.g. TAGME <ref type="bibr" target="#b4">(Ferragina and Scaiella, 2010</ref>), AIDA (Yosef et al., 2011) and <ref type="bibr">TremenRank (Cao et al., 2015)</ref>. However, the rich hyperlinks created by Wiki editors provide a more natural way. In our experiments, we simply use the hyperlinks in Wikipedia articles as annotated entities.</p><p>Representation Learning. We then learn word embeddings ( <ref type="bibr" target="#b15">Mikolov et al., 2013b</ref>,a) on W to obtain low-dimensional, real-valued vector repre- sentations for entities in E and words in W. Let us denote v e and v w as the vector of e ∈ E and w ∈ W, respectively. For a course concept a ∈ K, suppose a is a N -gram term g 1 · · · g N and g 1 , · · · , g N ∈ W, we obtain its semantic representations v a as follows.</p><formula xml:id="formula_3">va = ve, if a ≡ e and e ∈ E vg 1 + · · · + vg N , otherwise<label>(1)</label></formula><p>It means that if a is a Wikipedia entity, we can directly obtain its semantic representations; otherwise, we obtain its vector via the vector addition of its individual word vectors. In this way, a has no corresponding vector only if any of its constituent word is absence in the whole Wikipedia corpus. This case is unusual because a large online encyclopedia corpus can easily cover almost all individual words of the vocabulary. Our experimental results verify that over 98% of the course concepts have vector representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feature 1: Semantic Relatedness</head><p>For a given concept pair a, b, the semantic relatedness between a and b, denoted as ω(a, b), is our first feature (the only semantic feature). With learned semantic representations, semantic relatedness of two concepts can be easily reflected by their distance in the vector space. We define ω(a, b) ∈ [0, 1] as the normalized cosine distance between v a and v b , as follows.</p><formula xml:id="formula_4">ω(a, b) = 1 2 (1 + va · v b va · v b ) (2)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Contextual Features</head><p>Context information in course videos provides important clues to infer prerequisite relations. In videos where concept A is taught, if the teacher also mentions concept B for a lot but not vice versa, then B is more likely to be a prerequisite of A than A of B. For example, "gradient descent" is a prerequisite concept of "back propagation". In teaching videos of "back propagation", the con- cept "gradient descent" is frequently mentioned when illustrating the optimization detail of back propagation. On the contrary, however, "back propagation" is unlikely to be mentioned when teaching "gradient descent". A similar observation also exists in Wikipedia, based on which <ref type="bibr" target="#b10">Liang et al. (2015)</ref> proposed an indicator, namely reference distance (RefD), to infer prerequisite relations among Wikipedia articles. However, RefD is computed based on the link structure of Wikipedia, thus is only feasible for Wikipedia concepts and is not applicable in plain text. We overcome the above shortcomings of RefD to pro- pose three novel features, which utilize different aspects of context information-course videos, video sentences and Wikipedia articles-to infer prerequisite relations in MOOCs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feature 2: Video Reference Distance</head><p>Given a concept pair a, b where a, b ∈ K, we propose the video reference weight (V rw) to quantify how b is referred by videos of a, defined as follows.</p><formula xml:id="formula_5">V rw (a, b) = C∈D V∈C f (a, V) · r (V, b) C∈D V∈C f (a, V)<label>(3)</label></formula><p>where f (a, V) indicates the term frequency of concept a in video V, which reflects how im- portant is concept a to this video. r (V, b) ∈ {0, 1} denotes whether concept b appears in video V. Intuitively, if b appears in more important videos of a, V rw (a, b) tends to be larger, and the range of V rw (a, b) is between 0 and 1. Then, the video reference distance (V rd) is defined as the difference of V rw between two concepts, as follows.</p><formula xml:id="formula_6">V rd (a, b) = V rw (b, a) − V rw (a, b)<label>(4)</label></formula><p>In practice, this feature may be too sparse if the MOOC corpus is small. For an arbitrary concept pair, they may have no co-occurrence in all course videos. We expend the video reference distance to a more general version by considering the semantic relatedness among concepts. Besides the conditions in which A refers to B, we also consider the cases in which A-related concepts refer to B. We first define the generalized video reference weight (GV rw) as follows.</p><formula xml:id="formula_7">GV rw (a, b) = M i=1 V rw (ai, b) · ω (ai, b) M i=1 ω (ai, b)<label>(5)</label></formula><p>where a 1 , · · · , a M ∈ K are the top-M most similar concepts of a, measured by the semantic relatedness function ω(·, ·) in feature 1. GV rw is the weighted average of V rw (a i , b), indicating how b is referred by a-related concepts in their corresponding videos. Note that a 1 = a, thus GV rw (a, b) ≡ V rw (a, b) when M = 1. Sim- ilarly, we define the generalized video reference distance (GV rd) as follows.</p><formula xml:id="formula_8">GV rd (a, b) = GV rw (b, a) − GV rw (a, b)<label>(6)</label></formula><p>Intuitively, if most of b-related concepts refer to a but not vice versa, then a is likely to be a prerequisite of b. For example, it is plausible for the related concepts of "gradient descent", e.g., "steepest descent" and "Newton's method", to mention "matrix" but clearly not vice versa.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feature 3: Sentence Reference Distance</head><p>Sentence reference distance is similar to feature 2, but stands on the sentence level. Following the same design pattern of feature 2, we define the sentence reference weight (Srw) and sentence reference distance (Srd) as follows.</p><formula xml:id="formula_9">Srw (a, b) = C∈D V∈C s∈V r(s, a) · r(s, b) C∈D V∈C s∈V r(s, a) (7) Srd (a, b) = Srw (b, a) − Srw (a, b)<label>(8)</label></formula><p>where r (s, a) ∈ {0, 1} is an indicator of whether concept a appears in sentence s. Srw(a, b) calculates the ratio of B appearing in the sentences of a. We also define generalized sentence ref- erence weight (GSrw) and generalized sentence reference distance (GSrd) as follows.</p><formula xml:id="formula_10">GSrw (a, b) = M i=1 Srw (ai, b) · ω (ai, b) M i=1 ω (ai, b)<label>(9)</label></formula><formula xml:id="formula_11">GSrd (a, b) = GSrw (b, a) − GSrw (a, b)<label>(10)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feature 4: Wikipedia Reference Distance</head><p>Contextual information of Wikipedia is also useful for detecting prerequisite relations. As mention before, RefD is not general enough to be applied in our settings, because it is limited to Wikipedia concepts. Therefore, we improve this indicator to a more general one, which is also suitable for non-wiki concepts.</p><p>Specifically, for a concept a ∈ K, let us denote the top-M most related wiki entities of a as R a = e 1 , · · · , e M , where e 1 , · · · , e M ∈ E. Because concepts in K and entities in E are jointly embedded in the same vector space in Section 3.1, we can easily obtain R a with the semantic relatedness metric ω(·, ·) in Feature 1. We then define the wikipedia reference weight (W rw) as follows.</p><formula xml:id="formula_12">W rw (a, b) = e∈Ra Erw (e, b) · ω (e, a) e∈Ra ω (e, a)<label>(11)</label></formula><p>where Erw(e, a) is a binary indicator, in which Erw(e, a) = 1 if the Wikipedia article of e refers to any entity in R a , and Erw(e, a) = 0 other- wise. W rw (a, b) measures how frequently that a- related wiki entities refer to b-related wiki entities. Finally, wikipedia reference distance (W rd) is defined as the difference of W rw between a and b, i.e., W rd (a, b) = W rw (b, a) − W rw (a, b).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Structural Features</head><p>Since course concepts are usually introduced based on their learning dependencies, the structure of MOOC courses also significantly contribute to prerequisite relation inference in MOOCs. However, structure-based features for prerequisite detection have not been well-studied in previous works. In this section, we investigate different structural information, including appearing posi- tions of concepts, learning dependencies of videos and complexity levels of concepts, to propose three novel features to infer prerequisite relations in MOOCs. Before introducing these features, let us define two useful notations as follows. C(a) are the courses in which a is a course concept, i.e.,</p><formula xml:id="formula_13">C(a) = {C i |C i ∈ D, a ∈ K i }. I(C, a) are the video indexes that contain concept a in course C.</formula><p>For example, if a appears in the first and the 4-th video of C, then I(C, a) = {1, 4}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feature 5: Average Position Distance</head><p>In a course, for a specific concept, its pre- requisite concepts tend to be introduced before this concept and its subsequent concepts tend to be introduced after this concept. Based on this observation, for a concept pair a, b, we calculate the distance of the average appearing position of a and b as one feature, namely average position distance (Apd). If C(a) ∩ C(b) = ∅, Apd (a, b) is formally defined as follows.</p><formula xml:id="formula_14">Apd (a, b) = C∈C(a)∩C(b) i∈I(C,a) i |I(C,a)| − j∈I(C,b) j |I(C,b)| |C(a) ∩ C(b)|<label>(12)</label></formula><p>If C(a) ∩ C(b) = ∅, we set Apd (a, b) = 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feature 6: Distributional Asymmetry Distance</head><p>We also use the learning dependency of course videos to help infer learning dependency of course concepts. Based on our observation, the chance that a prerequisite concept is frequently mentioned in its subsequent videos is larger than that a sub- sequent concept is talked about in its prerequisite videos. Specifically, if video V a is a precursor video of V b , and a is a prerequisite concept of b, then it is likely that f (b, V a ) &lt; f (a, V b ), where f (a, V) denotes the term frequency of a in video V. We thus define another feature, namely distri- butional asymmetry distance (Dad), to calculate the extent that a given concept pair satisfies this distributional asymmetry pattern. Formally, in course C, for a given concept pair a, b, we first define S(C) = {(i, j)|i ∈ I(C, a), j ∈ I(C, b), i &lt; j}, i.e., all possible video pairs of a, b that have sequential relation. Then, the distributional asymmetry distance of a, b is formally defined as follows.</p><formula xml:id="formula_15">Dad (a, b) = C∈C(a)∩C(b) (i,j)∈S(C) f (a,V C i )−f (b,V C j ) |S(C)| |C(a) ∩ C(b)|<label>(13)</label></formula><p>where V C i denotes the i-th video of course C. If C(a) ∩ C(b) = ∅, we set Dad (a, b) = 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feature 7: Complexity Level Distance</head><p>Two related concepts with prerequisite relation- ship tend to have a difference in their complexity level, meaning that one concept is basic while another one is advanced. For example, "data set" and "training set" have learning dependencies and the latter concept is more advanced than the former one. However, "test set" and "training set" have no such relation when their complexity levels are similar. Complexity level of a course concept is implicit in its distribution in courses. Specifically, we observe that, for a concept in MOOCs, if it covers more videos in a course or it survives longer time in a course, then it is more likely to be a basic concept rather than an advanced one. We then formally define the average video coverage (avc) and the average survival time (ast) of a concept a as follows.</p><formula xml:id="formula_16">avc (a) = 1 |C(a)| C∈C(a) |I(C, a)| |C| (14) ast (a) = 1 |C(a)| C∈C(a) max(I(C, a)) − min(I(C, a)) + 1 |C|<label>(15)</label></formula><p>where max/min(I(C, a)) obtains the video index where a appears the last/first time in course C. Based on the above equations, we define the complexity level distance (Cld) between concept a and b as follows.</p><formula xml:id="formula_17">Cld (a, b) = avc (a) · ast (a) − avc (b) · ast (b)<label>(16)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data Sets</head><p>In order to validate the efficiency of our features, we conducted experiments on three MOOC cor- pus with different domains: "Machine Learning" (ML), "Data Structure and Algorithms" (DSA), and "Calculus" (CAL). To the best of our knowl- edge, there is no public data set for mining First, for each chosen domain, we select its relevant courses from Coursera, one of the leading MOOC platforms, and download all course mate- rials using coursera-dl 2 , a widely-used tool for automatically downloading Coursera.org videos. For example, for ML, we select 5 related courses 3 from 5 different universities and obtain a total of 548 course videos. Then, we manually label course concepts for each course: (1) Extract candidate concepts from documents of video sub- titles following the method of <ref type="bibr" target="#b18">Parameswaran et al. (2010)</ref>. <ref type="formula">(2)</ref> Label the candidates as "course concept" or "not course concept" and obtain a set of course concepts for this course.</p><p>Finally, we manually annotate the prerequisite relations among the labeled course concepts. If the number of course concepts is n, the number of all possible pairs to be checked could reach n × (n − 1)/2, which requires arduous human labeling work. Therefore, for each dataset, we randomly select 25 percent of all possible pairs for evaluation. For each course concept pair a, b, three human annotators majoring in the corresponding domain were asked to label them as "a is b's prerequisite", "b is a's prerequisite" or "no prerequisite relationship" using their own knowledge background and additional textbook resources. We take a majority vote of the anno- tators to create final labels and access the inter- annotator agreement using the average of pairwise κ statistics ( <ref type="bibr" target="#b8">Landis and Koch, 1981)</ref> between all pairs of the three annotators.</p><p>The statistics of the three datasets are listed in <ref type="table">Table 1</ref>, where #courses and #videos are the total number of courses and videos in each dataset and #concepts is the number of labeled course concepts. The #pairs denotes the number of labeled concept pairs for evaluation, in which '+'  <ref type="table">Table 2</ref>: Classification results of the proposed method(%). denotes the number of positive instances, i.e. pairs who have prerequisite relations, and '−' denotes the number of negative instances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation Results</head><p>For each dataset, we apply 5-fold cross valida- tion to evaluate the performance of the proposed method, i.e., testing our method on one fold while training the classifier using the other 4 folds. Usually, there are much fewer positive instances than negative instances, so we balance the training set by oversampling the positive instances <ref type="bibr" target="#b28">(Yosef et al., 2011;</ref><ref type="bibr" target="#b23">Talukdar and Cohen, 2012)</ref>. In our experiments, we employ 4 different binary classifiers, including Na¨ıveBayesNa¨ıveBayes (NB), Logistic Regression (LR), SVM with linear kernel (SVM) and Random Forest (RF). We use precision (P ), recall (R), and F1-score (F 1 ) to evaluate the pre- requisite classification results. The experimental results are presented in <ref type="table">Table 2</ref>.</p><p>Contextual features are shaped by the parameter M , i.e., the number of related concepts being considered. In our experiments, we tried different settings of M and report the results when M =1 and M =10 in <ref type="table">Table 2</ref>. As for the semantic representation, we use the latest publicly available Wikipedia dump <ref type="bibr">4</ref> and apply the skip-gram model ( <ref type="bibr" target="#b15">Mikolov et al., 2013b</ref>) to train word embeddings using the Python library gensim 5 with default parameters.</p><p>As shown in <ref type="table">Table 2</ref>, the evaluation results varies by different classifiers. It turns out that Na¨ıveBayesNa¨ıveBayes performs the worst. This seems to be caused by the fact that the independence assumption is not satisfied for our features; for example, Feature 2 and Feature 3 both utilize the local context information, only with different granularity, thus are quite co-related. Random Forest beats others, with best F 1 across all three datasets. Its average F 1 outperforms SVM, NB and LR by 7.0%, 11.1% and 8.3%, respectively (M =10). The reason is as follows. Instead of a simple descriptive feature, each of our proposed feature determines whether a concept pair has pre- requisite relation from a specific aspect; its func- tion is similar to an independent weak classifier. Therefore, rather than using a linear combination of features for classification (e.g., SVM and LR), a boosting model (e.g., Random Forest) is more suitable for this task. The performance is slightly better when M =10 for all classifiers, with +0.20% for SVM, +0.53% for NB, +0.73% for LR and +3.63% for RF, with respect to the average F 1 . The results verify the effectiveness of considering related concepts in contextual features. We use RF and set M =10 in the following experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Comparison with Baselines</head><p>We further compare our approach with three rep- resentative methods for prerequisite inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Baseline Approaches</head><p>Hyponym Pattern Method (HPM). Prerequi- site relationships often exists between hyponym- hypernym concept pairs (e.g., "Machine Learn- ing" and "Supervised Learning"). As a baseline, we adopt the 10 lexico-syntactic patterns used by <ref type="bibr" target="#b25">Wang et al. (2016)</ref> to extract hyponym relation- ships between concepts. If a concept pair matches at least one of these patterns in the MOOC corpus, we judge them to have prerequisite relations. Reference Distance (RD) We also employ the RefD proposed by <ref type="bibr" target="#b10">Liang et al. (2015)</ref> as one of our baselines. However, this method is only appliable to Wikipedia concepts. To make it comparable with our method, for each of our datasets, we construct a subset of it by picking out the concept pairs a, b in which a and b are both Wikipedia concepts. For example, we find 49% of course concepts in ML have their corresponding Wikipedia articles and 28% percent of concept pairs in ML meet the above condition. We use the new datasets constructed from ML, DSA and CAL, namely W-ML, W-DSA, and W-CAL, to compare our method with RefD. Supervised Relationship Identification (SRI) <ref type="bibr" target="#b25">Wang et al. (2016)</ref>   tures to infer prerequisite relations of Wikipedia concepts in textbooks, including 3 Textbook fea- tures and 6 Wikipedia features. Based on these features, they performed a binary classification using SVM to identify prerequisite relationships and has achieved state-of-the-art results. Because the Wikipedia features can only be applied to Wikipedia concepts, in order to make a compar- ison, we create two versions of their method: (1) T-SRI: only textbook features are used to train the classifier and (2) F-SRI: the original version, all features are used. We compare the performance of our method with T-SRI on ML, DSA and CAL datasets; we also compare our method with F-SRI on W-ML, W-DSA and W-CAL datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Performance Comparison</head><p>In <ref type="table" target="#tab_3">Table 3</ref> we summarize the comparing results of different methods across different datasets ("MOOC" refers to our method). We find that our method outperforms baseline methods across all six datasets 6 . For example, the F 1 of our method on ML outperforms T-SRI and HPM by 10.5% and 43.6%, respectively. Specifically, we have the following observations. First, HPM achieves relatively high precision but low recall. This is because when A "is a" B, a prerequisite relation often exists from B to A, but clearly not vise versa. Second, T-SRI has certain effectiveness for learn- ing prerequisite relations, with F 1 ranging from 62.1 to 65.2%. However, T-SRI only considers relatively simple features, such as the sequential and co-occurrence among concepts. With more comprehensive feature engineering, the F 1 of our method significantly outperforms T-SRI (+10.5% on ML, +9.1% on DSA and +7.1% on CAL). Third, incorporating Wikipedia-based features (F- SRI) achieves certain promotion in performance (+0.93% comparing with T-SRI in average F 1 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Feature Contribution Analysis</head><p>In order to get an insight into the importance of each feature in our method, we perform a contribution analysis with different features. Here, we run our approach 10 times on the ML dataset.</p><p>In each of the first 7 times, one feature is removed; in each of the rest 3 times, one group of features are removed, e.g., removing contextual features means removing Gvrd, Gsrd and W rd at the same time. We record the decrease of F1-score for each setting. <ref type="table" target="#tab_5">Table 4</ref> lists the evaluation results after ignoring different features. According to the decrement of F1-scores, we find that all the proposed features are useful in pre- dicting prerequisite relations. Especially, we ob- serve that Cld (Feature 7), decreasing our best F1- score by 7.4%, plays the most important role. This suggests that most concepts do exist difference in complexity level. For two concepts, the difference of their coverage and survival times in courses are important for prerequisite relation detection. On the contrary, with 1.9% decrease, Sr (Feature 1) is relatively less important. We may easily find two concepts which have related semantic meanings (e.g., "test set" and "training set") but have no prerequisite relationship. However, se- mantic relatedness is critical for the contextual features because it overcomes the problem of the sparsity of context in calculation. We experience a decrease of 5.4% when we further do not consider related concepts in contextual features, i.e., set M =1. As for the feature group contribution, we observe that Structural Features, with a decrease of 9.2%, has a greater impact than the other two groups. This is as expected because it includes Cld. Among the three structural features, Apd makes relatively less contribution. The reason is that sometimes the professor may frequently mention a prerequisite concept after introducing a subsequent concept orally, for helping students better understand the concept.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Works</head><p>To the best of our knowledge, there has been no previous work on mining prerequisite relations   In the area of education, researchers have tried to find general prerequisite structures from students' test performance <ref type="bibr" target="#b24">(Vuong et al., 2011;</ref><ref type="bibr" target="#b21">Scheines et al., 2014;</ref>. Different from them, we focus on more fine- grained prerequisite relations, i.e., the prerequisite relations among course concepts. Among the few related works of mining pre- requisite relations among concepts, <ref type="bibr" target="#b10">Liang et al. (2015)</ref> and <ref type="bibr" target="#b23">Talukdar and Cohen (Talukdar and Cohen, 2012</ref>) studied prerequisite relationships between Wikipedia articles. They assumed that hyperlinks between Wikipedia pages indicate a prerequisite relationship and design several useful features. Based on these Wikipedia features plus some textbook features, <ref type="bibr" target="#b25">Wang et al. (Wang et al., 2016)</ref> proposed a method to construct a concept map from textbooks, which jointly learns the key concepts and their prerequisite relations. How- ever, the investigation of only Wikipedia concepts is also the bottleneck of their studies. In our work, we propose more general features to infer prerequisite relations among concepts, regardless of whether the concept is in Wikipedia or not. <ref type="bibr" target="#b11">Liang et al. (2017)</ref> propose an optimization based framework to discover concept prerequisite relations from course dependencies. <ref type="bibr" target="#b5">Gordon et al. (2016)</ref> utilize cross-entropy to learn concept dependencies in scientific corpus. Besides local statistical information, our method also utilize external knowledge to enrich concept semantics, which is more informativeness.</p><p>Our work is also related to the study of auto- matic relation extraction. Different research lines have been proposed around this topic, includ- ing hypernym-hyponym relation extraction ( <ref type="bibr" target="#b19">Ritter et al., 2009;</ref><ref type="bibr" target="#b26">Wei et al., 2012)</ref>, entity relation extraction ( <ref type="bibr" target="#b29">Zhou et al., 2006;</ref><ref type="bibr" target="#b3">Fan et al., 2014;</ref><ref type="bibr" target="#b12">Lin et al., 2015)</ref> and open relation extraction <ref type="bibr" target="#b2">(Fader et al., 2011</ref>). However, previous works mainly focus on factual relations, the extraction of cognitive relations (e.g. prerequisite relations) has not been well studied yet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions and Future Work</head><p>We conducted a new investigation on automati- cally inferring prerequisite relations among con- cepts in MOOCs. We precisely define the problem and propose several useful features from different aspects, i.e., contextual, structural and semantic features. Moreover, we apply an embedding- based method that jointly learns the semantic representations of Wikipedia concepts and MOOC concepts to help implement the features. Exper- imental results on online courses with different domains validate the effectiveness of the proposed method. Promising future directions would be to investigate how to utilize user interaction in MOOCs for better prerequisite learning, as well as how deep learning models can be used to automatically learn useful features to help infer prerequisite relations.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example of prerequisite relations in MOOCs CS224), whose prerequisite knowledge is "Maximum Likelihood" (in video12 of Math112). Organizing the knowledge structure with prerequisite relations in education improves tasks such as curriculum planning (Yang et al., 2015), automatic reading list generation (Jardine, 2014), and improving education quality (Rouly et al., 2015). For example, as shown in Figure 1, with explicit prerequisite relations among concepts (in red), a coherent and reasonable learning sequence can be recommended to the student (in blue). Before, the prerequisite relationships were provided by teachers or teaching assistants (Novak, 1990); however in the era of MOOCs, it is becoming infeasible as the teachers would find that they are facing with hundreds of thousands of students with various background. Meanwhile, the rapid growth of Massive Open Online Courses has offered thousands of courses, and students are free to choose any course from the thousands of candidates. Therefore, there is a clear need for methods to automatically dig out the prerequisite relationships among knowledge concepts from the large course space, so that the students from different background can easily explore the knowledge space and better design their personalized learning schedule. There are a few efforts aiming to automatically detect prerequisite relations for knowledge base. For example, Talukdar and Cohen (2012) proposed a method for inferring prerequisite relationships between entities in Wikipedia and Liang et al. (2015) presented a more general approach</figDesc><graphic url="image-1.png" coords="1,307.33,204.54,215.44,96.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Ignored</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>has employed several fea-</head><label></label><figDesc></figDesc><table>Method 
ML 
DSA CAL 
W-
ML 

W-
DSA 

W-
CAL 

HPM 

P 
67.3 71.4 69.5 
79.9 72.3 73.5 

R 
18.4 14.8 16.5 
25.5 27.3 23.3 

F1 
29.0 24.5 26.7 
38.6 39.6 35.4 

RD 

P 
− 
− 
− 
73.4 77.8 74.4 

R 
− 
− 
− 
42.8 44.8 43.1 

F1 
− 
− 
− 
54.1 56.8 54.6 

T-SRI 

P 
61.4 62.3 62.5 
58.1 60.1 62.7 

R 
62.9 64.6 65.5 
67.6 65.3 67.9 

F1 
62.1 63.4 64.0 
62.5 62.6 65.2 

F-SRI 

P 
− 
− 
− 
64.3 64.3 64.8 

R 
− 
− 
− 
62.1 65.6 65.2 

F1 
− 
− 
− 
63.2 64.9 65.0 

MOOC 

P 
71.4 72.7 70.3 
72.8 68.4 71.4 

R 
73.8 72.3 71.9 
71.3 72.0 70.8 

F1 
72.6 72.5 71.1 
72.0 70.2 71.1 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Comparison with baselines(%). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Contribution analysis of different features(%). 

among concepts in MOOCs. Some researchers 
have been engaged in detecting other type of 
prerequisite relations. For example, Yang et al. 
(2015) proposed to induce prerequisite relations 
among courses to support curriculum planning. 
Liu et al. (2011) studied learning-dependency 
between knowledge units, a special text fragment 
containing concepts, using a classification-based 
method. </table></figure>

			<note place="foot" n="1"> https://www.coursera.org/</note>

			<note place="foot" n="2"> https://github.com/coursera-dl/coursera-dl 3 These courses are: &quot;Machine Learning (Stanford)&quot;, &quot;Machine Learning (Washington)&quot;, &quot;Practical Machine Learning (JHU)&quot;, &quot;Machine Learning With Big Data (UCSD)&quot; and &quot;Neural Networks for Machine Learning (UofT)&quot;</note>

			<note place="foot" n="4"> https://dumps.wikimedia.org/enwiki/20170120/ 5 http://radimrehurek.com/gensim/</note>

			<note place="foot" n="6"> The improvements are all statistically significant tested with bootstrap re-sampling with 95% confidence.</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">All our children learning: A primer for parents, teachers, and other educators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Samuel Bloom</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981" />
			<publisher>McGraw-Hill Companies</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Name list only? target entity disambiguation in short texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juanzi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofei</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuanhu</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="654" to="664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Identifying relations for open information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1535" to="1545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction with matrix completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deli</forename><surname>Miao Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">Fang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><forename type="middle">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="839" to="849" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">TAGME: on-the-fly annotation of short text fragments (by wikipedia entities)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Ferragina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ugo</forename><surname>Scaiella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CIKM</title>
		<meeting>CIKM</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1625" to="1628" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Modeling concept dependencies in a scientific corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linhong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aram</forename><surname>Galstyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prem</forename><surname>Natarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gully</forename><surname>Burns</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An efficient data mining approach to concept map generation for adaptive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaopeng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyeong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><forename type="middle">B</forename><surname>Lawrence</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICDM</title>
		<meeting>ICDM</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="247" to="260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Automatically generating reading lists</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Gregory</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jardine</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<pubPlace>UK</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Cambridge</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The measurement of interrater agreement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Landis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">G</forename><surname>Koch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Statistics methods for rates and proportions</title>
		<imprint>
			<date type="published" when="1981" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="212" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Laurence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Margolis</surname></persName>
		</author>
		<title level="m">Concepts and cognitive science. Concepts: core readings pages</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="3" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Measuring prerequisite relations among concepts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaohui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyi</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lee</forename><surname>Giles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1668" to="1674" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Recovering concept prerequisite relations from university course dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbo</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaohui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Pursel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lee</forename><surname>Giles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4786" to="4791" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning entity and relation embeddings for knowledge graph completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yankai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuan</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2181" to="2187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Mining learning-dependency between knowledge units from text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaohui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinghua</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ya-Nan</forename><surname>Qian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The VLDB Journal</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="335" to="345" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno>abs/1301.3781</idno>
	</analytic>
	<monogr>
		<title level="j">International Journal of CoRR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Concept mapping: A useful tool for science education</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Novak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Research in Science Teaching</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="937" to="949" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Wikipedia in the eyes of its beholders: A systematic review of scholarly research on wikipedia readers and readership</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chitu</forename><surname>Okoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamad</forename><surname>Mehdi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mostafa</forename><surname>Mesgari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Finnårupfinn˚finnårup</forename><surname>Nielsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arto</forename><surname>Lanamäki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of the American Society for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2381" to="2403" />
			<date type="published" when="2014" />
			<publisher>JASIST</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Towards the web of concepts: Extracting concepts from large datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><forename type="middle">G</forename><surname>Parameswaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hector</forename><surname>Garcia-Molina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anand</forename><surname>Rajaraman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="566" to="577" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">What is this, anyway: Automatic hypernym discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="88" to="93" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">What are we teaching?: Automated evaluation of CS curricula content using topic modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Michel Rouly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huzefa</forename><surname>Rangwala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Johri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICER</title>
		<meeting>ICER</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="189" to="197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Discovering prerequisite relationships among knowledge components</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Scheines</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elizabeth</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><forename type="middle">M</forename><surname>Goldin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EDM</title>
		<meeting>EDM</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="355" to="356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Wikipedia and psychology: Coverage of concepts and its use by undergraduate students</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schweitzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Teaching of Psychology</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="81" to="85" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Crowdsourced comprehension: predicting prerequisite structure in wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><forename type="middle">Pratim</forename><surname>Talukdar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>William W Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Workshop on Building Educational Applications Using NLP</title>
		<meeting>the Seventh Workshop on Building Educational Applications Using NLP</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="307" to="315" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A method for finding prerequisites within a curriculum</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Annalies</forename><surname>Vuong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tristan</forename><surname>Nixon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brendon</forename><surname>Towle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EDM</title>
		<meeting>EDM</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="211" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Using prerequisites to extract concept maps fromtextbooks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuting</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Ororbia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaohui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyle</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Pursel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lee</forename><surname>Giles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CIKM</title>
		<meeting>CIKM</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="317" to="326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">MOTIF-RE: motifbased hypernym/hyponym relation extraction from wikipedia links</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bifan</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinghua</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqin</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICONIP</title>
		<meeting>ICONIP</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="610" to="619" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Concept graph learning from educational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><forename type="middle">G</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WSDM</title>
		<meeting>WSDM</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="159" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">AIDA: an online tool for accurate disambiguation of named entities in text and tables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Amir Yosef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Hoffart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilaria</forename><surname>Bordino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Spaniol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<publisher>PVLDB</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1450" to="1453" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Modeling commonality among related classes in relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
