<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:19+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 15-20, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Banarescu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Bonial</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Cai</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Madalina</forename><surname>Georgescu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kira</forename><surname>Griffitt</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulf</forename><surname>Hermjakob</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Banarescu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Bonial</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Cai</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Madalina</forename><surname>Georgescu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kira</forename><surname>Griffitt</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulf</forename><surname>Hermjakob</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Schneider</surname></persName>
						</author>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 51st Annual Meeting of the Association for Com-putational Linguistics</title>
						<meeting>the 51st Annual Meeting of the Association for Com-putational Linguistics <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="volume">1</biblScope>
							<biblScope unit="page" from="196" to="206"/>
							<date type="published">July 15-20, 2018</date>
						</imprint>
					</monogr>
					<note>74 Unsupervised Semantic Abstractive Summarization Shibhansh Dohare CSE Department IIT Kanpur sdohare&apos; Vivek Gupta Microsoft Research Bangalore t-vigu&quot; Harish Karnick CSE Department IIT Kanpur hk&apos;</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Automatic abstractive summary generation remains a significant open problem for natural language processing. In this work, we develop a novel pipeline for Semantic Abstractive Summarization (SAS). SAS, as introduced by Liu et al. (2015) first generates an AMR graph of an input story, through which it extracts a summary graph and finally, creates summary sentences from this summary graph. Compared to earlier approaches, we develop a more comprehensive method to generate the story AMR graph using state-of-the-art co-reference resolution and Meta Nodes. Which we then use in a novel unsupervised algorithm based on how humans summarize a piece of text to extract the summary sub-graph. Our algorithm outperforms the state of the art SAS method by 1.7% F1 score in node prediction. Miguel Almeida and Andre Martins. 2013. Fast and robust compressive summarization with dual decomposition and multi-task learning. In. 2013. Abstract meaning representation for sembanking. Proceedings of Linguistic Annotation Workshop.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Summarization of large texts is still an open prob- lem in natural language processing. Automatic summarization is often used in summarizing large texts like stories, journal papers, news articles and even larger texts like books and court judgments.</p><p>Existing methods for summarization can be broadly categorized into two categories Extrac- tive and Abstractive. Most of the work done on summarization in the past has been Extractive <ref type="bibr" target="#b3">Dang and Owczarzak (2008)</ref>. Extractive meth- ods directly pick up words and sentences from the text to generate a summary. <ref type="bibr" target="#b24">Vanderwende et al. (2004)</ref> transformed the input to nodes, then used '@cse.iitk.ac.in, "@microsoft.com, Shibhansh is the corresponding author the Pagerank algorithm to score nodes, and finally grow the nodes from high-value to low-value us- ing some heuristics. Some of the approaches com- bine this with sentence compression so that more sentences can be packed in the summary. <ref type="bibr" target="#b15">McDonald (2007)</ref>, <ref type="bibr" target="#b14">Martins and Smith (2009)</ref>, <ref type="bibr">Almeida and Martins (2013)</ref>, and <ref type="bibr" target="#b6">Gillick and Favre (2009)</ref> among others used ILPs and approximations for encoding compression and extraction. However, human level summary generation require rephras- ing sentences and combining information from different parts of the text. Thus, these methods are inherently limited in the sense that they can never generate human level summaries for large and complicated documents.</p><p>On the other hand, most Abstractive methods take advantages of the recent developments in deep learning. Specifically, the recent success of the sequence to sequence <ref type="bibr" target="#b22">Sutskever et al. (2014)</ref> learning models, where recurrent networks read the text; encodes it and then generate target text produce promising results. <ref type="bibr" target="#b19">Rush et al. (2015)</ref>, <ref type="bibr" target="#b2">Chopra et al. (2016)</ref>, <ref type="bibr" target="#b16">Nallapati et al. (2016)</ref>, <ref type="bibr" target="#b21">See et al. (2017)</ref> used standard encoder-decoder models along with their variants to generate sum- maries. <ref type="bibr" target="#b23">Takase et al. (2016)</ref> incorporated the AMR information in the standard encoder-decoder models to improve results. These approaches have produced promising results and have been recently shown to be competitive with the extractive meth- ods, but they are still far from reaching human level quality in summary generation. One of the significant problems with these methods is that there is no guarantee that they can handle sub- tleties of language like the presence of a word that negates the meaning of the full text, hard to cap- ture co-references, etc. <ref type="bibr">Banarescu et al. (2013)</ref> introduced AMR as a base for work on statistical natural language un- derstanding and generation. AMR tries to cap-ture "who is doing what to whom" in a sentence. An AMR represents the meaning of a sentence us- ing rooted, acyclic, labeled, directed graphs. <ref type="figure">Fig- ure 2</ref> shows the AMR graph of the sentence "I looked carefully all around me" generated by the JAMR parser <ref type="bibr" target="#b5">Flanigan et al. (2014)</ref>. The nodes in the AMR are labeled with concepts, in <ref type="figure">Figure 2</ref> 'around' represents one such concept. Edges con- tain the information regarding the semantic rela- tion between the concepts. In <ref type="figure">Figure 2</ref> direction is the relation between the concepts look-01 and around. AMR relies on Propbank for semantic re- lations (edge labels). Concepts can also be of the form run-01 where the index 01 represents the first sense of the word run. Further details about the AMR can be found in the AMR guidelines <ref type="bibr">Banarescu et al. (2015)</ref>. <ref type="bibr" target="#b13">Liu et al. (2015)</ref> started the work on summarization using AMR, which we call Semantic Abstractive Summarization (SAS). <ref type="bibr" target="#b13">Liu et al. (2015)</ref> introduced the fundamental idea behind SAS. In SAS the final summary is pro- duced by extracting a summary subgraph from the story graph and generating the summary from this extracted graph (See <ref type="figure" target="#fig_0">Figure 1)</ref>. But the work was limited to obtaining the summary graph due to the absence of AMR to text generators at that time. They used various graphical features like distance from the root, the number of outgoing edges, etc. and sentence number as features for nodes. The procedure then learned weights over these features with the constraint that the nodes must form a con- nected graph.</p><p>In this work, we propose an alternative method to use AMRs for abstractive summarization. Our approach is inspired by the way humans summa- rize any piece of text. User studies <ref type="bibr" target="#b1">Chin et al. (2009)</ref>; <ref type="bibr" target="#b8">Kang et al. (2011)</ref> have shown that hu- mans summarize by first writing down the key phrases and then try to figure out the relationships among them and then organize the data accord- ingly. <ref type="bibr" target="#b4">Falke and Gurevych (2017)</ref> used similar ideas to propose the task of concept map based summarization. We design our algorithm along the same lines. The first step is to find the most important entities/events in the text. The second step is to identify the key relations among the most important entities/events, and finally, in the last step, we capture information around the selected relation. AMRs provide a natural way to achieve this process, as all the events/entities can be rep- resented by a node <ref type="bibr" target="#b17">Rao et al. (2017)</ref> or a group of nodes, while any relation can be captured by a path in the AMR graph. We also develop a more comprehensive method to generate the story AMR from the sentence AMRs based on event/entity co-reference resolution and Meta Nodes. Our al- gorithm outperforms the previous state of the art methods for SAS by 1.7% F1 score on Node pre- diction.</p><p>Our major contributions in this work are :</p><p>• We propose a novel unsupervised algorithm for the key step of summary graph extraction, which provides a stronger baseline for future work on SAS.</p><p>• We propose a novel method to generate the story AMR based on a more comprehensive co-reference resolution and Meta Nodes.</p><p>The rest of the paper is organized as follows. Section 2 and 3 contain description of the datasets and the algorithm used for summary generation re- spectively. Section 4 contains the results of exper- iments using our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Datasets</head><p>We use the proxy report section of the AMR Bank <ref type="bibr" target="#b9">Knight et al. (2014)</ref>, as it is the only section that is relevant for the task because it contains the gold-standard (human-generated) AMR graphs for news articles and their summaries. In the training set, the stories and summaries contain 17.5 sen- tences and 1.5 sentences on average respectively. The training and test sets include 298 and 33 sum- mary document pairs respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Pipeline for Summary Generation</head><p>The pipeline consists of three major steps. The first step is to convert the document into an AMR (step-1). The next step is to extract a summary AMR from the document AMR constructed in the previous step (step-2). The final step generates text from the extracted sub-graph (step-3). In the following subsections, we expand on each step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Step 1: Story to AMR: Document graph generation</head><p>Document AMR refers to the AMR representing the meaning of the whole document. The AMR Code for the complete pipeline for the end to end summarization is available at https://github.com/ shibhansh/Unsupervised-SAS The graphical representation of the AMR graph of the sentence : "I looked care- fully all around me" using AMRICA <ref type="bibr" target="#b20">Saphra and Lopez (2015)</ref> formalism guarantees that no two nodes refer to the same event/entity. <ref type="bibr" target="#b13">Liu et al. (2015)</ref> extends this principle to multiple sentences by merging nodes referring to the same named entity (or date) across sentences. However, they adopted a naive ap- proach to for co-reference resolution using a sim- ple name and date matching 3.1. The co-reference resolution can be greatly improved if we take ad- vantage of the huge literature on text co-reference resolution. We solve node co-reference resolu- tion using text co-reference resolution followed by mapping the text to a node using Alignments.</p><p>Node Co-reference Resolution is a crucial step, as a wrongly generated document AMR can pro- duce a factually wrong summary. To mitigate wrong mergers, we implement multiple sanity checks to avoid wrong mergers. Text co-reference resolution techniques can be broadly categorized into three major categories -neural, statistical and rule-based. We used the state-of-the-art end- to-end neural co-reference resolution system <ref type="bibr" target="#b11">Lee et al. (2017)</ref>. Future work can use an ensemble of co-reference resolvers to improve robustness. A list of major sanity checks that we employed</p><p>• Don't merge nodes which have an outgo- ing edge with label :name if the value of :name argument is different, and neither of the names is the initials of the other</p><p>• Don't merge if, cycle emerges in the graph after the merger</p><p>• Don't merge if, the nodes to be merged have common outgoing edge labels, and the nodes that are connected with these edges are dif- ferent</p><p>For mapping text to the node, we use align- ments. Alignments provide a mapping from a word in the text to the corresponding node in the AMR. Most co-reference systems provide co-references between noun phrases instead of individual words. But for node co-reference resolution we are re- quired to merge individual nodes rather than a group of nodes. However, <ref type="bibr" target="#b11">Lee et al. (2017)</ref> sys- tem also outputs attention weight for every word of a noun phrase which signifies the importance of each word in the noun phrase. We merge the nodes corresponding to the word that has the max- imum attention weight among the words in the noun phrase.</p><p>Merging nodes that refer to the same event/entity suggests that the merged node is more important in the graph than the original nodes as there are more incoming and outgoing edges in the graph now. Co-reference resolution captures explicit reference of an event/entity, which implies that the nodes should be merged as they are same and thus it helps increase the importance of the node. But, there are many cases where words are not referring to the same entity or event but they refer to the same abstract concept, or there might be cases where the words are talking about the same event without explicitly referring to it. In such cases, these words should reinforce the importance of each other, but simple co-reference resolution does not capture this, and hence co-reference resolution is not enough. We need something new in the graph that captures when two nodes are reinforcing the importance of each other without actually merging the two nodes. In table 1 we present two examples where words reinforce the importance of each other without referring to the exact same thing.</p><p>These examples inspire us to introduce a new set of nodes which we call Meta nodes. In this work, we use Meta nodes to increase the impor- tance of only common nouns. <ref type="figure" target="#fig_0">Fig. 1</ref>, we introduce a Meta Node for the common noun Opium, which is present twice in the story. Each Meta node is con- nected to all the occurrences of the correspond- ing common noun. The nodes connected with a meta node signifies that the nodes at some level might refer to the same thing. Meta nodes are used as representative for the group during ranking but they are not extracted in the final summary graph, and hence they are not used during the final step of summary generation.</p><note type="other">Common nouns like drugs, opium, etc. can occur a lot of times in the text which suggests that they are relevant for the text, but they are not identified by co-reference systems as their different occurrences do not refer to exactly the same thing. To capture the impor- tant common nouns which are otherwise not cap- tured in the co-reference resolution, we add a new Meta node in the graph for each such set of com- mon nouns. In Example 2 of</note><p>The cases that we examined in <ref type="table">Table 1</ref> are cases where the words don't have a perfect identity but rather a near identity. This points out that co- reference resolution is not a simple yes/no ques- tion but rather a complicated one. This problem of the complexity of co-reference resolution has been explored theoretically in the literature <ref type="bibr" target="#b18">Recasens et al. (2011);</ref><ref type="bibr" target="#b25">Versley (2008)</ref> and our work will benefit directly from more work on the complex- ity of co-reference resolution. In our current work, we don't implement any procedure to detect rein- forcements of the sort given in Example 2 of <ref type="table">Table  1</ref>. Future works may include event co-reference resolution and word similarity using word embed- dings to identify such reinforcements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Step 2: Summary Graph Extraction</head><p>Summary graph extraction is a key step in SAS. In this step, we extract the summary sentence AMR graphs from the document AMR produced in Step- 1. We take our cue from the way humans summa- rize a text by first identifying the most important entities/events in the text then finding the most im- portant relationships among these events/entities and finally include information surrounding the Step-A: Finding Important Nodes -For finding important events/entities, we use term frequency-inverse document frequency (Tf − IDF) to determine the importance of any node. We first find the top n nodes in the graph using term frequency. This n depends upon the size of the summary required. Similar to earlier approaches we use Alignments to find text corre- sponding to the nodes. Finally, we use Tf-IDF values of the text corresponding to the nodes to rank the selected n nodes. The proxy report section of the AMR Bank is quite small with only 298 training stories. We use the CNN-Dailymail <ref type="bibr" target="#b7">Hermann et al. (2015)</ref> corpus containing around 300,000 news articles to evaluate the Document Frequencies (DF). We calculate Tf − Idf as - Tf − Idf = Tf × log 10 (300, 000/(DF + 1))</p><p>As explained in section 3.1, Meta Nodes are used as a representative for a set of nodes during importance evaluation. Hence, during importance evaluation we do not consider nodes that are con- nected with any Meta Node. To evaluate the im- portance of a Meta Node, we take the number of nodes connected with a Meta Node as the term fre- quency for the Meta Node.</p><p>Step-B: Finding Key Relation-The next step is to find the important relationship between a pair of selected nodes. We use a heuristic in this step. The idea is that the key relationship between the nodes will generally be present in the sentence where they occur together for the first time. If there is no such sentence, then there is probably no important direct relationship between the two nodes, and we ignore the pair. AMRs contain se- mantic information at the top of the AMR graph. <ref type="table">Table 1</ref>: In Example 1, the words illegal and ban reinforce each others importance but they are not captured by co-reference resolution. We add a Meta Node connected to the nodes corresponding to the words illegal and ban. During importance evaluation, the occurrences of this Meta Node will be these occurrences of illegal and ban and term frequency for this Meta Node will be 2. Similarly, in the second example both the occurrences of the word opium are connected to a new Meta Node 1. On 011006 The Citizen newspaper stated that it is illegal for South Africans to be involved in mercenary activity or to render foreign military assistance inside or outside of South Africa. The Citizen newspaper stated that the South African Foreign Ministry announced on 011005 that the South African government imposed the mercenary activity ban following reports that 1000 Muslims with military training have enlisted to leave South Africa for Afghanistan to fight for the Taliban against the United States. 2. Head of the U.N. drug office Antonio Maria Costa said that Afghanistan has produced so much opium in recent years that the Taliban are cutting back poppy cultivation and stockpiling raw opium in an effort to support prices and preserve a major source of financing for the insurgency. Costa said this to reporters last week as the U.N. Drug Office Office prepared to release its latest survey of Afghanistan's opium crop. <ref type="table">Table 2</ref>: Results on the Proxy report section of the AMR bank. First-half contains the Recall, Precision, and F-1 for the nodes in the generated summary AMR. The second half contains the scores for the final summary generated using state-of-the-art text generator evaluated using the ROUGE metric Thus, in the selected sentence we find a path be- tween the two nodes closest to the root. If one of the selected nodes happens to be a Meta Node, the occurrences of the Meta Node include all the occurrences of all the nodes that the Meta Node represents ( <ref type="figure" target="#fig_0">Fig. 1)</ref>.</p><formula xml:id="formula_0">Subgraph extraction Full pipeline Method Recall Precision F 1 R-1 R-2 R-L</formula><p>Step-C: Capture Surrounding Information - The final step in subgraph extraction is to expand around the selected path to capture the surround- ing information. We use OpenIE Banko (2009) at this step. The output of the OpenIE system are tuples of the form (arg; relation; arg). The rele- vant tuples for us are the set of tuples that contain the selected path. As, these tuples contain all the auxiliary information about the relationship that they are describing, selecting a tuple will solve the problem of graph expansion. To capture the max- imum amount of auxiliary information we choose the largest tuple among the set of relevant tuples. This ends the process of summary graph extrac- tion. Algorithm 1 provides an overview of the en- tire algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Step 3: Summary Generation</head><p>To generate sentences from the extracted AMR graphs we use state of the art AMR to text gen- erator <ref type="bibr" target="#b10">Konstas et al. (2017)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In table 2 we report results on the test set of the proxy report section of the AMR bank. The table contains results using the human annotated AMRs. We outperform the state-of-the-art in SAS by 1.7% F1 scores in node prediction. Similar to previous methods we use the target summary size to control the length of the output summary.</p><p>To evaluate the effectiveness of the method till the summary graph extraction step, we com- pare the generated summary graph with the gold- standard target summary graph. We report Recall, Precision, and F1 for graph nodes. Finally, to eval- uate the effectiveness of the pipeline, we evaluate the performance using ROUGE <ref type="bibr" target="#b12">Lin (2004)</ref>, and we report ROUGE-1, ROUGE-2, and ROUGE-L. As clear from table 2 there is not much dif- ference between the scores when we use naive node resolution and date merging and when we use state-of-art co-reference resolution. To check the impact of co-reference resolution, we also did manual co-reference resolution on the test set which resulted in a further 2% increase in the scores to 62.4%. We suspect that a significant rea- son for lower performance with state of the art co-reference resolution might be the inability of the system to handle cataphoric references. These references are particularly crucial in news articles where the first occurrence of an entity/event is generally essential.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>In this work, we present a new method to do Se- mantic Abstractive Summarization <ref type="figure" target="#fig_3">(Figure 4)</ref>. We outperform the previous state-of-the-art methods for SAS by 1.7% and by 3.7% using human co- reference resolution. In the process, we complete the SAS pipeline for the first time showing that SAS can be used to construct high-quality sum- maries. We also extend the method to construct a document AMR graph from the sentence AMRs using Meta nodes which can further be used in some future formalism for Document Meaning Representation.</p><p>The work will benefit directly from improve- ments in each step of the pipeline. Specifically, the advances in co-reference resolution for the near-identity cases might significantly improve the summary quality. We are currently experiment- ing with bigger text summarization datasets like <ref type="bibr">DUC 2004 and</ref><ref type="bibr">DUC 2006</ref>. The hypothesis we used to find the key relations is the main hurdle in extending the work to multi-document summa- rization as all other steps can be directly applied in multi-document summarization. Using differ- ent methods that might be based on supervision to find the key relation is an interest direction for fu- ture work.</p><p>A Example to generate document AMR from sentence AMR</p><p>In this appendix, we give an example showing how to generate Document AMR from the sentence AMRs. Consider a short multi-sentence story - A Kathmandu police officer reports -. 1 soldier of the Royal Nepal Army was seriously injured on 29 August 2002 when a bomb disposal team at- tempted to defuse the bomb left at an electricity pole in okubahal near Sundhara in Lalitpur dis- trict in Kathmandu. Anti-government insurgents are believed to have planted the bomb. The injured soldier has been admitted to the army hospital in Kathmandu. <ref type="figure" target="#fig_4">Figure 5</ref> shows the sentence AMRs of the four sentences of the short story. The nodes that re- fer to the similar entity have to be merged; the dashed lines connect the nodes to be merged. <ref type="figure">Fig- ure 6</ref> shows, the generated document AMR from the merger. <ref type="figure">Fig 6 also</ref> shows how large the AMRs of even short stories can become after merging.</p><p>If the summarization process were to follow, we would've started by finding the key nodes in the document graph based on TF − IDF. The Term frequency is the number of incoming edges in the AMR. It is clear from the document AMR that the important nodes based on Term frequency are Soldier, Bomb, and Kathmandu. Then we use TF − IDF to rank among these key nodes, it turns out that the key nodes that the final ranking in de- creasing order of importance is Kathmandu, Sol- dier and Bomb. The next step is to find the key relation, which according to our hypothesis lies in the sentence where they first co-occur, i.e., the second sentence. The exact relation is the highest path. As clear from <ref type="figure" target="#fig_4">Figure 5</ref> the path will include the nodes corresponding to the words Kathmandu, Soldier, Injured. And finally in the last step we use the OpenIE system to capture important informa- tion surrounding this path. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The pipeline proposed by (Liu et al., 2015) had the following step-AMR Parsing, Naive node merging, Subgraph selection and Text generation</figDesc><graphic url="image-2.png" coords="3,100.52,162.66,158.50,159.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: An example of node merging in a very basic AMR, The mergers 1 and 2 were also present in the methods proposed by Liu et al. (2015) but not the merger 3. Here, dash line represent node to be merged.</figDesc><graphic url="image-3.png" coords="4,311.55,62.81,207.00,82.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The updated pipeline proposed by us has the following step-AMR Parsing, Co-reference resolution, Open Information Extraction,TF-IDF calculation, Subgraph selection and Text generation</figDesc><graphic url="image-4.png" coords="6,91.25,62.81,412.32,109.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The AMRs of the 4 sentence of the short story. Dashed lines represent the nodes to be merged.</figDesc><graphic url="image-5.png" coords="9,72.00,207.01,453.56,372.32" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank the anonymous ACL re-viewers for their insightful comments. We also thank Susmit Wagle and Prerna Bharti of IIT Kan-pur for helpful discussions. Vivek Gupta acknowl-edges support from Microsoft Research Travel Award. We would also like to thank Roam Analyt-ics for sponsoring Shibhansh's ACL SRW travel grant. The opinions stated in this paper are of au-thors alone.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Open Information Extraction for the Web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michele</forename><surname>Banko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<pubPlace>Seattle, WA, USA. AAI3370456</pubPlace>
		</imprint>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Exploring the analytical processes of intelligence analysts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><forename type="middle">A</forename><surname>Kuchar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><forename type="middle">E</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">InProceedings of the SIGCHI Conference on Human Factors in Computing Systems, page 1120</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Abstractive sentence summarization with attentive recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="93" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Overview of the tac 2008 update summarization task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trang</forename><surname>Hoa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karolina</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Owczarzak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Text Analysis Conference</title>
		<meeting>Text Analysis Conference</meeting>
		<imprint>
			<publisher>TAC</publisher>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Bringing structure into summaries: Crowdsourcing a benchmark corpus of concept maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Falke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2951" to="2961" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A discriminative graph-based parser for the abstract meaning representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Flanigan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1426" to="1436" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A scalable global model for summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Gillick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoit</forename><surname>Favre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL Workshop on Integer Linear Programming for Natural Langauge Processing</title>
		<meeting>the NAACL Workshop on Integer Linear Programming for Natural Langauge Processing</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Teaching machines to read and comprehend</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Moritz Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Kocisky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lasse</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><surname>Suleyman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">How can visual analytics assist investigative analysis? design implications from an evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youn-Ah</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Gorg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="570" to="583" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Deft phase 2 amr annotation r1 ldc2015e86. philadelphia: Linguistic data consortium. Abstract meaning representation (AMR) annotation release 1.0 LDC2014T12. Web Download</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Baranescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Bonial</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Madalina</forename><surname>Georgescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kira</forename><surname>Griffitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulf</forename><surname>Hermjakob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Schneider</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>Linguistic Data Consortium</publisher>
			<pubPlace>Philadelphia</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Neural amr: Sequence-to-sequence models for parsing and generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Konstas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinivasan</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Yatskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">End-to-end neural coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno>abs/1707.07045</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Rouge: A package for automatic evaluation of summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text Summarization Branches Out, Post-Conference Workshop of ACL</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Toward abstractive summarization using semantic representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Flanigan</forename><surname>Jeffrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomson</forename><surname>Sam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics<address><addrLine>Denver, Colorado</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page">10771086</biblScope>
		</imprint>
	</monogr>
	<note>Sadeh Norman, and Smith Noah A</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Summarization with a joint model for sentence extraction and compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">T</forename><surname>Andre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL Workshop on Integer Linear Programming for Natural Language Processing</title>
		<meeting>the ACL Workshop on Integer Linear Programming for Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A study of global inference algorithms in multi-document summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th European Conference on IR Research, ECIR&apos;07</title>
		<meeting>the 29th European Conference on IR Research, ECIR&apos;07<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="557" to="564" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Abstractive text summarization using sequence-tosequence rnns and beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Cicero Dos Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 20th SIGNLL Conference on Computational Natural Language Learning</title>
		<meeting>The 20th SIGNLL Conference on Computational Natural Language Learning<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="280" to="290" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Biomedical event extraction using abstract meaning representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sudha</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="126" to="135" />
			<pubPlace>Vancouver, Canada</pubPlace>
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Identity, non-identity, and near-identity: Addressing the complexity of coreference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><surname>Recasens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Antnia</forename><surname>Mart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lingua</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1138" to="1152" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">A neural attention model for sentence summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Amrica: an amr inspector for cross-language alignments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naomi</forename><surname>Saphra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lopez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations<address><addrLine>Denver, Colorado</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="36" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Get to the point: Summarization with pointergenerator networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abigail</forename><surname>See</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Neural headline generation on abstract meaning representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Sho Takase</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naoaki</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsutomu</forename><surname>Okazaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masaaki</forename><surname>Hirao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nagata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1054" to="1059" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Event-centric summary generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucy</forename><surname>Vanderwende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michele</forename><surname>Banko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arul</forename><surname>Menezes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of DUC</title>
		<meeting>DUC</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Vagueness and referential ambiguity in a large-scale annotated corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannick</forename><surname>Versley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Research on Language and Computation</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="333" to="353" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
