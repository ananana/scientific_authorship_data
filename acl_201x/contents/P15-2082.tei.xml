<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:46+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Unsupervised Decomposition of a Multi-Author Document Based on Naive-Bayesian Model</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khaled</forename><surname>Aldebei</surname></persName>
							<email>Khaled.w.aldebei@student.uts.edu.au Xiangjian.He@uts.edu.au</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computing and Communications Faculty of Engineering</orgName>
								<orgName type="laboratory">Lab of Pattern Analysis and Machine Intelligence Shanghai Jiaotong University</orgName>
								<orgName type="institution">IT University of Technology</orgName>
								<address>
									<settlement>Sydney</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangjian</forename><surname>He</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing and Communications Faculty of Engineering</orgName>
								<orgName type="laboratory">Lab of Pattern Analysis and Machine Intelligence Shanghai Jiaotong University</orgName>
								<orgName type="institution">IT University of Technology</orgName>
								<address>
									<settlement>Sydney</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Yang</surname></persName>
							<email>jieyang@sjtu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computing and Communications Faculty of Engineering</orgName>
								<orgName type="laboratory">Lab of Pattern Analysis and Machine Intelligence Shanghai Jiaotong University</orgName>
								<orgName type="institution">IT University of Technology</orgName>
								<address>
									<settlement>Sydney</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Unsupervised Decomposition of a Multi-Author Document Based on Naive-Bayesian Model</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="501" to="505"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper proposes a new unsupervised method for decomposing a multi-author document into authorial components. We assume that we do not know anything about the document and the authors, except the number of the authors of that document. The key idea is to exploit the difference in the posterior probability of the Naive-Bayesian model to increase the precision of the clustering assignment and the accuracy of the classification process of our method. Experimental results show that the proposed method outperforms two state-of-the-art methods.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The traditional studies on text segmentation, as shown in <ref type="bibr" target="#b3">Choi (2000)</ref>, <ref type="bibr" target="#b2">Brants et al. (2002)</ref>, <ref type="bibr" target="#b7">Misra et al. (2009)</ref> and <ref type="bibr" target="#b4">Hennig and Labor (2009)</ref>, focus on dividing the text into signification components such as words, sentences and topics rather than authors. Natural Language Processing techniques (NLP) and various machine learning schemas have been applied for these approaches. Due to the availability of online communication facilities, the cooperation between authors to produce a docu- ment becomes much easier. The co-authored doc- uments include Web pages, books, academic pa- pers and blog posts. There are almost no ap- proaches that have concentrated on developing techniques for segmentation of a multi-author doc- ument according to the authorship. The exist- ing approaches, as those in <ref type="bibr" target="#b8">Schaalje et al. (2013)</ref>, <ref type="bibr" target="#b9">Segarra et al. (2014)</ref> and <ref type="bibr" target="#b6">Layton et al. (2013)</ref> that are most related to our research in this paper, deal with documents written by a single author only. Although the work in <ref type="bibr" target="#b5">Koppel et al. (2011)</ref> has con- sidered the segmentation of a document according to multi-authorship, this approach requires man- ual translations and concordance to be available beforehand. Hence, their method can only be ap- plied on particular types of documents such as Bible books. <ref type="bibr" target="#b0">Akiva and Koppel (2013)</ref> investi- gated this limitation and presented a generic unsu- pervised method. They evaluated their method us- ing two different types of features. The first one is the occurrence of the 500 most common words in the document. The second one is the synonym set, which is only valid on special types of documents like Bible books. Their method relies on the dis- tance measurement to increase the precision and accuracy of the clustering and classification pro- cess. The performance of this method is degraded when the number of authors increases to more than two.</p><p>The contributions of this paper are as follows.</p><p>• A procedure for segment elicitation is devel- oped and it is applied in the clustering assign- ment process. It is for the first time to develop such a procedure relying upon the differences in the posterior probabilities.</p><p>• A probability indication procedure is devel- oped to improve the accuracy of sentence classification. It selects the significant and trusted sentences from a document and in- volves them to reclassify all sentences in the document. Our approach does not require any information about the document and the authors other than the number of authors of the document.</p><p>• Our proposed method is not restricted to any type of documents. It is still workable even when the topics in a document are not de- tectable.</p><p>The organization of this paper is as follows. Section 2 demonstrates the proposed framework. Section 3 uses an example to clarify our method. Results are conducted in Section 4. Finally, Sec- tion 5 presents the conclusion and future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>501</head><p>Given a multi-author document written by l au- thors, it is assumed that every author has writ- ten consecutive sequences of sentences, and every sentence is completely written by only one of the l authors. The value of l is pre-defined.</p><p>Our approach goes through the following steps:</p><p>• Step 1 Divide the document into segments of fixed length.</p><p>• Step 2 Represent the resulted segments as vectors using an appropriate feature set which can differentiate the writing styles among authors.</p><p>• Step 3 Cluster the resulted vectors into l clus- ters using an appropriate clustering algorithm targeting on achieving high recall rates.</p><p>• Step 4 Re-vectorize the segments using a dif- ferent feature set to more accurately discrim- inate the segments in each cluster.</p><p>• Step 5 Apply the "Segment Elicitation Proce- dure" to select the best segments from each cluster to increase the precision rates.</p><p>• Step 6 Re-vectorize all selected segments us- ing another feature set that can capture the differences among the writing styles of all sentences in a document.</p><p>• Step 7 Train the classifier using the Naive- Bayesian model.</p><p>• Step 8 Classify each sentence using the learned classifier.</p><p>• Step 9 Apply the "Probability Indication Pro- cedure" to increase the accuracy of the clas- sification results using five criteria.</p><p>To assess the performance of the proposed scheme, we perform our experiments on an arti- ficially merged document. The generation of this merged document begins with randomly choosing an author from an authors list. Then, we pick up the first r previously-unselected sentences from a document of that author, and merge them with the first r previously-unselected sentences from the documents of other randomly selected authors. Keep doing like this until all sentences from all au- thors' documents are selected. The value of r on each switch is an integer value chosen randomly from a uniform distribution varying from 1 to V.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Ezekiel-Job Document as Example</head><p>For interpretative intent, we will exploit the bible books of Ezekiel and Job to create a merged doc- ument. The book of Ezekiel contains 1,273 sen- tences and book of Job contains 1,018 sentences. We use this example of a merged document to clar- ify each step of our proposed framework shown in Section 2. We also use this merged docu- ment to work out the values of parameters used in our approach. We set V to be equal to 200. In the merged document, there are 2,291 sentences in total and there are hence 20 transitions from Ezekiel sentences to Job sentences and from Job's to Ezekiel's.</p><p>In Step 1, we divide the merged document into segments. Each segment has 30 sentences. As a result, we get 77 segments, of which 34 are writ- ten by Ezekiel, 27 are written by Job and 16 are mixed. In Step 2, we represent each segment us- ing a binary vector that reflects all words that ap- pear at least three times in the document. In Step 3, we cluster these segments by using a Gaus- sian Mixture Model (GMMs) into 2 multivariate Gaussian densities. The GMMs are trained using the iterative Expectation-Maximization (EM) al- gorithm <ref type="bibr">(Bilmes and others, 1998)</ref>. We find that all 34 Ezekiel segments are clustered in Cluster 1, and all 27 Job segments are clustered in Cluster 2. Mixed segments are divided equally between the two clusters (Note that, the recalls of both cluster are 100%, and the precisions are 81% and 77% in Cluster 1 and Cluster 2, respectively). In Step 4, all of the segments in both clusters are re-vectorized using the binary representation of the 1500 most frequently-appeared words in the document.</p><p>In the Step 5, a Segment Elicitation Procedure is proposed. The key idea is to choose only the segments from a cluster that can best represent the writing style of the cluster. We call these selected segments vital segments. The vital segments have the following two features. First, they can repre- sent the expressive style of a specific cluster. Sec- ond, they can distinguish the writing style of that cluster from other clusters. Henceforth, we con- sider all of the segments as labelled, based on the results of the clustering assignment (Step 3). To find the vital segments of each class (noting that, the term 'cluster' is now substituted with 'class'), we consider the differences in the posterior prob- abilities of each segment according to the other classes. Expressly, for each segment in a class, we compute the differences between the posterior probability of that segment in its class and the maximum posterior probability of that segment in other classes. Then, we select s% of them which have the biggest differences as vital segments of that class. To prevent the underflow point, we compute the posterior probability by adding the logarithms of probabilities instead of multiplying the probabilities. Furthermore, we assume that the features in the segments are mutually indepen- dent.</p><note type="other">In the Ezekiel-Job document, Cluster 1 is the Ezekiel class and Cluster 2 is the Job class. We set s to be 80, so we get 34 vital segments for the Ezekiel class and 28 vital segments for the Job class. Of the 34 vital segments in Ezekiel class, 30 are truly written by Ezekiel, and of the 28 vi- tal segments in Job class, 25 are truly written by Job. As a result, the precisions of Ezekiel class and Job class are increased to 88.2% and 89.3%, respectively. The vital segments for</note><p>two classes are used to train the supervised classifier which can best classify each sentence to the correct au- thor's class. Therefore, in Step 6, the vital seg- ments are represented in terms of the frequencies of all words that have appeared at least three times in the whole document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>In</head><p>Step 7, the Naive-Bayesian model is applied to learn a classifier. In Step 8, this classifier is used to classify the sentences in the merged document to either Ezekiel class or Job class.We find that 93.1% of all sentences of Ezekiel and Job classes are correctly classified. In (Step 9), a probability indication procedure is proposed based on the following five criteria. First, any sentence in the document is considered as trusted sentence if its posterior probability in its class is greater than its posterior probabilities in all other classes by more than threshold q. There- upon, every trusted sentence holds its class. Sec- ond, if the first sentences in the document are not deemed to be trusted sentences, then they are as- signed to the same class of the first trusted sen- tence that follow them. Third, if the last sentences in the document are not deemed to be trusted sen- tences, then they are assigned to the same class of the last trusted sentence that precede them. Fourth, if a group of unassigned sentences is located be- tween two trusted sentences which have the same class, then all of the sentences in that group are as- signed to the same class of these trusted sentences. Fifth, if a group of unassigned sentences is located between two trusted sentences which have differ- ent labels, then the best separated point in that group is detected to separate it into two subgroups, left and right subgroups. The left subgroup is as- signed to the same label of the last trusted sen- tence that precede it and the right subgroup is as- signed to the same label of the first trusted sen- tence that follow it. In the Ezekiel-Job document, by setting the value of q to be 5.0, 98.8% of the Ezekiel sentences and 99.1% of the Job sentences are correctly classified. The overall accuracy of all sentences is 99.0%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>We use three datasets to test our method and show the adaptability of our method to different types of documents. The first dataset consists of 690 blogs written by Gary Becker and Richard Pos- ner. This dataset containing articles of multiple authors is challenging because it covers a lot of different topics. That means, we cannot depend on the topics to help us distinguish the authors. The second dataset consists of 1,182 New York Times articles. These articles have been written by Maureeen Dowd, Gail Collins, Thomas Fried- man and Paul Krugman. The third dataset consists of 5 biblical books which are written in Hebrew, a language other than English. These books are written by Isaiah (for Chapters 1-33), Jeremiah, Ezekiel, Job (for Chapters 3-41) and Proverbs. The first 3 are all in the prophetic literature and the other two are in the wisdom literature. In view of this, we conduct our experiments on three dif- ferent datasets, each dataset has its characteristics which yield us to use it. In our experiments, the merged documents are created in the same way as we have discussed before. We set the value of V to be 200, and the number of authors of these doc- uments to be two, three or four (l = {2,3,4}). We use the same values of the parameters as we have used in the Ezekiel-Job document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Becker-Posner</head><p>In the first dataset, each author has written for a lot of different topics, and there have been some topics taken by both authors. Therefore, there is no topic indication to distinguish between the two authors. We have achieved an overall accuracy of 96.6% when testing on this dataset. This re- sult is gratifying in this merged document that has more than 246 transitions between sentences writ- <ref type="figure">Figure 1</ref>: Accuracy comprisons between our method and the method used by <ref type="bibr" target="#b0">Akiva and Koppel (2013)</ref> in Becker-Posner document, and in docu- ments created by three or four New York Times au- thors (GC = Gail Collins, PK = Paul Krugman, TF = Thomas Friedman, MD = Maureen Dowd) ten by the two authors and more than 26,900 sen- tences. In <ref type="figure">Figure 1</ref>, we show the comparison be- tween our method and the method in Akiva and Koppel (2013).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">New York Times Articles</head><p>This dataset contains articles written by four au- thors. First, we test our method using the merged documents created by any pair of the four authors. The results again are noticeable. The classification accuracies range from 93.3% to 96.1%. For com- parison,the accuracy can be as low as 88.0% when applying the method in <ref type="bibr" target="#b0">Akiva and Koppel (2013)</ref> on some of the merged documents.</p><p>To prove that our method can also work well when merged documents written by more than two authors, we have created merged documents writ- ten by any three of these four authors and formed four merged documents. We have also created a merged document written by all four New York Times authors. Then, we apply our method on these documents. In <ref type="figure">Figure 1</ref>, we show the ac- curacies of our method for classification on these documents. It is obvious that our method achieves high accuracies even when the documents are writ- ten by more than two authors. Furthermore, Fig- ure 1 also compares our results with the results achieved by <ref type="bibr" target="#b0">Akiva and Koppel (2013)</ref>. It shows that our method has given consistent results and better performance than the ones in Akiva and Koppel (2013).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Bible Books</head><p>In these experiments, we use two literature types of biblical books. We create merged documents written by any pair of authors. The resulted docu- <ref type="table" target="#tab_0">Different   Documents  1  2  3</ref> Our method Eze-Prov 77% 99% 91% 98% Jer-Prov 73% 97% 75% 99% Jer-Job 88% 98% 93% 98% Isa-Job 83% 99% 89% 99% Eze-Job 86% 99% 95% 99% Isa-Prov 71% 95% 85% 98% Overall 80% 98% 88% 99%</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Same</head><p>Jer-Eze 82% 97% 96% 97% Isa-Eze 79% 80% 88% 83% Job-Prov 85% 94% 82% 95% Isa-Jer 72% 67% 83% 71% Overall 80% 85% 87% 87%  <ref type="table" target="#tab_0">Tables 1, we</ref> show the comparisons of accu- racies of using our method and the methods pre- sented in <ref type="bibr" target="#b5">Koppel et al. (2011)</ref>, Akiva and Kop- pel (2013)-BinaryCommonWords and Akiva and Koppel (2013)-Synonyms.</p><p>As can be seen, the accuracies using our method in the documents with different literatures are in- teresting, and have achieved the accuracies of ei- ther 99% or 98% and have performed a lot bet- ter than the three state-of-the-art methods. Fur- thermore, the accuracies using our method on the documents with same literature are encouraging, and our method has achieved approximately the same overall accuracy compared with the method in <ref type="bibr" target="#b0">Akiva and Koppel (2013)</ref>, and have achieved better overall accuracy compared with the meth- ods in <ref type="bibr" target="#b0">Akiva and Koppel (2013)</ref> and <ref type="bibr" target="#b5">Koppel et al. (2011)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>In this paper, we have proposed an unsupervised method for decomposing a multi-author document by authorship.</p><p>We have tested our method on three datasets, of which every one has its own characteristics. It is clear that our method has achieved a significantly high accuracies in these datasets, even when there is no topic indication to differentiate sentences be- tween authors, and when the number of authors exceeds 2. Our results tested on these datasets have shown significantly better than those using the methods in <ref type="bibr" target="#b5">Koppel et al. (2011)</ref> and <ref type="bibr" target="#b0">Akiva and Koppel (2013)</ref>. Furthermore, our method can also compete with the method proposed in <ref type="bibr" target="#b0">(Akiva and Koppel, 2013</ref>)-Synonyms, which is only valid for Bible documents.</p><p>In our research, our aim is to segment classify sentences in a multi-author document according to the sentences' authors. We assume that the num- ber of authors of that document is known. In our future work, we work to automatically determine the number of authors of a multi-author document. Furthermore, we will explore an adaptive learning method to select the optimal value of the threshold q for the probability indication procedure.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Accuracy performance obtained from 
documents having different literatures or same 
literatures using the methods of 1-Koppel 
et al. (2011), 2-Akiva and Koppel (2013)-
BinaryCommonWords, 3-Akiva and Koppel 
(2013)-Synonyms and our method 

ments may belong to either the same literatures or 
different literatures. 
In </table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A generic unsupervised method for decomposing multi-author documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navot</forename><surname>Akiva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moshe</forename><surname>Koppel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Society for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2256" to="2264" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A gentle tutorial of the em algorithm and its application to parameter estimation for gaussian mixture and hidden markov models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jeff A Bilmes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Science Institute</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">510</biblScope>
			<biblScope unit="page">126</biblScope>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Topic-based document segmentation with probabilistic latent semantic analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><surname>Brants</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francine</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Tsochantaridis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the eleventh international conference on Information and knowledge management</title>
		<meeting>the eleventh international conference on Information and knowledge management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="211" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Advances in domain independent linear text segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Freddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st North American chapter of the Association for Computational Linguistics conference</title>
		<meeting>the 1st North American chapter of the Association for Computational Linguistics conference</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="26" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Topicbased multi-document summarization with probabilistic latent semantic analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonhard</forename><surname>Hennig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dai</forename><surname>Labor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RANLP</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="144" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Unsupervised decomposition of a document into authorial components</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moshe</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navot</forename><surname>Akiva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Idan</forename><surname>Dershowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nachum</forename><surname>Dershowitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1356" to="1364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Automated unsupervised authorship analysis using evidence accumulation clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Layton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Watters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Dazeley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">01</biblScope>
			<biblScope unit="page" from="95" to="120" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Text segmentation via topic modeling: an analytical study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hemant</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Yvon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Joemon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Jose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cappe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th ACM conference on Information and knowledge management</title>
		<meeting>the 18th ACM conference on Information and knowledge management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1553" to="1556" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An open-set size-adjusted bayesian classifier for authorship attribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bruce Schaalje</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalie</forename><forename type="middle">J</forename><surname>Blades</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomohiko</forename><surname>Funai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Society for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1815" to="1825" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Santiago</forename><surname>Segarra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Eisen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alejandro</forename><surname>Ribeiro</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.4469</idno>
		<title level="m">Authorship attribution through function word adjacency networks</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
