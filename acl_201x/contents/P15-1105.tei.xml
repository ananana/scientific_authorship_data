<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:58+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Automatic Spontaneous Speech Grading: A Novel Feature Derivation Technique using the Crowd</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinay</forename><surname>Shashidhar</surname></persName>
							<email>vinay.shashidhar@aspiringminds.com</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Aspiring Minds</orgName>
								<orgName type="department" key="dep2">Aspiring Minds</orgName>
								<orgName type="department" key="dep3">Aspiring Minds</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nishant</forename><surname>Pandey</surname></persName>
							<email>nishant.pandey@aspiringminds.com</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Aspiring Minds</orgName>
								<orgName type="department" key="dep2">Aspiring Minds</orgName>
								<orgName type="department" key="dep3">Aspiring Minds</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varun</forename><surname>Aggarwal</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Aspiring Minds</orgName>
								<orgName type="department" key="dep2">Aspiring Minds</orgName>
								<orgName type="department" key="dep3">Aspiring Minds</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Automatic Spontaneous Speech Grading: A Novel Feature Derivation Technique using the Crowd</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1085" to="1094"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In this paper, we address the problem of evaluating spontaneous speech using a combination of machine learning and crowdsourcing. Machine learning techniques inadequately solve the stated problem because automatic speaker-independent speech transcription is inaccurate. The features derived from it are also inaccurate and so is the machine learning model developed for speech evaluation. To address this, we post the task of speech transcription to a large community of online workers (crowd). We also get spoken English grades from the crowd. We achieve 95% transcription accuracy by combining transcriptions from multiple crowd workers. Speech and prosody features are derived by force aligning the speech samples on these highly accurate transcriptions. Additionally , we derive surface and semantic level features directly from the transcription. To demonstrate the efficacy of our approach we performed experiments on an expert-graded speech sample of 319 adult non-native speakers. Using these features in a regression model, we are able achieve a Pearson correlation of 0.76 with expert grades, an accuracy much higher than any previously reported machine learning approach. Our approach has an accuracy that rivals that of expert agreement. This work is timely given the huge requirement of spoken English training and assessment.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Automatic evaluation of spoken English has been of keen interest for more than two decades <ref type="bibr" target="#b48">(Zechner et al., 2007;</ref><ref type="bibr" target="#b32">Neumeyer et al., 1996;</ref><ref type="bibr" target="#b14">Franco et al., 2000</ref>; <ref type="bibr" target="#b6">Cucchiarini et al., 1997)</ref>. It can help learners get feedback in a scalable manner, help build better English training software and also help companies and institutions filter and se- lect prospective employees more effectively. The problem acquires significance given the evidence that better English leads to better employment out- come, wages and promotions <ref type="bibr" target="#b16">(Guven and Islam, 2013)</ref>.</p><p>There has been a considerable success in auto- matically scoring spoken English, when the spo- ken text is known a priori ( <ref type="bibr" target="#b7">Cucchiarini et al., 2000</ref>; <ref type="bibr" target="#b14">Franco et al., 2000</ref>). In these cases, the candidate is asked to either read a given text or listen to some speech and repeat it. For these tasks, the scores generated by an automatic sys- tem on parameters such as pronunciation and flu- ency closely mimic those given by human ex- perts. The primary approach behind a majority of these systems is to force align the speech sample on the known text using an HMM-based acous- tic model. Features such as likelihood, posterior probability and fluency related features are derived from the aligned speech and a machine learning model is used to predict expert grades <ref type="bibr" target="#b32">(Neumeyer et al., 1996;</ref><ref type="bibr" target="#b14">Franco et al., 2000;</ref><ref type="bibr" target="#b6">Cucchiarini et al., 1997</ref>). Some approaches additionally use prosody and energy related features ( <ref type="bibr" target="#b9">Dong et al., 2004</ref>). More recently, this research has moved towards the assessment of higher granularity metrics like the mispronunciation of particular phonemes ( <ref type="bibr" target="#b27">Li et al., 2009;</ref><ref type="bibr" target="#b21">Ito et al., 2006</ref>; <ref type="bibr" target="#b22">Koniaris and Engwall, 2011)</ref>.</p><p>In spontaneous speech evaluation, the candidate is asked to speak on a topic or answer a question and what he/she speaks isn't known priori. Evalu- ation of spontaneous speech is the ultimate test of a candidate's proficiency in speaking a language <ref type="bibr" target="#b17">(Hagley, 2010;</ref><ref type="bibr" target="#b18">Halleck, 1995)</ref>. While scores from the evaluation of read/repeat speech do correlate with spontaneous speech evaluation, there remains an unexplained variance in the spontaneous speech scores (see Section 5). Generally, candidates who score high on spontaneous speech also score high on read speech and not vice versa.</p><p>Given the primacy of spontaneous speech eval- uation in judging a person's language capabil- ity, there is considerable interest in doing it au- tomatically ( <ref type="bibr" target="#b6">Cucchiarini et al., 1997;</ref><ref type="bibr" target="#b9">Dong et al., 2004</ref>). Automated approaches for the same have not worked well ( <ref type="bibr" target="#b36">Powers et al., 2002;</ref><ref type="bibr" target="#b7">Cucchiarini et al., 2000</ref>) primarily because speaker- independent speech recognition is a tough com- puter science problem. This is exacerbated when the speakers are not proficient in the language or are non-natives ( <ref type="bibr" target="#b36">Powers et al., 2002</ref>). Given that speech to text conversion for such candidates has a low accuracy, force alignment of the speech on this inaccurate text makes the features and the model inaccurate.</p><p>We present a semi-automated approach to grade short duration (45 seconds) spontaneous speech. We accurately predict a holistic score which is based on the pronunciation, fluency, content char- acteristics and grammar of the speech sample, as determined by experts. Multiple previous studies in language acquisition and second language re- search conclusively show that proficiency in a sec- ond language can be characterized by these factors <ref type="bibr" target="#b3">(Bhat et al., 2014</ref>). Being able to provide a holistic score is of high interest in both educational test- ing ( <ref type="bibr" target="#b49">Zechner et al., 2009</ref>) and job related testing <ref type="bibr" target="#b39">(Streeter et al., 2011</ref>). Institutions and firms look for a holistic score, say based on CEFR, a stan- dard to describe spoken English assessment <ref type="bibr" target="#b29">(Little, 2006;</ref><ref type="bibr" target="#b30">Little, 2007)</ref>, to make an accept or reject decision on candidates. Currently, an expert based assessment is used for these purposes.</p><p>Our method involves combining machine learn- ing with a crowdsourcing layer. Crowdsourcing <ref type="bibr">(Estellés-Arolas and González-Ladrón-de Guevara, 2012</ref>) is the process of getting human in- telligence tasks performed by a large community of online workers (crowd) as opposed to tradi- tional employees. <ref type="bibr">1</ref> The responses from the hu- man intelligence tasks are then used to create rel- evant features for machine learning. Human in- 1 Our approach is different from peer grading <ref type="bibr" target="#b26">(Lejk and Wyvill, 2001</ref>) or crowd grading <ref type="bibr" target="#b42">(Van Houdnos, 2011;</ref><ref type="bibr" target="#b41">Tetreault et al., 2010;</ref><ref type="bibr" target="#b31">Madnani et al., 2011</ref>) approaches. These approaches directly ask the crowd to grade the re- sponse. The primary feature of our technique is using the crowd in the feature extraction step of machine learning. telligence tasks are defined as those which most humans find easy, but are hard for machines. For instance, a classic example is the task of finding a particular object in an image. There is a large research community that uses crowdsourcing and has demonstrated that it can help perform tasks in- expensively, in large volumes and within reason- able time <ref type="bibr" target="#b20">(Howe, 2006;</ref><ref type="bibr" target="#b45">Whitla, 2009)</ref>.</p><p>Our system design for evaluation of sponta- neous speech is illustrated in <ref type="figure" target="#fig_0">Figure 1</ref>. We post the task 2 of speech transcription to the crowd. We get a final accurate transcription by combining the transcriptions from more than one crowd worker for the same speech sample. Once we have this accurate transcription, we force-align <ref type="bibr" target="#b10">(Erling and Seargeant, 2013;</ref><ref type="bibr" target="#b37">Sjölander, 2003</ref>) the speech of the candidate on this text to derive various features which go into a machine learning engine. We also collect spoken English grades of the speech from the crowd ( <ref type="bibr" target="#b26">Lejk and Wyvill, 2001</ref>), which are used as additional features. With these accurately iden- tified features and crowd grades, machine learning is able to grade spontaneous speech with high ac- curacy. We found that this approach does much better than a pure machine learning approach.</p><p>Crowdsourcing has been used for almost a decade in various problems in speech analysis, grading and language learning <ref type="bibr" target="#b24">(Kunath and Weinberger, 2010;</ref><ref type="bibr" target="#b35">Peabody, 2011;</ref><ref type="bibr" target="#b44">Wang et al., 2014</ref>). Within assessment of speech, currently all such approaches use the crowd to directly grade cer- tain parts of the speech ( <ref type="bibr" target="#b43">Wang and Meng, 2012)</ref>. Our work is uniquely positioned where we use the crowd to do accurate transcription, a human intel- ligence task, and use it in a machine learning based algorithm. <ref type="bibr">3</ref> We show that such a system provides an accuracy rivaling that of experts.</p><p>In this paper, we solve a hitherto unsolved prob- lem of spontaneous speech evaluation ( <ref type="bibr" target="#b49">Zechner et al., 2009</ref>). The paper makes the following contri- butions:</p><p>• We show that spoken English can be graded with accuracy by combining machine learn- ing and crowdsourcing higher than a pure machine learning approach. • We show that the features derived from crowdsourced transcriptions perform as well as crowd grades in predicting expert grades. However, crowd grades add additional pre- dictive value.</p><p>• We propose a scalable and accurate way to perform evaluation of spontaneous speech, a huge requirement in the industry and else- where.</p><p>The paper is organized as follows-Section 2 describes the procedure and aim of the speech assessment task; Section 3 describes the feature classes used in the prediction algorithm; Section 4 describes the crowdsourcing framework which is used as an input to machine learning meth- ods; Section 5 demonstrates how this framework is used with machine learning techniques to pre- dict a composite spoken English score; Section 6 discusses the future work and concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Grading Task</head><p>We want to assess the quality of spoken English of candidates based on their spontaneous speech samples. The speech samples of the candidates were collected using Aspiring Minds' automated speech assessment tool-SVAR <ref type="bibr" target="#b40">(SVAR, 2014)</ref>. SVAR is conducted over phone as well as on a computer. The test has multiple sections where the candidate is required to: read sentences aloud, listen and repeat sentences, listen to a passage or conversation and answer multiple choice questions and finally spontaneously speak on a given topic.</p><p>In the spontaneous speech section, the candidates 4 are provided with a topic and given 30 seconds 5 to think, take notes and then speak on the topic for 45 seconds. The topic is repeated to ensure task clarity. The complete test takes 16-20 minutes to complete, depending on the test version.</p><p>Currently, SVAR evaluates speech samples from the read and repeat sections with high accu- racy <ref type="bibr" target="#b40">(SVAR, 2014)</ref>. Our goal in this paper is to evaluate the spontaneous speech of the candidate and provide a composite score based on it.</p><p>A 5 point rubric for the composite score, similar to CEFR (Examinations, 2011), was prepared with the help of experts. This score is a function of the pronunciation, fluency, content organization and grammar quality of the speech sample. Broadly speaking, Pronunciation <ref type="bibr" target="#b8">(Dobson, 1957)</ref> refers to the correctness in the utterance of the phonemes of a word by the students as per neutral accent. Fluency <ref type="bibr" target="#b5">(Brumfit and Brumfit, 1984)</ref> refers to a desired rate of speech along with the absence of hesitations, false starts and stops etc. Content or- ganization <ref type="bibr" target="#b38">(Stalnaker, 1999</ref>) measures the candi- date's ability to structure the information disposi- tion and present it coherently. Grammar <ref type="bibr" target="#b4">(Brazil, 1995)</ref> measures how well the syntax of the lan- guage was followed by the candidate. In the next section we discuss the features which are used in the prediction algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Features</head><p>We use three classes of features-Crowd Grades (CG), Force Alignment features (FA) and Natu- ral Language Processing features (NLP). The spo- ken English samples are posted to the crowd to get the transcription and spoken English grades <ref type="figure" target="#fig_0">(Fig- ure 1)</ref>. Each task was completed by three workers. The crowd grades become one set of features. A second set, i.e., FA features, are derived by align- ing ( <ref type="bibr" target="#b10">Erling and Seargeant, 2013;</ref><ref type="bibr" target="#b37">Sjölander, 2003</ref>) the speech sample on the crowdsourced transcrip- tions. A third set, i.e., NLP features, are also de- rived from the crowdsourced text. These are ex- plained in the succeeding paragraphs.</p><p>• Crowd Grades: The crowd transcribes the speech in addition to providing scores on each of the following-pronunciation, flu- ency, content organization and grammar. These grades are combined to form a com- posite score per worker per candidate. These are further averaged across workers to give a final score. 6</p><p>• FA features: The speech sample is forced aligned <ref type="bibr" target="#b10">(Erling and Seargeant, 2013;</ref><ref type="bibr" target="#b37">Sjölander, 2003)</ref> on the crowdsourced tran- scription using the HTK speech recognizer ( <ref type="bibr" target="#b46">Young et al., 2006</ref>). We used an acoustic model based on TIMIT ( <ref type="bibr" target="#b15">Garofolo et al., 1993)</ref> for our experiments. TIMIT is a 6 Advanced Expectation-Maximization techniques (Hos- seini et al., 2012) may also be used for an aggregation strat- egy, once the number of tasks done by every individual worker increases. In our current experiments, this number wasn't very high. corpus of phonemically and lexically tran- scribed speech of American English speakers of different sexes and dialects.</p><p>A number of speech quality features are de- rived, which include-rate of speech, posi- tion and length of pauses, log likelihood of recognition, posterior probability, hesitations and repetitions etc. These features are well known in literature and may be referred from <ref type="bibr" target="#b32">(Neumeyer et al., 1996;</ref><ref type="bibr" target="#b49">Zechner et al., 2009;</ref><ref type="bibr" target="#b7">Cucchiarini et al., 2000</ref>). These features are predictive of the pronunciation and fluency of the candidate.</p><p>• NLP features: These features predict the con- tent quality and grammar of the spoken con- tent 7 . They were derived using standard NLP packages <ref type="bibr" target="#b28">(LightSide, 2013;</ref><ref type="bibr" target="#b0">AfterTheDeadline, 2014</ref>) on the crowdsourced transcrip- tion. The package calculates surface level features such as the number of words, com- plexity or difficulty of words and the num- ber of common words used. It also calculates semantic features like the coherency in text, context of the words spoken, sentiment of the text and grammar correctness. In the current system, we do not use any prompt specific features such as occurrence of specific words or phrases. These features are predictive of the grammar and content organization of the sample.</p><p>All the features described above were obtained for the spontaneous speech sample. We also derived features similar to FA features for the candidate's read and repeat speech samples col- lected during his/her SVAR test. The speech and prosody features are calculated by force aligning the speech on the known text. One of the mod- els (RS/LR) in our experiments is based on these features and has been included for comparison. These features do not have any bearing on our final model for spontaneous speech evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Crowdsourcing</head><p>The spoken English sample was given to the crowd to transcribe and provide grades. The task was posted on a popular crowdsourcing platform- Amazon Mechanical Turk (AMT) ( <ref type="bibr" target="#b34">Paolacci et al., 2010)</ref>. AMT is a popular crowdsourcing market- place. It is inspired by the famous 18 th century au- tomated chess playing machine, running on the in- telligence of a hidden human operator. It has more than 500, 000 online workers from 190 countries <ref type="bibr">(Turk, 2014)</ref>. One can post tasks on the platform online and offer fixed remuneration for their com- pletion.</p><p>A clean and simple interface was provided to the worker with standard features needed for tran- scription. Additionally, an advanced audio player was embedded with the ability to play the speech sample in repeat mode, rewind and forward, apart from standard play/pause functionality to help the worker. The different transcriptions were com- bined using the ROVER algorithm <ref type="bibr" target="#b13">(Fiscus, 1997)</ref>. ROVER is a sophisticated voting algorithm to combine multiple transcriptions with errors, to ob- tain the best estimate of the correct transcription. It is reported to lead to an error reduction of 20- 25%. ROVER proceeds in two stages: first the outputs are aligned and a single word transcription network (WTN) is built. The second stage consists of selecting the best scoring word (with the highest number of votes) at each node.</p><p>Several methods have been used in the past for increasing the reliability of the grades given by the crowd by identifying and correcting any biases and removing non-serious/low quality workers <ref type="bibr" target="#b1">(Aker et al., 2012</ref>). One of the key techniques for this involves inserting gold standard tasks with known answers to get an estimate of the worker's abil- ity ( <ref type="bibr" target="#b33">Nguyen et al., 2013</ref>). The gold standard tasks are similar to real tasks and the workers have no way to distinguish between the two. Our tasks took workers a reasonable amount of time <ref type="bibr">(8-10 minutes)</ref>. It wasn't hence feasible to insert a gold standard task, as done typically, with every task to be completed.</p><p>To overcome this problem, we propose an in- novative approach where a risk is assigned to a worker based on his/her performance on the gold standard tasks. We conceptualized this system as a state machine that determines the risk level of a worker and proposes actions based on it (Re- fer to <ref type="figure" target="#fig_2">Figure 3</ref>). All workers started with an ini- tial risk level of 0.2. Gold standard tasks were probabilistically inserted among real tasks based on the worker's risk level. Workers with a higher risk level saw more gold standard tasks. Also, the risk level of the worker was updated based on his/her performance on the gold standard tasks. Workers who consistently performed poorly on gold standard tasks were allocated a higher risk level and a notification was sent to them with a corrective course of action. Beyond a certain level, the worker was barred from attempting fu- ture work. We did not do any retrospective correc- tion of the barred worker's completed tasks and simply stopped him/her from attempting newer tasks. This approach allowed us to control for the quality of workers, provide feedback, remove un- suitable workers and also adaptively control the balance between real and gold standard tasks. <ref type="bibr">8</ref> We describe the experimental setup and the re- sults in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>We conducted the experiments to answer the fol- lowing questions:</p><p>• Can read/repeat features predict spontaneous speech grades accurately?</p><p>• How accurate is a pure machine learning ap- proach (without crowdsourced transcription) in predicting grades as compared to grades given by human experts?</p><p>• How much better is the ML-CS approach in <ref type="bibr">8</ref> Specific details of the implementation are beyond the scope of the paper. predicting grades as compared to a pure ML approach and to using Crowd Grades only?</p><p>• Do Crowd Grades add additional value in predicting grades over and above the features derived from the crowdsourced transcription?</p><p>We conducted the experiments on 319 sponta- neous speech samples which were graded by ex- pert assessors. To answer the questions stated above, we used different sets of features to develop models and compared their accuracy. The mod- els were built against expert grades using super- vised learning techniques. We experimented with three machine learning techniques-Ridge Regres- sion, SVMs and Neural Networks with different features selection algorithms. The data set used in the experiments is discussed in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Data Set</head><p>Our data set contains 319 spontaneous speech re- sponses. The speech samples were from seniors (non-native English speakers in final year of un- dergraduate education) pursuing bachelor's degree in India. The candidates were asked to describe one of the following scenes: a hospital, flood, a crowded market and a school playground. The candidates were given 30 seconds to think and take notes and were then asked to speak for the next 45 seconds. The responses were collected on the phone during the SVAR test <ref type="bibr" target="#b40">(SVAR, 2014)</ref>. Apart from the spontaneous speech response, each can- didate was asked to read 12 given sentences and repeat 9 given sentences immediately after listen- ing to each of them. Empty or very noisy re- sponses (not humanly discernible) were not in- cluded in the final 319 sample set. These responses were graded by two experts who had more than fifteen years of experience in grading spoken English responses. There were two set of scores. The first was a holistic score on the spontaneous speech samples based on its pronunciation, fluency, content characteristics and grammar. The second was a score on the pronun- ciation and fluency quality of the read/repeat sen- tences. The correlation between grades given by the two experts was 0.86 and 0.83 respectively for the two cases. For each of the two scores, the av- erage of the scores by the two expert grades was used for further purposes.</p><p>The correlation between the expert scores on spontaneous speech and read/repeat speech was 0.54. This shows that there is a considerable unex- plained variance (70%) in the spontaneous speech score, not addressed by the read/repeat scores. This could be due to a difference in the pronun- ciation quality and fluency of the candidates in reading/repeating text vs. speaking spontaneously and also due to the additional parameters of gram- mar and content characteristics in the spontaneous speech score. Thus, an automatic score mimick- ing the read/repeat expert grades, which is a solved problem, is inadequate for our task.</p><p>The first score is used for all subsequent discus- sion and development of models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Crowdsourced Tasks</head><p>The 319 speech sample assessment task was posted on Amazon Mechanical Turk (AMT). Each task was completed by three workers. In total, 71 unique workers completed the tasks. The majority of workers (90%) belonged to USA and India.</p><p>The task took on an average 8-9 minutes to complete and a worker was paid between 6-10 cents per task including a bonus which was paid on completion of every 4 tasks. We also got the speech transcribed by experts to find the accuracy we could get from turks. The average transcrip- tion accuracy for a worker was 82.4% 9 . This sig- nificantly improved to 95.4% when the transcrip- tions of the three workers were combined using the ROVER algorithm. In comparison, the aver- age automatic transcription of a speech recogni- tion engine was 59.8%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Regression Modeling</head><p>The data set was split into two sets: train and vali- dation. The train-set had 75% of the sample points whereas the validation set had 25%. The split was done randomly making sure that the grade distri- bution in both the sets was similar. While learning the model, a 4-fold cross validation was performed on the train sample.</p><p>Linear ridge regression, Neural Networks and SVM regression with different kernels were used to build the models. The least cross-validation er- ror was used to select the models. We used some simple techniques for feature selection including forward feature selection and the algorithm which removes all but the k highest correlating features.</p><p>Regression parameters: For linear regression with regularization, optimal ridge coefficient λ, between 1 and 1000, was selected based on the the least RMS error in cross-validation.</p><p>For support vector machines we tested two kernels: linear and radial basis function. In order to select the optimal SVM model, we varied the penalty factor C, pa- rameters γ and , the SVM kernel and the selected set of values that gave us the lowest RMS error in cross-validation. The Neural Networks model had one hidden layer and 5 to 10 neurons. Feature sets used: The experiments were car- ried out on five sets of features:</p><p>• RS/LR: A set of features generated by force aligning read/repeated by candidates.</p><p>• Pure ML: Features generated by automatic speech transcription of spontaneous speech using a speech recognizer.</p><p>• Crowd Grades: A set of features pertaining to grades given by the crowd.</p><p>• ML-CS: NLP and FA features generated by force aligning free speech on crowdsourced transcription.</p><p>• All: NLP and FA features from crowd- sourced transcription and Crowd Grades.</p><p>Here, the first set, RS/LR, helps us to know how well we can predict spontaneous speech grades by simply using the read/speak speech of the candi- date and without using his/her spontaneous speech sample. This provides a comparison baseline. The second approach evaluates how well we can grade spontaneous speech of the candidate using ma- chine learning approaches only. The third feature shows the efficacy of directly using grades given by crowd, while the fourth finds how well machine learning can do if it has a fairly accurate transcrip- tion of the speech by the crowd. The final fifth set tests what happens if we combine the third and fourth set of features, i.e. make use of both the crowdsourced transcription and the crowd grades.</p><p>In the following subsection, the features per- taining to ML-CS approach are referred to as ML- CS, those pertaining to natural language process- ing on crowdsourced transcription are referred to as NLP features while the one pertaining to crowd grades are referred to as Crowd Grades.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Observations</head><p>The results of the experiments are tabulated in Ta- ble 1. We report the Pearson coefficient of corre- lation (r) for the different models against the ex- pert grades. These are the results for the models selected according to least cross-validation error. The best cross-validation error in case of SVMs was obtained for the linear kernel.</p><p>All the following observations are based on the validation error. All three techniques perform sim- ilarly with Neural Networks doing slightly worse in some cases. The broad trends across fea- ture-sets remain similar across different modeling techniques. We will be referring to the ridge re- gression results for further discussion.</p><p>Firstly, it is observed that the read/repeat fea- tures predict the spontaneous speech score with low accuracy (r = 0.47). This implies that read- /repeat speech and derived features are inadequate to grade a person's spontaneous speech, the ulti- mate test of a person's spoken language skills.</p><p>The second observation is that the ML-only ap- proach using spontaneous speech features (Model RR-2) is also inadequate to grade spontaneous speech and does worse than approaches that uses features from crowdsourced transcription (Model RR-4). This clearly shows the value of getting ac- curate transcription from workers towards better features and model. Further, among the crowdsourcing approaches, we find that the crowd-grades (Model RR-3) does equivalently well (and sometimes worse) than the model using features derived from the crowd- sourced speech (Model RR-4). However, when we combine all the features from crowdsourcing including the crowd grades, we find much better prediction accuracy (r = 0.76). This shows that the crowd grades feature provides some orthogo- nal information as compared to the features from the crowdsourced transcription, towards predict- ing the grade given by experts.</p><p>The validation r for Model RR-5 is 0.76. We find that the expert agreement on the validation sample is 0.78. Thus, our predicted score rivals the agreement of experts. This shows great promise for the technique to be used in a high-stake test setting.</p><p>In summary, we show the following:</p><p>• Read/repeat speech features are inadequate to predict spontaneous speech scores.</p><p>• ML only approach based on spontaneous speech samples is also inadequate for the pur- pose.</p><p>• Features derived from crowdsourced tran- scription (or even crowd grades) do better than a ML only approach.</p><p>• When considering features from crowd- sourced transcription and crowd grades to- gether, we can predict spontaneous speech scores as well as those done by experts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>We addressed the problem of evaluating spon- taneous speech using a combination of machine learning and crowdsourcing. To achieve this, we post the task of speech transcription to the crowd. Additionally, we also get spoken English grades from the crowd. We are able to derive accurate features by force aligning the speech sample on the crowdsourced text. We experimented our tech- nique on expert-graded speech samples of adult non-native speakers. Using these features in a regression model, we are able to predict expert grades with much higher accuracy than a machine learning only approach. These features also pre- dict equivalent or better than crowd grades and a combination of these two outperforms all other ap- proaches. Our approach shows an accuracy that rivals that of expert agreement. Our technique has a promise of higher accuracy but has some trade-offs compared to fully auto- mated approaches. First, there is a cost for ev- ery assessment done and the scalability depends on the number of non-expert workers available. Though these drawbacks exist, we were able get tasks done inexpensively. We recently had the crowd rate a hundred samples in a day without any challenge. Second, our approach doesn't provide instant grades. This works fine in many scenarios, but doesn't cater well to providing real-time feed- back. Real time crowdsourcing has been an active area of research <ref type="bibr" target="#b25">Lasecki et al., 2013)</ref> and is an area for future work for us as well.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: System Design</figDesc><graphic url="image-1.png" coords="3,72.00,62.81,453.54,204.49" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Our intuition of how different features predict the holistic score.</figDesc><graphic url="image-2.png" coords="4,72.00,62.81,218.26,123.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Risk Level State Diagram: In the above figure, each node corresponds to a risk level associated with a worker. The values range between 0 (min)-1 (max). The worker is either assigned a gold standard task (G) or a normal task (N) on the basis of his/her present risk level. The risk level changes every time a task is Accepted (A) or Rejected (R). Additionally worker may be warned (W) or blocked (B) in case of rejection.</figDesc><graphic url="image-3.png" coords="5,307.28,62.81,218.27,129.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 : Regression Results</head><label>1</label><figDesc></figDesc><table>Technique 
Model Code Feature Type 
Train r Validation r 

RR-1 
RS/LR 
0.51 
0.47 
Ridge Regression RR-2 
Pure ML 
0.54 
0.47 
RR-3 
Crowd Grades 
0.63 
0.57 
RR-4 
ML-CS 
0.55 
0.60 
RR-5 
All 
0.76 
0.76 
SVM-1 
RS/LR 
0.50 
0.46 
SVM 
SVM-2 
Pure ML 
0.53 
0.46 
SVM-3 
Crowd Grades 
0.62 
0.57 
SVM-4 
ML-CS 
0.60 
0.61 
SVM-5 
All 
0.75 
0.74 
NN-1 
RS/LR 
0.56 
0.51 
Neural Networks NN-2 
Pure ML 
0.60 
0.44 
NN-3 
Crowd Grades 
0.63 
0.57 
NN-4 
ML-CS 
0.66 
0.57 
NN-5 
All 
0.80 
0.76 

</table></figure>

			<note place="foot" n="2"> Even though speaker-independent speech recognition is a hard problem for machines, it is fairly easy for a native speaker or anyone with reasonable command over the language. 3 Again, speech transcription has been done previously using crowdsourcing (Zaidan and Callison-Burch, 2011), but not used for a grading purpose or combined with machine learning.</note>

			<note place="foot" n="4"> The subjects of our study use English as their second language and hail from various backgrounds, dialects and educational qualifications. 5 This is as per global standards of spoken English assessment. High stake tests such as TOEFL provide the candidate 15-30 seconds to think before responding to a spontaneous speech task.</note>

			<note place="foot" n="7"> We were looking at prompt independent features only, at this point.</note>

			<note place="foot" n="9"> PHP similar text function was used as similarity metric.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Afterthedeadline</surname></persName>
		</author>
		<ptr target="www.afterthedeadline.com" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Assessing crowdsourcing quality through objective tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmet</forename><surname>Aker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahmoud</forename><surname>El-Haj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M-Dyaa</forename><surname>Albakour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Udo</forename><surname>Kruschwitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1456" to="1461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Crowds in two seconds: Enabling realtime crowd-powered interfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Michael S Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David R</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Karger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th annual ACM symposium on User interface software and technology</title>
		<meeting>the 24th annual ACM symposium on User interface software and technology</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="33" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Shallow analysis based assessment of syntactic complexity for automated speech scoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suma</forename><surname>Bhat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huichao</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Su-Youn</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1305" to="1315" />
		</imprint>
	</monogr>
	<note>Long Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">A grammar of speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Brazil</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<publisher>Oxford University Press</publisher>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Communicative methodology in language teaching: The roles of fluency and accuracy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Brumfit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brumfit</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984" />
			<publisher>Cambridge University Press</publisher>
			<biblScope unit="volume">129</biblScope>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Automatic evaluation of dutch pronunciation by using speech recognition technology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catia</forename><surname>Cucchiarini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helmer</forename><surname>Strik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lou</forename><surname>Boves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automatic Speech Recognition and Understanding</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="622" to="629" />
		</imprint>
	</monogr>
<note type="report_type">Proceedings</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Quantitative assessment of second language learners&apos; fluency by means of automatic speech recognition technology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catia</forename><surname>Cucchiarini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helmer</forename><surname>Strik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lou</forename><surname>Boves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="989" to="999" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">English Pronunciation, 1500-1700: Phonology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric John</forename><surname>Dobson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1957" />
			<publisher>Clarendon Press</publisher>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Automatic assessment of pronunciation quality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingwei</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghong</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Chinese Spoken Language Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="137" to="140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">English and development: Policy, pedagogy and globalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Elizabeth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Erling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Seargeant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multilingual Matters</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Towards an integrated crowdsourcing definition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enrique</forename><surname>Estellés</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Arolas</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando Gonzálezladrón-De</forename><surname>Guevara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Information science</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="189" to="200" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Using the CEFR: Principles of good practice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eocl</forename><surname>Cambridge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Examinations</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
		<respStmt>
			<orgName>at University of Cambridge</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A post-processing system to yield reduced word error rates: Recognizer output voting error reduction (rover)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Jonathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fiscus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automatic Speech Recognition and Understanding</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="347" to="354" />
		</imprint>
	</monogr>
<note type="report_type">Proceedings</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The sri eduspeaktm system: Recognition and pronunciation scoring for language learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horacio</forename><surname>Franco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Abrash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristin</forename><surname>Precoda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harry</forename><surname>Bratt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramana</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Butzberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Romain</forename><surname>Rossier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Cesari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of InSTILL 2000</title>
		<meeting>InSTILL 2000</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="123" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Darpa timit acoustic-phonetic continous speech corpus cd-rom</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lori</forename><forename type="middle">F</forename><surname>John S Garofolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lamel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><forename type="middle">G</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David S</forename><surname>Fiscus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pallett</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page">27403</biblScope>
		</imprint>
	</monogr>
	<note>nist speech disc 1-1.1. NASA STI/Recon Technical Report N</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Age at migration, language proficiency and socio-economic outcomes: Evidence from australia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cahit</forename><surname>Guven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asadul</forename><surname>Islam</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Creation of speaking tests for efl communication classes. ł</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Hagley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="33" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Assessing oral proficiency: A comparison of holistic and objective measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gene</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Halleck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Modern Language Journal</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="223" to="234" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">On aggregating labels from multiple crowd workers to infer relevance of documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ingemar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nataša</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriella</forename><surname>Mili´cmili´cfrayling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vishwa</forename><surname>Kazai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vinay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in information retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="182" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">The rise of crowdsourcing. Wired magazine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Howe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Automatic detection of english mispronunciation using speaker adaptation and automatic assessment of english intonation and rhythm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akinori</forename><surname>Ito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tadao</forename><surname>Nagasawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hirokazu</forename><surname>Ogasawara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Motoyuki</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shozo</forename><surname>Makino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Educational technology research</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="13" to="23" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Perceptual differentiation modeling explains phoneme mispronunciation by non-native speakers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Koniaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olov</forename><surname>Engwall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acoustics, Speech and Signal Processing</title>
		<imprint>
			<publisher>ICASSP</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page">2011</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<title level="m">IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="5704" to="5707" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The wisdom of the crowd&apos;s ear: speech accent rating and annotation with amazon mechanical turk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Kunath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon&apos;s Mechanical Turk</title>
		<meeting>the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon&apos;s Mechanical Turk</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="168" to="171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Warping time for more effective real-time crowdsourcing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Walter S Lasecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey P</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bigham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2033" to="2036" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The effect of the inclusion of selfassessment with peer assessment of contributions to a group project: A quantitative study of secret and agreed assessments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Lejk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Wyvill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Assessment &amp; Evaluation in Higher Education</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="551" to="561" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">High performance automatic mispronunciation detection method based on neural network and trap features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shijin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1911" to="1914" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lightside</surname></persName>
		</author>
		<ptr target="http://lightsidelabs.com/" />
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">The common european framework of reference for languages: Content, purpose, origin, reception and impact. Language Teaching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Little</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="167" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The common european framework of reference for languages: Perspectives on the making of supranational language education policy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Little</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Modern Language Journal</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="645" to="655" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">They can help: using crowdsourcing to improve the evaluation of grammatical error detection systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitin</forename><surname>Madnani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Tetreault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Chodorow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alla</forename><surname>Rozovskaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="508" to="513" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Automatic textindependent pronunciation scoring of foreign language student speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonardo</forename><surname>Neumeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horacio</forename><surname>Franco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchel</forename><surname>Weintraub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patti</forename><surname>Price</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Spoken Language, 1996. ICSLP 96. Proceedings., Fourth International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1996" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1457" to="1460" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">An evaluation of aggregation techniques in crowdsourcing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Viet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hung</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tam</forename><forename type="middle">Nguyen</forename><surname>Thanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tran</forename><forename type="middle">Lam</forename><surname>Ngoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Aberer</surname></persName>
		</author>
		<idno>number EPFL- CONF-187456</idno>
	</analytic>
	<monogr>
		<title level="m">The 14th International Conference on Web Information System Engineering (WISE)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Running experiments on amazon mechanical turk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriele</forename><surname>Paolacci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Chandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panagiotis G</forename><surname>Ipeirotis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Judgment and Decision making</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="411" to="419" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Methods for pronunciation assessment in computer aided language learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peabody</forename><surname>Mitchell Aaron</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
		<respStmt>
			<orgName>Massachusetts Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Stumping e-rater: challenging the validity of automated essay scoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jill</forename><forename type="middle">C</forename><surname>Donald E Powers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Burstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><forename type="middle">E</forename><surname>Chodorow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Fowles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kukich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="103" to="134" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">An hmm-based system for automatic segmentation and alignment of speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kåre</forename><surname>Sjölander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Fonetik</title>
		<meeting>Fonetik</meeting>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="93" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">The problem of logical omniscience, ii. context and content: Essays on intentionality in speech and thought</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Stalnaker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="255" to="273" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Pearsons automated scoring of writing, speaking, and mathematics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lynn</forename><surname>Streeter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jared</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Foltz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><surname>Deland</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svar</forename></persName>
		</author>
		<ptr target="http://www.aspiringminds.in/talent-evaluation/spoken-english-SVAR.html" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Rethinking grammatical error annotation and evaluation with the amazon mechanical turk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Joel R Tetreault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Filatova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chodorow</surname></persName>
		</author>
		<ptr target="https://requester.mturk.com/tour" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL HLT 2010 Fifth Workshop on Innovative Use of NLP for Building Educational Applications</title>
		<meeting>the NAACL HLT 2010 Fifth Workshop on Innovative Use of NLP for Building Educational Applications</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="45" to="48" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics. Amazon Mechanical Turk</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Can the internet grade math? crowdsourcing a complex scoring task and picking the optimal crowd size. Dietrich College of Humanities and Social Sciences at Research Showcase @ CMU</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Van Houdnos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Deriving perceptual gradation of l2 english mispronunciations using crowdsourcing and the workerrank algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helen</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 15th Oriental COCOSDA</title>
		<meeting>of the 15th Oriental COCOSDA<address><addrLine>Macau, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="9" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Phonological modeling of mispronunciation gradations in l2 english speech of l1 chinese learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helen</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acoustics, Speech and Signal Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="7714" to="7718" />
		</imprint>
	</monogr>
	<note>2014 IEEE International Conference on</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Crowdsourcing and its application in marketing activities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Whitla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Contemporary Management Research</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">The htk book (for htk version 3.4). Cambridge university engineering department</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gunnar</forename><surname>Evermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Gales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Hain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Kershaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xunying</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gareth</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Odell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dave</forename><surname>Ollason</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Povey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="2" to="3" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Crowdsourcing translation: Professional quality from non-professionals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Omar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Zaidan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1220" to="1229" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Speechrater: A construct-driven approach to scoring spontaneous non-native speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Zechner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derrick</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Xi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SLaTE</title>
		<meeting>SLaTE</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Automatic scoring of non-native spontaneous speech in tests of spoken english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Zechner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derrick</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Xi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David M</forename><surname>Williamson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Speech Communication</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="883" to="895" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
