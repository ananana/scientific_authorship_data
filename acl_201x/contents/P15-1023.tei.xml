<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:44+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Context-Aware Topic Model for Statistical Machine Translation</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinsong</forename><surname>Su</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Soochow University</orgName>
								<address>
									<settlement>Suzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyi</forename><surname>Xiong</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Institute of Software</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianpei</forename><surname>Han</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyu</forename><surname>Lin</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Soochow University</orgName>
								<address>
									<settlement>Suzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junfeng</forename><surname>Yao</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Soochow University</orgName>
								<address>
									<settlement>Suzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Xiamen University</orgName>
								<address>
									<settlement>Xiamen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Context-Aware Topic Model for Statistical Machine Translation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="229" to="238"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Lexical selection is crucial for statistical machine translation. Previous studies separately exploit sentence-level contexts and document-level topics for lexical selection, neglecting their correlations. In this paper, we propose a context-aware topic model for lexical selection , which not only models local contexts and global topics but also captures their correlations. The model uses target-side translations as hidden variables to connect document topics and source-side local contextual words. In order to learn hidden variables and distributions from data, we introduce a Gibbs sampling algorithm for statistical estimation and inference. A new translation probability based on distributions learned by the model is integrated into a translation system for lexical selection. Experiment results on NIST Chinese-English test sets demonstrate that 1) our model significantly outperforms previous lexical selection methods and 2) modeling correlations between local words and global topics can further improve translation quality.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Lexical selection is a very important task in statis- tical machine translation (SMT). Given a sentence in the source language, lexical selection statistically predicts translations for source words, based on vari- ous translation knowledge. Most conventional SMT systems ( <ref type="bibr" target="#b19">Koehn et al., 2003;</ref><ref type="bibr" target="#b9">Galley et al., 2006;</ref><ref type="bibr" target="#b5">Chiang, 2007</ref>) exploit very limited context informa- tion contained in bilingual rules for lexical selection. Previous studies that explore richer information for lexical selection can be divided into two categories: 1) incorporating sentence-level contexts <ref type="bibr" target="#b4">(Chan et al., 2007;</ref><ref type="bibr" target="#b3">Carpuat and Wu, 2007;</ref><ref type="bibr" target="#b13">Hasan et al., 2008;</ref><ref type="bibr" target="#b22">Mauser et al., 2009;</ref><ref type="bibr" target="#b29">Shen et al., 2009</ref>) or 2) integrating document-level topics <ref type="bibr" target="#b35">(Xiao et al., 2011;</ref><ref type="bibr" target="#b33">Ture et al., 2012;</ref><ref type="bibr" target="#b36">Xiao et al., 2012;</ref><ref type="bibr" target="#b8">Eidelman et al., 2012;</ref><ref type="bibr" target="#b17">Hewavitharana et al., 2013;</ref><ref type="bibr" target="#b38">Xiong et al., 2013;</ref><ref type="bibr">Hasler et al., 2014a;</ref><ref type="bibr">Hasler et al., 2014b</ref>) into SMT. The methods in these two strands have shown their effectiveness on lexical selection.</p><p>However, correlations between sentence-and document-level contexts have never been explored before. It is clear that local contexts and global top- ics are often highly correlated. Consider a Chinese- English translation example presented in <ref type="figure" target="#fig_0">Figure 1</ref>. On the one hand, if local contexts suggest that the source word "á|/l` ıchˇangıchˇang" should be translated in-to "stance", they will also indicate that the topic of the document where the example sentence oc- curs is about politics. The politics topic can be fur- ther used to enable the decoder to select a correc- t translation "issue" for another source word "¯ K/w` entˇientˇ entˇi", which is consistent with this topic. On the other hand, if we know that this document main- ly focuses on the politics topic, the candiate trans- lation "stance" will be more compatible with the context of "á|/l` ıchˇangıchˇang" than the candiate transla- tion "attitude". This is because neighboring source- side words "¥I/zh¯ onguó" and "¥á/zh¯ongì ı" of- ten occur in documents that are about international politics. We believe that such correlations between local contextual words and global topics can be used to further improve lexical selection.</p><p>In this paper, we propose a unified framework to jointly model local contexts, global topics as well as their correlations for lexical selection. Specifically,</p><p>• First, we present a context-aware topic mod- el (CATM) to exploit the features mentioned above for lexical selection in SMT. To the best of our knowledge, this is the first work to joint- ly model both local and global contexts for lex- ical selection in a topic model.</p><p>• Second, we present a Gibbs sampling algorith- m to learn various distributions that are related to topics and translations from data. The trans- lation probabilities derived from our model are integrated into SMT to allow collective lexical selection with both local and global informtion.</p><p>We validate the effectiveness of our model on a state-of-the-art phrase-based translation system. Ex- periment results on the NIST Chinese-English trans- lation task show that our model significantly outper- forms previous lexical selection methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Context-Aware Topic Model</head><p>In this section, we describe basic assumptions and elaborate the proposed context-aware topic model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Basic Assumptions</head><p>In CATM, we assume that each source document d consists of two types of words: topical words which are related to topics of the document and contextual words which affect translation selections of topical words.</p><p>As topics of a document are usually represented by content words in it, we choose source-side nouns, verbs, adjectives and adverbs as topical words. For contextual words, we use all words in a source sen- tence as contextual words. We assume that they are generated by target-side translations of other words than themselves. Note that a source word may be both topical and contextual. For each topical word, we identify its candidate translations from training corpus according to word alignments between the source and target language. We allow a target trans- lation to be a phrase of length no more than 3 words. We refer to these translations of source topical word- s as target-side topical items, which can be either words or phrases. In the example shown in <ref type="figure" target="#fig_0">Figure  1</ref>, all source words within dotted boxes are topical words. Topical word "á|/l` ıchˇangıchˇang" is supposed to be translated into a target-side topical item "stance", which is collectively suggested by neighboring con- textual words " ¥ I/zh¯ ongguó", "¥ á/zh¯ongì ı" and the topic of the corresponding document.</p><p>In our model, all target-side topical items in a doc- ument are generated according to the following two assumptions:</p><p>• Topic consistency assumption: All target-side topical items in a document should be consis- tent with the topic distribution of the document. For example, the translations "issue", "stance" tend to occur in documents about politics topic.</p><p>• Context compatibility assumption: For a top- ical word, its translation (i.e., the counter- part target-side topical item) should be com- patible with its neighboring contextual word- s. For instance, the translation "stance" of "á|/l` ıchˇangıchˇang" is closely related to contextu- al words "¥I/zh¯ onguó" and "¥á/zh¯ongì ı".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Model</head><p>The graphical representation of CATM, which visu- alizes the generative process of training data D, is shown in <ref type="figure" target="#fig_1">Figure 2</ref>. Notations of CATM are present- ed in <ref type="table">Table 1</ref>. In CATM, each document d can be generated in the following three steps 1 : Symbol Meaning α hyperparameter for θ β hyperparameter for φ γ hyperparameter for ψ δ hyperparameter for ξ f topical word c contextual word˜e word˜ word˜e target-side topical item˜e item˜ item˜e a sampled target-side topical item used to generate a source-side contextual word θ the topic distribution of document φ the distribution of a topic over target-side topical items ψ the translation probability distribution of a target-side topical item over source-side topical words ξ the generation probability distribution of a target-side topical item over source-side contextual words Nz topic number</p><formula xml:id="formula_0">N d document number N f</formula><p>the number of topical words Nc the number of contextual words N˜eN˜e the number of target-side topical items</p><formula xml:id="formula_1">N f,d</formula><p>the number of topical words in</p><formula xml:id="formula_2">d N c,d</formula><p>the number of contextual words in d <ref type="table">Table 1</ref>: Notations in CATM.</p><p>1. Sample a topic distribution θ d ∼Dir(α). To better illustrate CATM, let us revisit the example in <ref type="figure" target="#fig_0">Figure 1</ref>. We describe how CATM generates top- spectively. ical words "¯K/w` entí", "á|/l` ıchˇangıchˇang", and con- textual word "¥á/zh¯ongì ı" in the following steps:</p><p>Step 1: The model generates a topic dis- tribution for the corresponding document as {economy 0.25 , politics 0.75 }.</p><p>Step 2: Based on the topic distribution, we choose "economy" and "politics" as topic assign- ments for "¯K/w` entí" and "á|/l` ıchˇangıchˇang" respec- tively; Then, according to the distributions of the t- wo topics over target-side topical items, we generate target-side topical items "issue" and "stance"; Final- ly, according to the translation probability distribu- tions of these two topical items over source-side top- ical words, we generate source-side topical words "¯K/w` entí" and "á|/l` ıchˇangıchˇang" for them respec- tively.</p><p>Step 3: For the contextual word "¥á/zh¯ongì ı", we first collect target-side topical items of its neigh- boring topical words such as "¯ K/w` entí", " ±/bˇaochíbˇaochí" and "á |/l` ıchˇangıchˇang" to form a target- side topical item set {"issue","keep", "stance"}, from which we randomly sample one item "stance". Next, according to the generation probability dis- tribution of "stance" over source contextual words, we finally generate the source contextual word "¥ á/zh¯ongì ı".</p><p>In the above generative process, all target-side topical items are generated from the underlying top- ics of a source document, which guarantees that se- lected target translations are topic-consistent. Ad-ditionally, each source contextual word is derived from a target-side topical item given its generation probability distribution. This makes selected target translations also compatible with source-side local contextual words. In this way, global topics, topical words, local contextual words and target-side topi- cal items are highly correlated in CATM that exactly captures such correlations for lexical selection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Parameter Estimation and Inference</head><p>We propose a Gibbs sampling algorithm to learn var- ious distributions described in the previous section. Details of the learning and inference process are p- resented in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The Probability of Training Corpus</head><p>According to CATM, the total probability of train- ing data D given hyperparameters α, β, γ and δ is computed as follows:</p><formula xml:id="formula_3">P (D; α, β, γ, δ) = d P (f d , c d ; α, β, γ, δ) = d ˜ e d P (˜ e d |α, β)P (f d |˜e|˜e d , γ)P (c d |˜e|˜e d , δ) = φ P (φ|β) ψ P (ψ|γ) d ˜ e d P (f d |˜e|˜e d , ψ) × ξ P (ξ|δ) ˜ e d P (˜ e d |˜e|˜e d )p(c d |˜e|˜e d , ξ) × θ P (θ|α)P (˜ e d |θ, φ)dθdξdψdφ<label>(1)</label></formula><p>where f d and˜eand˜and˜e d denote the sets of topical words and their target-side topical item assignments in docu- ment d, c d and˜eand˜and˜e d are the sets of contextual word- s and their target-side topical item assignments in document d.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Parameter Estimation via Gibbs Sampling</head><p>The joint distribution in Eq. <ref type="formula" target="#formula_3">(1)</ref> is intractable to compute because of coupled hyperparameters and hidden variables. Following Han et al, (2012), we adapt the well-known Gibbs sampling algorith- m ( <ref type="bibr" target="#b11">Griffiths and Steyvers, 2004</ref>) to our model. We compute the joint posterior distribution of hidden variables, denoted by P (z, ˜ e, ˜ e |D), and then use this distribution to 1) estimate θ, φ, ψ and ξ, and 2) pre- dict translations and topics of all documents in D.</p><p>Specifically, we derive the joint posterior distribu- tion from Eq. (1) as: P (z, ˜ e, ˜ e |D) ∝ P (z)P (˜ e|z)P (f|˜ef|˜e)P (˜ e |˜e|˜e)P (c|˜ec|˜e ) <ref type="formula">(2)</ref> Based on the equation above, we construct a Markov chain that converges to P (z, ˜ e, ˜ e |D), where each s- tate is an assignment of a hidden variable (includ- ing topic assignment to a topical word, target-side topical item assignment to a source topical or con- textual word.). Then, we sequentially sample each assignment according to the following three condi- tional assignment distributions:</p><p>1. P (z i = z|z −i , ˜ e, ˜ e , D): topic assignment dis- tribution of a topical word given z −i that denotes all topic assignments but z i , ˜ e and˜eand˜and˜e that are target-side topical item assignments. It is updated as follows:</p><formula xml:id="formula_4">P (z i = z|z −i , ˜ e, ˜ e , D) ∝ C DZ (−i)dz + α C DZ (−i)d * +N z α × C Z ˜ E (−i)z˜ez˜e + β C Z ˜ E (−i)z * +N˜e+N˜ +N˜e β (3)</formula><p>where the topic assignment to a topical word is de- termined by the probability that this topic appears in document d (the 1st term) and the probability that the selected item˜eitem˜ item˜e occurs in this topic (the 2nd ter- m).</p><p>2. P (˜ e i = ˜ e|z, ˜ e −i , ˜ e , D): target-side topical item assignment distribution of a source topical word giv- en the current topic assignments z, the current item assignments of all other topical words˜ewords˜words˜e −i , and the current item assignments of contextual words˜ewords˜words˜e . It is updated as follows:</p><formula xml:id="formula_5">P (˜ e i = ˜ e|z, ˜ e −i , ˜ e , D) ∝ C Z ˜ E (−i)z˜ez˜e + β C Z ˜ E (−i)z * + N ˜ e β × C ˜ EF (−i)˜ ef + γ C ˜ EF (−i)˜ e * + N f γ × ( C W ˜ E (−i)w˜ew˜e + 1 C W ˜ E (−i)w˜ew˜e ) C W ˜ E w˜ew˜e (4)</formula><p>where the target-side topical item assignment to a topical word is determined by the probability that this item is from the topic z (the 1st term), the prob- ability that this item is translated into the topical word f (the 2nd term) and the probability of con- textual words within a w s word window centered at the topical word f , which influence the selection of the target-side topical item˜eitem˜ item˜e (the 3rd term). It is very important to note that we use a parallel corpus to train the model. Therefore we directly identify target-side topical items for source topical words via word alignments rather than sampling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">P (˜ e</head><p>i = ˜ e|z, ˜ e, ˜ e −i , D): target-side topical item assignment distribution for a contextual word given the current topic assignments z, the current item as- signments of topical words˜ewords˜words˜e, and the current item assignments of all other contextual words˜ewords˜words˜e −i . It is updated as follows:</p><formula xml:id="formula_6">P (˜ e i = ˜ e|z, ˜ e, ˜ e −i , D) ∝ C W ˜ E w˜ew˜e C W ˜ E w * × C ˜ EC (−i)˜ ec + δ C ˜ EC (−i)˜ e * + N c δ (5)</formula><p>where the target-side topical item assignment used to generate a contextual word is determined by the probability of this item being assigned to generate contextual words within a surface window of size w s (the 1st term) and the probability that contextu- al words occur in the context of this item (the 2nd term).</p><p>In all above formulas, C DZ dz is the number of times that topic z has been assigned for all topical words </p><formula xml:id="formula_7">in document d, C DZ d * = z C DZ</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Inference on Unseen Documents</head><p>For a new document, we first predict its topics and target-side topical items using the incremental Gibb- s sampling algorithm described in <ref type="bibr" target="#b18">(Kataria et al., 2011)</ref>. In this algorithm, we iteratively update top- ic assignments and translation assignments of an unseen document following the same process de- scribed in Section 3.2, but with estimated model pa- rameters.</p><p>Once we obtain these assignments, we estimate lexical translation probabilities based on the sam- pled counts of target-side topical items. Formal- ly, for the position i in the document correspond- ing to the content word f , we collect the sampled count that translatioñ e generates f , denoted by C sam (˜ e, f ). This count can be normalized to form a new translation probability in the following way:</p><formula xml:id="formula_8">p(˜ e|f ) = C sam (˜ e, f ) + k C sam + k · N ˜ e,f<label>(6)</label></formula><p>where C sam is the total number of samples during inference and N ˜ e,f is the number of candidate trans- lations of f . Here we apply add-k smoothing to re- fine this translation probability, where k is a tunable global smoothing constant. Under the framework of log-linear model <ref type="bibr" target="#b23">(Och and Ney, 2002</ref>), we use this translation probability as a new feature to improve lexical selection in SMT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In order to examine the effectiveness of our mod- el, we carried out several groups of experiments on Chinese-to-English translation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Setup</head><p>Our bilingual training corpus is from the FBIS cor- pus and the Hansards part of LDC2004T07 cor- pus (1M parallel sentences, 54.6K documents, with 25.2M Chinese words and 29M English words). We first used ZPar toolkit 2 and Stanford toolkit 3 to preprocess (i.e., word segmenting, PoS tagging) the Chinese and English parts of training corpus, and then word-aligned them using GIZA++ (Och and Ney, 2003) with the option "grow-diag-final-and". We chose the NIST evaluation set of MT05 as the development set, and the sets of MT06/MT08 as test sets. On average, these three sets contain 17.2, 13.9 and 14.1 content words per sentence, respectively. We trained a 5-gram language model on the Xinhua portion of Gigaword corpus using the SRILM Toolk- it <ref type="bibr" target="#b30">(Stolcke, 2002</ref>).</p><p>Our baseline system is a state-of-the-art SMT sys- tem, which adapts bracketing transduction gram- mars (Wu, 1997) to phrasal translation and equip- s itself with a maximum entropy based reordering model (MEBTG) ( <ref type="bibr" target="#b37">Xiong et al., 2006</ref>). We used the toolkit 4 developed by <ref type="bibr">Zhang (2004)</ref> to train the re- ordering model with the following parameters: it- eration number iter=200 and Gaussian prior g=1.0. During decoding, we set the ttable-limit as 20, the stack-size as 100. The translation quality is eval- uated by case-insensitive BLEU-4 ( <ref type="bibr">Papineni et al., 2002</ref>) metric. Finally, we conducted paired boot- strap sampling <ref type="bibr" target="#b20">(Koehn, 2004</ref>) to test the significance in BLEU score differences.  <ref type="table">(± 6w)</ref> 33.35 CATM (± 8w) 33.43 CATM (± 10w) 33.42 CATM (± 12w) 33.49 CATM (± 14w) 33.30 <ref type="table">Table 2</ref>: Experiment results on the development set using different window sizes w s .</p><p>To train CATM, we set the topic number N z as 25. <ref type="bibr">5</ref> For hyperparameters α and β, we empirically set α=50/N z and β=0.1, as implemented in <ref type="bibr" target="#b11">(Griffiths and Steyvers, 2004)</ref>. Following <ref type="bibr" target="#b12">Han et al. (2012)</ref>, we set γ and δ as 1.0/N f and 2000/N c , re- spectively. During the training process, we ran 400 iterations of the Gibbs sampling algorithm. For doc- uments to be translated, we first ran 300 rounds in a burn-in step to let the probability distributions con- verge, and then ran 1500 rounds where we collected independent samples every 5 rounds. The longest training time of CATM is less than four days on our server using 4GB RAM and one core of 3.2GHz CPU. As for the smoothing constant k in Eq. <ref type="formula" target="#formula_8">(6)</ref>, we set its values to 0.5 according to the performance on the development set in additional experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Impact of Window Size w s</head><p>Our first group of experiments were conducted on the development set to investigate the impact of the window size w s . We gradually varied window size from 6 to 14 with an increment of 2.</p><p>Experiment results are shown in <ref type="table">Table 2</ref>. We achieve the best performance when w s =12. This suggests that a ?12-word window context is suf- ficient for predicting target-side translations for am- biguous source-side topical words. We therefore set w s =12 for all experiments thereafter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Overall Performance</head><p>In the second group of experiments, in addition to the conventional MEBTG system, we also compared CATM with the following two models:</p><p>Word Sense Disambiguation Model (WSDM) ( <ref type="bibr" target="#b4">Chan et al., 2007)</ref>. This model improves lexical s- election in SMT by exploiting local contexts. For each content word, we construct a MaxEnt-based classifier incorporating local collocation and sur- rounding word features, which are also adopted by <ref type="bibr" target="#b4">Chan et al. (2007)</ref>. For each candidate translatioñtranslatioñ e of topical word f , we use WSDM to estimate the context-specific translation probability P (˜ e|f ), which is used as a new feature in SMT system.</p><p>Topic-specific Lexicon Translation Model (TLTM) ( <ref type="bibr">Zhao and Xing, 2007)</ref>. This model focuses on the utilization of document-level context. We adapted it to estimate a lexicon translation probability as follows:</p><formula xml:id="formula_9">p(f |˜e|˜e, d) ∝ p(˜ e|f, d) · p(f |d) = z p(˜ e|f, z) · p(f |z) · p(z|d)<label>(7)</label></formula><p>where p(˜ e|f, z) is the lexical translation probabil- ity conditioned on topic z, which can be calculat- ed according to the principle of maximal likelihood, p(f |z) is the generation probability of word f from topic z, and p(z|d) denotes the posterior topic distri- bution of document d.</p><p>Note that our CATM is proposed for lexical se- lection on content words. To show the strong effec- tiveness of our model, we also compared it against the full-fledged variants of the above-mentioned two models that are built for all source words. We refer to them as WSDM (All) and TLTM (All), respec- tively. <ref type="table">Table 3</ref> displays BLEU scores of different lexical selection models. All models outperform the base- line. Although we only use CATM to predict trans- lations for content words, CATM achieves an aver- age BLEU score of 26.77 on the two test sets, which is higher than that of the baseline by 1.18 BLEU points. This improvement is statistically significant at p&lt;0.01. Furthermore, we also find that our model performs better than WSDM and TLTM with signif- icant improvements. Finally, even if WSDM (All) and TLTM (all) are built for all source words, they are still no better than than CATM that selects de- sirable translations for content words. These exper- iment results strongly demonstrate the advantage of CATM over previous lexical selection models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Analysis</head><p>In order to investigate why CATM is able to outper- form previous models that explore only local contex-  <ref type="table">Table 3</ref>: Experiment results on the test sets. Avg = average BLEU scores. WSDM (All) and TLTM (All) are models built for all source words. ↓: significantly worse than CATM (p&lt;0.05), ↓↓: significantly worse than CATM (p&lt;0.01) .</p><p>tual words or global topics, we take a deep look in- to topics, topical items and contextual words learned by CATM and empirically analyze the effect of mod- eling correlations between local contextual words and global topics on lexical selection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Outputs of CATM</head><p>We present some examples of topics learned by CATM in <ref type="table">Table 4</ref>. We also list five target-side topi- cal items with the highest probabilities for each top- ic, and the most probable five contextual words for each target-side topical item. These examples clear- ly show that target-side topical items tightly connect global topics and local contextual words by captur- ing their correlations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Effect of Correlation Modeling</head><p>Compared to previous lexical selection models, CATM jointly models both local contextual words and global topics. Such a joint modeling also en- ables CATM to capture their inner correlations at the model level. In order to examine the effect of corre- lation modeling on lexical selection, we compared CATM with its three variants: CATM (Contex- t) that only uses local context information. We de- termined target-side topical items for content words in this variant by setting the probability distribution that a topic generates a target-side topical item to be uniform; CATM (Topic) that explores only glob- al topic information. We identified target-side topi- cal items for content words in the model by setting w s as 0, i.e., no local contextual words being used at all. CATM (Log-linear) is the combination of the above-mentioned two variants ( and ) in a log-linear manner, which does not capture corre- lations between local contextual words and global topics at the model level.  Results in <ref type="table" target="#tab_2">Table 5</ref> show that CATM performs sig- nificantlly better than both CATM (Topic) and CAT- M (Context). Even compared with CATM (Log- linear), CATM still achieves a significant improve- ment of 0.35 BLEU points (p&lt;0.05). This validates the effectiveness of capturing correlations for lexical selection at the model level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Our work is partially inspired by <ref type="bibr" target="#b12">(Han and Sun, 2012)</ref>, where an entity-topic model is presented for entity linking. We successfully adapt this work to lexical selection in SMT. The related work mainly includes the following two strands.</p><p>(1) Lexical Selection in SMT. In order to explore rich context information for lexical selection, some researchers propose trigger-based lexicon models to capture long-distance dependencies <ref type="bibr" target="#b13">(Hasan et al., 2008;</ref><ref type="bibr" target="#b22">Mauser et al., 2009)</ref>, and many more re- searchers build classifiers to select desirable trans- lations during decoding ( <ref type="bibr" target="#b4">Chan et al., 2007;</ref><ref type="bibr" target="#b3">Carpuat and Wu, 2007;</ref>.  </p><formula xml:id="formula_10">economy country uÐ¥(developing) uˆ(developed) š³(Africa) uÐ(development) ¥(China) development OE±Y(sustainable) ²L(economy) r?(promote) ¬(society) ¯(situation) international ¬(society) |"(organization) ÜŠ(coorporation) I[(country) éÜI(United Nations) economic ¬(society) uÐ(development) O•(growth) I[(country) ¥z(globalization) trade uÐ(development) IS(international) -.(world) Ý](investment) :(point)</formula><p>cross-strait relation <ref type="table">Table 4</ref>: Examples of topics, topical items and contextual words learned by CATM with N z =25 and W s =12. Chinese words that do not have direct English translations are denoted with "*". Here "q" and "|" are Chinese quantifiers for missile and war, respectively; "ü" and "W" together means cross-starit.</p><formula xml:id="formula_11">Taiwan ¥I(China) OEº(mainland) Û(authority) {I(USA) Óoe(compatriot) ChinàChinà(say) {I(USA) (Taiwan) K(principle) ü(*) relation uÐ(development) W(*) ¥(China) ü(*) I(country) cross-strait ü(*) 'X(relation) (Taiwan) W(*) 6(exchange) issue )û(settlement) ?Ø(discuss) ¯K(issue) - ‡(important) (Taiwan)</formula><p>the document-level translation consistency. <ref type="bibr" target="#b33">Ture et al. (2012)</ref> soften this consistency constraint by in- tegrating three counting features into decoder. Also relevant is the work of <ref type="bibr" target="#b38">Xiong et al.(2013)</ref>, who use three different models to capture lexical cohesion for document-level SMT.</p><p>(2) SMT with Topic Models. In this strand, <ref type="bibr">Xing (2006, 2007)</ref> first present a bilingual top- ical admixture formalism for word alignment in SMT. <ref type="bibr" target="#b32">Tam et al. (2007)</ref> and <ref type="bibr" target="#b28">Ruiz et al. (2012)</ref> apply topic model into language model adaptation. <ref type="bibr" target="#b31">Su et al. (2012)</ref> conduct translation model adaptation with monolingual topic information. <ref type="bibr" target="#b10">Gong et al. (2010)</ref> and <ref type="bibr" target="#b36">Xiao et al. (2012)</ref> introduce topic-based similar- ity models to improve SMT system. <ref type="bibr" target="#b0">Axelrod et al. (2012)</ref> build topic-specific translation models from the TED corpus and select topic-relevant data from the UN corpus to improve coverage. <ref type="bibr" target="#b8">Eidelman et al. (2012)</ref> incorporate topic-specific lexical weights in- to translation model. <ref type="bibr" target="#b17">Hewavitharana et al. (2013)</ref> propose an incremental topic based translation mod- el adaptation approach that satisfies the causality constraint imposed by spoken conversations.  present a new bilingual variant of LDA to compute topic-adapted, probabilistic phrase trans- lation features. They also use a topic model to learn latent distributional representations of different con- text levels of a phrase pair ( <ref type="bibr">Hasler et al., 2014b</ref>).</p><p>In the studies mentioned above, those by <ref type="bibr">Zhao and Xing (2006)</ref>, <ref type="bibr">Zhao and Xing (2007)</ref>, <ref type="bibr">Hasler et al. (2014a), and</ref><ref type="bibr">Hasler et al. (2014b)</ref> are most relat- ed to our work. However, they all perform dynam- ic translation model adaptation with topic models. Significantly different from them, we propose a new topic model that exploits both local contextual word- s and global topics for lexical selection. To the best of our knowledge, this is first attempt to capture cor- relations between local words and global topics for better lexical selection at the model level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion and Future Work</head><p>This paper has presented a novel context-aware topic model for lexical selection in SMT. Jointly modeling local contexts, global topics and their correlations in a unified framework, our model provides an effec- tive way to capture context information at differen- t levels for better lexical selection in SMT. Experi- ment results not only demonstrate the effectiveness of the proposed topic model, but also show that lex- ical selection benefits from correlation modeling.</p><p>In the future, we want to extend our model from the word level to the phrase level. We also plan to 236 improve our model with monolingual corpora.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: A Chinese-English translation example to illustrate the effect of local contexts and global topics as well as their correlations on lexical selection. Each black line indicates a set of translation candidates for a Chinese content word (within a dotted box). Green lines point to translations that are favored by local contexts while blue lines show bidirectional associations between global topics and their consistent target-side translations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>2 .</head><label>2</label><figDesc>For each position i that corresponds to a topical word f i in the document: (a) Sample a topic z i ∼M ult(θ d ). (b) Conditioned on the topic z i , sample a target-side topical item˜eitem˜ item˜e i ∼M ult(φ z i ). (c) Conditioned on the target-side topi- cal item˜eitem˜ item˜e i , sample the topical word f i ∼M ult(ψ ˜ e i ). 3. For each position j that corresponds to a contex- tual word c j in the document: (a) Collect all target-side topical items˜eitems˜items˜e s that are translations of neighboring topical words within a window centered at c j (window size w s ). (b) Randomly sample an item from˜efrom˜from˜e s , ˜ e j ∼U nif (˜ e s ). (c) Conditioned on the sampled target-side topical item˜eitem˜ item˜e j , sample the contextual word c j ∼M ult(ξ ˜ e j ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Graphical representation of our model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>dz is the topic number in document d, and C Z ˜ E z˜ez˜e , C ˜ EF˜ef EF˜ EF˜ef , C W ˜ E w˜ew˜e , C W ˜ E w˜ew˜e and C ˜ EC˜ec EC˜ EC˜ec have similar explanations. Based on the above marginal distributions, we iteratively update all as- signments of corpus D until the constructed Markov chain converges. Model parameters are estimated using these final assignments.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Along this line, Shen et al. (2009) introduce four new linguistic and contextual features for translation selection in SMT. Recently, we have witnessed an increasing efforts in exploiting document-level con- text information to improve lexical selection. Xiao et al. (2011) impose a hard constraint to guarantee</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Topic Target-side Topical Items Source-side Contextual Words refugee UNHCR J¬(refugee) •¯?(office) ;(commissioner) ¯Ö(affair) p?(high-level) republic é †(union) ¬Ì(democracy) ?(government) žd=(Islam) ¥š(Central Africa) refugee J¬(refugee) ˆ£(return) 6l"¤(displaced) eˆ(repatriate) o(protect) Kosovo r÷Fae(Metohija) ¸S(territory) ˆÅ(crisis) Û³(situation) l'ae(Serbia) federal ÚI(republic) Hd.Å(Yugoslavia) ‰¢»(Kosovo) ?(government) Û(authority) military military *(observer) 1Ä(action) {I(USA) &lt;(personnel) Üè(army) missile ""(defense) XÚ(system) {I(USA) u(launch) q(*) United States ¥I(China) F(Japan) (Taiwan) ¯(military) NMD(National Missile Defense) system éÜI(United Nations) ïá(build) I(country) I[(country) &amp;E(information) war Ô(war) |( * ) -.(world) uÄ(wage) °(gulf)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Experiment results on the test sets. CATM (Log-
linear) is the combination of CATM (Context) and CATM 
(Topic) in a log-linear manner. 

</table></figure>

			<note place="foot" n="1"> In the following description, Dir(.), M ult(.) and U nif (.) denote Dirichlet, Multinomial and Uniform distributions, re</note>

			<note place="foot" n="2"> http://people.sutd.edu.sg/∼yue zhang/doc/index.html 3 http://nlp.stanford.edu/software 4 http://homepages.inf.ed.ac.uk/lzhang10/maxenttoolkit.html</note>

			<note place="foot" n="5"> We try different topic numbers from 25 to 100 with an increment of 25 each time. We find that Nz=25 produces a slightly better performance than other values on the development set.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors were supported by National Natural Sci-ence Foundation of China <ref type="table">(Grant Nos 61303082</ref> </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">New methods and evaluation experiments on translating TED talks in the IWSLT benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amittai</forename><surname>Axelrod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Acero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mei-Yuh</forename><surname>Hwang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICASSP 2012</title>
		<meeting>of ICASSP 2012</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="4945" to="4648" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A Semantic Feature for Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafael</forename><forename type="middle">E</forename><surname>Banchs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><forename type="middle">R</forename><surname>Costa-Jussà</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SSSST-5 2011</title>
		<meeting>of SSSST-5 2011</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="126" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<title level="m">Latent Dirichlet Allocation. Journal of Machine Learning</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="993" to="1022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Improving Statistical Machine Translation Using Word Sense Disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marine</forename><surname>Carpuat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekai</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="61" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Word Sense Disambiguation Improves Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee</forename><surname>Seng Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee</forename><forename type="middle">Tou</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="33" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Hierarchical Phrase-Based Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="page" from="201" to="228" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Better Hypothesis Testing for Statistical Machine Translation: Controlling for Optimizer Instability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">H</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="176" to="181" />
		</imprint>
	</monogr>
	<note>short papers</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Translation Quality Using Ngram Cooccurrence Statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Doddington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of HLT</title>
		<meeting>of HLT</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="138" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Topic Models for Dynamic Translation Model Adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Eidelman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL 2012, Short Papers</title>
		<meeting>of ACL 2012, Short Papers</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="115" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Scalable Inference and Training of ContextRich Syntactic Translation Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Graehl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Deneefe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ignacio</forename><surname>Thayer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="961" to="968" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Improve SMT with Source-side Topic-Document Distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengxian</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SUMMIT</title>
		<meeting>of SUMMIT</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Finding Scientific Topics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Steyvers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the National Academy of Sciences</title>
		<meeting>of the National Academy of Sciences</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">An Entity-Topic Model for Entity Linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianpei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP 2012</title>
		<meeting>of EMNLP 2012</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="105" to="115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Triplet Lexicon Models for Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saša</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juri</forename><surname>Ganitkevitch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesús</forename><surname>Andrés-Ferrer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="372" to="381" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Dynamic Topic Adaptation for Phrase-based MT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eva</forename><surname>Hasler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EACL</title>
		<meeting>of EACL</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="328" to="337" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Dynamic Topic Adaptation for SMT using Distributional Profiles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eva</forename><surname>Hasler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of WMT 2014</title>
		<meeting>of WMT 2014</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="445" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Improving Statistical Machine Translation using Lexicalized Rule Selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongjun</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shouxun</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of COLING</title>
		<meeting>of COLING</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="321" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Incremental Topic-based TM Adaptation for Conversational SLT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjika</forename><surname>Hewavitharana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dennis</forename><surname>Mehay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sankaranarayanan</forename><surname>Ananthakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prem</forename><surname>Natarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL 2013, Short Papers</title>
		<meeting>of ACL 2013, Short Papers</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="697" to="701" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Entity Disambiguation with Hierarchical Topic Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Saurabh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kataria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajeev</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rastogi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of KDD</title>
		<meeting>of KDD</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1037" to="1045" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Statistical Phrase-based Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz</forename><forename type="middle">Josef</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL-HLT 2003</title>
		<meeting>of NAACL-HLT 2003</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="127" to="133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Statistical Significance Tests for Machine Translation Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="388" to="395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Maximum Entropy based Rule Selection Model for Syntax-based Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongjun</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shouxun</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="89" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Extending Statistical Machine Translation with Discriminative and Trigger-based Lexicon Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arne</forename><surname>Mauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saša</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP 2009</title>
		<meeting>of EMNLP 2009</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="210" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Discriminative Training and Maximum Entropy Models for Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL 2002</title>
		<meeting>of ACL 2002</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="295" to="302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A Systematic Comparison of Various Statistical Alignment Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="issue">29</biblScope>
			<biblScope unit="page" from="19" to="51" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Minimum Error Rate Training in Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz Josef</forename><surname>Och</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL 2003</title>
		<meeting>of ACL 2003</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="160" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The Alignment Template Approach to Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="issue">30</biblScope>
			<biblScope unit="page" from="417" to="449" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">BLEU: A Method for Automatic Evaluation of Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL 2002</title>
		<meeting>of ACL 2002</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Topic Adaptation for Lecture Translation through Bilingual Latent Semantic Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Sixth Workshop on Statistical Machine Translation</title>
		<meeting>of the Sixth Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="294" to="302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Effective Use of Linguistic and Contextual Information for Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Libin</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinxi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyros</forename><surname>Matsoukas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Weischedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP 2009</title>
		<meeting>of EMNLP 2009</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="72" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Srilm-An Extensible Language Modeling Toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Stolcke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICSLP 2002</title>
		<meeting>of ICSLP 2002</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="901" to="904" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Translation Model Adaptation for Statistical Machine Translation with Monolingual Topic Information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinsong</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yidong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huailin</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL 2012</title>
		<meeting>of ACL 2012</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="459" to="468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Bilingual LSA-based adaptation for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yik-Cheung</forename><surname>Tam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">R</forename><surname>Lane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tanja</forename><surname>Schultz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Translation</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="187" to="207" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Encouraging Consistent Translation Choices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ferhan Ture</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Douglasw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Oard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Resnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL-HLT 2012</title>
		<meeting>of NAACL-HLT 2012</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="417" to="426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Stochastic inversion transduction grammars and bilingual parsing of parallel corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekai</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="377" to="403" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Document-level Consistency Verification in Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingbo</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shujie</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of MT SUMMIT 2011</title>
		<meeting>of MT SUMMIT 2011</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="131" to="138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A Topic Similarity Model for Hierarchical Phrase-based Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyan</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyi</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shouxun</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL 2012</title>
		<meeting>of ACL 2012</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="750" to="758" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Maximum Entropy Based Phrase Reordering Model for Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyi</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shouxun</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="521" to="528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Modeling Lexical Cohesion for Document-Level Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyi</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Ben</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yajuan</forename><surname>Lü</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IJCAI 2013</title>
		<meeting>of IJCAI 2013</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2183" to="2189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A Sense-Based Translation Model for Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyi</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1459" to="1469" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">BiTAM: Bilingual Topic AdMixture Models for Word Alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL/COLING 2006</title>
		<meeting>of ACL/COLING 2006</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="969" to="976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">HM-BiTAM: Bilingual Topic Exploration, Word Alignment, and Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NIPS 2007</title>
		<meeting>of NIPS 2007</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
