<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:53+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Using Global Constraints and Reranking to Improve Cognates Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bloodgood</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Strauss</surname></persName>
						</author>
						<title level="a" type="main">Using Global Constraints and Reranking to Improve Cognates Detection</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</title>
						<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1983" to="1992"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-1181</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Global constraints and reranking have not been used in cognates detection research to date. We propose methods for using global constraints by performing rescoring of the score matrices produced by state of the art cognates detection systems. Using global constraints to perform rescoring is complementary to state of the art methods for performing cognates detection and results in significant performance improvements beyond current state of the art performance on publicly available datasets with different language pairs and various conditions such as different levels of base-line state of the art performance and different data size conditions, including with more realistic large data size conditions than have been evaluated with in the past.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This paper presents an effective method for us- ing global constraints to improve performance for cognates detection. Cognates detection is the task of identifying words across languages that have a common origin. Automatic cognates detection is important to linguists because cognates are needed to determine how languages evolved. Cognates are used for protolanguage reconstruction ( <ref type="bibr" target="#b9">Hall and Klein, 2011;</ref><ref type="bibr" target="#b3">Bouchard-Côté et al., 2013)</ref>. Cognates are important for cross-language dictio- nary look-up and can also improve the quality of machine translation, word alignment, and bilin- gual lexicon induction ( <ref type="bibr" target="#b22">Simard et al., 1993;</ref><ref type="bibr" target="#b13">Kondrak et al., 2003)</ref>.</p><p>A word is traditionally only considered cognate with another if both words proceed from the same ancestor. Nonetheless, in line with the conven- tions of previous research in computational lin- guistics, we set a broader definition. We use the word 'cognate' to denote, as in <ref type="bibr" target="#b12">(Kondrak, 2001</ref>): "...words in different languages that are similar in form and meaning, without making a distinction between borrowed and genetically related words; for example, English 'sprint' and the Japanese bor- rowing 'supurinto' are considered cognate, even though these two languages are unrelated." These broader criteria are motivated by the ways scien- tists develop and use cognate identification algo- rithms in natural language processing (NLP) sys- tems. For cross-lingual applications, the advan- tage of such technology is the ability to identify words for which similarity in meaning can be ac- curately inferred from similarity in form; it does not matter if the similarity in form is from strict genetic relationship or later borrowing <ref type="bibr" target="#b15">(Mericli and Bloodgood, 2012)</ref>.</p><p>Cognates detection has received a lot of atten- tion in the literature. The research of the use of statistical learning methods to build systems that can automatically perform cognates detection has yielded many interesting and creative approaches for gaining traction on this challenging task. Cur- rently, the highest-performing state of the art sys- tems detect cognates based on the combination of multiple sources of information. Some of the most indicative sources of information discovered to date are word context information, phonetic in- formation, word frequency information, temporal information in the form of word frequency dis- tributions across parallel time periods, and word burstiness information. See section 3 for fuller ex- planations of each of these sources of information that state of the art systems currently use. Scores for all pairs of words from language L1 x language L2 are generated by generating component scores based on these sources of information and then combining them in an appropriate manner. Simple methods of combination are giving equal weight-ing for each score, while state of the art perfor- mance is obtained by learning an optimal set of weights from a small seed set of known cognates. Once the full matrix of scores is generated, the word pairs with the highest scores are predicted as being cognates.</p><p>The methods we propose in the current paper consume as input the final score matrix that state of the art methods create. We test if our meth- ods can improve performance by generating new rescored matrices by rescoring all of the pairs of words by taking into account global constraints that apply to cognates detection. Thus, our meth- ods are complementary to previous methods for creating cognates detection systems. Using global constraints and performing rescoring to improve cognates detection has not been explored yet. We find that rescoring based on global constraints im- proves performance significantly beyond current state of the art levels.</p><p>The cognates detection task is an interesting task to apply our methods to for a few reasons:</p><p>• It's a challenging unsolved task where ongo- ing research is frequently reported in the lit- erature trying to improve performance;</p><p>• There is significant room for improvement in performance;</p><p>• It has a global structure in its output clas- sifications since if a word lemma 1 w i from language L1 is cognate with a word lemma w j from language L2, then w i is not cognate with any other word lemma from L2 different from w j and w j is not cognate with any other word lemma w k from L1.</p><p>• There are multiple standard datasets freely and publicly available that have been worked on with which to compare results.</p><p>• Different datasets and language pairs yield initial score matrices with very different qual- ities. Some of the score matrices built using the existing state of the art best approaches yield performance that is quite low (11-point interpolated average precision of only ap- proximately 16%) while some of these score matrices for other language pairs and data sets have state of the art score matrices that are already able to achieve 11-point interpo- lated average precision of 57%.</p><p>Although we are not aware of work using global constraints to perform rescoring to improve cog- nates detection, there are related methodologies for reranking in different settings. Methodologi- cally related work includes past work in structured prediction and reranking <ref type="bibr" target="#b5">(Collins, 2002;</ref><ref type="bibr" target="#b8">Collins and Roark, 2004;</ref><ref type="bibr" target="#b6">Collins and Koo, 2005;</ref><ref type="bibr">Taskar et al., 2005a,b)</ref>. Note that in these past works, there are many instances with structured outputs that can be used as training data to learn a struc- tured prediction model. For example, a semi- nal application in the past was using online train- ing with structured perceptrons to learn improved systems for performing various syntactic analyses and tagging of sentences such as POS tagging and base noun phrase chunking <ref type="bibr" target="#b5">(Collins, 2002</ref>). Note that in those settings the unit at which there are structural constraints is a sentence. Also note that there are many sentences available so that online training methods such as discriminative training of structured perceptrons can be used to learn struc- tured predictors effectively in those settings. In contrast, for the cognates setting the unit at which there are structural constraints is the entire set of cognates for a language pair and there is only one such unit in existence (for a given language pair). We call this a single overarching global structure to make the distinction clear. The method we present in this paper deals with a single overar- ching global structure on the predictions of all in- stances in the entire problem space for a task. For this type of setting, there is only a single global structure in existence, contrasted with the situa- tion of there being many sentences each impos- ing a global structure on the tagging decisions for that individual sentence. Hence, previous struc- tured prediction methods that require numerous instances each having a structured output on which to train parameters via methods such as perceptron training are inapplicable to the cognates setting. In this paper we present methods for rescoring effec- tively in settings with a single overarching global structure and show their applicability to improv- ing the performance of cognates detection. Still, we note that philosophically our method builds on previous structured prediction methods since in both cases there is a similar intuition in that we're using higher-level structural properties to inform and accordingly alter our system's predictions of values for subitems within a structure.</p><p>In section 2 we present our methods for per- forming rescoring of matrices based on global constraints such as those that apply for cognates detection. The key intuition behind our approach is that the scoring of word pairs for cognateness ought not be made independently as is currently done, but rather that global constraints ought to be taken into account to inform and potentially alter system scores for word pairs based on the scores of other word pairs. In section 3 we provide results of experiments testing the proposed methods on the cognates detection task on multiple datasets with multiple language pairs under multiple conditions. We show that the new methods complement and effectively improve performance over state of the art performance achieved by combining the ma- jor research breakthroughs that have taken place in cognates detection research to date. Complete precision-recall curves are provided that show the full range of performance improvements over the current state of the art that are achieved. Summary measurements of performance improvements, de- pending on the language pair and dataset, range from 6.73 absolute MaxF1 percentage points to 16.75 absolute MaxF1 percentage points and from 5.58 absolute 11-point interpolated average preci- sion percentage points to 17.19 absolute 11-point interpolated average precision percentage points. Section 4 discusses the results and possible exten- sions of the method. Section 5 wraps up with the main conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Algorithm</head><p>While our focus in this paper is on using global constraints to improve cognates detection, we be- lieve that our method is useful more generally. We therefore abstract out some of the specifics of cog- nates detection and present our algorithm more generally in this section, with the hope that it will be able to be used in the future for other appli- cations in addition to cognates detection. None of our abstraction harms understanding of our method's applicability to cognates detection and the fact that the method may be more widely ben- eficial does not in any way detract from the utility we show it has for improving cognates detection.</p><p>A common setting is where one has a set X = {x 1 , x 2 , ..., x n } and a set Y = {y 1 , y 2 , ..., y n } where the task is to extract (x, y) pairs such that (x, y) are in some relation R. Here are examples:</p><p>• X might be a set of states and Y might be a set of cities and the relation R might be "is the capital of";</p><p>• X might be a set of images and Y might be a set of people's names and the relation R might be "is a picture of";</p><p>• X might be a set of English words and Y might be a set of French words and the re- lation R might be "is cognate with".</p><p>A common way these problems are approached is that a model is trained that can score each pair (x, y) and those pairs with scores above a thresh- old are extracted. We propose that often the rela- tion will have a tendency, or a hard constraint, to satisfy particular properties and that this ought to be utilized to improve the quality of the extracted pairs.</p><p>The approach we put forward is to re-score each (x, y) pair by utilizing scores generated for other pairs and our knowledge of properties of the rela- tion being extracted. In this paper, we present and evaluate methods for improving the scores of each (x, y) pair for the case when the relation is known to be one-to-one and discuss extensions to other situations.</p><p>The current approach is to generate a matrix of scores for each candidate pair as follows:</p><formula xml:id="formula_0">Score X,Y =    s x 1 ,y 1 · · · s x 1 ,yn . . . . . . . . . s xn,y 1 · · · s xn,yn    . (1)</formula><p>Then those pairs with scores above a threshold are predicted as being in the relation. We now de- scribe methods for sharpening the scores in the matrix by utilizing the fact that there is an over- arching global structure on the predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Reverse Rank</head><p>We know that if</p><formula xml:id="formula_1">(x i , y j ) ∈ R, then (x k , y j ) / ∈ R for k = i when R is 1-to-1. We define reverse rank(x i , y j ) = |{x k ∈ X|s x k ,y j ≥ s x i ,y j }|.</formula><p>Intuitively, a high reverse rank means that there are lots of other elements of X that score bet- ter to y j than x i does; this could be evidence that (x i , y j ) is not in R and ought to have a lower score. Alternatively, if there are very few or no other ele- ments of X that score better to y j than x i does this could be evidence that (x i , y j ) is in R and ought to have a higher score. In accord with this intuition, we use reverse rank as the basis for rescaling our scores as follows:</p><formula xml:id="formula_2">score RR (x i , y j ) = s x i ,y j reverse rank(x i , y j ) .<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Forward Rank</head><p>Analogous to reverse rank, another basis we can use for adjusting scores is the forward rank. We define f orward rank(</p><formula xml:id="formula_3">x i , y j ) = |{y k ∈ Y |s x i ,y k ≥ s x i ,y j }|.</formula><p>We then scale the scores anal- ogously to how we did with reverse ranks via an inverse linear function. <ref type="bibr">2</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Combining Reverse Rank and Forward Rank</head><p>For combining reverse rank and forward rank, we present results of experiments doing it two ways.</p><p>The first is a 1-step approach:</p><formula xml:id="formula_4">score RR F R 1step (x i , y j ) = s x i ,y j product ,<label>(3)</label></formula><p>where</p><formula xml:id="formula_5">product =reverse rank(x i , y j )× f orward rank(x i , y j ).<label>(4)</label></formula><p>The second combination method involves first computing the reverse rank and re-adjusting every score based on the reverse ranks. Then in a second step the new scores are used to compute forward ranks and then those scores are adjusted based on the forward ranks. We refer to this method as RR FR 2step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Maximum Assignment</head><p>If one makes the assumption that all elements in X and Y are present and have their partner element in the other set present with no extra elements and the sets are not too large, then it is interesting to compute what the 'maximal assignment' would be using the Hungarian Algorithm to optimize:</p><formula xml:id="formula_6">max Z∈X×Y (x,y)∈Z score(x, y) s.t. (x i , y j ) ∈ Z ⇒ (x k , y j ) / ∈ Z, ∀k = i (x i , y j ) ∈ Z ⇒ (x i , y k ) / ∈ Z, ∀k = j.<label>(5)</label></formula><p>We do this on datasets where the assumptions hold and see how close our methods get to the Hungarian maximal assignment at similar points of the precision-recall curves. For our larger datasets where the assumptions don't hold, the Hungarian either can't complete due to limited computational resources or it functioned poorly in comparison with the performance of our reverse rank and forward rank combination methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>Our goal is to test whether using the global struc- ture algorithms we described in section 2 can sig- nificantly boost performance for cognates detec- tion. To test this hypothesis, our first step is to implement a system that uses state of the art re- search results to generate the initial score matri- ces as a current state of the art system would cur- rently do for this task. To that end, we imple- mented a baseline state of the art system that uses the information sources that previous research has found to be helpful for this task such as pho- netic information, word context information, tem- poral context information, word frequency infor- mation, and word burstiness information <ref type="bibr" target="#b12">(Kondrak, 2001;</ref><ref type="bibr" target="#b14">Mann and Yarowsky, 2001;</ref><ref type="bibr" target="#b20">Schafer and Yarowsky, 2002;</ref><ref type="bibr" target="#b11">Klementiev and Roth, 2006;</ref><ref type="bibr" target="#b10">Irvine and Callison-Burch, 2013)</ref>. Consistent with past work <ref type="bibr" target="#b10">(Irvine and Callison-Burch, 2013</ref>), we use supervised training to learn the weights for combining the various information sources. The system combines the sources of information by us- ing weights learned by an SVM (Support Vector Machine) on a small seed training set of cognates 3 to optimize performance. This baseline system obtains state of the art performance on cognates detection. Using this state of the art system as our baseline, we investigated how much we could improve performance beyond current state of the art levels by applying the rescoring algorithm we described in section 2. We performed experi- ments on three language pairs: French-English, German-English, and Spanish-English, with dif- ferent text corpora used as training and test data. The different language pairs and datasets have dif- ferent levels of performance in terms of their base- line current state of the art score matrices. In the next few subsections, we describe our experimen- tal details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Lemmatization</head><p>We used morphological analyzers to convert the words in text corpora to lemma form. For En- glish, we used the NLTK WordNetLemmatizer ( <ref type="bibr" target="#b2">Bird et al., 2009</ref>). For French, German, and Span- ish we used the TreeTagger ( <ref type="bibr" target="#b21">Schmid, 1994)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Word Context Information</head><p>We used the Google N-Gram corpus ( <ref type="bibr" target="#b16">Michel et al., 2010</ref>). For English we used the English 2012 Google 5-gram corpus, for French we used the French 2012 Google 5-gram corpus, for German we used the German 2012 Google 5-gram corpus, and for Spanish we used the Spanish 2012 Google 5-gram corpus. From these corpora we compute word context similarity scores across languages using Rapp's method <ref type="bibr" target="#b18">(Rapp, 1995</ref><ref type="bibr" target="#b19">(Rapp, , 1999</ref>). The intuition behind this method is that cognates are more likely to occur in correlating context win- dows and this statistic inferred from large amounts of data captures this correlation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Frequency Information</head><p>The intuition is that over large amounts of data cognates should have similar relative frequencies. We compute our relative frequencies by using the same corpora mentioned in the previous subsec- tion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Temporal Information</head><p>The intuition is that cognates will have simi- lar temporal distributions ( <ref type="bibr" target="#b11">Klementiev and Roth, 2006</ref>). To compute the temporal similarity we use newspaper data and convert it to simple daily word counts. For each word in the cor- pora the word counts create a time series vec- tor. The Fourier transform is computed on the time series vectors. Spearman rank correlation is computed on the transform vectors. For En- glish we used the English Gigaword Fifth Edi- tion <ref type="bibr">4</ref> . For French we used French Gigaword Third Edition 5 . For Spanish we used Span- ish Gigaword First Edition <ref type="bibr">6</ref> . The German news corpora were obtained by web crawling http: //www.tagesspiegel.de/ and extracting the news articles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Word Burstiness</head><p>The intuition is that cognates will have similar burstiness measures <ref type="bibr" target="#b4">(Church and Gale, 1995)</ref>. For word burstiness we used the same corpora as for the temporal corpora.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Phonetic Information</head><p>The intuition is that cognates will have correspon- dences in how they are pronounced. For this, we compute a measurement based on Normalized Edit Distance (NED).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Combining Information Sources</head><p>We combine the information sources by using a linear Support Vector Machine to learn weights for each of the information sources from a small seed training set of cognates. So our final score assigned to a candidate cognate pair (x, y) is:</p><formula xml:id="formula_7">score(x, y) = m∈metrics w m score m (x, y), (6)</formula><p>where metrics is the set of measurements such as phonetic similarity measurements, word bursti- ness similarity, relative frequency similarity, etc. that were explained in subsections 3.2 through 3.6; w m is the learned weight for metric m; and score m (x, y) is the score assigned to the pair (x, y) by metric m.</p><p>The scores such assigned represent a state of the art approach for filling in the matrix identified in equation 1. At this point the matrix of scores would be used to predict cognates. We now turn to evaluation of the use of the global constraint rescoring methods from section 2 for improving performance beyond the state of the art levels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.8">Using Global Constraints to Rescore</head><p>For our cognates data we used the French-English pairs from <ref type="bibr" target="#b1">(Bergsma and Kondrak, 2007)</ref> and the German-English and Spanish-English pairs from ( <ref type="bibr" target="#b0">Beinborn et al., 2013)</ref>. <ref type="figure">Fig- ure 1</ref> shows the precision-recall 7 curves for <ref type="bibr">7</ref> Precision and recall are the standard measures used for systems that perform search. Precision is the percentage of predicted cognates that are indeed cognate. Recall is the per- centage of cognates that are predicted as cognate. We vary the threshold that determines cognateness to generate all points along the Precision-Recall curve. We start with a very high threshold enabling precision of 100% and lower the threshold until recall of 100% is reached. In particular, we sort the test examples by score in descending order and then go down the list of scores in order to complete the entire precision-recall curve. Baseline denotes state of the art performance.</p><p>French-English, <ref type="figure" target="#fig_1">Figure 2</ref> shows the performance for German-English, and <ref type="figure" target="#fig_3">Figure 3</ref> shows the performance for Spanish-English. Note that state of the art performance (denoted in the figures as Baseline) has very different performance across the three datasets, but in all cases the systems from section 2 that incorporate global constraints and perform rescoring greatly exceed current state of the art performance levels. The Max Assignment is really just the single point that the Hungarian finds. We drew lines connecting it, but keep in mind those lines are just connecting the single point to the endpoints. Max Assignment Score traces the precision-recall curve back from the Max Assignment by steadily increasing the threshold so that only points in the maximum assignment set with scores above the increasing threshold are predicted as cognate.</p><p>For the non-max assignment curves, it is some- times helpful to compute a single metric summa- rizing important aspects of the full curve. For this purpose, maxF1 and 11-point interpolated average precision are often used. MaxF1 is the F1 mea- sure (i.e., harmonic mean of precision and recall) at the point on the precision-recall curve where F1 is highest. The interpolated precision p interp at a given recall level r is defined as the highest preci- sion level found for any recall level r ≥ r: p interp (r) = max r ≥r p(r ).</p><p>The 11-point interpolated average precision (11-point IAP) is then the average of the p interp at r = 0.0, 0.1, ..., 1.0.    Baseline denotes state of the art performance.</p><p>shows the results for German-English, and <ref type="table" target="#tab_4">Table 3</ref> show the results for Spanish-English. In all cases, using global structure greatly improves upon the state of the art baseline performance. In <ref type="bibr" target="#b1">(Bergsma and Kondrak, 2007)</ref>, for French-English data a re- sult of 66.5 11-point IAP is reported for a situation where word alignments from a bitext are available and a result of 77.7 11-point IAP is reported for a situation where translation pairs are available in large quantities. The setting considered in the cur- rent paper is much more challenging since it does not use bilingual dictionaries or word alignments from bitexts. The setting in the current paper is the one mentioned as future work on page 663 of <ref type="bibr" target="#b1">(Bergsma and Kondrak, 2007)</ref>: "In particular, we plan to investigate approaches that do not re-  quire the bilingual dictionaries or bitexts to gener- ate training data." Note that the evaluation thus far is a bit artifi- cial for real cognates detection because in a real setting you wouldn't only be selecting matches for relatively small subsets of words that are guaranteed to have a cognate on the other side. Such was the case for our evaluation where the French-English set had approx. 600 cognate pairs, the German-English set had approx. 1000 pairs, and the Spanish-English set had approx. 3000 pairs. In a real setting, the system would have to consider words that don't have a cognate match in the other language and not only words that were hand-selected and guaranteed to have cognates. We are not aware of others evaluating according to this much more difficult condition, but we think it is important to consider especially given the po- tential impacts it could have on the global struc- ture methods we've put forward. Therefore, we run a second set of evaluations where we take the ten thousand most common words in our corpora for each of our languages, which contain many of the cognates from the standard test sets and we add in any remaining words from the stan- dard test sets that didn't make it into the top ten thousand. We then repeat each of the experi-   ments under this much more challenging condi- tion. With approx. ten thousand squared candi- dates, i.e., approx. 100 million candidates, to con- sider for cognateness, this is a large data condi- tion. The Hungarian didn't run to completion on two of the datasets due to limited computational resources. On French-English it completed, but achieved poorer performance than any of the other methods. This makes sense as it is designed when there really is a bipartite matching to be found like in the artificial yet standard cognates evaluation that was just presented. When confronted with large amounts of words that create a much denser space and have no match at all on the other side the all or nothing assignments of the Hungarian are not ideal. The reverse rank and forward rank rescoring methods are still quite effective in im- proving performance although not by as much as they did in the small data results from above. <ref type="figure" target="#fig_4">Figure 4</ref> shows the full precision-recall curves for French-English for the large data condition, <ref type="figure" target="#fig_5">Figure 5</ref> shows the curves for German-English for the large data condition, and <ref type="figure">Figure 6</ref> shows the results for Spanish-English for the large data con- dition. <ref type="table" target="#tab_6">Tables 4 through 6</ref> show the summary metrics for the three language pairs for the large data ex- periments. We can see that the reverse rank and forward rank methods of taking into account the global structure of interactions among predictions is still helpful, providing large improvements in performance even in this challenging large data condition over strong state of the art baselines that  Figure 6: Precision-Recall Curves for Spanish-English (large data). Note that Baseline denotes state of the art performance. make cognate predictions independently of each other and don't do any rescoring based on global constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion</head><p>We believe that this work opens up new avenues for further exploration. A few of these include the following:</p><p>• investigating the utility of applying and ex- tending the method to other applications such as Information Extraction applications, many of which have similar global constraints as cognates detection;</p><p>• investigating how to handle other forms of global structure including tendencies that are    not necessarily hard constraints;</p><p>• developing more theory to more precisely understand some of the nuances of using global structure when it's applicable and making connections with other areas of ma- chine learning such as semi-supervised learn- ing, active learning, etc.; and</p><p>• investigating how to have a machine learn that global structure exists and learn what form of global structure exists.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>Cognates detection is an interesting and challeng- ing task. Previous work has yielded state of the art approaches that create a matrix of scores for all word pairs based on optimized weighted combina- tions of component scores computed on the basis of various helpful sources of information such as phonetic information, word context information, temporal context information, word frequency in- formation, and word burstiness information. How- ever, when assigning a score to a word pair, the current state of the art methods do not take into ac- count scores assigned to other word pairs. We pro- posed a method for rescoring the matrix that cur-rent state of the art methods produce by taking into account the scores assigned to other word pairs. The methods presented in this paper are com- plementary to existing state of the art methods, easy to implement, computationally efficient, and practically effective in improving performance by large amounts. Experimental results reveal that the new methods significantly improve state of the art performance in multiple cognates detec- tion experiments conducted on standard freely and publicly available datasets with different language pairs and various conditions such as different lev- els of baseline performance and different data size conditions, including with more realistic large data size conditions than have been evaluated with in the past.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Figure 1: Precision-Recall Curves for French-English. Baseline denotes state of the art performance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Precision-Recall Curves for German-English. Baseline denotes state of the art performance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Precision-Recall Curves for Spanish-English. Baseline denotes state of the art performance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Precision-Recall Curves for French-English (large data). Note that Baseline denotes state of the art performance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Precision-Recall Curves for German-English (large data). Note that Baseline denotes state of the art performance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 shows</head><label>1</label><figDesc></figDesc><table>these per-
formance measures for French-English, Table 2 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>German-English Performance. BASE-
LINE indicates current state of the art performance. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Spanish-English Performance. BASE-
LINE indicates current state of the art performance. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>French-English Performance (large data). 
BASELINE indicates state of the art performance. 

METHOD 
MAX F1 11-POINT IAP 
BASELINE 
21.25 
16.17 
RR 
24.78 
19.13 
RR FR 1STEP 
30.72 
24.97 
RR FR 2STEP 
30.34 
24.86 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>German-English Performance (large 
data). BASELINE indicates state of the art perfor-
mance. 

METHOD 
MAX F1 11-POINT IAP 
BASELINE 
54.75 
54.55 
RR 
62.52 
61.42 
RR FR 1STEP 
66.45 
65.89 
RR FR 2STEP 
66.38 
65.5 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Spanish-English Performance (large 
data). BASELINE indicates state of the art perfor-
mance. 

</table></figure>

			<note place="foot" n="1"> A lemma is a base form of a word. For example, in English the words &apos;baked&apos; and &apos;baking&apos; would both map to the lemma &apos;bake&apos;. Lemmatizing software exists for many languages and lemmatization is a standard preprocessing task conducted before cognates detection.</note>

			<note place="foot" n="2"> For both reverse rank and forward rank we also experimented with exponential decay and step functions, but found that simple division by the ranks worked as well or better than any of those more complicated methods.</note>

			<note place="foot" n="3"> The small seed set was randomly selected and less than 20% in all cases. It was not used for testing. Note that using this data to optimize performance of the baseline system makes our baseline even stronger and makes it even harder for our new rescoring method to achieve larger improvements.</note>

			<note place="foot" n="4"> Linguistic Data Consortium Catalog No. LDC2011T07 5 Linguistic Data Consortium Catalog No. LDC2011T10 6 Linguistic Data Consortium Catalog No. LDC2006T12</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Cognate production using character-based machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lisa</forename><surname>Beinborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torsten</forename><surname>Zesch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/I13-1112" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth International Joint Conference on Natural Language Processing. Asian Federation of Natural Language Processing</title>
		<meeting>the Sixth International Joint Conference on Natural Language Processing. Asian Federation of Natural Language Processing<address><addrLine>Nagoya, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="883" to="891" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Alignment-based discriminative string similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shane</forename><surname>Bergsma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Kondrak</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P07-1083" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics</title>
		<meeting>the 45th Annual Meeting of the Association of Computational Linguistics<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="656" to="663" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Natural Language Processing with Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ewan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Loper</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Reilly Media, Inc</publisher>
		</imprint>
	</monogr>
	<note>1st edition</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Automated Reconstruction of Ancient Languages using Probabilistic Models of Sound Change</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Bouchard-Côté</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<idno type="doi">10.1073/pnas.1204678110</idno>
		<ptr target="https://doi.org/10.1073/pnas.1204678110" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="page" from="4224" to="4229" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Poisson mixtures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kenneth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">A</forename><surname>Church</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="163" to="190" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<idno type="doi">10.3115/1118693.1118694</idno>
		<ptr target="https://doi.org/10.3115/1118693.1118694" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics</title>
		<meeting>the 2002 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Discriminative reranking for natural language parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Koo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="25" to="70" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<idno type="doi">10.1162/0891201053630273</idno>
		<ptr target="https://doi.org/10.1162/0891201053630273" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Incremental parsing with the perceptron algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Roark</surname></persName>
		</author>
		<idno type="doi">10.3115/1218955.1218970</idno>
		<ptr target="https://doi.org/10.3115/1218955.1218970" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL&apos;04</title>
		<meeting>the 42nd Meeting of the Association for Computational Linguistics (ACL&apos;04<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="111" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Large-scale cognate recovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/D11-1032" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Edinburgh, Scotland, UK.</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="344" to="354" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Supervised bilingual lexicon induction with multiple monolingual signals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ann</forename><surname>Irvine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Atlanta, Georgia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="518" to="523" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Weakly supervised named entity transliteration and discovery from multilingual comparable corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Klementiev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<idno type="doi">10.3115/1220175.1220278</idno>
		<ptr target="https://doi.org/10.3115/1220175.1220278" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="817" to="824" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Identifying cognates by phonetic and semantic similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Kondrak</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/N/N01/N01-1014.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the second meeting of the North American Chapter of the Association for Computational Linguistics on Language technologies. Association for Computational Linguistics</title>
		<meeting>the second meeting of the North American Chapter of the Association for Computational Linguistics on Language technologies. Association for Computational Linguistics<address><addrLine>Stroudsburg, PA, USA, NAACL &apos;01</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Cognates can improve statistical translation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Kondrak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/N/N03/N03-2016.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology: Companion Volume of the Proceedings of HLT-NAACL 2003-short Pa</title>
		<meeting>the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology: Companion Volume of the HLT-NAACL 2003-short Pa<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="46" to="48" />
		</imprint>
	</monogr>
	<note>NAACL-Short &apos;03</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Multipath translation lexicon induction via bridge languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gideon</forename><forename type="middle">S</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/N/N01/N01-1020.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the second meeting of the North American Chapter of the Association for Computational Linguistics on Language technologies. Association for Computational Linguistics</title>
		<meeting>the second meeting of the North American Chapter of the Association for Computational Linguistics on Language technologies. Association for Computational Linguistics<address><addrLine>Stroudsburg, PA, USA, NAACL &apos;01</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Annotating cognates and etymological origin in Turkic languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Benjamin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mericli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bloodgood</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1501.03191" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Language Resources and Technologies for Turkic Languages at the Eighth International Conference on Languange Resources and Evaluation (LREC&apos;12). European Language Resources Association</title>
		<meeting>the First Workshop on Language Resources and Technologies for Turkic Languages at the Eighth International Conference on Languange Resources and Evaluation (LREC&apos;12). European Language Resources Association<address><addrLine>Istanbul, Turkey</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="47" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Quantitative analysis of culture using millions of digitized books</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Baptiste</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan Kui</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aviva</forename><surname>Presser Aiden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrian</forename><surname>Veres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">K</forename><surname>Gray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<editor>Joseph P. Pickett, Dale Hoiberg, Dan Clancy, Peter Norvig, Jon Orwant, Steven Pinker, Martin A. Nowak, and Erez Lieberman Aiden</editor>
		<imprint>
			<biblScope unit="volume">331</biblScope>
			<biblScope unit="issue">6014</biblScope>
			<biblScope unit="page" from="176" to="182" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note>The Google Books Team</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title/>
		<idno type="doi">10.1126/science.1199644</idno>
		<ptr target="https://doi.org/10.1126/science.1199644" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Identifying word translations in non-parallel texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reinhard</forename><surname>Rapp</surname></persName>
		</author>
		<idno type="doi">10.3115/981658.981709</idno>
		<ptr target="https://doi.org/10.3115/981658.981709" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics</title>
		<meeting>the 33rd Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics<address><addrLine>Cambridge, Massachusetts, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="320" to="322" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Automatic identification of word translations from unrelated english and german corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reinhard</forename><surname>Rapp</surname></persName>
		</author>
		<idno type="doi">10.3115/1034678.1034756</idno>
		<ptr target="https://doi.org/10.3115/1034678.1034756" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics</title>
		<meeting>the 37th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics<address><addrLine>College Park, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="519" to="526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Inducing translation lexicons via diverse similarity measures and bridge languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Schafer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/W/W02/W02-2026.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th Conference on Natural language Learning</title>
		<meeting>the 6th Conference on Natural language Learning<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Part-of-speech tagging with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helmut</forename><surname>Schmid</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/C/C94/C94-1027.pdf" />
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="172" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Using cognates to align sentences in bilingual corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Simard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">F</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Isabelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1993 Conference of the Centre for Advanced Studies on Collaborative Research: Distributed Computing-Volume</title>
		<meeting>the 1993 Conference of the Centre for Advanced Studies on Collaborative Research: Distributed Computing-Volume<address><addrLine>CASCON &apos;93</addrLine></address></meeting>
		<imprint>
			<publisher>IBM Press</publisher>
			<date type="published" when="1993" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1071" to="1082" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning structured prediction models: A large margin approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Taskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vassil</forename><surname>Chatalbashev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daphne</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Machine learning</title>
		<meeting>the 22nd International Conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="896" to="903" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A discriminative matching approach to word alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Taskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lacoste-Julien</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klein</forename><surname>Dan</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/H/H05/H05-1010.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing<address><addrLine>Vancouver, British Columbia, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="73" to="80" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
