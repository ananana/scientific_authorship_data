<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:53+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Challenging Language-Dependent Segmentation for Arabic: An Application to Machine Translation and Part-of-Speech Tagging</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hassan</forename><surname>Sajjad</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fahim</forename><surname>Dalvi</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nadir</forename><surname>Durrani</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><surname>Abdelali</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Belinkov</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Vogel</surname></persName>
						</author>
						<title level="a" type="main">Challenging Language-Dependent Segmentation for Arabic: An Application to Machine Translation and Part-of-Speech Tagging</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</title>
						<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="601" to="607"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-2095</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Word segmentation plays a pivotal role in improving any Arabic NLP application. Therefore, a lot of research has been spent in improving its accuracy. Off-the-shelf tools, however, are: i) complicated to use and ii) domain/dialect dependent. We explore three language-independent alternatives to morphological segmentation using: i) data-driven sub-word units, ii) characters as a unit of learning, and iii) word embeddings learned using a character CNN (Convolution Neural Network). On the tasks of Machine Translation and POS tagging, we found these methods to achieve close to, and occasionally surpass state-of-the-art performance. In our analysis , we show that a neural machine translation system is sensitive to the ratio of source and target tokens, and a ratio close to 1 or greater, gives optimal performance.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Arabic word segmentation has shown to signifi- cantly improve output quality in NLP tasks such as machine translation <ref type="bibr">(Habash and Sadat, 2006;</ref><ref type="bibr">Almahairi et al., 2016)</ref>, part-of-speech tagging ( <ref type="bibr">Diab et al., 2004;</ref><ref type="bibr">Habash and Rambow, 2005)</ref>, and information retrieval (M. <ref type="bibr" target="#b7">Aljlayl and Grossman, 2002</ref>). A considerable amount of research has therefore been spent on Arabic morphologi- cal segmentation in the past two decades, rang- ing from rule-based analyzers <ref type="bibr">(Beesley, 1996)</ref> to state-of-the-art statistical segmenters ( <ref type="bibr" target="#b10">Pasha et al., 2014;</ref><ref type="bibr" target="#b0">Abdelali et al., 2016;</ref><ref type="bibr" target="#b1">Khalifa et al., 2016)</ref>. Morphological segmentation splits words into morphemes. For example, ''wktAbnA" " "</p><p>(gloss: and our book) is decomposed into its stem and affixes as: "w+ ktAb +nA" " ".</p><p>Despite the gains obtained from using morpho- logical segmentation, there are several caveats to using these tools. Firstly, they make the train- ing pipeline cumbersome, as they come with complicated pre-processing (and additional post- processing in the case of English-to-Arabic trans- lation <ref type="bibr">(El Kholy and Habash, 2012)</ref>). More impor- tantly, these tools are dialect-and domain-specific. A segmenter trained for modern standard Arabic (MSA) performs significantly worse on dialectal Arabic ( <ref type="bibr">Habash et al., 2013)</ref>, or when it is applied to a new domain.</p><p>In this work, we explore whether we can avoid the language-dependent pre/post-processing com- ponents and learn segmentation directly from the training data being used for a given task. We in- vestigate data-driven alternatives to morphologi- cal segmentation using i) unsupervised sub-word units obtained using byte-pair encoding <ref type="bibr" target="#b13">(Sennrich et al., 2016)</ref>, ii) purely character-based segmen- tation ( <ref type="bibr" target="#b5">Ling et al., 2015)</ref>, and iii) a convolutional neural network over characters ( .</p><p>We evaluate these techniques on the tasks of machine translation (MT) and part-of-speech (POS) tagging and compare them against mor- phological segmenters MADAMIRA ( <ref type="bibr" target="#b10">Pasha et al., 2014</ref>) and Farasa ( <ref type="bibr" target="#b0">Abdelali et al., 2016</ref>). On the MT task, byte-pair encoding (BPE) performs the best among the three methods, achieving very similar performance to morphological segmenta- tion in the Arabic-to-English direction and slightly worse in the other direction. Character-based methods, in comparison, perform better on the task of POS tagging, reaching an accuracy of 95.9%, only 1.3% worse than morphological seg- mentation. We also analyze the effect of segmen- tation granularity of Arabic on the quality of MT. We observed that a neural MT (NMT) system is sensitive to source/target token ratio and performs best when this ratio is close to or greater than 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Segmentation Approaches</head><p>We experimented with three data-driven segmen- tation schemes: i) morphological segmentation, ii) sub-word segmentation based on BPE, and iii) two variants of character-based segmentation. We first map each source word to its corresponding seg- ments (depending on the segmentation scheme), embed all segments of a word in vector space and feed them one-by-one to an encoder-decoder model. See <ref type="figure" target="#fig_0">Figure 1</ref> for illustration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Morphological Segmentation</head><p>There is a vast amount of work on statistical seg- mentation for Arabic. Here we use the state- of-the-art Arabic segmenter MADAMIRA and Farasa as our baselines. MADAMIRA involves a morphological analyzer that generates a list of possible word-level analyses (independent of con- text). The analyses are provided with the original text to a Feature Modeling component that applies an SVM and a language model to make predictions, which are scored by an Analysis Ranking component. Farasa on the other hand is a light weight segmenter, which ignores context and instead uses a variety of features and lexicons for segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Data Driven Sub-word Units</head><p>A number of data-driven approaches have been proposed that learn to segment words into smaller units from data <ref type="bibr">(Demberg, 2007;</ref><ref type="bibr" target="#b12">Sami Virpioja and Kurimo, 2013)</ref> and shown to improve phrase- based MT ( <ref type="bibr">Fishel and Kirik, 2010;</ref><ref type="bibr" target="#b14">Stallard et al., 2012)</ref>. Recently, with the advent of neural MT, a few sub-word-based techniques have been pro- posed that segment words into smaller units to tackle the limited vocabulary and unknown word problems ( <ref type="bibr" target="#b13">Sennrich et al., 2016;</ref><ref type="bibr" target="#b15">Wu et al., 2016)</ref>.</p><p>In this work, we explore Byte-Pair Encoding (BPE), a data compression algorithm <ref type="bibr">(Gage, 1994)</ref> as an alternative to morphological segmentation of Arabic. BPE splits words into symbols (a se- quence of characters) and then iteratively replaces the most frequent symbols with their merged vari- ants. In essence, frequent character n-gram se- quences will be merged to form one symbol. The number of merge operations is controlled by a hyper-parameter OP which directly affects the granularity of segmentation: a high value of OP means coarse segmentation and a low value means fine-grained segmentation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Character-level Encoding</head><p>Character-based models have been found to be effective in translating closely related language pairs ( <ref type="bibr">Durrani et al., 2010;</ref><ref type="bibr" target="#b9">Nakov and Tiedemann, 2012)</ref> and OOV words ( <ref type="bibr">Durrani et al., 2014</ref>). <ref type="bibr" target="#b6">Ling et al. (2016)</ref> used character embeddings to address the OOV word problem. We explored them as an alternative to morphological segmentation. Their advantage is that character embeddings do not re- quire any complicated pre-and post-processing step other than segmenting words into characters. The fully character-level encoder treats the source sentence as a sequence of letters, encoding each letter (including white-space) in the LSTM en- coder (see <ref type="figure" target="#fig_0">Figure 1</ref>). The decoding may follow identical settings. We restricted the character-level representation to the Arabic side of the parallel corpus and use words for the English side.</p><p>Character-CNN  presented a neural language model that takes character-level input and learns word embeddings using a CNN over characters. The embedding are then pro- vided to the encoder as input. The intuition is that the character-based word embedding should be able to learn the morphological phenomena a word inherits. Compared to fully character- level encoding, the encoder gets word-level em- beddings as in the case of unsegmented words (see <ref type="figure" target="#fig_0">Figure 1)</ref>. However, the word embedding is intuitively richer than the embedding learned over unsegmented words because of the convolu- tion over characters. The method was previously shown to help neural MT ( <ref type="bibr">Belinkov and Glass, 2016;</ref><ref type="bibr">Costa-jussà and Fonollosa, 2016)</ref>. <ref type="bibr">Belinkov et al. (2017)</ref> also showed character-based repre- sentations learned using a CNN to be superior, at learning word morphology, than their word-based counter-parts. However, they did not compare these against BPE-based segmentation. We use character-CNN to aid Arabic word segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Arabic-to-English</head><p>English-to-Arabic # SEG tst11 tst12 tst13 tst14 AVG. tst11 tst12 tst13 tst14 AVG. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>In the following, we describe the data and system settings and later present the results of machine translation and POS tagging.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Settings</head><p>Data Segmentation MADAMIRA and Farasa nor- malize the data before segmentation. In order to have consistent data, we normalize it for all seg- mentation approaches. For BPE, we tuned the value of merge operations OP and found 30k and 90k to be optimal for Ar-to-En and En-to-Ar re- spectively. In case of no segmentation (UNSEG) and character-CNN (cCNN), we tokenized the Arabic with the standard Moses tokenizer, which separates punctuation marks. For character-level encoding (CHAR), we preserved word boundaries by replacing space with a special symbol and then separated every character with a space. English- side is tokenized/truecased using Moses scripts.</p><p>Neural MT Settings We used the seq2seq- attn (Kim, 2016) implementation, with 2 layers of <ref type="bibr">1</ref> We used 3.75% as reported to be optimal filtering thresh- old in ( <ref type="bibr" target="#b0">Durrani et al., 2016).</ref> LSTM in the (bidirectional) encoder and the de- coder, with a size of 500. We limit the sentence length to 100 for MORPH, UNSEG, BPE, cCNN, and 500 for CHAR experiments. The source and target vocabularies are limited to 50k each. <ref type="table">Table 1</ref> presents MT results using various segmen- tation strategies. Compared to the UNSEG system, the MORPH system 2 improved translation quality by 4.6 and 1.6 BLEU points in Ar-to-En and En- to-Ar systems, respectively. The results also im- proved by up to 3 BLEU points for cCNN and CHAR systems in the Ar-to-En direction. How- ever, the performance is lower by at least 0.6 BLEU points compared to the MORPH system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Machine Translation Results</head><p>In the En-to-Ar direction, where cCNN and CHAR are applied on the target side, the perfor- mance dropped significantly. In the case of CHAR, mapping one source word to many target char- acters makes it harder for NMT to learn a good model. This is in line with our finding on using a lower value of OP for BPE segmentation (see paragraph Analyzing the effect of OP). Surpris- ingly, the cCNN system results were inferior to the UNSEG system for En-to-Ar. A possible explana- tion is that the decoder's predictions are still done at word level even when using the cCNN model (which encodes the target input during training but not the output). In practice, this can lead to generating unknown words. Indeed, in the Ar-to- En case cCNN significantly reduces the unknown words in the test sets, while in the En-to-Ar case the number of unknown words remains roughly the same between UNSEG and cCNN.</p><p>The BPE system outperformed all other systems in the Ar-to-En direction and is lower than MORPH by only 0.2 BLEU points in the opposite direction. This shows that machine translation involving the 2 Farasa performed better in the Ar-to-En experiments and MADAMIRA performed better in the En-to-Ar direction. We used best results as our baselines for comparison and call them MORPH.</p><p>Arabic language can achieve competitive results with data-driven segmentation. This comes with an additional benefit of language-independent pre- processing and post-processing pipeline. In an attempt to find, whether the gains obtained from data-driven segmentation techniques and morpho- logical segmentation are additive, we applied BPE to morphological segmented data. We saw further improvement of up to 1 BLEU point by using the two segmentations in tandem.</p><p>Analyzing the effect of OP: The unsegmented training data consists of 23M Arabic tokens and 28M English tokens. The parameter OP decides the granularity of segmentation: a higher value of OP means fewer segments. For example, at OP=50k, the number of Arabic tokens is greater by 7% compared to OP=90k. We tested four differ- ent values of OP (15k, 30k, 50k, and 90k). <ref type="figure" target="#fig_1">Figure  2</ref> summarizes our findings on test-2011 dataset, where x-axis presents the ratio of source to tar- get language tokens and y-axis shows the BLEU score. The boundary values for segmentation are character-level segmentation (OP=0) and unseg- mented text (OP=N ). <ref type="bibr">3</ref> For both language direc- tions, we observed that a source to target token ra- tio close to 1 and greater works best provided that the boundary conditions (unsegmented Arabic and character-level segmentation) are avoided. In the En-to-Ar direction, the system improves for coarse segmentation whereas in the Ar-to-En direction, a much finer-grained segmentation of Arabic per- formed better. This is in line with the ratio of to- kens generated using the MORPH systems (Ar-to- En ratio = 1.02). Generalizing from the perspec- tive of neural MT, the system learns better when total numbers of source and target tokens are close to each other. The system shows better tolerance towards modeling many source words to a few tar- get words compared to the other way around.</p><p>Discussion: Though BPE performed well for machine translation, there are a few reservations that we would like to discuss here. Since the main goal of the algorithm is to compress data and segmentation comes as a by-product, it often produces different segmentations of a root word when occurred in different morphological forms. For example, the words driven and driving are seg- mented as driv en and drivi ng respectively. This adds ambiguity to the data and may result in un- 3 N is the number of types in the unsegmented corpus. expected translation errors. Another limitation of BPE is that at test time, it may divide the unknown words to semantically different known sub-word units which can result in a semantically wrong translation. For example, the word " " is un- known to our vocabulary. BPE segmented it into known units which ended up being translated to courage. One possible solution to this problem is; at test time, BPE is applied to those words only which were known to the full vocabulary of the training corpus. In this way, the sub-word units created by BPE for the word are already seen in a similar context during training and the model has learned to translate them correctly. The down- side of this method is that it limits BPE's power to segment unknown words to their correct sub-word units and outputs them as UNK in translation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Part of Speech Tagging</head><p>We also experimented with the aforementioned segmentation strategies for the task of Arabic POS tagging. Probabilistic taggers like HMM- based <ref type="bibr">(Brants, 2000</ref>) and sequence learning mod- els like CRF ( <ref type="bibr" target="#b4">Lafferty et al., 2001</ref>) consider pre- vious words and/or tags to predict the tag of the current word. We mimic a similar setting but in a sequence-to-sequence learning frame- work. <ref type="figure">Figure 3</ref> describes a step by step procedure to train a neural encoder-decoder tagger. Con- sider an Arabic phrase "klm &gt;SdqA}k b$rhm" " " (gloss: call your friends</p><p>give them the good news), we want to learn the tag <ref type="figure">Figure 3</ref>: Seq-to-Seq POS Tagger: The number of segments and the embeddings depend on the seg- mentation scheme used (See <ref type="figure" target="#fig_0">Figure 1)</ref>.</p><p>of the word " " using the context of the pre- vious two words and their tags. First, we segment the phrase using a segmentation approach (step 1) and then add POS tags to context words (step 2). The entire sequence with the words and tags is fed to the sequence-to-sequence framework. The embeddings (for both words and tags) are learned jointly with other parameters in an end-to-end fashion, and optimized on the target tag sequence; for example, "NOUN PRON" in this case. For a given word w i in a sentence s = {w 1 , w 2 , ..., w M } and its POS tag t i , We formu- late the neural TAGGER as follows:</p><formula xml:id="formula_0">SEGMENTER(τ ) : ∀w i → S i TAGGER : S i−2 S i−1 S i → t i</formula><p>where S i is the segmentation of word w i . In case of UNSEG and cCNN, S i would be same as w i . SEGMENTER here is identical to the one described in <ref type="figure" target="#fig_0">Figure 1</ref>. TAGGER is a NMT architecture that learns to predict a POS tag of a segmented/unseg- mented word given previous two words. <ref type="bibr">4</ref> Table 2 summarizes the results. The MORPH system performed best with an improvement of 5.3% over UNSEG. Among the data-driven meth- ods, CHAR model performed best and was behind MORPH by only 0.3%. Even though BPE was infe- rior compared to other methods, it was still better than UNSEG by 4%. <ref type="bibr">5</ref> Analysis of POS outputs We performed a comparative error analysis of predictions made <ref type="bibr">4</ref> We also tried using previous words with their POS tags as context but did not see any significant difference in the end result. <ref type="bibr">5</ref> Optimizing the parameter OP did not yield any difference in accuracy. We used 10k operations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SEG UNSEG MORPH CHAR cCNN BPE</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACC</head><p>90.9 96.2 95.9 95.8 94.9 <ref type="table">Table 2: POS tagging with various segmentations</ref> through MORPH, CHAR and BPE based segmen- tations. MORPH and CHAR observed very similar error patterns, with most confusion between For- eign and Particle tags. In addition to this confu- sion, BPE had relatively scattered errors. It had lower precision in predicting nouns and had con- fused them with adverbs, foreign words and adjec- tives. This is expected, since most nouns are out- of-vocabulary terms, and therefore get segmented by BPE into smaller, possibly known fragments, which then get confused with other tags. However, since the accuracies are quite close, the overall er- rors are very few and similar between the various systems. We also analyzed the number of tags that are output by the sequence-to-sequence model us- ing various segmentation schemes. In 99.95% of the cases, the system learned to output the correct number of tags, regardless of the number of source segments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>We explored several alternatives to language- dependent segmentation of Arabic and evaluated them on the tasks of machine translation and POS tagging. On the machine translation task, BPE segmentation produced the best results and even outperformed the state-of-the-art morphological segmentation in the Arabic-to-English direction. On the POS tagging task, character-based models got closest to using the state-of-the-art segmen- tation. Our results showed that data-driven seg- mentation schemes can serve as an alternative to heavily engineered language-dependent tools and achieve very competitive results. In our analy- sis we showed that NMT performs better when the source to target token ratio is close to one or greater. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Segmentation approaches for the word "b$rhm" " "; the blue vectors indicate the embedding(s) used before the encoding layer.</figDesc><graphic url="image-1.png" coords="2,312.73,62.81,207.35,75.17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Source/Target token ratio with varying OP versus BLEU. Character and unsegmented systems can be seen as BPE with OP=0 and OP=N .</figDesc><graphic url="image-2.png" coords="4,307.28,62.81,218.25,182.18" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank the three anonymous re-viewers for their useful suggestions. This re-search was carried out in collaboration between the HBKU Qatar Computing Research Institute (QCRI) and the MIT Computer Science and Ar-tificial Intelligence Laboratory (CSAIL).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Farasa: A fast and furious segmenter for arabic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><surname>Abdelali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kareem</forename><surname>Darwish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nadir</forename><surname>Durrani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamdy</forename><surname>Mubarak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations<address><addrLine>San Diego, California; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>the Association for Computational Linguistics (HLTNAACL&apos;06)</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Yamama: Yet another multi-dialect arabic morphological analyzer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nasser</forename><surname>Salam Khalifa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nizar</forename><surname>Zalmout</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Habash</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations</title>
		<meeting>COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="223" to="227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<ptr target="https://github.com/harvardnlp/seq2seq-attn" />
		<title level="m">Seq2seq-attn</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Character-Aware Neural Language Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yacine</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Sontag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">D</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><forename type="middle">C N</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighteenth International Conference on Machine Learning. ICML &apos;01</title>
		<meeting>the Eighteenth International Conference on Machine Learning. ICML &apos;01</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="282" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Character-based neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabel</forename><surname>Trancoso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">W</forename><surname>Black</surname></persName>
		</author>
		<idno>CoRR abs/1511.04586</idno>
		<ptr target="http://arxiv.org/abs/1511.04586" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabel</forename><surname>Trancoso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">W</forename><surname>Black</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.04586</idno>
		<title level="m">Character-based neural machine translation</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">On Arabic-English cross-language information retrieval: A machine translation approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Frieder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Aljlayl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Grossman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Third International Conference on Information Technology: Coding and Computing (ITCC)</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Arabic treebank: Part 3 v 3.2 ldc2010t08. web download</title>
		<editor>Ann Bies Seth Kulick Sondos Krouna Fatma Gaddeche Wajdi Zaghouani Mohamed Maamouri</editor>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Linguistic Data Consortium</publisher>
			<pubPlace>Philadelphia</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Combining word-level and character-level models for machine translation between closely-related languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jörg</forename><surname>Tiedemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Jeju, Korea</addrLine></address></meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="301" to="305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">MADAMIRA: A fast, comprehensive tool for morphological analysis and disambiguation of Arabic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arfath</forename><surname>Pasha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Al-Badrashiny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><forename type="middle">El</forename><surname>Kholy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramy</forename><surname>Eskander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nizar</forename><surname>Habash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manoj</forename><surname>Pooleery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Owen</forename><surname>Rambow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan M</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Language Resources and Evaluation Conference. Reykjavik, Iceland, LREC &apos;14</title>
		<meeting>the Language Resources and Evaluation Conference. Reykjavik, Iceland, LREC &apos;14</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1094" to="1101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">QCRI at IWSLT 2013: Experiments in Arabic-English and English-Arabic spoken language translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hassan</forename><surname>Sajjad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Guzmn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><surname>Abdelali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fahad</forename><forename type="middle">Al</forename><surname>Obaidli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Vogel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Spoken Language Technology</title>
		<meeting>the 10th International Workshop on Spoken Language Technology</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>IWSLT-13</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Morfessor 2.0: Python implementation and extensions for morfessor baseline</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Smit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stig-Arne Grnroos Sami</forename><surname>Virpioja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikko</forename><surname>Kurimo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
		<respStmt>
			<orgName>Aalto University publication series SCIENCE + TECHNOLOGY</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Neural machine translation of rare words with subword units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Unsupervised morphology rivals supervised morphology for arabic mt</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Stallard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Kayser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
	<note>Yoong Keok Lee, and Regina Barzilay</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Google&apos;s neural machine translation system: Bridging the gap between human and machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qin</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Klingner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apurva</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melvin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Gouws</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshikiyo</forename><surname>Kato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taku</forename><surname>Kudo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hideto</forename><surname>Kazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Stevens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Kurian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nishant</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<idno>CoRR abs/1609.08144</idno>
		<ptr target="http://arxiv.org/abs/1609.08144" />
	</analytic>
	<monogr>
		<title level="j">Oriol Vinyals</title>
		<editor>Greg Corrado, Macduff Hughes, and Jeffrey Dean</editor>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
