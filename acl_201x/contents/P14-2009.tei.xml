<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:38+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Adaptive Recursive Neural Network for Target-dependent Twitter Sentiment Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>June 23-25 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
							<email>donglixp@gmail.com fuwei@microsoft.com {ysjtcq,tangduyu}@gmail.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<settlement>Harbin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuanqi</forename><surname>Tan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
							<email>mingzhou@microsoft.com kexu@nlsde.buaa.edu.cn</email>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<settlement>Harbin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Xu</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Beihang University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Adaptive Recursive Neural Network for Target-dependent Twitter Sentiment Classification</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="49" to="54"/>
							<date type="published">June 23-25 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We propose Adaptive Recursive Neural Network (AdaRNN) for target-dependent Twitter sentiment classification. AdaRNN adaptively propagates the sentiments of words to target depending on the context and syntactic relationships between them. It consists of more than one composition functions, and we model the adaptive sentiment propagations as distributions over these composition functions. The experimental studies illustrate that AdaRNN improves the baseline methods. Furthermore , we introduce a manually annotated dataset for target-dependent Twitter sentiment analysis.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Twitter becomes one of the most popular social networking sites, which allows the users to read and post messages (i.e. tweets) up to 140 charac- ters. Among the great varieties of topics, people in Twitter tend to express their opinions for the brands, celebrities, products and public events. As a result, it attracts much attention to estimate the crowd's sentiments in Twitter.</p><p>For the tweets, our task is to classify their senti- ments for a given target as positive, negative, and neutral. People may mention several entities (or targets) in one tweet, which affects the availabil- ities for most of existing methods. For example, the tweet "@ballmer: windows phone is better than ios!" has three targets (@ballmer, windows phone, and ios). The user expresses neutral, pos- itive, and negative sentiments for them, respec- tively. If target information is ignored, it is diffi- cult to obtain the correct sentiment for a specified target. For target-dependent sentiment classifica- tion, the manual evaluation of <ref type="bibr" target="#b8">Jiang et al. (2011)</ref>  show that about 40% of errors are caused by not considering the targets in classification.</p><p>The features used in traditional learning-based methods ( <ref type="bibr" target="#b11">Pang et al., 2002;</ref><ref type="bibr" target="#b10">Nakagawa et al., 2010)</ref> are independent to the targets, hence the results are computed despite what the targets are. <ref type="bibr" target="#b7">Hu and Liu (2004)</ref> regard the features of products as tar- gets, and sentiments for them are heuristically de- termined by the dominant opinion words. <ref type="bibr" target="#b8">Jiang et al. (2011)</ref> combine the target-independent fea- tures (content and lexicon) and target-dependent features (rules based on the dependency parsing results) together in subjectivity classification and polarity classification for tweets.</p><p>In this paper, we mainly focus on integrating target information with Recursive Neural Network (RNN) to leverage the ability of deep learning models. The neural models use distributed repre- sentation <ref type="bibr" target="#b12">Rumelhart et al., 1986;</ref><ref type="bibr" target="#b0">Bengio et al., 2003</ref>) to automatically learn fea- tures for target-dependent sentiment classification. RNN utilizes the recursive structure of text, and it has achieved state-of-the-art sentiment analysis re- sults for movie review dataset <ref type="bibr" target="#b14">(Socher et al., 2012;</ref><ref type="bibr" target="#b15">Socher et al., 2013</ref>). The recursive neural mod- els employ the semantic composition functions, which enables them to handle the complex com- positionalities in sentiment analysis.</p><p>Specifically, we propose a framework which learns to propagate the sentiments of words to- wards the target depending on context and syn- tactic structure. We employ a novel adaptive multi-compositionality layer in recursive neural network, which is named as <ref type="bibr">AdaRNN (Dong et al., 2014</ref>). It consists of more than one compo- sition functions, and we model the adaptive sen- timent propagations as learning distributions over these composition functions. We automatically learn the composition functions and how to select them from supervisions, instead of choosing them heuristically or by hand-crafted rules. AdaRNN determines how to propagate the sentiments to- wards the target and handles the negation or in- tensification phenomena <ref type="bibr" target="#b16">(Taboada et al., 2011</ref>) in sentiment analysis. In addition, we introduce a manually annotated dataset, and conduct extensive experiments on it. The experimental results sug- gest that our approach yields better performances than the baseline methods.  As illustrated in <ref type="figure" target="#fig_1">Figure 1</ref>, we obtain the repre- sentation of "very good" by the composition of "very" and "good", and the representation of tri- gram "not very good" is recursively obtained by the vectors of "not" and "very good". The di- mensions of parent node are calculated by linear combination of the child vectors' dimensions. The vector representation v is obtained via:</p><formula xml:id="formula_0">v = f (g (v l , v r )) = f W v l v r + b (1)</formula><p>where v l , v r are the vectors of its left and right child, g is the composition function, f is the non- linearity function (such as tanh, sigmoid, softsign, etc.), W ∈ R D×2D is the composition matrix, and b is the bias vector. The dimension of v is the same as its child vectors, and it is recursively used in the next step. Notably, the word vectors in the leaf nodes are regarded as the parameters, and will be updated according to the supervisions. The vector representation of root node is then fed into a softmax classifier to predict the label. The k-th element of softmax(x) is exp{x k } j exp{x j } . For a vector, the softmax obtains the distribution over K classes. Specifically, the predicted distribution is y = softmax (Uv), where y is the predicted distribution, U ∈ R K×D is the classification ma- trix, and v is the vector representation of node.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Our Approach</head><p>We use the dependency parsing results to find the words syntactically connected with the interested target. Adaptive Recursive Neural Network is pro- posed to propagate the sentiments of words to the target node. We model the adaptive sentiment propagations as semantic compositions. The com- putation process is conducted in a bottom-up man- ner, and the vector representations are computed recursively. After we obtain the representation of target node, a classifier is used to predict the sen- timent label according to the vector.</p><p>In Section 3.1, we show how to build recur- sive structure for target using the dependency pars- ing results. In Section 3.2, we propose Adaptive Recursive Neural Network and use it for target- dependent sentiment analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Build Recursive Structure</head><p>The dependency tree indicates the dependency re- lations between words. As described above, we propagate the sentiments of words to the target. Hence the target is placed at the root node to com- bine with its connected words recursively. The de- pendency relation types are remained to guide the sentiment propagations in our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Convert Dependency Tree</head><p>Input: Target node, Dependency tree Output: Converted tree 1: function CONV(r)</p><p>2:</p><p>E r ← SORT(dep edges connected with r)</p><p>3:</p><formula xml:id="formula_1">v ← r 4: for (r t − → u/u t − → r) in E r do 5:</formula><p>if r is head of u then v ← w 10:</p><p>return v 11: Call CONV(target node) to get converted tree As illustrated in the Algorithm 1, we recursively convert the dependency tree starting from the tar- get node. We find all the words connected to the target, and these words are combined with target node by certain order. Every combination is con- sidered as once propagation of sentiments. If the target is head of the connected words, the target vector is combined as the right node; if otherwise, it is combined as the left node. This ensures the child nodes in a certain order. We use two rules to determine the order of combinations: (1) the words whose head is the target in dependency tree are first combined, and then the rest of connected words are combined; (2) if the first rule cannot de- termine the order, the connected words are sorted by their positions in sentence from right to left. Notably, the conversion is performed recursively for the connected words and the dependency rela- tion types are remained. <ref type="figure">Figure 2</ref> shows the con- verted results for different targets in one sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">AdaRNN: Adaptive Recursive Neural Network</head><p>RNN employs one global matrix to linearly com- bine the elements of vectors. Sometimes it is challenging to obtain a single powerful function to model the semantic composition, which moti- vates us to propose AdaRNN. The basic idea of AdaRNN is to use more than one composition functions and adaptively select them depending on the linguistic tags and the combined vectors. The model learns to propagate the sentiments of words by using the different composition functions. <ref type="figure">Figure 2</ref> shows the computation process for the example sentence "windows is better than ios", where the user expresses positive sentiment to- wards windows and negative sentiment to ios. For the targets, the order of compositions and the de- pendency types are different. AdaRNN adap- tively selects the composition functions g 1 . . . g C depending on the child vectors and the linguistic types. Thus it is able to determine how to propa- gate the sentiments of words towards the target.</p><p>Based on RNN described in Section 2, we de- fine the composition result v in AdaRNN as:</p><formula xml:id="formula_2">v = f C h=1 P (g h |v l , v r , e) g h (v l , v r )<label>(2)</label></formula><p>where g 1 , . . . , g C are the composition functions, P (g h |v l , v r , e) is the probability of employing g h given the child vectors v l , v r and external feature vector e, and f is the nonlinearity function. For the composition functions, we use the same forms as in Equation <ref type="formula">(1)</ref>, i.e., we have C composition matrices W 1 . . . W C . We define the distribution over these composition functions as:</p><formula xml:id="formula_3">   P (g 1 |v l , v r , e) . . . P (g C |v l , v r , e)    = softmax   βS   v l v r e     (3)</formula><p>where β is the hyper-parameter, S ∈ R C×(2D+|e|) is the matrix used to determine which composition function we use, v l , v r are the left and right child vectors, and e are external feature vector. In this work, e is a one-hot binary feature vector which indicates what the dependency type is. If relation is the k-th type, we set e k to 1 and the others to 0. Adding β in softmax function is a widely used parametrization method in statistical mechanics, which is known as Boltzmann distribution and Gibbs measure <ref type="bibr" target="#b4">(Georgii, 2011)</ref>. When β = 0, this function produces a uniform distribution; when β = 1, it is the same as softmax function; when β → ∞, it only activates the dimension with max- imum weight, and sets its probability to 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Model Training</head><p>We use the representation of root node as the fea- tures, and feed them into the softmax classifier to predict the distribution over classes. We define the ground truth vector t as a binary vector. If the k-th class is the label, only t k is 1 and the others are 0. Our goal is to minimize the cross-entropy error between the predicted distribution y and ground truth distribution t. For each training instance, we define the objective function as:</p><formula xml:id="formula_4">min Θ − j t j log y j + θ∈Θ λ θ θ 2 2 (4)</formula><p>where Θ represents the parameters, and the L 2 - regularization penalty is used.</p><p>Based on the converted tree, we employ back- propagation algorithm <ref type="bibr" target="#b12">(Rumelhart et al., 1986)</ref> to propagate the errors from root node to the leaf nodes. We calculate the derivatives to update the parameters. The AdaGrad ( <ref type="bibr" target="#b2">Duchi et al., 2011</ref>) is employed to solve this optimization problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>As people tend to post comments for the celebri- ties, products, and companies, we use these key- words (such as "bill gates", "taylor swift", "xbox", "windows 7", "google") to query the Twitter API. After obtaining the tweets, we manually anno- tate the sentiment labels (negative, neutral, posi- tive) for these targets. In order to eliminate the effects of data imbalance problem, we randomly sample the tweets and make the data balanced. Dependency tree:</p><p>windows is target: ios is target: <ref type="figure">Figure 2</ref>: For the sentence "windows is better than ios", we convert its dependency tree for the different targets (windows and ios). AdaRNN performs semantic compositions in bottom-up manner and forward propagates sentiment information to the target node. The g 1 , . . . , g C are different composition functions, and the combined vectors and dependency types are used to select them adaptively. These composition functions decide how to propagate the sentiments to the target.</p><p>tweets. We randomly sample some tweets, and they are assigned with sentiment labels by two an- notators. About 82.5% of them have the same la- bels. The agreement percentage of polarity clas- sification is higher than subjectivity classification.</p><p>To the best of our knowledge, this is the largest target-dependent Twitter sentiment classification dataset which is annotated manually. We make the dataset publicly available 1 for research purposes. We preprocess the tweets by replacing the tar- gets with $T$ and setting their POS tags to NN. <ref type="bibr">Liblinear (Fan et al., 2008</ref>) is used for baselines. A tweet-specific tokenizer <ref type="bibr" target="#b5">(Gimpel et al., 2011</ref>) is employed, and the dependency parsing results are computed by Stanford Parser ( <ref type="bibr" target="#b9">Klein and Manning, 2003</ref>). The hyper-parameters are chosen by cross-validation on the training split, and the test accuracy and macro-average F1-score score are re- ported. For recursive neural models, the dimen- sion of word vector is set to 25, and f = tanh is used as the nonlinearity function. We employ 10 composition matrices in AdaRNN. The param- eters are randomly initialized. Notably, the word vectors will also be updated. the target-independent (SVM-indep) and target- dependent features and uses SVM as the classifier. There are seven rules to extract target-sensitive features. We do not implement the social graph optimization and target expansion tricks in it.</p><p>SVM-conn: The words, punctuations, emoti- cons, and #hashtags included in the converted de- pendency tree are used as the features for SVM.</p><p>RNN: It is performed on the converted depen- dency tree without adaptive composition selection.</p><p>AdaRNN-w/oE: Our approach without using the dependency types as features in adaptive se- lection for the composition functions.</p><p>AdaRNN-w/E: Our approach with employing the dependency types as features in adaptive se- lection for the composition functions.</p><p>AdaRNN-comb: We combine the root vectors obtained by AdaRNN-w/E with the uni/bi-gram features, and they are fed into a SVM classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Accuracy  <ref type="table">Table 1</ref>: Evaluation results on target-dependent Twitter sentiment classification dataset. Our ap- proach outperforms the baseline methods.</p><p>As shown in the <ref type="table">Table 1</ref>, AdaRNN achieves bet- ter results than the baselines. Specifically, we find that the performances of SVM-dep increase than SVM-indep. It indicates that target-dependent fea- tures help improve the results. However, the accu- racy and F1-score do not gain significantly. This is caused by mismatch of the rules <ref type="bibr" target="#b8">(Jiang et al., 2011</ref>) used to extract the target-dependent fea- tures. The POS tagging and dependency parsing results are not precise enough for the Twitter data, so these hand-crafted rules are rarely matched. Further, the results of SVM-conn illustrate that us- ing the words which have paths to target as bag-of- words features does not perform well.</p><p>RNN is also based on the converted depen- dency tree. It outperforms SVM-indep, and is comparable with SVM-dep. The performances of AdaRNN-w/oE are better than the above base- lines. It shows that multiple composition functions and adaptive selection help improve the results. AdaRNN provides more powerful composition ability, so that it achieves better semantic compo- sition for recursive neural models. AdaRNN-w/E obtains best performances among the above meth- ods. Its macro-average F1-score rises by 5.3% than the target-independent method SVM-indep. It employs dependency types as binary features to select the composition functions adaptively. The results illustrate that the syntactic tags are helpful to guide the model propagate sentiments of words towards target. Although the dependency results are also not precise enough, the composition se- lection is automatically learned from data. Hence AdaRNN is more robust for the imprecision of parsing results than the hand-crafted rules. The performances become better after adding the uni- gram and bi-gram features (target-independent).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Effects of β</head><p>We compare different β for AdaRNN defined in Equation (3) in this section. Different parameter β leads to different composition selection schemes.</p><p>As illustrated in <ref type="figure" target="#fig_4">Figure 3</ref>, the AdaRNN-w/oE and AdaRNN-w/E achieve the best accuracies at β = 2, and they have a similar trend. Specifi- cally, β = 0 obtains a uniform distribution over the composition functions which does not help im- prove performances. β → ∞ results in a max- imum probability selection algorithm, i.e., only the composition function which has the maximum probability is used. This selection scheme makes </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We propose Adaptive Recursive Neural Network (AdaRNN) for the target-dependent Twitter senti- ment classification. AdaRNN employs more than one composition functions and adaptively chooses them depending on the context and linguistic tags. For a given tweet, we first convert its dependency tree for the interested target. Next, the AdaRNN learns how to adaptively propagate the sentiments of words to the target node. AdaRNN enables the sentiment propagations to be sensitive to both linguistic and semantic categories by using differ- ent compositions. The experimental results illus- trate that AdaRNN improves the baselines without hand-crafted rules.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>2</head><label></label><figDesc>RNN: Recursive Neural Network RNN (Socher et al., 2011) represents the phrases and words as D-dimensional vectors. It performs compositions based on the binary trees, and obtain the vector representations in a bottom-up way.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The composition process for "not very good" in Recursive Neural Network.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>w</head><label></label><figDesc>← node with CONV(u), v as children 7: else 8: w ← node with v, CONV(u) as children 9:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>SVM-indep: It uses the uni-gram, bi-gram, punctuations, emoticons, and #hashtags as the content features, and the numbers of positive or negative words in General Inquirer as lexicon fea- tures. These features are all target-independent. SVM-dep: We re-implement the method pro- posed by Jiang et al. (2011). It combines both 1 http://goo.gl/5Enpu7</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The curve shows the accuracy as the hyper-parameter β = 0, 2 0 , 2 1 ,. .. , 2 6 increases. AdaRNN achieves the best results at β = 2 1 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>* Contribution during internship at Microsoft Research.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>The negative, neutral, positive classes account for 25%, 50%, 25%, respectively. Training data con- sists of 6,248 tweets, and testing data has 692</figDesc><table>windows 

is 

better 

ios 
than 

g 1 
g C 
... 

g 1 
g C 
... 

g 1 
g C 
... 

g 1 
g C 
... 

nsubj 

cop 

prep 

pobj 

Positve 

Softmax 

ios 

than 

windows 

is 
better 

g 1 
g C 
... 

g 1 
g C 
... 

g 1 
g C 
... 

g 1 
g C 
... 

pobj 

prep 

nsubj 

cop 

Negative 

Softmax 

windows 
is 
better 
than 
ios 

ROOT 

cop 

nsubj 

prep 
pobj 

(target) 
(target) 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research was partly supported by the National </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A neural probabilistic language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Réjean</forename><surname>Ducharme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Janvin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1137" to="1155" />
			<date type="published" when="2003-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Adaptive multi-compositionality for recursive neural models with applications to sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Twenty-Eighth AAAI Conference on Artificial Intelligence (AAAI)</title>
		<imprint>
			<publisher>AAAI</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Adaptive subgradient methods for online learning and stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2121" to="2159" />
			<date type="published" when="2011-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Liblinear: A library for large linear classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Wei</forename><surname>Rong-En Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho-Jui</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangrui</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Jen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1871" to="1874" />
			<date type="published" when="2008-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Gibbs Measures and Phase Transitions. De Gruyter studies in mathematics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">O</forename><surname>Georgii</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>De Gruyter</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Part-of-speech tagging for twitter: Annotation, features, and experiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O&amp;apos;</forename><surname>Brendan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Mills</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Eisenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dani</forename><surname>Heilman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Flanigan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: Short Papers</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: Short Papers<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="42" to="47" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning distributed representations of concepts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Geoffrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth Annual Conference of the Cognitive Science Society</title>
		<meeting>the Eighth Annual Conference of the Cognitive Science Society<address><addrLine>Hillsdale, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Erlbaum</publisher>
			<date type="published" when="1986" />
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Mining and summarizing customer reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minqing</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;04</title>
		<meeting>the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;04<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="168" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Target-dependent twitter sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiejun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="151" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Accurate unlexicalized parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 41st Annual Meeting on Association for Computational Linguistics<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="423" to="430" />
		</imprint>
	</monogr>
	<note>ACL &apos;03. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Dependency tree-based sentiment classification using crfs with hidden variables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tetsuji</forename><surname>Nakagawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kentaro</forename><surname>Inui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="786" to="794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Thumbs up?: sentiment classification using machine learning techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shivakumar</forename><surname>Vaithyanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL-02 conference on Empirical methods in natural language processing</title>
		<meeting>the ACL-02 conference on Empirical methods in natural language processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning representations by back-propagating errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">323</biblScope>
			<biblScope unit="issue">6088</biblScope>
			<biblScope unit="page" from="533" to="536" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Parsing Natural Scenes and Natural Language with Recursive Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cliff</forename><forename type="middle">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Semantic compositionality through recursive matrix-vector spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brody</forename><surname>Huval</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-CoNLL</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1201" to="1211" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Perelygin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1631" to="1642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Lexiconbased methods for sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maite</forename><surname>Taboada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Brooke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milan</forename><surname>Tofiloski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kimberly</forename><surname>Voll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><surname>Stede</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Linguist</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="267" to="307" />
			<date type="published" when="2011-06" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
