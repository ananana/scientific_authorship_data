<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:00+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Domain Specific Named Entity Recognition Referring to the Real World by Deep Neural Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suzushi</forename><surname>Tomori</surname></persName>
							<email>tomori.suzushi.72e@st.kyoto-u.ac.jp † † ninomiya@cs.ehime-u.ac.jp † † † forest@i.kyoto-u.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Graduate School of Informatics</orgName>
								<orgName type="department" key="dep2">Graduate School of Science and Engineering</orgName>
								<orgName type="laboratory">† † † Academic Center for Computing and Media Studies</orgName>
								<orgName type="institution" key="instit1">Kyoto University</orgName>
								<orgName type="institution" key="instit2">Ehime University</orgName>
								<orgName type="institution" key="instit3">Kyoto University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takashi</forename><surname>Ninomiya</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Graduate School of Informatics</orgName>
								<orgName type="department" key="dep2">Graduate School of Science and Engineering</orgName>
								<orgName type="laboratory">† † † Academic Center for Computing and Media Studies</orgName>
								<orgName type="institution" key="instit1">Kyoto University</orgName>
								<orgName type="institution" key="instit2">Ehime University</orgName>
								<orgName type="institution" key="instit3">Kyoto University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinsuke</forename><surname>Mori</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Graduate School of Informatics</orgName>
								<orgName type="department" key="dep2">Graduate School of Science and Engineering</orgName>
								<orgName type="laboratory">† † † Academic Center for Computing and Media Studies</orgName>
								<orgName type="institution" key="instit1">Kyoto University</orgName>
								<orgName type="institution" key="instit2">Ehime University</orgName>
								<orgName type="institution" key="instit3">Kyoto University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Domain Specific Named Entity Recognition Referring to the Real World by Deep Neural Networks</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="236" to="242"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In this paper, we propose a method for referring to the real world to improve named entity recognition (NER) specialized for a domain. Our method adds a stacked auto-encoder to a text-based deep neural network for NER. We first train the stacked auto-encoder only from the real world information , then the entire deep neural network from sentences annotated with NEs and accompanied by real world information. In our experiments, we took Japanese chess as the example. The dataset consists of pairs of a game state and commentary sentences about it annotated with game-specific NE tags. We conducted NER experiments and showed that referring to the real world improves the NER accuracy.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In recent years there has been a surge of inter- est in relating natural language to the real world. And more and more language resources accom- panied by nonlinguistic data are becoming avail- able. Typical examples are image descriptions <ref type="bibr" target="#b22">(Yang et al., 2011;</ref><ref type="bibr" target="#b21">Ushiku et al., 2011</ref>) and video ( <ref type="bibr">Hashimoto et al., 2014</ref>). <ref type="bibr">Ferraro et al. (2015)</ref> summarized many other image and video datasets. These datasets allow us to attempt the task of con- necting language expressions to the real world, which is called symbol grounding <ref type="bibr">(Harnad, 1990)</ref>. <ref type="bibr" target="#b2">Bruni et al. (2014)</ref> proposed methods for acquiring multimodal representations by applying SVD to distributional semantics and bag-of-visual-words (BoVW). <ref type="bibr" target="#b6">Ngiam et al. (2011)</ref> proposed unsu- pervised multimodal learning based on deep re- stricted boltzmann machines (RBMs). In the field of natural language processing (NLP) research, * This work was done when the first author was at Ehime University. <ref type="bibr">Kiela et al. (2015)</ref> proposed to acquire bilingual lexicon based on visual similarity. <ref type="bibr" target="#b8">Ramisa et al. (2015)</ref> describe a method for predicting a preposi- tion referring to positions in the image.</p><p>In this paper, we propose a method for enhanc- ing a named entity (NE) recognizer referring to the real world. Because of the lack of datasets con- sisting of sentences annotated with the general NE tags such as names of people, organizations, and times <ref type="bibr" target="#b9">(Sang and Meulder, 2003)</ref>, with accompa- nying real world data, we take game states as the counterpart of the language and the NE tag set spe- cialized for game commentaries such as defense formations and opening names <ref type="bibr" target="#b4">(Mori et al., 2016)</ref>. Similar to bio-medical NEs <ref type="bibr" target="#b11">(Settles, 2004;</ref><ref type="bibr" target="#b18">Tateisi et al., 2002</ref>), these NEs are useful for applications in the game domain. Our method could be used to improve automatic game commentary systems ( <ref type="bibr">Kameko et al., 2015b;</ref><ref type="bibr">Chen et al., 2010</ref>) or to build a state search method that uses natural lan- guage queries instead of state notations ( <ref type="bibr">Ganguly et al., 2014</ref>). In addition to these interesting ap- plications, game states have another advantage for NLP research. They are much easier to recognize than images and video, which allows us to concen- trate on the NLP problem.</p><p>In order to incorporate the real world, i.e. game states, into NE recognition (NER), we propose to use deep neural networks (DNNs), which have been reported to be successful in various NLP tasks such as word embedding ( <ref type="bibr" target="#b0">Bengio et al., 2003;</ref><ref type="bibr">Mikolov et al., 2013b;</ref><ref type="bibr" target="#b7">Pennington et al., 2014;</ref><ref type="bibr">Mikolov et al., 2013a)</ref>, part-of-speech tag- ging <ref type="bibr" target="#b20">(Tsuboi, 2014</ref>), parsing <ref type="bibr" target="#b13">(Socher et al., 2010;</ref><ref type="bibr" target="#b14">Socher et al., 2012;</ref><ref type="bibr" target="#b15">Socher et al., 2013a</ref>), parsing <ref type="bibr" target="#b15">(Socher et al., 2013a</ref>), NER <ref type="bibr">(Hammerton, 2003)</ref> , sentiment analysis ( <ref type="bibr" target="#b16">Socher et al., 2013b</ref>) and ma- chine translation <ref type="bibr" target="#b5">(Neubig et al., 2015)</ref>. First we build a normal NE recognizer by referring only to the text information based on DNN. Each unit of its output layer corresponds to a BIO tag for the word (see Section 3). We use post processing based on the Viterbi algorithm to choose the best tag sequence by discarding inconsistent ones. This design allows us to train the model from partially annotated sentences, in which only some words are annotated with NE tags ( <ref type="bibr" target="#b10">Sasada et al., 2015)</ref>. Next we extend the text-based DNN with a mod- ule that refers to game states. This module is a stacked-auto-encoder (SAE) ( <ref type="bibr" target="#b1">Bengio et al., 2007)</ref> and we first train it only from game states. The pre-training allows the model to learn game state embedding which abstracts game state informa- tion. Then we fine-tune the entire DNN for NER, consisting of both text-based DNN and SAE. As we show in later section of this paper, we end up with an NE recognizer that refers to real world in- formation in addition to text information, which increases its accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>There are several lines of multimodal learning in the fields of pattern recognition and NLP. Most learn multimodal representations by solving un- supervised learning tasks or pseudo-supervised learning tasks, but there were only a few studies that directly learned multimodal representations for target tasks in NLP. Our method incorporates multimodal information in DNNs for NER. <ref type="bibr" target="#b2">Bruni et al. (2014)</ref> proposed methods for acquir- ing multimodal representations by applying SVD to distributional semantics and BoVW. <ref type="bibr">Lopopolo and van Miltenburg (2015)</ref> proposed a similar method for acquiring sound-based distributional semantics. Textual vectors are acquired by us- ing latent semantic analysis (LSA) and auditory vectors are acquired by the bag-of-audio-words (BoAW) method. The multimodal representa- tions are acquired by applying SVD. <ref type="bibr" target="#b6">Ngiam et al. (2011)</ref> and <ref type="bibr" target="#b17">Srivastava and Salakhutdinov (2012)</ref> proposed unsupervised learning methods based on deep RBMs for learning multimodal representa- tions in hidden layers. Providing paired infor- mation such as text-image pairs or audio-video pairs to RBMs, shared representations are learned in their hidden layers. <ref type="bibr" target="#b6">Ngiam et al. (2011)</ref> also used deep auto-encoders for learning RBMs. Af- ter acquiring multimodal representations, they can be used as inputs for other supervised learning tasks, such as speech recognition and image re- trieval, where standard linear classifiers are used for solving the tasks. <ref type="bibr" target="#b12">Silberer and Lapata (2014)</ref> proposed a deep learning method for learning multimodal representations by solving pseudo- supervised tasks to predict the input's object label, such as 'boat,' given textual and visual attribute- based representations for the object. Their ob- jective function is the weighted sum of the auto- encoding error and the classification error. Though their model is for supervised learning, Multi- modal representations are learned In their exper- iments, the acquired multimodal representations were used for evaluating the word similarity task and word clustering task.</p><p>Lazaridou et al. (2015) extend word2vec ( <ref type="bibr">Mikolov et al., 2013a;</ref><ref type="bibr">Mikolov et al., 2013b</ref>) to incorporate visual information for acquiring mul- timodal representations. Word embedding meth- ods including word2vec are often used for vari- ous NLP tasks instead of one hot representations, and were shown to improve the performance of NLP systems. Word embeddings are mappings from a word to a low-dimensional real vectors that represents word meanings and relations be- tween words. Word2vec is a method for ac- quiring word embeddings from a neural network which solves a pseudo-supervised task to predict surrounding words. <ref type="bibr">Kiela and Clark (2015)</ref> ex- tend word2vec to incorporate bag-of-audio-words (BoAW). <ref type="bibr">Gupta et al. (2015)</ref> have shown that word embeddings contain much information for predict- ing attributes. <ref type="bibr">Herbelot and Vecchi (2015)</ref> pro- posed a method for predicting general quantifiers such as some for predicate-subject pairs. Similar to this paper <ref type="bibr">Kameko et al. (2015a)</ref> pro- posed a method for word segmentation using game states and DNNs. The main differences between their method and ours is that i) they use game states to build a term dictionary for word seg- mentation, but our method directly incorporates a game state to improve NER, and ii) they used manually developed features to extract game states while we automatically acquire game states by us- ing pre-training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Game Commentary Corpus</head><p>The game we chose for the experiments is Japanese chess, called shogi in Japanese. It is a two-player board game with professional players. The board has 9×9 squares and games are played with 40 pieces of 14 different types. Unlike chess, players can reuse captured pieces. In computer science terms, it is a deterministic perfect informa- The main idea of this paper is that the game state, i.e. the real world, provides information on the texts that describe it. In the next section, we propose a method for utilizing this information in the NER task. Text features  <ref type="figure" target="#fig_0">Figure 1</ref> shows the overall architecture of our DNN for NER. The left part is the DNN for text- based NER and the bottom right part is an addi- tional DNN for referring to the real world.</p><formula xml:id="formula_0">w i−2 , w i−1 , w i , w i+1 , w i+2 w i−2 w i−1 , w i−1 w i , w i w i+1 , w i+1 w i+2 w i−2 w i−1 w i , w i w i+1 w i+2 c(w i−2 ), c(w i−1 ), c(w i ), c(w i+1 ), c(w i+2 ) pos(w i−2 ), pos(w i−1 ), pos(w i ), pos(w i+1 ), pos(w i+2 )</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Utilizing Real World Information in a Named Entity Recognizer</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Text-based NER</head><p>The text-based NER refers to the text only through the standard features for NER (Sang and Meulder, 2003) listed in <ref type="table" target="#tab_1">Table 2</ref>. They con- sist of word n-grams in the window w i+2 i−2 = w i−2 w i−1 w i w i+1 w i+2 , where w i is the word to be labelled, the part-of-speech tags pos(w) and the character type c(w) 2 of a word w in the window w i+2 i−2 . Each feature corresponds to a unit at the bottom left in <ref type="figure" target="#fig_0">Figure 1</ref> (f t 1 . . . f t n ). Each unit aligned at the top of <ref type="figure" target="#fig_0">Figure 1</ref> corre- sponds to a BIO tag. Thus there are 43 units in the shogi NE case. The last layer is the softmax func- tion and we choose the tag of the highest unit value for the input word. As we mentioned in Section 1, this design makes it possible to use partially anno- tated data. 3 It can, however, generate inconsistent BIO tag sequences, e.g., an NE starting with an I tag. We use a best path search module based on the Viterbi algorithm while limiting the search space into valid tag sequences (Sasada et al., 2015).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">NER Referring to the Real World</head><p>To enable our NE recognizer to refer to the real world, we add a network to the DNN for text- based NER as shown in the bottom right in <ref type="figure" target="#fig_0">Fig- ure 1</ref>. The input layer corresponds to the game state features depicted in <ref type="figure" target="#fig_1">Figure 2</ref> (f r 1 . . . f r m ). For shogi they are nine-by-nine binary features which represent the positions of pieces on the board for each piece type and each player. Thus we have m = 2, 268 (= 9 × 9 × 14 × 2) features for the pieces on the board and 14 (= 7 × 2) integer features which represent the number of captured pieces for each type and each player.</p><p>To incorporate the game state features we pro- pose using an SAE ( <ref type="bibr" target="#b1">Bengio et al., 2007</ref>) to ab- stract the game state information instead of di- rectly adding the units for these features to the text-based NER. To build the SAE, we first pre- pare a three-layer neural network (with one hid- den layer) as depicted on the left side of <ref type="figure" target="#fig_3">Figure  3</ref> and train it providing the same game states to both input and output layers. With this process we can obtain the best reduced representations for the game states as the hidden layer that reconstructs the input game state features at the output layer.    Then we duplicate the hidden layer and put an- other hidden layer of smaller dimension between them (see the network in the middle of <ref type="figure" target="#fig_3">Figure 3</ref>) and train it in the same manner. This time the out- put layer is the duplicated former hidden layer and we train the new hidden layer by minimizing the difference between the duplicated former hidden layers. We repeat this process for a fixed number of times as shown on the right side of <ref type="figure" target="#fig_3">Figure 3</ref>. This process is called pre-training. Note that dur- ing pre-training only game states are used.</p><p>After the pre-training, we cut off the top layer to obtain a network with a trapezoid shape whose top layer abstracts game states (a 1 . . . a l in <ref type="figure" target="#fig_0">Figure  1</ref>). Then we join it to the DNN for the text-based NER as shown in <ref type="figure" target="#fig_0">Figure 1</ref>. Finally, we fine-tune it from both game states and texts annotated with NE tags. Note that we also tune parameters in the pre-trained SAE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Evaluation</head><p>In this section we describe the NER experiments we conducted to evaluate our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Settings</head><p>The corpus we used is the game commentary cor- pus (Mori et al., 2016) described in Section 3 briefly. <ref type="table" target="#tab_3">Table 3</ref> shows its specifications. <ref type="table" target="#tab_4">Table 4</ref> shows the number of dimensions in each layer for game state embeddings in pre-training. We set the number of layers in the SAE (Subsection 4.2) to four, with which we could maximize the accuracy on the development set held-out from the training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Models for Comparison</head><p>The baseline is text-based NER based on DNN as described in Subsection 4.1. In addition, we tested NER based on conditional random fields (CRFs) ( <ref type="bibr">Lafferty et al., 2001</ref>) with the same text features, because NER is a sequence labeling problem and   CRFs are the standard method used to solve it <ref type="bibr">(McCallum and Li, 2003)</ref>. We compared these baselines and our NER that refers to the real world (DNN+R) as described in Subsection 4.2. Its SAE was trained on 213,195 game states. <ref type="table" target="#tab_6">Table 5</ref> shows the results. From the F-measures we see that DNN is better than CRFs. This is consistent with many works which apply DNN to NLP problems. A comparison between DNN and DNN+R tells us that we can achieve a further improvement by referring to real world informa- tion. The difference in BIO accuracies between them is statistically significant (McNemar's test, p &lt; 0.01). Therefore we can say that our method successfully integrates real world information into text information to build a better solution to the NER problem. When we take a close look at the precision and recall, DNN+R and DNN balance them better than CRFs. CRFs recognized shogi-NEs with high pre- cision but with low recall. The NER results tell that CRFs tended to output O tags when they were not confident to classify correct shogi-NE tags. DNN+R and DNN can classify BIO tags more accurately than CRFs as can be seen in BIO ac- curacies in <ref type="table" target="#tab_6">Table 5</ref>. As a consequence DNN+R and DNN confidently recognize more shogi-NEs, which makes their recall higher than that of CRFs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Results and Discussion</head><p>From <ref type="table" target="#tab_6">Table 5</ref> we see that DNN+R is better than DNN. Followings are examples of shogi-NEs which DNN+R successfully recognized but DNN failed: Ot tag for "tataki," which means dropping a pawn in front of a piece of the opponent, and Mn tag for "tsumero" (threatmate). By referring to the game state, DNN+R was better at understanding the game situation and resulted better performance than DNN, the text-based NER.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we proposed a method for referring to the real world to improve NER in a specialized domain. Our method adds an SAE to a text-based DNN for NER. We first pre-train the SAE using only real world information, and then we train the entire DNN from sentences annotated with NEs and accompanied by real world information.</p><p>In our experiments, we used shogi (Japanese chess) as the example. The dataset consists of pairs of a game state and commentary sentences on it annotated with 21 shogi NE tags. We con- ducted NER experiments and showed that refer- ring to the real world improves NER accuracy.</p><p>Our method has the potential to be applied to various NER problems, such as general NER with pictures and financial NER with stock charts, by changing the SAE features. An interesting area of future work is preparing datasets in these domains and testing our method on them. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Deep neural networks for shogi NER.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Game state features.</figDesc><graphic url="image-1.png" coords="4,73.56,64.38,217.95,154.01" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Usage</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>…Figure 3 :</head><label>3</label><figDesc>Figure 3: Building stacked-auto-encoder.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Tag Meaning Hu Human Tu Turn Po Position Pi Piece Ps Piece specifier</head><label></label><figDesc></figDesc><table>Mc 

Move compliment 

Pa 

Piece attribute 

Pq 

Piece quantity 

Re 

Region 

Ph 

Phase 

St 

Strategy 

Ca 

Castle 

Me 

Move eval. 

Mn 

Move name 

Ee 

Eval. element 

Ev 

Evaluation 

Ti 

Time 

Ac 

Player action 

Ap 

Piece action 

Ao 

Other action 

Ot 

Other notion 

Table 1: The named entity tag set. 

tion game, so we can completely specify a game 
state by the positions of the pieces on the board 
and the captured pieces held by on both sides. 
Many matches between professional players 
have been recorded, and many game states have 
commentaries made for fans by other professional 
players. 
A game commentary corpus 1 (Mori et al., 2016) 
defines 21 types of NEs, which are called shogi-
NEs, as listed in Table 1. The words in the com-
mentary sentences in the corpus are annotated with 
BIO-style tags. B, I, and O stand for beginning, 
intermediate, and others, respectively. B or I are 
used for representing the beginning or intermedi-
ate words of an NE as extension like Hu-B. And O 
is used for representing words that are not part of 
any NEs. Therefore there are 43 = 21 × 2 + 1 BIO 
tags. 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Text features for DNN/CRF NER. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 : Game commentary corpus specifications.</head><label>3</label><figDesc></figDesc><table>Layer 
0 
1 
2 
3 
4 
5 
Dimension 2,282 1,000 500 200 100 50 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Dimensions of the SAE layers. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 5 : NER results.</head><label>5</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="1"> http://www.ar.media.kyoto-u.ac.jp/ data/game/</note>

			<note place="foot" n="2"> In the target language in the experiments, Japanese, the types are hiragana, katakana, kanji, number, symbol, and combinations of them.</note>

			<note place="foot" n="3"> Tsuboi et al. (2008) extended conditional random fields to be trained from partially annotated data. One can extend sequence labeling DNN (RNN or LSTM) in a similar way. This is, however, clearly out of the scope of this paper.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported by JSPS Grants-in-Aid for Scientific Research Grant Numbers 26540190 and 25280084. We are also grateful to Professor Yoshimasa Tsuruoka and Mr. Hirotaka Kameko for their valuable comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A neural probabilistic language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rejean</forename><surname>Ducharme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Jauvin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1137" to="1155" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Greedy layer-wise training of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Popovici</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>B. Schölkopf, J. C. Platt, and T. Hoffman</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2007" />
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="153" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Multimodal distributional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bruni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">K</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="1" to="47" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A Japanese chess commentary corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinsuke</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atsushi</forename><surname>Ushiku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tetsuro</forename><surname>Sasada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hirotaka</forename><surname>Kameko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshimasa</forename><surname>Tsuruoka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Conference on Language Resources and Evaluation</title>
		<meeting>the Tenth International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Neural reranking improves subjective quality of machine translation: NAIST at WAT2015</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makoto</forename><surname>Morishita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Nakamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Asian Translation (WAT2015)</title>
		<meeting>the 2nd Workshop on Asian Translation (WAT2015)<address><addrLine>Kyoto, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Multimodal deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ngiam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Machine Learning</title>
		<meeting>the 28th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="689" to="696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar, October</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Combining geometric, textual and visual features for predicting prepositions in image descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnau</forename><surname>Ramisa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josiah</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emmanuel</forename><surname>Dellandrea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesc</forename><surname>Moreno-Noguer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Gaizauskas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="214" to="220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Introduction to the conll-2003 shared task: Language-independent named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><forename type="middle">F</forename><surname>Tjong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kim</forename><surname>Sang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fien De</forename><surname>Meulder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Conference on Computational Natural Language Learning</title>
		<meeting>the Seventh Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="142" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Named entity recognizer trainable from partially annotated data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tetsuro</forename><surname>Sasada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinsuke</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatsuya</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoko</forename><surname>Yamakata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference Pacific Association for Computational Linguistics</title>
		<meeting>the Eleventh International Conference Pacific Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Biomedical named entity recognition using conditional random fields and rich feature sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Burr</forename><surname>Settles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Joint Workshop on Natural Language Processing in Biomedicine and its Applications</title>
		<meeting>the International Joint Workshop on Natural Language Processing in Biomedicine and its Applications</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="33" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning grounded meaning representations with autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carina</forename><surname>Silberer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Maryland</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2014-06" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="721" to="732" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning continuous phrase representations and syntactic parsing with recursive neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Deep Learning and Unsupervised Feature Learning Workshop-NIPS</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Semantic compositionality through recursive matrix-vector spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brody</forename><surname>Huval</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012-07" />
			<biblScope unit="page" from="1201" to="1211" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Parsing with compositional vector grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ng</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-08" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="455" to="465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Recursive deep models for semantic compositionality over a sentiment treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Perelygin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-10" />
			<biblScope unit="page" from="1631" to="1642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multimodal learning with deep boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ruslan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="2222" to="2230" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The genia corpus: an annotated research abstract corpus in molecular biology domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuka</forename><surname>Tateisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin-Dong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoko</forename><surname>Ohta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the HLT</title>
		<meeting>the HLT</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="73" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Training conditional random fields using incomplete annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuta</forename><surname>Tsuboi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hisashi</forename><surname>Kashima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinsuke</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroki</forename><surname>Oda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Computational Linguistics</title>
		<meeting>the 22nd International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="897" to="904" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Neural networks leverage corpuswide information for part-of-speech tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuta</forename><surname>Tsuboi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014-10" />
			<biblScope unit="page" from="938" to="950" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Automatic sentence generation from images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshitaka</forename><surname>Ushiku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatsuya</forename><surname>Harada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasuo</forename><surname>Kuniyoshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th Annual ACM International Conference on Multimedia</title>
		<meeting>the 19th Annual ACM International Conference on Multimedia</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1533" to="1536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Corpus-guided sentence generation of natural images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yezhou</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ching</forename><forename type="middle">Lik</forename><surname>Teo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiannis</forename><surname>Aloimonos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
