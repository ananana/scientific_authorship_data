<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:57+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Enemy in Your Own Camp: How Well Can We Detect Statistically-Generated Fake Reviews-An Adversarial Study</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>August 7-12, 2016. 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Hovy</surname></persName>
							<email>dirk.hovy@hum.ku.dk</email>
							<affiliation key="aff0">
								<orgName type="department">Center for Language Technology</orgName>
								<orgName type="institution">University of Copenhagen</orgName>
								<address>
									<postCode>2300</postCode>
									<settlement>Copenhagen</settlement>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">The Enemy in Your Own Camp: How Well Can We Detect Statistically-Generated Fake Reviews-An Adversarial Study</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="351" to="356"/>
							<date type="published">August 7-12, 2016. 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Online reviews are a growing market, but it is struggling with fake reviews. They undermine both the value of reviews to the user, and their trust in the review sites. However, fake positive reviews can boost a business, and so a small industry producing fake reviews has developed. The two sides are facing an arms race that involves more and more natural language processing (NLP). So far, NLP has been used mostly for detection, and works well on human-generated reviews. But what happens if NLP techniques are used to generate fake reviews as well? We investigate the question in an adversarial setup, by assessing the detectability of different fake-review generation strategies. We use generative models to produce reviews based on meta-information, and evaluate their effectiveness against deception-detection models and human judges. We find that meta-information helps detection, but that NLP-generated reviews conditioned on such information are also much harder to detect than conventional ones.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Online reviews written by customers are a boom- ing market. Several companies cater to a wide variety of audiences, supplying-among others- reviews for restaurants (Yelp), travel (TripAdvi- sor), businesses (Trustpilot), and specialized com- munities, such as beer (RateBeer). While the rev- enue of the providers is in the billions of dollars, the currency this industry is built on is consumer trust. The majority of consumers uses such re- views to inform themselves before buying. <ref type="bibr">1</ref> On-line review companies therefore put considerable effort into maintaining this trust, by addressing the greatest threat to consumer trust (and therefore income)-fake reviews.</p><p>Identifying fake reviews is a natural fit for NLP, since they presumably contain linguistic cues that indicate their nature. Indeed, a number of previ- ous works have dealt with the detection of fake reviews <ref type="bibr">(Jindal and Liu, 2007;</ref><ref type="bibr" target="#b0">Badaskar et al., 2008;</ref><ref type="bibr" target="#b6">Mackiewicz, 2008;</ref><ref type="bibr">Jindal et al., 2010;</ref><ref type="bibr" target="#b8">Ott et al., 2011;</ref><ref type="bibr" target="#b4">Fornaciari and Poesio, 2014</ref>). How- ever, in those cases, human writers were produc- ing reviews to fool a human audience, not an NLP model. The detection models were therefore able to exploit the regularities resulting from the writ- ers' tendency to follow a pattern to minimize their effort.</p><p>Writing fake reviews has become a lucrative business <ref type="bibr" target="#b12">(Streitfeld, 2012)</ref>, and so there is now an arms race going on between producers and detec- tors <ref type="bibr" target="#b10">(Roberts, 2012)</ref>. What if fake review writ- ers become aware of the ways to game a detection algorithm? <ref type="bibr">2</ref> As NLP technology becomes more common, we should expect to also see fake re- views generated by NLP models. This pits tech- nology against technology.</p><p>In this paper, we explore the impact fake review generation has on NLP models' ability to detect them, and an ethical challenge in our development of NLP technology: the fact that it can be used for both sides <ref type="bibr">(Hovy and Spruit, 2016)</ref>.</p><p>Our contributions We set up an adversarial evaluation approach inspired by <ref type="bibr" target="#b11">(Smith, 2012)</ref>  <ref type="figure">Figure 1</ref>: Age distribution of gaming reviews for men and women in the US how well a logistic regression model can distin- guish real from fake reviews from both models under two settings (the model has access to meta- information or not), and how well human judges can detect fake reviews generated by the model with meta-information.</p><p>Our results indicate that fake review generation could be a serious problem for detection mecha- nisms that solely rely on textual features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data</head><p>We use data extracted from the American and British versions of the review site Trustpilot. <ref type="bibr">3</ref> It comprises reviews for a variety of online busi- nesses, as well as information about users' age and gender. <ref type="bibr">4</ref> We extracted all reviews that contained the full set of meta-information. We lower-case and tokenize by words, but leave reviews intact, rather than splitting them up into sentences. This results in 120,976 review instances. We reserve 10,000 for evaluation purposes, and use the rest to induce our adversarial generative models, and to derive features for the detection model (see be- low).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Review Generation Models</head><p>The basic approach is a simple Markov chain with a sufficiently large horizon to generate fluent re- views. Such an n-gram language model (LM) is a function that assigns probability to any sentence S, where S is a sequence w 0 , w 1 , · · · , w n , and</p><formula xml:id="formula_0">P (S) = N i P (w i |w i−n:i−1 )</formula><p>w 0 is a special (sequence of) start token(s), n is the size of the Markov horizon, and</p><formula xml:id="formula_1">w i−1:i−(n−1) a) Start W1 W2 Wn … G A C γ N Wi b) Start W1 W2 Wn … G A C γ N Wi</formula><p>Figure 2: Regular n-gram Markov chain LM (top) and conditioned LM (bottom). γ based on empirically-observed gender distribution in data is the sequence of preceding words in context. The model is depicted in <ref type="figure">Figure 2</ref> a). Since this is a generative model, it can not only be used to assign probability to observed sentences, but also gener- ate new sentences based on the model parameters.</p><p>However, extra-linguistic information, if avail- able, can improve classification performance ( <ref type="bibr" target="#b13">Volkova et al., 2013;</ref><ref type="bibr">Hovy, 2015)</ref>, and fake- review detection models often also exploit meta- information about the author and their behavior ( <ref type="bibr">Lim et al., 2010)</ref>, looking for irregularities. We therefore use a generative story that assumes that people of different age and gender review different things, which in turn influences the type of busi- ness reviewed, and the choice of words. This as- sumption is borne out in the data (cf. <ref type="figure">Figure 1)</ref>. We extend this model by conditioning on latent variables age (A), gender (G), and review category (C). <ref type="bibr">5</ref> In the generative story of this model, we first draw a user from one of the two genders in our data, select an age based on gender-specific age distributions, and choose a review category depen- dent on the two previous variables. We then then generate a sentence conditioned on all of these set- tings and the Markov horizon. Our model is de- picted as plate diagram in <ref type="figure">Figure 2</ref> b) (we omit the start token and the Markov horizon for clarity). It can formally be written as:</p><formula xml:id="formula_2">P (S|G, A, C) =P (G) · P (A|G) · P (C|G, A) · N i P (w i |w i−n:i−1 , C, G, A)</formula><p>5 These factors could of course be extended to cover other information, including ratings. We do not condition on rat- ings here, but a commercial system for fake reviews would presumably be restricted to positive scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>352</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CATEGORY AGE GROUP SEX TEXT</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hotels</head><p>30-45 F i ordered a new toner for our printer and after price matching the best i could find they also honoured a free delivery on top .</p><p>Computer Accessories 45-60 M this is a company that takes customer care seriously . we re- ceived really impressive service when we contacted the com- pany . <ref type="table">Table 1</ref>: Generated examples from unconditional (top) and conditional (bottom) LM.</p><p>We can now use either model to generate fake reviews. In both cases, we use a Markov hori- zon of 6 words, i.e., a 7-gram model. For the unconditioned LM, meta-information is generated at random. This simulates a fake-review writer who is unaware of the context effects, but knows that companies might take profile information into account. Two examples are shown in <ref type="figure">Figure 1</ref>. Both examples are fluent, but the unconditioned one suffers from two problems: somewhat stream- of-consciousness-like sentences and a for human readers obvious mismatch between the category and the discussed topic.</p><p>Conditional LMs, on the other hand, suffer from a certain sparsity: the more meta-information we condition on, the sparser the n-gram counts be- come. They are therefore more likely to faithfully re-generate the training data. We use interpolation between genders, but this could also be addressed with a wide variety of techniques <ref type="bibr" target="#b1">(Chen and Goodman, 1998)</ref>.</p><p>Even though the classifier does not have access to the training data, we want to make the task as difficult as possible, so we remove all duplicates, as well as any generated reviews that do not end in a punctuation mark, that exceed 200 words, or that have a category not contained in our real-review test set, and select from the rest by lowest entropy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In our experiments, we pit an adversary (i.e., the two LMs we experiment with) against a judge (a classifier or human annotator). The goal of the ad- versary is to produce fake reviews that convince the judge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Logistic Regression Model</head><p>As classifier, we use a logistic regression model, regularized with L 2 norm, and fit it on a data set of 10,000 true reviews and a varying amount of fake reviews. In one setting, we use 1600 fake re- views , based on current estimates of 16% <ref type="bibr" target="#b5">(Luca and Zervas, 2015)</ref>. In a second setting, we use 10,000 fake reviews, a scenario where 50% of all reviews are fake. Given the ease of generating fake reviews with the models presented here, the rate could quickly go up in the future, so this ration gives a bound on how much our detection models could decline.</p><p>The base features of the classifier are word n- grams, with n ranging from 1 to 4. Depend- ing on the setting, we also add meta-information features, including combinations of the n-grams with each category (e.g., category=Hotels &amp; word="soft bed"), and the average PMI score for the words in the sentence and each cate- gory (e.g., PMI(Hotels, soft bed)). That way, we hope to capture mismatches between the stated category and the review content.</p><p>We measure F1 performance over 5-fold strati- fied cross-validation.</p><p>Initially, we would like to establish whether conditioning LMs on demographic information has any effect on detection. For this purpose, we compare the performance of the logistic regression model on (1) a test set including fake reviews generated by an unconditioned 7-gram LM and (2) a test set whose fake reviews have been conditioned on meta-information. In both cases, the detector has only access to the base features, i.e., ignores demographic information. This is equivalent to a situation where the judge can only see the text, not the meta information.</p><p>As mentioned before, though, many companies employ meta-information in order to capture fake reviews, and if a spammer knew this, they could simply generate some meta-information. The question is: does this meta-information have to follow a coherent generative story? Intuitively, we expect the answer to be "yes": we would be sur- prised to see a teenager review retirement homes.</p><p>To test this assumption, we compare the per- formance of the classifier when having access to the base features plus meta-information under two settings: (3) with each piece of meta-information generated independently at random, and (4) with meta-information generated as part of our genera- tive process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Human Judges</head><p>The first experiment tests the detectability of fake reviews by statistical means. How hard is it for humans, though, to distinguish the fake reviews generated by this model from real reviews, and do they exploit meta-information?</p><p>To answer these questions, we also conduct a human judges study on Crowdflower <ref type="bibr">6</ref> . We se- lect 200 items at random (100 real reviews and 100 from the conditional model, half of each with meta-information), and ask annotators to rate them as real or fake. Judges were not informed about the nature of the reviews, only advised to use their best judgement. The task involved 8 test questions to bar bad annotators from entering. 76 unique judges participated, and rated the task as relatively difficult (3.5/5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>Bear in mind that this is an adversarial setup: we are trying to improve the fake reviews to "trick" the judge into producing as many false positives as possible. A low F1-score thus means that the respective LM has managed to fool the classifier. <ref type="table">Table 2</ref> shows the results. Note also that the fake reviews are generated independent of the classifi- cation model, i.e., the generative LM does not take the classification model into account.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Logistic Regression Model</head><p>In order to assess whether the differences in per- formance are statistically significant, we conduct a bootstrap sampling test <ref type="bibr" target="#b3">(Efron and Tibshirani, 1993</ref>) with 10,000 repetitions on the overall pre- dictions.</p><p>The numbers are generally in a high range, which is encouraging, since it means that our mod- els can detect fake reviews fairly reliably. How- ever, we also see that the conditional models in- troduced here quickly become significantly harder to detect than the regular LM.</p><p>Adding meta-information leads to sometimes small, but always significant increases in perfor-  <ref type="table">Table 2</ref>: Model performance (F1) with different amounts of information on reviews generated by regular or conditional model under two conditions mance. This effect is especially pronounced in the regular LMs, since the detection model is able to pick up on the mismatch between category and text content.</p><p>As the number of fake reviews grows, though, detection gets more difficult, and the rift between the two generation models becomes more appar- ent: at 50% fake reviews, the conditional LM is almost twice as hard to detect as the regular LM when using meta-information.</p><p>Feature Analysis Finally, we analyze the fea- tures (word-based and meta-information) to find the most predictive elements of fake reviews. For each feature, we average over all folds of our cross-validation. Features which are selected fre- quently, irrespective of the exact training condi- tions, can be assumed to be robust predictors.</p><p>Unsurprisingly, the most predictive features are PMI(gender, ·) and PMI(category, ·), followed by gender-and age-specific words (gender=M &amp; word="delivery", age-group=3 &amp; word="."), category- specific words (category=Package Service &amp; word="parcel"), and indi- vidual words (service, easy, quick)</p><p>For the unconditional models, the PMI-category coefficients dominate other features in a power- law distribution, while for the conditional model, the PMI-age score is only slightly ahead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Human Judges</head><p>The general tendency among human judges was to assume reviews are real: overall, 87% of the indi- vidual answers judged a review to be real. That is, only a minority of judges suspected fraud, irre- spective of whether they had access to the meta- information or not. Whatever signal the logistic regression model picks up seems to be more sub- tle than what the average human can perceive.</p><p>This tendency plays out in the F1 scores (see <ref type="table" target="#tab_3">Table 3</ref>): human judges have a much lower detec- tion rate than the logistic regression model, even though the availability of meta-information im- proves performance here as well.</p><p>These results hold whether we treat each vote as an individual item or aggregating the five votes for each instance by an item-response model <ref type="bibr">(Hovy et al., 2013</ref>). In the latter case, the performance for both conditions and the average increases, more so for the instances without meta-information, but still not reaching the same level.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Reviews are a rich source of studies for NLP, and a variety of recent papers <ref type="bibr" target="#b7">(McAuley et al., 2012;</ref><ref type="bibr" target="#b2">Danescu-Niculescu-Mizil et al., 2013;</ref><ref type="bibr" target="#b9">Reschke et al., 2013;</ref><ref type="bibr">Jurafsky et al., 2014;</ref><ref type="bibr">Hovy et al., 2015)</ref> have explored it. <ref type="bibr" target="#b0">Badaskar et al. (2008)</ref> also use real and fake re- views and LMs, but in almost exactly the opposite setup: they select features that have high discrim- inative power in distinguishing real from fake re- views to include in their LMs. However, they use a review corpus that is more than an order of magni- tude smaller, focus on tri-and quad-gram features, and do not take meta-information into account.</p><p>The work of <ref type="bibr" target="#b4">Fornaciari and Poesio (2014)</ref> is similar in that they also deal with fake review de- tection. However, they do not use an adversarial setup, but focus on the use of an item-response model to detect fake-review writers. Their corpus is considerably smaller than ours, but the detection rate they report is similar to the one we find when not using meta-information.</p><p>To our knowledge, only Lappas (2012) has taken the view from the adversary's point of view, although the paper does not generate fake reviews, but assesses the presence of several defined mea- sures of meretriciousness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We have investigated the detectability of fake re- views generated with meta-information. We find that (1) using access to meta-information can sig- nificantly improve the detection of fake reviews, and (2) generated reviews conditioned on meta- information are considerably harder to detect than the ones generated without. We also see that sta- tistical models fare better than human judges. Our results indicate the viability of an adversarial setup to test detection tasks, but also highlight the fact that NLP techniques can be used for either side. We should therefore be more vigilant and willing to play devil's advocate, pitting potential models as adversaries against our solutions. <ref type="bibr">Dirk Hovy and Shannon L. Spruit. 2016. Beyond Privacy:</ref> The Social Impact of Natural Language Pro- cessing. In Proceedings of the 54th Annual Meet- ing of the Association for Computational Linguis- tics. ACL, Association for Computational Linguis- tics. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>6 https://crowdflower.com 16% FAKE JUDGE COND. LM REG. LM p &lt; 0.01</head><label>6</label><figDesc></figDesc><table>words only 
88.27 
87.89 
no 
+meta-info 
88.92 
92.42 
yes 

p &lt; 0.01 
yes 
yes 

50% FAKE 

words only 
75.52 
72.78 
yes 
+meta-info 
77.40 
88.43 
yes 

p &lt; 0.01 
yes 
yes 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Human performance (F1) with different 
amounts of information on reviews generated by 
conditional model 

</table></figure>

			<note place="foot" n="1"> http://www.business2community.com/ infographics/impact-online-reviews</note>

			<note place="foot" n="3"> www.trustpilot.com 4 For a more detailed description of the data, see Hovy et al. (2015).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The author would like to thank the members of the COASTAL group and the anonymous reviewers for their detailed comments and suggestions, and Noah Smith for pointing out a missing reference. This research was funded under the ERC Starting Grant LOWLANDS No. 313695.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Identifying real or fake articles: Towards better language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Badaskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shilpa</forename><surname>Arora</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third International Joint Conference on Natural Language Processing</title>
		<meeting>the Third International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>II</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">An empirical study of smoothing techniques for language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanley</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Goodman</surname></persName>
		</author>
		<idno>TR-10-98</idno>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
		<respStmt>
			<orgName>Harvard University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">No country for old members: User lifecycle and linguistic change in online communities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Danescu-Niculescu-Mizil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd international conference on World Wide Web</title>
		<meeting>the 22nd international conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="307" to="318" />
		</imprint>
	</monogr>
	<note>International World Wide Web Conferences Steering Committee</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">An introduction to the bootstrap</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bradley</forename><surname>Efron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Tibshirani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>Chapman &amp; Hall</publisher>
			<pubPlace>Boca Raton, FL</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Identifying fake amazon reviews as learning from crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomes</forename><surname>Fornaciari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimo</forename><surname>Poesio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 14th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="279" to="287" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Fake it till you make it: Reputation, competition, and yelp review fraud</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Luca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Zervas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Harvard Business School NOM Unit Working Paper</title>
		<imprint>
			<biblScope unit="page" from="14" to="20" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Reviewer motivations, bias, and credibility in online reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jo</forename><surname>Mackiewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Handbook of research on computer mediated communication</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="252" to="266" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning attitudes and attributes from multiaspect reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 12th International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1020" to="1025" />
		</imprint>
	</monogr>
	<note>Data Mining (ICDM)</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Finding deceptive opinion spam by any stretch of the imagination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey T</forename><surname>Hancock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="309" to="319" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Generating recommendation dialogs by extracting information from user reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Reschke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Vogel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st annual meeting of the ACL</title>
		<meeting>the 51st annual meeting of the ACL</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="499" to="504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Amazon sues people who charge $5 for fake reviews. Fortune</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff John</forename><surname>Roberts</surname></persName>
		</author>
		<ptr target="http://fortune.com/2015/10/19/amazon-fake-reviews/" />
		<imprint>
			<date type="published" when="2012-10-19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Adversarial evaluation for models of natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Smith</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1207.0245" />
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">The Best Book Reviews Money Can Buy. The New York Times</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Streitfeld</surname></persName>
		</author>
		<ptr target="http://www.nytimes.com/2012/08/26/business/book-reviewers-for-hire-meet-a-demand-for-online-raves.html" />
		<imprint>
			<date type="published" when="2012-08-25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Exploring demographic language variations to improve multilingual sentiment analysis in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svitlana</forename><surname>Volkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1815" to="1827" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
