<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:00+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Mixed Feelings: Natural Text Generation with Variable, Coexistent Affective Categories</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 15-20, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lee</forename><surname>Kezar</surname></persName>
							<email>kezarlee@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Mathematics and Computer Science Department</orgName>
								<orgName type="institution">Rhodes College Memphis</orgName>
								<address>
									<region>Tennessee</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Mixed Feelings: Natural Text Generation with Variable, Coexistent Affective Categories</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of ACL 2018, Student Research Workshop</title>
						<meeting>ACL 2018, Student Research Workshop <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="141" to="145"/>
							<date type="published">July 15-20, 2018</date>
						</imprint>
					</monogr>
					<note>141</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Conversational agents, having the goal of natural language generation, must rely on language models which can integrate emotion into their responses. Recent projects outline models which can produce emotional sentences, but unlike human language , they tend to be restricted to one af-fective category out of a few (e.g. Zhao et al. (2018)). To my knowledge, none allow for the intentional coexistence of multiple emotions on the word or sentence level. Building on prior research which allows for variation in the intensity of a singular emotion (Ghosh et al., 2017), this research proposal outlines an LSTM (Long Short-Term Memory) language model which allows for variation in multiple emotions simultaneously.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In closing her landmark paper on affective com- puting, Rosalind Picard charges researchers of artificial intelligence with a task. She writes, "Computers that will interact naturally and intelligently with humans need the ability to at least recognize and express affect" <ref type="bibr" target="#b4">(Picard, 1995)</ref>. While Picard herself has since spent her time primarily studying the physiology behind emotion and health, there is also a strong relationship between linguistics and emotion. The task for computer scientists who study this relationship is to symbolize and express emotion through verbal language alone.</p><p>Although this goal easy to articulate, accom- plishing it has proven to be quite challenging. However, in the same way AI researchers acquired valuable insight from reviewing models of cellular neuroscience to produce an artificial neural net- work, perhaps we can demystify affect generation by reviewing psychological models which build on neuro-biological findings in regards to human emotion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Need for Affective Mixing</head><p>I will now summarize two key ideas from these findings: emotion/language dynamic and classifi- cation of emotion.</p><p>First, emotion usually precedes language. In describing phenomenal consciousness as it pertains to emotion, Carroll Izard wrote that "an emotion feeling remains functional and motivational without being symbolized and made accessible in reflective consciousness via language" <ref type="bibr" target="#b2">(Izard, 2009)</ref>. One might support this claim by noting how complex emotional qualia feels and how rather limited language can be. For example, how accurate is it to say that "Alice is happy"? To what extent is she happy? Is it the same happiness that she feels when being in good company, or in favorable weather? Do they only differ in magnitude, or also along some other dimension? Or as a second example, can you recall a moment where you couldn't describe how you were feeling, but felt it nonetheless? Clearly, emotion is rather difficult to express in simple words. Yet, recent affective generation techniques tend to presume that they fall neatly into one of five or six discrete categories ( <ref type="bibr" target="#b11">Zhao et al., 2018)</ref>. Recently, researchers added nuance to affect generation via variation in intensity ( <ref type="bibr" target="#b1">Ghosh et al., 2017</ref>), but to my knowledge no model adds nuance along extra dimensions, such as other emotions.</p><p>Second, emotion is usually the conflation of two distinct phenomena: "basic emotions" and "dynamic emotion-cognition interactions" <ref type="bibr" target="#b2">(Izard, 2009)</ref>. The basic emotions are linked to old evolu- tionary stimuli and are more automatic (e.g. fear as a response mechanism to avoid danger). That is to say, basic emotions have little involvement with cognition. Emotion schemas, on the other hand, result directly from interactions between cognition and emotion. This type of emotion is underscored by research which casts emotion and cognition as interdependent processes <ref type="bibr" target="#b7">(Storbeck and Clore, 2007)</ref>, closely mirroring Picard's insis- tence that intelligence is comprised of emotion.</p><p>The categorizations usually found in lexicons (e.g. Linguistic Inquiry and Word Count or LIWC) treat words as stimuli which humans re- spond to with emotions. This model aligns closely with basic emotions, and supposes language pre- cedes emotion. However, in actuality humans tend to incorporate cognitive processes such as memory and perspective-taking, allowing us to have multi- ple emotions simultaneously. If we are to use this as inspiration for generating affective text algorith- mically, we might then permit the AI to intention- ally express multiple emotions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Project Overview</head><p>Having established this need for emotional intelligence in AI (including natural language processing), and reviewed psychological research in this area, we might conclude that emotions should not be modeled as singular, discrete categories but continuous and constantly mixing.</p><p>This project aims to create an algorithm which is capable of taking some priming text and the desired affective state which can vary along different emotional dimensions simultaneously, and produce a corresponding utterance. This algorithm is primarily meant for conversational agents, but could be adapted for other purposes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Use Cases</head><p>Mixing emotions are not only more realistic to human emotion, since they allow for significantly more flexibility in expression, but also more helpful for specific applications. I will introduce three such applications here.</p><p>First, the ability to mix emotions in a contin- uous fashion allows for conversational agents to gradually and imperceptibly shift the tone of a conversation toward a new tone. Human tendency to mirror the emotions of others through empathy would make this an effective strategy to improve attitude and emotional outlook.</p><p>Second, mixing emotions in this way also al- lows for an extra layer of nuance in conversational practice, as we are affected by emotional language as often as we produce it. For example, in sim- ulating a realistic conversation, the deliverance of emotionally-charged statements should cause the computer to respond appropriately. However, models which treat emotion as discrete categories would "overreact" and abruptly switch from one emotion to another.</p><p>Third, realistic personality can be introduced as a tendency to hover near or avoid specific points. Naturally, the conversational agent will vary in emotion, but ultimately return to some default state. For example, if an agent were to express optimistic personality, it might impose some min- imum on the joy vector, and a maximum on the sadness and anger vectors. This is not possible with models that suppose emotions are discrete categories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.4">Algorithm Overview</head><p>We can encapsulate this goal with a broad formula</p><formula xml:id="formula_0">g(p, e) = w (1)</formula><p>where p is the priming text, e is a quadruple of values such that</p><formula xml:id="formula_1">e x ∈ R | x ∈ {j, s, f, a}, 0 ≤ e x ≤ 1<label>(2)</label></formula><p>which correspond to the intensity of joy, sadness, fear, anger, respectively; and w is an array of words and punctuation which represent the algorithm's response to p with emotional state e. The emotional categories are selected to correspond with the DepecheMood database, which I will describe in section 3.2. The priming text can be a sentence fragment which the user seeks to complete or a natural sentence which the algorithm is meant to respond to.</p><p>The purpose for g is to be embedded into a conversational setting with improvements on parsing and production. I will not detail what this embedding looks like for sake of brevity and coherency.</p><p>An example set of sentences generated across a gradient beginning at high happiness (e j ≈ 1), low fear (e f ≈ 0) and ending at moderate happiness (e j ≈ 0.5), high fear (e f ≈ 1) might look like this:</p><p>• I am happy to go to work today</p><p>• I am content to go . . .</p><p>• I am hesitant to go . . .</p><p>• I am worried to go . . .</p><p>• I am nervous to go . . .</p><p>• I am anxious to go . . . since anxiety is, in a sense, the combination of fear and partial excitement or happiness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>In the last two years, different models have been used to create conversational agents which can express affect. Namely, the Emotional Chatting Machine (ECM) ( <ref type="bibr" target="#b11">Zhao et al., 2018)</ref> and Affect- LM ( <ref type="bibr" target="#b1">Ghosh et al., 2017</ref>). These models are motivated by the psychological finding that agents with subtle expressivity can improve the affective state of the user ( <ref type="bibr" target="#b5">Prendinger et al., 2005</ref>). These projects utilize an array of emotional categories including liking, happiness, sadness, disgust, anger, and anxiety.</p><p>To accomplish this, different language mod- els which utilize machine learning algorithms have been crafted and tested for accuracy and grammaticality. The most popular include feed- forward neural networks, recurrent neural net- works (RNNs), and long short-term memory (LSTM) neural networks ( <ref type="bibr" target="#b10">Sundermeyer et al., 2015</ref>). Among these, the LSTM model is notably superior for establishing long-term dependencies in text, and reducing the vanishing gradient prob- lem found in RNNs. This is the method used by <ref type="bibr" target="#b1">(Ghosh et al., 2017)</ref>, with an additional net- work for including emotionally-charged words of the desired strength. Importantly, they accommo- dated and tested for loss in grammaticality, which was predicted for expressions of intense emotion but not low emotions, where standard LSTMs typ- ically suffice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">LSTM Language Model</head><p>The LSTM Language Model allows for the use of all prior words as evidence in predicting the next best word, w t . We can write this prediction as a probability like so:</p><formula xml:id="formula_2">p(w M 1 ) = M i=1 p(w i |w i−1 1 )<label>(3)</label></formula><p>for a sequence of M words. We can utilize the LSTM as a function l of the prior words w i−1 1 to calculate p(w i ). An additional bias term b i corre- sponding to unigram occurrence of w i may be in- cluded to favor more common words, as in <ref type="bibr" target="#b1">Ghosh et al. (2017)</ref>. The output layer of l summed with this bias term then pass through a softmax activa- tion function to normalize the outputs, producing</p><formula xml:id="formula_3">p(w i |w i−1 1 ) = softmax(l(w i−1 1 ) + b i ) (4)</formula><p>The algorithm would simply repeat this calcu- lation, each step incrementing i and selecting the most probable word, until a period is produced in- dicating the end of the sentence and completion of the algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Incorporating Affective Data</head><p>The DepecheMood lexicon contains affective data for over 13,500 words, each rated along a contin- uous interval <ref type="bibr">[0,</ref><ref type="bibr">1]</ref> for eight affective dimensions: {Fear, Amusement, Anger, Annoyance, Indiffer- ence, Happiness, Inspiration, <ref type="bibr">Sadness} (Staiano and Guerini, 2014)</ref>. As a comical American exam- ple, DepecheMood rates the word "president" as {0.2, 0.346, 0.626, 1.0, 0.528, 0.341, 0.0, 0.115} respectively -that is, moderately infuriating, never inspiring, and completely annoying.</p><p>For this project, I would use the more typical categories of joy, sadness, fear, and anger. This lexicon contrasts other popular lexicons with affective data, e.g. LIWC, in that these ratings are continuous along <ref type="bibr">[0,</ref><ref type="bibr">1]</ref>. This property allows for more precise matching to the affective state, and movement along a gradient between the four dimensions.</p><p>In addition to the bias term from the previous section, we would account for affect by intro- ducing a third term d(w i , e) which favors words most affectively similar to the desired output.</p><p>Graphically, this equation maps the vocabulary V into four-dimensional space corresponding to each word's emotional valences, and calculates the dis- tance between e, a point in this space, and each word w i ∈ V . This inverse distance function can be written as such:</p><formula xml:id="formula_4">d(w i , e) = softmax   1 |e| j=1 (w ij − e j ) 2   (5)</formula><p>where j enumerates each of the four affective di- mensions, w ij is the intensity along that dimension e j is the target intensity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Optimizing d(w i , e)</head><p>In its current form, this function requires a calcu- lation for each w i ∈ V which is has a subideal time complexity of O(n). We can reduce this to O(log n) by estimating e to its nearest neighbor in V (a O(log n) operation, as I will soon explain), whose distances to every other word can be precomputed and accessed via a hash table O(1). This replacement can be done without loss of accuracy due to the density of the data set.</p><p>To find e nearest neighbor in V , we can uti- lize a modified QuadTree algorithm to reduce the search space to some arbitrary n much smaller than 13,500. To briefly review, this algorithm or- ganizes a set of data points into a hierarchical tree with leaf nodes containing a list of less than n points ( <ref type="bibr" target="#b0">Finkel and Bentley, 1974)</ref>. Querying this tree to find nearby data points has been empirically shown to take on average O(log n) time, a modest improvement over O(n).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Avoiding Over-Emphasis</head><p>As <ref type="bibr" target="#b11">Zhao et al. (2018)</ref> noted in their ECM project, "emotional responses are relatively short lived and involve changes." These changes, which the au- thors call "emotion dynamics", involve modeling emotions as quantities which decays at each step. This avoids the problem of over-emphasizing the input e by repeatedly expressing the same state, unintentionally compounding its strength. Their implementation of this decay involves updating e j in (5) by subtracting w ij for each dimension j. Therefore, upon completion, e would be close to <ref type="bibr">[0,</ref><ref type="bibr">0,</ref><ref type="bibr">0,</ref><ref type="bibr">0]</ref>.</p><p>Preliminary experimentation would certainly need to reveal the appropriate weights for g, d, and b i such that precision of emotion does not sacrifice grammaticality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Implementation, Training, and Review</head><p>For the LSTM, we would follow the suggestion of <ref type="bibr" target="#b8">Sundermeyer et al. (2012)</ref> and implement a net- work using TensorFlow 1 with two hidden layers of 200 nodes: the first being a projection layer of standard neural network units and the second be- ing hidden layer of LSTM units. The output layer would also have 200 nodes.</p><p>The same authors later suggest training the net- work using the cross-entropy error criterion, using the function</p><formula xml:id="formula_5">F (A) = − M i=1 log p A (w i |w i−1 i−n+1 ) (6)</formula><p>where M is the size of the training corpus <ref type="bibr" target="#b10">(Sundermeyer et al., 2015)</ref>. For a stochastic gradient descent algorithm, we can obtain a gradient using epochwise backpropogation through time (BPTT) on the first pass, and update the weights on the sec- ond pass as specified in <ref type="bibr" target="#b9">Sundermeyer et al. (2014)</ref>. The training corpus for this algorithm would need only be some collection of natural dialogue. This can be catered to the environment it will be used in, but for our purposes the Ubuntu Dialogue Corpus will be used for its generality, accessibil- ity, dyadic nature, and size ( <ref type="bibr" target="#b3">Lowe et al., 2016)</ref>.</p><p>Additional funds have been secured to utilize Amazon's Mechanical Turk to analyze loss in grammaticality and verify the manipulation of e by simply assessing sentences along a Likert scale and comparing this data to the intended affect. I predict that certain categories and combinations will be harder to express in text than others, result- ing in higher variability and weaker correlations. For example, anger and sadness (an approxima- tion of remorse) may be rather easy to express, but joy and sadness may be difficult. Visualizing these strengths and weaknesses will be an interesting re- flection of the English language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this research proposal, I have given a brief overview of a natural language generation algo- rithm which is capable of producing utterances ex- pressive of multiple emotional dimensions simul- taneously. The DepecheMood lexicon enables the mapping of words into n-dimensional space, al- lowing us to prefer words which minimize the dis- tance between it and the target affective state along the four emotional dimensions.</p><p>After clarifying implementation details such as LSTM node construction, neural architecture, and use of the training corpus, this algorithm has the potential to add further nuance to our current mod- els of generating affect which are consistent with psychological and neuro-biological findings.</p></div>
			<note place="foot" n="1"> http://www.tensorflow.org</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Quad trees: A data structure for retrieval on composite keys</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Bentley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Informatica</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Affect-lm: A neural language model for customizable affective text generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sayan</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Chollet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Laksana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Louis-Philippe</forename><surname>Morency</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Scherer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACL</title>
		<imprint>
			<biblScope unit="page" from="634" to="642" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Emotion theory and research: Highlights, unanswered questions, and emerging issues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carroll</forename><forename type="middle">E</forename><surname>Izard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual Review of Psychology</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="1" to="25" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nissan</forename><surname>Pow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Iulian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pineau</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Affective computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rosalind</forename><forename type="middle">W</forename><surname>Picard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<publisher>Perceptual Computing Section</publisher>
		</imprint>
		<respStmt>
			<orgName>Massachusetts Institute of Technology</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Using human physiology to evaluate subtle expressivity of a virtual quizmaster in a mathematical game</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helmut</forename><surname>Prendinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junichiro</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitsuru</forename><surname>Ishizuka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human-Computer Studies</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="231" to="245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Depechemood: a lexicon for emotion analysis from crowd-annotated news</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacopo</forename><surname>Staiano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Guerini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">On the interdependence of cognition and emotion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Storbeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerald</forename><forename type="middle">L</forename><surname>Clore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Emotion</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1212" to="1237" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Lstm neural networks for language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Sundermeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralf</forename><surname>Schlter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>Interspeech</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Rwthlm-the rwth aachen university neural network language modeling toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Sundermeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralf</forename><surname>Schlter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Interspeech</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2093" to="2097" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">From feedforward to recurrent lstm neural networks for language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Sundermeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralf</forename><surname>Schlter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on Audio, Speech, and Language Processing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Emotional chatting machine: Emotional conversation generation with internal and external memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
