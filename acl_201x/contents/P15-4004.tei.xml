<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:49+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">KeLP: a Kernel-based Learning Platform for Natural Language Processing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 26-31, 2015. c 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Filice</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">( †) Dept. of Civil Engineering and Computer Science Engineering ( ‡) Dept. of Electronic Engineering () Dept. of Enterprise Engineering University of Roma</orgName>
								<address>
									<addrLine>Tor Vergata</addrLine>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Castellucci</surname></persName>
							<email>castellucci@ing.uniroma2.it</email>
							<affiliation key="aff0">
								<orgName type="institution">( †) Dept. of Civil Engineering and Computer Science Engineering ( ‡) Dept. of Electronic Engineering () Dept. of Enterprise Engineering University of Roma</orgName>
								<address>
									<addrLine>Tor Vergata</addrLine>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Croce</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">( †) Dept. of Civil Engineering and Computer Science Engineering ( ‡) Dept. of Electronic Engineering () Dept. of Enterprise Engineering University of Roma</orgName>
								<address>
									<addrLine>Tor Vergata</addrLine>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Basili</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">( †) Dept. of Civil Engineering and Computer Science Engineering ( ‡) Dept. of Electronic Engineering () Dept. of Enterprise Engineering University of Roma</orgName>
								<address>
									<addrLine>Tor Vergata</addrLine>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">KeLP: a Kernel-based Learning Platform for Natural Language Processing</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of ACL-IJCNLP 2015 System Demonstrations</title>
						<meeting>ACL-IJCNLP 2015 System Demonstrations <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="19" to="24"/>
							<date type="published">July 26-31, 2015. c 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Kernel-based learning algorithms have been shown to achieve state-of-the-art results in many Natural Language Processing (NLP) tasks. We present KELP, a Java framework that supports the implementation of both kernel-based learning algorithms and kernel functions over generic data representation, e.g. vectorial data or discrete structures. The framework has been designed to decouple kernel functions and learning algorithms: once a new kernel function has been implemented it can be adopted in all the available kernel-machine algorithms. The platform includes different Online and Batch Learning algorithms for Classification, Regression and Clustering, as well as several Kernel functions, ranging from vector-based to structural kernels. This paper will show the main aspects of the framework by applying it to different NLP tasks.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Most of the existing Machine Learning (ML) plat- forms assume that instances are represented as vectors in a feature space, e.g. <ref type="bibr" target="#b11">(Joachims, 1999;</ref><ref type="bibr" target="#b10">Hall et al., 2009;</ref><ref type="bibr" target="#b4">Chang and Lin, 2011)</ref>, that must be defined beforehand. In Natural Language Pro- cessing (NLP) the definition of a feature space of- ten requires a complex feature engineering phase. Let us consider any NLP task in which syntactic information is crucial, e.g. Boundary Detection in Semantic Role Labeling <ref type="bibr" target="#b2">(Carreras and M` arquez, 2005)</ref>. Understanding which syntactic patterns should be captured is non-trivial and usually the resulting feature vector model is a poor approxi- mation. Instead, a more natural approach is oper- ating directly with the parse tree of sentences. Ker- nel methods <ref type="bibr" target="#b22">(Shawe-Taylor and Cristianini, 2004</ref>) provide an efficient and effective solution, allow- ing to represent data at a more abstract level, while their computation still looks at the informative properties of them. For instance, Tree Kernels ( <ref type="bibr" target="#b5">Collins and Duffy, 2001</ref>) take in input two syntac- tic parse trees, and compute a similarity measure by looking at the shared sub-structures.</p><p>In this paper, KELP, a Java kernel based learn- ing platform is presented. It supports the imple- mentation of Kernel-based learning algorithms, as well as kernel functions over generic data repre- sentations, e.g. vectorial data or discrete struc- tures, such as trees and sequences. The framework has been designed to decouple data structures, ker- nel functions and learning algorithms in order to maximize the re-use of existing functionalities: as an example, a new kernel can be included inherit- ing existing algorithms and vice versa. KELP sup- ports XML and JSON serialization of kernel func- tions and algorithms, enabling the agile definition of kernel-based learning systems without writing additional lines of code. KELP can effectively tackle a wide variety of learning problems. In par- ticular, in this paper we will show how vectorial and structured data can be exploited by KELP in three NLP tasks: Twitter Sentiment Analysis, Text Categorization and Question Classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Framework Overview</head><p>KELP is a machine learning library completely written in Java. The Java language has been cho- sen in order to be compatible with many Java NLP/IR tools that are developed by the commu-nity, such as Stanford CoreNLP 1 , OpenNLP 2 or Lucene <ref type="bibr">3</ref> . KELP is released as open source soft- ware under the Apache 2.0 license and the source code is available on github <ref type="bibr">4</ref> . Furthermore it can be imported via Maven. A detailed documentation of KELP with helpful examples and use cases is available on the website of the Semantic Analytics Group 5 of the University of Roma, Tor Vergata.</p><p>In this Section, a closer look at the implementa- tion of different kinds of data representations, ker- nel functions and kernel-based learning algorithms is provided.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data Representations</head><p>KELP supports both vectorial and structured data to model learning instances.</p><p>For ex- ample, SparseVector can host a Bag-of- Words model, while DenseVector can rep- resent data derived from low dimensional em- beddings. TreeRepresentation can model a parse tree and SequenceRepresentation can be adopted to represent sequences of charac- ters or sequences of words. Moreover, the plat- form enables the definition of more complex forms of data such as pairs, which are useful in model- ing those problems where instances can be natu- rally represented as pairs of texts, such as question and answer in Q/A re-ranking ( <ref type="bibr" target="#b20">Severyn and Moschitti, 2013</ref>), text and hypothesis in textual entail- ment ( <ref type="bibr" target="#b25">Zanzotto et al., 2009</ref>) or sentence pairs in paraphrasing detection ( <ref type="bibr" target="#b9">Filice et al., 2015</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Kernels</head><p>Many ML algorithms rely on the notion of similar- ity between examples. Kernel methods <ref type="bibr">(ShaweTaylor and Cristianini, 2004</ref>) leverage on the so-called kernel functions, which compute the similarity between instances in an implicit high- dimensional feature space without explicitly com- puting the coordinates of the data in that space. The kernel operation is often cheaper from a com- putational perspective and specific kernels have been defined for sequences, graphs, trees, texts, images, as well as vectors.</p><p>Kernels  exploited at the same time. This flexibil- ity is completely supported by KELP, which is also easy to extend with new kernels. Among the currently available implementations of ker- nels, there are various standard kernels, such as LinearKernel, PolynomialKernel or RbfKernel. A large set of kernels specifically designed for NLP applications will be described in the following section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Kernels for NLP</head><p>Many tasks in NLP cannot be properly tackled considering only a Bag-of-Words approach and re- quire the exploration of deep syntactic aspects. In question classification the syntactic information is crucial has largely demonstrated in <ref type="bibr" target="#b7">(Croce et al., 2011</ref>). In Textual Entailment Recognition or in Paraphrase Detection a pure lexical similarity be- tween text and hypothesis cannot capture any dif- ference between Federer won against Nadal and Nadal won against Federer. A manual definition of an artificial feature set accounting for syntax is a very expensive operation that requires a deep knowledge of the linguistic phenomena character- izing a specific task. Moreover, every task has specific patterns that must be considered, making a manual feature engineering an extremely com- plex and not portable operation. How can linguis- tic patterns characterizing a question be automat- ically discovered? How can linguistic rewriting rules in paraphrasing be learnt? How can seman- tic and syntactic relations in textual entailment be automatically captured? An elegant and efficient approach to solve NLP problems involving the us- age of syntax is provided by tree kernels <ref type="bibr" target="#b5">(Collins and Duffy, 2001</ref>). Instead of trying to design a synthetic feature space, tree kernels directly oper- ate on the parse tree of sentences evaluating the tree fragments shared by two trees. This operation implicitly corresponds to a dot product in the fea- ture space of all possible tree fragments. The di- mensionality of such space is extremely large and operating directly on it is not viable.</p><p>Many tree kernels are implemented in KELP, and they differ by the type of tree fragment considered in the evaluation of the matching structures. In the <ref type="bibr">SubTreeKernel (Collins and Duffy, 2001</ref>) valid fragments are subtrees (ST), i.e. any node of a tree along with all its descendants. A subset tree (SST) ex- ploited by the SubSetTreeKernel is a more general structure since its leaves can be non-  <ref type="bibr">, 2005</ref>) is included in the library, and it allows to compare two texts evaluating the num- ber of common sub-sequences. This implicitly corresponds to operate on the space of all possi- ble N-grams. Kernels operating over pairs, such as the PreferenceKernel (Shen and Joshi, 2003) for re-ranking, are also included in KELP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Machine Learning Algorithms</head><p>In ML, a plethora of learning algorithms have been defined for different purposes, and many variations of the existing ones as well as com- pletely new learning methods are often proposed. KELP provides a large number of learning algo- rithms 6 ranging from batch, e.g. Support Vec- tor Machines <ref type="bibr" target="#b24">(Vapnik, 1995)</ref>, to online learning models, e.g. PassiveAggressive algorithms ( <ref type="bibr" target="#b6">Crammer et al., 2006</ref>), and from linear to kernel- based methods, for tackling classification, regres- sion or clustering tasks. Moreover, algorithms can be composed in meta-learning schemas, like multi-class classification (e.g. One-VS-One and One-VS-All, ( <ref type="bibr" target="#b19">Rifkin and Klautau, 2004)</ref>) and multi-label classification, or can be combined in ensembles. A simple interface taxonomy allows to easily extend the platform with new custom learning algorithms. A complete support for tack- ling NLP tasks is thus provided. For exam- ple, in scenarios where the syntactic informa- tion is necessary for achieving good accuracy, C-SVM or ν-SVM (Chang and Lin, 2011) oper- ating on trees with kernels can be effectively ap- plied. When dealing with large datasets, many efficient learning algorithm can be adopted, like linear methods, e.g</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>. Pegasos (Shalev-Shwartz et al., 2007) or LibLinear, (Fan et al., 2008), or like budgeted kernel-based algorithms, e.g. RandomizedPerceptron (Cesa-Bianchi and</head><p>Gentile, 2006).</p><p>Listing 1: A JSON example.</p><p>{"algorithm" : "oneVsAll", "baseAlgorithm" : { "algorithm" : "binaryCSvmClassification", "c" : 10, "kernel" : { "kernelType" : "linearComb", "weights" : [1,1], "toCombine" : [ { "kernelType" : "norm", "baseKernel" : { "kernelType" : "ptk", "mu" : 0.4, "lambda" : 0.4, "representation" : "parseTree" } }, { "kernelType" : "linear", "representation" : "Bag-of-Words" } ] } } }</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">A JSON example</head><p>Kernel functions and algorithms are serializable in JSON or XML. This is useful for instantiating a new algorithm without writing a single line of Java code, i.e. the algorithm description can be pro- vided in JSON to an interpreter that will instantiate it. Listing 1 reports a JSON example of a kernel- based Support Vector Machine operating in a one- vs-all schema, where a kernel linear combination between a normalized Partial Tree Kernel and a linear kernel is adopted. As the listing shows ker- nels and algorithms can be easily composed and combined in order to create new training models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Case Studies in NLP</head><p>In this Section, the functionalities and use of the learning platform are shown. We apply KELP to very different NLP tasks, i.e. Sentiment Analysis in Twitter, Text Categorization and Question Clas- sification, providing examples of kernel-based and linear learning algorithms. Further examples are available on the KELP website 7 where it is shown how to instantiate each algorithm or kernel via JSON and how to add new algorithms, represen- tations and kernels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Sentiment Analysis in Twitter</head><p>The task of Sentiment Analysis in Twitter has been proposed in 2013 during the SemEval competi- tion ( <ref type="bibr" target="#b17">Nakov et al., 2013</ref>). We built a classifier for the subtask B, i.e. the classification of a tweet with respect to the positive, negative and neutral classes. The contribution of different kernel func- tions is evaluated using the Support Vector Ma- chine learning algorithm. As shown in <ref type="table">Table 1</ref>, we apply linear (Lin), polynomial (Poly) and Gaus- sian (Rbf) kernels on two different data represen- tations: a Bag-Of-Words model of tweets (BoW ) and a distributional representation (W S). The last is obtained by linearly combining the distri- butional vectors corresponding to the words of a message; these vectors are obtained by applying a Skip-gram model ( <ref type="bibr" target="#b15">Mikolov et al., 2013</ref>) with the word2vec tool 8 over 20 million of tweets. The lin- ear combination of the proposed kernel functions is also applied, e.g. Poly Bow +Rbf W S . The mean F1-measure of the positive and negative classes (pn) <ref type="bibr">9</ref> as well as of all the classes (pnn) is shown in <ref type="table">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Text Categorization</head><p>In order to show the scalability of the platform, a second evaluation considers linear algorithms.   We selected the Text Categorization task on the RCV1 dataset ( <ref type="bibr" target="#b12">Lewis et al., 2004</ref>) with the setting that can be found on the LibLinear website <ref type="bibr">10</ref> . In this version of the dataset, CCAT and ECAT are collapsed into a positive class, while GCAT and MCAT are the negative class, resulting in a dataset composed by 20, 242 examples. As shown in Ta- ble 2, we applied the LibLinear, Pegasos and Lin- ear Passive-Aggressive implementations, comput- ing the accuracy and the standard deviation with respect to a 5-fold cross validation strategy.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Question Classification</head><p>The third case study explores the application of Tree Kernels to Question Classification (QC), an inference task required in many Question Answer- ing processes. In this problem, questions writ- ten in natural language are assigned to different classes. A QC system should select the correct class given an instance question. In this setting, Tree Kernels allow to directly model the examples in terms of their parse trees. The reference cor- pus is the UIUC dataset ( <ref type="bibr" target="#b13">Li and Roth, 2002</ref>), in- cluding 5,452 questions for training and 500 ques- tions for test <ref type="bibr">11</ref>    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related Work</head><p>Many software tools for computational linguis- tic research already exist. Tools like Stan- ford CoreNLP or OpenNLP provide a complete pipeline for performing linguistic tasks such as stemming, lemmatization, Part-of-Speech tagging or parsing. They are complementary to KELP: they can be used in the feature extraction phase, while KELP will care about the machine learning part. Regarding other machine learning platforms there are plenty of available possibilities, but for different reasons no one can provide something close to what the proposed library offers.</p><p>Weka ( <ref type="bibr" target="#b10">Hall et al., 2009</ref>) is a collection of ma- chine learning algorithms for data mining tasks. The algorithms can either be applied directly to a dataset or called from Java. It contains vari- ous tools for different data mining activities: data pre-processing, classification, regression, cluster- ing and visualization.</p><p>Mallet <ref type="bibr" target="#b14">(McCallum, 2002</ref>) is more oriented to NLP applications. It is entirely in Java and in- cludes feature extraction tools for converting text into vectors and statistical analysis tools for docu- ment classification, clustering, topic modeling, in- formation extraction, and other machine learning applications to text. Regarding the kernel-based learning both Weka and Mallet leverage on Lib- SVM, and obviously inherit its limits.</p><p>LibSVM <ref type="formula">(</ref> Another very popular Support Vector Machines (SVM) package is SvmLight <ref type="bibr" target="#b11">(Joachims, 1999)</ref>. It is entirely written in C language and its main fea- ture is speed. It solves classification and regres- sion problems, as well as ranking problems. Its efficiency is paid in terms of extensibility: C lan- guage does not allow a fast prototyping of new ma- chine learning kernels or algorithms. Many times in research contexts fast prototyping is more im- portant than performances: the proposed platform has been developed with extensibility in mind.</p><p>The most similar platform to ours is JKernel- Machines ( <ref type="bibr" target="#b18">Picard et al., 2013)</ref>. It is a Java based package focused on Kernel machines. Just like the proposed library, JKernelMachines is primary de- signed to deal with custom kernels that cannot be easily found in standard libraries. Standard SVM optimization algorithms are implemented, but also more sophisticated learning-based kernel combi- nation methods such as Multiple Kernel Learn- ing (MKL). However, many features covered by KELP are not offered by JKernelMachines, just like tree kernels, regression and clustering. More- over, different architectural choices have been ap- plied in KELP in order to support an easier com- position and combination of representations, ker- nels as well as learning algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>This paper presented KELP, a Java framework to support the application of Kernel-based learn- ing methods with a particular attention to Lan- guage Learning tasks. The library implements a large variety of kernel functions used in NLP (such as Tree Kernels or Sequence Kernels) as well as many learning algorithms useful in classification, regression, novelty detection or clustering prob- lems. KELP can be imported via Maven but its usage is not restricted to a Java-compliant environ- ment as it allows to build complex kernel machine based systems, leveraging on JSON/XML inter- faces to instantiate classifiers. The entire frame- work has been designed to support researchers in the development of new kernel functions or algo- rithms, providing a principled decoupling of the data structures in order to maximize the re-use of existing functionalities. The benefits of the pro- posed environment have been shown in three NLP tasks, where results in line with the state-of-the-art have been reached with the simple application of various kernel functions available in KELP.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: a) Constituent parse tree of the sentence Federer won against Nadal. b) some subtrees. c) some subset trees. d) some partial trees. terminal symbols. The SSTs satisfy the constraint that grammatical rules cannot be broken. PartialTreeKernel (Moschitti, 2006) relaxes this constraint considering partial trees (PT), i.e. fragments generated by the application of partial production rules. Examples of different kinds of tree fragments are shown in Figure 1. The SmoothedPartialTreeKernel (SPTK) (Croce et al., 2011) allows to match those fragments that are not identical but that are semantically related, by relying on the similarity between lexical items, e.g. by applying a word similarity metric (e.g. WordNet or word embeddings similarities). The adopted implementation allows to easily extend the notion of similarity between nodes, enabling the implementation of more expressive kernels, as the Compositionally Smoothed Partial Tree Kernel (CSPTK) that embeds algebraic operators of Distributional Compositional Semantics (Annesi et al., 2014). Moreover, the SequenceKernel (Bunescu and Mooney, 2005) is included in the library, and it allows to compare two texts evaluating the number of common sub-sequences. This implicitly corresponds to operate on the space of all possible N-grams. Kernels operating over pairs, such as the PreferenceKernel (Shen and Joshi, 2003) for re-ranking, are also included in KELP.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>7</head><label></label><figDesc>http://sag.art.uniroma2.it/demo-software/kelp/ 8 https://code.google.com/p/word2vec/ 9 pn was the official metric of the SemEval competition.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Kernel</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>, organized in six coarse-grained classes, such as HUMAN or LOCATION. Again, Kernel-based SVM has been evaluated adopting the same setup of (Croce et al., 2011). A pure lex- ical model based on a linear kernel over a Bag-of- Words (BoW) is considered a baseline. The con- tribution of the syntactic information is demon- strated by the results achieved by the Partial Tree Kernel (PTK), the Smoothed Partial Tree Kernels (SPTK) and the Compositionally Smoothed Par- tial Tree Kernel (CSPTK), as shown in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 : Text Categorization Accuracy</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 .</head><label>3</label><figDesc></figDesc><table>Kernel 

Accuracy 
BoW 
87.2% 
PolyBoW 
88.8% 
PTK 
91.6% 
SPTK 
94.6% 
CSPTK 
95.0% 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 : Question Classification Accuracy.</head><label>3</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head></head><label></label><figDesc>Chang and Lin, 2011) is a machine learning platform focusing on Support Vector Ma- chines. It is written in C++ language and it includes different SVM formulations: C-svm, Nu-svm and OneClass-svm, as well as a one- vs-one multi classification schema. It implements also regression support vector solvers. It has been ported in different languages, including Java. The batch learning part of KELP is strongly inspired by LibSVM formulations and implementations. LibSVM is mainly intended for plain users and does not provide any support for extendibility. It can operate only on sparse feature vectors via stan- dard kernel functions. No structured representa- tions are considered.</figDesc><table></table></figure>

			<note place="foot" n="6"> All the algorithms are completely re-implemented in Java and they do not wrap any external library</note>

			<note place="foot" n="10"> http://www.csie.ntu.edu.tw/∼cjlin/ libsvmtools/datasets/ 11 http://cogcomp.cs.illinois.edu/Data/QA/QC/</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Semantic compositionality in tree kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Annesi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Croce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Basili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CIKM 2014</title>
		<meeting>of CIKM 2014<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1029" to="1038" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Subsequence kernels for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Razvan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Bunescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Introduction to the conll-2005 shared task: Semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Carreras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lluís</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth Conference on Computational Natural Language Learning, CONLL &apos;05</title>
		<meeting>the Ninth Conference on Computational Natural Language Learning, CONLL &apos;05<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="152" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Tracking the best hyperplane with a simple budget perceptron</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudio</forename><surname>Nicoì O Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gentile</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 19th Annual Conference on Computational Learning Theory</title>
		<meeting>of the 19th Annual Conference on Computational Learning Theory</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="483" to="498" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">LIBSVM: A library for support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chung</forename><surname>Chih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Jen</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Intelligent Systems and Technology</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">27</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Convolution kernels for natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nigel</forename><surname>Duffy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Online passive-aggressive algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ofer</forename><surname>Dekel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Keshet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shai</forename><surname>Shalev-Shwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="551" to="585" />
			<date type="published" when="2006-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Structured lexical similarity via convolution kernels on dependency trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Croce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Basili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<meeting><address><addrLine>Edinburgh</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Liblinear: A library for large linear classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Wei</forename><surname>Rong-En Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho-Jui</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangrui</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Jen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1871" to="1874" />
			<date type="published" when="2008-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Structural representations for learning relations between pairs of texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Filice</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giovanni</forename><surname>Da San</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Martino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">The weka data mining software: An update. sigkdd explor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eibe</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Pfahringer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Reutemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Making large-scale SVM learning practical</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Kernel Methods-Support Vector Learning</title>
		<editor>B. Schölkopf, C. Burges, and A. Smola</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="169" to="184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Rcv1: A new benchmark collection for text categorization research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">D</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tony</forename><forename type="middle">G</forename><surname>Rose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="361" to="397" />
			<date type="published" when="2004-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning question classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics</title>
		<meeting><address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
	<note>Proceedings of ACL &apos;02, COLING &apos;02</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Mallet: A machine learning for language toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Kachites</forename><surname>Mccallum</surname></persName>
		</author>
		<ptr target="http://mallet.cs.umass.edu" />
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Efficient convolution kernels for dependency and constituent syntactic trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECML</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Semeval-2013 task 2: Sentiment analysis in twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Rosenthal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zornitsa</forename><surname>Kozareva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SemEval 2013</title>
		<meeting>SemEval 2013<address><addrLine>Atlanta, USA. ACL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="312" to="320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Jkernelmachines: A simple framework for kernel machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Picard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Thome</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1417" to="1421" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">In defense of one-vs-all classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Rifkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aldebaro</forename><surname>Klautau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="101" to="141" />
			<date type="published" when="2004-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Automatic feature engineering for answer selection and extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aliaksei</forename><surname>Severyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on EMNLP</title>
		<meeting>the 2013 Conference on EMNLP<address><addrLine>Seattle, USA. ACL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="458" to="467" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Pegasos: Primal estimated sub-gradient solver for SVM</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shalev-Shwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srebro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICML</title>
		<meeting>of ICML</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Kernel Methods for Pattern Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Shawe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Taylor</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nello</forename><surname>Cristianini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">An svm based voting algorithm with application to parse reranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Libin</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><forename type="middle">K</forename><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CoNLL</title>
		<meeting>of CoNLL</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">The Nature of Statistical Learning Theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><forename type="middle">N</forename><surname>Vapnik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<publisher>Springer-Verlag New York, Inc</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A machine learning approach to textual entailment recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Fabio Massimo Zanzotto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Pennacchiotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Lang. Eng</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="551" to="582" />
			<date type="published" when="2009-10" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
