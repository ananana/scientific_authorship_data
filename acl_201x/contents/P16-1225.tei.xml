<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:58+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Finding Non-Arbitrary Form-Meaning Systematicity Using String-Metric Learning for Kernel Regression</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>August 7-12, 2016. 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Darío Gutiérrez</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">UC San Diego</orgName>
								<orgName type="institution" key="instit2">MIT</orgName>
								<orgName type="institution" key="instit3">UC</orgName>
								<address>
									<settlement>San Diego</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Levy</surname></persName>
							<email>rplevy@mit.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">UC San Diego</orgName>
								<orgName type="institution" key="instit2">MIT</orgName>
								<orgName type="institution" key="instit3">UC</orgName>
								<address>
									<settlement>San Diego</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><forename type="middle">K</forename><surname>Bergen</surname></persName>
							<email>bkbergen@ucsd.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">UC San Diego</orgName>
								<orgName type="institution" key="instit2">MIT</orgName>
								<orgName type="institution" key="instit3">UC</orgName>
								<address>
									<settlement>San Diego</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Finding Non-Arbitrary Form-Meaning Systematicity Using String-Metric Learning for Kernel Regression</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2379" to="2388"/>
							<date type="published">August 7-12, 2016. 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Arbitrariness of the sign-the notion that the forms of words are unrelated to their meanings-is an underlying assumption of many linguistic theories. Two lines of research have recently challenged this assumption , but they produce differing characterizations of non-arbitrariness in language. Behavioral and corpus studies have confirmed the validity of localized form-meaning patterns manifested in limited subsets of the lexicon. Meanwhile, global (lexicon-wide) statistical analyses instead find diffuse form-meaning system-aticity across the lexicon as a whole. We bridge the gap with an approach that can detect both local and global form-meaning systematicity in language. In the kernel regression formulation we introduce , form-meaning relationships can be used to predict words&apos; distributional semantic vectors from their forms. Furthermore , we introduce a novel metric learning algorithm that can learn weighted edit distances that minimize kernel regression error. Our results suggest that the English lexicon exhibits far more global form-meaning systematicity than previously discovered, and that much of this systematicity is focused in localized form-meaning patterns.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Arbitrariness of the sign refers to the notion that the phonetic/orthographic forms of words have no relationship to their meanings ( <ref type="bibr" target="#b11">de Saussure, 1916)</ref>. It is a foundational assumption of many theories of language comprehension, production, acquisi- tion, and evolution. For instance, <ref type="bibr" target="#b17">Hockett's (1960)</ref> influential enumeration of the design features of human language ascribes a central role to arbi- trariness in enabling the combination and recom- bination of phonemic units to create new words. <ref type="bibr" target="#b15">Gasser (2004)</ref> uses simulations to show that for large vocabularies, arbitrary form-meaning map- pings may provide an advantage in acquisition. Meanwhile, modular theories of language compre- hension rely upon the duality of patterning to sup- port the independence of the phonetic and seman- tic aspects of language comprehension ( <ref type="bibr" target="#b20">Levelt et al., 1999</ref>). Quantifying the extent to which the ar- bitrariness principle actually holds is important for understanding how language works.</p><p>Language researchers have long noted excep- tions to arbitrariness. Most of these are patterns that occur in some relatively localized subset of the lexicon. These patterns are sub-morphemic because, unlike conventional morphemes, they cannot combine reliably to produce new words. <ref type="bibr">Phonaesthemes (1930)</ref> are one example. A phonaestheme is a phonetic cluster that recurs in many words that have related meanings. One no- table phonaestheme is the onset gl-, which occurs at the beginning of at least 38 English words re- lating to vision: glow, glint, glaze, gleam, etc. <ref type="bibr" target="#b7">(Bergen, 2004)</ref>. At least 46 candidate phonaes- themes have been posited in the linguistics liter- ature, according to a list compiled by <ref type="bibr" target="#b18">Hutchins (1998)</ref>. Iconicity is another violation of arbitrari- ness that can lead to non-arbitrary local regular- ities. Iconicity occurs when the form of a word is transparently motivated by some perceptual as- pect of its referent. Consequently, when several referents share perceptual features, their associ- ated word-forms would tend to be similar as well (to the extent that they are iconic). For instance, <ref type="bibr" target="#b29">Ohala (1984)</ref> conjectures that vowels with high acoustic frequency tend to associate with smaller items while vowels with low acoustic frequency tend to associate with larger items, due to the experiential link between vocalizer size and fre- quency. Systematic iconicity is also manifested in sets of onomatopoeic words that echo similar sounds (e.g., clink, clank). Although these excep- tions to non-arbitrariness differ, in each case, spe- cific form-meaning relationships emerge in a sub- set of the lexicon. We will refer to all such specific localized form-meaning patterns as phonoseman- tic sets.</p><p>In recent decades, behavioral and corpus stud- ies have empirically confirmed the psychological reality and statistical reliability of many phonose- mantic sets that had previously been identified by intuition and observation. Various candidate phonaesthemes have significant effects on reaction times during language processing tasks <ref type="bibr" target="#b18">(Hutchins, 1998;</ref><ref type="bibr" target="#b22">Magnus, 1998;</ref><ref type="bibr" target="#b7">Bergen, 2004)</ref>.  test the statistical significance of the 46 candidates in <ref type="bibr" target="#b18">Hutchins's (1998)</ref> list, and find that 27 of them exhibit more within-category dis- tributional semantic coherence than expected by chance. These results have been replicated using other corpora and distributional semantic models ( <ref type="bibr" target="#b0">Abramova et al., 2013)</ref>. <ref type="bibr" target="#b19">Klink (2000)</ref> shows that sound-symbolic attributes such as those proposed by <ref type="bibr" target="#b29">Ohala (1984)</ref> are associated with human judg- ments about nonwords' semantic attributes, such as smallness or beauty. Using a statistical corpus analysis and WordNet semantic features, Mon- aghan et al. (2014a) examine a similar hypothesis space of sound-symbolic phonological and seman- tic attributes, and reach similar conclusions.</p><p>While these localized studies support the exis- tence of some islands of non-arbitrariness in lan- guage, their results do not address how pervasive non-arbitrariness is at the global level-that is, in the lexicon of a language as a whole. After all, some seemingly non-arbitrary local patterns can be expected to emerge merely by chance. How can we measure whether local phonosemantic pat- terning translates into global phonosemantic sys- tematicity-that is, strong, non-negligible lexicon- wide non-arbitrariness? <ref type="bibr" target="#b35">Shillcock et al. (2001)</ref> in- troduce the idea of measuring phonosemantic sys- tematicity by analyzing the correlation between phonological edit distances and distributional se- mantic distances. In a lexicon of monomor- phemic and monosyllabic English words, they find a small but statistically significant correlation be- tween these two distance measures. <ref type="bibr" target="#b26">Monaghan et al. (2014b)</ref> elaborate on this methodology, show- ing that the statistical effect is robust to different choices of form-distance and semantic-distance metrics. They also look at the effect of leaving out each word in the lexicon on the overall corre- lation measure; from this, they derive a phonose- mantic systematicity measure for each word. In- terestingly, they find that systematicity is diffusely distributed across the words in English in a pattern indistinguishable from random chance. Hence, they conclude that "systematicity in the vocab- ulary is not a consequence of small clusters of sound symbolism." This line of work provides a proof-of-concept that it is possible to detect the phonosemantic systematicity of a language, and confirms that English exhibits significant phonose- mantic systematicity.</p><p>Broadly speaking, both the localized tests of in- dividual phonosemantic sets and the global anal- yses of phonosemantic systematicity challenge the arbitrariness of the sign. However, they at- tribute responsibility for non-arbitrariness differ- ently. The local methods reveal dozens of specific phonosemantic sets that have strong, measurable behavioral effects and statistical signatures in cor- pora. Meanwhile, the global methods find small and diffuse systematicity. How can we reconcile this discrepancy?</p><p>Original Contributions. We attempt to bridge the gap with a new approach that builds off of previous lexicon-wide analyses, making two inno- vations. The first addresses the concern that the lexicon-wide methods currently in use may not be well suited to finding local regularities such as phonosemantic sets, because they make the as- sumption that systematicity exists only in the form of a global correlation between distances in form- space and distances in meaning-space. Instead, we model the problem using kernel regression, a non- parametric regression model. Crucially, in kernel regression the prediction for a point is based on the predictions of neighboring points; this enables us to conduct a global analysis while still cap- turing local, neighborhood effects. As in previ- ous work, we represent word-forms by their or- thographic strings, and word-meanings by their semantic vector representations as produced by a distributional semantic vector space model. The goal of the regression is then to learn a mapping from string-valued predictor variables to vector- valued target variables that minimizes regression error in the vector space. Conveniently, our model allows us to produce predictions of the semantic vectors associated with both words and nonwords.</p><p>Previous work may also underestimate system- aticity in that it weights all edits (substitutions, insertions, and deletions) equally in determining edit distance. A priori, there is no reason to be- lieve this is the case-indeed, the work on in- dividual phonosemantic sets suggests that some orthographic/phonetic attributes are more impor- tant than others for non-arbitrariness. To address this, we introduce String-Metric Learning for Ker- nel Regression (SMLKR), a metric-learning algo- rithm that is able to learn a weighted edit distance metric that minimizes the prediction error in ker- nel regression.</p><p>We find that SMLKR enables us to recover more systematicity from a lexicon of monomor- phemic English words than reported in previous global analyses. Using SMLKR, we propose a new measure of per-word phonosemantic system- aticity. Our analyses using this systematicity mea- sure indicate that specific phonosemantic sets do contribute significantly to the global phonoseman- tic systematicity of English, in keeping with previ- ous local-level analyses. Finally, we evaluate our systematicity measure against human judgments, and find that it accords with raters' intuitions about what makes a word's form well suited to its mean- ing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background &amp; Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Previous Approaches to Finding</head><p>Lexicon-Wide Systematicity Measuring Form, Meaning, and Systematicity.  <ref type="formula">(2006)</ref> study distance measures based on a selected set binary phonological features, with similar results. Phonosemantic systematicity is then measured as the correlation between all the pairwise semantic distances and all the pairwise string distances.</p><p>Hypothesis Testing. In this line line of work, statistical significance of the results is assessed using the Mantel test, a permutation test of the correlation between two sets of pairwise distances <ref type="bibr" target="#b23">(Mantel, 1967)</ref>. The test involves randomly shuf- fling the assignments of semantic vectors to word- strings in the lexicon. We can think of each form- meaning shuffle as a member of the set of all pos- sible lexicons. Next, the correlation between the semantic distances and the string distances is com- puted under each reassignment. An empirical p- value for the true lexicon is then derived by per- forming many shufflings, and comparing the cor- relation coefficients measured under the shuffles to the correlation coefficient measured in the true lex- icon. Under the null hypothesis that form-meaning assignments are arbitrary, the probability of ob- serving a form-meaning correlation of at least the magnitude actually observed in the true lexicon is asymptotically equal to the proportion of reassign- ments that produce greater correlations than the true lexicon. , and find significant form-meaning correla- tions in both.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Kernel Regression</head><p>In contrast to previous studies, we study form- meaning systematicity using a kernel regression framework. Kernel regression is a nonparametric supervised learning technique that is able to learn highly nonlinear relationships between predictor variables and target variables. Rather than assum- ing any particular parametric relationship between the predictor and target variables, kernel regres- sion assumes only that the value of the target vari-able is a smooth function of the value of the pre- dictors. In other words, given a new point in pre- dictor space, the value of the target at that point can reasonably be estimated by the value of the targets at points that are nearby in the predictor space. In this way, kernel regression is analo- gous to an exemplar model. We performed ker- nel regression on our lexicon using the Nadaraya- Watson estimator <ref type="bibr" target="#b27">(Nadaraya, 1964)</ref>. Given a data set D of vector-valued predictor variables {x i } N i=1 , and targets {y i } N i=1 , the Nadaraya-Watson estima- tor of the target for sample i isˆy</p><formula xml:id="formula_0">isˆ isˆy i = ˆ y(x i ) = j =i k ij y j j =i k ij ,<label>(1)</label></formula><p>where k ij is the kernel between point i and point j.</p><p>A commonly used kernel is the exponential kernel:</p><formula xml:id="formula_1">k ij = k(x i , x j ) = exp(−d(x i , x j )/h),</formula><p>where d(·, ·) is a distance metric and h is a band- width that determines the radius of the effective neighborhood around each point that contributes to its estimate. For our purposes we use the Lev- enshtein string edit distance metric <ref type="bibr" target="#b21">(Levenshtein, 1966)</ref>. The Levenshtein edit distance between two strings is the minimum number of edits needed to transform one string into the other, where an edit is defined as the insertion, deletion, or substitution of a single character. Using this edit distance and semantic vectors derived from a distributional se- mantic model, the Nadaraya-Watson estimator can estimate the position in the semantic vector space for each word in the lexicon. The exponential edit distance kernel has been useful for modeling be- havior in many tasks involving word similarity and neighborhood effects; see, for example the Gen- eralized Context Model <ref type="bibr" target="#b28">(Nosofsky, 1986)</ref>, which has been applied to word identification, recogni- tion, and categorization, to inflectional morphol- ogy, and to artificial grammar learning <ref type="bibr" target="#b3">(Bailey and Hahn, 2001</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Metric Learning for Kernel Regression</head><p>In kernel regression, the bandwidth h of the kernel function must be fine-tuned by testing out many different bandwidths. Moreover, for many tasks there is no reason to assume that all of the dimen- sions of a vector-valued predictor are equally im- portant. This is problematic for conventional ker- nel regression, as the quality of its predictions is wholly reliant on the appropriateness of the given distance metric. <ref type="bibr" target="#b39">Weinberger and Tesauro (2007)</ref> introduce met- ric learning for kernel regression (MLKR), an al- gorithm that can learn a task-specific Mahalanobis (i.e., weighted Euclidean) distance metric over a real-vector-valued predictor space, in which small distances between two vectors imply similar target values. They note that this metric induces a kernel function whose parameters are set entirely from the data. Specifically, MLKR can learn a weight matrix W for a Mahalanobis metric that optimizes the leave-one out mean squared error of kernel re- gression (MSE), defined as:</p><formula xml:id="formula_2">L(D) = 1 N N i=1 L(ˆ y i , y i ) = 1 N N i=1ˆy i=1ˆi=1ˆy i − y i 2 2 ,</formula><p>wherê y i is estimated usingˆyusingˆ usingˆy j for all i = j, as in Eq. 1.</p><p>In MLKR, the weighted distance metric is learned using stochastic gradient descent. As an added benefit, MLKR is implicitly able to learn an appropriate kernel bandwidth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">String-Metric Learning for Kernel</head><p>Regression (SMLKR)</p><p>Our novel contribution is an extension of MLKR to situations where the predictor variables are not real-valued vectors, but strings, and the distance metric we wish to learn is a weighted Leven- shtein edit distance. Vector-valued representa- tions of the strings themselves would only ap- proximately preserve edit distance. Fortunately, it turns out that we do not need vector-valued rep- resentations of the strings at all. Define the mini- mum edit-distance path as the smallest-length se- quence of edits that is needed to transform one string into another. Observe that the weighted edit distance between two strings s i and s j can be rep- resented as the weighted sum of all the edits that must take place to transform one string into the other along the minimum edit-distance path (Bel- let et al., 2012). In turn, these edits can be rep- resented by a vector ν ij constructed as in <ref type="figure" target="#fig_2">Fig 1,</ref> while the weights can be represented by a vector w = (w 1 , ..., w M ) T : Each entry of ν ij corresponds to a particular type of edit operation (e.g., substitution of character a for character b). The value assigned to each entry is the count of the total number of times that the corresponding edit operation must be applied to achieve transformation of string i to string j along the minimum edit-distance path.</p><formula xml:id="formula_3">d W L (s i , s j ) = M m=1 w m ν ijm = w T ν ij .</formula><p>We note that ν ij does not admit a unique rep- resentation, since there are multiple ways to trans- form one string to another in the same number of edits, using different edit operations. However, we adopt the convention that some class of edit opera- tions always takes priority over another-e.g., that deletions always occur before substitutions. This then enables us to specify ν ij uniquely. We also adopt the convention that the weights for edit op- erations are symmetric-e.g., that the weight for substituting character a for character b is the same as the weight for substituting character b for char- acter a, so we represent every such pair of edit op- erations by a single entry in ν ij .</p><p>As in MLKR, our goal is to minimize the leave- one-out MSE, 1 where k ij = e −w T ν ij . The gradi- ent of the regression error for MSE is</p><formula xml:id="formula_4">∂L(D) ∂w = 2 N N i=1 (y i − ˆ y i ) ∂ ˆ y i ∂w where ∂ ˆ y i ∂w = j =i (y j − ˆ y i ) T k ij ν ij j =i k ij .</formula><p>Using this exact gradient, we can find the edit weights that minimize the loss function. We wish to constrain the weights to be non- negative, since weighted edit distance only <ref type="bibr">1</ref> We attained similar results minimizing mean cosine er- ror. The gradient for mean cosine error is</p><formula xml:id="formula_5">∂L(D) ∂w = 1 N N i=1 (ˆ yiyi − L(yi, ˆ yi)ˆ yi) ˆ yi 2 ∂ ˆ yi ∂w .</formula><p>makes sense with nonnegative weights. Thus, to minimize the loss we use the limited- memory Broyden-Fletcher-Goldfarb-Shanno al- gorithm for box constraints (L-BFGS-B) <ref type="bibr" target="#b9">(Byrd et al., 1995)</ref>, a quasi-Newton method that allows bounded optimization. We made a Python implementation of SMLKR available at http://bit.ly/25Hidqg/.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Setup</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data</head><p>Lexicon. A principal concern is the possibility that our models may detect morphemes rather than sub-morphemic units. To minimize this concern, we adopted an approach similar to that of <ref type="bibr" target="#b35">Shillcock et al. (2001)</ref>, of training our model only on monomorphemic words. Monomorphemic words were selected by cross-referencing the mor- phemic analyses contained in the CELEX lex- ical database ( <ref type="bibr">Baayen et al., 1996</ref>) with the morphemic analyses contained in the etymolo- gies of the Oxford English Dictionary Online (http://www.oed.com). Then, we went through the filtered list and removed any remain- ing polymorphemic words as well as place names, demonyms, spelling variants, and proper nouns. Finally, words that were not among the 40,000 most frequent non-filler word types in the corpus were excluded. The final lexicon was composed of 4,949 word types.</p><p>Corpus and Semantic Model. The corpus we used to train our semantic model is a concate- nation of the UKWaC, BNC, and Wikipedia cor- pora <ref type="bibr" target="#b12">(Ferraresi et al., 2008;</ref><ref type="bibr" target="#b8">BNC Consortium, 2007;</ref><ref type="bibr" target="#b32">Parker et al., 2011</ref>). We trained our vector- space model on this corpus using the Word2Vec ( <ref type="bibr" target="#b24">Mikolov et al., 2013)</ref>, as instantiated in the GEN- SIM package <ref type="bibr">( ˇ Rehůřek and Sojka, 2010</ref>) for Python using default parameters. We produced 100-dimensional word-embedding vectors using the SkipGram algorithm of Word2Vec and normal- ized the 100-dimensional vector for each word so that its Euclidean norm was equal to 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Training</head><p>We trained SMLKR on the 100-dimensional Word2Vec embeddings using L-BGFS-B, and placing non-negativity constraints on the weights w. We let SMLKR run until convergence, as de-termined by the following criterion:</p><formula xml:id="formula_6">|L (k−1) − L (k) | max(|L (k−1) |, |L (k) |) =</formula><p>where L (k) is the loss at the k th iteration of learn- ing, and we set = 2 × 10 −8 . We randomly ini- tialized the L-BGFS-B algorithm 10 times to avoid poor local minima, and kept the solution with the lowest loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Model Analysis</head><p>Weighted Edit Distance Reveals More Non- Arbitrariness. We first assessed whether the structure found by kernel regression could arise merely by arbitrary, random pairings of form and meaning (i.e., strings and semantic vectors). We adopt a Monte Carlo testing procedure similar to the Mantel test of §2.1. We first randomly shuffled the assignment of the semantic vectors of all the words in the lexicon. We then trained SMLKR on the shuffled lexicon just as we did on the true lex- icon. We measured the mean squared error of the SMLKR prediction. Out of 1000 reassignments, none produced a prediction error as small as the prediction error in the true lexicon (i.e., empirical p-value of p &lt; .001).</p><p>For comparison, we analyzed our corpus us- ing the correlation method of <ref type="bibr" target="#b26">Monaghan et al. (2014b)</ref>. In our implementation, we measured the correlation between the pairwise cosine distances produced by Word2Vec and pairwise orthographic edit distances for all pairs of words in our lexicon. The correlation between the Word2Vec semantic distances and the orthographic edit distances in our corpus was r = 0.0194, similar to the correla- tion reported by Monaghan et al. of r = 0.016 be- tween the phoneme edit distances and the seman- tic distances in the monomorphemic English lexi- con. We also looked at the correlation between the weighted edit distances produced by SMLKR and the Word2Vec semantic distances. The correlation between these distances was r = 0.0464; thus, the weighted edit distance captures more than 5.7 times as much variance as the unweighted edit dis- tance. Further, using the estimated semantic vec- tors produced by the SMLKR model, we can ac- tually produce new estimates of the semantic dis- tances between the words. The correlation be- tween these estimated semantic distances and the true semantic distances was r = 0.1028, reveal- ing much more systematicity than revealed by the simple linear correlation method. The Mantel test with 1,000 permutations produced significant em- pirical p-values for all correlations (p &lt; .001).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Systematicity Not Evenly Distributed Across</head><p>Lexicon. What could be accounting for the higher degree of systematicity detected with SM- LKR? Applying a more expressive model could result in a better fit simply because incidental but inconsequential patterns are being captured. Con- versely, SMLKR could be finding phonosemantic sets which the correlation method of <ref type="bibr" target="#b26">Monaghan et al. (Monaghan et al., 2014b</ref>) is unable to de- tect. We investigated further by determining what was driving the better fit produced by SMLKR. Monaghan et al. measure per-word systematicity as the change in the lexicon-wide form-meaning correlation that results from removing the word from the lexicon. The more the correlation de- creases from removing the word, the more sys- tematic the word is, according to this measure. They compared the distribution of this systematic- ity measure across the words in the lexicon to the distribution of systematicity in lexicons with ran- domly shuffled form-meaning assignments, and found that the null hypothesis that the distribu- tions were identical could not be rejected. From this, they conclude that the observed systematicity of the lexicon is not a consequence only of small pockets of sound symbolism, but is rather a feature of the mappings from sound to meaning across the lexicon as a whole. However, it is possible that their methods may not be sensitive enough to find localized phonosemantic sets.</p><p>We developed our own measure of per-word systematicity by measuring the per-word regres- sion error of the SMLKR model. We presume words with lower regression errors to be more sys- tematic. A list of the words with the lowest per- word regression error in our corpus can be found in <ref type="table">Table 1</ref>. Notably, many of these words, such as fluff, flutter, and flick, exhibit word beginnings or word endings that have been previously identified as phonaesthemes <ref type="bibr" target="#b18">(Hutchins, 1998;</ref>. Others exhibit regular onomatopoeia, such as clang and croak.</p><p>We decided to investigate the distribution of systematicity across two-letter word-beginnings in our lexicon using a permutation test. The goal of the permutation test is to estimate a p-value for the  <ref type="table">gurgle  emu  tunic  tingle  nexus  decay  hoop  asylum  skirmish  chink  ethic  scroll  swirl  odd  silk  ladle  slime  prom  flick  snare  knob  wobble  scarlet  havoc  tangle  deem  irate  knuckle  balustrade  veer  glitter  envoy  wear  twig  scrape  phone  fluff  essay  surgeon  rasp  ambit  hiccup  quill  echo  bowel  flutter  onus  sack  whirl  exam  lens  croak  pirouette  hovel  squeal  kohl  challenge  clang  chandelier  box   Table 1</ref>: Left: Most systematic words according to SMLKR. Center: Most systematic words accord- ing to the leave-one-out correlation method pro- posed by <ref type="bibr" target="#b26">Monaghan et al. (2014b)</ref>. Right: Ran- domly generated list for comparison.</p><p>likelihood that each set of words sharing a word beginning would exhibit the mean regression error it exhibits, if systematicity is randomly distributed across the lexicon. For each set S ω of words with word-beginning ω, we measured the mean SM- LKR regression error of the words in S ω . To get an empirical p-value for each S ω with cardinality greater than 5 (i.e., more than 5 word tokens), we randomly chose 10 5 sets of words in the lexicon with the same cardinality, and measured the mean SMLKR regression error for each of these random sets. If r of the randomly assembled sets had a lower mean regression error than S ω did, we as- sign an empirical p-value of r 10 5 to S ω . A his- togram of empirical p-values is in <ref type="figure" target="#fig_4">Fig. 2</ref>. From the figure, it seems clear that the p-values are not uniformly distributed; instead, an inordinate num- ber of word-beginnings exhibit mean errors that are unlikely to occur if error is distributed arbitrar- ily across word-beginnings.</p><p>We can confirm this observation statistically. On the assumption that systematicity is arbitrarily distributed across word-beginnings, the empirical p-values of the permutation test should approxi- mately conform to a Unif(0, 1) distribution. We can test this hypothesis using a χ 2 test on the nega- tive logarithms of the p-values <ref type="bibr" target="#b14">(Fisher, 1932)</ref>. Us- ing this test, we reject the hypothesis that the p- values are uniformly distributed with p &lt; .0001 (χ 2 156 = 707.8). The particular word-beginnings Onset p-value fl- <ref type="table">Table 2</ref>: Word-beginnings with mean errors lower than predicted by random distribution of errors across lexicon. Bold are among the phonaes- themes identified by <ref type="bibr" target="#b18">Hutchins (1998)</ref>. Italics were identified by .</p><formula xml:id="formula_7">&lt; 1 × 10 −4 sn- &lt; 1 × 10 −4 sw- &lt; 1 × 10 −4 tw- &lt; 1 × 10 −4 gl- 1 × 10 −3 sl- 1 × 10 −3 bu- 1 × 10 −3 mu- 2 × 10 −3 wh- 2 × 10 −3 sc-/sk- 3 × 10 −3</formula><p>with statistically significant empirical p-values (p &lt; .05 after Benjamini-Hochberg (1995) cor- rection for multiple comparisons) are in <ref type="table">Table  2</ref>. Eight of these ten features are among the 18 two-letter onsets posited to be phonaesthemes by <ref type="bibr" target="#b18">Hutchins (1998)</ref>. For comparison,  identified eight of Hutchins's 18 two-letter word-beginning candidate phonaesthemes (and 12 two-letter word-beginnings overall) as statistically significant, though they restricted their hypothe- sis space to only 50 pre-specified word-beginnings and word-endings. We are able to identify just as many candidate phonaesthemes, but with a much less restricted hypothesis space of candidates (225 rather than the 50 in Otis and Sagi's analysis) and with a general model not specifically attuned to finding phonaesthemes in particular, but rather systematicity in general.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Behavioral Evaluation of Systematicity Measure</head><p>We empirically tested whether the systematicity measure based on SMLKR regression error ac- cords with na¨ıvena¨ıve human judgments about how well-suited a word's form is to its meaning (its "phonosemantic feeling") <ref type="bibr" target="#b36">(Stefanowitsch, 2002</ref>). We recruited 60 native English-speaking partici- pants through Mechanical Turk, and asked them to judge the phonosemantic feeling of the 60 words in <ref type="table">Table 1</ref> on a sliding scale from 1 to 5. <ref type="bibr">2</ref> We used Cronbach's α to measure inter-annotator reliabil- ity at α = 0.96, indicating a high degree of inter- annotator reliability <ref type="bibr" target="#b10">(Cronbach, 1951;</ref><ref type="bibr" target="#b16">George, 2000</ref>). The results showed that the words in the SMLKR list were rated higher for phonoseman- tic feeling than the words in the Correlation and Random lists. We fit a parametric linear mixed- effects model to the phonosemantic feeling judg- ments ( <ref type="bibr" target="#b2">Baayen et al., 2008)</ref>, as implemented in the lme4 library for R. As fixed effects, we en- tered the list identity (SMLKR, Correlation, Ran- dom), the word length, and the log frequency of the word in our corpus. Our random effects struc- ture included a random intercept for word, and random subject slopes for all fixed effects, with all correlations allowed (a "maximal" random- effects structure ( <ref type="bibr" target="#b4">Barr et al., 2013)</ref>). Including list identity in the maximal mixed-effects model significantly improved model fit (χ 2 11 = 126.08, p &lt; 10 −6 ). Post-hoc analysis revealed that the SMLKR list elicited average suitability judgments that were 0.49 points higher than the Random list (p &lt; 10 −6 ) and 0.59 points higher than the Cor- relation list (p &lt; 10 −6 ). Post-hoc analysis did not find a significant difference in suitability judg- ments between the Random and Correlation lists (p &gt; .16). <ref type="bibr">3</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we proposed SMLKR, a novel algo- rithm that can learn weighted string edit distances that minimize kernel regression error. We succeed in applying this algorithm to the problem of find- ing form-meaning systematicity in the monomor- phemic English lexicon. Our algorithm offers im- proved global predictions of word-meaning given word-form at the lexicon-wide level. We show that this improvement seems related to localized pockets of form-meaning systematicity such as those previously uncovered in behavioral and cor- pus analyses. Unlike previous lexicon-wide anal- yses, we find that form-meaning systematicity is not randomly distributed throughout the English lexicon. Moreover, the measure of systematicity that we compute using SMLKR accords signifi- cantly with human raters' judgments about form- meaning correspondences in English.</p><p>Future work may investigate to what extent the SMLKR model can predict human intuitions about form-meaning systematicity in language. We do not know, for instance, if our model can predict human semantic judgments of novel words that have never been encountered. This is a question that has received attention in the market research literature, where new brand names are tested for the emotions they elicit <ref type="bibr" target="#b19">(Klink, 2000</ref>). We would also like to investigate the degree to which our statistical model predicts the behavioral effects of phonosemantic systematicity during human se- mantic processing that have been reported in the psycholinguistics literature. Our model makes precise quantitative predictions that should allow us to address these questions. While developing our model on preliminary versions of the monomorphemic lexicon, we no- ticed that the model detected high degrees of sys- tematicity in words with suffixes such as -ate and -tet (e.g., quintet, quartet). We removed such words in the final analysis since they are poly- morphemic, but this observation suggests that our algorithm may have applications in unsupervised morpheme discovery.</p><p>Finally, we would like to test our model us- ing other representations of word-form and word- meaning. We chose to use orthographic rather than phonetic representations of words because of the variance in pronunciation present in the di- alects of English that are manifested in our cor- pus. However, it would be interesting to verify our results in a phonological setting, perhaps using a monodialectal corpus. Moreover, previous local- level analyses suggest that systematicity seems to be concentrated in word-beginnings and word-endings. Thus, it may be worthwhile to augment the representation of edit distance in our model by making it context-sensitive. Future work could also test whether a more interpretable meaning- space representation such as that provided by bi- nary WordNet feature vectors reveals patterns of systematicity not found using a distributional se- mantic space.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>To our knowledge, all previous lexicon-level anal- yses of phonosemantic systematicity have used variations of the method of Shillcock et al. (2001). The inputs for this method are form-meaning tu- ples (y i , s i ) for each word i in the lexicon, where y i is the vector representation of the word in a dis- tributional semantic model, and s i is the string rep- resentation of the word (phonological, phonemic, or orthographic). Semantic distances are mea- sured as cosine distances between the vectors of each pair of words. Shillcock et al. (Shillcock et al., 2001) and Monaghan et al. (Monaghan et al., 2014b) measure form-distances in terms of edit distance between each pair of strings. In addi- tion Monaghan et al. (2014b) and Tamariz</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Previous Findings.</head><label></label><figDesc>Shillcock et al. (2001) find a statistically significant correlation between se- mantic and phonological edit distances in a lex- icon of the 1733 most frequent monosyllabic monomorphemic words in the BNC. Tamariz (2008) extends these results to Spanish data, look- ing only at words with one of three consonant- vowel (CV) structures (CVCV, CVCCV, and CVCVCV). (2001), Monaghan et al. (2014b) de- rive a list of 5138 monomorphemic monosyllabic words and a list of 5604 monomorphemic poly- syllabic from the CELEX database (Baayen et al., 1996)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Each element in ν ij (the vector at left) represents a type of edit. The entry ν ijm represents the number of edits of type m that occur as string s i (boot) is transformed into string s j (bee).</figDesc><graphic url="image-1.png" coords="5,72.29,62.81,217.71,111.71" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Histogram showing distribution of systematicity across two-letter word-beginnings, as measured by permutation-test empirical p-value.</figDesc><graphic url="image-2.png" coords="7,307.56,62.81,217.70,150.67" type="bitmap" /></figure>

			<note place="foot" n="2"> Participants were given the following guidance: &quot;Your job is to decide how well-suited each word is to what it means. This is known as the &apos;phonosemantic feeling.&apos; Basically, most people feel like some of the words in their native language sound right, given what they mean.&quot; Full instructions and experiment available at http://goo.gl/Z6Lzlp 3 Post hoc analyses were produced by comparing the items in only two of the lists at a time, and fitting the same mixedeffects model as above.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work used the Extreme Science and Engi-neering Discovery Environment (XSEDE), which is supported by National Science Foundation grant number ACI-1053575.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Automatic labeling of phonesthemic senses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekaterina</forename><surname>Abramova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Fernández</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Sangati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proeedings of the 35th Annual Conference of the Cognitive Science Society</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">35</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harald</forename><surname>Baayen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Piepenbrock</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>and Léon Gulikers. 1996. CELEX2 (CD-ROM</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Mixed-effects modeling with crossed random effects for subjects and items</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harald</forename><surname>Baayen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><forename type="middle">J</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><forename type="middle">M</forename><surname>Bates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Memory and Language</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="390" to="412" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Determinants of wordlikeness: Phonotactics or lexical neighborhoods?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Todd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrike</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Memory and Language</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="568" to="591" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Random effects structure for confirmatory hypothesis testing: Keep it maximal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dale</forename><forename type="middle">J</forename><surname>Barr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Scheepers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harry</forename><forename type="middle">J</forename><surname>Tily</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Memory and Language</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="255" to="278" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Good edit similarity learning by loss minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurélien</forename><surname>Bellet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amaury</forename><surname>Habrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Sebban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="5" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Controlling the false discovery rate: a practical and powerful approach to multiple testing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Benjamini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yosef</forename><surname>Hochberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society. Series B (Methodological)</title>
		<imprint>
			<biblScope unit="page" from="289" to="300" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Benjamin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bergen</surname></persName>
		</author>
		<title level="m">The psychological reality of phonaesthemes. Language</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="290" to="311" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">British National Corpus, Version 3 BNC XML edition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bnc Consortium</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A limited memory algorithm for bound constrained optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">H</forename><surname>Byrd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peihuang</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jorge</forename><surname>Nocedal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ciyou</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Scientific Computing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1190" to="1208" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Coefficient alpha and the internal structure of tests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cronbach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="297" to="334" />
			<date type="published" when="1951" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Course in General Linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferdinand</forename><surname>De Saussure</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1916" />
			<publisher>McGraw-Hill</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Introducing and evaluating UKWaC, a very large web-derived corpus of English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriano</forename><surname>Ferraresi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eros</forename><surname>Zanchetta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvia</forename><surname>Bernardini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Web as Corpus Workshop (WAC-4) Can we beat Google</title>
		<meeting>the 4th Web as Corpus Workshop (WAC-4) Can we beat Google</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="47" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">R</forename><surname>Firth</surname></persName>
		</author>
		<title level="m">Speech. Benn&apos;s Sixpenny Library</title>
		<meeting><address><addrLine>London</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1930" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Statistical methods for research workers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Fisher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1932" />
			<publisher>Oliver and Boyd</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The origins of arbitrariness in language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Gasser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Annual Conference of the Cognitive Science Society</title>
		<meeting>the 26th Annual Conference of the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="4" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Darren</forename><surname>George</surname></persName>
		</author>
		<title level="m">SPSS for Windows Step by Step: A Simple Guide and Reference, 11.0 Update</title>
		<meeting><address><addrLine>Allyn &amp; Bacon, London</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
	<note>4th ed.</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The origin of speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><forename type="middle">F</forename><surname>Hockett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific American</title>
		<imprint>
			<biblScope unit="volume">203</biblScope>
			<biblScope unit="page" from="88" to="96" />
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">The psychological reality, variability, and compositionality of English phonesthemes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><forename type="middle">Suzanne</forename><surname>Hutchins</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
		<respStmt>
			<orgName>Emory University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
	<note>Atlanta</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Creating brand names with meaning: The use of sound symbolism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Klink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Letters</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="20" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A theory of lexical access in speech production</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Willem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ardi</forename><surname>Levelt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antje</forename><forename type="middle">S</forename><surname>Roelofs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Meyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">01</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Binary codes capable of correcting deletions, insertions, and reversals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><forename type="middle">I</forename><surname>Levenshtein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Soviet Physics Doklady</title>
		<imprint>
			<date type="published" when="1966" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="707" to="710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">What&apos;s in a Word? Evidence for Phonosemantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>Magnus</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<pubPlace>Trondheim, Norway</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Trondheim</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The detection of disease clustering and a generalized regression approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Mantel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cancer Research</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="209" to="220" />
			<date type="published" when="1967" />
		</imprint>
	</monogr>
	<note>Part 1</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The systematicity of the sign: Modeling activation of semantic attributes from nonwords</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Padraic</forename><surname>Monaghan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary</forename><surname>Lupyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morten</forename><forename type="middle">H</forename><surname>Christiansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th Annual Meeting of the Cognitive Science Society</title>
		<editor>P. Bello, M. Guarini, M. McShane, and B. Scassellati</editor>
		<meeting>the 36th Annual Meeting of the Cognitive Science Society<address><addrLine>Austin, TX</addrLine></address></meeting>
		<imprint>
			<publisher>Cognitive Science Society</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2741" to="2746" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">How arbitrary is language?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Padraic</forename><surname>Monaghan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">C</forename><surname>Shillcock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morten</forename><forename type="middle">H</forename><surname>Christiansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kirby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Philosophical Transactions of the Royal Society of London B: Biological Sciences</title>
		<imprint>
			<date type="published" when="1651" />
			<biblScope unit="page">369</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">On estimating regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Elizbar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nadaraya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Theory of Probability &amp; Its Applications</title>
		<imprint>
			<date type="published" when="1964" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="141" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Attention, similarity, and the identification-categorization relationship</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">M</forename><surname>Nosofsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">39</biblScope>
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">An ethological perspective on common cross-language utilization of f0 of voice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">J</forename><surname>Ohala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phonetica</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Phonaesthemes: A corpus-based analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katya</forename><surname>Otis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eyal</forename><surname>Sagi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th</title>
		<meeting>the 30th</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Annual Conference of the Cognitive Science Society</title>
		<imprint>
			<biblScope unit="page" from="65" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">English Gigaword Fifth Edition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Parker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Graff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junbo</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuaki</forename><surname>Maeda</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Software Framework for Topic Modelling with Large Corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petr</forename><surname>Radimřehůřekradimˇradimřehůřek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sojka</surname></persName>
		</author>
		<ptr target="http://is.muni.cz/publication/884893/en" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks</title>
		<meeting>the LREC 2010 Workshop on New Challenges for NLP Frameworks<address><addrLine>Valletta, Malta, May. ELRA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="45" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Semantic glimmers: Phonaesthemes facilitate access to sentence meaning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eyal</forename><surname>Sagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katya</forename><surname>Otis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">9th Conference on Conceptual Structure, Discourse, &amp; Language (CSDL9)</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Filled pauses and their status in the mental lexicon</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Shillcock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kirby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA Tutorial and Research Workshop (ITRW) on Disfluency in Spontaneous Speech</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Sound symbolism in a usage-driven model. Unpublished manuscript</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anatol</forename><surname>Stefanowitsch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<pubPlace>Houston, Texas, USA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Rice University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Exploring the adaptive structure of the mental lexicon</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Monica</forename><surname>Tamariz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<pubPlace>Edinburgh</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Edinburgh</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Exploring systematicity between phonological and context-cooccurrence representations of the mental lexicon</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Monica</forename><surname>Tamariz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Mental Lexicon</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="259" to="278" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Metric learning for kernel regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Killian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerald</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tesauro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eleventh International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="608" to="615" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
