<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:31+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Building a Semantic Parser Overnight</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yushi</forename><surname>Wang</surname></persName>
							<email>yushiw@cs.stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Stanford University</orgName>
								<orgName type="institution" key="instit2">Stanford University</orgName>
								<orgName type="institution" key="instit3">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
							<email>joberant@stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Stanford University</orgName>
								<orgName type="institution" key="instit2">Stanford University</orgName>
								<orgName type="institution" key="instit3">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
							<email>pliang@cs.stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Stanford University</orgName>
								<orgName type="institution" key="instit2">Stanford University</orgName>
								<orgName type="institution" key="instit3">Stanford University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Building a Semantic Parser Overnight</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1332" to="1342"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>How do we build a semantic parser in a new domain starting with zero training ex-amples? We introduce a new methodology for this setting: First, we use a simple grammar to generate logical forms paired with canonical utterances. The logical forms are meant to cover the desired set of compositional operators, and the canon-ical utterances are meant to capture the meaning of the logical forms (although clumsily). We then use crowdsourcing to paraphrase these canonical utterances into natural utterances. The resulting data is used to train the semantic parser. We further study the role of compositionality in the resulting paraphrases. Finally, we test our methodology on seven domains and show that we can build an adequate semantic parser in just a few hours.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>By mapping natural language utterances to exe- cutable logical forms, semantic parsers have been useful for a variety of applications requiring pre- cise language understanding ( <ref type="bibr" target="#b25">Zelle and Mooney, 1996;</ref><ref type="bibr" target="#b26">Zettlemoyer and Collins, 2005;</ref><ref type="bibr" target="#b13">Liang et al., 2011;</ref><ref type="bibr" target="#b3">Berant et al., 2013;</ref><ref type="bibr" target="#b11">Kwiatkowski et al., 2013;</ref><ref type="bibr" target="#b10">Kushman and Barzilay, 2013)</ref>. Previous work has focused on how to train a semantic parser given input utter- ances, but suppose we wanted to build a seman- tic parser for a new domain-for example, a natu- ral language interface into a publications database. Since no such interface exists, we do not even have a naturally occurring source of input utterances that we can annotate. So where do we start?</p><p>In this paper, we advocate a functionality- driven process for rapidly building a semantic * Both authors equally contributed to the paper. Paraphrases what is the newest published article? who has published the most articles?</p><p>...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Semantic parser</head><p>(1) by builder (∼30 minutes)</p><p>(2) via domain-general grammar parser in a new domain. At a high-level, we seek to minimize the amount of work needed for a new domain by factoring out the domain- general aspects (done by our framework) from the domain-specific ones (done by the builder of the semantic parser). We assume that the builder already has the desired functionality of the semantic parser in mind-e.g., the publica- tions database is set up and the schema is fixed. <ref type="figure" target="#fig_0">Figure 1</ref> depicts the functionality-driven process: First, the builder writes a seed lexicon specifying a canonical phrase ("publication date") for each predicate (publicationDate).</p><p>Second, our framework uses a domain-general grammar, along with the seed lexicon and the database, to automatically generate a few hundred canonical utterances paired with their logical forms (e.g., "article that has the largest publication date" and arg max(type.article, publicationDate)). These utterances need not be the most elegant, but they should retain the semantics of the logical forms. Third, the builder leverages crowdsourcing to paraphrase each canonical utterance into a few natural utterances (e.g., "what is the newest published article?"). Finally, our framework uses this data to train a semantic parser.</p><p>Practical advantages. There are two main ad- vantages of our approach: completeness and ease of supervision. Traditionally, training data is collected in a best-effort manner, which can re- sult in an incomplete coverage of functionality. For example, the WebQuestions dataset <ref type="bibr" target="#b3">(Berant et al., 2013)</ref> contains no questions with numeric answers, so any semantic parser trained on that dataset would lack that functionality. These bi- ases are not codified, which results in an idiosyn- cratic and mysterious user experience, a major drawback of natural language interfaces ( <ref type="bibr" target="#b18">Rangel et al., 2014</ref>). In contrast, our compact grammar precisely specifies the logical functionality. We enforce completeness by generating canonical ut- terances that exercise every grammar rule.</p><p>In terms of supervision, state-of-the-art seman- tic parsers are trained from question-answer pairs ( <ref type="bibr" target="#b11">Kwiatkowski et al., 2013;</ref><ref type="bibr" target="#b2">Berant and Liang, 2014)</ref>. Although this is a marked improvement in cost and scalability compared to annotated logical forms, it still requires non-trivial effort: the an- notator must (i) understand the question and (ii) figure out the answer, which becomes even harder with compositional utterances. In contrast, our main source of supervision is paraphrases, which only requires (i), not (ii). Such data is thus cheaper and faster to obtain.</p><p>Linguistic reflections. The centerpiece of our framework is a domain-general grammar that con- nects logical forms with canonical utterances. This connection warrants further scrutiny, as the structural mismatch between logic and language is the chief source of difficulty in semantic pars- ing ( <ref type="bibr" target="#b13">Liang et al., 2011;</ref><ref type="bibr" target="#b11">Kwiatkowski et al., 2013;</ref><ref type="bibr" target="#b2">Berant and Liang, 2014</ref>).</p><p>There are two important questions here. First, is it possible to design a simple grammar that simul- taneously generates both logical forms and canon- ical utterances so that the utterances are under- standable by a human? In Section 3, we show how to choose appropriate canonical utterances to max- imize alignment with the logical forms.</p><p>Second, our grammar can generate an infinite number of canonical utterances. How many do we need for adequate coverage? Certainly, single relations is insufficient: just knowing that "pub- lication date of X" paraphrases to "when X was published" would offer insufficient information to generalize to "articles that came after X" mapping to "article whose publication date is larger than publication date of X". We call this phenomena sublexical compositionality-when a short lexical unit ("came after") maps onto a multi-predicate logical form. Our hypothesis is that the sublexi- cal compositional units are small, so we only need to crowdsource a small number of canonical utter- ances to learn about most of the language variabil- ity in the given domain (Section 4).</p><p>We applied our functionality-driven process to seven domains, which were chosen to explore par- ticular types of phenomena, such as spatial lan- guage, temporal language, and high-arity rela- tions. This resulted in seven new semantic parsing datasets, totaling 12.6K examples. Our approach, which was not tuned on any one domain, was able to obtain an average accuracy of 59% over all do- mains. On the day of this paper submission, we created an eighth domain and trained a semantic parser overnight.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Approach Overview</head><p>In our functionality-driven process <ref type="figure" target="#fig_0">(Figure 1</ref>), there are two parties: the builder, who provides domain-specific information, and the framework, which provides domain-general information. We assume that the builder has a fixed database w, represented as a set of triples (e 1 , p, e 2 ), where e 1 and e 2 are entities (e.g., <ref type="bibr">article1, 2015)</ref> and p is a property (e.g., publicationDate). The database w can be queried using lambda DCS logical forms, described further in Section 2.1.</p><p>The builder supplies a seed lexicon L, which contains for each database property p (e.g., publicationDate) a lexical entry of the form t → s <ref type="bibr">[p]</ref>, where t is a natural language phrase (e.g., "publication date") and s is a syntactic cat-egory (e.g., RELNP). In addition, L contains two typical entities for each semantic type in the database (e.g., alice → NP <ref type="bibr">[alice]</ref> for the type person). The purpose of L is to simply connect each predicate with some representation in natural language.</p><p>The framework supplies a grammar G, which specifies the modes of composition, both on log- ical forms and canonical utterances. Formally, G is a set of rules of the form α 1 . . . α n → s <ref type="bibr">[z]</ref>, where α 1 . . . α n is a sequence of tokens or cate- gories, s is a syntactic category and z is the log- ical form constructed. For example, one rule in</p><formula xml:id="formula_0">G is RELNP[r] of NP[x] → NP[R(r).x]</formula><p>, which constructs z by reversing the binary predicate r and joining it with a the unary predicate x. We use the rules G ∪ L to generate a set of (z, c) pairs, where z is a logical form (e.g., R(publicationDate).article1), and c is the corresponding canonical utterance (e.g., "publica- tion date of article 1"). The set of (z, c) is denoted by GEN(G ∪ L). See Section 3 for details.</p><p>Next, the builder (backed by crowdsourcing) paraphrases each canonical utterance c output above into a set of natural utterances P(c) (e.g., "when was article 1 published?"). This defines a set of training examples D = {(x, c, z)}, for each (z, c) ∈ GEN(G ∪ L) and x ∈ P(c). The crowd- sourcing setup is detailed in Section 5.</p><p>Finally, the framework trains a semantic parser on D. Our semantic parser is a log-linear distribu- tion p θ (z, c | x, w) over logical forms and canon- ical utterances specified by the grammar G. Note that the grammar G will in general not parse x, so the semantic parsing model will be based on para- phrasing, in the spirit of <ref type="bibr" target="#b2">Berant and Liang (2014)</ref>.</p><p>To summarize, (1) the builder produces a seed lexicon L; (2) the framework produces logical forms and canonical utterances GEN(G ∪ L) = {(z, c)}; (3) the builder (via crowdsourcing) uses P(·) to produce a dataset D = {(x, c, z)}; and (4) the framework uses D to train a semantic parser p θ (z, c | x, w).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Lambda DCS</head><p>Our logical forms are represented in lambda DCS, a logical language where composition operates on sets rather than truth values. Here we give a brief description; see Liang (2013) for details.</p><p>Every logical form z in this paper is either a unary (denoting a set of entities) or a binary (de- noting a set of entity-pairs). In the base case, each entity e (e.g., <ref type="bibr">2015</ref>) is a unary denoting the single- ton set: e w = {e}; and each property p (e.g., publicationDate) is a binary denoting all entity- pairs (e 1 , e 2 ) that satisfy the property p. Unaries and binaries can be composed: Given a binary b and unary u, the join b.u denotes all entities e 1 for which there exists an e 2 ∈ u w with (e 1 , e 2 ) ∈ b w . For example, publicationDate.2015 de- note entities published in 2015.</p><p>The intersection u 1 u 2 , union u 1 u 2 , com- plement ¬u denote the corresponding set op- erations on the denotations. We let R(b) de- note the reversal of b:</p><formula xml:id="formula_1">(e 1 , e 2 ) ∈ b w iff (e 2 , e 1 ) ∈ R(b) w .</formula><p>This allows us to define R(publicationDate).article1 as the publica- tion date of article 1. We also include aggregation operations (count(u), sum(u) and average(u, b)), and superlatives (argmax(u, b)).</p><p>Finally, we can construct binaries using lambda abstraction: λx.u denotes a set of (e 1 , e 2 ) where</p><formula xml:id="formula_2">e 1 ∈ u[x/e 2 ] w and u[x/e 2 ]</formula><p>is the logical form where free occurrences of x are replaced with e 2 . For example, R(λx.count(R(cites).x)) denotes the set of entities (e 1 , e 2 ), where e 2 is the number of entities that e 1 cites.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Generation and canonical compositionality</head><p>Our functionality-driven process hinges on having a domain-general grammar that can connect logi- cal forms with canonical utterances composition- ally. The motivation is that while it is hard to write a grammar that parses all utterances, it is possible to write one that generates one canonical utterance for each logical form. To make this explicit: Assumption 1 (Canonical compositionality) Using a small grammar, all logical forms ex- pressible in natural language can be realized compositionally based on the logical form.</p><p>Grammar. We target database querying appli- cations, where the parser needs to handle superla- tives, comparatives, negation, and coordination. We define a simple grammar that captures these forms of compositionality using canonical utter- ances in a domain-general way. <ref type="figure">Figure 2</ref> illustrates a derivation produced by the grammar. The seed lexicon specified by the builder con- tains canonical utterances for types, entities, and properties. All types (e.g., person) have the syn- tactic category TYPENP, and all entities (e.g., <ref type="bibr">NP[type.article publicationDate.1950]</ref> NP <ref type="bibr">[type.article]</ref> TypeNP <ref type="bibr">[article]</ref> article whose RelNP <ref type="bibr">[publicationDate]</ref> publication date is EntityNP <ref type="bibr">[1950]</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1950</head><p>Figure 2: Deriving a logical form z (red) and a canonical utterance c (green) from the grammar G. Each node contains a syntactic category and a logical form, which is generated by applying a rule. Nodes with only leaves as children are pro- duced using the seed lexicon; all other nodes are produced by rules in the domain-general grammar.</p><p>alice) are ENTITYNP's. Unary predicates are realized as verb phrases VP (e.g., "has a private bath"). The builder can choose to represent bina- ries as either relational noun phrases (RELNP) or generalized transitive verbs (VP/NP). RELNP's are usually used to describe functional proper- ties (e.g., "publication date"), especially numer- ical properties. VP/NP's include transitive verbs ("cites") but also longer phrases with the same syntactic interface ("is the president of"). <ref type="table">Table  1</ref> shows the seed lexicon for the SOCIAL domain.</p><p>From the seed lexicon, the domain-general grammar <ref type="table">(Table 2)</ref> constructs noun phrases (NP), verbs phrases (VP), and complementizer phrase (CP), all of which denote unary logical forms. Broadly speaking, the rules (R1)-(R4), (C1)-(C4) take a binary and a noun phrase, and compose them (optionally via comparatives, counting, and negation) to produce a complementizer phrase CP representing a unary (e.g., "that cites article 1" or "that cites more than three article"). (G3) combines these CP's with an NP (e.g., "article"). In addition, (S0)-(S4) handle superlatives (we in- clude argmin in addition to argmax), which take an NP and return the extremum-attaining subset of its denotation. Finally, we support transformations such as join (T1) and disjunction (T4), as well as aggregation (A1)-(A2).</p><p>Rendering utterances for multi-arity predicates was a major challenge.</p><p>The predicate in- stances are typically reified in a graph database, akin to a neo-Davidsonian treatment of events: There is an abstract entity with binary predi- cates relating it to its arguments. For exam- ple, in the SOCIAL domain, Alice's education can be represented in the database as five triples: <ref type="table">Table 1</ref>: The seed lexicon for the SOCIAL do- main, which specifies for each predicate (e.g., birthdate) a phrase (e.g., "birthdate") that real- izes that predicate and its syntactic category (e.g., RELNP).</p><formula xml:id="formula_3">birthdate → RELNP[birthdate] person|university|field → TYPENP[person| · · · ] company|job title → TYPENP[company| · · · ] student|university|field of study → RELNP[student| · · · ] employee|employer|job title → RELNP[employee| · · · ] start date|end date → RELNP[startDate| · · · ] is friends with → VP/NP[friends| · · · ]</formula><p>(e17, student, alice), (e17, university, ucla), (e17, fieldOfStudy, music), (e17, startDate, 2005), (e17, endDate, 2009).</p><p>All five properties here are represented as RELNP's, with the first one designated as the sub- ject (RELNP 0 ). We support two ways of querying multi-arity relations: "student whose university is ucla" (T2) and "university of student Alice whose start date is 2005" (T3).</p><p>Generating directly from the grammar in <ref type="table">Ta- ble 2</ref> would result in many uninterpretable canon- ical utterances. Thus, we perform type checking on the logical forms to rule out "article that cites 2004", and limit the amount of recursion, which keeps the canonical utterances understandable.</p><p>Still, the utterances generated by our grammar are not perfectly grammatical; we do not use de- terminers and make all nouns singular. Nonethe- less, AMT workers found most canonical utter- ances understandable (see <ref type="table" target="#tab_1">Table 3</ref> and Section 5 for details on crowdsourcing). One tip for the builder is to keep the RELNP's and VP/NP's as context-independent as possible; e.g., using "pub- lication date" instead of "date". In cases where more context is required, we use parenthetical re- marks (e.g., "number of assists (over a season)" → RELNP <ref type="bibr">[...]</ref>) to pack more context into the confines of the part-of-speech.</p><p>Limitations. While our domain-general gram- mar covers most of the common logical forms in a database querying application, there are sev- eral phenomena which are out of scope, notably nested quantification (e.g., "show me each au- thor's most cited work") and anaphora (e.g., "au- thor who cites herself at least twice"). Handling these would require a more radical change to the grammar, but is still within scope. <ref type="table">Table 2</ref>: The domain-general grammar which is combined with the seed lexicon to generate logical forms and canonical utterances that cover the supported logical functionality.</p><formula xml:id="formula_4">[glue] (G1) ENTITYNP[x] → NP[x] (G2) TYPENP[x] → NP[type.x] (G3) NP[x] CP[f ] (and CP[g])* → NP[x f g] [simple] (R0) that VP[x] → CP[x] (R1) whose RELNP[r] CMP[c] NP[y] → CP[r.c</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>.y] is|is not|is smaller than|is larger than|is at least|is at most</head><formula xml:id="formula_5">→ CMP[= | = | &lt; | &gt; | ≤ | ≥] (R2) that (not)? VP/NP[r] NP[y] → CP[(¬)r.y] (R3) that is (not)? RELNP[r] of NP[y] → CP[(¬)R(r).y] (R4) that NP[y] (not)? VP/NP[r] → CP[(¬)(R(r).y)] [counting] (C1) that has CNT[c] RELNP[r] → CP[R(λx.count(R(r).x)).c] (C2) that VP/NP[r] CNT[c] NP[y] → CP[R(λx.count(y R(r).x)).c] (C3) that is RELNP[r] of CNT[c] NP[y] → CP[R(λx.count(y r.x)).c] (C4) that CNT[c] NP[y] VP/NP[r] → CP[R(λx.count(y r.x)).c] (less than|more than) NUM[n] → CNT[(&lt; .| &gt; .)n] [superlatives] (S0) NP[x] that has the largest RELNP[r] → NP[arg max(x, r)] (S1) NP[x] that has the most number of RELNP[r] → NP[arg max(x, R(λy.count(R(r).y)))] (S2) NP[x] that VP/NP[r] the most number of NP[y] → NP[arg max(x, R(λy.count(R(r).y)))] (S3) NP[x] that is RELNP[r] of the most number of NP[y] → NP[arg max(x, R(λz.count(y r.z)))] (S4) NP[x] that the most number of NP[y] VP/NP[r] → NP[arg max(x, R(λz.count(y r.z)))] [transformation] (T1) RELNP[r] of NP[y] → NP[R(r).y] (T2) RELNP 0 [h]CP[f ] (and CP[g])* → NP[R(h).(f g)] (T3) RELNP[r] of RELNP 0 [h] NP[x] CP[f ] (and CP[g])* → NP[R(r).(h.x f g)] (T4) NP[x] or NP[y] → NP[x y] [aggregation] (A1) number of NP[x] → NP[count(x)] (A2) total|average RELNP[r] of NP[x] → NP[sum|average(x, r)]</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Paraphrasing and bounded non-compositionality</head><p>While the canonical utterance c is generated compositionally along with the logical form z, natural paraphrases x ∈ P(c) generally devi- ate from this compositional structure. For ex- ample, the canonical utterance "NP[number of NP[article CP[whose publication date is larger than NP[publication date of article 1]]]]" might get paraphrased to "How many articles were pub- lished after article 1?". Here, "published after" non-compositionally straddles the inner NP, intu- itively responsible for both instances of "publica- tion date". But how non-compositional can para- phrases be? Our framework rests on the assump- tion that the answer is "not very":</p><p>Assumption 2 (Bounded non-compositionality) Natural utterances for expressing complex logical forms are compositional with respect to fragments of bounded size.</p><p>In the above example, note that while "published after" is non-compositional with respect to the grammar, the rewriting of "number of" to "how many" is compositional. The upshot of Assump- tion 2 is that we only need to ask for paraphrases of canonical utterances generated by the grammar up to some small depth to learn about all the non- compositional uses of language, and still be able generalize (compositionally) beyond that. We now explore the nature of the possible para- phrases. Broadly speaking, most paraphrases in- volve some sort of compression, where the clunky but faithful canonical utterance is smoothed out into graceful prose.</p><p>Alternations of single rules. The most basic paraphrase happens at the single phrase level with synonyms ("block" to "brick"), which preserve the part-of-speech. However, many of our prop- erties are specified using relational noun phrases, which are more naturally realized using preposi- tions ("meeting whose attendee is alice ⇒ meet- ing with alice") or verbs ("author of article 1 ⇒ who wrote article 1"). If the RELNP is com- plex, then the argument can become embedded: "player whose number of points is 15 ⇒ player who scored 15 points". Superlative and compara- tive constructions reveal other RELNP-dependent words: "article that has the largest publication date ⇒ newest article". When the value of the relation has enough context, then the relation is elided completely: "housing unit whose housing type is apartment ⇒ apartment".</p><p>Multi-arity predicates are compressed into a single frame: "university of student alice whose field of study is music" becomes "At which uni- versity did Alice study music?", where the se- mantic roles of the verb "study" carry the bur- den of expressing the multiple relations: student, university, and fieldOfStudy. With a different combination of arguments, the natural verb would change: "Which university did Alice attend?" Sublexical compositionality. The most interest- ing paraphrases occur across multiple rules, a phe- nomenon which we called sublexical composition- ality. The idea is that common, multi-part con- cepts are compressed to single words or simpler constructions. The simplest compression is a lex- ical one: "parent of alice whose gender is female ⇒ mother of alice". Compression often occurs when we have the same predicate chained twice in a join: "person that is author of paper whose author is X ⇒ co-author of X" or "person whose birthdate is birthdate of X ⇒ person born on the same day as X". When two CP's combined via coordination have some similarity, then the co- ordination can be pushed down ("meeting whose start time is 3pm and whose end time is 5pm ⇒ meetings between 3pm and 5pm") and sometimes even generalized ("that allows cats and that al- lows dogs ⇒ that allows pets"). Sometimes, com- pression happens due to metonymy, where people stand in for their papers: "author of article that ar- ticle whose author is X cites ⇒ who does X cite".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Crowdsourcing</head><p>We tackled seven domains covering various lin- guistic phenomena. <ref type="table" target="#tab_1">Table 3</ref> lists the domains, their principal phenomena, statistics about their predi- cates and dataset, and an example from the dataset.</p><p>We use Amazon Mechanical Turk (AMT) to paraphrase the canonical utterances generated by the domain-general grammar. In each AMT task, a worker is presented with four canonical utter- ances and is asked to reformulate them in natu- ral language or state that they are incomprehensi- ble. Each canonical utterance was presented to 10 workers. Over all domains, we collected 18,032 responses. The average time for paraphrasing one utterance was 28 seconds. Paraphrases that share the same canonical utterance are collapsed, while identical paraphrases that have distinct canonical utterances are deleted. This produced a total of 12,602 examples over all domains.</p><p>To estimate the level of noise in the data, we manually judged the correctness of 20 examples in each domain, and found that 17% of the utterances were inaccurate. There are two main reasons: lex- ical ambiguity on our part ("player that has the least number of team ⇒ player with the lowest jersey number"), and failure on the worker's part ("restaurant whose star rating is 3 stars ⇒ hotel which has a 3 star rating").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Model and Learning</head><p>Our semantic parsing model defines a distribu- tion over logical forms given by the domain- general grammar G and additional rules trig- gered by the input utterance x. Specifically, given an utterance x, we detect numbers, dates, and perform string matching with database en- tities to recognize named entities. This results in a set of rules T(x). Our semantic parsing model defines a log- linear distribution over candidate pairs (z, c) ∈ GEN(G ∪ L x ):</p><formula xml:id="formula_6">p θ (z, c | x, w) ∝ exp(φ(c, z, x, w) θ),<label>(1)</label></formula><p>where φ(z, c, x, w) ∈ R d is a feature vector and θ ∈ R d is a parameter vector. To generate candidate logical forms, we use a simple beam search: For each search state, which includes the syntactic category s (e.g., NP) and the depth of the logical form, we generate at most K = 20 candidates by applying the rules in Ta- ble 2. In practice, the lexical rules T(x) are ap- plied first, and composition is performed, but not constrained to the utterance. For example, the ut- terance "article" would generate the logical form count(type.article). Instead, soft paraphras- ing features are used to guide the search. This rather unorthodox approach to semantic parsing can be seen as a generalization of <ref type="bibr" target="#b2">Berant and Liang (2014)</ref> and is explained in more detail in <ref type="bibr" target="#b17">Pasupat and Liang (2015)</ref>.</p><p>Training. We train our model by maximiz- ing the regularized log-likelihood O(θ) = Domain # pred. # ex. <ref type="table">Phenomena  Example  CALENDAR  22</ref> 837 temporal language x: "Show me meetings after the weekly standup day" c: "meeting whose date is at least date of weekly standup" z: type.meeting date. &gt; R(date).weeklyStandup BLOCKS 19 1995 spatial language x: "Select the brick that is to the furthest left." c: "block that the most number of block is right of" z: argmax(type.block, R(λx.count(R(right).x))) HOUSING 24 941 measurement units x: "Housing that is 800 square feet or bigger?" c: "housing unit whose size is at least 800 square feet" z: type.housingUnit area. &gt; .800 RESTAURANTS 32 1657 long unary relations x: "What restaurant can you eat lunch outside at?" c: "restaurant that has outdoor seating and that serves lunch" z: type.restaurant hasOutdoorSeating serveslunch PUBLICATIONS 15 801 sublexical compositionality x: "Who has co-authored articles with Efron?" c: "person that is author of article whose author is efron" z: type.person R(author).(type.article author.efron) SOCIAL 45 4419 multi-arity relations x: "When did alice start attending brown university?" c: "start date of student alice whose university is brown university" z: R(date).(student.Alice university.Brown) BASKETBALL 24 1952 parentheticals x: "How many fouls were played by Kobe Bryant in 2004?" c: "number of fouls (over a season) of player kobe bryant whose season is 2004" z: count(R(fouls).(player.    <ref type="table">Table 4</ref>: Features for the paraphrasing model. pos(x i:i ) is the POS tag; type(z w ) is a coarse se- mantic type for the denotation (an entity or a num- ber). A is a maximum weight alignment between x and c. (x,c,z)∈D log p θ (z, c | x, w) − λθ 1 . To opti- mize, we use AdaGrad ( <ref type="bibr" target="#b6">Duchi et al., 2010</ref>).</p><p>Features <ref type="table">Table 4</ref> describes the features. Our basic features mainly match words and bigrams in x and c, if they share a lemma or are aligned in the PPDB resource ( <ref type="bibr" target="#b8">Ganitkevitch et al., 2013)</ref>. We count the number of exact matches, PPDB matches, and unmatched words.</p><p>To obtain lexical features, we run the Berkeley Aligner ( <ref type="bibr" target="#b12">Liang et al., 2006</ref>) on the training set and compute conditional probabilities of aligning one word type to another. Based on these probabilities we compute a maximum weight alignment A be- tween words in x and c. We define features over A (see <ref type="table">Table 4</ref>). We also use the word alignments to construct a phrase table by applying the consistent phrase pair heuristic ( <ref type="bibr" target="#b16">Och and Ney, 2004</ref>). We de- fine an indicator feature for every phrase pair of x and c that appear in the phrase table. Examples from the PUBLICATIONS domain include fewest- least number and by-whose author is. Note that we do not build a hard lexicon but only use A and the phrase table to define features, allowing the model to learn useful paraphrases during train- ing. Finally, we define standard features on logical forms and denotations <ref type="bibr" target="#b3">(Berant et al., 2013</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Experimental Evaluation</head><p>We evaluated our functionality-driven process on the seven domains described in Section 5 and one new domain we describe in Section 7.3. For each domain, we held out a random 20% of the exam- ples as the test set, and performed development on the remaining 80%, further splitting it to a train- ing and development set (80%/20%). We created a database for each domain by randomly generating facts using entities and properties in the domain (with type-checking). We evaluated using accu- racy, which is the fraction of examples that yield the correct denotation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Domain-specific linguistic variability</head><p>Our functionality-driven process is predicated on the fact that each domain exhibits domain-specific  phenomena. To corroborate this, we compare our full system to NOLEX, a baseline that omits all lexical features <ref type="table">(Table 4</ref>), but uses PPDB as a domain-general paraphrasing component. We per- form the complementary experiment and compare to NOPPDB, a baseline that omits PPDB match features. We also run BASELINE, where we omit both lexical and PPDB features. <ref type="table" target="#tab_3">Table 5</ref> presents the results of this experiment. Overall, our framework obtains an average accu- racy of 59% across all eight domains. The per- formance of NOLEX is dramatically lower than FULL, indicating that it is important to learn domain-specific paraphrases using lexical fea- tures. The accuracy of NOPPDB is only slightly lower than FULL, showing that most of the re- quired paraphrases can be learned during training. As expected, removing both lexical and PPDB fea- tures results in poor performance (BASELINE).</p><p>Analysis. We performed error analysis on 10 er- rors in each domain. Almost 70% of the errors are due to problems in the paraphrasing model, where the canonical utterance has extra material, is missing some content, or results in an incorrect paraphrase. For example, "restaurants that have waiters and you can sit outside" is paraphrased to "restaurant that has waiter service and that takes reservations". Another 12.5% result from reorder- ing issues, e.g, we paraphrase "What venue has fewer than two articles" to "article that has less than two venue". Inaccurate paraphrases provided by AMT workers account for the rest of the errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Bounded non-compositionality</head><p>We hypothesized that we need to obtain para- phrases of canonical utterances corresponding to logical forms of only small depth. We ran the following experiment in the CALENDAR domain to test this claim. First, we define by NP 0 , NP 1 , and NP 2 the set of utterances generated by an NP that has exactly zero, one, and two NPs embed- ded in it. We define the training scenario 0 → 1, where we train on examples from NP 0 and test on examples from NP 1 ; 0 ∪ 1 → 1, 0 ∪ 1 → 2, and 0 ∪ 1 ∪ 2 → 2 are defined analogously. Our</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Scenario</head><p>Acc. Scenario Acc. hypothesis is that generalization on 0 ∪ 1 → 2 should be better than for 0 → 1, since NP 1 ut- terances have non-compositional paraphrases, but training on NP 0 does not expose them.</p><formula xml:id="formula_7">0 → 1 22.9 0 ∪ 1 → 2 28.1 0 ∪ 1 → 1 85.8 0 ∪ 1 ∪ 2 → 2 47.5</formula><p>The results in <ref type="table" target="#tab_4">Table 6</ref> verify this hypothesis. The accuracy of 0 → 1 is almost 65% lower than 0 ∪ 1 → 1. On the other hand, the accuracy of 0 ∪ 1 → 2 is only 19% lower than 0 ∪ 1 ∪ 2 → 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">An overnight experiment</head><p>To verify the title of this paper, we attempted to create a semantic parser for a new domain (RECIPES) exactly 24 hours before the submission deadline. Starting at midnight, we created a seed lexicon in less than 30 minutes. Then we gener- ated canonical utterances and allowed AMT work- ers to provide paraphrases overnight. In the morn- ing, we trained our parser and obtained an accu- racy of 70.8% on the test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Testing on independent data</head><p>Geo880. To test how our parser generalizes to utterances independent of our framework, we cre- ated a semantic parser for the domain of US ge- ography, and tested on the standard 280 test ex- amples from GEO880 ( <ref type="bibr" target="#b25">Zelle and Mooney, 1996</ref>). We did not use the standard 600 training examples. Our parser obtained 56.4% accuracy, which is sub- stantially lower than state-of-the-art (∼ 90%).</p><p>We performed error analysis on 100 random sentences from the development set where accu- racy was 60%. We found that the parser learns from the training data to prefer shorter para- phrases, which accounts for 30% of the errors. In most of these cases, the correct logical form is ranked at the top-3 results (accuracy for the top- 3 derivations is 73%). GEO880 contains highly compositional utterances, and in 25% of the errors the correct derivation tree exceeds the maximum depth used for our parser. Another 17.5% of the errors are caused by problems in the paraphrasing model. For example, in the utterance "what is the size of california", the model learns that "size" corresponds to "population" rather than "area". Errors related to reordering and the syntactic struc- ture of the input utterance account for 7.5% of the errors. For example, the utterance "what is the area of the largest state" is paraphrased to "state that has the largest area".</p><p>Calendar. In Section 7.1, we evaluated on ut- terances obtained by paraphrasing canonical utter- ances from the grammar. To examine the cover- age of our parser on independently-produced ut- terances, we asked AMT workers to freely come up with queries. We collected 186 such queries; 5 were spam and discarded. We replaced all entities (people, dates, etc.) with entities from our seed lexicon to avoid focusing on entity detection.</p><p>We were able to annotate 52% of the utterances with logical forms from our grammar. We could not annotate 20% of the utterances due to relative time references, such as "What time is my next meeting?". 14% of the utterances were not cov- ered due to binary predicates not in the grammar ("What is the agenda of the meeting?") or missing entities ("When is Dan's birthday?"). Another 2% required unsupported calculations ("How much free time do I have tomorrow?"), and the rest are out of scope for other reasons ("When does my Verizon data plan start over?").</p><p>We evaluated our trained semantic parser on the 95 utterances annotated with logical forms. Our parser obtained an accuracy of 46.3% and oracle accuracy of 84.2%, which measures how often the correct denotation is on the final beam. The large gap shows that there is considerable room for im- provement in the paraphrasing model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Related work and discussion</head><p>Much of current excitement around semantic pars- ing emphasizes large knowledge bases such as Freebase <ref type="bibr" target="#b4">(Cai and Yates, 2013;</ref><ref type="bibr" target="#b11">Kwiatkowski et al., 2013;</ref><ref type="bibr" target="#b3">Berant et al., 2013)</ref>. However, despite the apparent scale, the actual question answering datasets (Free917 and WebQuestions) are limited in compositionality. Moreover, specialized do- mains with specialized jargon will always exist, e.g., in regular expressions <ref type="bibr" target="#b10">(Kushman and Barzilay, 2013</ref>) or grounding to perception <ref type="bibr" target="#b15">(Matuszek et al., 2012;</ref><ref type="bibr" target="#b21">Tellex et al., 2011;</ref><ref type="bibr" target="#b9">Krishnamurthy and Kollar, 2013)</ref>. Therefore, we believe build- ing a targeted domain-specific semantic parser for a new website or device is a very practical goal.</p><p>Recent work has made significant strides in reducing supervision from logical forms <ref type="bibr" target="#b26">(Zettlemoyer and Collins, 2005;</ref><ref type="bibr" target="#b23">Wong and Mooney, 2007</ref>) to denotations <ref type="bibr" target="#b5">(Clarke et al., 2010;</ref><ref type="bibr" target="#b13">Liang et al., 2011</ref>) and to weaker forms <ref type="bibr" target="#b0">(Artzi and Zettlemoyer, 2011;</ref><ref type="bibr" target="#b19">Reddy et al., 2014</ref>). All of these works presuppose having input utterances, which do not exist in a new domain. Our methodol- ogy overcomes this hurdle by exploiting a very lightweight form of annotation: paraphrasing.</p><p>Paraphrasing has been applied to single- property question answering <ref type="bibr" target="#b7">(Fader et al., 2013)</ref> and semantic parsing <ref type="bibr" target="#b2">(Berant and Liang, 2014)</ref>. We not only use paraphrasing in the semantic parser, but also for data collection. <ref type="table">Table 2</ref> might evoke rule-based systems <ref type="bibr" target="#b24">(Woods et al., 1972;</ref><ref type="bibr" target="#b22">Warren and Pereira, 1982)</ref> or con- trolled natural languages <ref type="bibr" target="#b20">(Schwitter, 2010)</ref>. How- ever, there is an important distinction: the gram- mar need only connect a logical form to one canonical utterance; it is not used directly for pars- ing. This relaxation allows the grammar to be much simpler. Our philosophy is to use the simple domain-general grammar to carry the torch just to the point of being understandable by a human, and let the human perform the remaining correction to produce a natural utterance.</p><p>In summary, our contributions are two-fold: a new functionality-driven process and an explo- ration of some of its linguistic implications. We believe that our methodology is a promising way to build semantic parsers, and in future work, we would like to extend it to handle anaphora and nested quantification.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Functionality-driven process for building semantic parsers. The two red boxes are the domain-specific parts provided by the builder of the semantic parser, and the other two are generated by the framework.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>For example, if x is "article published in 2015 that cites article 1", then T(x) contains 2015 → NP[2015] and article 1 → NP[article1]. Let L x be the rules in the seed lexicon L where the entity rules (e.g., alice → NP[alice]) are replaced by T(x).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>KobeBryant season.2004)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Category Description Basic #words and bigram matches in (x, c) #words and bigram PPDB matches in (x, c) #unmatched words in x #unmatched words in c size of denotation of z, (|z w |) pos(x0:0) conjoined with type(z w ) #nodes in tree generating z Lexical ∀(i, j) ∈ A. (xi:i, cj:j) ∀(i, j) ∈ A. (xi:i, cj:j+1) ∀(i, j) ∈ A. (xi:i, cj−1:j) ∀(i, j), (i + 1, j + 1) ∈ A. (xi:i+1, cj:j+1) all unaligned words in x and c (xi:j, c i :j ) if in phrase table</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>We experimented on seven domains, covering a variety of phenomena. For each domain, we 
show the number of predicates, number of examples, and a (c, z) generated by our framework along with 
a paraphrased utterance x. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 5 : Test set results on all domains and baselines.</head><label>5</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Test set results in the CALENDAR domain 
on bounded non-compositionality. 

</table></figure>

			<note place="foot">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 1332-1342, Beijing, China, July 26-31, 2015. c 2015 Association for Computational Linguistics Building a Semantic Parser Overnight Yushi Wang * Stanford University yushiw@cs.stanford.edu Jonathan Berant *</note>

			<note place="foot" n="1"> Our system uses the SEMPRE toolkit (http://nlp. stanford.edu/software/sempre).</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Bootstrapping semantic parsers from conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="421" to="432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Weakly supervised learning of semantic parsers for mapping instructions to actions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics (TACL)</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="49" to="62" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Semantic parsing via paraphrasing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Semantic parsing on Freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Large-scale semantic parsing via schema matching and lexicon extension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Driving semantic parsing from the world&apos;s response</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Goldwasser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Natural Language Learning (CoNLL)</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="18" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Adaptive subgradient methods for online learning and stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Learning Theory (COLT)</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Paraphrase-driven learning for open question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">PPDB: The paraphrase database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ganitkevitch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">V</forename><surname>Durme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technology and North American Association for Computational Linguistics (HLT/NAACL)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="758" to="764" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Jointly learning to parse and perceive: Connecting natural language to the physical world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kollar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions of the Association for Computational Linguistics (TACL)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="193" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Using semantic unification to generate regular expressions from natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kushman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technology and North American Association for Computational Linguistics (HLT/NAACL)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="826" to="836" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Scaling semantic parsers with on-the-fly ontology matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Alignment by agreement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Taskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">North American Association for Computational Linguistics (NAACL)</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="104" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning dependency-based compositional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="590" to="599" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<title level="m">Lambda dependency-based compositional semantics. arXiv</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A joint model of language and perception for grounded attribute learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Matuszek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1671" to="1678" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The alignment template approach to statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">J</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="417" to="449" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Compositional semantic parsing on semi-structured tables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Features and pitfalls that users should seek in natural language interfaces to databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A P</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Aguirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Gonzlez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Carpio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Recent Advances on Hybrid Approaches for Designing Intelligent Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="617" to="630" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Largescale semantic parsing without question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lapata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics (TACL)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="377" to="392" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Controlled natural languages for knowledge representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Schwitter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computational Linguistics (COLING)</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1113" to="1121" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Understanding natural language commands for robotic navigation and mobile manipulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tellex</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kollar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dickerson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Walter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Teller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for the Advancement of Artificial Intelligence (AAAI)</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">An efficient easily adaptable system for interpreting natural language queries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="110" to="122" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning synchronous grammars for semantic parsing with lambda calculus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="960" to="967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">The lunar sciences natural language information system: Final report</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">A</forename><surname>Woods</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">N</forename><surname>Webber</surname></persName>
		</author>
		<idno>2378</idno>
		<imprint>
			<date type="published" when="1972" />
			<publisher>Newman Inc</publisher>
		</imprint>
	</monogr>
<note type="report_type">BBN Report</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning to parse database queries using inductive logic programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for the Advancement of Artificial Intelligence (AAAI)</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="1050" to="1055" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Uncertainty in Artificial Intelligence (UAI)</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="658" to="666" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
