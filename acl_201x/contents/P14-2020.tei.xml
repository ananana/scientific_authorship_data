<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:59+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Improved Typesetting Models for Historical OCR</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>June 23-25 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename><surname>Berg-Kirkpatrick</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Division</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Division</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Improved Typesetting Models for Historical OCR</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="118" to="123"/>
							<date type="published">June 23-25 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present richer typesetting models that extend the unsupervised historical document recognition system of Berg-Kirkpatrick et al. (2013). The first model breaks the independence assumption between vertical offsets of neighboring glyphs and, in experiments, substantially decreases transcription error rates. The second model simultaneously learns multiple font styles and, as a result, is able to accurately track italic and non-italic portions of documents. Richer models complicate inference so we present a new, streamlined procedure that is over 25x faster than the method used by Berg-Kirkpatrick et al. (2013). Our final system achieves a relative word error reduction of 22% compared to state-of-the-art results on a dataset of historical newspapers .</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Modern OCR systems perform poorly on histor- ical documents from the printing-press era, often yielding error rates that are too high for down- stream research projects ( <ref type="bibr" target="#b0">Arlitsch and Herbert, 2004;</ref><ref type="bibr" target="#b8">Shoemaker, 2005;</ref><ref type="bibr" target="#b3">Holley, 2010)</ref>. The two primary reasons that historical documents present difficultly for automatic systems are (1) the type- setting process used to produce such documents was extremely noisy and (2) the fonts used in the documents are unknown. <ref type="bibr" target="#b1">Berg-Kirkpatrick et al. (2013)</ref> proposed a system for historical OCR that generatively models the noisy typesetting process of printing-press era documents and learns the font for each input document in an unsupervised fash- ion. Their system achieves state-of-the-art results on the task of historical document recognition.</p><p>We take the system of Berg- <ref type="bibr" target="#b1">Kirkpatrick et al. (2013)</ref> as a starting point and consider extensions of the typesetting model that address two short- comings of their model: (1) their layout model as- sumes that baseline offset noise is independent for each glyph and (2) their font model assumes a sin- gle font is used in every document. Both of these assumptions are untrue in many historical datasets.</p><p>The baseline of the text in printing-press era documents is not rigid as in modern documents but rather drifts up and down noisily (see <ref type="figure" target="#fig_1">Figure 2</ref>). In practice, the vertical offsets of character glyphs change gradually along a line. This means the ver- tical offsets of neighboring glyphs are correlated, a relationship that is not captured by the original model. In our first extension, we let the vertical offsets of character glyphs be generated from a Markov chain, penalizing large changes in offset. We find that this extension decreases transcription error rates. Our system achieves a relative word error reduction of 22% compared to the state-of- the-art original model on a test set of historical newspapers (see Section 4.1), and a 11% relative reduction on a test set of historical court proceed- ings.</p><p>Multiple font styles are also frequently used in printing-press era documents; the most common scenario is for a basic font style to co-occur with an italic variant. For example, it is common for proper nouns and quotations to be italicized in the Old Bailey corpus <ref type="bibr" target="#b8">(Shoemaker, 2005</ref>). In our second extension, we incorporate a Markov chain over font styles, extending the original model so that it is capable of simultaneously learning italic and non-italic fonts within a single document. In experiments, this model is able to detect which words are italicized with 93% precision at 74% recall in a test set of historical court proceedings (see Section 4.2).</p><p>These richer models that we propose do in- crease the state space and therefore make infer- ence more costly. To remedy this, we stream- line inference by replacing the coarse-to-fine in- ference scheme of <ref type="bibr" target="#b1">Berg-Kirkpatrick et al. (2013)</ref> e i1</p><formula xml:id="formula_0">e i g i p i v i g i1 v i1 p i1 X PAD i X GLYPH i X PAD i1 X GLYPH i1 f i1 f i Original model Slow-vary Italic { { { Vertical offset</formula><p>Glyph width with a forward-cost-augmented beaming scheme. Our method is over 25x faster on a typical docu- ment, yet actually yields improved transcriptions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Model</head><p>We first describe the generative model used by the 'Ocular' historical OCR system of Berg- <ref type="bibr" target="#b1">Kirkpatrick et al. (2013)</ref>  <ref type="bibr">1</ref> and then describe our extensions. The graphical model corresponding to their basic generative process for a single line of text is diagrammed in <ref type="figure" target="#fig_0">Figure 1</ref>. A Kneser- Ney ( <ref type="bibr" target="#b4">Kneser and Ney, 1995</ref>) character 6-gram lan- guage model generates a sequence of characters E = (e 1 , e 2 , . . . , e n ). For each character index i, a glyph box width g i and a pad box width p i are gen- erated, conditioned on the character e i . g i specifies the width of the bounding box that will eventually house the pixels of the glyph for character e i . p i specifies the width of a padding box which con- tains the horizontal space before the next character begins. Next, a vertical offset v i is generated for the glyph corresponding to character e i . v i allows the model to capture variance in the baseline of the text in the document. We will later let v i depend on v i−1 , as depicted in <ref type="figure" target="#fig_0">Figure 1</ref>, but in the baseline <ref type="bibr">1</ref> The model we describe and extend has two minor dif- ferences from the one described by <ref type="bibr" target="#b1">Berg-Kirkpatrick et al. (2013)</ref>. While Berg- <ref type="bibr" target="#b1">Kirkpatrick et al. (2013)</ref> generate two pad boxes for each character token, one to the left and one to the right, we only generate one pad box, always to the right. Additionally, <ref type="bibr" target="#b1">Berg-Kirkpatrick et al. (2013)</ref> do not carry over the language model context between lines, while we do. system they are independent. Finally, the pixels in the ith glyph bounding box X GLYPH i are generated conditioned on the character e i , width g i , and ver- tical offset v i , and the pixels in the ith pad bound- ing box X PAD i are generated conditioned on the width p i . We refer the reader to <ref type="bibr" target="#b1">Berg-Kirkpatrick et al. (2013)</ref> for the details of the pixel generation process. We have omitted the token-level inking random variables for the purpose of brevity. These can be treated as part of the pixel generation pro- cess.</p><p>Let X denote the matrix of pixels for the entire line, V = (v 1 , . . . , v n ), P = (p 1 , . . . , p n ), and G = (g 1 , . . . , g n ). The joint distribution is writ- ten:</p><formula xml:id="formula_1">P (X,V, P, G, E) = P (E) [Language model] · n i=1 P (g i |e i ; Φ) [Glyph widths] · n i=1 P (p i |e i ; Φ) [Pad widths] · n i=1 P (v i ) [Vertical offsets] · n i=1 P (X PAD i |p i ) [Pad pixels] · n i=1 P (X GLYPH i |v i , g i , e i ; Φ) [Glyph pixels] 119</formula><p>Document image:</p><p>Learned typsetting independent offsets:</p><p>slow-varying offsets: Learned typsetting The font is parameterized by the vector Φ which governs the shapes of glyphs and the distributions over box widths. Φ is learned in an unsupervised fashion. Document recognition is accomplished via Viterbi decoding over the character random variables e i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Slow-varying Offsets</head><p>The original model generates the vertical offsets v i independently, and therefore cannot model how neighboring offsets are correlated. This correla- tion is actually strong in printing-press era docu- ments. The baseline of the text wanders in the in- put image for two reasons: (1) the physical groove along which character templates were set was un- even and (2) the original document was imaged in a way that produced distortion. Both these under- lying causes are likely to yield baselines that wan- der slowly up and down across a document. We refer to this behavior of vertical offsets as slow- varying, and extend the model to capture it. In our first extension, we augment the model by incorporating a Markov chain over the verti- cal offset random variables v i , as depicted in <ref type="figure" target="#fig_0">Fig- ure 1</ref>. Specifically, v i is generated from a dis- cretized Gaussian centered at v i−1 :</p><formula xml:id="formula_2">P (v i |v i−1 ) ∝ exp (v i − v i−1 ) 2 2σ 2</formula><p>This means that the if v i differs substantially from v i−1 , a large penalty is incurred. As a result, the model should prefer sequences of v i that vary slowly. In experiments, we set σ 2 = 0.05.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Italic Font Styles</head><p>Many of the documents in the Old Bailey corpus contain both italic and non-italic font styles <ref type="bibr" target="#b8">(Shoemaker, 2005</ref>). The way that italic fonts are used depends on the year the document was printed, but generally italics are reserved for proper nouns, quotations, and sentences that have a special role (e.g. the final judgment made in a court case). The switch between font styles almost always occurs at space characters. Our second extension of the typesetting model deals with both italic and non-italic font styles. We augment the model with a Markov chain over font styles f i , as depicted in <ref type="figure" target="#fig_0">Figure 1</ref>. Each font style token f i takes on a value in {ITALIC, NON-ITALIC} and is generated condi- tioned on the previous font style f i−1 and the cur- rent character token e i . Specifically, after generat- ing a character token that is not a space, the lan- guage model deterministically generates the last font used. If the language model generates a space character token, the decision of whether to switch font styles is drawn from a Bernoulli distribution. This ensures that the font style only changes at space characters.</p><p>The font parameters Φ are extended to contain entries for the italic versions of all characters. This means the shapes and widths of italic glyphs can be learned separately from non-italic ones. Like Berg- <ref type="bibr" target="#b1">Kirkpatrick et al. (2013)</ref>, we initialize the font parameters from mixtures of modern fonts, using mixtures of modern italic font styles for italic characters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Streamlined Inference</head><p>Inference in our extended typesetting models is costly because the state space is large; we propose an new inference procedure that is fast and simple. <ref type="bibr" target="#b1">Berg-Kirkpatrick et al. (2013)</ref> used EM to learn the font parameters Φ, and therefore required ex- pected sufficient statistics (indicators on (e i , g i , v i ) tuples), which they computed using coarse-to- fine inference ( <ref type="bibr" target="#b7">Petrov et al., 2008;</ref><ref type="bibr" target="#b10">Zhang and Gildea, 2008</ref>) with a semi-Markov dynamic pro- gram <ref type="bibr" target="#b6">(Levinson, 1986)</ref>. This approach is effec-Learned typesetting: tive, but slow. For example, while transcribing a typical document consisting of 30 lines of text, their system spends 63 minutes computing ex- pected sufficient statistics and decoding when run on a 4.5GHz 4-core CPU.</p><p>We instead use hard counts of the sufficient statistics for learning (i.e. perform hard-EM). As a result, we are free to use inference procedures that are specialized for Viterbi computation. Specif- ically, we use beam-search with estimated for- ward costs. Because the model is semi-Markov, our beam-search procedure is very similar the one used by Pharaoh <ref type="bibr" target="#b5">(Koehn, 2004</ref>) for phrase- based machine translation, only without a distor- tion model. We use a beam of size 20, and estimate forward costs using a character bigram language model. On the machine mentioned above, tran- scribing the same document, our simplified system that uses hard-EM and beam-search spends only 2.4 minutes computing sufficient statistics and de- coding. This represents a 26x speedup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>We ran experiments with four different systems. The first is our baseline, the system presented by <ref type="bibr" target="#b1">Berg-Kirkpatrick et al. (2013)</ref>, which we re- fer to as OCULAR. The second system uses the original model, but uses beam-search for infer- ence. We refer to this system as OCULAR-BEAM. The final two systems use beam-search for infer- ence, but use extended models: OCULAR-BEAM- SV uses the slow-varying vertical offset extension described in Section 2.1 and OCULAR-BEAM- IT uses the italic font extension described in Sec- tion 2.2.</p><p>We evaluate on two different test sets of histor- ical documents. The first test set is called Trove, and is used by <ref type="bibr" target="#b1">Berg-Kirkpatrick et al. (2013)</ref> for evaluation. Trove consists of 10 documents that were printed between 1803 and 1954, each con- sisting of 30 lines, all taken from a collection of historical Australian newspapers hosted by the Na- tional Library of Australia <ref type="bibr" target="#b3">(Holley, 2010)</ref>. The second test set, called Old Bailey, consists of 20 documents that were printed between 1716 and 1906, each consisting of 30 lines, all taken from a the proceedings of the Old Bailey Courthouse in London <ref type="bibr" target="#b8">(Shoemaker, 2005</ref>). 2 Following Berg- <ref type="bibr" target="#b1">Kirkpatrick et al. (2013)</ref>, we train the language model using 36 millions words from the New York Times portion of the Gigaword corpus ( <ref type="bibr" target="#b2">Graff et al., 2007</ref>). <ref type="bibr">3</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Document Recognition Performance</head><p>We evaluate predicted transcriptions using both character error rate (CER) and word error rate (WER). CER is the edit distance between the guessed transcription and the gold transcription, divided by the number of characters in the gold transcription. WER is computed in the same way, but words are treated as tokens instead of charac- ters.</p><p>First we compare the baseline, OCULAR, to our system with simplified inference, OCULAR- BEAM. To our surprise, we found that OCULAR- BEAM produced better transcriptions than OCU- LAR. On Trove, OCULAR achieved a WER of 33.0 while OCULAR-BEAM achieved a WER of 30.7. On Old Bailey, OCULAR achieved a WER of 30.8 while OCULAR-BEAM achieved a WER of 28.8. These results are shown in <ref type="table">Table 1</ref>, where we also report the performance of Google Tesseract <ref type="bibr" target="#b9">(Smith, 2007)</ref> and ABBYY FineReader, a state- of-the-art commercial system, on the Trove test set (taken from <ref type="bibr" target="#b1">Berg-Kirkpatrick et al. (2013)</ref>).</p><p>Next, we evaluate our slow-varying vertical off- set model. OCULAR-BEAM-SV out-performs OCULAR-BEAM on both test sets. On Trove, OCULAR-BEAM-SV achieved a WER of 25.6, and on Old Bailey, OCULAR-BEAM-SV achieved a WER of 27.5. Overall, compared to our baseline system, OCULAR-BEAM-SV achieved a relative reduction in WER of 22% on Trove and 11% on Old Bailey.</p><p>By looking at the predicted typesetting layouts we can make a qualitative comparison between the vertical offsets predicted by OCULAR-BEAM and OCULAR-BEAM-SV. <ref type="figure" target="#fig_1">Figure 2</ref> shows representa- tions of the Viterbi estimates of the typesetting random variables predicted by the models on a portion of an example document. The first line is the typesetting layout predicted by OCULAR- BEAM-SV and the second line is same, but for OCULAR-BEAM. The locations of padding boxes are depicted in blue. The white glyph bounding boxes reveal the values of the Bernoulli template probabilities used to generate the observed pixels. The Bernoulli templates are produced from type- level font parameters, but are modulated by token- level widths g i and vertical offsets v i (and ink- ing random variables, whose description we have omitted for brevity). The predicted vertical off- sets are visible in the shifted baselines of the tem- plate probabilities. The third line shows the corre- sponding portion of the input image. In this ex- ample, the text baseline predicted by OCULAR- BEAM-SV is contiguous, while the one predicted by OCULAR-BEAM is not. Given how OCULAR- BEAM-SV was designed, this meets our expecta- tions. The text baseline predicted by OCULAR- BEAM has a discontinuity in the middle of its pre- diction for the gold word Surplus. In contrast, the vertical offsets predicted by OCULAR-BEAM- SV at this location vary smoothly and more ac- curately match the true text baseline in the input image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Font Detection Performance</head><p>We ran experiments with the italic font style model, OCULAR-BEAM-IT, on the Old Bai- ley test set (italics are infrequent in Trove). We evaluated the learned styles by measuring how ac- curately OCULAR-BEAM-IT was able to distin- guish between italic and non-italic styles. Specifi- cally, we computed the precision and recall for the system's predictions about which words were ital- icized. We found that, across the entire Old Bai- ley test set, OCULAR-BEAM-IT was able to detect which words were italicized with 93% precision at 74% recall, suggesting that the system did suc- cessfully learn both italic and non-italic styles. <ref type="bibr">4</ref>  We can look at the typesetting layout predicted by OCULAR-BEAM-IT to gain insight into what has been learned by the model. The first line of <ref type="figure" target="#fig_2">Figure 3</ref> shows the typesetting layout predicted by the OCULAR-BEAM-IT model for a line of a doc- ument image that contains italics. The second line of <ref type="figure" target="#fig_2">Figure 3</ref> displays the corresponding portion of the input document image. From this example, it appears that the model has effectively learned separate glyph shapes for italic and non-italic ver- sions of certain characters. For example, compare the template probabilities used to generate the d's in defraud to the template probabilities used to generate the d in hard.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System CER WER Trove</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We began with an efficient simplification of the state-of-the-art historical OCR system of <ref type="bibr">BergKirkpatrick et al. (2013)</ref> and demonstrated two ex- tensions to its underlying model. We saw an im- provement in transcription quality as a result of re- moving a harmful independence assumption. This suggests that it may be worthwhile to consider still further extensions of the model, designed to more faithfully reflect the generative process that pro- duced the input documents.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: See Section 2 for a description of the generative process. We consider an extension of Berg-Kirkpatrick et al. (2013) that generates vi conditioned on the previous vertical offset vi−1 (labeled Slow-vary) and an extension that generates a sequence of font styles fi (labeled Italic).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The first line depicts the Viterbi typesetting layout predicted by the OCULAR-BEAM-SV model. The second line depicts the same, but for the OCULAR-BEAM model. Pad boxes are shown in blue. Glyphs boxes are shown in white and display the Bernoulli template probabilities used to generate the observed pixels. The third line shows the corresponding portion of the input image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: This first line depicts the Viterbi typesetting layout predicted by the OCULAR-BEAM-IT model. Pad boxes are shown in blue. Glyphs boxes are shown in white and display the Bernoulli template probabilities used to generate the observed pixels. The second line shows the corresponding portion of the input image.</figDesc></figure>

			<note place="foot" n="2"> Old Bailey is comparable to the the second test set used by Berg-Kirkpatrick et al. (2013) since it is derived from the same collection and covers a similar time span, but it consists of different documents. 3 This means the language model is out-of-domain on both test sets. Berg-Kirkpatrick et al. (2013) also consider a perfectly in-domain language model, though this setting is somewhat unrealistic.</note>

			<note place="foot" n="4"> While it seems plausible that learning italics could also improve transcription accuracy, we found that OCULAR</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported by Grant IIS-1018733 from the National Science Foundation and also a National Science Foundation fellowship to the first author.</p><p>BEAM-IT actually performed slightly worse than OCULAR-BEAM. This negative result is possibly due to the extra diffi-culty of learning a larger number of font parameters.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Microfilm, paper, and OCR: Issues in newspaper digitization. the Utah digital newspapers program. Microform &amp; Imaging Review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenning</forename><surname>Arlitsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Herbert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Unsupervised transcription of historical documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Durrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">English Gigaword third edition. Linguistic Data Consortium, Catalog Number LDC2007T07</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Graff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junbo</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuaki</forename><surname>Maeda</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Trove: Innovation in access to information in Australia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rose</forename><surname>Holley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Ariadne</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Improved backing-off for m-gram language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reinhard</forename><surname>Kneser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Acoustics, Speech, and Signal Processing</title>
		<meeting>the International Conference on Acoustics, Speech, and Signal Processing</meeting>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Pharaoh: a beam search decoder for phrase-based statistical machine translation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine translation: From real users to research</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="115" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Continuously variable duration hidden Markov models for automatic speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stephen Levinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Coarse-to-fine syntactic machine translation using language projections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aria</forename><surname>Haghighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2008 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Digital London: Creating a searchable web of interlinked sources on eighteenth century London. Electronic Library and Information Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Shoemaker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">An overview of the Tesseract OCR engine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ray</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International Conference on Document Analysis and Recognition</title>
		<meeting>the Ninth International Conference on Document Analysis and Recognition</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Efficient multipass decoding for synchronous context free grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2008 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
