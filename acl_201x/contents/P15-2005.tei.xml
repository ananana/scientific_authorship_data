<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:00+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Semi-Stacking for Semi-supervised Sentiment Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 26-31, 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shoushan</forename><surname>Li</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Collaborative Innovation Center of Novel Software Technology and Industrialization</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">† ‡</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Huang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingjing</forename><surname>Wang</surname></persName>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
							<email>gdzhou@suda.edu.cn</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="laboratory">Natural Language Processing Lab</orgName>
								<orgName type="institution">Soochow University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Semi-Stacking for Semi-supervised Sentiment Classification</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="27" to="31"/>
							<date type="published">July 26-31, 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In this paper, we address semi-supervised sentiment learning via semi-stacking, which integrates two or more semi-supervised learning algorithms from an ensemble learning perspective. Specifically, we apply meta-learning to predict the unlabeled data given the outputs from the member algorithms and propose N-fold cross validation to guarantee a suitable size of the data for training the meta-classifier. Evaluation on four domains shows that such a semi-stacking strategy performs consistently better than its member algorithms .</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The past decade has witnessed a huge exploding interest in sentiment analysis from the natural lan- guage processing and data mining communities due to its inherent challenges and wide applica- tions ( <ref type="bibr" target="#b12">Pang et al., 2008;</ref><ref type="bibr" target="#b11">Liu, 2012)</ref>. One funda- mental task in sentiment analysis is sentiment classification, which aims to determine the senti- mental orientation a piece of text expresses <ref type="bibr" target="#b13">(Pang et al., 2002</ref>). For instance, the sentence "I abso- lutely love this product." is supposed to be deter- mined as a positive expression in sentimental ori- entation. <ref type="bibr"></ref> While early studies focus on supervised learn- ing, where only labeled data are required to train the classification model ( <ref type="bibr" target="#b13">Pang et al., 2002</ref>), recent studies devote more and more to reduce the heavy dependence on the large amount of labeled data by exploiting semi-supervised learning ap- proaches, such as co-training <ref type="bibr" target="#b16">(Wan, 2009;</ref><ref type="bibr" target="#b10">Li et al., 2011</ref>), label propagation ( <ref type="bibr" target="#b15">Sindhwani and Melville, 2008)</ref>, and deep learning ( <ref type="bibr" target="#b9">Zhou et al., 2013)</ref>, to sentiment classification. Empirical evaluation on various domains demonstrates the effectiveness of the unlabeled data in enhancing the performance  * Corresponding author of sentiment classification. However, semi-super- vised sentiment classification remains challeng- ing due to the following reason.</p><p>Although various semi-supervised learning al- gorithms are now available and have been shown to be successful in exploiting unlabeled data to improve the performance in sentiment classifica- tion, each algorithm has its own characteristic with different pros and cons. It is rather difficult to tell which performs best in general. Therefore, it remains difficult to pick a suitable algorithm for a specific domain. For example, as shown in <ref type="bibr" target="#b9">Li et al. (2013)</ref>, the co-training algorithm with personal and impersonal views yields better performances in two product domains: Book and Kitchen, while the label propagation algorithm yields better per- formances in other two product domains: DVD and Electronic.</p><p>In this paper, we overcome the above challenge above by combining two or more algorithms in- stead of picking one of them to perform semi-su- pervised learning. The basic idea of our algorithm ensemble approach is to apply meta-learning to re-predict the labels of the unlabeled data after ob- taining their results from the member algorithms. First, a small portion of labeled samples in the in- itial labeled data, namely meta-samples, are picked as unlabeled samples and added into the initial unlabeled data to form a new unlabeled data. Second, we use the remaining labeled data as the new labeled data to perform semi-supervised learning with each member algorithm. Third, we collect the meta-samples' probability results from all member algorithms to train a meta-learning classifier (called meta-classifier). Forth and fi- nally, we utilize the meta-classifier to re-predict the unlabeled samples as new automatically-la- beled samples. Due to the limited number of la- beled data in semi-supervised learning, we use N- fold cross validation to obtain more meta-samples for better learning the meta-classifier. In principle, the above ensemble learning approach could be seen as an extension of the famous stacking ap- proach ( <ref type="bibr">Džeroski and Ženko, 2004</ref>) to semi-su- pervised learning. For convenience, we call it semi-stacking.</p><p>The remainder of this paper is organized as fol- lows. Section 2 overviews the related work on semi-supervised sentiment classification. Section 3 proposes our semi-stacking strategy to semi-su- pervised sentiment classification. Section 4 pro- poses the data filtering approach to filter low-con- fident unlabeled samples. Section 5 evaluates our approach with a benchmark dataset. Finally, Sec- tion 6 gives the conclusion and future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Early studies on sentiment classification mainly focus on supervised learning methods with algo- rithm designing and feature engineering ( <ref type="bibr" target="#b13">Pang et al., 2002;</ref><ref type="bibr" target="#b2">Cui et al., 2006;</ref><ref type="bibr" target="#b14">Riloff et al., 2006;</ref><ref type="bibr" target="#b8">Li et al., 2009)</ref>. Recently, most studies on sentiment classification aim to improve the performance by exploiting unlabeled data in two main aspects: semi-supervised learning <ref type="bibr" target="#b3">(Dasgupta and Ng, 2009;</ref><ref type="bibr" target="#b16">Wan, 2009;</ref><ref type="bibr" target="#b7">Li et al., 2010</ref>) and cross-domain learning ( <ref type="bibr" target="#b0">Blitzer et al. 2007;</ref><ref type="bibr" target="#b6">He et al. 2011;</ref><ref type="bibr" target="#b9">Li et al., 2013)</ref>. Specifically, existing approaches to semi-supervised sentiment classification could be categorized into two main groups: bootstrapping- style and graph-based.</p><p>As for bootstrapping-style approaches, Wan (2009) considers two different languages as two views and applies co-training to conduct semi-su- pervised sentiment classification. Similarly, <ref type="bibr" target="#b7">Li et al. (2010)</ref> propose two views, named personal and impersonal views, and apply co-training to use un- labeled data in a monolingual corpus. More re- cently, <ref type="bibr" target="#b5">Gao et al. (2014)</ref> propose a feature sub- space-based self-training to semi-supervised sen- timent classification. Empirical evaluation demonstrates that subspace-based self-training outperforms co-training with personal and imper- sonal views.</p><p>As for graph-based approaches, Sindhwani and Melville (2008) first construct a document-word bipartite graph to describe the relationship among the labeled and unlabeled samples and then apply label propagation to get the labels of the unlabeled samples.</p><p>Unlike above studies, our research on semi-su- pervised sentiment classification does not merely focus on one single semi-supervised learning al- gorithm but on two or more semi-supervised learning algorithms with ensemble learning. To the best of our knowledge, this is the first attempt to combine two or more semi-supervised learning algorithms in semi-supervised sentiment classifi- cation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Semi-Stacking for Semi-supervised Sentiment Classification</head><p>In semi-supervised sentiment classification, the learning algorithm aims to learn a classifier from a small scale of labeled samples, named initial la- beled data, with a large number of unlabeled sam- ples. In the sequel, we refer the labeled data as </p><formula xml:id="formula_0">1 {( , )} L n i i i L x y  </formula><formula xml:id="formula_1">' {( , )} U n k k k U x y  </formula><p>which de- notes the unlabeled data with automatically as- signed labels. Besides the labeled results, it is al- ways possible to obtain the probability results, de- noted as U P  , which contains the posterior proba- bilities belonging to the positive and negative cat- egories of each unlabeled sample, i.e., &lt;</p><p>kk p pos x p neg x &gt;. For clarity, some im- portant symbols are listed in <ref type="table" target="#tab_1">Table 1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Framework Overview</head><p>In our approach, two member semi-supervised learning algorithm are involved, namely, 1 semi l and 2 semi l respectively, and the objective is to leverage both of them to get a better-performed semi-su- pervised learning algorithm. Our basic idea is to apply meta-learning to re-predict the labels of the unlabeled data given the outputs from the member algorithms. <ref type="figure" target="#fig_0">Figure 1</ref> shows the framework of our implementation of the basic idea. The core com- ponent in semi-stacking is the meta-classifier learned from the meta-learning process, i.e., meta c . This classifier aims to make a better prediction on the unlabeled samples by combining two different probability results from the two member algo- rithms. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Meta-learning</head><p>As shown above, meta-classifier is the core com- ponent in semi-stacking, trained through the meta- learning process. Here, meta-means the learning samples are not represented by traditional descrip- tive features, e.g., bag-of-words features, but by the result features generated from member algo- rithms. In our approach, the learning samples in meta-learning are represented by the posterior probabilities of the unlabeled samples belonging to the positive and negative categories from mem- ber algorithms, i.e.,  Procedure:  One problem of meta-learning is that the data size of un L might be too small to learn a good meta- classifier. To better use the labeled samples in the initial labeled data, we employ N-fold cross vali- dation to generate more meta-samples. Specifi- cally, we first split L into N folds. Then, we se- lect one of them as un L and consider the others as new L and generate the meta-learning samples as described in Section 3.2; Third and finally, we re- peat the above step 1 N  times by selecting a dif- ferent fold as un L in each time. In this way, we can obtain the meta-learning samples with the same size as the initial labeled data. <ref type="figure" target="#fig_3">Figure 3</ref> presents the algorithm description of meta-learning with N-fold cross validation. In our implementation, we set N to be 10. Semi-supervised learning algorithms: (1) The first member algorithm is called self-trainingFS, proposed by <ref type="bibr" target="#b5">Gao et al. (2014)</ref>. This approach can be seen as a special case of self-training. Different from the traditional self-training, self-trainingFS use the feature-subspace classifier to make the prediction on the unlabeled samples instead of us- ing the whole-space classifier. In our implementa- tion, we use four random feature subspaces. <ref type="formula">(2)</ref> The second member algorithm is called label propagation, a graph-based semi-supervised learning approach, proposed by <ref type="bibr" target="#b18">Zhu and Ghahramani (2002)</ref>. In our implementation, the docu- ment-word bipartite graph is adopted to build the document-document graph <ref type="bibr" target="#b15">(Sindhwani and Melville, 2008)</ref>. Significance testing: We perform t-test to evalu- ate the significance of the performance difference between two systems with different approaches (Yang and Liu, 1999) <ref type="figure" target="#fig_4">Figure 4</ref> compares the performances of the baseline approach and three semi-supervised learning approaches. Here, the baseline approach is the supervised learning approach by using only the initial labeled data (i.e. no unlabeled data is used). From the figure, we can see that both Self- trainingFS and label propagation are successful in exploiting unlabeled data to improve the perfor- mances. Self-trainingFS outperforms label propa- gation in three domains including Book, DVD, and Kitchen but it performs worse in Electronic. Our approach (semi-stacking) performs much bet- ter than baseline with an impressive improvement of 4.95% on average. Compared to the two mem- ber algorithms, semi-stacking always yield a bet- ter performance, although the improvement over the better-performed member algorithm is slight, only around 1%-2%. Significance test shows that our approach performs significantly better than worse-performed member algorithm (p- value&lt;0.01) in all domains and it also performs significantly better than better-performed member algorithm (p-value&lt;0.05) in three domains, i.e., Book, DVD, and Kitchen.</p><formula xml:id="formula_3">(a) Initialize the meta-sample set meta S  (b) Split L into N folds, i.e., 12 N L L L L    (c) For i in 1: N : c1) new i L L L , un i LL  c2</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we present a novel ensemble learn- ing approach named semi-stacking to semi-super- vised sentiment classification. Semi-stacking is implemented by re-predicting the labels of the un- labeled samples with meta-learning after two or more member semi-supervised learning ap- proaches have been performed. Experimental evaluation in four domains demonstrates that semi-stacking outperforms both member algo- rithms. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The framework of semi-stacking</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>p</head><label></label><figDesc>pos x and 1 ( | ) k p neg x are the pos- terior probabilities from the first semi-supervised learning algorithm while 2 ( | ) k p pos x and 2 ( | ) k p neg x are the posterior probabilities from the second semi-supervised learning algorithm. The framework of the meta-learning process is shown in Figure 2. In detail, we first split the ini- tial labeled data into two partitions, new L and un L where new L is used as the new initial labeled data while un L is merged into the unlabeled data U to form a new set of unlabeled data un LU  . Then, two semi-supervised algorithms are performed with the labeled data new L and the unlabeled data un LU  . Third and finally, the probability results of un L , together with their real labels are used as meta-learning samples to train the meta-classifier. The feature representation of each meta-sample is defined in Formula (1).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The framework of meta-learning 3.3 Meta-learning with N-fold Cross Validation Input: Labeled data L , Unlabeled data U Output: The meta-classifier meta c</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The algorithm description of meta-learning with N-fold cross validation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Performance comparison of baseline and three semi-supervised learning approaches</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>are L and U , and the output is 1</head><label></label><figDesc></figDesc><table>where 

d 
i 

x R is the d dimen-
sional input vector, and i 
y is its output label. The 
unlabeled data in the target domain is denoted as 

1 

{( )} U 

n 
kk 

Ux  
 
. Suppose semi 

l 

is a semi-supervised 

learning algorithm. The inputs of semi 

l 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Symbol definition 
Symbol 
Definition 
L 
Labeled data 
U 
Unlabeled data 

U  
Unlabeled data with automatically 
assigned labels 

U 

P  
The probability result of unlabeled 
data 

super 

l 
A supervised learning algorithm 

semi 

l 
A semi-supervised learning algo-
rithm 

meta 

c 
The meta-classifier obtained from 
meta-learning 

test 

c 
The test classifier for classifying the 
test data 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>) Perform 1 semi l on new L and un LU  c3) Perform 2 semi l on new L and un LU </head><label></label><figDesc></figDesc><table>c4) Generate the meta-samples, i 

meta 

S 
, 

from the probability results of un 
L in the above 
two steps. 
c5) 

i 
meta 
meta 
meta 

S 
S 
S 
 

(d) Train the meta-classifier meta 
c 
with meta 
S 

and super 
l 

</table></figure>

			<note place="foot" n="1"> 1 2 2</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research work has been partially supported by three NSFC grants, <ref type="bibr">No.61273320, No.61375073, No.61331011</ref>, and Collaborative Innovation Center of Novel Software Technology and Industrialization.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Biographies, Bollywood, Boom-boxes and Blenders: Domain Adaptation for Sentiment Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dredze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-07</title>
		<meeting>ACL-07</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="440" to="447" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Combining Labeled and Unlabeled Data with Co-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLT-98</title>
		<meeting>COLT-98</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="92" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Comparative Experiments on Sentiment Classification for Online Product Reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Datar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI-06</title>
		<meeting>AAAI-06</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="1265" to="1270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Mine the Easy, Classify the Hard: A Semi-Supervised Approach to Automatic Sentiment Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-IJCNLP-09</title>
		<meeting>ACL-IJCNLP-09</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="701" to="709" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Džeroski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ženko</surname></persName>
		</author>
		<title level="m">Is Combining Classifiers with Stacking Better than Selecting the Best One? Machine Learning</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="255" to="273" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Semi-supervised Sentiment Classification with Self-training on Feature Subspaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CLSW-14</title>
		<meeting>CLSW-14</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="231" to="239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Automatically Extracting Polarity-Bearing Topics for Cross-Domain Sentiment Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Alani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-11</title>
		<meeting>ACL-11</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="123" to="131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Employing Personal/Impersonal Views in Supervised and Semi-supervised Sentiment Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><forename type="middle">S</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-10</title>
		<meeting>ACL-10</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="414" to="423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A Framework of Feature Selection Methods for Text Categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><forename type="middle">S</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-IJCNLP-09</title>
		<meeting>ACL-IJCNLP-09</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="692" to="700" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Active Learning for Cross-Domain Sentiment Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><forename type="middle">S</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI-13</title>
		<meeting>IJCAI-13</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2127" to="2133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Semi-supervised Learning for Imbalanced Sentiment Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><forename type="middle">S</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI-11</title>
		<meeting>IJCAI-11</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1826" to="1831" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Sentiment Analysis and Opinion Mining (Introduction and Survey)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012-05" />
			<publisher>Morgan &amp; Claypool Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Opinion Mining and Sentiment Analysis: Foundations and Trends. Information Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Thumbs up? Sentiment Classification using Machine Learning Techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vaithyanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-02</title>
		<meeting>EMNLP-02</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Feature Subsumption for Opinion Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Riloff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Patwardhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wiebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-06</title>
		<meeting>EMNLP-06</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="440" to="448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Document-Word Co-Regularization for Semi-supervised Sentiment Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sindhwani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Melville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICDM-08</title>
		<meeting>ICDM-08</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1025" to="1030" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Co-Training for Cross-Lingual Sentiment Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACLIJCNLP-09</title>
		<meeting>ACLIJCNLP-09</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="235" to="243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A Re-Examination of Text Categorization Methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGIR99</title>
		<meeting>SIGIR99</meeting>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Learning from Labeled and Unlabeled Data with Label Propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<idno>. CMU-CALD-02- 107</idno>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
		<respStmt>
			<orgName>CMU CALD</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
