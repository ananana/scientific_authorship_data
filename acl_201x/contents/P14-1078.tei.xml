<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:13+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Medical Relation Extraction with Manifold Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>June 23-25 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Wang</surname></persName>
							<email>changwangnk@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">IBM T. J. Watson Research Center Yorktown Heights</orgName>
								<orgName type="institution">IBM T. J. Watson Research Center Yorktown Heights</orgName>
								<address>
									<postCode>10598, 10598</postCode>
									<region>New York, New York</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Fan</surname></persName>
							<email>fanj@us.ibm.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">IBM T. J. Watson Research Center Yorktown Heights</orgName>
								<orgName type="institution">IBM T. J. Watson Research Center Yorktown Heights</orgName>
								<address>
									<postCode>10598, 10598</postCode>
									<region>New York, New York</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Medical Relation Extraction with Manifold Models</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="828" to="838"/>
							<date type="published">June 23-25 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In this paper, we present a manifold model for medical relation extraction. Our model is built upon a medical corpus containing 80M sentences (11 gigabyte text) and designed to accurately and efficiently detect the key medical relations that can facilitate clinical decision making. Our approach integrates domain specific parsing and typing systems, and can utilize labeled as well as unlabeled examples. To provide users with more flexibility, we also take label weight into consideration. Effectiveness of our model is demonstrated both theoretically with a proof to show that the solution is a closed-form solution and experimentally with positive results in experiments .</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>There exists a vast amount of knowledge sources and ontologies in the medical domain. Such in- formation is also growing and changing extremely quickly, making the information difficult for peo- ple to read, process and remember. The combi- nation of recent developments in information ex- traction and the availability of unparalleled medi- cal resources thus offers us the unique opportunity to develop new techniques to help healthcare pro- fessionals overcome the cognitive challenges they face in clinical decision making.</p><p>Relation extraction plays a key role in informa- tion extraction. Using question answering as an example ( <ref type="bibr">Wang et al., 2012)</ref>: in question analy- sis, the semantic relations between the question focus and each term in the clue can be used to identify the weight of each term so that better search queries can be generated. In candidate an- swer generation, relations enable the background knowledge base to be used for potential candidate answer generation. In candidate answer scoring, relation-based matching algorithms can go beyond explicit lexical and syntactic information to detect implicit semantic relations shared across the ques- tion and passages.</p><p>To construct a medical relation extraction sys- tem, several challenges have to be addressed:</p><p>• The first challenge is how to identify a set of relations that has sufficient coverage in the medical domain. To address this issue, we study a real-world diagnosis related question set and identify a set of relations that has a good coverage of the clinical questions.</p><p>• The second challenge is how to efficiently de- tect relations in a large amount of medical text. The medical corpus underlying our re- lation extraction system contains 80M sen- tences (11 gigabytes pure text). To extract relations from a dataset at this scale, the re- lation detectors have to be fast. In this paper, we speed up relation detectors through pars- ing adaptation and replacing non-linear clas- sifiers with linear classifiers.</p><p>• The third challenge is that the labeled rela- tion examples are often insufficient due to the high labeling cost. When we build a na¨ıvena¨ıve model to detect relations, the model tends to overfit for the labeled data. To address this issue, we develop a manifold model ( <ref type="bibr" target="#b2">Belkin et al., 2006</ref>) that encourages examples (in- cluding both labeled and unlabeled exam- ples) with similar contents to be assigned with similar scores. Our model goes beyond regular regression models in that it applies constraints to those coefficients, such that the topology of the given data manifold will be respected. Computing the optimal weights in a regression model and preserving mani- fold topology are conflicting objectives, we present a closed-form solution to ideally bal- ance these two goals.</p><p>The contributions of this paper on medical rela- tion extraction are three-fold:</p><p>• The problem setup is new. There is a "fundamental" difference between our prob- lem setup and the conventional setups, like i2b2 <ref type="bibr">(Uzuner et al., 2011</ref>). In i2b2 rela- tion extraction task, entity mentions are man- ually labeled, and each mention has 1 of 3 concepts: 'treatment', 'problem', and 'test'. To resemble real-world medical relation ex- traction challenges where perfect entity men- tions do not exist, our new setup requires the entity mentions to be automatically de- tected. The most well-known tool to detect medical entity mentions is MetaMap <ref type="bibr" target="#b1">(Aronson, 2001</ref>), which considers all terms as en- tities and automatically associates each term with a number of concepts from UMLS CUI dictionary ( <ref type="bibr" target="#b13">Lindberg et al., 1993</ref>) with more than 2.7 million distinct concepts (compared to 3 in i2b2). The huge amount of entity mentions, concepts and noisy concept assign- ments provide a tough situation that people have to face in real-world applications.</p><p>• From the perspective of relation extraction applications, we identify "super relations"- the key relations that can facilitate clinical decision making <ref type="table">(Table 1)</ref>. We also present approaches to collect training data for these relations with a small amount of labeling ef- fort.</p><p>• From the perspective of relation extraction methodologies, we present a manifold model for relation extraction utilizing both labeled and unlabeled data. Our approach can also take the label weight into consideration.</p><p>The experimental results show that our relation detectors are fast and outperform the state-of-the- art approaches on medical relation extraction by a large margin. We also apply our model to build a new medical relation knowledge base as a comple- ment to the existing knowledge bases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Medical Ontologies and Sources</head><p>Medical domain has a huge amount of natural lan- guage content found in textbooks, encyclopedias, guidelines, electronic medical records, and many other sources. It is also growing at an extremely high speed. Substantial understanding of the med- ical domain has already been included in the Uni- fied Medical Language System (UMLS) <ref type="bibr" target="#b13">(Lindberg et al., 1993)</ref>, which includes medical con- cepts, relations, definitions, etc. The 2012 version of the UMLS contains information about more than 2.7 million concepts from over 160 source vocabularies. Softwares for using this knowledge also exist: MetaMap <ref type="bibr" target="#b1">(Aronson, 2001</ref>) is able to identify concepts in text. SEMREP ( <ref type="bibr" target="#b20">Rindflesch and Fiszman, 2003)</ref> can detect some relations us- ing hand-crafted rules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Relation Extraction</head><p>To extract semantic relations from text, three types of approaches have been applied. Rule-based methods ( <ref type="bibr" target="#b15">Miller et al., 2000</ref>) employ a number of linguistic rules to capture relation patterns. Feature-based methods <ref type="bibr" target="#b12">(Kambhatla, 2004;</ref><ref type="bibr">Zhao and Grishman, 2005</ref>) transform relation instances into a large amount of linguistic features like lex- ical, syntactic and semantic features, and capture the similarity between these feature vectors. Re- cent results mainly rely on kernel-based meth- ods. Many of them focus on using tree kernels to learn parse tree structure related features <ref type="bibr" target="#b5">(Collins and Duffy, 2001;</ref><ref type="bibr" target="#b6">Culotta and Sorensen, 2004;</ref><ref type="bibr" target="#b3">Bunescu and Mooney, 2005</ref>).</p><p>Other researchers study how different ap- proaches can be combined to improve the extrac- tion performance. For example, by combining tree kernels and convolution string kernels, ( <ref type="bibr">Zhang et al., 2006</ref>) achieved the state of the art performance on ACE data <ref type="bibr" target="#b0">(ACE, 2004)</ref>. Recently, "distant su- pervision" has emerged to be a popular choice for training relation extractors without using manually labeled data ( <ref type="bibr" target="#b17">Mintz et al., 2009;</ref><ref type="bibr" target="#b11">Jiang, 2009;</ref><ref type="bibr" target="#b4">Chan and Roth, 2010;</ref><ref type="bibr">Wang et al., 2011;</ref><ref type="bibr" target="#b19">Riedel et al., 2010;</ref><ref type="bibr" target="#b10">Ji et al., 2011;</ref><ref type="bibr" target="#b9">Hoffmann et al., 2011;</ref><ref type="bibr" target="#b23">Surdeanu et al., 2012;</ref><ref type="bibr">Takamatsu et al., 2012;</ref><ref type="bibr" target="#b16">Min et al., 2013</ref>).</p><p>Various relation extraction approaches have been adapted to the medical domain, most of which focus on designing heuristic rules targeted for diagnosis and integrating the medical ontology in the existing extraction approaches. Results of some of these approaches are reported on the i2b2 data <ref type="bibr">(Uzuner et al., 2011</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Identifying Key Medical Relations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Super Relations in Medical Domain</head><p>The first step in building a relation extraction sys- tem for medical domain is to identify the relations that are important for clinical decision making.</p><p>Four main clinical tasks that physicians engage in are discussed in <ref type="bibr" target="#b8">(Demner-Fushman and Lin, 2007)</ref>. They are Therapy-select treatments to of- fer a patient, taking consideration of effectiveness, risk, cost and other factors (prevention is under the general category of Therapy), Diagnosis (includ- ing differential diagnosis based on findings and di- agnostic test), Etiology-identify the factors that cause the disease and Prognosis-estimate the pa- tient's likely course over time. These activities can be translated into "search tasks". For example, the search for therapy is usually the therapy selection given a disease.</p><p>We did an independent study regarding what clinical questions usually ask for on a set of 5,000 Doctor Dilemma (DD) questions from the Ameri- can College of Physicians (ACP). This set includes questions about diseases, treatments, lab tests, and general facts 1 . Our analysis shows that about 15% of these questions ask for treatments, preventions or contraindicated drugs for a disease or another way around, 4% are about diagnosis tests, 6% are about the causes of a disease, 1% are about the lo- cations of a disease, 25% are about the symptoms of a disease, 8% are asking for definitions, 7% are about guidelines and the remaining 34% questions either express no relations or some relations that are not very popular.</p><p>Based on the analysis in <ref type="bibr" target="#b8">(Demner-Fushman and Lin, 2007)</ref> and our own results, we decided to fo- cus on seven key relations in the medical domain, which are described in <ref type="table">Table 1</ref>. We call these re- lations "super relations", since they cover most questions in the DD question set and align well with the analysis result in (Demner-Fushman and Lin, 2007).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Collect Training Data</head><p>This section presents how we collect training data for each relation. The overall procedure is illus- trated in <ref type="figure">Figure 1</ref>. <ref type="bibr">1</ref> Here's an example of these questions and its answer: Question: The syndrome characterized by joint pain, abdom- inal pain, palpable purpura, and a nephritic sediment. An- swer: Henoch-Schonlein purpura.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Large Amount of Noisy Relation Data</head><p>Medical Text</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relation Knowledge in Medical Domain</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training Data for Each Relation</head><p>For each relation, choose a small amount of the most representative examples</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Annotation</head><p>Unlabeled Data</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Labeled Data</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1: Collect Training Data</head><p>Our medical corpus has incorporated a set of medical books/journals 2 and MEDLINE ab- stracts. We also complemented these sources with Wikipedia articles. In total, the corpus contains 80M sentences (11 gigabyte pure text).</p><p>The UMLS 2012 Release contains more than 600 relations and 50M relation instances under around 15 categories. The RO category (RO stands for "has Relationship Other than synony- mous, narrower, or broader") is the most inter- esting one, and covers relations like "may treat", "has finding site", etc.</p><p>Each relation has a certain number of Concept Unique Identifier (CUI) pairs that are known to bear that rela- tion. In UMLS, some relation information is redundant. Firstly, half of these relations are simply inverse of each other (e.g. the relation "may treat" and "may be treated by"). Secondly, there is a significant amount of redundancy even among non-inverse relations (e.g. the relation "has manifestation" and "disease has finding").</p><p>From UMLS relations, we manually chose a subset of them that are directly related to the su- per relations discussed in Section 3.1. The cor- respondences between them are given in <ref type="table">Table 1</ref>. One thing to note is that super relations are more general than the UMLS relations, and one super relation might integrate multiple UMLS relations. Using the CUI pairs in the UMLS relation knowl- <ref type="table">Table 1</ref>: Super relations &amp; their arguments, UMLS sources and noise% in the annotation data <ref type="table" target="#tab_1">treats  disease  treatments  may treat, treats  16%  prevents  disease  treatments  may prevent  49%  contraindicates  disease  treatments  contraindicated drug  97%  diagnoses  disease  tests  may diagnose  63%  causes</ref> disease causes cause of, causative agent of 66% location of disease locations has finding site 41% disease has primary anatomic site symptom of disease symptoms disease has finding 66% disease may have finding has manifestation has definitional manifestation edge base, we associate each super relation with a set of CUI pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Super Relations Argument 1 Argument 2 UMLS Sources Noise% in Annotation Data</head><p>To collect the training data for each super re- lation, we need to collect sentences that express the relation. To achieve this, we parsed all 80M sentences in our medical corpus, looking for the sentences containing the terms that are associated with the CUI pairs in the knowledge base. This (distant supervision) approach resulted in a huge amount of sentences that contain the desired rela- tions, but also brought in a lot of noise in the form of false positives. For example, we know from the knowledge base that "antibiotic drug" may treat "Lyme disease". However the sentence "This paper studies the relationship between antibiotic drug and Lyme disease" contains both terms but does not express the "treats" relation.</p><p>The most reliable way to clean the training data is to ask annotators to go through the sentences and assign the sentences with positive/negative la- bels. However, it will not work well when we have millions of sentences to vet. To minimize the hu- man labeling effort, we ran a K-medoids clustering on the sentences associated with each super rela- tion and kept the cluster centers as the most rep- resentative sentences for annotation. Depending on the number of the sentences we collected for each relation, the #clusters was chosen from 3,000 -6,000. The similarity of two sentences is defined as the bag-of-words similarity of the dependency paths connecting arguments. Part of the resulting data was manually vetted by our annotators, and the remaining was held as unlabeled data for fur- ther experiments.</p><p>Our relation annotation task is quite straightfor- ward, since both arguments are given and the de- cision is a Yes-or-No decision. The noise rate of each relation (#sentences expressing the relation / #sentences) is reported in <ref type="table">Table 1</ref> based on the annotation results. The noise rates differ signifi- cantly from one relation to another. For "treats" relation, only 16% of the sentences are false posi- tives. For "contraindicates" relation, the noise rate is 97%.</p><p>To grow the size of the negative training set for each super relation, we also added a small amount of the most representative examples (also coming from K-medoids clustering) from each unrelated UMLS relation to the training set as negative ex- amples. This resulted in more than 10,000 extra negative examples for each relation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Parsing and Typing</head><p>The most well-known tool to detect medical en- tity mentions is MetaMap <ref type="bibr" target="#b1">(Aronson, 2001)</ref>, which considers all terms as entities and automatically associates each term with a number of concepts from UMLS CUI dictionary ( <ref type="bibr" target="#b13">Lindberg et al., 1993</ref>) with 2.7 million distinct concepts.</p><p>The parser used in our system is Medi- calESG, an adaptation of ESG (English Slot Grammar) <ref type="bibr" target="#b14">(McCord et al., 2012</ref>) to the medical domain with extensions of medical lexicons inte- grated in the UMLS 2012 Release. Compared to MetaMap, MedicalESG is based on the same med- ical lexicons, 10 times faster and produces very similar parsing results.</p><p>We use the semantic types defined in UMLS ( <ref type="bibr" target="#b13">Lindberg et al., 1993</ref>) to categorize argument types. The UMLS consists of a set of 133 subject categories, or semantic types, that provide a consistent categorization of more than 2M concepts represented in the UMLS Metathesaurus. Our system assigns each relation argument with one or more UMLS semantic types through a two step process. Firstly, we use Med- icalESG to process the input sentence, identify segments of text that correspond to concepts in Most relation arguments are associated with multiple semantic types. For example, the term "tetracycline hydrochloride" has two types: "Or- ganic Chemical" and "Antibiotic". Sometimes, the semantic types are noisy due to ambiguity of terms. For example, the term "Hepatitis b" is asso- ciated with both "Pharmacologic Substance" and "Disease or Syndrome" based on UMLS. The rea- son for this is that people use "Hepatitis b" to rep- resent both "the disease of Hepatitis b" and "Hep- atitis b vaccine", so UMLS assigns both types to it. This is a concern for relation extraction, since two types bear opposite meanings. Our current strat- egy is to integrate all associated types, and rely on the relation detector trained with the labeled data to decide how to weight different types based upon the context.</p><p>Here is an illustrative example. Consider the sentence: "Antibiotics are the standard therapy for Lyme disease": MedicalESG first generates a dependency parse tree <ref type="figure" target="#fig_0">(Figure 2</ref>) to represent grammatical relations between the words in the sentence, and then associates the words with CUIs. For example, "Antibiotics" is associated with CUI "C0003232" and "Lyme disease" is associated with two CUIs: "C0024198" and "C0717360". CUI lookup will assign "Antibiotics" with a se- mantic type "Antibiotic", and "Lyme disease" with three semantic types: "Disease or Syndrome", "Pharmacologic Substance" and "Immunologic Factor". This sentence expresses a "treats" rela- tion between "Antibiotics" and "Lyme disease".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Relation Extraction with Manifold Models</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Motivations</head><p>Given a few labeled examples and many unlabeled examples for a relation, we want to build a re- lation detector leveraging both labeled and unla- beled data. Following the manifold regularization idea ( <ref type="bibr" target="#b2">Belkin et al., 2006</ref>), our strategy is to learn a function that assigns a score to each example. Scores are fit so that examples (both labeled and unlabeled) with similar content get similar scores, and scores of labeled examples are close to their labels. Integration of the unlabeled data can help solve overfitting problems when the labeled data is not sufficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Features</head><p>We use 8 groups of features to represent each rela- tion example. These features are commonly used for relation extraction.</p><p>• (1) Semantic types of argument 1, such as "Antibiotic".</p><p>• (2) Semantic types of argument 2.</p><p>• (3) Syntactic features representing the depen- dency path between two arguments, such as "subj", "pred", "mod nprep" and "objprep" (between arguments "antibiotic" and "lyme disease") in <ref type="figure" target="#fig_0">Figure 2</ref>.</p><p>• (4) Features modeling the incoming and out- going links of both arguments. These fea- tures are useful to determine if a relation goes from argument 1 to argument 2 or vice versa.</p><p>• (5) Topic features modeling the words in the dependency path. In the example given in <ref type="figure" target="#fig_0">Figure 2</ref>, the dependency path contains the following words: "be", "standard ther- apy" and "for". These features as well as the features in (6) are achieved by projecting the words onto a 100 dimensional LSI topic space <ref type="bibr" target="#b7">(Deerwester et al., 1990</ref>) constructed from our medical corpus.</p><p>• (6) Topic features modeling the words in the whole sentence.</p><p>• (7) Bag-of-words features modeling the de- pendency path. In <ref type="formula">(7)</ref> and <ref type="formula">(8)</ref>, we only con- sider the words that have occurred in the pos- itive training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Notations:</head><p>The input dataset X = {x 1 , · · · , x m } is repre- sented as a feature-instance matrix. The desired label vector Y = {y 1 , · · · , y l } repre- sents the labels of {x 1 , · · · , x l }, where l ≤ m. W is a weight matrix, where W i,j = e −−x i −x j 2 models the similarity of x i and x j . x i − x j stands for the Euclidean distance be- tween x i and x j in the vector space. D is a diagonal matrix:</p><formula xml:id="formula_0">D i,i = j W i,j . L = D −0.5 (D − W )D −0.5 is called normalized graph Laplacian matrix.</formula><p>∆ is a user defined l × l diagonal matrix, where ∆ i represents the weight of label y i .</p><formula xml:id="formula_1">A = ∆ 0 0 0 is an m × m matrix. V = [y 1 , · · · y l , 0, · · · , 0] is a 1 × m matrix.</formula><p>µ is a weight scalar. () + represents pseudo inverse. Algorithm:</p><p>1. Represent each example using features:  In relation extraction, many recent approaches use non-linear kernels to get the similarity of two relation examples. To classify a relation exam- ple, a lot of dot product computations are required. This is very time consuming and becomes a bottle- neck in using relation extraction to facilitate clin- ical decision making. To speed up the classifier during the apply time, we decided to use a linear classifier instead of non-linear classifiers.</p><formula xml:id="formula_2">X = {x 1 , · · · , x m },</formula><p>We represent all features in a single feature space. For example, we use a vector of 133 en- tries (UMLS contains 133 semantic types) to rep- resent the types of argument 1. If argument 1 is associated with two types: "Organic Chemical" and "Antibiotic", we set the two corresponding en- tries to 1 and all the other entries to 0. Similar ap- proaches are used to represent the other features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">The Main Algorithm</head><p>The problem we want to solve is formalized as fol- lows: given a relation dataset X = {x 1 , · · · , x m }, and the desired label Y = {y 1 , · · · , y l } for {x 1 , · · · , x l }, where l ≤ m, we want to construct a mapping function f to project any example x i to a new space, where f T x i matches x i 's desired la- bel y i . In addition, we also want f to preserve the manifold topology of the dataset, such that similar examples (both labeled and unlabeled) get simi- lar scores. Here, the label is '+1' for positive ex- amples, and '-1' for negative examples. Notations and the main algorithm to construct f for each re- lation are given in <ref type="figure" target="#fig_2">Figure 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Justification</head><p>The solution to the problem defined in Section 4.3 is given by the mapping function f to minimize the following cost function:</p><formula xml:id="formula_3">C(f ) = i≤l αi(f T xi − yi) 2 + µ i,j Wi,j(f T xi − f T xj) 2 .</formula><p>The first term of C(f ) is based on labeled ex- amples, and penalizes the difference between the mapping result of x i and its desired label y i . α i is a user specified parameter, representing the weight of label y i . The second term of C(f ) does not take label information into account. It encourages the neighborhood relationship (geometry of the man- ifold) within X to be preserved in the mapping. When x i and x j are similar, the corresponding W i,j is big. If f maps x i and x j to different posi- tions, f will be penalized. The second term is use- ful to bound the mapping function f and prevents overfitting from happening. Here µ is the weight of the second term. When µ = 0, the model dis- regards the unlabeled data, and the data manifold topology is not respected.</p><p>Compared to manifold regularization ( <ref type="bibr" target="#b2">Belkin et al., 2006</ref>), we do not include the RKHS norm term. Instead, we associate each labeled example with an extra weight for label confidence. This weight is particularly useful when the training data comes from "Crowdsourcing", where we ask multiple workers to complete the same task to correct errors. In that scenario, weights can be as- signed to labels based upon annotator agreement.</p><p>Theorem 1: f = (X(A + µL)X T ) + XAV T minimizes the cost function C(f ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proof:</head><p>Given the input X, we want to find the optimal mapping function f such that C(f ) is minimized:</p><formula xml:id="formula_4">f = arg min f C(f ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>It can be verified that</head><formula xml:id="formula_5">i≤l αi(f T xi − yi) 2 = f T XAX T f − 2f T XAV T + V AV T .</formula><p>We can also verify that</p><formula xml:id="formula_6">µ i,j (f T x i − f T x j ) 2 W i,j = µf T XLX T f.</formula><p>So C(f ) can be written as</p><formula xml:id="formula_7">f T XAX T f − 2f T XAV T + V AV T + µf T XLX T f.</formula><p>Using the Lagrange multiplier trick to differentiate C(f ) with respect to f , we have</p><formula xml:id="formula_8">2XAX T f + 2µXLX T f = 2XAV T .</formula><p>This implies that</p><formula xml:id="formula_9">X(A + µL)X T f = XAV T . So f = (X(A + µL)X T ) + XAV T ,</formula><p>where "+" represents pseudo inverse.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Advantages</head><p>Our algorithm offers the following advantages:</p><p>• The algorithm exploits unlabeled data, which helps prevent "overfitting" from happening.</p><p>• The algorithm provides users with the flex- ibility to assign different labels with differ- ent weights. This feature is useful when the training data comes from "crowdsourcing" or "distant supervision".</p><p>• Different from many approaches in this area, our algorithm provides a closed-form solu- tion of the result. The solution is global opti- mal regarding the cost function C(f ).</p><p>• The algorithm is computationally efficient at the apply time (as fast as linear regressions).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Cross-Validation Test</head><p>We use a cross-validation test <ref type="bibr">3</ref> with the relation data generated in Section 3.2 to compare our ap- proaches against the state-of-the-art approaches.</p><p>The task is to classify the examples into positive or negative for each relation. We applied a 5-fold cross-validation. In each round of validation, we used 20% of the data for training and 80% for test- ing. The F 1 scores reported here are the average of all 5 rounds. We used MedicalESG to process the input text for all approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Data and Parameters</head><p>This dataset includes 7 relations. We do not con- sider the relation of "contraindicates" in this test, since it has too few positive examples. On average, each relation contains about 800 positive examples and more than 13,000 negative examples. To elim- inate the examples that are trivial to classify, we removed the negative examples that do not bear the valid argument types. This removed the exam- ples that can be easily classified by a type filter, resulting in 3,000 negatives on average per rela- tion. For each relation, we also collected 5,000 unlabeled examples and put them into two sets: unlabeled set 1 and 2 (2,500 examples in each set).</p><p>No parameter tuning was taken and no relation specific heuristic rules were applied in all tests. In all manifold models, µ = 1. In SVM implemen- tations, the trade-off parameter between training error and margin was set to 1 for all experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Baseline Approaches</head><p>We compare our approaches to three state-of-the- art approaches including SVM with convolution tree kernels <ref type="bibr" target="#b5">(Collins and Duffy, 2001</ref>), linear re- gression and SVM with linear kernels <ref type="bibr">(SchölkopfSch¨Schölkopf and Smola, 2002</ref>). To adapt the tree kernel to med- ical domain, we followed the approach in <ref type="bibr" target="#b18">(Nguyen et al., 2009</ref>) to take the syntactic structures into consideration. We also added the argument types as features to the tree kernel. In the tree kernel im- plementation, we assigned the tree structure and the vector corresponding to the argument types </p><note type="other">location of 0.6113 0.6009 0.4968 0.7275 0.7363 0.6964 0.7454 diagnoses 0.5520 0.4934 0.3202 0.6468 0.6485 0.5720 0.6954 symptom of 0.4398 0.5611 0.5984 0.6347 0.5314 0.4515 0.5968 average 0.5071 0.5553 0.5094 0.6566 0.6331 0.5902 0.6646</note><p>with equal weights. The SVM with linear kernels and the linear regression model used the same fea- tures as the manifold models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3">Settings for the Manifold Models</head><p>We tested our manifold model for each relation un- der three different settings:</p><p>(1) Manifold Unlabeled: We combined the la- beled data and unlabeled set 1 in training. We set α i = 1 for i ∈ <ref type="bibr">[1, l]</ref>.</p><p>(2) Manifold Predicted Labels: We combined labeled data and unlabeled set 2 in training. α i = 1 for i ∈ <ref type="bibr">[1, l]</ref>. Different from the previous set- ting, we gave a label estimation to all the exam- ples in the unlabeled set 2 based on the noise rate (Noise%) from <ref type="table">Table 1</ref>. The label of all unla- beled examples was set to "+1" when 100% − 2 · N oise% &gt; 0, or "-1" otherwise. Two weighting strategies were applied:</p><p>• With Weights: We let label weight α i = |100% − 2 · N oise%| for all x i coming from the unlabeled set 2. This setting represents an empirical rule to estimate the label and con- fidence of each unlabeled example based on the sampling result.</p><p>• Without Weights: α i is always set to 1.</p><p>(3) Manifold UnLabeled+Predicted Labels: a combination of setting <ref type="formula">(1)</ref> and <ref type="bibr">(2)</ref>. In this setting, the data from unlabeled set 1 was used as unla- beled data and the data from unlabeled set 2 was used as labeled data (With Weights).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.4">Results</head><p>The results are summarized in <ref type="table" target="#tab_0">Table 2</ref>.</p><p>The tree kernel-based approach and linear re- gression achieved similar F 1 scores, while linear SVM made a 5% improvement over them. One thing to note is that the results from these ap- proaches vary significantly. The reason for this is that the labeled training data is not sufficient. So the approaches that completely depend on the la- beled data are likely to run into overfitting. Linear SVM performed better than the other two, since the large-margin constraint together with the lin- ear model constraint can alleviate overfitting.</p><p>By integrating unlabeled data, the manifold model under setting (1) made a 15% improvement over linear regression model on F 1 score, where the improvement was significant across all rela- tions.</p><p>Under setting <ref type="formula">(2)</ref>, the With Weights strategy achieved a slightly worse F 1 score than the previ- ous setting but much better result than the baseline approaches. This tells us that estimating the label of unlabeled examples based upon the sampling result is one way to utilize unlabeled data and may help improve the relation extraction results. The results also show that the label weight is important for this setting, since the Without Weights strategy did not perform very well.</p><p>Compared to setting (1) and (2), setting (3) made use of 2,500 more unlabeled examples, and achieved the best performance among all ap- proaches. On one hand, this result shows that using more unlabeled data can further improve the result. On the other hand, the insignificant improvement over (1) and (2) strongly indicates that how to utilize more unlabeled data to achieve a significant improvement is non-trivial and de- serves more attention. To what extensions the un- labeled data can help the learning process is an open problem. Generally speaking, when the ex- isting data is sufficient to characterize the dataset geometry, adding more unlabeled data will not help ( <ref type="bibr" target="#b22">Singh et al., 2008)</ref>.</p><p>We tested the tree kernel-based approach with- out integrating the medical types as well. That re- sulted in very poor performance: the average F 1 score was below 30%. We also applied the rules used in SEMREP ( <ref type="bibr" target="#b20">Rindflesch and Fiszman, 2003)</ref> to this dataset. Since the relations detected by SEMREP rules cannot be perfectly aligned with super relations, we cannot directly compare the re- sults. Overall speaking, SEMREP rules are very conservative and detect very few relations from the same text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Knowledge Base (KB) Construction</head><p>The UMLS Metathesaurus ( <ref type="bibr" target="#b13">Lindberg et al., 1993)</ref> contains a large amount of manually extracted re- lation knowledge. Such knowledge is invaluable for people to collect training data to build new relation detectors. One downside of using this KB is its incompleteness. For example, it only contains the treatments for about 8,000 diseases, which are far from sufficient. Further, the medical knowledge is changing extremely quickly, making people hard to understand it, and update it in the knowledge base in a timely manner.</p><p>To address these challenges, we constructed our own relation KB as a complement to the UMLS relation KB. We directly ran our relation detec- tors (trained with all labeled and unlabeled exam- ples) on our medical corpus to extract relations. Then we combined the results and put them in a new KB. The new KB covers all super relations and stores the knowledge in the format of (rela- tion name, argument 1, argument 2, confidence), where the confidence is computed based on the re- lation detector confidence score and relation pop- ularity in the corpus. The most recent version of our relation KB contains 3.4 million such entries.</p><p>We compared this new KB against UMLS KB using an answer generation task on a set of 742 Doctor Dilemma questions. We first ran our rela- tion detectors to detect the relation(s) in the ques- tion clue involving question focus (what the ques- tion asks for). Then we searched against both KBs using the relation name and the non-focus argu- ment for the missing argument. The search re- sults were then generated as potential answers. We used the same relations to do KB lookup, so the results are directly comparable. Since most ques- tions only have one correct answer, the precision number is not very important in this experiment.</p><p>If we detect multiple relations in the question, and the same answer is generated from more than one relations, we sum up all those confidence scores to make such answers more preferable. Sometimes, we may generate too many answers from KBs. For example, if the detected relation is "location of" and the non-focus argument is "skin", then thousands of answers can be gener- ated. In this scenario, we sort the answers based upon the confidence scores and only consider up to p answers for each question. In our test, we considered three numbers for p: 20, 50 and 3,000.</p><p>From <ref type="table" target="#tab_1">Table 3</ref>, we can see that the new KB out- performs the most popularly-used UMLS KB at all recall levels by a large margin. This result in- dicates that the new KB has a much better knowl- edge coverage. The UMLS KB is manually cre- ated and thus more precise. In our experiment, the UMLS KB generated fewer answers than the new KB. For example, when up to 20 answers were generated for each question, the UMLS KB gen- erated around 4,700 answers for the whole ques- tion set, while the new KB generated about 7,600 answers.</p><p>Construction of the new KB cost 16 machines (using 4×2.8G cores per machine) 8 hours. The reported computation time is for the whole corpus with 11G pure text. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>In this paper, we identify a list of key relations that can facilitate clinical decision making. We also present a new manifold model to efficiently extract these relations from text. Our model is developed to utilize both labeled and unlabeled examples. It further provides users with the flexibility to take label weight into consideration. Effectiveness of the new model is demonstrated both theoretically and experimentally. We apply the new model to construct a relation knowledge base (KB), and use it as a complement to the existing manually cre- ated KBs. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: A Parse Tree Example</figDesc><graphic url="image-7.png" coords="5,79.99,63.77,203.35,132.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>where x i is the ith ex- ample. 2 . Construct graph Laplacian matrix L modeling the data manifold. 3 .</head><label>23</label><figDesc>Construct vector V = [y 1 , · · · y l , 0, · · · , 0]. 4. Compute projection function f for each relation: f = (X(A + µL)X T ) + XAV T .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Notations and the Algorithm to Train a Manifold Model for Relation Extraction</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 2 : F 1 Scores from a Five-Fold Cross Validation Experiment</head><label>2</label><figDesc></figDesc><table>SVM 
SVM 
Linear 
Manifold 
Manifold 
Manifold 
Manifold 
Tree 
Linear Regression Unlabeled Predicted Labels Predicted Labels Unlabeled+Predicted 
Kernel Kernel 
with Weights 
without Weights 
Labels with Weights 
treats 
0.7648 0.7850 
0.7267 
0.8025 
0.8041 
0.7884 
0.8085 
prevents 
0.2859 0.3887 
0.3922 
0.5502 
0.5696 
0.6349 
0.6332 
causes 
0.3885 0.5024 
0.5219 
0.5779 
0.5088 
0.3978 
0.5081 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 3 : Knowledge Base Comparison</head><label>3</label><figDesc></figDesc><table>Recall@20 Recall@50 Recall@3000 
Our KB 
135/742 
182/742 
301/742 
UMLS KB 
42/742 
52/742 
73/742 

</table></figure>

			<note place="foot" n="2"> This is a full list of the books and journals used in our corpus: ACP-Medical Knowledge Self-Assessment Program, EBSCO-Dynamed, EBSCO-Quick Lessons, EBSCOEBCS, EBSCO-Clinical Review, Wiley-Essential Evidence Plus: EBMG Guidelines, Wiley-Essential Evidence Topics, Wiley-Essential Evidence Plus: EBMG Summaries, WileyPOEMs, Wiley-The Breast Journal, New England Journal of Medicine, Journal Watch, NCCN-CME, NCCN-GUS, NCCN-Compendium, NCCN-Templates, NCCN-Guidelines for Patients, NCCN-Physician Guidelines, Merck Manual of Diagnosis and Therapy, and UpToDate.</note>

			<note place="foot" n="3"> If we take the perfect entity mentions and the associated concepts provided by i2b2 (Uzuner et al., 2011) as the input, our system can directly apply to i2b2 relation extraction data. However, the i2b2 data has a tough data use agreement. Our legal team held several rounds of negotiations with the i2b2 data owner and then decided we should not use it due to the high legal risks. We are not aware of other available medical relation extraction datasets that fit for our evaluations.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Siddharth Patwardhan for help on tree kernels, Sugato Bagchi and Dr. Herbert Chase's team for categorizing the Doctor Dilemma ques-tions. We also thank Anthony Levas, Karen In-graffea, Mark Mergen, Katherine Modzelewski, Jonathan Hodax, Matthew Schoenfeld and Adarsh Thaker for vetting the training data.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">The automatic content extraction projects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ace</forename></persName>
		</author>
		<ptr target="http://projects.ldc.upenn.edu/ace/" />
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Effective mapping of biomedical text to the UMLS metathesaurus: the MetaMap program</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Aronson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2001 Annual Symposium of the American Medical Informatics Association</title>
		<meeting>the 2001 Annual Symposium of the American Medical Informatics Association</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Manifold regularization: a geometric framework for learning from labeled and unlabeled examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Niyogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sindhwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="page" from="2399" to="2434" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A shortest path dependency kernel for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bunescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Human Language Technology and Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Exploiting background knowledge for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics</title>
		<meeting>the 23rd International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="152" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Convolution kernels for natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Duffy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Advances in Neural Information Processing Systems (NIPS)</title>
		<meeting>the Advances in Neural Information Processing Systems (NIPS)</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="625" to="632" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Dependency tree kernels for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Culotta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sorensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 42nd Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="423" to="429" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Indexing by latent semantic analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Deerwester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Furnas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">K</forename><surname>Landauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Harshman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="391" to="407" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Answering clinical questions with knowledge-based and statistical techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="63" to="103" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Knowledge-based weak supervision for information extraction of overlapping relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Overview of the TAC 2011 knowledge base population track</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">T</forename><surname>Dang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Text Analytics Conference</title>
		<meeting>the Text Analytics Conference</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Multi-task transfer learning for weaklysupervised relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the Association for Computational Linguistics (ACL) and the 4th International Joint Conference on Natural Language Processing (IJCNLP)</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the Association for Computational Linguistics (ACL) and the 4th International Joint Conference on Natural Language Processing (IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1012" to="1020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Combining lexical, syntactic, and semantic features with maximum entropy models for extracting relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kambhatla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2004 on Interactive poster and demonstration sessions</title>
		<meeting>the ACL 2004 on Interactive poster and demonstration sessions</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The Unified Medical Language System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lindberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Humphreys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Methods of Information in Medicine</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="281" to="291" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep parsing in Watson</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mccord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Murdock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">K</forename><surname>Boguraev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Journal of Research and Development</title>
		<imprint>
			<biblScope unit="page">56</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A novel use of statistical parsing to extract information from text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ramshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Weischedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st North American Chapter of the Association for Computational Linguistics Conference</title>
		<meeting>the 1st North American Chapter of the Association for Computational Linguistics Conference</meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction with an incomplete knowledge base</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gondek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction without labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mintz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bills</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Snow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the Association for Computational Linguistics (ACL) and the 4th International Joint Conference on Natural Language Processing (IJCNLP)</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the Association for Computational Linguistics (ACL) and the 4th International Joint Conference on Natural Language Processing (IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1003" to="1011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Convolution kernels on constituent, dependency and sequential structures for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Riccardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2009 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Modeling relations and their mentions without labeled text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Machine Learning and Knowledge Discovery in Databases (ECML PKDD)</title>
		<meeting>the European Conference on Machine Learning and Knowledge Discovery in Databases (ECML PKDD)</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The interaction of domain knowledge and linguistic structure in natural language processing: interpreting hypernymic propositions in biomedical text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">C</forename><surname>Rindflesch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fiszman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Biomedical Informatics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="462" to="477" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Unlabeled data: now it helps, now it doesnot</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Nowak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Advances in Neural Information Processing Systems (NIPS)</title>
		<meeting>the Advances in Neural Information Processing Systems (NIPS)</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Multi-instance multilabel learning for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012</title>
		<meeting>the 2012</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
