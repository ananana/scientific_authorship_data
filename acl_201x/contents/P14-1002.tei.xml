<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:56+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Representation Learning for Text-level Discourse Parsing</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>June 23-25 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Interactive Computing</orgName>
								<orgName type="department" key="dep2">School of Interactive Computing Georgia Institute of Technology</orgName>
								<orgName type="institution">Georgia Institute of Technology</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
							<email>jacobe@gatech.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Interactive Computing</orgName>
								<orgName type="department" key="dep2">School of Interactive Computing Georgia Institute of Technology</orgName>
								<orgName type="institution">Georgia Institute of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Representation Learning for Text-level Discourse Parsing</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="13" to="24"/>
							<date type="published">June 23-25 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Text-level discourse parsing is notoriously difficult, as distinctions between discourse relations require subtle semantic judgments that are not easily captured using standard features. In this paper, we present a representation learning approach, in which we transform surface features into a latent space that facilitates RST discourse parsing. By combining the machinery of large-margin transition-based struc-tured prediction with representation learning , our method jointly learns to parse discourse while at the same time learning a discourse-driven projection of surface features. The resulting shift-reduce discourse parser obtains substantial improvements over the previous state-of-the-art in predicting relations and nuclearity on the RST Treebank.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Discourse structure describes the high-level or- ganization of text or speech. It is central to a number of high-impact applications, such as text summarization <ref type="bibr" target="#b23">(Louis et al., 2010)</ref>, senti- ment analysis <ref type="bibr" target="#b51">(Voll and Taboada, 2007;</ref><ref type="bibr" target="#b42">Somasundaran et al., 2009</ref>), question answering <ref type="bibr" target="#b12">(Ferrucci et al., 2010)</ref>, and automatic evaluation of student writing ( <ref type="bibr" target="#b30">Miltsakaki and Kukich, 2004;</ref><ref type="bibr" target="#b3">Burstein et al., 2013)</ref>. Hierarchical discourse representa- tions such as Rhetorical Structure Theory (RST) are particularly useful because of the computa- tional applicability of tree-shaped discourse struc- tures ( <ref type="bibr" target="#b46">Taboada and Mann, 2006</ref>), as shown in <ref type="figure" target="#fig_0">Fig- ure 1</ref>.</p><p>Unfortunately, the performance of discourse parsing is still relatively weak: the state-of-the-art F-measure for text-level relation detection in the RST Treebank is only slightly above 55% (Joty when profit was $107.8 million on sales of $435.5 million.</p><p>The projections are in the neighborhood of 50 cents a share to 75 cents, et al., 2013). While recent work has introduced increasingly powerful features <ref type="bibr" target="#b11">(Feng and Hirst, 2012</ref>) and inference techniques ( <ref type="bibr" target="#b17">Joty et al., 2013)</ref>, discourse relations remain hard to detect, due in part to a long tail of "alternative lexicalizations" that can be used to realize each relation ( <ref type="bibr" target="#b36">Prasad et al., 2010</ref>). Surface and syntactic features are not capable of capturing what are fundamentally se- mantic distinctions, particularly in the face of rel- atively small annotated training sets.</p><p>In this paper, we present a representation learn- ing approach to discourse parsing. The core idea of our work is to learn a transformation from a bag-of-words surface representation into a latent space in which discourse relations are easily iden- tifiable. The latent representation for each dis- course unit can be viewed as a discriminatively- trained vector-space representation of its meaning. Alternatively, our approach can be seen as a non- linear learning algorithm for incremental struc- ture prediction, which overcomes feature sparsity through effective parameter tying. We consider several alternative methods for transforming the original features, corresponding to different ideas of the meaning and role of the latent representa- tion.</p><p>Our method is implemented as a shift-reduce discourse parser <ref type="bibr" target="#b26">(Marcu, 1999;</ref><ref type="bibr" target="#b37">Sagae, 2009)</ref>. Learning is performed as large-margin transition- based structure prediction ( <ref type="bibr" target="#b47">Taskar et al., 2003</ref>), while at the same time jointly learning to project the surface representation into latent space. The resulting system strongly outperforms the prior state-of-the-art at labeled F-measure, obtaining raw improvements of roughly 6% on relation la- bels and 2.5% on nuclearity. In addition, we show that the latent representation coheres well with the characterization of discourse connectives in the Penn Discourse Treebank ( <ref type="bibr" target="#b35">Prasad et al., 2008</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Model</head><p>The core idea of this paper is to project lexical fea- tures into a latent space that facilitates discourse parsing. In this way, we can capture the meaning of each discourse unit, without suffering from the very high dimensionality of a lexical representa- tion. While such feature learning approaches have proven to increase robustness for parsing, POS tagging, and NER ( <ref type="bibr" target="#b29">Miller et al., 2004;</ref><ref type="bibr" target="#b19">Koo et al., 2008;</ref><ref type="bibr" target="#b48">Turian et al., 2010)</ref>, they would seem to have an especially promising role for discourse, where training data is relatively sparse and ambi- guity is considerable. <ref type="bibr" target="#b36">Prasad et al. (2010)</ref> show that there is a long tail of alternative lexicalizations for discourse relations in the Penn Discourse Tree- bank, posing obvious challenges for approaches based on directly matching lexical features ob- served in the training data.</p><p>Based on this observation, our goal is to learn a function that transforms lexical features into a much lower-dimensional latent representation, while simultaneously learning to predict discourse structure based on this latent representation. In this paper, we consider a simple transformation function, linear projection. Thus, we name the ap- proach DPLP: Discourse Parsing from Linear Pro- jection. We apply transition-based (incremental) structured prediction to obtain a discourse parse, training a predictor to make the correct incremen- tal moves to match the annotations of training data in the RST Treebank. This supervision signal is then used to learn both the weights and the projec- tion matrix in a large-margin framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Shift-reduce discourse parsing</head><p>We construct RST Trees using shift-reduce pars- ing, as first proposed by <ref type="bibr" target="#b26">Marcu (1999)</ref>. At each point in the parsing process, we maintain a stack and a queue; initially the stack is empty and the first elementary discourse unit (EDU) in the docu- ment is at the front of the queue. <ref type="bibr">1</ref> The parser can <ref type="bibr">1</ref> We do not address segmentation of text into elemen- tary discourse units in this paper. Standard classification- Notation Explanation V Vocabulary for surface features V Size of V K Dimension of latent space wm</p><p>Classification weights for class m C Total number of classes, which correspond to possible shift-reduce operations A Parameter of the representation function (also the projection matrix in the linear representa- tion function) v i</p><p>Word count vector of discourse unit i v Vertical concatenation of word count vectors for the three discourse units currently being considered by the parser λ Regularization for classification weights τ</p><p>Regularization for projection matrix ξi Slack variable for sample i ηi,m</p><p>Dual variable for sample i and class m αt Learning rate at iteration t <ref type="table">Table 1</ref>: Summary of mathematical notation then choose either to shift the front of the queue onto the top of the stack, or to reduce the top two elements on the stack in a discourse relation. The reduction operation must choose both the type of relation and which element will be the nucleus. So, overall there are multiple reduce operations with specific relation types and nucleus positions. Shift-reduce parsing can be learned as a classifi- cation task, where the classifier uses features of the elements in the stack and queue to decide what move to take. Previous work has employed deci- sion trees <ref type="bibr" target="#b26">(Marcu, 1999</ref>) and the averaged percep- tron ( <ref type="bibr" target="#b5">Collins and Roark, 2004;</ref><ref type="bibr" target="#b37">Sagae, 2009)</ref> for this purpose. Instead, we employ a large-margin classifier, because we can compute derivatives of the margin-based objective function with respect to both the classifier weights as well as the projec- tion matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Discourse parsing with projected features</head><p>More formally, we denote the surface feature vo- cabulary V, and represent each EDU as the nu- meric vector v ∈ N V , where V = #|V| and the n- th element of v is the count of the n-th surface fea- ture in this EDU (see <ref type="table">Table 1</ref> for a summary of no- tation). During shift-reduce parsing, we consider features of three EDUs: 2 the top two elements on based approaches can achieve a segmentation F-measure of 94% ( <ref type="bibr" target="#b15">Hernault et al., 2010)</ref>; a more complex rerank- ing model does slightly better, at 95% F-Measure with automatically-generated parse trees, and 96.6% with gold an- notated trees <ref type="bibr" target="#b52">(Xuan Bach et al., 2012)</ref>. Human agreement reaches 98% F-Measure. <ref type="bibr">2</ref> After applying a reduce operation, the stack will include a span that contains multiple EDUs. We follow the strong the stack (v 1 and v 2 ), and the front of the queue (v 3 ). The vertical concatenation of these vectors is denoted v = [v 1 ; v 2 ; v 3 ]. In general, we can formulate the decision function for the multi-class shift-reduce classifier asˆm</p><formula xml:id="formula_0">asˆ asˆm = arg max m∈{1,...,C} w m f (v; A)<label>(1)</label></formula><p>where w m is the weight for the m-th class and f (v; A) is the representation function parametrized by A. The score for class m (in our case, the value of taking the m-th shift- reduce operation) is computed by the inner prod- uct w m f (v; A). The specific shift-reduce opera- tion is chosen by maximizing the decision value in Equation 1.</p><p>The representation function f (v; A) can be de- fined in any form; for example, it could be a non- linear function defined by a neural network model parametrized by A. We focus on the linear projec- tion,</p><formula xml:id="formula_1">f (v; A) = Av,<label>(2)</label></formula><p>where A ∈ R K×3V is projects the surface repre- sentation v of three EDUs into a latent space of size K V . Note that by setting˜wsetting˜ setting˜w m = w m A, the decision scoring function can be rewritten as˜was˜ as˜w m v, which is linear in the original surface features. Therefore, the expressiveness of DPLP is identical to a linear separator in the original feature space. However, the learning problem is considerably different. If there are C total classes (possible shift-reduce op- erations), then a linear classifier must learn 3V C parameters, while DPLP must learn (3V + C)K parameters, which will be smaller under the as- sumption that K &lt; C V . This can be seen as a form of parameter tying on the linear weights˜w weights˜ weights˜w m , which allows statistical strength to be shared across training instances. We will consider special cases of A that reduce the parameter space still further.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Special forms of the projection matrix</head><p>We consider three different constructions for the projection matrix A.</p><p>• General form: In the general case, we place compositionality criterion of Marcu (1996) and consider only the nuclear EDU of the span. Later work may explore the composition of features between the nucleus and satellite. no special constraint on the form of A.</p><formula xml:id="formula_2">f (v; A) = A   v 1 v 2 v 3   (3)</formula><p>This form is shown in <ref type="figure">Figure 2</ref>(a).</p><p>• Concatenation form: In the concatenation form, we choose a block structure for A, in which a single projection matrix B is applied to each EDU:</p><formula xml:id="formula_3">f (v; A) = B 0 0 0 B 0 0 0 B v 1 v 2 v 3 (4)</formula><p>In this form, we transform the representa- tion of each EDU separately, but do not at- tempt to represent interrelationships between the EDUs in the latent space. The number of parameters in A is 1 3 KV . Then, the total number of parameters, including the decision weights {w m }, in this form is</p><formula xml:id="formula_4">( V 3 + C)K.</formula><p>• Difference form. In the difference form, we explicitly represent the differences between adjacent EDUs, by constructing A as a block difference matrix,</p><formula xml:id="formula_5">f (v; A) = C −C 0 C 0 −C 0 0 0 v 1 v 2 v 3 ,<label>(5)</label></formula><p>The result of this projection is that the la- tent representation has the form</p><formula xml:id="formula_6">[C(v 1 − v 2 ); C(v 1 − v 3 )],</formula><p>representing the difference between the top two EDUs on the stack, and between the top EDU on the stack and the first EDU in the queue. This is intended to capture semantic similarity, so that reduc- tions between related EDUs will be preferred. Similarly, the total number of parameters to estimate in this form is (V + 2C) K 3 . Specifically, we formulate the following con- strained optimization problem,</p><formula xml:id="formula_7">min {w 1:C ,ξ 1:l ,A} λ 2 C m=1 wm 2 2 + l i=1 ξi + τ 2 A 2 F s.t. (wy i −wm) f (vi; A) ≥ 1 − δy i =m − ξi, ∀ i, m<label>(6)</label></formula><p>where m ∈ {1, . . . , C} is the index of the shift-reduce decision taken by the classifier (e.g., SHIFT, REDUCE-CONTRAST-RIGHT, etc), i ∈ {1, · · · , l} is the index of the training sample, and w m is the vector of classification weights for class m. The slack variables ξ i permit the margin con- straint to be violated in exchange for a penalty, and the delta function δ y i =m is unity if y i = m, and zero otherwise. As is standard in the multi-class linear SVM <ref type="bibr" target="#b9">(Crammer and Singer, 2001</ref>), we can solve the problem defined in Equation 6 via Lagrangian optimization:</p><formula xml:id="formula_8">L({w1:C , ξ 1:l , A, η 1:l,1:C }) = λ 2 C m=1 wm 2 2 + l i=1 ξi + τ 2 A 2 F + i,m ηi,m (w m − w y i )f (vi; A) + 1 − δy i =m − ξi s.t. ηi,m ≥ 0 ∀i, m<label>(7)</label></formula><p>Then, to optimize L, we need to find a saddle point, which would be the minimum for the vari- ables {w 1:C , ξ 1:l } and the projection matrix A, and the maximum for the dual variables {η 1:l,1:C }.</p><p>If A is fixed, then the optimization problem is equivalent to a standard multi-class SVM, in the transformed feature space f (v i ; A). We can obtain the weights {w 1:C } and dual variables {η 1:l,1:C } from a standard dual-form SVM solver. We then update A, recompute {w 1:C } and {η 1:l,1:C }, and iterate until convergence. This iterative procedure is similar to the latent variable structural SVM ( <ref type="bibr" target="#b53">Yu and Joachims, 2009)</ref>, although the specific details of our learning algorithm are different.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Learning Projection Matrix A</head><p>We update A while holding fixed the weights and dual variables. The derivative of L with respect to A is</p><formula xml:id="formula_9">∂L ∂A = τ A + i,m ηi,m(w m − w y i ) ∂f (vi; A) ∂A = τ A + i,m ηi,m(wm − wy i )vi<label>(8)</label></formula><p>Setting ∂L ∂A = 0, we have the closed-form solution,</p><formula xml:id="formula_10">A = 1 τ i,m ηi,m(wm − wy i )vi = 1 τ i,j (wy i − m ηi,mwm)vi ,<label>(9)</label></formula><p>because the dual variables for each instance must sum to one, m η i,m = 1. Note that for a given i, the matrix (</p><formula xml:id="formula_11">w y i − m η i,m w m )v i</formula><p>is of (at most) rank-1. There- fore, the solution of A can be viewed as the lin- ear combination of a sequence of rank-1 matrices, where each rank-1 matrix is defined by distribu- tional representation v i and the weight difference between the weight of true label w y i and the "ex- pected" weight m η i,m w m . One property of the dual variables is that f (v i ; A) is a support vector only if the dual vari- able η i,y i &lt; 1. Since the dual variables for each instance are guaranteed to sum to one, we have</p><formula xml:id="formula_12">w y i − m η i,m w m = 0 if η i,y i = 1.</formula><p>In other words, the contribution from non support vectors to the projection matrix A is 0. Then, we can fur- ther simplify the updating equation as</p><formula xml:id="formula_13">A = 1 τ v i ∈SV (w y i − m η i,m w m )v i<label>(10)</label></formula><p>This is computationally advantageous since many instances are not support vectors, and it shows that the discriminatively-trained projection matrix only incorporates information from each instance to the extent that the correct classification receives low confidence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Mini-batch learning algorithm</head><p>Input: Training set D, Regularization parame- ters λ and τ , Number of iteration T , Initializa- tion matrix A 0 , and Threshold ε while t = 1, . . . , T do Randomly choose a subset of training sam-</p><note type="other">ples D t from D Train SVM with A t−1 to obtain {w (t) m } and {η (t) i,m } Update A t using Equation 11 with α t = 1 t if At−A t−1 F A 2 −A 1 F &lt; ε then Return end if end while Re-train SVM with D and the final A Output: Projection matrix A, SVM classifier with weights w 3.2 Gradient-based Learning for A</note><p>Solving the quadratic programming defined by the dual form of the SVM is time-consuming, espe- cially on a large-scale dataset. But if we focus on learning the projection matrix A, we can speed up learning by sampling only a small proportion of the training data to compute an approximate op- timum for {w 1:C , η 1:l,1:C }, before each update of A. This idea is similar to the mini-batch learning, which has been used in large-scale SVM problem ( <ref type="bibr" target="#b33">Nelakanti et al., 2013)</ref> and deep learning models ( <ref type="bibr" target="#b21">Le et al., 2011</ref>).</p><p>Specifically, in iteration t, the algorithm ran- domly chooses a subset of training samples D t to train the model. We cannot make a closed-form update to A based on this small sample, but we can take an approximate gradient step,</p><formula xml:id="formula_14">At = (1 − αtτ )At−1+ αt v i ∈SV(D t ) w (t) y i − m η (t) i,m w (t) m vi ,<label>(11)</label></formula><p>where α t is a learning rate. In iteration t, we choose α t = 1 t . After convergence, we obtain the weights w by applying the SVM over the entire dataset, using the final A. The algorithm is sum- marized in Algorithm 1 and more details about im- plementation will be clarified in Section 4. While minibatch learning requires more iterations, the SVM training is much faster in each batch, and the overall algorithm is several times faster than using the entire training set for each update.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Implementation</head><p>The learning algorithm is applied in a shift-reduce parser, where the training data consists of the (unique) list of shift and reduce operations re- quired to produce the gold RST parses. On test data, we choose parsing operations in an online fashion -at each step, the parsing algorithm changes the status of the stack and the queue ac- cording the selected transition, then creates the next sample with the updated status.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Parameters and Initialization</head><p>There are three free parameters in our approach: the latent dimension K, and regularization pa- rameters λ and τ . We consider the values K ∈ {30, 60, 90, 150}, λ ∈ {1, 10, 50, 100} and τ ∈ {1.0, 0.1, 0.01, 0.001}, and search over this space using a development set of thirty document ran- domly selected from within the RST Treebank training data. We initialize each element of A 0 to a uniform random value in the range <ref type="bibr">[0,</ref><ref type="bibr">1]</ref>. For mini-batch learning, we fixed the batch size to be 500 training samples (shift-reduce operations) in each iteration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Additional features</head><p>As described thus far, our model considers only the projected representation of each EDU in its parsing decisions. But prior work has shown that other, structural features can provide useful in- formation ( <ref type="bibr" target="#b17">Joty et al., 2013)</ref>. We therefore aug- ment our classifier with a set of simple feature templates. These templates are applied to individ- ual EDUs, as well as pairs of EDUs: (1) the two EDUs on top of the stack, and (2) the EDU on top of the stack and the EDU in front of the queue. The features are shown in <ref type="table" target="#tab_0">Table 2</ref>. In computing these features, all tokens are downcased, and nu- merical features are not binned. The dependency structure and POS tags are obtained from MALT- Parser ( <ref type="bibr" target="#b34">Nivre et al., 2007</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>We evaluate DPLP on the RST Discourse Tree- bank ( <ref type="bibr" target="#b4">Carlson et al., 2001</ref>), comparing against state-of-the-art results. We also investigate the in- formation encoded by the projection matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Setup</head><p>Dataset The RST Discourse Treebank (RST- DT) consists of 385 documents, with 347 for train- Words at beginning and end of the EDU BEGIN-WORD-STACK1 = but BEGIN-WORD-STACK1-QUEUE1 = but, the POS tag at beginning and end of the EDU BEGIN-TAG-STACK1 = CC BEGIN-TAG-STACK1-QUEUE1 = CC, DT Head word set from each EDU. The set includes words whose parent in the depenency graph is ROOT or is not within the EDU <ref type="bibr" target="#b37">(Sagae, 2009)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>HEAD-WORDS-STACK2 = working</head><p>Length of EDU in tokens LEN-STACK1-STACK2 = 7, 8 Distance between EDUs DIST-STACK1-QUEUE1 = 2 Distance from the EDU to the beginning of the document DIST-FROM-START-QUEUE1 = 3 Distance from the EDU to the end of the document DIST-FROM-END-STACK1 = 1 Whether two EDUs are in the same sentence SAME-SENT-STACK1-QUEUE1 = True  <ref type="bibr" target="#b6">(Collobert and Weston, 2008)</ref>. In this case, we can view the product Bv as a com- position of the word embeddings, using the simple additive composition model proposed by <ref type="bibr" target="#b31">Mitchell and Lapata (2010)</ref>. We used the word embeddings from <ref type="bibr" target="#b6">Collobert and Weston (2008)</ref> with dimension {25, 50, 100}. Grid search over heldout training data was used to select the optimum latent dimen- sion for both the NMF and word embedding base- lines. Note that the size K of the resulting projec- tion matrix is three times the size of the embed- ding (or NMF representation) due to the concate- nate construction.</p><p>We also consider the special case where A = I.  <ref type="formula" target="#formula_0">(2013)</ref> proposed two dif- ferent approaches to combine sentence-level pars- ing models: sliding windows (TSP SW) and 1 sentence-1 subtree (TSP 1-1). In the comparison, we report the results of both approaches. All re- sults are based on the same gold standard EDU segmentation. We cannot compare with the re- sults of <ref type="bibr" target="#b11">Feng and Hirst (2012)</ref>, because they do not evaluate on the overall discourse structure, but rather treat each relation as an individual classifi- cation problem.</p><p>Metrics To evaluate the parsing performance, we use the three standard ways to measure the per- formance: unlabeled (i.e., hierarchical spans) and labeled (i.e., nuclearity and relation) F-score, as defined by <ref type="bibr" target="#b2">Black et al. (1991)</ref>. The application of this approach to RST parsing is described by <ref type="bibr" target="#b28">Marcu (2000b)</ref>. <ref type="bibr">3</ref> To compare with previous works on RST-DT, we use the 18 coarse-grained relations defined in <ref type="bibr" target="#b4">(Carlson et al., 2001</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Matrix Form +Features K Span Nuclearity Relation Prior work 1. HILDA <ref type="bibr" target="#b15">(Hernault et al., 2010)</ref> 83.0 68.4 54.8 2. TSP 1-1 ( <ref type="bibr" target="#b17">Joty et al., 2013)</ref> 82.47 68.43 55.73 3. TSP SW ( <ref type="bibr" target="#b17">Joty et al., 2013)</ref> 82   <ref type="table" target="#tab_2">Table 3</ref> presents RST parsing results for DPLP and some alternative systems. All versions of DPLP outperform the prior state-of-the-art on nuclearity and relation detection. This includes relatively simple systems whose features are simply a projection of the word count vectors for each EDU (lines 7 and 8). The addition of the features from <ref type="table" target="#tab_0">Table 2</ref> improves performance further, leading to absolute F-score improvement of around 2.5% in nuclearity and 6% in relation prediction (lines 9 and 10).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experimental Results</head><p>On span detection, DPLP performs slightly worse than the prior state-of-the-art. These sys- tems employ richer syntactic and contextual fea- tures, which might be especially helpful for span identification. As shown by line 4 of the re- sults table, the basic features from <ref type="table" target="#tab_0">Table 2</ref> pro- vide most of the predictive power for spans; how- ever, these features are inadequate at the more semantically-oriented tasks of nuclearity and re- lation prediction, which benefit substantially from the projected features. Since correctly identifying spans is a precondition for nuclearity and relation prediction, we might obtain still better results by combining features from HILDA and TSP with the representation learning approach described here.</p><p>Lines 5 and 6 show that discriminative learning of the projection matrix is crucial, as fixed projec- tions obtained from NMF or neural word embed- dings perform substantially worse. Line 7 shows that the original bag-of-words representation to- gether with basic features could give us some ben- efit on discourse parsing, but still not as good as results from DPLP. From lines 8 and 9, we see that the concatenation construction is superior to the difference construction, but the comparison between lines 10 and 11 is inconclusive on the merits of the general form of A. This suggests that using the projection matrix to model interre- lationships between EDUs does not substantially improve performance, and the simpler concatena- tion construction may be preferred. <ref type="figure" target="#fig_4">Figure 3</ref> shows how performance changes for different latent dimensions K. At each value of K, we employ grid search over a development set to identify the optimal regularizers λ and τ . For the concatenation construction, performance is not overly sensitive to K. For the general form of A, performance decreases with large K. Recall from Section 2.3 that this construction has nine times as many parameters as the concatenation form; with large values of K, it is likely to overfit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Analysis of Projection Matrix</head><p>Why does projection of the surface features im- prove discourse parsing? To answer this question, we examine what information the projection ma- trix is learning to encoded. We take the projec- tion matrix from the concatenation construction and K = 60 as an example for case study. Re- calling the definition in equation 4, the projection matrix A will be composed of three identical sub- matrices B ∈ R 20×V . The columns of the B ma- trix can be viewed as 20-dimensional descriptors of the words in the vocabulary.</p><p>For the purpose of visualization, we further re- duce the dimension of latent representation from K = 20 to 2 dimensions using t-SNE <ref type="bibr" target="#b50">(van der Maaten and Hinton, 2008)</ref>. One further simpli-  <ref type="table" target="#tab_2">Table 3</ref> fication for visualization is we consider only the top 1000 frequent unigrams in the RST-DT train- ing set. For comparison, we also apply t-SNE to the projection matrix B nmf recovered from non- negative matrix factorization. <ref type="figure" target="#fig_7">Figure 4</ref> highlights words that are related to dis- course analysis. Among the top 1000 words, we highlight the words from 5 major discourse con- nective categories provided in Appendix B of the PDTB annotation manual ( <ref type="bibr" target="#b35">Prasad et al., 2008)</ref>: CONJUNCTION, CONTRAST, PRECEDENCE, RE- SULT, and SUCCESSION. In addition, we also highlighted two verb categories from the top 1000 words: modal verbs and reporting verbs, with their inflections ( <ref type="bibr" target="#b20">Krestel et al., 2008)</ref>.</p><p>From the figure, it is clear DPLP has learned a projection matrix that successfully groups several major discourse-related word classes: particularly modal and reporting verbs; it has also grouped succession and precedence connectives with some success. In contrast, while NMF does obtain com- pact clusters of words, these clusters appear to be completely unrelated to discourse function of the words that they include. This demonstrates the value of using discriminative training to obtain the transformed representation of the discourse units.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Early work on document-level discourse parsing applied hand-crafted rules and heuristics to build trees in the framework of Rhetorical Structure Theory ( <ref type="bibr" target="#b45">Sumita et al., 1992;</ref><ref type="bibr" target="#b8">Corston-Oliver, 1998;</ref><ref type="bibr" target="#b27">Marcu, 2000a</ref>). An early data-driven approach was offered by <ref type="bibr" target="#b38">Schilder (2002)</ref>, who used distribu- tional techniques to rate the topicality of each dis- course unit, and then chose among underspecified discourse structures by placing more topical sen- tences near the root. Learning-based approaches were first applied to identify within-sentence dis- course relations <ref type="bibr" target="#b43">(Soricut and Marcu, 2003)</ref>, and only later to cross-sentence relations at the docu- ment level <ref type="bibr" target="#b0">(Baldridge and Lascarides, 2005</ref>). Of particular relevance to our inference technique are incremental discourse parsing approaches, such as shift-reduce (Sagae, 2009) and A* ( <ref type="bibr" target="#b32">Muller et al., 2012)</ref>. Prior learning-based work has largely focused on lexical, syntactic, and structural fea- tures, but the close relationship between discourse structure and semantics <ref type="bibr" target="#b13">(Forbes-Riley et al., 2006)</ref> suggests that shallow feature sets may struggle to capture the long tail of alternative lexicaliza- tions that can be used to realize discourse rela- tions ( <ref type="bibr" target="#b36">Prasad et al., 2010;</ref><ref type="bibr" target="#b24">Marcu and Echihabi, 2002</ref>). Only Subba and Di Eugenio (2009) incor- porate rich compositional semantics into discourse parsing, but due to the ambiguity of their seman- tic parser, they must manually select the correct semantic parse from a forest of possiblities.</p><p>Recent work has succeeded in pushing the state- of-the-art in RST parsing by innovating on sev- eral fronts. Feng and Hirst (2012) explore rich linguistic linguistic features, including lexical se- mantics and discourse production rules suggested by <ref type="bibr" target="#b22">Lin et al. (2009)</ref> in the context of the Penn Dis- course Treebank ( <ref type="bibr" target="#b35">Prasad et al., 2008)</ref>. <ref type="bibr" target="#b32">Muller et al. (2012)</ref> show that A* decoding can outperform both greedy and graph-based decoding algorithms. <ref type="bibr" target="#b17">Joty et al. (2013)</ref> achieve the best prior results on RST relation detection by (i) jointly perform- ing relation detection and classification, (ii) per- forming bottom-up rather than greedy decoding, and (iii) distinguishing between intra-sentence and inter-sentence relations. Our approach is largely orthogonal to this prior work: we focus on trans-   forming the lexical representation of discourse units into a latent space to facilitate learning. As shown in <ref type="figure" target="#fig_7">Figure 4</ref>(a), this projection succeeds at grouping words with similar discourse func- tions. We might expect to obtain further improve- ments by augmenting this representation learning approach with rich syntactic features (particularly for span identification), more accurate decoding, and special treatment of intra-sentence relations; this is a direction for future research. Discriminative learning of latent features for discourse processing can be viewed as a form of representation learning ( <ref type="bibr" target="#b1">Bengio et al., 2013)</ref>. Also called Deep Learning, such approaches have recently been applied in a number of NLP tasks <ref type="bibr" target="#b7">(Collobert et al., 2011;</ref><ref type="bibr" target="#b40">Socher et al., 2012</ref>). Of particular relevance are applications to the de- tection of semantic or discourse relations, such as paraphrase, by comparing sentences in an in- duced latent space <ref type="bibr" target="#b39">(Socher et al., 2011;</ref><ref type="bibr" target="#b14">Guo and Diab, 2012;</ref><ref type="bibr" target="#b16">Ji and Eisenstein, 2013)</ref>. In this work, we show how discourse structure annotations can function as a supervision signal to discriminatively learn a transformation from lexical features to a la- tent space that is well-suited for discourse parsing. Unlike much of the prior work on representation learning, we induce a simple linear transforma- tion. Extension of our approach by incorporating a non-linear activation function is a natural topic for future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We have presented a framework to perform dis- course parsing while jointly learning to project to a low-dimensional representation of the discourse units. Using the vector-space representation of EDUs, our shift-reduce parsing system substan- tially outperforms existing systems on nuclearity detection and discourse relation identification. By adding some additional surface features, we ob- tain further improvements. The low dimensional representation also captures basic intuitions about discourse connectives and verbs, as shown in <ref type="figure" target="#fig_7">Fig- ure 4(a)</ref>.</p><p>Deep learning approaches typically apply a non-linear transformation such as the sigmoid function ( <ref type="bibr" target="#b1">Bengio et al., 2013</ref>). We have con- ducted a few unsuccessful experiments with the "hard tanh" function proposed by <ref type="bibr" target="#b6">Collobert and Weston (2008)</ref>, but a more complete exploration of non-linear transformations must wait for future work. Another direction would be more sophis- ticated composition of the surface features within each elementary discourse unit, such as the hierar- chical convolutional neural network <ref type="bibr" target="#b18">(Kalchbrenner and Blunsom, 2013)</ref> or the recursive tensor network <ref type="bibr" target="#b41">(Socher et al., 2013)</ref>. It seems likely that a better accounting for syntax could improve the latent representations that our method induces.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example of RST discourse structure.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Figure 2: Decision problem with different representation functions</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Competitive systems We compare our approach with HILDA (Hernault et al., 2010) and TSP (Joty et al., 2013). Joty et al.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The performance of our parser over different latent dimension K. Results for DPLP include the additional features from Table 3</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Latent representation of words from projection learning with K = 20.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Latent representation of words from non-negative matrix factorization with K = 20.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: t-SNE Visualization on latent representations of words.</figDesc><graphic url="image-1.png" coords="9,85.95,73.80,198.90,135.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Additional features for RST parsing 

ing and 38 for testing in the standard split. As 
we focus on relational discourse parsing, we fol-
low prior work (Feng and Hirst, 2012; Joty et al., 
2013), and use gold EDU segmentations. The 
strongest automated RST segmentation methods 
currently attain 95% accuracy (Xuan Bach et al., 
2012). 

Preprocessing In the RST-DT, most nodes have 
exactly two children, one nucleus and one satellite. 
For non-binary relations, we use right-branching 
to binarize the tree structure. For multi-nuclear 
relations, we choose the left EDU as "head" 
EDU. The vocabulary V includes all unigrams af-
ter down-casing. No other preprocessing is per-
formed. In total, there are 16250 unique unigrams 
in V. 

Fixed projection matrix baselines Instead of 
learning from data, a simple way to obtain a pro-
jection matrix is to use matrix factorization. Re-
cent work has demonstrated the effectiveness of 
non-negative matrix factorization (NMF) for mea-
suring distributional similarity (Dinu and Lapata, 
2010; Van de Cruys and Apidianaki, 2011). We 
can construct B nmf in the concatenation form 
of the projection matrix by applying NMF to the 
EDU-feature matrix, M ≈ WH. As a result, W 
describes each EDU with a K-dimensional vector, 
and H describes each word with a K-dimensional 
vector. We can then construct B nmf by taking 
the pseudo-inverse of H, which then projects from 
word-count vectors into the latent space. 
Another way to construct B is to use neural 
word embeddings </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Parsing results of different models on the RST-DT test set. The results of TSP and HILDA are 
reprinted from prior work (Joty et al., 2013; Hernault et al., 2010). 

</table></figure>

			<note place="foot" n="3"> Large-Margin Learning Framework We apply a large margin structure prediction approach to train the model. There are two parameters that need to be learned: the classification weights {w m }, and the projection matrix A. As we will see, it is possible to learn {w m } using standard support vector machine (SVM) training (holding A fixed), and then make a simple gradient-based update to A (holding {w m } fixed). By interleaving these two operations, we arrive at a saddle point of the objective function.</note>

			<note place="foot" n="3"> We implemented the evaluation metrics by ourselves. Together with the DPLP system, all codes are published on https://github.com/jiyfeng/DPLP</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the reviewers for their helpful feedback, particularly for the connection to multitask learn-ing. We also want to thank Kenji Sagae and Vanessa Wei Feng for the helpful discussion via email communication. This research was sup-ported by Google Faculty Research Awards to the second author.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Probabilistic head-driven parsing for discourse structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Baldridge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Lascarides</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth Conference on Computational Natural Language Learning</title>
		<meeting>the Ninth Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="96" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<title level="m">Representation Learning: A Review and New Perspectives. IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1798" to="1828" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A Procedure for Quantitatively Comparing the Syntactic Coverage of English Grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ezra</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Abney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Flickinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudia</forename><surname>Gdaniec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Don</forename><surname>Hindle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Ingria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fred</forename><surname>Jelinek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judith</forename><surname>Klavans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Liberman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatrice</forename><surname>Santorini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomek</forename><surname>Strzalkowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Speech and Natural Language: Proceedings of a Workshop Held at</title>
		<meeting><address><addrLine>Pacific Grove, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1991-02-19" />
			<biblScope unit="page" from="306" to="311" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Holistic discourse coherence annotation for noisy essay writing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jill</forename><surname>Burstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Tetreault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Chodorow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dialogue &amp; Discourse</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="34" to="52" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Building a Discourse-tagged Corpus in the Framework of Rhetorical Structure Theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lynn</forename><surname>Carlson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><forename type="middle">Ellen</forename><surname>Okurowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Second SIGdial Workshop on Discourse and Dialogue</title>
		<meeting>Second SIGdial Workshop on Discourse and Dialogue</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Incremental parsing with the perceptron algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Roark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL, page 111. Association for Computational Linguistics</title>
		<meeting>ACL, page 111. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A Unified Architecture for Natural Language Processing: Deep Neural Networks with Multitask Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Natural Language Processing (Almost) from Scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Beyond string matching and cue phrases: Improving efficiency and coverage in discourse analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Simon Corston-Oliver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The AAAI Spring Symposium on Intelligent Text Summarization</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="9" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">On the Algorithmic Implementation of Multiclass Kernel-based Vector Machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="265" to="292" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Measuring Distributional Similarity in Context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgiana</forename><surname>Dinu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1162" to="1172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Text-level Discourse Parsing with Rich Linguistic Features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Vanessa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graeme</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hirst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Building Watson: An overview of the DeepQA project</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Ferrucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Chu-Carroll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Gondek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><forename type="middle">A</forename><surname>Kalyanpur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lally</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Murdock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Nyberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Prager</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI magazine</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="59" to="79" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Computing discourse semantics: The predicate-argument semantics of discourse connectives in D-LTAG</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><surname>Forbes-Riley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Webber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Semantics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="55" to="106" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Modeling Sentences in the Latent Space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012-07" />
			<biblScope unit="page" from="864" to="872" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">HILDA: A Discourse Parser Using Support Vector Machine Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Hernault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helmut</forename><surname>Prendinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">A</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitsuru</forename><surname>Ishizuka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dialogue and Discourse</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="33" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Discriminative Improvements to Distributional Sentence Similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<meeting><address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-10" />
			<biblScope unit="page" from="891" to="896" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Combining Intra-and Multi-sentential Rhetorical Parsing for Documentlevel Discourse Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shafiq</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Carenini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yashar</forename><surname>Mehdad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Recurrent convolutional neural networks for discourse compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Continuous Vector Space Models and their Compositionality</title>
		<meeting>the Workshop on Continuous Vector Space Models and their Compositionality<address><addrLine>Sofia, Bulgaria, August</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="119" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Simple Semi-supervised Dependency Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Carreras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics</title>
		<meeting><address><addrLine>Columbus, Ohio</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-06" />
			<biblScope unit="page" from="595" to="603" />
		</imprint>
	</monogr>
	<note>Proceedings of ACL-HLT</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Minding the Source: Automatic Tagging of Reported Speech in Newspaper Articles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralf</forename><surname>Krestel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabine</forename><surname>Bergler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">René</forename><surname>Witte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<meeting><address><addrLine>Marrakech, Morocco</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-05" />
		</imprint>
	</monogr>
	<note>European Language Resources Association (ELRA</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">On Optimization Methods for Deep Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiquan</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Ngiam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhik</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bobby</forename><surname>Lahiri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Prochnow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Recognizing Implicit Discourse Relations in the Penn Discourse Treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min-Yen</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee Tou</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Discourse indicators for content selection in summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Annie</forename><surname>Louis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue</title>
		<meeting>the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="147" to="156" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">An Unsupervised Approach to Recognizing Discourse Relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdessamad</forename><surname>Echihabi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL<address><addrLine>Philadelphia, Pennsylvania, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002-07" />
			<biblScope unit="page" from="368" to="375" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Building Up Rhetorical Structure Trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A Decision-Based Approach to Rhetorical Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL<address><addrLine>College Park, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-06" />
			<biblScope unit="page" from="365" to="372" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The Rhetorical Parsing of Unrestricted Texts: A Surface-based Approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="395" to="448" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">The Theory and Practice of Discourse Parsing and Summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Name Tagging with Word Clusters and Discriminative Training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jethran</forename><surname>Guinness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Zamanian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<editor>Daniel Marcu Susan Dumais and Salim Roukos</editor>
		<meeting><address><addrLine>Boston, Massachusetts, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004-05-02" />
			<biblScope unit="page" from="337" to="342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Evaluation of text coherence for electronic essay scoring systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleni</forename><surname>Miltsakaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Kukich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="25" to="55" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Composition in distributional models of semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1388" to="1429" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Constrained Decoding for Text-Level Discourse Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stergos</forename><surname>Afantenos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Denis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Asher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The COLING 2012 Organizing Committee</title>
		<meeting><address><addrLine>Mumbai, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-12" />
			<biblScope unit="page" from="1883" to="1900" />
		</imprint>
	</monogr>
	<note>Coling</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Structured Penalties for Log-Linear Language Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anil</forename><surname>Kumar Nelakanti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cedric</forename><surname>Archambeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Bouchard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">October. Association for Computational Linguistics</title>
		<meeting><address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="233" to="243" />
		</imprint>
	</monogr>
	<note>EMNLP</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">MaltParser: A language-independent system for data-driven dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Nilsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atanas</forename><surname>Chanev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gülsen</forename><surname>Eryigit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandra</forename><surname>Kübler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svetoslav</forename><surname>Marinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erwin</forename><surname>Marsi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="95" to="135" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The penn discourse treebank 2.0</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rashmi</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhil</forename><surname>Dinesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleni</forename><surname>Miltsakaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Livio</forename><surname>Robaldo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Webber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Realization of discourse relations by other means: alternative lexicalizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rashmi</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Webber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics: Posters</title>
		<meeting>the 23rd International Conference on Computational Linguistics: Posters</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1023" to="1031" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Analysis of Discourse Structure with Syntactic Dependencies and Data-Driven ShiftReduce Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Sagae</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Conference on Parsing Technologies (IWPT)</title>
		<meeting>the 11th International Conference on Parsing Technologies (IWPT)<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009-10" />
			<biblScope unit="page" from="81" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Robust discourse parsing via discourse markers, topicality and position</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Schilder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="235" to="255" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Dynamic Pooling and Unfolding Recursive Autoencoders for Paraphrase Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Semantic Compositionality Through Recursive Matrix-Vector Spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brody</forename><surname>Huval</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Recursive deep models for semantic compositionality over a sentiment treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Perelygin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Supervised and unsupervised methods in employing discourse relations for improving opinion polarity classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swapna</forename><surname>Somasundaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Galileo</forename><surname>Namata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lise</forename><surname>Getoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Sentence Level Discourse Parsing using Syntactic and Lexical Information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">An effective Discourse Parser that uses Rich Linguistic Information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajen</forename><surname>Subba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><forename type="middle">Di</forename><surname>Eugenio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<meeting><address><addrLine>Colorado</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009-06" />
			<biblScope unit="page" from="566" to="574" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A discourse structure analyzer for Japanese text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sumita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ono</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ukita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Amano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings International Conference on Fifth Generation Computer Systems</title>
		<meeting>International Conference on Fifth Generation Computer Systems</meeting>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="1133" to="1140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Applications of rhetorical structure theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maite</forename><surname>Taboada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>William C Mann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Discourse studies</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="567" to="588" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Max-margin markov networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Taskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daphne</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Word Representation: A Simple and General Method for Semi-Supervised Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Turian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="384" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Latent Semantic Word Sense Induction and Disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Van De Cruys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marianna</forename><surname>Apidianaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL<address><addrLine>Portland, Oregon, USA, June</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1476" to="1485" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Visualizing Data using t-SNE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2759" to="2605" />
			<date type="published" when="2008-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Not all words are created equal: Extracting semantic orientation as a function of adjective relevance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kimberly</forename><surname>Voll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maite</forename><surname>Taboada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Australian Conference on Artificial Intelligence</title>
		<meeting>Australian Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A Reranking Model for Discourse Segmentation using Subtree Features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ngo Xuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nguyen</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akira</forename><surname>Le Minh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shimazu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue</title>
		<meeting>the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="160" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Learning structural SVMs with latent variables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Nam John</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Annual International Conference on Machine Learning</title>
		<meeting>the 26th Annual International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1169" to="1176" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
