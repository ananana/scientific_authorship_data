<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:28+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Won&apos;t somebody please think of the children? Improving Topic Model Clustering of Newspaper Comments for Summarisation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clare</forename><surname>Llewellyn</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Informatics</orgName>
								<orgName type="department" key="dep2">School of Informatics</orgName>
								<orgName type="institution">University of Edinburgh Edinburgh</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Grover</surname></persName>
							<email>grover@inf.ed.ac.uk</email>
							<affiliation key="aff1">
								<orgName type="department">School of Informatics</orgName>
								<orgName type="institution">University of Edinburgh Edinburgh</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Oberlander</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">University of Edinburgh Edinburgh</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Won&apos;t somebody please think of the children? Improving Topic Model Clustering of Newspaper Comments for Summarisation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics-Student Research Workshop</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics-Student Research Workshop <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="43" to="50"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Online newspaper articles can accumulate comments at volumes that prevent close reading. Summarisation of the comments allows interaction at a higher level and can lead to an understanding of the overall discussion. Comment summarisation requires topic clustering, comment ranking and extraction. Clustering must be robust as the subsequent extraction relies on a good set of clusters. Comment data, as with many social media datasets, contains very short documents and the number of words in the documents is a limiting factors on the performance of LDA clustering. We evaluate whether we can combine comments to form larger documents to improve the quality of clusters. We find that combining comments with comments that reply to them produce the highest quality clusters.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Newspaper articles can accumulate many hun- dreds and sometimes thousands of online com- ments. When studied closely and analysed effec- tively they provide multiple points of view and a wide range of experience and knowledge from diverse sources. However, the number of com- ments produced per article can prohibit close read- ing. Summarising the content of these comments allows users to interact with the data at a higher level, providing a transparency to the underlying data ( <ref type="bibr" target="#b8">Greene and Cross, 2015)</ref>.</p><p>The current state of the art within the comment summarisation field is to cluster comments us- ing Latent Dirichlet Allocation (LDA) topic mod- elling ( <ref type="bibr" target="#b12">Khabiri et al., 2011;</ref><ref type="bibr" target="#b16">Ma et al., 2012;</ref><ref type="bibr" target="#b14">Llewellyn et al., 2014</ref>). The comments within each topic cluster are ranked and comments are typically extracted to construct a summary of the cluster. In this paper we focus on the clustering subtask. It is important that the clustering is ap- propriate and robust as the subsequent extraction relies on a good set of clusters. Research in a re- lated domain has found that topical mistakes were the largest source of error in summarising blogs - ( <ref type="bibr" target="#b18">Mithun and Kosseim, 2009</ref>) a similar data type.</p><p>Comment data, as with many social media datasets, differs from other content types as each 'document' is very short. Previous studies have indicated that the number of documents and the number of words in the documents are limiting factors on the performance of topic modelling ( <ref type="bibr">Tang et al., 2014</ref>). Topic models built using longer documents and using more documents are more accurate. Short documents can be enriched with external data. In our corpus the number of comments on each newspaper article is finite and the topics discussed within each set have evolved from the original article. We therefore decided not to increase the set with data from external sources.</p><p>In this work we consider whether we can com- bine comments within a comments dataset to form larger documents to improve the quality of clus- ters. Combining comments into larger documents reduces the total number of comments available to cluster which may decrease the quality of the clus- ters. The contribution of this work is in showing that combining comments with their direct replies, their children, increases the quality of the cluster- ing. This approach can be applied to any other task which requires clustering of newspaper com- ments and any other data which contains small documents linked using a thread like structure. Combining data in this way to improve the clus- tering reduces the need to import data from exter- nal sources or to adapt the underlying clustering algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Summarisation</head><p>The summarisation domain is well developed. The earliest focus of the field was single document summarisation -for a survey paper see <ref type="bibr" target="#b10">(Gupta and Lehal, 2010)</ref>. This approach was extended into the summarisation of multiple documents on the same topic ( <ref type="bibr" target="#b7">Goldstein et al., 2000</ref>) and to summarising discussions such as email or Twitter conversations ( <ref type="bibr" target="#b4">Cselle et al., 2007;</ref><ref type="bibr" target="#b22">Sharifi et al., 2010;</ref><ref type="bibr" target="#b11">Inouye and Kalita, 2011</ref>).</p><p>The basic idea behind the summarisation of tex- tual data is the grouping together of similar infor- mation and describing those groups ( <ref type="bibr" target="#b20">Rambow et al., 2004</ref>). Once these groups are formed they are described using either an extractive or abstractive approach. Extractive summarisation uses units of text, generally sentences, from within the data in the group to represent the group. Abstractive sum- marisation creates a description of the data in the group as a whole, analogous to the approach a hu- man would take.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Comment Summarisation</head><p>Abstractive summarisation is a very complex task, and because comment summarisation is a rela- tively new task, current work mostly focuses on extractive approaches. The general task involves clustering the comments into appropriate topics and then extracting comments, or parts of com- ments to represent those topics ( <ref type="bibr" target="#b12">Khabiri et al., 2011;</ref><ref type="bibr" target="#b16">Ma et al., 2012)</ref>. <ref type="bibr" target="#b16">Ma et al. (2012)</ref> summarise discussion on news articles from Ya- hoo!News and Khabiri et al (2011) summarise comments on YouTube videos. Both studies agree on the definition of the basic task as: clustering comments into topics, ranking to identify com- ments that are key in the clusters, and evaluat- ing the results through a human study. Both ap- proaches focus on using LDA topic modelling to cluster the data. <ref type="bibr" target="#b16">Ma et al. (2012)</ref> explored two topic models, one where topics are derived from the original news article and a second, extended version that allows new topics to be formed from the comments. They found that the extended ver- sion was judged superior in a user study. <ref type="bibr" target="#b12">Khabiri et al. (2011)</ref> contrasted LDA topic models with k-means and found topic modelling superior. A study by <ref type="bibr" target="#b14">Llewellyn et al. (2014)</ref> contrasted topic modelling, k-means, incremental one pass cluster- ing and clustering on common unigrams and bi- grams. They found that the topic modelling ap- proach was superior. <ref type="bibr" target="#b0">Aker et al. (2016)</ref> looked at a graph based model that included information from DBpedia, finding that this approach out per- formed an un-optimised LDA model. They then labelled the clusters using LDA clustering and ex- tracted keywords.</p><p>Other work has been conducted in related do- mains such as summarising blogs, microblogs and e-mail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Blog Summarisation</head><p>Comments are similar to blogs in that they are generated by multiple individuals who exhibit a vast array of writing styles. <ref type="bibr">Mithum and Koseim (2009)</ref> found that whereas news articles have a generalisable structure that can be used to aid sum- marisation, blogs are more variable. In particu- lar they found that errors in blog summarisation are much higher than in news text summarisation. They determined that errors were often due to the candidate summary sentences being off topic and they suggest that blog summarisation needs to be improved in terms of topic detection. When in- vestigating the summarisation of blogs and com- ments on blogs <ref type="bibr" target="#b1">Balahur et al.(2009)</ref> found that it is very common to change topics between the orig- inal blog post and the comments, and from com- ment to comment. The research of <ref type="bibr">Mithum and Koseim (2009)</ref> and <ref type="bibr" target="#b1">Balahur et al. (2009)</ref> indicates that topic identification is a key area on which to concentrate efforts in the emerging field of com- ment summarisation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3">Microblog Summarisation</head><p>A significant amount of work has been conducted in the area of Twitter summarisation. Many Twit- ter summarisation techniques exploit that tweets often include hashtags which serve as an indica- tion of their topic. Duan et al.(2012) designed a summarisation framework for Twitter by defining topics and selecting tweets to represent those top- ics. The topics are defined using hashtags and are split when at high volume by specific time slices and word frequency. <ref type="bibr" target="#b21">Rosa et al. (2011)</ref> also use hashtags to cluster tweets into topics, using them as annotated classes for training data. They fo- cus on supervised machine learning, specifically SVM and K Nearest Neighbour, as they found the results from unsupervised clustering (LDA and k- means clustering) performed poorly when applied to Twitter data. In a further Twitter summarisation tool, TweetMotif, O' <ref type="bibr">Connor et al. (2010)</ref> use lan- guage modelling to create summaries. They form topic clusters by identifying phrases that could de- fine a topic, looking for those phrases in the corpus and merging sets of topics that are similar. Re- search on microblog summarisation indicates that when summarising comments it is possible but dif- ficult to use unsupervised clustering and several rules have been suggested that can be followed to produce the most suitable clusters for summarisa- tion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.4">E-mail Summarisation</head><p>E-mail and comments are similar in several re- spects: they both exhibit a thread-like structure, containing multiple participant conversations that occur along a variable time line, they may refer back to previous parts of the conversation and ex- hibit high variability in writing styles <ref type="bibr" target="#b3">(Carenini et al., 2007)</ref>. Topic identification is challenging in e- mail threads. <ref type="bibr">Wan and Mckeown (2004)</ref> noted that several different tasks were conducted in email conversations: decision making, requests for ac- tion, information seeking and social interaction. <ref type="bibr" target="#b20">Rambow et al. (2004)</ref> found that e-mail has an in- herent structure and that this structure can be use to extract e-mail specific features for summarisa- tion. This suggests that comments may have an inherent structure which can be used to assist in summarisation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data</head><p>The work reported here is based on comments from news articles taken from the online, UK ver- sion of the Guardian newspaper. It is composed of online comments that are created by readers who have registered and posted under a user-name. The site is moderated and comments can be re- moved. We harvested the comments once the com- ment section is closed and the data is no longer up- dated. The comment system allows users to view comments either in a temporal fashion, oldest or newest first, or as threads. Users are then able to add their own comments to the set by either post- ing directly or by replying to another user, adding their comments to any point in the thread. This de- velops a conversational style of interaction where users interact with each other and comment upon the comments of others. The topics discussed can therefore evolve from the topics of the original ar- ticle.</p><p>In total we have gathered comments posted in response to thirteen articles. Each week a journal- ist from the Guardian summarises the comments on one particular article and we have selected data from these weekly summaries to provide a further point of comparison. A typical example is our comment set 5 where the initial article was titled 'Cutting edge: the life of a former London gang leader', the journalist had divided the comments into sets as follows:</p><p>• 40% criticised gang culture for creating a de- sire for fame and respect</p><p>• 33% would like to hear more from victims of gang violence</p><p>• 17% found Dagrou's story depressing</p><p>• 10% believed he should be praised for turn- ing his life around</p><p>An example of a comment that fit into the jour- nalist based classification scheme is: "I'd love to see an in-depth article about a person whose life is made a complete misery by gangs. You know, maybe a middle-aged lady who lives on her own in a gang area, something like that."</p><p>An example of a comment that does not fit into the classification scheme: "So people who don't have to turn their lives around are ignored and not supported. These are the people who are sometimes homeless cause there is no help if you haven't been in prison or don't have kids".</p><p>In this work we refer to all of the comments on a single article as a comment set. There is data that has been annotated by humans (the gold standard set) and data that has not. The gold standard data set contained three comment sets. It was produced by human(s) assigning all comments from a com- ment set to topic groups. For one comment set two humans assigned groups (Set 1) and for two com- ment sets (Sets 2 and 3) a single human assigned groups. No guidance was given as to the number of topics required, but the annotators were asked to make the topics as broad or as inclusive as they could.</p><p>In the set where both humans assigned topics the first annotator determined that there were 26 topics whereas the second annotator identified 45 topics. This difference in topic number was due to a variation in numbers of clusters with a single <ref type="table" target="#tab_0">Table 1: Comment Set Composition -A description of the data set  Set  1  2  3  4  5  6  7  8  9  10  11  12  13  Comments  160 230 181 51 121 169 176 205 254 328 373 397 661  Authors  67 140 112 28  65 105 103 111 120 204 240 246 420  Threads  54 100  82 21  53  71  67  80  95 132 198 164 319  Groups of siblings  126 186 154 45 108 139 148 160 205 256 314 320 553  Time Segment  77 113  68 33  72 110  76 117 142 160 124 119 203  Over 50 Words (%)  58  52  29 39  37  36  18  38  49  44  26  26  30  Mean number of words  80  81  45 58  53  45  38  69  72  61  40  43  48  Human topics  14  21  20  - - - - - - - - - Automatic topics  - - - 5  5  7  8  5  5  18  18  16  7</ref> member. Once these were removed both annota- tors had created 14 clusters. The human-human F-Score was 0.607 including the single clusters and 0.805 without. It was felt that agreement at this level meant that double annotation was not re- quired for the futher two sets. All annotated sets have the clusters with single members removed. A further 10 sets of comments were collected which were not annotated. <ref type="table">Table I</ref> shows the com- position of these comment sets. We can see that the number of comments varies and that number of authors, threads, groups of siblings (comments that reply to the same comment) and time seg- ments tend to increase with size. The number of words in a comment does not. The sets of com- ments, with annotations where available, can be found at (Llewellyn, 2016).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Data Manipulation</head><p>We have investigated methods for combining the individual comments into larger 'documents' us- ing metadata features. The data is combined ac- cording to aspects extracted from the metadata; these are as follows:</p><p>• STANDARD: Comments are not combined in any way. This is a baseline result to which the other results can be compared.</p><p>• AUTHOR: Comments are grouped together if they have the same author. A common ap- proach to increase the size of Twitter docu- ments is to group tweets together that come from a single author on the assumption that authors stick to the same/similar topics. Here the same approach is tried with comments.</p><p>• TIME: Comments are grouped together within a ten minute segment. Comments may be on the same topics if they are posted at the same time (if the users are viewing comments through the newest first method).</p><p>It is hypothesised that there may be topical consis- tency within threads. The 'threadness' was identi- fied in several ways:</p><p>• FULL THREAD: Comments were grouped together to reflect the full thread from the original root post and including all replies to that post and all subsequent posts in the thread.</p><p>• CHILDREN: A comment is grouped with all direct replies to that comment.</p><p>• SIBLINGS: A comment is grouped with its siblings, all other comments that reply to a specific comment.</p><p>All of the groups of related comments are com- bined together, according to the method, to form a single document for each group.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Short Documents</head><p>Previous work indicates that removing short doc- uments from the data sets prior to topic modelling improves the quality of the topic models ( <ref type="bibr">Tang et al., 2014</ref>). We found, in an experiment into whether length of comments influenced the qual- ity of clusters, that removing comments that con- tain few than 50 terms increases the ability of a topic model to classify documents that are longer than 50 terms but it does not increase the ability to classify all documents, especially shorter doc- uments. If we deem it useful to have short com- ments in the clusters for the ranking and extraction phase of summarisation, then it is important that these shorter documents are retained in the model building stage, we therefore include them in our experiments detailed here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Topic Modelling</head><p>The clustering method used in this work is Latent Dirichlet Allocation (LDA) topic modelling ( <ref type="bibr" target="#b2">Blei et al., 2003)</ref>. It produces a generative model used to determine the topics contained in a text docu- ment. A topic is formed from words that often co-occur, therefore the words that co-occur more frequently across multiple documents most likely belong to the same topic. It is also true that each document may contain a variety of topics. LDA provides a score for each document for each topic.</p><p>In this case we assign the document to the topic or topics for which it has the highest score. This approach was implemented using the Mal- let tool-kit <ref type="bibr" target="#b17">(McCallum, 2002</ref>). The Mallet tool kit topic modelling implementation allows dirich- let hyper-parameter re-estimation. This means that although the hyper parameters are initially set it is possible to allow them to be re-estimated to better suit the data set being modelled. In these exper- iments, after previous optimisation tests, we ini- tially set the sum of alpha across all topics as 4, beta as 0.08. We set the number of iterations at 1000, and we allow re-estimation of the dirichlet hyper-parameters every 10 iterations.</p><p>In order to cluster the comment data into topics an appropriate number of topics must be chosen. In choosing the number of topics we aim to pick a number which strikes a balance between produc- ing a small number of broad topics or a large num- ber of overly specific topics. We aim to echo a human like decision as to when something is on- or off-topic. Too few items in each topic is to be avoided, as is having a small number of topics (O' <ref type="bibr">Connor et al., 2010)</ref>.</p><p>In our data set, we choose the number of clus- ters by two methods. When data has been anno- tated by humans the number of topics identified by humans was chosen as the cluster number. When the data had not been annotated by humans the cluster number was identified using an automatic method of stability analysis. This method was pro- posed by <ref type="bibr">Greene, O' Callaghan, and Cunningham (2014)</ref>, and it assumes that if there is a 'natural' number of topics within a data set, then this num- ber of topics will give the most stable result each time the data is re-clustered. Stability is calculated using a ranked list of most predictive topic words. Each time the data is modelled, the change in the members and ordering of that list is used to cal- culate a stability score. <ref type="bibr">Green et. al (2014)</ref> used the top twenty features to form their ranked list of features. Here, as the length of the documents is shorter, we use the top ten. The sets of documents as described in the pre- vious sections are then used to build topic mod- els and the comments are assigned to topical clus- ters using these models. Ten-fold cross-validation is used. As topic modelling is a generative pro- cess, the topics produced are not identical on each new run as discussed in more detail in ( <ref type="bibr" target="#b13">Koltcov et al., 2014)</ref>. Therefore the process is repeated 100 times, so that an average score can be supplied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Metrics</head><p>There are two main metrics that are exploited in this work: Perplexity and micro-averaged F-score. Perplexity is judged by building a model using training data, and then testing with a held out set to see how well the word counts of the test doc- uments are represented by the word distributions represented in the topics in the model ( <ref type="bibr">Wallach et al., 2009)</ref>. This score shows how perplexed the model is by the new data. Perplexity has been found to be consistent with other measures of clus- ter quality such as point-wise mutual information ( <ref type="bibr">Tang et al., 2014</ref>). PMI data is also available and can be supplied if requested.</p><p>It is difficult to judge when a perplexity score is 'good enough' as perplexity will continue to de- crease as the number of clusters increases. Topic models that represent single comments are the least perplexed. Therefore a section of the dataset has been hand annotated and this is used to pro- vide a micro-averaged F-score. This can be used to gauge if the perplexity scores are equivalent to human judgements. For more details on this met- ric see <ref type="bibr" target="#b23">Sokolova and Lapalme (2009)</ref>. <ref type="table">Table 3</ref>: Combined Data -Perplexity Score (the best / least perplexed model is in bold) Comment <ref type="table" target="#tab_0">Set  1  2  3  4  5  6  7  8  9  10  11  12  13  Standard  253 671 520 343 555 444 531  960 1084 818 659 756  810  Author  572 644 525 422 555 582 518 1005 1224 908 669 766  761  Children  373 608 405 274 427 406 434  673 1019 637 712 514  657  Full Thread  707 764 477 394 496 499 567 1026 1490 991 933 753  875  Siblings  613 730 560 401 590 532 607  804 1009 734 759 649  813  Time  584 715 459 460 579 433 542  796 1090 965 776 720 716.05</ref> Here we present scores in terms of micro- averaged F-score (when a gold standard is avail- able for comparison), and by perplexity. A higher F-score indicates a more human like model and a lower perplexity score indicates a less perplexed model. Significance is tested using a Student's two tailed t-test and significant results are quoted when p&lt;0.01 <ref type="bibr" target="#b6">(Field, 2013)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and Discussion</head><p>First we will discuss the results from the 3 anno- tated data sets (1, 2 and 3). Using an F-score met- ric we find that, for all three annotated sets that grouping comments using the metadata features author and time does not improve topic cluster- ing. Grouping comments using thread based fea- tures was more sucessful. We found that combin- ing comments with their replies (the children) and combining comments within the full thread sets significantly beat the standard baseline ( <ref type="table" target="#tab_0">Table 2)</ref>.</p><p>The results differ when judged by perplexity <ref type="table">(Table 3)</ref>. We found for two of the comment sets (2 and 3) the children data set gave models that were significantly less perplexed than the standard baseline but this was not the case for comment set 1. For comment set 1 no models beats the baseline using the perplexity metric.</p><p>When we look at all of the data, judged using a perplexity score <ref type="table">(Table 3)</ref>, we found that the combined children data sets consistently created models (for 10 out of the 13 sets) that are signifi- cantly less perplexed than a standard baseline. For one of the datasets the data combined with other replies to the same message, the siblings set, beats the baseline. For two of the sets no combination method beats the baseline.</p><p>The automated results and human results as in- dicated by perplexity and micro-averaged F-score are not in complete agreement, but there are some commonalities. Both sets of results indicate that the group that combines responses with comments (the children group) has the highest agreement with the human model, and it consistently pro- duces the least perplexed model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>It is worth noting that although we focus here on newspaper comments, the need for summarisation applies to any web-based chat forum and the find- ings therefore have a wide applicability.</p><p>LDA topic modelling perfoms better with longer documents. Here we have investigated methods for combining newspaper comments into longer documents in order to improve LDA clus- tering and therefore provide a strong basis for sub- sequent comment summarisation. We found that combining comments using features derived from the thread structure of the commenting system was more successful than features from the comments metadata. We found that using a combination of a comment and its children provides 'documents' that produce models that can more accurately clas- sify comments into topics than other document combination methods. It is likely that the method of grouping comments with their direct replies, their children, is the most successful because com- mentors interact with the other comments through the thread system (rather than newest or oldest first) and they add topically relevent information to the threads. It also indicates that topics in threads evolve, meaning that grouping the entire thread to- gether into a single document works less well than grouping the immediate decendants -the children.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Jian Tang, Zhaoshi Meng, Xuanlong Nguyen, Qiaozhu</head><p>Mei, and Ming Zhang. 2014. Understanding the limiting factors of topic modeling via posterior con- traction analysis. In Proceedings of The 31st In- ternational Conference on Machine <ref type="bibr">Learning, pages 190-198</ref> </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Combined Data, Annotated, F-score (re-
sults that beat the standard baseline are in bold) 
1 
2 
3 
Standard Baseline 0.59 0.36 0.33 
Author 
0.43 0.34 0.32 
Children 
0.70 0.41 0.48 
Full Thread 
0.63 0.38 0.37 
Siblings 
0.59 0.37 0.33 
Time 
0.38 0.31 0.24 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>.</head><label></label><figDesc></figDesc><table>Hanna M Wallach, Iain Murray, Ruslan Salakhutdinov, 
and David Mimno. 2009. Evaluation methods for 
topic models. In Proceedings of the 26th Annual In-
ternational Conference on Machine Learning, pages 
1105-1112. ACM. 

Stephen Wan and Kathy McKeown. 2004. Generating 
overview summaries of ongoing email thread dis-
cussions. In Proceedings of the 20th international 
conference on Computational Linguistics, page 549. 
Association for Computational Linguistics. </table></figure>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A graph-based approach to topic clustering for online comments to news</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmet</forename><surname>Aker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emina</forename><surname>Kurtic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Balamurali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Monica</forename><surname>Paramita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emma</forename><surname>Barker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Hepple</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Gaizauskas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Information Retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="15" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Summarizing opinions in blog threads</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Balahur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandrov</forename><surname>Kabadjov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Steinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralf</forename><surname>Steinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andres</forename><surname>Montoyo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PACLIC</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="606" to="613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<title level="m">Latent dirichlet allocation</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Summarizing email conversations with clue words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Carenini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Raymond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th international conference on World Wide Web</title>
		<meeting>the 16th international conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="91" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">BuzzTrack: topic detection and tracking in email</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Cselle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keno</forename><surname>Albrecht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rogert</forename><surname>Wattenhofer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th International Conference on Intelligent User Interfaces, IUI &apos;07</title>
		<meeting>the 12th International Conference on Intelligent User Interfaces, IUI &apos;07</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="190" to="197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Twitter topic summarization by ranking tweets using social influence and content quality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duan</forename><surname>Yajuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weif</forename><surname>Chen Zhumin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Uru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Heung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shum</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on Computational Linguistics</title>
		<meeting>the 24th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="763" to="780" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Discovering statistics using IBM SPSS statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Field</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<pubPlace>Sage</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Multi-document summarization by sentence extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jade</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vibhu</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Kantrowitz</surname></persName>
		</author>
		<idno>NAACL-ANLP- AutoSum &apos;00</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2000 NAACL-ANLPWorkshop on Automatic Summarization</title>
		<meeting>the 2000 NAACL-ANLPWorkshop on Automatic Summarization</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="40" to="48" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Unveiling the political agenda of the european parliament plenary: A topical analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><surname>Greene</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James P</forename><surname>Cross</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.07302</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">How many topics? stability analysis for topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><surname>Greene</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><surname>O&amp;apos;callaghan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pádraig</forename><surname>Cunningham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning and Knowledge Discovery in Databases</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="498" to="513" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">A survey of text summarization extractive techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vishal</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gurpreet</forename><surname>Singh Lehal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Comparing twitter summarization algorithms for multiple post summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Inouye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kalita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Privacy, Security, Risk and Trust (PASSAT) and 2011 IEEE Third Inernational Conference on Social Computing (SocialCom)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="298" to="306" />
		</imprint>
	</monogr>
	<note>IEEE Third International Conference on</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Summarizing user-contributed comments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elham</forename><surname>Khabiri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Caverlee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiao-Fang</forename><surname>Hsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICWSM</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Latent dirichlet allocation: stability and applications to studies of usergenerated content</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergei</forename><surname>Koltcov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olessia</forename><surname>Koltsova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Nikolenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 ACM conference on Web science</title>
		<meeting>the 2014 ACM conference on Web science</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="161" to="165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Re-using an argument corpus to aid in the curation of social media collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clare</forename><surname>Llewellyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Oberlander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ewan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="462" to="468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Guardian Comments data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clare</forename><surname>Llewellyn</surname></persName>
		</author>
		<ptr target="http://homepages.inf.ed.ac.uk/s1053147/data/comments_2016.html" />
		<imprint>
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
	<note>Online; accessed 09</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Topic-driven reader comments summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongyang</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aixin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Cong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st ACM international conference on Information and knowledge management</title>
		<meeting>the 21st ACM international conference on Information and knowledge management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="265" to="274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">MALLET: a machine learning for language toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Mccallum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Summarizing blog entries versus news texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shamima</forename><surname>Mithun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leila</forename><surname>Kosseim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Events in Emerging Text Types</title>
		<meeting>the Workshop on Events in Emerging Text Types</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Tweetmotif: Exploratory search and topic summarization for twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O&amp;apos;</forename><surname>Brendan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Krieger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICWSM</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Summarizing email threads</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Owen</forename><surname>Rambow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lokesh</forename><surname>Shrestha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chirsty</forename><surname>Lauridsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of HLT-NAACL 2004: Short Papers</title>
		<meeting>HLT-NAACL 2004: Short Papers</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="105" to="108" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Anatole Gershman, and Robert Frederking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><forename type="middle">Dela</forename><surname>Rosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rushin</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGIR: SWSM</title>
		<meeting>the ACM SIGIR: SWSM</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note>Topical clustering of tweets</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Summarizing microblogs automatically</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beaux</forename><surname>Sharifi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark-Anthony</forename><surname>Hutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jugal</forename><surname>Kalita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="685" to="688" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">A systematic analysis of performance measures for classification tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marina</forename><surname>Sokolova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guy</forename><surname>Lapalme</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="427" to="437" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
