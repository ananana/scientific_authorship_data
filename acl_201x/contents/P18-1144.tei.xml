<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:16+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Chinese NER Using Lattice LSTM</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 15-20, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
							<email>yue zhang@sutd.edu.sg jie yang@mymail.sutd.edu.sg</email>
							<affiliation key="aff0">
								<orgName type="institution">Singapore University of Technology and Design</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Singapore University of Technology and Design</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Chinese NER Using Lattice LSTM</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1554" to="1564"/>
							<date type="published">July 15-20, 2018. 2018</date>
						</imprint>
					</monogr>
					<note>1554</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We investigate a lattice-structured LSTM model for Chinese NER, which encodes a sequence of input characters as well as all potential words that match a lexicon. Compared with character-based methods, our model explicitly leverages word and word sequence information. Compared with word-based methods, lattice LSTM does not suffer from segmentation errors. Gated recurrent cells allow our model to choose the most relevant characters and words from a sentence for better NER results. Experiments on various datasets show that lattice LSTM outperforms both word-based and character-based LSTM baselines, achieving the best results.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>As a fundamental task in information extraction, named entity recognition (NER) has received con- stant research attention over the recent years. The task has traditionally been solved as a sequence labeling problem, where entity boundary and cate- gory labels are jointly predicted. The current state- of-the-art for English NER has been achieved by using LSTM-CRF models ( <ref type="bibr" target="#b13">Lample et al., 2016;</ref><ref type="bibr" target="#b23">Ma and Hovy, 2016;</ref><ref type="bibr">Chiu and Nichols, 2016;</ref><ref type="bibr" target="#b17">Liu et al., 2018</ref>) with character information being in- tegrated into word representations.</p><p>Chinese NER is correlated with word segmen- tation. In particular, named entity boundaries are also word boundaries. One intuitive way of per- forming Chinese NER is to perform word segmen- tation first, before applying word sequence label- ing. The segmentation → NER pipeline, how- ever, can suffer the potential issue of error propa- gation, since NEs are an important source of OOV different paths to each character. Trained over NER data, the lattice LSTM can learn to find more useful words from context automatically for bet- ter NER performance. Compared with character- based and word-based NER methods, our model has the advantage of leveraging explicit word in- formation over character sequence labeling with- out suffering from segmentation error.</p><p>Results show that our model significantly out- performs both character sequence labeling models and word sequence labeling models using LSTM- CRF, giving the best results over a variety of Chinese NER datasets across different domains. Our code and data are released at https:// github.com/jiesutd/LatticeLSTM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Our work is in line with existing methods us- ing neural network for NER. <ref type="bibr" target="#b6">Hammerton (2003)</ref> attempted to solve the problem using a uni- directional LSTM, which was among the first neu- ral models for NER. <ref type="bibr" target="#b2">Collobert et al. (2011)</ref> used a CNN-CRF structure, obtaining competitive re- sults to the best statistical models. dos <ref type="bibr" target="#b4">Santos et al. (2015)</ref> used character CNN to augment a CNN-CRF model. Most recent work leverages an LSTM-CRF architecture.  uses hand-crafted spelling features; <ref type="bibr" target="#b23">Ma and Hovy (2016)</ref> and <ref type="bibr">Chiu and Nichols (2016)</ref> use a char- acter CNN to represent spelling characteristics; <ref type="bibr" target="#b13">Lample et al. (2016)</ref> use a character LSTM in- stead. Our baseline word-based system takes a similar structure to this line of work.</p><p>Character sequence labeling has been the dom- inant approach for Chinese NER <ref type="bibr">(Chen et al., 2006b</ref>; <ref type="bibr" target="#b21">Lu et al., 2016;</ref>. There have been explicit discussions comparing statisti- cal word-based and character-based methods for the task, showing that the latter is empirically a superior choice <ref type="bibr" target="#b9">(He and Wang, 2008;</ref><ref type="bibr" target="#b20">Liu et al., 2010;</ref><ref type="bibr" target="#b16">Li et al., 2014</ref>). We find that with proper representation settings, the same conclusion holds for neural NER. On the other hand, lattice LSTM is a better choice compared with both word LSTM and character LSTM.</p><p>How to better leverage word information for Chinese NER has received continued research at- tention ( <ref type="bibr" target="#b5">Gao et al., 2005</ref>), where segmentation in- formation has been used as soft features for NER ( <ref type="bibr" target="#b49">Zhao and Kit, 2008;</ref><ref type="bibr" target="#b26">Peng and Dredze, 2015;</ref><ref type="bibr" target="#b7">He and Sun, 2017a)</ref>, and joint segmentation and NER has been investigated using dual decomposition ( <ref type="bibr" target="#b42">Xu et al., 2014)</ref>, multi-task learning <ref type="bibr" target="#b27">(Peng and Dredze, 2016)</ref>, etc. Our work is in line, focusing on neural representation learning. While the above methods can be affected by segmented training data and segmentation errors, our method does not require a word segmentor. The model is conceptu- ally simpler by not considering multi-task settings.</p><p>External sources of information has been lever- aged for NER. In particular, lexicon features have been widely used <ref type="bibr" target="#b2">(Collobert et al., 2011;</ref><ref type="bibr" target="#b25">Passos et al., 2014;</ref><ref type="bibr" target="#b22">Luo et al., 2015)</ref>. Rei (2017) uses a word-level language modeling objective to augment NER training, performing multi-task learning over large raw text. <ref type="bibr" target="#b30">Peters et al. (2017)</ref> pretrain a character language model to enhance word representations. <ref type="bibr" target="#b47">Yang et al. (2017b)</ref> exploit cross-domain and cross-lingual knowledge via multi-task learning. We leverage external data by pretraining word embedding lexicon over large automatically-segmented texts, while semi- supervised techniques such as language modeling are orthogonal to and can also be used for our lat- tice LSTM model. Lattice structured RNNs can be viewed as a nat- ural extension of tree-structured RNNs ( <ref type="bibr" target="#b38">Tai et al., 2015)</ref> to DAGs. They have been used to model motion dynamics , dependency- discourse DAGs ( , as well as speech tokenization lattice ( <ref type="bibr" target="#b34">Sperber et al., 2017)</ref> and multi-granularity segmentation outputs ( <ref type="bibr" target="#b36">Su et al., 2017</ref>) for NMT encoders. Compared with existing work, our lattice LSTM is different in both motivation and structure. For example, be- ing designed for character-centric lattice-LSTM- CRF sequence labeling, it has recurrent cells but not hidden vectors for words. To our knowledge, we are the first to design a novel lattice LSTM representation for mixed characters and lexicon words, and the first to use a word-character lattice for segmentation-free Chinese NER.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model</head><p>We follow the best English NER model <ref type="bibr" target="#b23">Ma and Hovy, 2016;</ref><ref type="bibr" target="#b13">Lample et al., 2016)</ref>, using LSTM-CRF as the main network structure. Formally, denote an input sentence as s = c 1 , c 2 , . . . , c m , where c j denotes the jth char- acter. s can further be seen as a word sequence s = w 1 , w 2 , . . . , w n , where w i denotes the ith word in the sentence, obtained using a Chinese segmentor. We use t(i, k) to denote the index j for the kth character in the ith word in the sen- tence. Take the sentence in <ref type="figure">Figure 1</ref> for exam- ple. If the segmentation is " ", and indices are from 1, then t(2, 1) = 4 () and t(1, 3) = 3 (). We use the BIOES tagging scheme <ref type="bibr" target="#b32">(Ratinov and Roth, 2009</ref>) for both word- based and character-based NER tagging.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Character-Based Model</head><p>The character-based model is shown in <ref type="figure" target="#fig_2">Figure  3</ref>(a). It uses an LSTM-CRF model on the char- acter sequence c 1 , c 2 , . . . , c m . Each character c j is represented using</p><formula xml:id="formula_0">x c j = e c (c j )<label>(1)</label></formula><p>e c denotes a character embedding lookup table.</p><p>A bidirectional LSTM (same structurally as Eq. 11) is applied to</p><formula xml:id="formula_1">x 1 , x 2 , . . . , x m to obtain − → h c 1 , − → h c 2 , . . . , − → h c m and ← − h c 1 , ← − h c 2 , . . . ,</formula><p>← − h c m in the left-to-right and right-to-left directions, respec- tively, with two distinct sets of parameters. The hidden vector representation of each character is:</p><formula xml:id="formula_2">h c j = [ − → h c j ; ← − h c j ]<label>(2)</label></formula><p>A standard CRF model (Eq. 17) is used on h c 1 , h c 2 , . . . , h c m for sequence labelling.</p><p>• Char + bichar. Character bigrams have been shown useful for representing characters in word segmentation ( <ref type="bibr">Chen et al., 2015;</ref><ref type="bibr" target="#b46">Yang et al., 2017a</ref>). We augment the character-based model with bigram information by concatenating bigram embeddings with character embeddings:</p><formula xml:id="formula_3">x c j = [e c (c j ); e b (c j , c j+1 )],<label>(3)</label></formula><p>where e b denotes a charater bigram lookup table.</p><p>• Char + softword. It has been shown that using segmentation as soft features for character-based NER models can lead to improved performance ( <ref type="bibr" target="#b49">Zhao and Kit, 2008;</ref><ref type="bibr" target="#b27">Peng and Dredze, 2016)</ref>.  We augment the character representation with seg- mentation information by concatenating segmen- tation label embeddings to character embeddings:</p><formula xml:id="formula_4">京 Capital I-­-LOC í µí² " # í µí² " # í µí² " # E-­-LOC í µí² &amp; # í µí² &amp; # í µí² &amp; # B-­-LOC í µí² ' # í µí² ' # í µí² ' # 市 City 长 Long B-­-LOC í µí² ( # í µí² ( # í µí² ( # 南 South (a) Character-based model. B-­-LOC í µí² " # í µí² " # í µí² " # E-­-LOC í µí² &amp; # í µí² &amp; # í µí² &amp; # 市 City 南京 Nanjing B-­-LOC í µí² ' # í µí² ' # í µí² ' # 长江 Yangtze River E-­-LOC í µí² ( # í µí² ( # í µí² ( # 大桥 Bridge (b) Word-based model.</formula><formula xml:id="formula_5">x c j = [e c (c j ); e s (seg(c j ))],<label>(4)</label></formula><p>where e s represents a segmentation label em- bedding lookup table. seg(c j ) denotes the segmen- tation label on the character c j given by a word segmentor. We use the BMES scheme for repre-senting segmentation <ref type="bibr" target="#b44">(Xue, 2003)</ref>.</p><formula xml:id="formula_6">h w i = [ − → h w i ; ← − h w i ]<label>(5)</label></formula><p>Similar to the character-based case, a standard CRF model (Eq. 17) is used on h w 1 , h w 2 , . . . , h w m for sequence labelling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Word-Based Model</head><p>The word-based model is shown in <ref type="figure" target="#fig_2">Figure 3</ref>(b). It takes the word embedding e w (w i ) for representa- tion each word w i :</p><formula xml:id="formula_7">x w i = e w (w i ),<label>(6)</label></formula><p>where e w denotes a word embedding lookup table. A bi-directioanl LSTM (Eq. 11) is used to obtain a left-to-right sequence of hid- den states </p><formula xml:id="formula_8">− → h w 1 , − → h w 2 , . . . , − → h w n and a right-to-left se- quence of hidden states ← − h w 1 , ← − h w 2 , . . . ,</formula><formula xml:id="formula_9">x w i = [e w (w i ); x c i ]<label>(7)</label></formula><p>• Word + char LSTM. Denoting the em- bedding of each input character as e c (c j ), we use a bi-directional LSTM (Eq. 11) to learn hidden states</p><formula xml:id="formula_10">− → h c t(i,1) , . . . , − → h c t(i,len(i)) and ← − h c t(i,1) , . . . , ← − h c t(i,len(i))</formula><p>for the characters c t(i,1) , . . . , c t(i,len(i)) of w i , where len(i) denotes the number of characters in w i . The final charac- ter representation for w i is:</p><formula xml:id="formula_11">x c i = [ − → h c t(i,len(i)) ; ← − h c t(i,1) ]<label>(8)</label></formula><p>• Word + char LSTM . We investigate a varia- tion of word + char LSTM model that uses a single LSTM to obtain − → h c j and</p><formula xml:id="formula_12">← − h c j for each c j .</formula><p>It is sim- ilar with the structure of <ref type="bibr" target="#b17">Liu et al. (2018)</ref> but not uses the highway layer. The same LSTM structure as defined in Eq. 11 is used, and the same method as Eq. 8 is used to integrate character hidden states into word representations.</p><p>• Word + char CNN. A standard <ref type="bibr">CNN (LeCun et al., 1989)</ref> structure is used on the character se- quence of each word to obtain its character repre- sentation x c i . Denoting the embedding of character c j as e c (c j ), the vector x c i is given by:</p><formula xml:id="formula_13">x c i = max t(i,1)≤j≤t(i,len(i)) (W CNN    e c (c j− ke−1 2 ) . . . e c (c j+ ke−1 2 )    + b CNN ),<label>(9)</label></formula><p>where W CNN and b CNN are parameters, ke = 3 is the kernal size and max denotes max pooling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Lattice Model</head><p>The overall structure of the word-character lattice model is shown in <ref type="figure" target="#fig_0">Figure 2</ref>, which can be viewed as an extension of the character-based model, in- tegrating word-based cells and additional gates for controlling information flow.</p><p>Shown in <ref type="figure" target="#fig_2">Figure 3</ref>(c), the input to the model is a character sequence c 1 , c 2 , . . . , c m , together with all character subsequences that match words in a lexicon D. As indicated in Section 2, we use au- tomatically segmented large raw text for buinding D. Using w d b,e to denote such a subsequence that begins with character index b and ends with char- acter index e, the segment w d 1,2 in <ref type="figure">Figure 1</ref> is " (Nanjing)" and w d 7,8 is " (Bridge)". Four types of vectors are involved in the model, namely input vectors, output hidden vectors, cell vectors and gate vectors. As basic components, a character input vector is used to represent each chacracter c j as in the character-based model:</p><formula xml:id="formula_14">x c j = e c (c j )<label>(10)</label></formula><p>The basic recurrent structure of the model is constructed using a character cell vector c c j and a hidden vector h c j on each c j , where c c j serves to record recurrent information flow from the begin- ning of the sentence to c j and h c j is used for CRF sequence labelling using Eq. 17.</p><p>The basic recurrent LSTM functions are:</p><formula xml:id="formula_15">    i c j o c j f c j c c j     =     σ σ σ tanh     W c x c j h c j−1 + b c c c j = f c j c c j−1 + i c j c c j h c j = o c j tanh(c c j )<label>(11)</label></formula><p>where i c j , f c j and o c j denote a set of input, forget and output gates, respectively. W c and b c are model parameters. σ() represents the sigmoid function. Different from the character-based model, how- ever, the computation of c c j now considers lexicon subsequences w d b,e in the sentence. In particular, each subsequence w d b,e is represented using</p><formula xml:id="formula_16">x w b,e = e w (w d b,e ),<label>(12)</label></formula><p>where e w denotes the same word embedding lookup table as in Section 3.2.</p><p>In addition, a word cell c w b,e is used to represent the recurrent state of x w b,e from the beginning of the sentence. The value of c w b,e is calculated by:</p><formula xml:id="formula_17">  i w b,e f w b,e c w b,e   =   σ σ tanh   W w x w b,e h c b + b w c w b,e = f w b,e c c b + i w b,e c w b,e<label>(13)</label></formula><p>where i w b,e and f w b,e are a set of input and forget gates. There is no output gate for word cells since labeling is performed only at the character level.</p><p>With </p><formula xml:id="formula_18">i c b,e = σ W l x c e c w b,e + b l<label>(14)</label></formula><p>The calculation of cell values c c j thus becomes</p><formula xml:id="formula_19">c c j = b∈{b |w d b ,j ∈D} α c b,j c w b,j + α c j c c j<label>(15)</label></formula><p>In Eq. 15, the gate values i c b,j and i c j are nor- malised to α c b,j and α c j by setting the sum to 1.</p><formula xml:id="formula_20">α c b,j = exp(i c b,j ) exp(i c j ) + b ∈{b |w d b ,j ∈D} exp(i c b ,j ) α c j = exp(i c j ) exp(i c j ) + b ∈{b |w d b ,j ∈D} exp(i c b ,j )<label>(16)</label></formula><p>The final hidden vectors h c j are still computed as described by Eq. 11. During NER train- ing, loss values back-propagate to the parameters <ref type="bibr">2</ref> We experimented with alternative configurations on in- dexing word and character path links, finding that this con- figuration gives the best results in preliminary experiments. Single-character words are excluded; the final performance drops slightly after integrating single-character words. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Decoding and Training</head><p>A standard CRF layer is used on top of h 1 , h 2 , . . . , h τ , where τ is n for character-based and lattice-based models and m for word-based models. The probability of a label sequence y = l 1 , l 2 , . . . , l τ is</p><formula xml:id="formula_21">P (y|s) = exp( i (W l i CRF h i + b (l i−1 ,l i ) CRF )) y exp( i (W l i CRF h i + b (l i−1 ,l i ) CRF ))<label>(17)</label></formula><p>Here y represents an arbitary label sequence, and</p><formula xml:id="formula_22">W l i</formula><p>CRF is a model parameter specific to l i , and b</p><formula xml:id="formula_23">(l i−1 ,l i ) CRF</formula><p>is a bias specific to l i−1 and l i . We use the first-order Viterbi algorithm to find the highest scored label sequence over a word-based or character-based input sequence. Given a set of manually labeled training data {(s i , y i )}| N i=1 , sentence-level log-likelihood loss with L 2 regularization is used to train the model:</p><formula xml:id="formula_24">L = N i=1 log(P (y i |s i )) + λ 2 ||Θ|| 2 ,<label>(18)</label></formula><p>where λ is the L 2 regularization parameter and Θ represents the parameter set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We carry out an extensive set of experiments to investigate the effectiveness of word-character lat- tice LSTMs across different domains. In addition, we aim to empirically compare word-based and character-based neural Chinese NER under differ- ent settings. Standard precision (P), recall (R) and F1-score (F1) are used as evaluation metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Settings</head><p>Data  <ref type="table" target="#tab_2">Country  260  33  28  Educational Institution 858  106  112  Location  47  2  6  Personal Name  952  110  112  Organization  4611  523  553  Profession  287  18  33  Ethnicity Background 115  15  14  Job Title  6308  690  772  Total Entity  13438 1497 1630</ref>   <ref type="bibr">4</ref> , which consists of resumes of senior executives from listed compa- nies in the Chinese stock market. We randomly se- lected 1027 resume summaries and manually an- notated 8 types of named entities. Statistics of the dataset is shown in <ref type="table" target="#tab_2">Table 2</ref>. The inter-annotator agreement is 97.1%. We release this dataset as a resource for further research.</p><p>Segmentation. For the OntoNotes and MSRA datasets, gold-standard segmentation is available in the training sections. For OntoNotes, gold seg- mentation is also available for the development and test sections. On the other hand, no seg- mentation is available for the MSRA test sections, nor the Weibo / resume datasets. As a result, OntoNotes is leveraged for studying oracle situ- ations where gold segmentation is given. We use the neural word segmentor of <ref type="bibr" target="#b46">Yang et al. (2017a)</ref> to automatically segment the development and test sets for word-based NER. In particular, for the OntoNotes and MSRA datasets, we train the seg- mentor using gold segmentation on their respec- tive training sets. For Weibo and resume, we take the best model of <ref type="bibr" target="#b46">Yang et al. (2017a)</ref> off the shelf 5 , which is trained using CTB 6.0 ( <ref type="bibr" target="#b43">Xue et al., 2005</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parameter</head><p>Value Parameter Value char emb size 50 bigram emb size 50 lattice emb size 50 LSTM hidden 200 char dropout 0.5 lattice dropout 0.5 LSTM layer 1 regularization λ 1e-8 learning rate lr 0.015 lr decay 0.05 <ref type="table">Table 3</ref>: Hyper-parameter values.</p><p>Word Embeddings. We pretrain word embed- dings using word2vec <ref type="bibr" target="#b24">(Mikolov et al., 2013</ref>) over automatically segmented Chinese Giga-Word 6 , obtaining 704.4k words in a final lexicon. In particular, the number of single-character, two- character and three-character words are 5.7k, 291.5k, 278.1k, respectively. The embedding lex- icon is released alongside our code and models as a resource for further research. Word embeddings are fine-tuned during NER training. Character and character bigram embeddings are pretrained on Chinese Giga-Word using word2vec and fine- tuned at model training.</p><p>Hyper-parameter settings. <ref type="table">Table 3</ref> shows the values of hyper-parameters for our models, which as fixed according to previous work in the litera- ture without grid-search adjustments for each indi- vidual dataset. In particular, the embedding sizes are set to 50 and the hidden size of LSTM models to 200. Dropout ( <ref type="bibr" target="#b35">Srivastava et al., 2014</ref>) is ap- plied to both word and character embeddings with a rate of 0.5. Stochastic gradient descent (SGD) is used for optimization, with an initial learning rate of 0.015 and a decay rate of 0.05.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Development Experiments</head><p>We compare various model configurations on the OntoNotes development set, in order to select the best settings for word-based and character-based NER models, and to learn the influence of lattice word information on character-based models.</p><p>Character-based NER. As shown in <ref type="table" target="#tab_4">Table 4</ref>, without using word segmentation, a character- based LSTM-CRF model gives a development F1- score of 62.47%. Adding character-bigram and softword representations as described in Section 3.1 increases the F1-score to 67.63% and 65.71%, respectively, demonstrating the usefulness of both sources of information. In addition, a combination of both gives a 69.64% F1-score, which is the best 6 https://catalog.ldc.upenn.edu/ LDC2011T13  Word-based NER. <ref type="table" target="#tab_4">Table 4</ref> shows a vari- ety of different settings for word-based Chinese NER. With automatic segmentation, a word-based LSTM CRF baseline gives a 64.12% F1-score, which is higher compared to the character-based baseline. This demonstrates that both word in- formation and character information are useful for Chinese NER. The two methods of using charac- ter LSTM to enrich word representations in Sec- tion 3.2, namely word+char LSTM and word+char LSTM , lead to similar improvements.</p><p>A CNN representation of character sequences gives a slightly higher F1-score compared to LSTM character representations. On the other hand, further using character bigram informa- tion leads to increased F1-score over word+char LSTM, but decreased F1-score over word+char CNN. A possible reason is that CNN inherently captures character n-gram information. As a re- sult, we use word+char+bichar LSTM for word- based NER in the remaining experiments, which gives the best development results, and is struc- turally consistent with the state-of-the-art English NER models in the literature.</p><p>Lattice-based NER. <ref type="figure" target="#fig_5">Figure 4</ref> shows the F1- score of character-based and lattice-based models against the number of training iterations. We in- clude models that use concatenated character and character bigram embeddings, where bigrams can play a role in disambiguating characters. As can be seen from the figure, lattice word information is useful for improving character-based NER, im- proving the best development result from 62.5% to 71.6%. On the other hand, the bigram-enhanced lattice model does not lead to further improve- ments compared with the original lattice model.   This is likely because words are better sources of information for character disambiguation com- pared with bigrams, which are also ambiguous. As shown in <ref type="table" target="#tab_4">Table 4</ref>, the lattice LSTM-CRF model gives a development F1-score of 71.62%, which is significantly 7 higher compared with both the word-based and character-based methods, de- spite that it does not use character bigrams or word segmentation information. The fact that it signif- icantly outperforms char+softword shows the ad- vantage of lattice word information as compared with segmentor word information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Final Results</head><p>OntoNotes. The OntoNotes test results are shown in <ref type="table" target="#tab_6">Table 5</ref> 8 . With gold-standard segmentation, our word-based methods give competitive results to the state-of-the-art on the dataset ( , which leverage bilingual data. This demonstrates that LSTM-CRF is a competi- tive choice for word-based Chinese NER, as it is for other languages. In addition, the results show   that our word-based models can serve as highly competitive baselines. With automatic segmenta- tion, the F1-score of word+char+bichar LSTM de- creases from 75.77% to 71.70%, showing the in- fluence of segmentation to NER. Consistent with observations on the development set, adding lat- tice word information leads to an 88.81% → 93.18% increasement of F1-score over the charac- ter baseline, as compared with 88.81% → 91.87% by adding bichar+softword. The lattice model gives significantly the best F1-score on automatic segmentation. MSRA. Results on the MSRA dataset are shown in <ref type="table" target="#tab_8">Table 6</ref>. For this benchmark, no gold- standard segmentation is available on the test set. Our chosen segmentor gives 95.93% accuracy on 5-fold cross-validated training set. The best sta- tistical models on the dataset leverage rich hand- Compared with the existing methods, our word- based and character-based LSTM-CRF models give competitive accuracies. The lattice model significantly outperforms both the best character- based and word-based models (p &lt; 0.01), achiev- ing the best result on this standard benchmark.</p><p>Weibo/resume. Results on the Weibo NER dataset are shown in <ref type="table" target="#tab_9">Table 7</ref>, where NE, NM and  Figure 5: F1 against sentence length.</p><p>Overall denote F1-scores for named entities, nom- inal entities (excluding named entities) and both, respectively. Gold-standard segmentation is not available for this dataset. Existing state-of-the- art systems include <ref type="bibr" target="#b27">Peng and Dredze (2016)</ref> and <ref type="bibr" target="#b8">He and Sun (2017b)</ref>, who explore rich embedding features, cross-domain and semi-supervised data, some of which are orthogonal to our model 9 .</p><p>Results on the resume NER test data are shown in <ref type="table" target="#tab_11">Table 8</ref>. Consistent with observations on OntoNotes and MSRA, the lattice model signifi- cantly outperforms both the word-based mode and the character-based model for Weibo and resume (p &lt; 0.01), giving state-of-the-art results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Discussion</head><p>F1 against sentence length. <ref type="figure">Figure 5</ref> shows the F1-scores of the baseline models and lat- tice LSTM-CRF on the OntoNotes dataset. The character-based baseline gives relatively stable F1-scores over different sentence lengths, al- though the performances are relatively low. The word-based baseline gives substantially higher F1-scores over short sentences, but lower F1- scores over long sentences, which can be be- cause of lower segmentation accuracies over longer sentences. Both word+char+bichar and char+bichar+softword give better performances compared to their respective baselines, showing that word and character representations are com- plementary for NER. The accuracy of lattice also decreases as the sentence length increases, which can result from exponentially increasing number of word combinations in lattice. Compared with word+char+bichar and char+bichar+softword, the lattice model shows more robustness to increased sentence lengths, demonstrating the more effective use of word information. F1 against sentence length. <ref type="table" target="#tab_12">Table 9</ref> shows a case study comparing char+bichar+softword, word+char+bichar and the lattice model. In the ex- ample, there is much ambiguity around the named entity " (Taiwan Association in Dong- guan)". Word+char+bichar yields the entities " (Dongguan)" and " (Taiwan)" given that " (Taiwan Association in Dongguan)" is not in the segmentor output. Char+bichar+softword recognizes " (Taiwan Association in Dongguan)", which is valid on its own, but leaves the phrase "" ungrammatical. In contrast, the lattice model detects the organiza- tion name correctly, thanks to the lattice words " (Dongguan)", " (President)" and " (role)". There are also irrelevant words such as " (Taiwan Association)" and " (noisy word)" in the lexicon, which did not affect NER results. Note that both word+char+bichar and lattice use the same source of word information, namely the same pretrained word embedding lexicon. How- ever, word+char+bichar first uses the lexicon in the segmentor, which imposes hard constrains (i.e. fixed words) to its subsequence use in NER. In contrast, lattice LSTM has the freedom of consid- ering all lexicon words. Entities in lexicon. <ref type="table" target="#tab_14">Table 10</ref> shows the total num- ber of entities and their respective match ratios in the lexicon. The error reductions (ER) of the final</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>Split #Entity #Match Ratio (%) ER (%) OntoNotes  lattice model over the best character-based method (i.e. "+bichar+softword") are also shown. It can be seen that error reductions have a correlation be- tween matched entities in the lexicon. In this re- spect, our automatic lexicon also played to some extent the role of a gazetteer <ref type="bibr" target="#b32">(Ratinov and Roth, 2009;</ref><ref type="bibr">Chiu and Nichols, 2016)</ref>, but not fully since there is no explicit knowledge in the lexicon which tokens are entities. The ultimate disambiguation power still lies in the lattice encoder and super- vised learning.</p><p>The quality of the lexicon may affect the ac- curacy of our NER model since noise words can potentially confuse NER. On the other hand, our lattice model can potentially learn to select more correct words during NER training. We leave the investigation of such influence to future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We empirically investigated a lattice LSTM-CRF representations for Chinese NER, finding that it gives consistently superior performance compared to word-based and character-based LSTM-CRF across different domains. The lattice method is fully independent of word segmentation, yet more effective in using word information thanks to the freedom of choosing lexicon words in a context for NER disambiguation.</p><p>Fifth SIGHAN Workshop on Chinese Language Pro- cessing. pages 173-176.</p><p>Wenliang Chen, Yujie Zhang, and Hitoshi Isahara.</p><p>2006b. Chinese named entity recognition with con- ditional random fields. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Lattice LSTM structure.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Models. 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Integrating character representations Both character CNN (Ma and Hovy, 2016) and LSTM (Lample et al., 2016) have been used for representing the character sequence within a word. We experiment with both for Chinese NER. De- noting the representation of characters within w i as x c i , a new word representation is obtained by concatenation of e w (w i ) and x c i :</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>c w b,e , there are more recurrent paths for in- formation flow into each c c j . For example, in Fig- ure 2, input sources for c c 7 include x c 7 ( Bridge), c w 6,7 ( Bridge) and c w 4,7 ( Yangtze River Bridge). 2 We link all c w b,e with b ∈ {b |w d b ,e ∈ D} to the cell c c e . We use an addi- tional gate i c b,e for each subsequence cell c w b,e for controlling its contribution into c c b,e :</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: F1 against training iteration number.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>crafted features (Chen et al., 2006a; Zhang et al., 2006; Zhou et al., 2013) and character embedding features (Lu et al., 2016). Dong et al. (2016) ex- ploit neural LSTM-CRF with radical features.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Detailed statistics of resume NER. 

Dredze, 2015; He and Sun, 2017a) and a Chi-
nese resume dataset that we annotate. Statistics 
of the datasets are shown in Table 1. We take the 
same data split as Che et al. (2013) on OntoNotes. 
The development set of OntoNotes is used for 
reporting development experiments. While the 
OntoNotes and MSRA datasets are in the news do-
main, the Weibo NER dataset is drawn from the 
social media website Sina Weibo. 3 
For more variety in test domains, we collected a 
resume dataset from Sina Finance </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Development results. 

among various character representations. We thus 
choose this model in the remaining experiments. 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Main results on OntoNotes. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Main results on MSRA. 

Models 
NE 
NM 
Overall 
Peng and Dredze (2015) 
51.96 61.05 56.05 
Peng and Dredze (2016)* 55.28 62.97 58.99 
He and Sun (2017a) 
50.60 59.32 54.82 
He and Sun (2017b)* 
54.50 62.17 58.23 
Word baseline 
36.02 59.38 47.33 
+char+bichar LSTM 
43.40 60.30 52.33 
Char baseline 
46.11 55.29 52.77 
+bichar+softword 
50.55 60.11 56.75 
Lattice 
53.04 62.25 58.79 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head>Table 7 : Weibo NER results.</head><label>7</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11" validated="false"><head>Table 8 :</head><label>8</label><figDesc></figDesc><table>Main results on resume NER. 

20&lt; 
40 
60 
80 
100 &gt;100 

Sentence length 

0.65 

0.70 

0.75 

0.80 

0.85 

F1-value 

Word baseline 
Word+char+bichar LSTM 
Char baseline 
Char+bichar+softword 
Lattice 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12" validated="false"><head>Table 9 :</head><label>9</label><figDesc></figDesc><table>Example. Red and green represent incor-
rect and correct entities, respectively. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14" validated="false"><head>Table 10 :</head><label>10</label><figDesc></figDesc><table>Entities in lexicon. 

</table></figure>

			<note place="foot" n="1"> To keep the figure concise, we (i) do not show gate cells, which uses ht−1 for calculating ct; (ii) only show one direction.</note>

			<note place="foot" n="3"> https://www.weibo.com/ 4 http://finance.sina.com.cn/stock/ index.shtml 5 https://github.com/jiesutd/ RichWordSegmentor</note>

			<note place="foot" n="7"> We use a p-value of less than 0.01 from pairwise t-test to indicate statistical significance. 8 In Table 5, 6 and 7, we use * to denote a model with external labeled data for semi-supervised learning. † means that the model also uses discrete features.</note>

			<note place="foot" n="9"> The results of Peng and Dredze (2015, 2016) are taken from Peng and Dredze (2017).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the anonymous reviewers for their in-sightful comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Named entity recognition with bilingual constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengqiu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="52" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Chinese named entity recognition with conditional probabilistic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aitao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuchun</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gordon</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the</title>
		<meeting>the</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Characterbased LSTM-CRF with radical-level features for Chinese named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuanhai</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqing</forename><surname>Zong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masanori</forename><surname>Hattori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Di</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Processing of Oriental Languages</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="239" to="250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Boosting named entity recognition with neural character embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Cıcero Dos Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guimaraes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rio</forename><surname>Niterói</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janeiro</forename><surname>De</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NEWS 2015 The Fifth Named Entities Workshop</title>
		<meeting>NEWS 2015 The Fifth Named Entities Workshop</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page">25</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Chinese word segmentation and named entity recognition: A pragmatic approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang-Ning</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andi</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="531" to="574" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Named entity recognition with long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hammerton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL 2003</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="172" to="175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">F-score driven max margin neural network for named entity recognition in Chinese social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hangfeng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EACL</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="713" to="718" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A unified model for cross-domain and semi-supervised named entity recognition in Chinese social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hangfeng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3216" to="3222" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Chinese named entity recognition and word segmentation based on character</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingzhou</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houfeng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth SIGHAN Workshop on Chinese Language Processing</title>
		<meeting>the Sixth SIGHAN Workshop on Chinese Language Processing</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Addressing domain adaptation for chinese word segmentation with global recurrent structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houfeng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In IJCNLP</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="184" to="193" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1508.01991</idno>
		<title level="m">Bidirectional LSTM-CRF models for sequence tagging</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Discriminative learning with natural annotations: Word segmentation as a case study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenbin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yajuan</forename><surname>Lü</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yating</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="761" to="769" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Neural architectures for named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandeep</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuya</forename><surname>Kawakami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="260" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Backpropagation applied to handwritten zip code recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Boser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">S</forename><surname>Denker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donnie</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">E</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wayne</forename><surname>Hubbard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence D</forename><surname>Jackel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="541" to="551" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The third international Chinese language processing bakeoff: Word segmentation and named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gina-Anne</forename><surname>Levow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing</title>
		<meeting>the Fifth SIGHAN Workshop on Chinese Language Processing</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="108" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Comparison of the impact of word segmentation on name tagging for Chinese and japanese</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masato</forename><surname>Hagiwara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2532" to="2536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Empower sequence labeling with task-aware neural language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingbo</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation for joint segmentation and pos-tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2012: Posters pages</title>
		<meeting>COLING 2012: Posters pages</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="745" to="754" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Domain adaptation for crf-based Chinese word segmentation using free annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yijia</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="864" to="874" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Chinese named entity recognition with a sequence labeling approach: based on characters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangxun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Conghui</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiejun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanced intelligent computing theories and applications. With aspects of artificial intelligence</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="634" to="640" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Multiprototype Chinese character embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanan</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong-Hong</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Joint entity recognition and disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojiang</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="879" to="888" />
		</imprint>
	</monogr>
	<note>Chin-Yew Lin, and Zaiqing Nie</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">End-to-end sequence labeling via Bi-directional LSTM-CNNsCRF</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1064" to="1074" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Lexicon infused phrase embeddings for named entity resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vineet</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CoNLL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="78" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Named entity recognition for Chinese social media with jointly trained embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanyun</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="548" to="554" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Improving named entity recognition for Chinese social media with word segmentation representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanyun</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="149" to="155" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Supplementary results for named entity recognition on chinese social media with an updated dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanyun</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Cross-sentence n-ary relation extraction with graph lstms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanyun</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoifung</forename><surname>Poon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Quirk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TACL</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="101" to="115" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Semi-supervised sequence tagging with bidirectional language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Waleed</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chandra</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Russell</forename><surname>Power</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1756" to="1765" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Word segmentation for chinese novels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Likun</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2440" to="2446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Design challenges and misconceptions in named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CoNLL</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="147" to="155" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Semi-supervised multitask learning for sequence labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marek</forename><surname>Rei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2121" to="2130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Neural lattice-to-sequence models for uncertain inputs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Sperber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/D17-" />
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2017-01" />
			<biblScope unit="page" from="1380" to="1389" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Lattice-based recurrent neural network encoders for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinsong</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhixing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyi</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rongrong</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3302" to="3308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Lattice long short-term memory for human action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kui</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dit-Yan</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bertram</forename><forename type="middle">E</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Improved semantic representations from tree-structured long short-term memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai Sheng</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P15-1150" />
	</analytic>
	<monogr>
		<title level="m">ACL-IJCNLP</title>
		<meeting><address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1556" to="1566" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Effective bilingual constraints for semi-supervised learning of named entity recognizers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengqiu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Weischedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lance</forename><surname>Ramshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ann</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Craig</forename><surname>Greenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Belvin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note>Ontonotes release 4.0</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Linguistic Data Consortium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philadelphia</forename><surname>Ldc2011t03</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Penn</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Joint segmentation and named entity recognition using dual decomposition in Chinese discharge summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">I</forename><surname>Tsujii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAMIA</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">e1</biblScope>
			<biblScope unit="page" from="84" to="92" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">The penn Chinese treebank: Phrase structure annotation of a large corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naiwen</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fu-Dong</forename><surname>Chiou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural language engineering</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">02</biblScope>
			<biblScope unit="page" from="207" to="238" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Chinese word segmentation as character tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Journal of Computational Linguistics and Chinese Language Processing</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Combining discrete and neural features for sequence labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyang</forename><surname>Teng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meishan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computational Linguistics and Intelligent Text Processing</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Neural word segmentation with rich pretraining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Dong</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/P17-1078" />
	</analytic>
	<monogr>
		<title level="m">ACL. Vancouver, Canada</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="839" to="849" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Transfer learning for sequence tagging with hierarchical recurrent networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William W</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Word segmentation and named entity recognition for sighan bakeoff3</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suxiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojie</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing</title>
		<meeting>the Fifth SIGHAN Workshop on Chinese Language Processing</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="158" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Unsupervised segmentation helps supervised learning of character tagging for word segmentation and named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyu</forename><surname>Kit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth SIGHAN Workshop on Chinese Language Processing</title>
		<meeting>the Sixth SIGHAN Workshop on Chinese Language Processing</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Chinese named entity recognition via joint identification and categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsheng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiguang</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fen</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chinese Journal of Electronics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="225" to="230" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
