<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:31+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Dynamic and Static Topic Model for Analyzing Time-Series Document Collections</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 15-20, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rem</forename><surname>Hida</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Aeronautics and Astronautics</orgName>
								<orgName type="department" key="dep2">RIKEN Center for Advanced Intelligence Project</orgName>
								<orgName type="institution">The University of Tokyo</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naoya</forename><surname>Takeishi</surname></persName>
							<email>naoya.takeishi@riken.jp</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Aeronautics and Astronautics</orgName>
								<orgName type="department" key="dep2">RIKEN Center for Advanced Intelligence Project</orgName>
								<orgName type="institution">The University of Tokyo</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takehisa</forename><surname>Yairi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Aeronautics and Astronautics</orgName>
								<orgName type="department" key="dep2">RIKEN Center for Advanced Intelligence Project</orgName>
								<orgName type="institution">The University of Tokyo</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koichi</forename><surname>Hori</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Aeronautics and Astronautics</orgName>
								<orgName type="department" key="dep2">RIKEN Center for Advanced Intelligence Project</orgName>
								<orgName type="institution">The University of Tokyo</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Dynamic and Static Topic Model for Analyzing Time-Series Document Collections</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="516" to="520"/>
							<date type="published">July 15-20, 2018</date>
						</imprint>
					</monogr>
					<note>516</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>For extracting meaningful topics from texts, their structures should be considered properly. In this paper, we aim to analyze structured time-series documents such as a collection of news articles and a series of scientific papers, wherein topics evolve along time depending on multiple topics in the past, and are also related to each other at each time. To this end, we propose a dynamic and static topic model, which simultaneously considers the dynamic structures of the temporal topic evolution and the static structures of the topic hierarchy at each time. We show the results of experiments on collections of scientific papers , in which the proposed method out-performed conventional models. Moreover , we show an example of extracted topic structures, which we found helpful for analyzing research activities.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Probabilistic topic models such as latent Dirichlet allocation (LDA) ( <ref type="bibr" target="#b3">Blei et al., 2003</ref>) have been uti- lized for analyzing a wide variety of datasets such as document collections, images, and genes. Al- though vanilla LDA has been favored partly due to its simplicity, one of its limitations is that the out- put is not necessarily very understandable because the priors on the topics are independent. Conse- quently, there has been a lot of research aimed at improving probabilistic topic models by utilizing the inherent structures of datasets in their model- ing (see, e.g., ; <ref type="bibr" target="#b8">Li and McCallum (2006)</ref>; see Section 2 for other models).</p><p>In this work, we aimed to leverage the dynamic and static structures of topics for improving the modeling capability and the understandability of topic models. These two types of structures, which we instantiate below, are essential in many types of datasets, and in fact, each of them has been con- sidered separately in several previous studies. In this paper, we propose a topic model that is aware of both of these structures, namely dynamic and static topic model (DSTM).</p><p>The underlying motivation of DSTM is twofold. First, a collection of documents often has dynamic structures; i.e., topics evolve along time influenc- ing each other. For example, topics in papers are related to topics in past papers. We may want to extract such dynamic structures of topics from collections of scientific papers for summarizing research activities. Second, there are also static structures of topics such as correlation and hierar- chy. For instance, in a collection of news articles, the "sports" topic must have the "baseball" topic and the "football" topic as its subtopic. This kind of static structure of topics helps us understand the relationship among them.</p><p>The remainder of this paper is organized as fol- lows. In Section 2, we briefly review related work. In Section 3, the generative model and the infer- ence/learning procedures of DSTM are presented. In Section 4, the results of the experiments are shown. This paper is concluded in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Researchers have proposed several variants of topic models that consider the dynamic or static structure. Approaches focusing on the dynamic structure include dynamic topic model (DTM) ( ), topic over time (TOT) ( <ref type="bibr" target="#b14">Wang and McCallum, 2006)</ref>, multiscale dynamic topic model (MDTM) ( <ref type="bibr" target="#b6">Iwata et al., 2010</ref>), de- pendent Dirichlet processes mixture model (D- DPMM) ( <ref type="bibr" target="#b10">Lin et al., 2010)</ref>, and infinite dynamic topic model (iDTM) <ref type="bibr" target="#b0">(Ahmed and Xing, 2010)</ref>.  These methods have been successfully applied to a temporal collection of documents, but none of them take temporal dependencies between multi- ple topics into account; i.e., in these models, only a single topic contributes to a topic in the future.</p><p>For the static structure, several models includ- ing correlated topic model (CTM) ( ), pachinko allocation model (PAM) ( <ref type="bibr" target="#b8">Li and McCallum, 2006)</ref>, and segmented topic model (STM) ( <ref type="bibr" target="#b4">Du et al., 2010</ref>) have been proposed. CTM models the correlation between topics using the normal distribution as the prior, PAM introduces the hierarchical structure to topics, and STM uses paragraphs or sentences as the hierarchical struc- ture. These models can consider the static struc- ture such as correlation and hierarchy between topics. However, most of them lack the dynamic structure in their model; i.e., they do not premise temporal collections of documents.</p><p>One of the existing methods that is most re- lated to the proposed model is the hierarchical topic evolution model (HTEM) ( <ref type="bibr" target="#b13">Song et al., 2016)</ref>. HTEM captures the relation between evolving topics using a nested distance-dependent Chinese restaurant process. It has been successfully ap- plied to a temporal collection of documents for ex- tracting structure but does not take multiple topics dependencies into account either.</p><p>In this work, we built a new model to overcome the limitation of the existing models, i.e., to ex- amine both the dynamic and static structures si- multaneously. We expect that the proposed model can be applied to various applications such as topic trend analysis and text summarization. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Dynamic and Static Topic Model</head><p>In this section, we state the generative model of the proposed method, DSTM. Afterward, the pro- cedure for inference and learning is presented. Our notations are summarized in <ref type="table">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Generative Model</head><p>In the proposed model, DSTM, the dynamic and static structures are modeled as follows.</p><p>Dynamic Structure We model the temporal evolution of topic-word distribution by making it proportional to a weighted sum of topic-word dis- tributions at the previous time (epoch), i.e.,</p><formula xml:id="formula_0">t k ⇠ Dirichlet K X k 0 =1 t k,k 0 t1 k 0 ! ,<label>(1)</label></formula><p>where t k denotes the word distribution of the k-th topic at the t-th time-epoch, and t k,k 0 is a weight that determines the dependency between the k-th topic at epoch t and the k 0 -th topic at epoch t 1.</p><p>Static Structure We model the static structure as a hierarchy of topics at each epoch. We uti- lize the supertopic-subtopic structure as in PAM ( <ref type="bibr" target="#b8">Li and McCallum, 2006</ref>), where the priors of top- ics (subtopics) are determined by their supertopic.</p><p>Generative Process In summary, the generative process at epoch t is as follows. 1. For each subtopic k = 1, .., K , (a) Draw a topic-word distribution</p><formula xml:id="formula_1">t k ⇠ Dirichlet( P k 0 t k,k 0 t1 k 0 ). 2. For each document d = 1, ..., D t , (a) Draw a supertopic distribution 1 ✓ t d ⇠ Dirichlet( 1 ↵ t ). (b) For each supertopic s = 1, ..., S, i. Draw a subtopic distribution 2 ✓ t d,s ⇠ Dirichlet( 2 ↵ t s ). (c) For each word i = 1, ..., n t d , i. Draw a supertopic-word assignment y t d,i ⇠ Multinomial( 1 ✓ t d ). ii. Draw a subtopic-word assignment z t d,i ⇠ Multinomial( 2 ✓ t d,y t d,i</formula><p>). iii. Draw a word-observation</p><formula xml:id="formula_2">w t d,i ⇠ Multinomial( t z t d,i</formula><p>).</p><p>Note that the above process should be repeated for every epoch t. The corresponding graphical model is presented in <ref type="figure" target="#fig_1">Figure 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Inference and Learning</head><p>Since analytical inference for DSTM is in- tractable, we resort to a stochastic EM algorithm ( <ref type="bibr" target="#b1">Andrieu et al., 2003</ref>) with the collapsed Gibbs sampling ( <ref type="bibr" target="#b5">Griffiths and Steyvers, 2004</ref>). How- ever, such a strategy is still much costly due to the temporal dependencies of . Therefore, we intro- duce a further approximation; we surrogate t1 k 0 in Eq. (1) by its expectationˆt1expectationˆ expectationˆt1</p><formula xml:id="formula_3">k 0 = E[ t1 k 0 ]</formula><p>. This compromise enables us to run the EM algorithm for each epoch in sequence from t = 1 to t = T without any backward inference. In fact, such ap- proximation technique is also utilized in the infer- ence of MDTM ( <ref type="bibr" target="#b6">Iwata et al., 2010)</ref>.</p><p>Note that the proposed model has a moderate number of hyperparameters to be set manually, and that they can be tuned according to the ex- isting know-how of topic modeling. This feature makes the proposed model appealing in terms of inference and learning. E-step In E-step, the supertopic/subtopic as- signments are sampled. Given the current state of all variables except y t d,i and z t d,i , new values for them should be sampled according to</p><formula xml:id="formula_4">p(y t d,i = s, z t d,i = k | w t , y t , z t , t1 , 1 ↵ t , 2 ↵ t , t ) / n t d,s\i + 1 ↵ t s n t d\i + P S s=1 1 ↵ t s · n t d,s,k\i + 2 ↵ t s,k n t d,s\i + P K k=1 2 ↵ t s,k · n t k,v\i + P K k 0 =1 t k,k 0 ˆ t1 k 0 ,v n t k\i + P K k 0 =1 t k,k 0 ,<label>(2)</label></formula><p>where n t k,v denotes the number of tokens assigned to topic k for word v at epoch t, n t k = P v n t k,v , and n t d,s and n t d,s,k denote the number of tokens in document d assigned to supertopic s and subtopic  <ref type="bibr">1987-1999 2009</ref> <ref type="table">-2016  # Documents  1,740  1,035  # Vocabulary  11,443  3,442  # Tokens  2,271,087  68,305   Table 2</ref>: Summary of the datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NIPS Drone</head><p>k (via s), at epoch t respectively. Moreover, n t ·\i denotes the count yielded excluding the i-th token.</p><p>M-step In M-step, 2 ↵ t and t are updated using the fixed-point iteration <ref type="bibr" target="#b11">(Minka, 2000)</ref>.</p><formula xml:id="formula_5">( 2 ↵ t s,k ) ⇤ = 2 ↵ t s,k P D t d=1 (n t d,s,k + 2 ↵ t s,k ) ( 2 ↵ t s,k ) P D t d=1 (n t d,s + 2 ↵ t s ) ( 2 ↵ t s ) ,<label>(3)</label></formula><formula xml:id="formula_6">( t k,k 0 ) ⇤ = t k,k 0 P v ˆ t1 k 0 ,v B t k 0 ,v (n t k + P k 0 t k,k 0 ) ( P k 0 t k,k 0 )</formula><p>. <ref type="formula">(4)</ref> Here, is the digamma function, 2 ↵ t s = P k 2 ↵ t s,k , and</p><formula xml:id="formula_7">B t k 0 ,v = ⇣ n t k,v + X k 0 t k,k 0 ˆ t1 k 0 ,v ⌘ ⇣ X k 0 t k,k 0 ˆ t1 k 0 ,v ⌘ .</formula><p>Overall Procedure The EM algorithm is run for each epoch in sequence; at epoch t, after running the EM until convergence,</p><formula xml:id="formula_8">ˆ t k,v is computed byˆt byˆ byˆt k,v = n t k,v + P k 0 t k,k 0 ˆ t1 k 0 ,v n t k + P k 0 t k,k 0 ,</formula><p>and then this value is used for the EM at the next epoch t + 1. Moreover, see Supplementary A for the computation of the statistics of the other vari- ables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>We used two datasets comprising technical pa- pers: NIPS (Perrone et al., 2016) and Drone ( <ref type="bibr" target="#b9">Liew et al., 2017)</ref>. NIPS is a collection of the pa- pers that appeared in NIPS conferences. Drone is a collection of abstracts of papers on unmanned aerial vehicles (UAVs) and was collected from re- lated conferences and journals for surveying re- cent developments in UAVs. The characteristics of those datasets are summarized in <ref type="table">Table 2</ref>. See Supplementary B for the details of data prepro- cessing.  <ref type="table">Table 3</ref>: Means (and standard deviations) of PPLs averaged over all epochs for each dataset with different values of K and S. The proposed method, DSTM, achieved the smallest PPL. <ref type="figure">Figure 2</ref>: Part of the topic structure extracted from Drone dataset using the proposed method. The solid arrows denote the temporal evolution of "planning" topics. The dotted arrows mean that "planning" topics are related to "hardware", "control", and "mapping" topics via some supertopics (filled circles).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NIPS Drone</head><formula xml:id="formula_9">static dynamic K30 (S15) K40 (S20) K50 (S25) K15 (S3) K20 (S3) K25 (S3) LDA - -</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation by Perplexity</head><p>First, we evaluate the performance of the proposed method quantitatively using perplexity (PPL):</p><formula xml:id="formula_10">PPL = exp 0 @ P D d=1 P w test d log p(w d,i |M) P D d=1 n test d 1 A .</formula><p>For each epoch, we used 90% of tokens in each document for training and calculated the PPL us- ing the remaining 10% of tokens. We randomly created 10 train-test pairs and evaluated the means of the PPLs over those random trials. We com- pared the performance of DSTM to three base- lines: LDA ( <ref type="bibr" target="#b3">Blei et al., 2003)</ref>, PAM ( <ref type="bibr" target="#b8">Li and McCallum, 2006)</ref>, and the proposed model without the static structure, which we term DRTM. See Supplementary C on their hyperparameter setting. The means of the PPLs averaged over all epochs for each dataset with different values K are shown in <ref type="table">Table 3</ref>. In both datasets with every setting of K, the proposed model, DSTM, achieved the smallest PPL, which implies its effectiveness for modeling a collection of technical papers. For clarity, we conducted paired t-tests between the perplexities of the proposed method and those of the baselines. On the differences between DSTM and DRTM, the p-values were 4.2 ⇥ 10 2 (K = 30), 7.9 ⇥ 10 5 (K = 40), and 6.4 ⇥ 10 7 (K = 50) for the NIPS dataset, and 1.3 ⇥ 10 4 (K = 15), 8.8 ⇥ 10 5 (K = 20), and 4.9 ⇥ 10 6 (K = 25) for the Drone dataset, respectively. It is also noteworthy that DRTM shows more sig- nificant improvement relative to LDA than PAM does. This suggests that the dynamic structure with multiple-topic dependencies is essential for datasets of this kind.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Analysis of Extracted Structure</head><p>We examined the topic structures extracted from the Drone dataset using DSTM. In <ref type="figure">Figure 2</ref>, we show a part of the extracted structure regarding planning of the UAV's path and/or movement. We identified "planning" topics by looking for key- words such as "trajectory" and "motion." <ref type="figure">In Fig- ure 2</ref>, each node is labeled with eight most prob- able keywords. Moreover, solid arrows (dynamic relations) are drawn if the corresponding t k,k 0 is larger than 200, and dotted arrows (static relations) are drawn between a supertopic and subtopics with the two or three largest values of 2 ↵ t s,k . Looking at the dynamic structure, we may see how research interest regarding planning has changed.</p><p>For example, word "online" first emerges in the "planning" topic in 2016. This is possibly due to the increasing interest in real- time planning problems, which is becoming fea- sible due to the recent development of on-board computers. In regard to the static structures, for example, the "planning" topic is related to the "hardware" and "control" topics in 2013 and 2014, whereas it is also related to the "mapping" topic in 2015 and 2016. Looking at these static structures, we may anticipate how research areas are related to each other in each year. In this case, we can anticipate that planning problems are combined with mapping problems well in recent years. Note that we cannot obtain these results unless the dy- namic and static structures are considered simul- taneously.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this work, we developed a topic model with dynamic and static structures. We confirmed the superiority of the proposed model to the conven- tional topic models in terms of perplexity and ana- lyzed the topic structures of a collection of papers. Possible future directions of research include auto- matic inference of the number of topics and appli- cation to topic trend analysis in various domains.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>D</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Graphical model of the proposed model for epochs t 1 and t.</figDesc><graphic url="image-1.png" coords="2,324.34,62.81,181.41,155.87" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Date</head><label></label><figDesc></figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Chun Fui Liew for sharing his dataset with us and advice.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Timeline: A dynamic hierarchical Dirichlet process model for recovering birth/death and evolution of topics in text stream</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amr</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Conference on Uncertainty in Artificial Intelligence</title>
		<meeting>the 26th Conference on Uncertainty in Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="20" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An introduction to MCMC for machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christophe</forename><surname>Andrieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnaud</forename><surname>Nando De Freitas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="5" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Dynamic topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">D</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Machine Learning</title>
		<meeting>the 23rd International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="113" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Latent Dirichlet allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A segmented topic model based on the two-parameter Poisson-Dirichlet process</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lan</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wray</forename><surname>Buntine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huidong</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="5" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Finding scientific topics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Steyvers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences of the United States of America</title>
		<meeting>the National Academy of Sciences of the United States of America</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="5228" to="5235" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Online multiscale dynamic topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoharu</forename><surname>Iwata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeshi</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasushi</forename><surname>Sakurai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naonori</forename><surname>Ueda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="663" to="672" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Correlated topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">D</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="147" to="154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Pachinko allocation: DAG-structured mixture models of topic correlations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Machine Learning</title>
		<meeting>the 23rd International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="577" to="584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun Fui</forename><surname>Liew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danielle</forename><surname>Delatte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naoya</forename><surname>Takeishi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takehisa</forename><surname>Yairi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.10085</idno>
		<title level="m">Recent developments in aerial robotics: A survey and prototypes overview</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Construction of dependent Dirichlet processes based on Poisson processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Grimson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">W</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="1396" to="1404" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Estimating a Dirichlet distribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Minka</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>MIT</publisher>
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><forename type="middle">A</forename><surname>Valerio Perrone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Jenkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee</forename><forename type="middle">Whye</forename><surname>Spano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Teh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.07460</idno>
		<title level="m">Poisson random fields for dynamic feature models</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Discovering hierarchical topic evolution in time-stamped documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tinglei</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Association for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="915" to="927" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Topics over time: A non-Markov continuous-time model of topical trends</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuerui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="424" to="433" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
