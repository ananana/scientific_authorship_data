<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:46+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Joint Learning for Event Coreference Resolution</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Lu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
						</author>
						<title level="a" type="main">Joint Learning for Event Coreference Resolution</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</title>
						<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="90" to="101"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-1009</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>While joint models have been developed for many NLP tasks, the vast majority of event coreference resolvers, including the top-performing resolvers competing in the recent TAC KBP 2016 Event Nugget Detection and Coreference task, are pipeline-based, where the propagation of errors from the trigger detection component to the event coreference component is a major performance limiting factor. To address this problem, we propose a model for jointly learning event coreference, trigger detection, and event anaphoricity. Our joint model is novel in its choice of tasks and its features for capturing cross-task interactions. To our knowledge, this is the first attempt to train a mention-ranking model and employ event anaphoricity for event coreference. Our model achieves the best results to date on the KBP 2016 En-glish and Chinese datasets.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Within-document event coreference resolution is the task of determining which event mentions in a text refer to the same real-world event. Compared to entity coreference resolution, event coreference resolution is not only much less studied, but it is arguably more challenging. The challenge stems in part from the fact that an event coreference re- solver typically lies towards the end of the stan- dard information extraction pipeline, assuming as input the noisy outputs of its upstream compo- nents. One such component is the trigger detection system, which is responsible for identifying event triggers and determining their event subtypes.</p><p>As is commonly known, trigger detection is another challenging task that is far from being solved. In fact, in the recent TAC KBP 2016 Event Nugget Detection and Coreference task, trigger detection (a.k.a. event nugget detection in KBP) is deliberately made more challenging by focus- ing only on detecting the 18 subtypes of triggers on which the KBP 2015 participating systems' performances were the poorest ( . The best-performing KBP 2016 system on English trigger detection achieved only an F-score of 47 ( . <ref type="bibr">1</ref> Given the difficulty of trigger detection, it is conceivable that many errors will propagate from the trigger detection component to the event coref- erence component in any pipeline architecture where trigger detection precedes event corefer- ence resolution. These trigger detection errors could severely harm event coreference perfor- mance. For instance, two event mentions could be wrongly posited as coreferent if the underlying triggers were wrongly predicted to have the same subtype. Nevertheless, the top-performing sys- tems in the KBP 2016 event coreference task all adopted the aforementioned pipeline architecture ( <ref type="bibr" target="#b31">Nguyen et al., 2016)</ref>. Their performances are not particularly im- pressive, however: the best English event corefer- ence F-score (averaged over four scoring metrics) is only around 30%.</p><p>To address this error propagation problem, we describe a joint model of trigger detection, event coreference, and event anaphoricity in this pa- per. Our choice of these three tasks is moti- vated in part by their inter-dependencies. As men- tioned above, it is well-known that trigger de- tection performance has a huge impact on event coreference performance. Though largely under- investigated, event coreference could also improve trigger detection. For instance, if two event men- tions are posited as coreferent, then the under- lying triggers must have the same event sub- type. While the use of anaphoricity information for entity coreference has been extensively stud- ied (see <ref type="bibr" target="#b30">Ng (2010)</ref>), to our knowledge there has thus far been no attempt to explicitly model event anaphoricity for event coreference. <ref type="bibr">2</ref> Although the mention-ranking model we employ for event coreference also allows an event mention to be posited as non-anaphoric (by resolving it to a null candidate antecedent), our decision to train a sep- arate anaphoricity model and integrate it into our joint model is motivated in part by the recent suc- cesses of <ref type="bibr" target="#b37">Wiseman et al. (2015)</ref>, who showed that there are benefits in jointly training a noun phrase anaphoricity model and a mention-ranking model for entity coreference resolution. Finally, event anaphoricity and trigger detection can also mu- tually benefit each other. For instance, any verb posited as a non-trigger cannot be anaphoric, and any verb posited as anaphoric must be a trigger. Note that in our joint model, anaphoricity serves as an auxiliary task: its intended use is to im- prove trigger detection and event coreference, po- tentially mediating the interaction between trigger detection and event coreference.</p><p>Being a structured conditional random field, our model encompasses two types of factors. Unary factors encode the features specific for each task. Binary and ternary factors capture the interaction between each pair of tasks in a soft manner, en- abling the learner to learn which combinations of values of the output variables are more probable. For instance, the learner should learn that it is not a good idea to classify a verb both as anaphoric and as a non-trigger. Our model is similar in spirit to <ref type="bibr" target="#b14">Durrett and Klein's (2014)</ref> joint model for entity analysis, which performs joint learning for entity coreference, entity linking and semantic typing via the use of interaction features.</p><p>Our contributions are two-fold. First, we present a joint model of event coreference, trigger detection, and anaphoricity that is novel in terms of the choice of tasks and the features used to cap- ture cross-task interactions. Second, our model achieves the best results to date on the KBP 2016 English and Chinese event coreference tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Definitions, Task, and Corpora</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Definitions</head><p>We employ the following definitions in our discus- sion of trigger detection and event coreference:</p><p>• An event mention is an explicit occurrence of an event consisting of a textual trigger, ar- guments or participants (if any), and the event type/subtype.</p><p>• An event trigger is a string of text that most clearly expresses the occurrence of an event, usually a word or a multi-word phrase</p><p>• An event argument is an argument filler that plays a certain role in an event.</p><p>• An event coreference chain (a.k.a. an event hopper) is a group of event mentions that re- fer to the same real-world event. They must have the same event (sub)type. To understand these definitions, consider the ex- ample in <ref type="table">Table 1</ref>, which contains two coreferent event mentions, ev1 and ev2. left is the trig- ger for ev1 and departed is the trigger for ev2. Both triggers have subtype Movement.Transport- Person. ev1 has three arguments, Georges Cipri- ani, prison, and Wednesday with roles Person, Origin, and Time respectively. ev2 also has three arguments, He, Ensisheim, and police vehicle with roles Person, Origin, and Instrument respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Task</head><p>The version of the event coreference task we fo- cus on in this paper is the Event Nugget Detec- tion and Coreference task in the TAC KBP 2016 Event Track. While we discuss the role played by event arguments in event coreference in the previ- ous subsection, KBP 2016 addresses event argu- ment detection as a separate shared task. In other words, the KBP 2016 Event Nugget Detection and Coreference task focuses solely on trigger detec- tion and event coreference.</p><p>It is worth mentioning that the KBP Event Nugget Detection and Coreference task, which started in 2015, aims to address a major weakness of the ACE 2005 event coreference task. Specif- ically, ACE 2005 adopts a strict notion of event identity, with which two event mentions were an- notated as coreferent if and only if "they had the same agent(s), patient(s), time, and location" ( <ref type="bibr" target="#b35">Song et al., 2015)</ref>, and their event attributes (po- larity, modality, genericity, and tense) were not in- compatible. In contrast, KBP adopts a more re- laxed definition of event coreference, allowing two Georges Cipriani <ref type="bibr">[P erson]</ref> , {left}ev1 the prison <ref type="bibr">[Origin]</ref> in Ensisheim in northern France on parole on Wednesday <ref type="bibr">[T ime]</ref> . He <ref type="bibr">[P erson]</ref> {departed}ev2 Ensisheim <ref type="bibr">[Origin]</ref> in a police vehicle <ref type="bibr">[Instrument]</ref> bound for an open prison near Strasbourg. <ref type="table">Table 1</ref>: Event coreference resolution example. event mentions to be coreferent as long as they in- tuitively refer to the same real-world event. Under this definition, two event mentions can be corefer- ent even if their time and location arguments are not coreferent. In our example in <ref type="table">Table 1</ref>, ev1 and ev2 are coreferent in KBP because they both refer to the same event of Cipriani leaving the prison. However, they are not coreferent in ACE because their Origin arguments are not coreferent (one Ori- gin argument involves a prison in Ensisheim while the other involves the city Ensisheim).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Corpora</head><p>Given our focus on the KBP 2016 Event Nugget Detection and Coreference task, we employ the English and Chinese corpora used in this task for evaluation, referring to these corpora as the KBP 2016 English and Chinese corpora for brevity. There are no official training sets: the task orga- nizers simply made available a number of event coreference-annotated corpora for training. For English, we use LDC2015E29, E68, E73, and E94 for training. These corpora are composed of two types of documents, newswire documents and dis- cussion forum documents. Together they contain 648 documents with 18739 event mentions dis- tributed over 9955 event coreference chains. For Chinese, we use LDC2015E78, E105, and E112 for training. These corpora are composed of dis- cussion forum documents only. Together they con- tain 383 documents with 4870 event mentions dis- tributed over 3614 event coreference chains.</p><p>The test set for English consists of 169 newswire and discussion forum documents with 4155 event mentions distributed over 3191 event coreference chains. The test set for Chinese con- sists of 167 newswire and discussion forum docu- ments with 2518 event mentions distributed over 1912 event coreference chains. Note that these test sets contain only annotations for event triggers and event coreference (i.e., there are no event ar- gument annotations). While some of the training sets additionally contain event argument annota- tions, we do not make use of event argument an- notations in model training to ensure a fairer com- parison to the teams participating in the KBP 2016 Event Nugget Detection and Coreference task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview</head><p>Our model, which is a structured conditional ran- dom field, operates at the document level. Specif- ically, given a test document, we first extract from it (1) all single-word nouns and verbs and (2) all words and phrases that have appeared at least once as a trigger in the training data. We treat each of these extracted words and phrases as a candidate event mention. <ref type="bibr">3</ref> The goal of the model is to make joint predictions for the candidate event mentions in a document. Three predictions will be made for each candidate event mention that correspond to the three tasks in the model: its trigger subtype, its anaphoricity, and its antecedent.</p><p>Given this formulation, we define three types of output variables:</p><p>• Event subtype variables t = (t 1 , . . . , t n ). Each t i takes a value in the set of 18 event subtypes defined in KBP 2016 or NONE, which indi- cates that the event mention is not a trigger.</p><p>• Anaphoricity variables a = (a 1 , . . . , a n ). Each a i is either ANAPHORIC or NOT ANAPHORIC.</p><p>• Coreference variables c = (c 1 , . . . , c n ), where c i ∈ {1, . . . , i − 1, NEW}. In other words, the value of each c i is the id of its antecedent, which can be one of the preceding event men- tions or NEW (if the event mention underly- ing c i starts a new cluster).</p><p>Each candidate event mention is associated with exactly one coreference variable, one event sub- type variable, and one anaphoricity variable. Our model induces the following log-linear probability distribution over these variables:</p><formula xml:id="formula_0">p(t, a, c|x; Θ) ∝ exp( i θ i f i (t, a, c,x))</formula><p>3 According to the KBP annotation guidelines, each word may trigger multiple event mentions (e.g., murder can trig- ger two event mentions with subtypes Life.Die and Con- flict.Attack). Hence, our treating each extracted word as a candidate event mention effectively prevents a word from triggering multiple event mentions. Rather than complicate model design by relaxing this simplifying assumption, we present an alternative, though partial, solution to this prob- lem wherein we allow each event mention to be associated with multiple event subtypes. See the Appendix for details. where θ i ∈ Θ is the weight associated with feature function f i and x is the input document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Features</head><p>Given that our model is a structured conditional random field, the features can be divided into two types: (1) task-specific features, and (2) cross- task features, which capture the interactions be- tween a pair of tasks. We express these two types of features in factor graph notation. The task- specific features are encoded in unary factors, each of which is connected to the corresponding vari- able ( <ref type="figure" target="#fig_0">Figure 1</ref>). The cross-task features are en- coded in binary or ternary factors, each of which couples the output variables from two tasks <ref type="figure" target="#fig_1">(Fig- ure 2)</ref>. Next, we describe these two types of fea- tures. Each feature is used to train models for both English and Chinese unless otherwise stated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Task-Specific Features</head><p>We begin by describing the task-specific features, which are encoded in unary factors, as well as each of the three independent models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.1">Trigger Detection</head><p>When applied in isolation, our trigger detection model returns a distribution over possible subtypes given a candidate trigger. Each candidate trigger t is represented using t's word, t's lemma, word bi- grams formed with a window size of three from t, as well as feature conjunctions created by pair- ing t's lemma with each of the following features: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.2">Event Coreference</head><p>We employ a mention-ranking model for event coreference that selects the most probable an- tecedent for a mention to be resolved (or NEW if the mention is non-anaphoric) from its set of candidate antecedents. When applied in isola- tion, the model is trained to maximize the condi-tional likelihood of collectively resolving the men- tions to their correct antecedents in the training texts <ref type="bibr" target="#b13">(Durrett and Klein, 2013</ref>). Below we de- scribe the features used to represent the candidate antecedents for the mention to be resolved, m j . Features representing the NULL candidate an- tecedent: Besides m j 's word and m j 's lemma, we employ feature conjunctions given their useful- ness in entity coreference <ref type="bibr" target="#b16">(Fernandes et al., 2014</ref>). Specifically, we create a conjunction between m j 's lemma and the number of sentences preced- ing m j , as well as a conjunction between m j 's lemma and the number of mentions preceding m j in the document. Features representing a non-NULL candidate antecedent, m i : m i 's word, m i 's lemma, whether m i and m j have the same lemma, and fea- ture conjunctions including: (1) m i 's word paired with m j 's word, (2) m i 's lemma paired with m j 's lemma, (3) the sentence distance between m i and m j paired with m i 's lemma and m j 's lemma, (4) the mention distance between m i and m j paired with m i 's lemma and m j 's lemma, (5) a quadru- ple consisting of m i and m j 's subjects and their lemmas, and (6) a quadruple consisting of m i and m j 's objects and their lemmas.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.3">Anaphoricity Determination</head><p>When used in isolation, the anaphoricity model re- turns the probability that the given event mention is anaphoric. To train the model, we represent each event mention m j using the following features: (1) the head word of each candidate antecedent paired with m j 's word, (2) whether at least one candi- date antecedent has the same lemma as that of m j , and (3) the probability that m j is anaphoric in the training data (if m j never appears in the training data, this probability is set to 0.5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Cross-Task Interaction Features</head><p>Cross-task interaction features are associated with the binary and ternary factors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.1">Trigger Detection and Anaphoricity</head><p>We fire features that conjoin each candidate event mention's event subtype, the lemma of its trigger and its anaphoricity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.2">Trigger Detection and Coreference</head><p>We define our joint coreference and trigger detec- tion factors such that the features defined on sub- type variables t i and t j are fired only if current mention m j is coreferent with preceding mention m i . These features are: (1) the pair of m i and m j 's subtypes, (2) the pair of m j 's subtype and m i 's word, and (3) the pair of m i 's subtype and m j 's word.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.3">Coreference and Anaphoricity</head><p>We fire a feature that conjoins event mention m j 's anaphoricity and whether or not a non-NULL an- tecedent is selected for m j .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Training</head><p>We learn the model parameters Θ from a set of d training documents, where document i contains content x i , gold triggers t * i and gold event coref- erence partition C * i . Before learning, there are a couple of issues we need to address.</p><p>First, we need to derive gold anaphoricity la- bels a * i from C * i . This is straightforward: the first mention of each coreference chain is NOT ANAPHORIC, whereas the rest are ANAPHORIC.</p><p>Second, we employ gold event mentions for model training, but training models only on gold mentions is not sufficient: for instance, a trigger detector trained solely on gold mentions will not be able to classify a candidate event mention as NONE during testing. To address this issue, we additionally train the models on candidate event mentions corresponding to non-triggers. We cre- ate these candidate event mentions as follows. For each word w that appears as a true trigger at least once in the training data, we create a candidate event mention from each occurrence of w in the training data that is not annotated as a true trigger.</p><p>Third, since our model produces event corefer- ence output in the form of an antecedent vector (with one antecedent per event mention), it needs to be trained on antecedent vectors. However, since the coreference annotation for each docu- ment i is provided in the form of a clustering C * i , we follow previous work on entity coreference res- olution <ref type="bibr" target="#b13">(Durrett and Klein, 2013)</ref>: we sum over all antecedent structures A(C * i ) that are consis- tent with C * i (i.e., the first mention of a cluster has antecedent NEW, whereas each of the subsequent mentions can select any of the preceding mentions in the same cluster as its antecedent).</p><p>Next, we learn the model parameters to max- imize the following conditional likelihood of the training data with L1 regularization:</p><formula xml:id="formula_1">L(Θ) = d i=1 log c * ∈A(C * i ) p ′ (t * i , a * i , c * |x i ; Θ)+λΘ 1</formula><p>In this objective, p ′ is obtained by augment- ing the distribution p (defined in Section 3.1) with task-specific parameterized loss functions:</p><formula xml:id="formula_2">p ′ (t, a, c|x i ; Θ) ∝ p(t, a, c|x i ; Θ) exp[α t l t (t, t * ) + α a l a (a, a * ) + α c l c (c, C * )]</formula><p>where l t , l a and l c are task-specific loss functions, and α t , α a and α c are the associated weight pa- rameters that specify the relative importance of the three tasks in the objective function.</p><p>Softmax-margin, the technique of integrating task-specific loss functions into the objective func- tion, was introduced by <ref type="bibr" target="#b17">Gimpel and Smith (2010)</ref> and subsequently used by <ref type="bibr">Klein (2013, 2014)</ref>. By encoding task-specific knowl- edge, these loss functions can help train a model that places less probability mass on less desirable output configurations.</p><p>Our loss function for event coreference, l c , is motivated by the one Durrett and Klein (2013) de- veloped for entity coreference. It is a weighted sum of the counts of three error types:</p><formula xml:id="formula_3">l c (c, C * ) = α c,F A F A(c, C * )+α c,F N F N (c, C * ) + α c,W L W L(c, C * )</formula><p>where F A(c, C * ) is the number of non-anaphoric mentions misclassified as anaphoric, F N (c, C * ) is the number of anaphoric mentions misclassified as non-anaphoric, and W L(c, C * ) is the number of incorrectly resolved anaphoric mentions.</p><p>Our loss function for trigger detection, l t , is pa- rameterized in a similar way, having three param- eters associated with three error types: α t,F T is associated with the number of non-triggers mis- classified as triggers, α t,F N is associated with the number of triggers misclassified as non-triggers, and α t,W L is associated with the number of trig- gers labeled with the wrong subtype.</p><p>Finally, our loss function for anaphoricity deter- mination, l a , is also similarly parameterized, hav- ing two parameters: α a,F A and α a,F N are asso- ciated with the number of false anaphors and the number of false non-anaphors, respectively.</p><p>Following <ref type="bibr" target="#b14">Durrett and Klein (2014)</ref>, we use AdaGrad ( <ref type="bibr" target="#b12">Duchi et al., 2011</ref>) to optimize our ob- jective with λ = 0.001 in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Inference</head><p>Inference, which is performed during training and decoding, involves computing the marginals for a variable or a set of variables to which a factor con- nects. For efficiency, we perform approximate in- ference using belief propagation rather than exact inference. Given that convergence can typically be reached within five iterations of belief propaga- tion, we employ five iterations in all experiments.</p><p>Performing inference using belief propagation on the full factor graph defined in Section 3.1 can still be computationally expensive, however. One reason is that the number of ternary factors grows quadratically with the number of event mentions in a document. To improve scalability, we restrict the domains of the coreference variables. Rather than allow the domain of coreference variable c j to be of size j, we allow a preceding mention m i to be a candidate antecedent of mention m j if (1) the sentence distance between the two mentions is less than an empirically determined threshold and (2) either they are coreferent at least once in the train- ing data or their head words have the same lemma. Doing so effectively enables us to prune the un- likely candidate antecedents for each event men- tion. As <ref type="bibr" target="#b14">Durrett and Klein (2014)</ref> point out, such pruning has the additional benefit of reducing "the memory footprint and time needed to build a fac- tor graph", as we do not need to create any factor between m i and m j and its associated features if m i is pruned. To further reduce the memory foot- print, we additionally restrict the domains of the event subtype variables. Given a candidate event mention created from word w, we allow the do- main of its subtype variable to include only NONE as well as those subtypes that w is labeled with at least once in the training data.</p><p>For decoding, we employ minimum Bayes risk, which computes the marginals of each variable w.r.t. the joint model and derives the most prob- able assignment to each variable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Setup</head><p>We perform training and evaluation on the KBP   <ref type="bibr" target="#b26">Luo, 2005)</ref> and BLANC (Recasens and Hovy, 2011), as well as the unweighted average of their F-scores (AVG-F). The scorer reports event mention detec- tion performance in terms of F-score, consider- ing a mention correctly detected if it has an ex- act match with a gold mention in terms of bound- ary, event type, and event subtype. In addition, we report anaphoricity determination performance in terms of the F-score computed over anaphoric mentions, counting an extracted anaphoric men- tion as a true positive if it has an exact match with a gold anaphoric mention in terms of boundary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results and Discussion</head><p>Results are shown in <ref type="table" target="#tab_1">Table 2</ref> where performance on all three tasks (event coreference, trigger detec- tion, and anaphoricity determination) is expressed in terms of F-score. The top half of the table shows the results on the English evaluation set. Specif- ically, row 1 shows the performance of the best event coreference system participating in KBP 2016 ( . This system adopts a pipeline architecture. It first uses an ensemble of one-nearest-neighbor classifiers for trigger detec- tion. Using the extracted triggers, it then applies a pipeline of three sieves, each of which is a one- nearest-neighbor classifier, for event coreference. As we can see, this system achieves an AVG-F of 30.08 for event coreference and an F-score of 46.99 for trigger detection.</p><p>Row 2 shows the performance of the indepen- dent models, each of which is trained indepen- dently of the other models. Specifically, each in- dependent model is trained using only the unary factors associated with it. As we can see, the in- dependent models outperform the top KBP 2016 system by 1.2 points in AVG-F for event corefer- ence and 1.83 points for trigger detection.</p><p>Results of our joint model are shown in row 3. The absolute performance differences between the joint model and the independent models are shown in row 4. As we can see, the joint model outper- forms the independent models for all three tasks: by 1.80 points for event coreference, 0.48 points for trigger detection and 4.59 points for anaphoric- ity determination. Most encouragingly, the joint model outperforms the top KBP 2016 system for both event coreference and trigger detection. For event coreference, it outperforms the top KBP sys- tem w.r.t. all scoring metrics, yielding an improve- ment of 3 points in AVG-F. For trigger detection, it outperforms the top KBP system by 2.31 points.</p><p>The bottom half of <ref type="table" target="#tab_1">Table 2</ref> shows the results on the Chinese evaluation set. The top KBP 2016 event coreference system on Chinese is also the Lu and Ng (2016) system. While the top KBP sys- tem outperforms the independent models for both tasks (by 0.59 points in AVG-F for event coref- erence and 0.19 points for trigger detection), our joint model outperforms the independent models  for all three tasks: by 1.95 points for event coref- erence, 4.02 points for anaphoricity determination, and 0.71 points for trigger detection. Like its En- glish counterpart, our Chinese joint model outper- forms the top KBP system for both event corefer- ence and trigger detection. For event coreference, it outperforms the top KBP system w.r.t. all but the CEAF e metric, yielding an absolute improvement of 1.36 points in AVG-F. For trigger detection, it outperforms the top KBP system by 0.52 points. For both datasets, the joint model's superior per- formance to the independent coreference model stems primarily from considerable improvements in MUC F-score. As MUC is a link-based mea- sure, these results provide suggestive evidence that joint modeling has enabled more event corefer- ence links to be discovered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Model Ablations</head><p>To evaluate the importance of each of the three types of joint factors in the joint model, we per- form ablation experiments. 7 <ref type="table" target="#tab_3">Table 3</ref> shows the re- sults on the English and Chinese datasets when we add each type of joint factors to the independent model and remove each type of joint factors from the full joint model. The results of each task are expressed in terms of changes to the correspond- ing independent model's F-score. <ref type="bibr">7</ref> Chen and Ng (2013) also performed ablation on their ACE-style Chinese event coreference resolver. However, given the differences in the tasks involved (e.g., they did not model event anaphoricity, but included tasks such as event ar- gument extraction and role classification, entity coreference, and event mention attribute value computation) and the ab- lation setup (e.g., they ablated individual tasks/components in their pipeline-based system in an incremental fashion, whereas we ablate interaction factors rather than tasks), a di- rect comparison of their observations and ours is difficult.</p><p>Coref-Trigger interactions. Among the three types of factors, this one contributes the most to coreference performance, regardless of whether it is applied in isolation or in combination with the other two types of factors to the independent coref- erence model. In addition, it is the most effec- tive type of factor for improving trigger detec- tion. When applied in combination, it also im- proves anaphoricity determination, although less effectively than the other two types of factors.</p><p>Coref-Anaphoricity interactions. When ap- plied in isolation to the independent models, this type of factor improves coreference resolution but has a mixed impact on anaphoricity determina- tion. When applied in combination with other types of factors, it improves both tasks, partic- ularly anaphoricity determination. Its impact on trigger detection, however, is generally negative.</p><p>Trigger-Anaphoricity interactions. When ap- plied in isolation to the independent models, this type of factor improves both trigger detection and anaphoricity determination. When applied in combination with other types of factors, it still im- proves anaphoricity determination (particularly on Chinese), but has a mixed effect on trigger detec- tion. Among the three types of factors, it has the least impact on coreference resolution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Error Analysis</head><p>Next, we conduct an analysis of the major sources of error made by our joint coreference model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">Two Major Types of Precision Error</head><p>Erroneous and mistyped triggers. Our trigger model tends to assign the same subtype to event mentions triggered by the same word. As a result, it often assigns the wrong subtype to triggers that possess different subtypes in different contexts. For the same reason, words that are only some- times used as triggers are often wrongly posited as triggers when they are not. These two types of triggers have in turn led to the establishment of in- correct coreference links. <ref type="bibr">8</ref> Failure to extract arguments. In the absence of an annotated corpus for training an argument clas- sifier, we exploit dependency relations for argu- ment extraction. Doing so proves inadequate, par- ticularly for noun triggers, owing to the absence of dependency relations that can be used to reli- ably extract their arguments. Moreover, using de- pendency relations does not allow the extraction of arguments that do not appear in the same sentence as their trigger. Since the presence of incompat- ible arguments is an important indicator of non- coreference, our model's failure to extract argu- ments has resulted in incorrect coreference links.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">Three Major Types of Recall Error</head><p>Missing triggers. Our trigger model fails to identify trigger words that are unseen or rarely- occurring in the training data. As a result, many coreference links cannot be established. Lack of entity coreference information. Entity coreference information is useful for event coref- erence because the corresponding arguments of two event mentions are typically coreferent. Since our model does not exploit entity coreference in- formation, it treats two lexically different event ar- guments as non-coreferent/unrelated. This in turn weakens its ability to determine whether two event mentions are coreferent. This issue is particularly serious in discussion forum documents, where it is not uncommon to see pronouns serve as sub- jects and objects of event mentions. The situation is further aggravated in Chinese documents, where zero pronouns are prevalent. Lack of contextual understanding. Our model only extracts features from the sentence in which an event mention appears. However, additional contextual information present in neighboring sen- tences may be needed for correct coreference res- olution. This is particularly true in discussion fo- rum documents, where the same event may be de- scribed differently by different people. For exam-ple, when describing the fact that Tim Cook will attend Apple's Istanbul store opening, one person said "Cook is expected to return to Turkey for the store opening", and another person described this event as "Tim travels abroad YET AGAIN to be feted by the not-so-high-and-mighty". It is by no means easy to determine that return and travel trigger two coreferent mentions in these sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Existing event coreference resolvers have been evaluated on different corpora, such as MUC (e.g., <ref type="bibr" target="#b19">Humphreys et al. (1997)</ref>),</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We proposed a joint model of event coreference resolution, trigger detection, and event anaphoric- ity determination. The model is novel in its choice of tasks and the cross-task interaction features. When evaluated on the KBP 2016 English and Chinese corpora, our model not only outperforms the independent models but also achieves the best results to date on these corpora.</p><p>To train our joint model, however, the trigger annotations and the event coreference annotations in the training data must be consistent. Since we modified the trigger annotations (by merging event mentions and allowing combined subtypes), we make two modifications to the event coreference annotations to ensure consistency between the two sets of annotations. First, let C 1 and C 2 be two event coreference chains in a training document such that the set of words triggering the event mentions in C 1 (with subtype t 1 ) is the same as that triggering the event mentions in C 2 (with sub- type t 2 ). If each of the event mentions in C 1 was merged with the corresponding event mention in C 2 during the aforementioned preprocessing of the trigger annotations (because combining t 1 and t 2 results in one of the three most frequent combined subtypes), then we delete one of the two corefer- ence chains, and assign the combined subtype to the remaining chain. Finally, we remove any re- maining event mentions that were merged during the preprocessing of trigger annotations from their respective coreference chains and create a single- ton cluster for each of the merged mentions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Unary factors for the three tasks, the variables they are connected to, and the possible values of the variables. Unary factors encode taskspecific features. Each factor is connected to the corresponding output node. The features associated with a factor are used to predict the value of the output node it is connected to when a model is run independently of other models.</figDesc><graphic url="image-14.png" coords="4,72.14,63.88,222.93,158.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Binary and ternary factors. These higherorder factors capture cross-task interactions. The binary anaphoricity and trigger factors encourage anaphoric mentions to be triggers. The binary anaphoricity and coreference factors encourage non-anaphoric mentions to start a NEW coreference cluster. The ternary trigger and coreference factors encourage coreferent mentions to be triggers.</figDesc><graphic url="image-15.png" coords="4,308.78,62.80,215.68,158.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>2016 English and Chinese corpora. For English, we train models on 509 of the training documents, tune parameters on 139 training documents, and report results on the official KBP 2016 English test set. 6 For Chinese, we train models on 302 of the training documents, tune parameters on 81 train- ing documents, and report results on the official</figDesc><table>English 
MUC 
B 3 
CEAF e BLANC AVG-F Trigger Anaphoricity 
KBP2016 
26.37 37.49 34.21 
22.25 
30.08 
46.99 
− 
INDEP. 
22.71 40.72 39.00 
22.71 
31.28 
48.82 
27.35 
JOINT 
27.41 40.90 39.00 
25.00 
33.08 
49.30 
31.94 
∆ over INDEP. +4.70 +0.18 
0.00 
+2.29 
+1.80 
+0.48 
+4.59 
Chinese 
MUC 
B 3 
CEAF e BLANC AVG-F Trigger Anaphoricity 
KBP2016 
24.27 32.83 30.82 
17.80 
26.43 
40.01 
− 
INDEP. 
22.68 32.97 29.96 
17.74 
25.84 
39.82 
19.31 
JOINT 
27.94 33.01 29.96 
20.24 
27.79 
40.53 
23.33 
∆ over INDEP. +5.26 +0.04 
0.00 
+2.50 
+1.95 
+0.71 
+4.02 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 2 : Results of all three tasks on the KBP 2016 evaluation sets. The KBP2016 results are those achieved</head><label>2</label><figDesc></figDesc><table>by the best-performing coreference resolver in the official KBP 2016 evaluation. ∆ is the performance difference between the 

JOINT model and the corresponding INDEP. model. All results are expressed in terms of F-score. 

KBP 2016 Chinese test set. 
Results of event coreference and trigger de-
tection are obtained using version 1.7.2 of the 
official scorer provided by the KBP 2016 or-
ganizers. To evaluate event coreference per-
formance, the scorer employs four scoring 
measures, namely MUC (Vilain et al., 1995), 
B 3 (Bagga and Baldwin, 1998), CEAF e (</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Results of model ablations on the KBP 2016 evaluation sets. Each row of ablation results is obtained 

by either adding one type of interaction factor to the INDEP. model or deleting one type of interaction factor from the JOINT 

model. For each column, the results are expressed in terms of changes to the INDEP. model's F-score shown in row 1. 

</table></figure>

			<note place="foot" n="1"> This is the best English nugget type result in KBP 2016. In this paper, we will not be concerned with realis classification, as it does not play any role in event coreference.</note>

			<note place="foot" n="2"> Following the entity coreference literature, we overload the term anaphoricity, saying that an event mention is anaphoric if it is coreferent with a preceding mention in the associated text.</note>

			<note place="foot">the head word of the entity syntactically closest to t, the head word of the entity textually closest to t, the entity type of the entity that is syntactically closest to t, and the entity type of the entity that is textually closest to t. 4 In addition, for event mentions with verb triggers, we use the head words and the entity types of their subjects and objects as features, where the subjects and objects are extracted from the dependency parse trees obtained using Stanford CoreNLP (Manning et al., 2014). For event mentions with noun triggers, we create the same features that we did for verb triggers, except that we replace the subjects and verbs with heuristically extracted agents and patients. Finally, for the Chinese trigger detector, we additionally create two features from each character in t, one encoding the character itself and the other encoding the entry number of the corresponding character in a Chinese synonym dictionary. 5</note>

			<note place="foot" n="4"> We train a CRF-based entity extraction model for jointly identifying the entity mentions and their types. Details can be found in Lu et al. (2016). 5 The dictionary is available from http://ir.hit.edu.cn/. An entry number in this dictionary conceptually resembles a synset id in WordNet (Fellbaum, 1998).</note>

			<note place="foot" n="6"> The parameters to be tuned are the α&apos;s multiplying the loss functions and those inside the loss functions.</note>

			<note place="foot" n="8"> In our joint model, mentions that are posited as coreferent are encouraged to have the same subtype. While it can potentially fix the errors involving coreferent mentions that have different subtypes, it cannot fix the errors in which the two mentions involved have the same erroneous subtype.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the three anonymous reviewers for their detailed comments. This work was supported in part by NSF <ref type="bibr">Grants IIS-1219142 and IIS-1528037.</ref> </p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix: Handling Words that Trigger Multiple Event Mentions</head><p>In KBP, a word can trigger multiple event men- tions. However, since we create exactly one can- didate event mention from each extracted word in each test document, our model effectively prevents a word from triggering multiple event mentions. This poses a problem: each word cannot be as- sociated with more than one event subtype. This appendix describes how we (partially) address this issue that involves allowing each event mention to be associated with multiple event subtypes.</p><p>To address this problem, we preprocess the gold trigger annotations in the training data as follows. First, for each word triggering multiple event men- tions (with different event subtypes), we merge their event mentions into one event mention hav- ing the combined subtype. In principle, we can add each of these combined subtypes into our event subtype inventory and allow our model to make predictions using them. However, to avoid over-complicating the prediction task (by having a large subtype inventory), we only add the three most frequently occurring combined subtypes in the training data to the inventory. Merged men- tions whose combined subtype is not among the most frequent three will be unmerged in order to recover the original mentions so that the model can still be trained on them.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The stages of event extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Ahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the COLING/ACL Workshop on Annotating and Reasoning about Time and Events</title>
		<meeting>the COLING/ACL Workshop on Annotating and Reasoning about Time and Events</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Detecting subevent structure for event coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Araki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengzhong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teruko</forename><surname>Mitamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International Conference on Language Resources and Evaluation</title>
		<meeting>the Ninth International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="4553" to="4558" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Joint event trigger identification and event coreference resolution with structured perceptron</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Araki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teruko</forename><surname>Mitamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2074" to="2080" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Algorithms for scoring coreference chains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Bagga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Breck</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Linguistic Coreference Workshop at The First International Conference on Language Resources and Evaluation</title>
		<meeting>the Linguistic Coreference Workshop at The First International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="563" to="566" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Unsupervised event coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrian</forename><surname>Cosmin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanda</forename><surname>Bejan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Harabagiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="311" to="347" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A unified event coreference resolution by integrating multiple resolvers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chew Lim</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth International Conference on Natural Language Processing</title>
		<meeting>the Fifth International Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="102" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Chinese event coreference resolution: Understanding the state of the art</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Joint Conference on Natural Language Processing</title>
		<meeting>the 6th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="822" to="828" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Chinese event coreference resolution: An unsupervised probabilistic model rivaling supervised resolvers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technologies: The</title>
		<meeting>Human Language Technologies: The</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<title level="m">Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="page" from="1097" to="1107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Joint inference over a lightly supervised information extraction pipeline: Towards event coreference resolution for resourcescarce languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th AAAI Conference on Artificial Intelligence</title>
		<meeting>the 30th AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2913" to="2920" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Graph-based event coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Workshop on Graph-based Methods for Natural Language Processing (TextGraphs-4)</title>
		<meeting>the 2009 Workshop on Graph-based Methods for Natural Language Processing (TextGraphs-4)</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="54" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Using semantic relations to solve event coreference in text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agata</forename><surname>Cybulska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piek</forename><surname>Vossen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the LREC Workshop on Semantic Relations-II Enhancing Resources and Applications</title>
		<meeting>the LREC Workshop on Semantic Relations-II Enhancing Resources and Applications</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="60" to="67" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Adaptive subgradient methods for online learning and stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2121" to="2159" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Easy victories and uphill battles in coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Durrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1971" to="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A joint model for entity analysis: Coreference, typing, and linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Durrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="477" to="490" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">WordNet: An Electronical Lexical Database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christiane</forename><surname>Fellbaum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Cícero Nogueira dos Santos, and Ruy Luiz Milidiu</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Eraldo Rezende Fernandes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="801" to="835" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Latent trees for coreference resolution</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Softmaxmargin CRFs: Training log-linear models with cost functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="733" to="736" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">RPI BLENDER TAC-KBP2015 system description</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoman</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yadong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth Text Analysis Conference</title>
		<meeting>the Eighth Text Analysis Conference</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Event coreference for information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Humphreys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Gaizauskas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saliha</forename><surname>Azzam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL/EACL Workshop on Operational Factors in Practical, Robust Anaphora Resolution for Unrestricted Texts</title>
		<meeting>the ACL/EACL Workshop on Operational Factors in Practical, Robust Anaphora Resolution for Unrestricted Texts</meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="75" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Event linking with sentential features from convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feiyu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Weissenborn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th SIGNLL Conference on Computational Natural Language Learning</title>
		<meeting>the 20th SIGNLL Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="239" to="249" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Joint entity and event coreference resolution across documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heeyoung</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><surname>Recasens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angel</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="489" to="500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Supervised within-document event coreference using information propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengzhong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Araki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teruko</forename><surname>Mitamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International Conference on Language Resources and Evaluation</title>
		<meeting>the Ninth International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="4539" to="4544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">CMU-LTI at KBP 2016 event nugget track</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengzhong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Araki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teruko</forename><surname>Mitamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth Text Analysis Conference</title>
		<meeting>the Ninth Text Analysis Conference</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">UTD&apos;s event nugget detection and coreference system at KBP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth Text Analysis Conference</title>
		<meeting>the Ninth Text Analysis Conference</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Joint inference for event coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepak</forename><surname>Venugopal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vibhav</forename><surname>Gogate</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on Computational Linguistics</title>
		<meeting>the 26th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3264" to="3275" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">On coreference resolution performance metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoqiang</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="25" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Improving event coreference by context extraction and dynamic feature weighting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katie</forename><surname>Mcconky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rakesh</forename><surname>Nagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moises</forename><surname>Sudit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Hughes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 IEEE International Multi-Disciplinary Conference on Cognitive Methods in Situation Awareness and Decision Support</title>
		<meeting>the 2012 IEEE International Multi-Disciplinary Conference on Cognitive Methods in Situation Awareness and Decision Support</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="38" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Overview of TAC-KBP 2016 event nugget track</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teruko</forename><surname>Mitamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengzhong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth Text Analysis Conference</title>
		<meeting>the Ninth Text Analysis Conference</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Supervised noun phrase coreference research: The first fifteen years</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1396" to="1411" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">New York University 2016 system for KBP event nugget: A deep learning approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Thien Huu Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Meyers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Ninth Text Analysis Conference</title>
		<meeting>Ninth Text Analysis Conference</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Event detection and co-reference with minimal supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoruo</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqiu</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="392" to="402" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">BLANC: Implementing the Rand Index for coreference evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><surname>Recasens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="485" to="510" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Event coreference resolution using mincut based graph clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sangeetha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Arock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth International Workshop on Computer Networks &amp; Communications pages</title>
		<meeting>the Fourth International Workshop on Computer Networks &amp; Communications pages</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="253" to="260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">From light to rich ERE: Annotation of entities, relations, and events</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyi</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ann</forename><surname>Bies</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephanie</forename><surname>Strassel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Riese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Mott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joe</forename><surname>Ellis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seth</forename><surname>Kulick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neville</forename><surname>Ryant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyi</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Workshop on EVENTS</title>
		<meeting>the 3rd Workshop on EVENTS</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="89" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A modeltheoretic coreference scoring scheme</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Vilain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Aberdeen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Message Understanding Conference</title>
		<meeting>the Sixth Message Understanding Conference</meeting>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="45" to="52" />
		</imprint>
	</monogr>
	<note>Dennis Connolly, and Lynette Hirschman</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Learning anaphoricity and antecedent ranking features for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Wiseman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stuart</forename><surname>Shieber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1416" to="1426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A hierarchical distance-dependent Bayesian model for event coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bishan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Frazier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="517" to="528" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
