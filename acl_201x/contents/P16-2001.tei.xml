<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:42+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Transition-based dependency parsing with topological fields</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniël</forename><surname>De Kok</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Seminar für Sprachwissenschaft Wilhemstraße</orgName>
								<address>
									<postCode>19 72072</postCode>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erhard</forename><surname>Hinrichs</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Seminar für Sprachwissenschaft Wilhemstraße</orgName>
								<address>
									<postCode>19 72072</postCode>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Transition-based dependency parsing with topological fields</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1" to="7"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The topological field model is commonly used to describe the regularities in German word order. In this work, we show that topological fields can be predicted reliably using sequence labeling and that the predicted field labels can inform a transition-based dependency parser.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The topological field model <ref type="bibr">(Herling, 1821;</ref><ref type="bibr" target="#b7">Erdmann, 1886;</ref><ref type="bibr" target="#b5">Drach, 1937;</ref><ref type="bibr" target="#b11">Höhle, 1986)</ref> has tra- ditionally been used to account for regularities in word order across different clause types of Ger- man. This model assumes that each clause type contains a left bracket (LK) and a right bracket (RK), which appear to the left and the right of the middle field (MF). Additionally, in a verb-second declarative clause, the LK is preceded by the ini- tial field (VF) with the RK optionally followed by the final field (NF). <ref type="bibr">1</ref>  <ref type="table">Table 1</ref> gives examples of topological fields in verb-second declarative (MC) and verb-final relative (RC) clauses.</p><p>Certain syntactic restrictions can be described in terms of topological fields. For instance, only a single constituent is typically allowed in the VF, while multiple constituents are allowed in the MF and the NF. Many ordering preferences can also be stated using the model. For example, in a main clause, placing the subject in the VF and the direct object in the MF is preferred over the opposite or- der.</p><p>In parsing, topological field analysis is often seen as a task that is embedded in parsing itself. For instance, <ref type="bibr">Kübler (2005)</ref>, <ref type="bibr" target="#b16">Maier (2006)</ref>, and <ref type="bibr" target="#b2">Cheung and Penn (2009)</ref> train PCFG parsers on <ref type="bibr">1</ref> The abbreviations are derived from the German terms linke Klammer, rechte <ref type="bibr">Klammer, Mittelfeld, Vorfeld, and Nachfeld.</ref> treebanks that annotate topological fields as inte- rior nodes. It is perhaps not surprising that this ap- proach works effectively for phrase structure pars- ing, because topological fields favor annotations that do not rely on crossing or discontinuous de- pendencies ( <ref type="bibr" target="#b21">Telljohann et al., 2006</ref>).</p><p>However, the possible role of topological fields in statistical dependency parsing <ref type="bibr">(Kübler et al., 2009)</ref> has not been explored much. We will show that statistical dependency parsing of German can benefit from knowledge of clause structure as pro- vided by the topological field model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Motivation and corpus analysis</head><p>Transition-based dependency parsers <ref type="bibr" target="#b18">(Nivre, 2003;</ref><ref type="bibr" target="#b13">Kübler et al., 2009</ref>) typically use two tran- sitions (LEFT ARC and RIGHT ARC) to introduce a dependency relation between the token that is on top of the processing stack and the next token on the buffer of unprocessed tokens. The decision to make an attachment, the direction of attachment, and the label of the attachment is made by a classifier. Consequently, a good classifier is tasked to learn syntactic constraints, ordering preferences, and selectional preferences.</p><p>Since transition-based dependency parsers pro- cess sentences in one deterministic linear-time left-to-right sweep, the classifier typically has lit- tle global information. One popular approach for reducing the effect of early attachment er- rors is to retain some competition between alter- native parses using a globally optimized model with beam search <ref type="bibr">(Zhang and Clark, 2008)</ref>. Beam search presents a trade-off between speed (smaller beam) and higher accuracy (larger beam). More recently, <ref type="bibr" target="#b6">Dyer et al. (2015)</ref> have proposed to use Long short-term memory networks (LSTMs) to maintain (unbounded) representations of the buffer of unprocessed words, previous parsing ac- <ref type="table">Tansania ist  das Rad mehr  verbreitet als in Uganda  In Tansania  is  the bike more  common than in Uganda  RC:</ref> der fünfmal mehr nach Bremerhaven liefert als Daewoo who five-times more to Bremerhaven delivers than Daewoo <ref type="table">Table 1</ref>: Topological fields of a verb-second clause and a verb-final clause.</p><formula xml:id="formula_0">1 VF LK MF RK NF MC: In</formula><p>tions, and constructed tree fragments. We believe that in the case of German, the topo- logical field model can provide a linguistically- motivated approach for providing the parser with more global knowledge of the sentence structure. More concretely, if we give the transition classi- fier access to topological field annotations, it can learn regularities with respect to the fields wherein the head and dependent of a particular dependency relations lie.</p><p>In the remainder of this section, we provide a short (data-driven) exploration of such regulari- ties. Since there is a myriad of possible triples 2 consisting of relation, head field, and dependent field, we will focus on dependency relations that virtually never cross a field and relations that nearly always cross a field. <ref type="table">Table 2</ref> lists the five dependency relation that cross fields the least often in the TüBa-D/Z tree- bank ( <ref type="bibr" target="#b21">Telljohann et al., 2006;</ref><ref type="bibr" target="#b24">Versley, 2005</ref>) of German newspaper text. Using these statistics, a classifier could learn hard constraints with regard to these dependency relations -they should never be used to attach heads and dependents that are in different fields.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dependency label</head><p>Cross-field (%) Particles 0.00 Determiner 0.03 Adjective or attr. pronoun 0.04 Prepositional complement 0.04 Genetive attribute 0.07 <ref type="table">Table 2</ref>: The five dependency relations that most rarely cross fields in the TüBa-D/Z. <ref type="table">Table 3</ref> lists the five dependency relations that cross fields most frequently. 3 These relations (vir- tually) always cross fields because they are verbal attachments and verbs typically form the LK and RK. This information is somewhat informative, since a classifier should clearly avoid to attach to- kens within the same field using one of these re- lations. However, we can gain more interesting insights by looking at the dependents' fields.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dependency label</head><p>Cross-field (%) Expletive es 100.00 Separated verb prefix 100.00 Subject 100.00 Prepositional object 99.80 Direct object 99.51 <ref type="table">Table 3</ref>: The five dependency relations that most frequently cross fields in the TüBa-D/Z. <ref type="table">Table 4</ref> enumerates the three (where applicable) most frequent head and dependent field combina- tions of the five relations that always cross fields. As expected, the head is always in the LK or RK. Moreover, the dependents are in VF or MF in the far majority of cases. The actual distributions pro- vides some insights with respect to these depen- dency relations. We will discuss the direct object, prepositional object, and separated verb prefix re- lations in some more detail.</p><p>Direct objects In German, direct objects can be put in the VF. However, we can see that di- rect object fronting only happens very rarely in the TüBa-D/Z. This is in line with earlier obser- vations in corpus-based studies (c.f. <ref type="bibr" target="#b25">Weber and Müller (2004)</ref>). Since the probability of having a subject in the VF is much higher, the parser should attach the head of a noun phrase in the VF as a sub- ject, unless there is overwhelming evidence to the contrary, such as case markers, verb agreement, or other cues <ref type="bibr" target="#b22">(Uszkoreit, 1984;</ref><ref type="bibr" target="#b17">Müller, 1999</ref>).</p><p>Prepositional objects The dependency annota- tion scheme used by the TüBa-D/Z makes a dis- tinction between prepositional phrases that are a required complement of a verb (prepositional ob- jects) and other prepositional phrases. Since a sta- tistical dependency parser does not typically have access to a valency dictionary, it has difficulty de-  <ref type="table">Table 4</ref>: The three most frequent head-dependent field combinations of the five relations that always cross fields.</p><p>ciding whether a prepositional phrase is a preposi- tional object or not. Topological field information can complement verb-preposition co-occurrence statistics in deciding between these two different relations. The prepositional object mainly occurs in MF, while a prepositional phrase headed by the LK is almost as likely to be in the VF as in the MF (42.12% and 55.70% respectively).</p><p>Separated verb prefixes Some verbs in German have separable prefixes. A complicating factor in parsing is that such prefixes are often words that can also be used by themselves. For example, in (1-a) fest is a separated prefix of bindet (present tense third person of festbinden), while in (1-b) fest is an optional adverbial modifier of gebunden (the past participle of binden).</p><p>( Similarly to prepositional objects, a statistical parser is handicapped by not having an extensive lexicon. Again, topological fields can complement co-occurence statistics. In (1-a), fest is in the RK.</p><p>As we can see in <ref type="table">Table 4</ref>, the separated verb pre- fix is always in the RK. In contrast, an adverbial modifier as in (1-b) is rarely in the RK (0.35% of the adverbs cases in the TüBa-D/Z).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Predicting fields</head><p>As mentioned in Section 1, topological field an- notation has often been performed as a part of phrase structure parsing. In order to test our hy- pothesis that topological field annotation could in- form dependency parsing, it would be more ap- propriate to use a syntax-less approach. Several shallow approaches have been tried in the past. For instance, <ref type="bibr" target="#b23">Veenstra et al., (2002)</ref> compare three different chunkers (finite state, PCFG, and clas- sification using memory-based learning). <ref type="bibr" target="#b0">Becker and Frank (2002)</ref> predict topological fields using a PCFG specifically tailored towards topological fields. Finally, Liepert <ref type="formula" target="#formula_1">(2003)</ref> proposes a chunker that uses support vector machines.</p><p>In the present work, we will treat the topolog- ical field annotation as a sequence labeling task. This is more useful in the context of dependency parsing because it allows us to treat the topological field as any other property of a token.</p><p>Topological field projection In order to obtain data for training, validation, and evaluation, we use the TüBa-D/Z treebank. Topological fields are only annotated in the constituency version of the TüBa-D/Z, where the fields are represented as special constituent nodes. To obtain token-level field annotations for the dependency version of the treebank, we project the topological fields of the constituency trees on the tokens. The recursive projection function for projection is provided in Appendix B. The function is initially called with the root of the tree and a special unknown field marker, so that tokens that are not dominated by a topological field node (typically punctuation) also receive the topological field feature.</p><p>We should point out that our current projection method results in a loss of information when a sentence contains multiple clauses. For instance, an embedded clause is in a topological field of the main clause, but also has its own topological structure. In our projection method, the topologi- cal field features of tokens in the embedded clause reflect the topological structure of the embedded clause.</p><p>Model Our topological field labeler uses a recur- rent neural network. The inputs consist of con- catenated word and part-of-speech embeddings. The embeddings are fed to a bidirectional LSTM ( <ref type="bibr" target="#b8">Graves and Schmidhuber, 2005</ref>), on which we stack a regular LSTM (Hochreiter and Schmidhu-ber, 1997), and finally an output layer with the softmax activation function. The use of a recur- rent model is motivated by the necessity to have long-distance memory. For example, (2-a) con- sists of a main clause with the LK wird and RK begrünt and an embedded clause wie geplant with its own clausal structure. When the labeler en- counters jetzt, it needs to 'remember' that it was in the MF field of the main clause. Moreover, the use of a bidirectional LSTM is mo- tivated by the need for backwards-flowing infor- mation to make some labeling decisions. For in- stance, die Siegerin is in the VF of the verb-second clause (3-a), while it is in the MF of the verb- final clause (3-b). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Parsing with topological fields</head><p>To evaluate the effectiveness of adding topo- logical fields to the input, we use the publicly available neural network parser described by De <ref type="bibr" target="#b4">Kok (2015)</ref>. This parser uses an architecture that is similar to that of <ref type="bibr" target="#b1">Chen and Manning (2014)</ref>. However, it learns morphological analysis as an embedded task of parsing. Since most inflectional information that can be relevant for parsing Ger- man is available in the prefix or suffix, this parser learns morphological representations over charac- ter embeddings of prefixes and suffixes. We use the same parser configuration as that of De <ref type="bibr" target="#b4">Kok (2015)</ref>, with the addition of topological field annotations. We encode the topological fields as one-hot vectors in the input of the parser. This information is included for the four tokens on top of the stack and the next three tokens on the buffer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation and results</head><p>To evaluate the proposed topological field model, we use the same partitioning of TüBa-D/Z and the word and tag embeddings as De <ref type="bibr" target="#b4">Kok (2015)</ref>. For training, validation, and evaluation of the parser, we use these splits as-is. Since we want to test the parser with non-gold topological field annotations as well, we swapped the training and validation data for training our topological field predictor.</p><p>The parser was trained using the same hyper- parameters and embeddings as in De <ref type="bibr" target="#b4">Kok (2015)</ref>. Our topological field predictor is trained using <ref type="bibr">Keras (Chollet, 2015)</ref>. <ref type="bibr">4</ref> The hyperparameters that we use are summarized in Appendix A. The topo- logical field predictor uses the same word and tag embeddings as the parser.</p><p>In <ref type="table">Table 5</ref>, we show the accuracy of the topo- logical field labeler. The use of a bi-directional LSTM is clearly justified, since it outperforms the stacked unidirectional LSTM by a wide margin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parser</head><p>Accuracy (%) LSTM + LSTM 93.33 Bidirectional LSTM + LSTM 97.24 <ref type="table">Table 5</ref>: Topological field labeling accuracies. The addition of backward flowing information im- proves accuracy considerably. <ref type="table">Table 6</ref> shows the labeled attachment scores (LAS) for parsing with topological fields. As we can see, adding gold topological field annota- tions provides a marked improvement over pars- ing without topological fields. Although the parser does not achieve quite the same performance with the output of the LSTM-based sequence labeler, it is still a relatively large improvement over the parser of De Kok (2015). All differences are sig- nificant at p &lt; 0.0001. <ref type="bibr">5</ref>  <ref type="bibr" target="#b4">De Kok (2015)</ref> 89.49 91.88 Neural net + TFs 90.00 92.36 Neural net + gold TFs 90.42 92.76 <ref type="table">Table 6</ref>: Parse results with topological fields and gold topological fields. Parsers that use topolog- ical field information outperform parsers without access to such information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parser</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LAS UAS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Result analysis</head><p>Our motivation for introducing topological fields in dependency parsing is to provide the parser with a more global view of sentence structure (Sec- tion 2). If this is indeed the case, we expect the parser to improve especially for longer-distance relations. <ref type="figure" target="#fig_0">Figure 1</ref> shows the improvement in LAS as a result of adding gold-standard topolog- ical fields. We see a strong relation between the relation length and the improvement in accuracy. The introduction of topological fields clearly ben- efits the attachment of longer-distance dependents. Since the introduction of topological fields has very little impact on short-distance relations, the differences in the attachment of relations that vir- tually never cross fields <ref type="table">(Table 2</ref>) turn out to be negligable. However, for the relations that cross fields frequently, we see a marked improvements <ref type="table" target="#tab_5">(Table 7)</ref> for every relation except the preposi- tional object. In hindsight, this difference should not be surprising -the relations that never cross fields are usually very local, while those that al- most always cross fields tend to have longer dis- tances and/or are subject to relatively free order- ing.   The ten dependency relations with the highest overall improvement in LAS are shown in <ref type="table" target="#tab_6">Table 8</ref>. Many of these relations are special when it comes to topological field structure and were not dis- cussed in Section 2. The relations parenthesis, de- pendent clause, and sentence link two clauses; the sentence root marks the root of the dependency tree; and the coordinating conjunction (clausal) relation attaches a token that is always in its own field. 6 This confirms that the addition of topologi- cal fields also improves the analysis of the overall clausal structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion and outlook</head><p>In this paper, we have argued and shown that access to topological field information can im- prove the accuracy of transition-based dependency parsers. In future, we plan to see how com- petitive the bidirectional LSTM-based sequence labeling approach is compared to existing ap- proaches. Moreover, we plan to evaluate the use of topological fields in the architecture proposed by <ref type="bibr" target="#b6">Dyer et al., (2015)</ref> to see how many of these regularities that approach captures. <ref type="bibr">Yue Zhang and Stephen Clark. 2008</ref>. A tale of two parsers: investigating and combining graph- based and transition-based dependency parsing us- ing beam-search. In Proceedings of the Conference on Empirical Methods in Natural Language Pro- cessing, pages 562-571. Association for Computa- tional Linguistics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Hyperparameters</head><p>The topological field labeler was trained using Keras <ref type="bibr" target="#b3">(Chollet, 2015)</ref>. Here, we provide a short overview the hyperparameters that we used:</p><p>• Solver: rmsprop, this solver is recommended by the Keras documentation for recurrent neural networks. The solver is used with its default parameters.</p><p>• Learning rate: the learning rate was deter- mined by the function 0.01(1 + 0.02 i ) −2 , where i is the epoch. The intuition was to start with some epochs with a high learning rate, dropping the learning rate quickly. The results were not drastically different when us- ing a constant learning rate of 0.001.</p><p>• Epochs: The models was trained for 200 epochs, then we picked the model of the epoch with the highest performance on the validation data (27 epochs for the unidirec- tional LSTM, 124 epochs for the bidirec- tional LSTM).</p><p>• LSTM layers: all LSTM layers were trained with 50 output dimensions. Increasing the number of output dimensions did not provide an improvement.</p><p>• Regularization: 10% dropout ( <ref type="bibr" target="#b20">Srivastava et al., 2014</ref>) was used after each LSTM layer for regularization. A stronger dropout did not provide better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Topological field projection algorithm</head><p>Algorithm 1 Topological field projection. function PROJECT(node,field) if IS TERMINAL NODE(node) then node.field ← field else if IS TOPO NODE(node) then field ← node.field end if for child ∈ node do <ref type="bibr">PROJECT(child,field)</ref> end for end if end function</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The improvement in labeled attachment score as a result of adding gold topological fields to the parser by dependency length.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table>The LAS ∆ of the parser with access to 
gold standard topological fields compared to the 
De Kok (2015) parser for the relations of Table 4. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 8 :</head><label>8</label><figDesc></figDesc><table>The ten dependency relations with the 
highest LAS ∆ of the parser with access to gold 
topological fields compared to the (de Kok, 2015) 
parser. 

</table></figure>

			<note place="foot" n="2"> 335 in the TüBa-D/Z treebank. 3 Dependency relations that connect two clauses are excluded.</note>

			<note place="foot" n="4"> The software is available from: https://github. com/danieldk/toponn 5 Using paired approximate randomization tests (Noreen, 1989).</note>

			<note place="foot" n="6"> The KOORD field, see Telljohan et al. (2006).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors gratefully acknowledge the financial support of their research by the German Ministry for Education and Research (BMBF) as part of the CLARIN-D research infrastructure grant given to the University of Tübingen. Furthermore, we would like to thank Jianqiang Ma for his extensive comments on an early draft of this paper.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A stochastic topological parser for German</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anette</forename><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th international conference on Computational linguistics</title>
		<meeting>the 19th international conference on Computational linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A fast and accurate dependency parser using neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="740" to="750" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Topological field parsing of German</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jackie</forename><forename type="middle">Chi</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kit</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerald</forename><surname>Penn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="64" to="72" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Chollet</surname></persName>
		</author>
		<ptr target="https://github.com/fchollet/keras" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A poor man&apos;s morphology for German transition-based dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daniël De Kok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Treebanks and Linguistic Theories (TLT14)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Grundgedanken der Deutschen Satzlehre</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erich</forename><surname>Drach</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1937" />
			<pubPlace>Frankfurt/Main</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Transitionbased dependency parsing with stack long shortterm memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Austin</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015-07" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="334" to="343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Grundzüge der deutschen Syntax nach ihrer geschichtlichen Entwicklung dargestellt</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oskar</forename><surname>Erdmann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1886" />
			<pubPlace>Stuttgart</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Cotta. Erste Abteilung</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Framewise phoneme classification with bidirectional lstm and other neural network architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="602" to="610" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">1821. ¨ Uber die Topik der deutschen Sprache</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Herling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Abhandlungen des frankfurterischen Gelehrtenvereins für deutsche Sprache</title>
		<meeting><address><addrLine>Frankfurt/Main. Drittes Stück</addrLine></address></meeting>
		<imprint>
			<biblScope unit="volume">394</biblScope>
			<biblScope unit="page" from="296" to="362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Der Begriff &apos;Mittelfeld</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tilman</forename><surname>Höhle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">AnmerkungenüberAnmerkungen¨Anmerkungenüber die Theorie der topologischen Felder</title>
	</analytic>
	<monogr>
		<title level="m">Akten des 7. Internationalen Germanistenkongresses Göttingen</title>
		<editor>A. Schöne</editor>
		<meeting><address><addrLine>Tübingen</addrLine></address></meeting>
		<imprint>
			<publisher>Niemeyer</publisher>
			<biblScope unit="page" from="329" to="340" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandra</forename><surname>Kübler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthesis Lectures on Human Language Technologies</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="127" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">How do treebank annotation schemes influence parsing results? or how not to compare apples and oranges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandra</forename><surname>Kübler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of RANLP 2005</title>
		<meeting>RANLP 2005</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Topological fields chunking for German with SVM&apos;s: Optimizing SVM-parameters with GA&apos;s</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martina</forename><surname>Liepert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Recent Advances in Natural Language Processing</title>
		<meeting>the International Conference on Recent Advances in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Annotation schemes and their influence on parsing results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Maier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop</title>
		<meeting>the 21st International Conference on computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="19" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Optimality, markedness, and word order in German</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gereon</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Linguistics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="777" to="818" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An efficient algorithm for projective dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Workshop on Parsing Technologies (IWPT)</title>
		<meeting>the 8th International Workshop on Parsing Technologies (IWPT)</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="149" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Computer intensive methods for hypothesis testing: An introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Eric W Noreen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Stylebook for the tübingen treebank of written German (TüBa-D/Z)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heike</forename><surname>Telljohann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erhard</forename><forename type="middle">W</forename><surname>Hinrichs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandra</forename><surname>Kübler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heike</forename><surname>Zinsmeister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathrin</forename><surname>Beck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Seminar fur Sprachwissenschaft</title>
		<meeting><address><addrLine>Tübingen, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
		<respStmt>
			<orgName>Universität Tubingen</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Word order and constituent structure in German</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans</forename><surname>Uszkoreit</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984" />
			<publisher>CSLI Publications</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Topological field chunking for German</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jorn</forename><surname>Veenstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><forename type="middle">Henrik</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tylman</forename><surname>Ule</surname></persName>
		</author>
		<idno>COLING-02</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th Conference on Natural Language Learning</title>
		<meeting>the 6th Conference on Natural Language Learning<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Parser evaluation across text types</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannick</forename><surname>Versley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Workshop on Treebanks and Linguistic Theories</title>
		<meeting>the Fourth Workshop on Treebanks and Linguistic Theories</meeting>
		<imprint>
			<publisher>TLT</publisher>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Word order variation in German main clauses: A corpus analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karin</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th International conference on Computational Linguistics</title>
		<meeting>the 20th International conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="71" to="77" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
